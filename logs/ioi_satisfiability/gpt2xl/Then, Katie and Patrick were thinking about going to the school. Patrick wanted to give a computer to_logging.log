[2024-07-24 10:18:39,209][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Katie
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:18:39,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,210][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit13', 'circuit15', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:18:39,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,212][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:18:39,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:18:39,215][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit16']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,217][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,220][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,221][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit12', 'circuit26']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit26']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,222][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit26']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:18:39,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit28']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit25']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:18:39,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit22', 'circuit26']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,229][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit11', 'circuit20']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit26']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:18:39,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit26']
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,234][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit22']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20']
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:18:39,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit21']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,242][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit23']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit15', 'circuit17']
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit4', 'circuit9']
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:18:39,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:18:39,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,252][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,254][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,255][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:39,256][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,257][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit16']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,258][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit27']
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,259][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit20']
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit10', 'circuit13']
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit26']
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,260][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:18:39,261][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,262][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,263][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,264][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,265][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,266][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,267][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,268][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,269][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20']
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,270][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit26']
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:18:39,271][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit13', 'circuit20']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit8', 'circuit14']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit18', 'circuit20', 'circuit24', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit25']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,272][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit11']
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit22']
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19']
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,273][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22']
[2024-07-24 10:18:39,274][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit6', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,275][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,276][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,277][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:18:39,278][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,279][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,280][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,281][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,282][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,283][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,284][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,285][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit21']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit23']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,286][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,287][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20']
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,288][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20']
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,289][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:18:39,290][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit24']
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:18:39,291][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,292][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:18:39,293][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,294][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,295][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:18:39,296][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,297][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,298][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:18:39,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,300][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,301][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit12', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit24', 'circuit27']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,302][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,303][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,304][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,305][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,306][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit14', 'circuit17', 'circuit19']
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,307][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,308][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit22']
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,309][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit27']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit19']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit18', 'circuit22']
[2024-07-24 10:18:39,310][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,311][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,312][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,313][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:18:39,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,315][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,317][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,319][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:18:39,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit13', 'circuit15', 'circuit18']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit16']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,321][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,322][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit11', 'circuit13']
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20']
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,324][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:18:39,325][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,326][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit21']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit25']
[2024-07-24 10:18:39,327][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,328][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,329][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit16', 'circuit21', 'circuit24']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:18:39,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,331][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,332][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,334][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,335][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,336][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,337][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:39,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,339][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,340][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:39,341][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:40,602][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:40,603][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,604][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,605][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,606][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,607][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,610][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,611][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,611][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,612][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,616][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,616][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,617][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:40,618][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,619][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,621][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,625][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,627][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,628][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,628][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,629][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,630][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,633][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,637][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,638][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:40,639][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.4662, 0.3402, 0.1936], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,639][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([4.9107e-04, 1.1156e-04, 9.9940e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,640][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.5092, 0.2661, 0.2247], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,641][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0570, 0.0013, 0.9417], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,643][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0767, 0.0059, 0.9174], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,645][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([4.8162e-02, 6.6736e-06, 9.5183e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,649][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.3583, 0.3450, 0.2967], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,649][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.5940, 0.3336, 0.0725], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,650][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.5142, 0.2316, 0.2542], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,651][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.6283, 0.3246, 0.0471], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,652][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.4466, 0.2480, 0.3055], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,652][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.3851, 0.3241, 0.2907], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:40,656][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6605, 0.0748, 0.2063, 0.0584], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,658][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3027e-03, 3.9250e-02, 4.0426e-04, 9.5804e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,660][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2285, 0.1711, 0.0739, 0.5265], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,661][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1125, 0.3845, 0.0327, 0.4703], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,661][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3025, 0.1371, 0.3122, 0.2482], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,662][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1234, 0.1976, 0.0041, 0.6749], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,663][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5943, 0.0284, 0.3557, 0.0215], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,665][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2092, 0.1591, 0.3922, 0.2395], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,669][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0672, 0.4707, 0.0207, 0.4414], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,671][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4205, 0.2348, 0.1266, 0.2181], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,671][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4218, 0.3142, 0.0568, 0.2073], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,672][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4428, 0.1934, 0.1112, 0.2527], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:40,673][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.2603, 0.2708, 0.1668, 0.2194, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,674][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([2.7387e-04, 1.6908e-04, 1.1013e-03, 3.2945e-04, 9.9813e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,676][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.4352, 0.2444, 0.1736, 0.0703, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,678][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([2.1152e-02, 3.0140e-04, 5.1994e-03, 9.7521e-04, 9.7237e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,681][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0782, 0.0129, 0.0906, 0.0148, 0.8034], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,682][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([2.7143e-02, 8.3518e-06, 3.0525e-05, 2.8090e-06, 9.7282e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,683][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.2720, 0.1660, 0.3266, 0.0940, 0.1415], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,684][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.2449, 0.1665, 0.0983, 0.3778, 0.1125], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,684][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.1819, 0.2159, 0.3367, 0.1263, 0.1392], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,687][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.4022, 0.2148, 0.1749, 0.1774, 0.0306], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,691][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.2720, 0.2221, 0.0746, 0.1463, 0.2851], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,692][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.3448, 0.2156, 0.1167, 0.2253, 0.0976], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:40,693][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.4221, 0.0410, 0.0443, 0.0379, 0.0828, 0.3718], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,694][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ were] are: tensor([1.2457e-03, 8.3543e-03, 1.4534e-03, 7.9969e-03, 7.9825e-04, 9.8015e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,695][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.3881, 0.1304, 0.1446, 0.1360, 0.0511, 0.1498], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,695][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0324, 0.0157, 0.0024, 0.0296, 0.0071, 0.9128], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,698][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3141, 0.0630, 0.0830, 0.1004, 0.1131, 0.3264], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,701][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ were] are: tensor([4.4524e-02, 3.7369e-03, 2.3018e-04, 1.1009e-03, 3.6217e-04, 9.5005e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,703][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.2428, 0.0353, 0.4268, 0.0342, 0.2320, 0.0288], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,704][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1419, 0.1152, 0.0858, 0.2177, 0.2032, 0.2362], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,705][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0872, 0.2907, 0.0324, 0.3617, 0.0289, 0.1990], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,706][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.3196, 0.1817, 0.0969, 0.1874, 0.0779, 0.1366], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,706][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2561, 0.1947, 0.0615, 0.1515, 0.0525, 0.2838], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,709][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3507, 0.1729, 0.0873, 0.1962, 0.0691, 0.1239], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:40,713][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.2261, 0.0489, 0.2262, 0.0604, 0.2339, 0.1176, 0.0869],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,714][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([1.0307e-04, 2.0802e-04, 1.0793e-03, 1.2228e-04, 8.1025e-05, 8.1552e-05,
        9.9832e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,715][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.3545, 0.1542, 0.0769, 0.1750, 0.0410, 0.1417, 0.0567],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,716][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([1.8094e-03, 4.1776e-05, 8.1130e-05, 1.1035e-04, 7.5350e-04, 2.6027e-04,
        9.9694e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,717][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0701, 0.0094, 0.0149, 0.0103, 0.0571, 0.0305, 0.8077],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,717][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([6.1944e-03, 1.4065e-05, 3.1195e-05, 2.5022e-06, 8.6644e-07, 7.5432e-07,
        9.9376e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,720][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.2810, 0.0615, 0.2077, 0.0418, 0.1475, 0.0283, 0.2322],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,725][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1517, 0.1172, 0.0518, 0.1598, 0.0734, 0.2818, 0.1643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,726][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2193, 0.2021, 0.0676, 0.2280, 0.0613, 0.1748, 0.0469],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,727][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.2866, 0.1623, 0.1033, 0.1468, 0.0962, 0.1312, 0.0735],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,727][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.2547, 0.1657, 0.0597, 0.1164, 0.0368, 0.0772, 0.2896],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,728][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.3424, 0.1898, 0.0502, 0.2020, 0.0590, 0.0573, 0.0993],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:40,729][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.3423, 0.0803, 0.1193, 0.0533, 0.1520, 0.1016, 0.1193, 0.0319],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,731][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ about] are: tensor([1.2847e-03, 2.7246e-03, 2.2641e-03, 5.2369e-03, 1.7814e-04, 3.0871e-04,
        2.2902e-03, 9.8571e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,736][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.2752, 0.1510, 0.0389, 0.1349, 0.0688, 0.1388, 0.1074, 0.0852],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,737][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ about] are: tensor([1.3395e-03, 8.0229e-04, 6.3540e-04, 2.1686e-03, 1.1105e-03, 9.3942e-03,
        7.3678e-01, 2.4777e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,738][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0776, 0.0140, 0.0137, 0.0170, 0.0187, 0.0669, 0.6947, 0.0974],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,738][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ about] are: tensor([3.1358e-02, 6.3581e-03, 6.8956e-04, 3.2826e-03, 6.0977e-04, 1.5891e-03,
        2.9276e-03, 9.5319e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,739][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.2788, 0.0241, 0.1386, 0.0215, 0.1915, 0.0427, 0.2551, 0.0477],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,740][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1014, 0.0556, 0.0462, 0.1028, 0.0398, 0.1939, 0.2309, 0.2296],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,744][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0702, 0.2102, 0.0194, 0.3363, 0.0163, 0.1889, 0.0413, 0.1175],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,747][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.2209, 0.1488, 0.0947, 0.1484, 0.0686, 0.1173, 0.0786, 0.1228],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,748][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.2295, 0.1579, 0.0527, 0.1411, 0.0341, 0.0763, 0.0606, 0.2477],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,749][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.3016, 0.1207, 0.0535, 0.1775, 0.0472, 0.0827, 0.0718, 0.1449],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:40,750][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.2636, 0.0611, 0.0818, 0.0560, 0.0951, 0.1085, 0.1701, 0.0785, 0.0852],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,750][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ going] are: tensor([7.2515e-04, 4.5758e-04, 3.0476e-04, 3.5449e-04, 9.2273e-05, 3.7615e-04,
        3.6196e-03, 5.6317e-03, 9.8844e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,753][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.2737, 0.0899, 0.0599, 0.1499, 0.0452, 0.0896, 0.1213, 0.1233, 0.0472],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,755][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ going] are: tensor([1.4765e-02, 8.0606e-04, 1.9579e-04, 1.4372e-03, 2.6891e-03, 2.3839e-02,
        3.8294e-02, 4.4541e-02, 8.7343e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,758][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0917, 0.0250, 0.0208, 0.0380, 0.0183, 0.0721, 0.1711, 0.1069, 0.4561],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,759][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ going] are: tensor([6.8440e-02, 2.0077e-04, 4.4843e-04, 9.2548e-05, 5.0001e-05, 1.2315e-04,
        4.9512e-03, 4.7087e-04, 9.2522e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,760][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1848, 0.0310, 0.2192, 0.0234, 0.1958, 0.0270, 0.2069, 0.0456, 0.0662],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,760][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0802, 0.0298, 0.0191, 0.0731, 0.0450, 0.1086, 0.1247, 0.3533, 0.1663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,761][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1028, 0.1479, 0.0416, 0.2277, 0.0223, 0.2185, 0.0394, 0.1416, 0.0581],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,764][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.2116, 0.1281, 0.0792, 0.1254, 0.0772, 0.1076, 0.0773, 0.1188, 0.0748],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,768][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.1781, 0.1168, 0.0438, 0.1112, 0.0432, 0.0776, 0.0826, 0.1003, 0.2464],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,769][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.2765, 0.0852, 0.0642, 0.1002, 0.0419, 0.0610, 0.1034, 0.1753, 0.0922],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:40,770][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3305, 0.0379, 0.0809, 0.0315, 0.1336, 0.1081, 0.1169, 0.0361, 0.1037,
        0.0208], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,771][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.3166e-03, 1.7474e-02, 1.1458e-04, 4.6870e-02, 1.2885e-04, 3.1144e-04,
        3.1300e-04, 3.9359e-02, 3.5666e-03, 8.8755e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,772][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1856, 0.0928, 0.0382, 0.1131, 0.0299, 0.0775, 0.0816, 0.1165, 0.0879,
        0.1769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,772][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2095e-02, 2.8855e-03, 2.9110e-04, 3.2879e-03, 1.1100e-03, 2.3902e-02,
        5.6191e-03, 9.9259e-02, 1.3471e-01, 7.1684e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,776][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0338, 0.0030, 0.0011, 0.0056, 0.0063, 0.0462, 0.0827, 0.0403, 0.6842,
        0.0967], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,780][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0687, 0.0840, 0.0007, 0.0973, 0.0037, 0.0208, 0.0227, 0.0815, 0.0462,
        0.5743], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,780][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1779, 0.0105, 0.0930, 0.0085, 0.0875, 0.0310, 0.1127, 0.0584, 0.0908,
        0.3298], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,781][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0488, 0.0166, 0.0183, 0.0331, 0.0332, 0.0554, 0.1081, 0.1355, 0.2837,
        0.2674], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,782][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0179, 0.1413, 0.0106, 0.2290, 0.0075, 0.1116, 0.0138, 0.0548, 0.0296,
        0.3839], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,783][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1735, 0.1127, 0.0657, 0.1195, 0.0634, 0.0874, 0.0651, 0.1101, 0.0743,
        0.1283], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,785][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1641, 0.1444, 0.0453, 0.1501, 0.0473, 0.0848, 0.0494, 0.0921, 0.0822,
        0.1402], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,790][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2361, 0.0962, 0.0683, 0.1031, 0.0516, 0.0801, 0.0731, 0.1077, 0.0753,
        0.1084], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:40,791][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3875, 0.0345, 0.1013, 0.0223, 0.1348, 0.0388, 0.1223, 0.0340, 0.0871,
        0.0145, 0.0228], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,792][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.2746e-03, 2.1505e-02, 2.9649e-04, 4.6049e-02, 4.3671e-04, 9.9182e-04,
        6.9842e-05, 1.6292e-02, 5.7675e-04, 7.0075e-02, 8.4043e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,793][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1631, 0.0816, 0.0338, 0.0902, 0.0321, 0.1151, 0.0500, 0.1304, 0.0829,
        0.1944, 0.0264], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,794][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.3485e-02, 2.5349e-03, 4.6358e-04, 3.2058e-03, 1.9552e-03, 2.0711e-02,
        2.1215e-02, 4.0790e-02, 6.6962e-02, 1.7879e-01, 6.4988e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,796][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1205, 0.0145, 0.0182, 0.0199, 0.0284, 0.0920, 0.0958, 0.0687, 0.2019,
        0.1617, 0.1783], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,800][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0819, 0.1215, 0.0057, 0.0966, 0.0158, 0.0795, 0.0116, 0.0882, 0.0708,
        0.0858, 0.3426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,802][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2029, 0.0036, 0.2790, 0.0034, 0.2774, 0.0206, 0.1243, 0.0190, 0.0604,
        0.0071, 0.0024], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,802][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0457, 0.0126, 0.0177, 0.0256, 0.0125, 0.0362, 0.0654, 0.0950, 0.1394,
        0.2351, 0.3150], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,803][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0108, 0.0928, 0.0081, 0.1469, 0.0050, 0.0999, 0.0078, 0.0308, 0.0219,
        0.1753, 0.4008], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,804][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1740, 0.0990, 0.0662, 0.1021, 0.0524, 0.0786, 0.0593, 0.1012, 0.0655,
        0.1092, 0.0925], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,805][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1908, 0.1182, 0.0384, 0.1146, 0.0469, 0.0602, 0.0444, 0.0866, 0.0579,
        0.0875, 0.1547], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,809][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2001, 0.0816, 0.0823, 0.0869, 0.0512, 0.0650, 0.0845, 0.0912, 0.0785,
        0.0844, 0.0943], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:40,812][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.1491, 0.0574, 0.1604, 0.0459, 0.1613, 0.0289, 0.0650, 0.0675, 0.0742,
        0.0498, 0.0769, 0.0637], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,813][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ school] are: tensor([1.0502e-04, 1.3428e-03, 4.8398e-04, 2.9946e-04, 3.7392e-04, 1.0955e-04,
        9.2578e-04, 2.6137e-04, 8.3669e-05, 1.3201e-04, 1.7511e-04, 9.9571e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,814][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.2320, 0.0522, 0.0487, 0.0610, 0.1309, 0.0484, 0.1139, 0.0400, 0.0822,
        0.0452, 0.0441, 0.1014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,815][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ school] are: tensor([3.6899e-03, 1.3288e-05, 7.7564e-05, 1.8034e-05, 2.6324e-03, 1.3047e-04,
        1.0455e-03, 4.4326e-04, 1.0556e-03, 1.6996e-03, 1.9236e-03, 9.8727e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,816][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0281, 0.0020, 0.0087, 0.0021, 0.0138, 0.0072, 0.0033, 0.0043, 0.0130,
        0.0097, 0.0195, 0.8883], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,817][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ school] are: tensor([2.5515e-03, 2.9335e-05, 4.1994e-05, 4.3695e-06, 1.8902e-05, 2.6053e-06,
        4.1778e-05, 1.4679e-05, 1.8736e-06, 2.5794e-07, 4.8497e-07, 9.9729e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,821][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.1549, 0.0338, 0.3208, 0.0230, 0.1325, 0.0144, 0.0614, 0.0156, 0.0253,
        0.0087, 0.0204, 0.1892], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,823][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.0398, 0.0151, 0.0078, 0.0265, 0.0529, 0.0369, 0.0144, 0.0973, 0.1216,
        0.1810, 0.3347, 0.0722], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,824][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.1000, 0.0998, 0.0854, 0.0991, 0.0958, 0.0712, 0.0384, 0.0491, 0.0964,
        0.1116, 0.1292, 0.0240], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,825][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.1859, 0.1044, 0.0582, 0.1003, 0.0643, 0.0728, 0.0750, 0.0919, 0.0591,
        0.0824, 0.0901, 0.0156], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,826][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.1285, 0.1008, 0.0545, 0.0973, 0.0440, 0.0560, 0.0461, 0.0663, 0.0339,
        0.0675, 0.0672, 0.2378], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,827][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.2511, 0.0703, 0.0629, 0.0749, 0.0489, 0.0567, 0.0700, 0.1034, 0.0724,
        0.0770, 0.0358, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:40,830][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.3925, 0.0127, 0.0710, 0.0105, 0.1872, 0.0424, 0.1028, 0.0194, 0.0879,
        0.0085, 0.0333, 0.0226, 0.0091], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,834][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.1877e-03, 3.5191e-02, 3.3815e-04, 6.5400e-03, 2.3130e-04, 2.6340e-04,
        1.3578e-03, 2.7271e-03, 9.8715e-04, 4.1139e-03, 2.9265e-04, 3.0480e-04,
        9.4447e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,835][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3474, 0.0455, 0.0493, 0.0378, 0.0280, 0.1738, 0.0700, 0.0530, 0.0602,
        0.0439, 0.0211, 0.0250, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,836][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0158, 0.0021, 0.0010, 0.0023, 0.0012, 0.0112, 0.0077, 0.0181, 0.0370,
        0.0724, 0.1701, 0.1683, 0.4930], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,836][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0403, 0.0135, 0.0084, 0.0259, 0.0106, 0.0259, 0.0305, 0.0410, 0.1000,
        0.1186, 0.1229, 0.0989, 0.3635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,837][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1112, 0.1797, 0.0094, 0.1131, 0.0152, 0.0831, 0.0307, 0.0472, 0.0257,
        0.0626, 0.0683, 0.0158, 0.2383], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,841][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2657, 0.0069, 0.1960, 0.0051, 0.1546, 0.0196, 0.1346, 0.0249, 0.0348,
        0.0093, 0.0045, 0.1408, 0.0033], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,845][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0248, 0.0064, 0.0084, 0.0124, 0.0124, 0.0167, 0.0182, 0.0350, 0.0605,
        0.0788, 0.1582, 0.1113, 0.4570], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,845][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0162, 0.1429, 0.0035, 0.1136, 0.0049, 0.0275, 0.0068, 0.0198, 0.0098,
        0.1045, 0.1422, 0.0072, 0.4012], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,846][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1479, 0.0831, 0.0595, 0.0856, 0.0543, 0.0681, 0.0576, 0.0769, 0.0628,
        0.0828, 0.0723, 0.0607, 0.0882], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,847][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1145, 0.0978, 0.0496, 0.1031, 0.0418, 0.0781, 0.0542, 0.0688, 0.0554,
        0.0882, 0.0613, 0.0596, 0.1276], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,848][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2245, 0.0794, 0.0588, 0.0750, 0.0464, 0.0539, 0.0631, 0.0858, 0.0671,
        0.0655, 0.0369, 0.0408, 0.1028], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:40,852][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.1770, 0.1400, 0.1105, 0.1216, 0.0569, 0.0313, 0.0291, 0.0279, 0.0269,
        0.0827, 0.0402, 0.0332, 0.0660, 0.0567], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,855][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([1.1443e-04, 3.1229e-05, 2.3603e-04, 7.6774e-05, 5.3324e-01, 6.7868e-05,
        2.7915e-05, 3.2484e-05, 1.3178e-04, 3.5772e-05, 2.6666e-05, 2.0583e-05,
        8.6016e-06, 4.6595e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,856][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.1999, 0.0963, 0.0933, 0.0352, 0.0526, 0.0450, 0.0861, 0.0408, 0.0302,
        0.0295, 0.0838, 0.1011, 0.0570, 0.0494], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,857][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([2.0845e-03, 2.7573e-06, 2.9552e-05, 3.5737e-06, 3.7157e-03, 1.1536e-05,
        1.3816e-04, 1.4434e-04, 1.4765e-04, 1.6350e-04, 2.4612e-04, 5.7628e-03,
        3.3304e-04, 9.8722e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,858][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0172, 0.0017, 0.0084, 0.0016, 0.0556, 0.0018, 0.0014, 0.0011, 0.0046,
        0.0075, 0.0029, 0.0060, 0.0174, 0.8728], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,859][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([7.0912e-03, 1.6627e-06, 1.2357e-05, 6.1554e-07, 6.2426e-01, 4.7292e-07,
        5.2805e-08, 4.5358e-07, 4.5470e-07, 8.9173e-08, 1.4000e-07, 7.5205e-07,
        7.2630e-08, 3.6863e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,862][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.1552, 0.0839, 0.2563, 0.0549, 0.1128, 0.0233, 0.0246, 0.0166, 0.0143,
        0.0305, 0.0372, 0.0489, 0.0376, 0.1038], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,866][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0455, 0.0105, 0.0060, 0.0187, 0.0051, 0.0181, 0.0138, 0.0335, 0.0263,
        0.1177, 0.1552, 0.0162, 0.4454, 0.0880], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,867][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0886, 0.0974, 0.2062, 0.0655, 0.0789, 0.0333, 0.0316, 0.0372, 0.0247,
        0.0607, 0.0699, 0.0468, 0.0705, 0.0887], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,868][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.1759, 0.0955, 0.0981, 0.0839, 0.0148, 0.0526, 0.0451, 0.0671, 0.0555,
        0.0747, 0.0794, 0.0640, 0.0786, 0.0147], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,868][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0904, 0.0765, 0.0488, 0.0748, 0.2421, 0.0382, 0.0202, 0.0284, 0.0246,
        0.0503, 0.0490, 0.0175, 0.0446, 0.1945], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,869][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.1170, 0.0703, 0.0441, 0.0631, 0.0396, 0.1192, 0.0597, 0.0934, 0.0717,
        0.0749, 0.0479, 0.0225, 0.1255, 0.0511], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:40,873][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.2109, 0.0249, 0.0257, 0.0249, 0.0604, 0.2444, 0.0849, 0.0148, 0.0430,
        0.0139, 0.0203, 0.0137, 0.0157, 0.0771, 0.1253], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,876][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([7.6173e-05, 3.4636e-05, 4.2604e-05, 6.3698e-05, 2.7144e-05, 8.6328e-04,
        2.2772e-02, 1.5242e-04, 2.5753e-03, 4.9072e-05, 1.5946e-05, 6.7654e-05,
        1.4170e-05, 1.5037e-05, 9.7323e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,877][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1526, 0.0326, 0.0248, 0.0447, 0.0776, 0.0480, 0.1114, 0.0539, 0.0616,
        0.0598, 0.0534, 0.0925, 0.0744, 0.0797, 0.0332], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,878][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([9.0915e-04, 1.2143e-05, 6.2242e-06, 1.2131e-05, 9.5152e-06, 9.5781e-05,
        8.3272e-04, 1.7574e-04, 6.1681e-04, 1.9310e-04, 3.7838e-04, 1.2039e-03,
        1.0518e-03, 1.5608e-03, 9.9294e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,879][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0289, 0.0044, 0.0026, 0.0049, 0.0028, 0.0126, 0.0187, 0.0097, 0.0356,
        0.0196, 0.0185, 0.0393, 0.0592, 0.0388, 0.7043], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,880][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([3.5814e-02, 6.2914e-05, 1.8522e-04, 3.5156e-05, 2.9609e-05, 3.0245e-04,
        3.3086e-03, 9.1610e-05, 1.1642e-03, 1.5476e-05, 7.0834e-06, 9.7726e-05,
        4.7907e-06, 7.9365e-06, 9.5887e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,884][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0956, 0.0213, 0.1944, 0.0139, 0.1342, 0.0109, 0.0963, 0.0209, 0.0323,
        0.0082, 0.0142, 0.1283, 0.0207, 0.1674, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,887][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0191, 0.0046, 0.0013, 0.0093, 0.0015, 0.0104, 0.0178, 0.0215, 0.0324,
        0.0595, 0.0898, 0.0336, 0.4420, 0.0479, 0.2093], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,888][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.1051, 0.0797, 0.0187, 0.1192, 0.0195, 0.0710, 0.0404, 0.0632, 0.0454,
        0.1182, 0.0941, 0.0486, 0.1103, 0.0237, 0.0428], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,889][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.1291, 0.0698, 0.0446, 0.0710, 0.0354, 0.0628, 0.0651, 0.0779, 0.0590,
        0.0693, 0.0640, 0.0559, 0.0924, 0.0416, 0.0620], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,890][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0942, 0.0639, 0.0253, 0.0679, 0.0305, 0.0826, 0.0738, 0.0562, 0.0617,
        0.0614, 0.0515, 0.0303, 0.0633, 0.0266, 0.2107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,891][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.2156, 0.0865, 0.0364, 0.0726, 0.0390, 0.0476, 0.0423, 0.0910, 0.0563,
        0.0627, 0.0278, 0.0335, 0.0936, 0.0396, 0.0556], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:40,894][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2089, 0.0194, 0.0447, 0.0164, 0.0786, 0.0616, 0.0662, 0.0194, 0.0571,
        0.0108, 0.0261, 0.0319, 0.0178, 0.1203, 0.2070, 0.0140],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,898][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3141e-03, 6.1154e-03, 3.9075e-05, 1.7723e-02, 5.3848e-05, 1.2765e-04,
        1.1955e-04, 1.7574e-02, 1.6667e-03, 4.3381e-01, 9.2495e-04, 4.4309e-05,
        3.7855e-03, 3.6451e-05, 5.2625e-05, 5.1562e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,899][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1044, 0.0454, 0.0218, 0.0637, 0.0184, 0.0472, 0.0500, 0.0702, 0.0530,
        0.1007, 0.0189, 0.0331, 0.1852, 0.0193, 0.0508, 0.1180],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,900][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2312e-03, 2.4567e-04, 1.8099e-05, 1.4903e-04, 3.3800e-05, 5.9908e-04,
        1.3486e-04, 1.9302e-03, 2.4266e-03, 1.0802e-02, 1.5230e-02, 2.5212e-03,
        2.4910e-02, 6.0320e-03, 7.4010e-02, 8.5773e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,900][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3481e-02, 8.1189e-04, 2.5745e-04, 1.2951e-03, 9.7316e-04, 7.6968e-03,
        1.3823e-02, 5.5287e-03, 8.9901e-02, 1.1680e-02, 7.6338e-03, 2.0616e-02,
        1.2441e-02, 1.4157e-02, 6.8104e-01, 1.1867e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,901][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0287, 0.0391, 0.0004, 0.0512, 0.0019, 0.0125, 0.0111, 0.0485, 0.0299,
        0.3318, 0.1250, 0.0017, 0.0147, 0.0008, 0.0277, 0.2750],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,905][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0862, 0.0041, 0.0470, 0.0035, 0.0451, 0.0140, 0.0562, 0.0283, 0.0445,
        0.1638, 0.0029, 0.0561, 0.0046, 0.0797, 0.1126, 0.2514],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,909][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0190, 0.0034, 0.0033, 0.0051, 0.0040, 0.0054, 0.0104, 0.0107, 0.0221,
        0.0174, 0.0425, 0.0550, 0.2064, 0.1094, 0.2154, 0.2705],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,910][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0073, 0.0536, 0.0041, 0.0937, 0.0029, 0.0460, 0.0059, 0.0213, 0.0118,
        0.1502, 0.1943, 0.0111, 0.1516, 0.0044, 0.0154, 0.2262],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,911][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1067, 0.0659, 0.0422, 0.0730, 0.0413, 0.0545, 0.0438, 0.0666, 0.0475,
        0.0762, 0.0692, 0.0458, 0.0715, 0.0473, 0.0579, 0.0904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,912][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0885, 0.0718, 0.0295, 0.0879, 0.0325, 0.0575, 0.0370, 0.0654, 0.0651,
        0.1024, 0.0719, 0.0331, 0.0741, 0.0300, 0.0485, 0.1049],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,913][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1765, 0.0700, 0.0498, 0.0704, 0.0414, 0.0564, 0.0487, 0.0694, 0.0531,
        0.0682, 0.0333, 0.0304, 0.0753, 0.0402, 0.0460, 0.0706],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:40,916][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1886, 0.0185, 0.0733, 0.0195, 0.0638, 0.0339, 0.0745, 0.0323, 0.0851,
        0.0174, 0.0219, 0.0287, 0.0148, 0.0864, 0.1824, 0.0211, 0.0378],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,917][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.7597e-04, 4.5106e-04, 1.9865e-04, 3.7635e-04, 1.0648e-03, 1.5214e-04,
        2.3470e-03, 2.9185e-04, 2.1365e-03, 5.6429e-04, 1.8066e-04, 1.1074e-04,
        4.2908e-05, 8.0614e-04, 3.1904e-04, 5.0102e-04, 9.9018e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,918][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1144, 0.0304, 0.0435, 0.0401, 0.0271, 0.0663, 0.0708, 0.0757, 0.0645,
        0.0771, 0.0403, 0.0412, 0.0612, 0.0276, 0.0926, 0.0873, 0.0401],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,921][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([4.1249e-04, 3.0710e-06, 7.0247e-07, 3.2419e-06, 2.9321e-06, 1.2432e-05,
        6.0588e-05, 4.5087e-05, 9.2147e-05, 1.2149e-04, 2.0548e-04, 2.7677e-04,
        3.3706e-04, 6.4007e-04, 1.5242e-02, 8.3567e-03, 9.7419e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,924][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0296, 0.0037, 0.0048, 0.0045, 0.0037, 0.0099, 0.0126, 0.0050, 0.0161,
        0.0155, 0.0142, 0.0203, 0.0193, 0.0308, 0.2002, 0.1128, 0.4968],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,925][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([1.3140e-02, 5.7501e-05, 8.5482e-05, 2.8063e-05, 1.0389e-03, 3.7654e-05,
        3.9447e-04, 4.6864e-05, 1.6286e-04, 1.1243e-05, 1.6532e-05, 2.8431e-05,
        3.2532e-06, 3.9329e-04, 8.8040e-05, 6.6041e-06, 9.8446e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,926][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1354, 0.0138, 0.1596, 0.0124, 0.1150, 0.0158, 0.0836, 0.0210, 0.0342,
        0.0103, 0.0126, 0.1058, 0.0121, 0.1575, 0.0705, 0.0127, 0.0278],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,927][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0144, 0.0032, 0.0036, 0.0040, 0.0025, 0.0039, 0.0051, 0.0088, 0.0095,
        0.0209, 0.0304, 0.0175, 0.1236, 0.0490, 0.1889, 0.2987, 0.2160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,929][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0527, 0.0542, 0.0206, 0.0827, 0.0143, 0.0809, 0.0244, 0.0539, 0.0340,
        0.1107, 0.0855, 0.0418, 0.0720, 0.0188, 0.0655, 0.1472, 0.0407],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,933][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0982, 0.0540, 0.0356, 0.0598, 0.0364, 0.0591, 0.0501, 0.0589, 0.0482,
        0.0663, 0.0550, 0.0551, 0.0752, 0.0436, 0.0758, 0.0806, 0.0480],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,935][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0714, 0.0469, 0.0235, 0.0568, 0.0394, 0.0471, 0.0458, 0.0390, 0.0580,
        0.0690, 0.0512, 0.0350, 0.0614, 0.0430, 0.0534, 0.0749, 0.1844],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,936][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2369, 0.0661, 0.0374, 0.0775, 0.0338, 0.0333, 0.0420, 0.0735, 0.0558,
        0.0545, 0.0171, 0.0245, 0.0622, 0.0295, 0.0369, 0.0547, 0.0644],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:40,937][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2482, 0.0190, 0.0882, 0.0148, 0.0679, 0.0220, 0.0758, 0.0180, 0.0373,
        0.0119, 0.0223, 0.0401, 0.0168, 0.1013, 0.0955, 0.0157, 0.0849, 0.0203],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,938][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.2082e-04, 1.7500e-03, 2.6007e-04, 1.9194e-03, 4.7870e-04, 7.0315e-05,
        4.9457e-05, 1.1632e-02, 1.6708e-03, 6.4077e-03, 2.4460e-02, 1.2781e-04,
        4.6070e-04, 3.7147e-04, 6.0549e-05, 6.2431e-03, 9.3925e-04, 9.4238e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,940][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0803, 0.0402, 0.0211, 0.0615, 0.0187, 0.0488, 0.0370, 0.0678, 0.0574,
        0.1087, 0.0141, 0.0323, 0.1271, 0.0211, 0.0635, 0.1299, 0.0563, 0.0143],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,943][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.0588e-03, 1.9456e-04, 2.7881e-05, 1.1420e-04, 2.7555e-05, 2.4966e-04,
        3.1645e-04, 5.1818e-04, 4.8817e-04, 1.3086e-03, 5.1971e-03, 1.9820e-03,
        8.5814e-03, 2.7363e-03, 3.4528e-02, 6.5703e-02, 1.2964e-01, 7.4532e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,946][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0217, 0.0025, 0.0020, 0.0026, 0.0021, 0.0093, 0.0078, 0.0062, 0.0238,
        0.0097, 0.0103, 0.0130, 0.0126, 0.0193, 0.1919, 0.0752, 0.3817, 0.2082],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,947][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0259, 0.0832, 0.0011, 0.0758, 0.0030, 0.0128, 0.0065, 0.0373, 0.0189,
        0.0659, 0.1759, 0.0066, 0.0221, 0.0012, 0.0063, 0.0491, 0.0097, 0.3986],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,948][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1012, 0.0023, 0.1066, 0.0022, 0.1064, 0.0143, 0.0856, 0.0147, 0.0399,
        0.0054, 0.0019, 0.1236, 0.0020, 0.1842, 0.1280, 0.0073, 0.0704, 0.0039],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,949][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0143, 0.0025, 0.0027, 0.0038, 0.0017, 0.0034, 0.0046, 0.0062, 0.0105,
        0.0106, 0.0184, 0.0161, 0.1041, 0.0319, 0.0835, 0.1479, 0.2365, 0.3012],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,951][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0340, 0.0033, 0.0603, 0.0021, 0.0427, 0.0054, 0.0162, 0.0109,
        0.0777, 0.1787, 0.0112, 0.0961, 0.0032, 0.0167, 0.1154, 0.0176, 0.3016],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,956][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0971, 0.0584, 0.0418, 0.0646, 0.0351, 0.0476, 0.0389, 0.0584, 0.0424,
        0.0672, 0.0583, 0.0418, 0.0625, 0.0403, 0.0489, 0.0806, 0.0498, 0.0663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,957][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0728, 0.0556, 0.0311, 0.0668, 0.0276, 0.0340, 0.0288, 0.0690, 0.0485,
        0.0723, 0.0819, 0.0326, 0.0566, 0.0277, 0.0393, 0.0768, 0.0356, 0.1430],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,958][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1667, 0.0626, 0.0492, 0.0598, 0.0377, 0.0472, 0.0490, 0.0578, 0.0476,
        0.0632, 0.0333, 0.0306, 0.0655, 0.0356, 0.0382, 0.0649, 0.0468, 0.0444],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:40,959][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.1548, 0.0513, 0.0711, 0.0391, 0.0562, 0.0389, 0.0770, 0.0271, 0.0353,
        0.0243, 0.0196, 0.0419, 0.0365, 0.0662, 0.0961, 0.0281, 0.0380, 0.0297,
        0.0688], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,960][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([2.0936e-04, 4.7447e-04, 5.4557e-05, 2.7501e-04, 3.8231e-05, 6.7038e-05,
        7.0674e-04, 1.4918e-04, 7.8012e-05, 2.3904e-04, 2.3135e-04, 6.0591e-04,
        1.9536e-04, 2.2853e-05, 2.7723e-04, 2.0383e-04, 1.4288e-05, 7.6458e-05,
        9.9608e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,964][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1277, 0.0344, 0.0588, 0.0454, 0.0088, 0.0400, 0.0659, 0.0427, 0.0310,
        0.0493, 0.0564, 0.1371, 0.0478, 0.0079, 0.0319, 0.0510, 0.0262, 0.0524,
        0.0853], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,967][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([9.0093e-05, 7.6281e-08, 5.1195e-08, 1.1803e-07, 4.8436e-06, 3.1492e-07,
        9.5080e-06, 9.3694e-07, 6.4988e-06, 2.4069e-06, 3.7985e-06, 1.7575e-04,
        5.4436e-06, 5.7247e-04, 3.6561e-04, 1.0811e-04, 4.2037e-04, 2.8578e-04,
        9.9795e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,968][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([2.3142e-02, 1.6052e-03, 5.3538e-04, 8.6941e-04, 3.8230e-04, 6.3218e-04,
        2.3655e-03, 7.4426e-04, 8.9571e-04, 1.5050e-03, 2.4873e-03, 1.8388e-03,
        4.8452e-03, 1.8804e-03, 5.0141e-03, 9.0117e-03, 2.6254e-02, 2.3890e-02,
        8.9210e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,969][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.6410e-03, 3.2593e-05, 4.8536e-06, 4.8180e-06, 2.4252e-05, 1.2262e-06,
        1.4751e-04, 2.1040e-06, 8.0068e-06, 6.7416e-07, 8.8175e-06, 5.0374e-05,
        5.1245e-07, 7.3360e-06, 4.3616e-05, 3.7334e-07, 1.7774e-07, 4.6395e-06,
        9.9702e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,970][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.1085, 0.0260, 0.1134, 0.0144, 0.1042, 0.0109, 0.0430, 0.0212, 0.0276,
        0.0146, 0.0113, 0.0491, 0.0214, 0.1052, 0.0362, 0.0152, 0.0269, 0.0141,
        0.2366], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,971][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0393, 0.0044, 0.0024, 0.0063, 0.0017, 0.0071, 0.0060, 0.0092, 0.0097,
        0.0124, 0.0201, 0.0580, 0.0649, 0.0185, 0.0565, 0.1325, 0.1538, 0.2934,
        0.1038], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,975][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0901, 0.0479, 0.0407, 0.0514, 0.0267, 0.0343, 0.0323, 0.0271, 0.0412,
        0.0417, 0.0617, 0.1561, 0.0445, 0.0322, 0.0389, 0.0521, 0.0299, 0.0516,
        0.0995], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,978][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1050, 0.0600, 0.0566, 0.0555, 0.0522, 0.0407, 0.0375, 0.0521, 0.0362,
        0.0508, 0.0587, 0.0320, 0.0615, 0.0603, 0.0517, 0.0585, 0.0453, 0.0716,
        0.0137], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,979][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0840, 0.0481, 0.0170, 0.0508, 0.0246, 0.0357, 0.0366, 0.0382, 0.0236,
        0.0458, 0.0549, 0.0374, 0.0493, 0.0242, 0.0400, 0.0475, 0.0224, 0.0480,
        0.2717], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,980][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.2010, 0.0774, 0.0467, 0.0612, 0.0433, 0.0404, 0.0333, 0.0539, 0.0484,
        0.0510, 0.0210, 0.0264, 0.0555, 0.0409, 0.0290, 0.0529, 0.0629, 0.0217,
        0.0333], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:40,981][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1836, 0.0155, 0.0377, 0.0131, 0.0654, 0.0507, 0.0536, 0.0149, 0.0461,
        0.0083, 0.0204, 0.0267, 0.0139, 0.0978, 0.1643, 0.0106, 0.0685, 0.0232,
        0.0725, 0.0132], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,983][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5353e-03, 3.2721e-03, 1.9794e-05, 9.5140e-03, 2.9979e-05, 7.5053e-05,
        6.6821e-05, 1.0198e-02, 9.6837e-04, 2.5979e-01, 5.4316e-04, 2.5219e-05,
        2.5322e-03, 2.2823e-05, 3.4452e-05, 3.2995e-01, 2.5556e-04, 3.9130e-04,
        1.9586e-05, 3.8076e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,987][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0870, 0.0348, 0.0175, 0.0514, 0.0153, 0.0388, 0.0404, 0.0581, 0.0440,
        0.0813, 0.0152, 0.0303, 0.1494, 0.0164, 0.0413, 0.0959, 0.0417, 0.0147,
        0.0204, 0.1061], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,989][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.2118e-04, 4.3811e-05, 3.0991e-06, 1.9502e-05, 3.6178e-06, 4.6852e-05,
        1.0245e-05, 1.1374e-04, 1.2649e-04, 4.6143e-04, 6.2177e-04, 1.1208e-04,
        1.1061e-03, 2.6300e-04, 2.8791e-03, 3.0919e-02, 2.6223e-01, 7.0254e-02,
        1.4458e-02, 6.1541e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,990][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3304e-02, 7.1491e-04, 1.9848e-04, 1.0496e-03, 5.9764e-04, 4.4613e-03,
        7.6358e-03, 2.8452e-03, 3.9847e-02, 5.0118e-03, 3.1063e-03, 7.6195e-03,
        4.8672e-03, 4.8311e-03, 2.5092e-01, 4.3967e-02, 2.0224e-01, 6.4984e-02,
        1.3282e-01, 2.0897e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,991][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0182, 0.0262, 0.0003, 0.0364, 0.0013, 0.0101, 0.0080, 0.0362, 0.0238,
        0.2449, 0.0924, 0.0011, 0.0102, 0.0005, 0.0228, 0.2023, 0.0066, 0.0698,
        0.0022, 0.1868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,992][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0544, 0.0024, 0.0293, 0.0021, 0.0290, 0.0082, 0.0347, 0.0178, 0.0279,
        0.1063, 0.0016, 0.0353, 0.0028, 0.0519, 0.0702, 0.1657, 0.0410, 0.0033,
        0.1069, 0.2093], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,995][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0148, 0.0021, 0.0020, 0.0027, 0.0017, 0.0020, 0.0034, 0.0031, 0.0057,
        0.0039, 0.0094, 0.0120, 0.0450, 0.0226, 0.0407, 0.0505, 0.1042, 0.1803,
        0.1847, 0.3090], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:40,999][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0048, 0.0339, 0.0026, 0.0615, 0.0018, 0.0303, 0.0040, 0.0137, 0.0075,
        0.0959, 0.1211, 0.0074, 0.0967, 0.0028, 0.0099, 0.1446, 0.0113, 0.1554,
        0.0095, 0.1852], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,000][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0838, 0.0495, 0.0331, 0.0564, 0.0326, 0.0422, 0.0349, 0.0515, 0.0371,
        0.0578, 0.0526, 0.0368, 0.0562, 0.0375, 0.0453, 0.0692, 0.0477, 0.0632,
        0.0341, 0.0787], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,001][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0628, 0.0475, 0.0218, 0.0619, 0.0246, 0.0429, 0.0287, 0.0498, 0.0512,
        0.0784, 0.0561, 0.0278, 0.0614, 0.0258, 0.0418, 0.0870, 0.0452, 0.0653,
        0.0284, 0.0917], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,002][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1534, 0.0590, 0.0429, 0.0586, 0.0377, 0.0480, 0.0409, 0.0550, 0.0448,
        0.0553, 0.0271, 0.0238, 0.0571, 0.0340, 0.0366, 0.0546, 0.0425, 0.0347,
        0.0391, 0.0549], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,014][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:41,015][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,016][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,017][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,017][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,019][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,020][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,021][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,023][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,027][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,028][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,028][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,029][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,030][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,030][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,033][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,038][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,038][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,039][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,040][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,041][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,041][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,043][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,047][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,049][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,050][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.4662, 0.3402, 0.1936], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,050][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([4.9107e-04, 1.1156e-04, 9.9940e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,051][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.5092, 0.2661, 0.2247], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,052][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0570, 0.0013, 0.9417], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,054][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0767, 0.0059, 0.9174], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,056][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([4.8162e-02, 6.6736e-06, 9.5183e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,060][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.3583, 0.3450, 0.2967], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,060][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.5940, 0.3336, 0.0725], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,061][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.5142, 0.2316, 0.2542], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,062][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.6283, 0.3246, 0.0471], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,063][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.4466, 0.2480, 0.3055], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,064][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.3851, 0.3241, 0.2907], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,067][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6605, 0.0748, 0.2063, 0.0584], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,070][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3027e-03, 3.9250e-02, 4.0426e-04, 9.5804e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,071][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2285, 0.1711, 0.0739, 0.5265], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,072][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1125, 0.3845, 0.0327, 0.4703], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,073][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3025, 0.1371, 0.3122, 0.2482], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,073][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1234, 0.1976, 0.0041, 0.6749], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,074][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5943, 0.0284, 0.3557, 0.0215], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,077][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2092, 0.1591, 0.3922, 0.2395], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,081][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0672, 0.4707, 0.0207, 0.4414], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,082][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4205, 0.2348, 0.1266, 0.2181], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,083][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4218, 0.3142, 0.0568, 0.2073], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,084][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4428, 0.1934, 0.1112, 0.2527], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,084][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.2603, 0.2708, 0.1668, 0.2194, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,085][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([2.7387e-04, 1.6908e-04, 1.1013e-03, 3.2945e-04, 9.9813e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,089][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.4352, 0.2444, 0.1736, 0.0703, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,092][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([2.1152e-02, 3.0140e-04, 5.1994e-03, 9.7521e-04, 9.7237e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,093][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0782, 0.0129, 0.0906, 0.0148, 0.8034], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,093][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([2.7143e-02, 8.3518e-06, 3.0525e-05, 2.8090e-06, 9.7282e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,094][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.2720, 0.1660, 0.3266, 0.0940, 0.1415], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,095][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.2449, 0.1665, 0.0983, 0.3778, 0.1125], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,096][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.1819, 0.2159, 0.3367, 0.1263, 0.1392], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,099][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.4022, 0.2148, 0.1749, 0.1774, 0.0306], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,103][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2720, 0.2221, 0.0746, 0.1463, 0.2851], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,104][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.3448, 0.2156, 0.1167, 0.2253, 0.0976], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,105][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4221, 0.0410, 0.0443, 0.0379, 0.0828, 0.3718], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,105][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([1.2457e-03, 8.3543e-03, 1.4534e-03, 7.9969e-03, 7.9825e-04, 9.8015e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,106][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.3881, 0.1304, 0.1446, 0.1360, 0.0511, 0.1498], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,108][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0324, 0.0157, 0.0024, 0.0296, 0.0071, 0.9128], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,112][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.3141, 0.0630, 0.0830, 0.1004, 0.1131, 0.3264], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,114][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([4.4524e-02, 3.7369e-03, 2.3018e-04, 1.1009e-03, 3.6217e-04, 9.5005e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,115][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2428, 0.0353, 0.4268, 0.0342, 0.2320, 0.0288], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,115][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1419, 0.1152, 0.0858, 0.2177, 0.2032, 0.2362], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,116][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0872, 0.2907, 0.0324, 0.3617, 0.0289, 0.1990], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,117][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.3196, 0.1817, 0.0969, 0.1874, 0.0779, 0.1366], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,120][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2561, 0.1947, 0.0615, 0.1515, 0.0525, 0.2838], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,124][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.3507, 0.1729, 0.0873, 0.1962, 0.0691, 0.1239], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,125][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.2261, 0.0489, 0.2262, 0.0604, 0.2339, 0.1176, 0.0869],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,126][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([1.0307e-04, 2.0802e-04, 1.0793e-03, 1.2228e-04, 8.1025e-05, 8.1552e-05,
        9.9832e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,127][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.3545, 0.1542, 0.0769, 0.1750, 0.0410, 0.1417, 0.0567],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,127][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([1.8094e-03, 4.1776e-05, 8.1130e-05, 1.1035e-04, 7.5350e-04, 2.6027e-04,
        9.9694e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,128][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0701, 0.0094, 0.0149, 0.0103, 0.0571, 0.0305, 0.8077],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,130][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([6.1944e-03, 1.4065e-05, 3.1195e-05, 2.5022e-06, 8.6644e-07, 7.5432e-07,
        9.9376e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,134][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.2810, 0.0615, 0.2077, 0.0418, 0.1475, 0.0283, 0.2322],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,136][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.1517, 0.1172, 0.0518, 0.1598, 0.0734, 0.2818, 0.1643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,137][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.2193, 0.2021, 0.0676, 0.2280, 0.0613, 0.1748, 0.0469],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,137][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.2866, 0.1623, 0.1033, 0.1468, 0.0962, 0.1312, 0.0735],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,138][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.2547, 0.1657, 0.0597, 0.1164, 0.0368, 0.0772, 0.2896],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,139][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.3424, 0.1898, 0.0502, 0.2020, 0.0590, 0.0573, 0.0993],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,142][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.3423, 0.0803, 0.1193, 0.0533, 0.1520, 0.1016, 0.1193, 0.0319],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,144][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([1.2847e-03, 2.7246e-03, 2.2641e-03, 5.2369e-03, 1.7814e-04, 3.0871e-04,
        2.2902e-03, 9.8571e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,147][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2752, 0.1510, 0.0389, 0.1349, 0.0688, 0.1388, 0.1074, 0.0852],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,147][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([1.3395e-03, 8.0229e-04, 6.3540e-04, 2.1686e-03, 1.1105e-03, 9.3942e-03,
        7.3678e-01, 2.4777e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,148][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0776, 0.0140, 0.0137, 0.0170, 0.0187, 0.0669, 0.6947, 0.0974],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,149][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([3.1358e-02, 6.3581e-03, 6.8956e-04, 3.2826e-03, 6.0977e-04, 1.5891e-03,
        2.9276e-03, 9.5319e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,150][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.2788, 0.0241, 0.1386, 0.0215, 0.1915, 0.0427, 0.2551, 0.0477],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,153][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.1014, 0.0556, 0.0462, 0.1028, 0.0398, 0.1939, 0.2309, 0.2296],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,157][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0702, 0.2102, 0.0194, 0.3363, 0.0163, 0.1889, 0.0413, 0.1175],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,158][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.2209, 0.1488, 0.0947, 0.1484, 0.0686, 0.1173, 0.0786, 0.1228],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,159][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.2295, 0.1579, 0.0527, 0.1411, 0.0341, 0.0763, 0.0606, 0.2477],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,160][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.3016, 0.1207, 0.0535, 0.1775, 0.0472, 0.0827, 0.0718, 0.1449],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,160][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.2636, 0.0611, 0.0818, 0.0560, 0.0951, 0.1085, 0.1701, 0.0785, 0.0852],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,161][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([7.2515e-04, 4.5758e-04, 3.0476e-04, 3.5449e-04, 9.2273e-05, 3.7615e-04,
        3.6196e-03, 5.6317e-03, 9.8844e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,165][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2737, 0.0899, 0.0599, 0.1499, 0.0452, 0.0896, 0.1213, 0.1233, 0.0472],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,168][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([1.4765e-02, 8.0606e-04, 1.9579e-04, 1.4372e-03, 2.6891e-03, 2.3839e-02,
        3.8294e-02, 4.4541e-02, 8.7343e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,169][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0917, 0.0250, 0.0208, 0.0380, 0.0183, 0.0721, 0.1711, 0.1069, 0.4561],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,170][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([6.8440e-02, 2.0077e-04, 4.4843e-04, 9.2548e-05, 5.0001e-05, 1.2315e-04,
        4.9512e-03, 4.7087e-04, 9.2522e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,171][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.1848, 0.0310, 0.2192, 0.0234, 0.1958, 0.0270, 0.2069, 0.0456, 0.0662],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,171][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0802, 0.0298, 0.0191, 0.0731, 0.0450, 0.1086, 0.1247, 0.3533, 0.1663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,174][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1028, 0.1479, 0.0416, 0.2277, 0.0223, 0.2185, 0.0394, 0.1416, 0.0581],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,179][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.2116, 0.1281, 0.0792, 0.1254, 0.0772, 0.1076, 0.0773, 0.1188, 0.0748],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,180][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1781, 0.1168, 0.0438, 0.1112, 0.0432, 0.0776, 0.0826, 0.1003, 0.2464],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,181][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.2765, 0.0852, 0.0642, 0.1002, 0.0419, 0.0610, 0.1034, 0.1753, 0.0922],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,182][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3305, 0.0379, 0.0809, 0.0315, 0.1336, 0.1081, 0.1169, 0.0361, 0.1037,
        0.0208], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,182][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.3166e-03, 1.7474e-02, 1.1458e-04, 4.6870e-02, 1.2885e-04, 3.1144e-04,
        3.1300e-04, 3.9359e-02, 3.5666e-03, 8.8755e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,185][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1856, 0.0928, 0.0382, 0.1131, 0.0299, 0.0775, 0.0816, 0.1165, 0.0879,
        0.1769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,187][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2095e-02, 2.8855e-03, 2.9110e-04, 3.2879e-03, 1.1100e-03, 2.3902e-02,
        5.6191e-03, 9.9259e-02, 1.3471e-01, 7.1684e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,190][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0338, 0.0030, 0.0011, 0.0056, 0.0063, 0.0462, 0.0827, 0.0403, 0.6842,
        0.0967], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,191][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0687, 0.0840, 0.0007, 0.0973, 0.0037, 0.0208, 0.0227, 0.0815, 0.0462,
        0.5743], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,192][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1779, 0.0105, 0.0930, 0.0085, 0.0875, 0.0310, 0.1127, 0.0584, 0.0908,
        0.3298], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,193][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0488, 0.0166, 0.0183, 0.0331, 0.0332, 0.0554, 0.1081, 0.1355, 0.2837,
        0.2674], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,193][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0179, 0.1413, 0.0106, 0.2290, 0.0075, 0.1116, 0.0138, 0.0548, 0.0296,
        0.3839], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,196][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1735, 0.1127, 0.0657, 0.1195, 0.0634, 0.0874, 0.0651, 0.1101, 0.0743,
        0.1283], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,201][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1641, 0.1444, 0.0453, 0.1501, 0.0473, 0.0848, 0.0494, 0.0921, 0.0822,
        0.1402], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,202][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2361, 0.0962, 0.0683, 0.1031, 0.0516, 0.0801, 0.0731, 0.1077, 0.0753,
        0.1084], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,203][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3875, 0.0345, 0.1013, 0.0223, 0.1348, 0.0388, 0.1223, 0.0340, 0.0871,
        0.0145, 0.0228], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,203][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.2746e-03, 2.1505e-02, 2.9649e-04, 4.6049e-02, 4.3671e-04, 9.9182e-04,
        6.9842e-05, 1.6292e-02, 5.7675e-04, 7.0075e-02, 8.4043e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,204][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1631, 0.0816, 0.0338, 0.0902, 0.0321, 0.1151, 0.0500, 0.1304, 0.0829,
        0.1944, 0.0264], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,206][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.3485e-02, 2.5349e-03, 4.6358e-04, 3.2058e-03, 1.9552e-03, 2.0711e-02,
        2.1215e-02, 4.0790e-02, 6.6962e-02, 1.7879e-01, 6.4988e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,210][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1205, 0.0145, 0.0182, 0.0199, 0.0284, 0.0920, 0.0958, 0.0687, 0.2019,
        0.1617, 0.1783], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,212][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0819, 0.1215, 0.0057, 0.0966, 0.0158, 0.0795, 0.0116, 0.0882, 0.0708,
        0.0858, 0.3426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,213][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2029, 0.0036, 0.2790, 0.0034, 0.2774, 0.0206, 0.1243, 0.0190, 0.0604,
        0.0071, 0.0024], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,214][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0457, 0.0126, 0.0177, 0.0256, 0.0125, 0.0362, 0.0654, 0.0950, 0.1394,
        0.2351, 0.3150], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,215][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0108, 0.0928, 0.0081, 0.1469, 0.0050, 0.0999, 0.0078, 0.0308, 0.0219,
        0.1753, 0.4008], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,215][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1740, 0.0990, 0.0662, 0.1021, 0.0524, 0.0786, 0.0593, 0.1012, 0.0655,
        0.1092, 0.0925], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,219][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1908, 0.1182, 0.0384, 0.1146, 0.0469, 0.0602, 0.0444, 0.0866, 0.0579,
        0.0875, 0.1547], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,223][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2001, 0.0816, 0.0823, 0.0869, 0.0512, 0.0650, 0.0845, 0.0912, 0.0785,
        0.0844, 0.0943], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,224][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.1491, 0.0574, 0.1604, 0.0459, 0.1613, 0.0289, 0.0650, 0.0675, 0.0742,
        0.0498, 0.0769, 0.0637], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,224][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([1.0502e-04, 1.3428e-03, 4.8398e-04, 2.9946e-04, 3.7392e-04, 1.0955e-04,
        9.2578e-04, 2.6137e-04, 8.3669e-05, 1.3201e-04, 1.7511e-04, 9.9571e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,225][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.2320, 0.0522, 0.0487, 0.0610, 0.1309, 0.0484, 0.1139, 0.0400, 0.0822,
        0.0452, 0.0441, 0.1014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,226][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([3.6899e-03, 1.3288e-05, 7.7564e-05, 1.8034e-05, 2.6324e-03, 1.3047e-04,
        1.0455e-03, 4.4326e-04, 1.0556e-03, 1.6996e-03, 1.9236e-03, 9.8727e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,229][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.0281, 0.0020, 0.0087, 0.0021, 0.0138, 0.0072, 0.0033, 0.0043, 0.0130,
        0.0097, 0.0195, 0.8883], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,232][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([2.5515e-03, 2.9335e-05, 4.1994e-05, 4.3695e-06, 1.8902e-05, 2.6053e-06,
        4.1778e-05, 1.4679e-05, 1.8736e-06, 2.5794e-07, 4.8497e-07, 9.9729e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,234][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.1549, 0.0338, 0.3208, 0.0230, 0.1325, 0.0144, 0.0614, 0.0156, 0.0253,
        0.0087, 0.0204, 0.1892], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,235][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0398, 0.0151, 0.0078, 0.0265, 0.0529, 0.0369, 0.0144, 0.0973, 0.1216,
        0.1810, 0.3347, 0.0722], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,235][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.1000, 0.0998, 0.0854, 0.0991, 0.0958, 0.0712, 0.0384, 0.0491, 0.0964,
        0.1116, 0.1292, 0.0240], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,236][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.1859, 0.1044, 0.0582, 0.1003, 0.0643, 0.0728, 0.0750, 0.0919, 0.0591,
        0.0824, 0.0901, 0.0156], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,237][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.1285, 0.1008, 0.0545, 0.0973, 0.0440, 0.0560, 0.0461, 0.0663, 0.0339,
        0.0675, 0.0672, 0.2378], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,241][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.2511, 0.0703, 0.0629, 0.0749, 0.0489, 0.0567, 0.0700, 0.1034, 0.0724,
        0.0770, 0.0358, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,247][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.3925, 0.0127, 0.0710, 0.0105, 0.1872, 0.0424, 0.1028, 0.0194, 0.0879,
        0.0085, 0.0333, 0.0226, 0.0091], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,248][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.1877e-03, 3.5191e-02, 3.3815e-04, 6.5400e-03, 2.3130e-04, 2.6340e-04,
        1.3578e-03, 2.7271e-03, 9.8715e-04, 4.1139e-03, 2.9265e-04, 3.0480e-04,
        9.4447e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,249][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3474, 0.0455, 0.0493, 0.0378, 0.0280, 0.1738, 0.0700, 0.0530, 0.0602,
        0.0439, 0.0211, 0.0250, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,249][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0158, 0.0021, 0.0010, 0.0023, 0.0012, 0.0112, 0.0077, 0.0181, 0.0370,
        0.0724, 0.1701, 0.1683, 0.4930], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,250][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0403, 0.0135, 0.0084, 0.0259, 0.0106, 0.0259, 0.0305, 0.0410, 0.1000,
        0.1186, 0.1229, 0.0989, 0.3635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,253][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1112, 0.1797, 0.0094, 0.1131, 0.0152, 0.0831, 0.0307, 0.0472, 0.0257,
        0.0626, 0.0683, 0.0158, 0.2383], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,258][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2657, 0.0069, 0.1960, 0.0051, 0.1546, 0.0196, 0.1346, 0.0249, 0.0348,
        0.0093, 0.0045, 0.1408, 0.0033], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,259][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0248, 0.0064, 0.0084, 0.0124, 0.0124, 0.0167, 0.0182, 0.0350, 0.0605,
        0.0788, 0.1582, 0.1113, 0.4570], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,259][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0162, 0.1429, 0.0035, 0.1136, 0.0049, 0.0275, 0.0068, 0.0198, 0.0098,
        0.1045, 0.1422, 0.0072, 0.4012], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,260][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1479, 0.0831, 0.0595, 0.0856, 0.0543, 0.0681, 0.0576, 0.0769, 0.0628,
        0.0828, 0.0723, 0.0607, 0.0882], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,261][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1145, 0.0978, 0.0496, 0.1031, 0.0418, 0.0781, 0.0542, 0.0688, 0.0554,
        0.0882, 0.0613, 0.0596, 0.1276], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,264][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2245, 0.0794, 0.0588, 0.0750, 0.0464, 0.0539, 0.0631, 0.0858, 0.0671,
        0.0655, 0.0369, 0.0408, 0.1028], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,269][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.1770, 0.1400, 0.1105, 0.1216, 0.0569, 0.0313, 0.0291, 0.0279, 0.0269,
        0.0827, 0.0402, 0.0332, 0.0660, 0.0567], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,270][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([1.1443e-04, 3.1229e-05, 2.3603e-04, 7.6774e-05, 5.3324e-01, 6.7868e-05,
        2.7915e-05, 3.2484e-05, 1.3178e-04, 3.5772e-05, 2.6666e-05, 2.0583e-05,
        8.6016e-06, 4.6595e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,271][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1999, 0.0963, 0.0933, 0.0352, 0.0526, 0.0450, 0.0861, 0.0408, 0.0302,
        0.0295, 0.0838, 0.1011, 0.0570, 0.0494], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,271][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([2.0845e-03, 2.7573e-06, 2.9552e-05, 3.5737e-06, 3.7157e-03, 1.1536e-05,
        1.3816e-04, 1.4434e-04, 1.4765e-04, 1.6350e-04, 2.4612e-04, 5.7628e-03,
        3.3304e-04, 9.8722e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,272][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0172, 0.0017, 0.0084, 0.0016, 0.0556, 0.0018, 0.0014, 0.0011, 0.0046,
        0.0075, 0.0029, 0.0060, 0.0174, 0.8728], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,274][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([7.0912e-03, 1.6627e-06, 1.2357e-05, 6.1554e-07, 6.2426e-01, 4.7292e-07,
        5.2805e-08, 4.5358e-07, 4.5470e-07, 8.9173e-08, 1.4000e-07, 7.5205e-07,
        7.2630e-08, 3.6863e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,278][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.1552, 0.0839, 0.2563, 0.0549, 0.1128, 0.0233, 0.0246, 0.0166, 0.0143,
        0.0305, 0.0372, 0.0489, 0.0376, 0.1038], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,280][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0455, 0.0105, 0.0060, 0.0187, 0.0051, 0.0181, 0.0138, 0.0335, 0.0263,
        0.1177, 0.1552, 0.0162, 0.4454, 0.0880], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,281][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0886, 0.0974, 0.2062, 0.0655, 0.0789, 0.0333, 0.0316, 0.0372, 0.0247,
        0.0607, 0.0699, 0.0468, 0.0705, 0.0887], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,282][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.1759, 0.0955, 0.0981, 0.0839, 0.0148, 0.0526, 0.0451, 0.0671, 0.0555,
        0.0747, 0.0794, 0.0640, 0.0786, 0.0147], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,283][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0904, 0.0765, 0.0488, 0.0748, 0.2421, 0.0382, 0.0202, 0.0284, 0.0246,
        0.0503, 0.0490, 0.0175, 0.0446, 0.1945], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,284][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.1170, 0.0703, 0.0441, 0.0631, 0.0396, 0.1192, 0.0597, 0.0934, 0.0717,
        0.0749, 0.0479, 0.0225, 0.1255, 0.0511], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,287][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.2109, 0.0249, 0.0257, 0.0249, 0.0604, 0.2444, 0.0849, 0.0148, 0.0430,
        0.0139, 0.0203, 0.0137, 0.0157, 0.0771, 0.1253], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,291][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([7.6173e-05, 3.4636e-05, 4.2604e-05, 6.3698e-05, 2.7144e-05, 8.6328e-04,
        2.2772e-02, 1.5242e-04, 2.5753e-03, 4.9072e-05, 1.5946e-05, 6.7654e-05,
        1.4170e-05, 1.5037e-05, 9.7323e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,291][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1526, 0.0326, 0.0248, 0.0447, 0.0776, 0.0480, 0.1114, 0.0539, 0.0616,
        0.0598, 0.0534, 0.0925, 0.0744, 0.0797, 0.0332], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,292][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([9.0915e-04, 1.2143e-05, 6.2242e-06, 1.2131e-05, 9.5152e-06, 9.5781e-05,
        8.3272e-04, 1.7574e-04, 6.1681e-04, 1.9310e-04, 3.7838e-04, 1.2039e-03,
        1.0518e-03, 1.5608e-03, 9.9294e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,293][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0289, 0.0044, 0.0026, 0.0049, 0.0028, 0.0126, 0.0187, 0.0097, 0.0356,
        0.0196, 0.0185, 0.0393, 0.0592, 0.0388, 0.7043], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,294][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([3.5814e-02, 6.2914e-05, 1.8522e-04, 3.5156e-05, 2.9609e-05, 3.0245e-04,
        3.3086e-03, 9.1610e-05, 1.1642e-03, 1.5476e-05, 7.0834e-06, 9.7726e-05,
        4.7907e-06, 7.9365e-06, 9.5887e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,298][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0956, 0.0213, 0.1944, 0.0139, 0.1342, 0.0109, 0.0963, 0.0209, 0.0323,
        0.0082, 0.0142, 0.1283, 0.0207, 0.1674, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,301][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0191, 0.0046, 0.0013, 0.0093, 0.0015, 0.0104, 0.0178, 0.0215, 0.0324,
        0.0595, 0.0898, 0.0336, 0.4420, 0.0479, 0.2093], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,302][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.1051, 0.0797, 0.0187, 0.1192, 0.0195, 0.0710, 0.0404, 0.0632, 0.0454,
        0.1182, 0.0941, 0.0486, 0.1103, 0.0237, 0.0428], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,303][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.1291, 0.0698, 0.0446, 0.0710, 0.0354, 0.0628, 0.0651, 0.0779, 0.0590,
        0.0693, 0.0640, 0.0559, 0.0924, 0.0416, 0.0620], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,304][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0942, 0.0639, 0.0253, 0.0679, 0.0305, 0.0826, 0.0738, 0.0562, 0.0617,
        0.0614, 0.0515, 0.0303, 0.0633, 0.0266, 0.2107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,305][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.2156, 0.0865, 0.0364, 0.0726, 0.0390, 0.0476, 0.0423, 0.0910, 0.0563,
        0.0627, 0.0278, 0.0335, 0.0936, 0.0396, 0.0556], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,309][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2089, 0.0194, 0.0447, 0.0164, 0.0786, 0.0616, 0.0662, 0.0194, 0.0571,
        0.0108, 0.0261, 0.0319, 0.0178, 0.1203, 0.2070, 0.0140],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,312][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3141e-03, 6.1154e-03, 3.9075e-05, 1.7723e-02, 5.3848e-05, 1.2765e-04,
        1.1955e-04, 1.7574e-02, 1.6667e-03, 4.3381e-01, 9.2495e-04, 4.4309e-05,
        3.7855e-03, 3.6451e-05, 5.2625e-05, 5.1562e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,313][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1044, 0.0454, 0.0218, 0.0637, 0.0184, 0.0472, 0.0500, 0.0702, 0.0530,
        0.1007, 0.0189, 0.0331, 0.1852, 0.0193, 0.0508, 0.1180],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,314][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.2312e-03, 2.4567e-04, 1.8099e-05, 1.4903e-04, 3.3800e-05, 5.9908e-04,
        1.3486e-04, 1.9302e-03, 2.4266e-03, 1.0802e-02, 1.5230e-02, 2.5212e-03,
        2.4910e-02, 6.0320e-03, 7.4010e-02, 8.5773e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,315][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3481e-02, 8.1189e-04, 2.5745e-04, 1.2951e-03, 9.7316e-04, 7.6968e-03,
        1.3823e-02, 5.5287e-03, 8.9901e-02, 1.1680e-02, 7.6338e-03, 2.0616e-02,
        1.2441e-02, 1.4157e-02, 6.8104e-01, 1.1867e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,316][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0287, 0.0391, 0.0004, 0.0512, 0.0019, 0.0125, 0.0111, 0.0485, 0.0299,
        0.3318, 0.1250, 0.0017, 0.0147, 0.0008, 0.0277, 0.2750],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,319][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0862, 0.0041, 0.0470, 0.0035, 0.0451, 0.0140, 0.0562, 0.0283, 0.0445,
        0.1638, 0.0029, 0.0561, 0.0046, 0.0797, 0.1126, 0.2514],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,323][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0190, 0.0034, 0.0033, 0.0051, 0.0040, 0.0054, 0.0104, 0.0107, 0.0221,
        0.0174, 0.0425, 0.0550, 0.2064, 0.1094, 0.2154, 0.2705],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,324][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0073, 0.0536, 0.0041, 0.0937, 0.0029, 0.0460, 0.0059, 0.0213, 0.0118,
        0.1502, 0.1943, 0.0111, 0.1516, 0.0044, 0.0154, 0.2262],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,325][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1067, 0.0659, 0.0422, 0.0730, 0.0413, 0.0545, 0.0438, 0.0666, 0.0475,
        0.0762, 0.0692, 0.0458, 0.0715, 0.0473, 0.0579, 0.0904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,326][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0885, 0.0718, 0.0295, 0.0879, 0.0325, 0.0575, 0.0370, 0.0654, 0.0651,
        0.1024, 0.0719, 0.0331, 0.0741, 0.0300, 0.0485, 0.1049],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,328][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1765, 0.0700, 0.0498, 0.0704, 0.0414, 0.0564, 0.0487, 0.0694, 0.0531,
        0.0682, 0.0333, 0.0304, 0.0753, 0.0402, 0.0460, 0.0706],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,332][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.1886, 0.0185, 0.0733, 0.0195, 0.0638, 0.0339, 0.0745, 0.0323, 0.0851,
        0.0174, 0.0219, 0.0287, 0.0148, 0.0864, 0.1824, 0.0211, 0.0378],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,334][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.7597e-04, 4.5106e-04, 1.9865e-04, 3.7635e-04, 1.0648e-03, 1.5214e-04,
        2.3470e-03, 2.9185e-04, 2.1365e-03, 5.6429e-04, 1.8066e-04, 1.1074e-04,
        4.2908e-05, 8.0614e-04, 3.1904e-04, 5.0102e-04, 9.9018e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,335][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1144, 0.0304, 0.0435, 0.0401, 0.0271, 0.0663, 0.0708, 0.0757, 0.0645,
        0.0771, 0.0403, 0.0412, 0.0612, 0.0276, 0.0926, 0.0873, 0.0401],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,335][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.1249e-04, 3.0710e-06, 7.0247e-07, 3.2419e-06, 2.9321e-06, 1.2432e-05,
        6.0588e-05, 4.5087e-05, 9.2147e-05, 1.2149e-04, 2.0548e-04, 2.7677e-04,
        3.3706e-04, 6.4007e-04, 1.5242e-02, 8.3567e-03, 9.7419e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,336][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0296, 0.0037, 0.0048, 0.0045, 0.0037, 0.0099, 0.0126, 0.0050, 0.0161,
        0.0155, 0.0142, 0.0203, 0.0193, 0.0308, 0.2002, 0.1128, 0.4968],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,338][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.3140e-02, 5.7501e-05, 8.5482e-05, 2.8063e-05, 1.0389e-03, 3.7654e-05,
        3.9447e-04, 4.6864e-05, 1.6286e-04, 1.1243e-05, 1.6532e-05, 2.8431e-05,
        3.2532e-06, 3.9329e-04, 8.8040e-05, 6.6041e-06, 9.8446e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,341][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1354, 0.0138, 0.1596, 0.0124, 0.1150, 0.0158, 0.0836, 0.0210, 0.0342,
        0.0103, 0.0126, 0.1058, 0.0121, 0.1575, 0.0705, 0.0127, 0.0278],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,344][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0144, 0.0032, 0.0036, 0.0040, 0.0025, 0.0039, 0.0051, 0.0088, 0.0095,
        0.0209, 0.0304, 0.0175, 0.1236, 0.0490, 0.1889, 0.2987, 0.2160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,345][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0527, 0.0542, 0.0206, 0.0827, 0.0143, 0.0809, 0.0244, 0.0539, 0.0340,
        0.1107, 0.0855, 0.0418, 0.0720, 0.0188, 0.0655, 0.1472, 0.0407],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,346][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0982, 0.0540, 0.0356, 0.0598, 0.0364, 0.0591, 0.0501, 0.0589, 0.0482,
        0.0663, 0.0550, 0.0551, 0.0752, 0.0436, 0.0758, 0.0806, 0.0480],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,347][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0714, 0.0469, 0.0235, 0.0568, 0.0394, 0.0471, 0.0458, 0.0390, 0.0580,
        0.0690, 0.0512, 0.0350, 0.0614, 0.0430, 0.0534, 0.0749, 0.1844],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,350][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2369, 0.0661, 0.0374, 0.0775, 0.0338, 0.0333, 0.0420, 0.0735, 0.0558,
        0.0545, 0.0171, 0.0245, 0.0622, 0.0295, 0.0369, 0.0547, 0.0644],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,355][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2482, 0.0190, 0.0882, 0.0148, 0.0679, 0.0220, 0.0758, 0.0180, 0.0373,
        0.0119, 0.0223, 0.0401, 0.0168, 0.1013, 0.0955, 0.0157, 0.0849, 0.0203],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,356][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.2082e-04, 1.7500e-03, 2.6007e-04, 1.9194e-03, 4.7870e-04, 7.0315e-05,
        4.9457e-05, 1.1632e-02, 1.6708e-03, 6.4077e-03, 2.4460e-02, 1.2781e-04,
        4.6070e-04, 3.7147e-04, 6.0549e-05, 6.2431e-03, 9.3925e-04, 9.4238e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,356][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0803, 0.0402, 0.0211, 0.0615, 0.0187, 0.0488, 0.0370, 0.0678, 0.0574,
        0.1087, 0.0141, 0.0323, 0.1271, 0.0211, 0.0635, 0.1299, 0.0563, 0.0143],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,357][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.0588e-03, 1.9456e-04, 2.7881e-05, 1.1420e-04, 2.7555e-05, 2.4966e-04,
        3.1645e-04, 5.1818e-04, 4.8817e-04, 1.3086e-03, 5.1971e-03, 1.9820e-03,
        8.5814e-03, 2.7363e-03, 3.4528e-02, 6.5703e-02, 1.2964e-01, 7.4532e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,358][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0217, 0.0025, 0.0020, 0.0026, 0.0021, 0.0093, 0.0078, 0.0062, 0.0238,
        0.0097, 0.0103, 0.0130, 0.0126, 0.0193, 0.1919, 0.0752, 0.3817, 0.2082],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,362][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0259, 0.0832, 0.0011, 0.0758, 0.0030, 0.0128, 0.0065, 0.0373, 0.0189,
        0.0659, 0.1759, 0.0066, 0.0221, 0.0012, 0.0063, 0.0491, 0.0097, 0.3986],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,366][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1012, 0.0023, 0.1066, 0.0022, 0.1064, 0.0143, 0.0856, 0.0147, 0.0399,
        0.0054, 0.0019, 0.1236, 0.0020, 0.1842, 0.1280, 0.0073, 0.0704, 0.0039],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,367][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0143, 0.0025, 0.0027, 0.0038, 0.0017, 0.0034, 0.0046, 0.0062, 0.0105,
        0.0106, 0.0184, 0.0161, 0.1041, 0.0319, 0.0835, 0.1479, 0.2365, 0.3012],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,368][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0340, 0.0033, 0.0603, 0.0021, 0.0427, 0.0054, 0.0162, 0.0109,
        0.0777, 0.1787, 0.0112, 0.0961, 0.0032, 0.0167, 0.1154, 0.0176, 0.3016],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,369][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0971, 0.0584, 0.0418, 0.0646, 0.0351, 0.0476, 0.0389, 0.0584, 0.0424,
        0.0672, 0.0583, 0.0418, 0.0625, 0.0403, 0.0489, 0.0806, 0.0498, 0.0663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,371][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0728, 0.0556, 0.0311, 0.0668, 0.0276, 0.0340, 0.0288, 0.0690, 0.0485,
        0.0723, 0.0819, 0.0326, 0.0566, 0.0277, 0.0393, 0.0768, 0.0356, 0.1430],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,375][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1667, 0.0626, 0.0492, 0.0598, 0.0377, 0.0472, 0.0490, 0.0578, 0.0476,
        0.0632, 0.0333, 0.0306, 0.0655, 0.0356, 0.0382, 0.0649, 0.0468, 0.0444],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,377][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.1548, 0.0513, 0.0711, 0.0391, 0.0562, 0.0389, 0.0770, 0.0271, 0.0353,
        0.0243, 0.0196, 0.0419, 0.0365, 0.0662, 0.0961, 0.0281, 0.0380, 0.0297,
        0.0688], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,378][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.0936e-04, 4.7447e-04, 5.4557e-05, 2.7501e-04, 3.8231e-05, 6.7038e-05,
        7.0674e-04, 1.4918e-04, 7.8012e-05, 2.3904e-04, 2.3135e-04, 6.0591e-04,
        1.9536e-04, 2.2853e-05, 2.7723e-04, 2.0383e-04, 1.4288e-05, 7.6458e-05,
        9.9608e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,379][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1277, 0.0344, 0.0588, 0.0454, 0.0088, 0.0400, 0.0659, 0.0427, 0.0310,
        0.0493, 0.0564, 0.1371, 0.0478, 0.0079, 0.0319, 0.0510, 0.0262, 0.0524,
        0.0853], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,380][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([9.0093e-05, 7.6281e-08, 5.1195e-08, 1.1803e-07, 4.8436e-06, 3.1492e-07,
        9.5080e-06, 9.3694e-07, 6.4988e-06, 2.4069e-06, 3.7985e-06, 1.7575e-04,
        5.4436e-06, 5.7247e-04, 3.6561e-04, 1.0811e-04, 4.2037e-04, 2.8578e-04,
        9.9795e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,381][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([2.3142e-02, 1.6052e-03, 5.3538e-04, 8.6941e-04, 3.8230e-04, 6.3218e-04,
        2.3655e-03, 7.4426e-04, 8.9571e-04, 1.5050e-03, 2.4873e-03, 1.8388e-03,
        4.8452e-03, 1.8804e-03, 5.0141e-03, 9.0117e-03, 2.6254e-02, 2.3890e-02,
        8.9210e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,384][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.6410e-03, 3.2593e-05, 4.8536e-06, 4.8180e-06, 2.4252e-05, 1.2262e-06,
        1.4751e-04, 2.1040e-06, 8.0068e-06, 6.7416e-07, 8.8175e-06, 5.0374e-05,
        5.1245e-07, 7.3360e-06, 4.3616e-05, 3.7334e-07, 1.7774e-07, 4.6395e-06,
        9.9702e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,387][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.1085, 0.0260, 0.1134, 0.0144, 0.1042, 0.0109, 0.0430, 0.0212, 0.0276,
        0.0146, 0.0113, 0.0491, 0.0214, 0.1052, 0.0362, 0.0152, 0.0269, 0.0141,
        0.2366], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,388][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0393, 0.0044, 0.0024, 0.0063, 0.0017, 0.0071, 0.0060, 0.0092, 0.0097,
        0.0124, 0.0201, 0.0580, 0.0649, 0.0185, 0.0565, 0.1325, 0.1538, 0.2934,
        0.1038], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,389][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0901, 0.0479, 0.0407, 0.0514, 0.0267, 0.0343, 0.0323, 0.0271, 0.0412,
        0.0417, 0.0617, 0.1561, 0.0445, 0.0322, 0.0389, 0.0521, 0.0299, 0.0516,
        0.0995], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,390][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1050, 0.0600, 0.0566, 0.0555, 0.0522, 0.0407, 0.0375, 0.0521, 0.0362,
        0.0508, 0.0587, 0.0320, 0.0615, 0.0603, 0.0517, 0.0585, 0.0453, 0.0716,
        0.0137], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,393][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0840, 0.0481, 0.0170, 0.0508, 0.0246, 0.0357, 0.0366, 0.0382, 0.0236,
        0.0458, 0.0549, 0.0374, 0.0493, 0.0242, 0.0400, 0.0475, 0.0224, 0.0480,
        0.2717], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,398][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.2010, 0.0774, 0.0467, 0.0612, 0.0433, 0.0404, 0.0333, 0.0539, 0.0484,
        0.0510, 0.0210, 0.0264, 0.0555, 0.0409, 0.0290, 0.0529, 0.0629, 0.0217,
        0.0333], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,399][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1836, 0.0155, 0.0377, 0.0131, 0.0654, 0.0507, 0.0536, 0.0149, 0.0461,
        0.0083, 0.0204, 0.0267, 0.0139, 0.0978, 0.1643, 0.0106, 0.0685, 0.0232,
        0.0725, 0.0132], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,400][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5353e-03, 3.2721e-03, 1.9794e-05, 9.5140e-03, 2.9979e-05, 7.5053e-05,
        6.6821e-05, 1.0198e-02, 9.6837e-04, 2.5979e-01, 5.4316e-04, 2.5219e-05,
        2.5322e-03, 2.2823e-05, 3.4452e-05, 3.2995e-01, 2.5556e-04, 3.9130e-04,
        1.9586e-05, 3.8076e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,400][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0870, 0.0348, 0.0175, 0.0514, 0.0153, 0.0388, 0.0404, 0.0581, 0.0440,
        0.0813, 0.0152, 0.0303, 0.1494, 0.0164, 0.0413, 0.0959, 0.0417, 0.0147,
        0.0204, 0.1061], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,401][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.2118e-04, 4.3811e-05, 3.0991e-06, 1.9502e-05, 3.6178e-06, 4.6852e-05,
        1.0245e-05, 1.1374e-04, 1.2649e-04, 4.6143e-04, 6.2177e-04, 1.1208e-04,
        1.1061e-03, 2.6300e-04, 2.8791e-03, 3.0919e-02, 2.6223e-01, 7.0254e-02,
        1.4458e-02, 6.1541e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,403][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3304e-02, 7.1491e-04, 1.9848e-04, 1.0496e-03, 5.9764e-04, 4.4613e-03,
        7.6358e-03, 2.8452e-03, 3.9847e-02, 5.0118e-03, 3.1063e-03, 7.6195e-03,
        4.8672e-03, 4.8311e-03, 2.5092e-01, 4.3967e-02, 2.0224e-01, 6.4984e-02,
        1.3282e-01, 2.0897e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,407][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0182, 0.0262, 0.0003, 0.0364, 0.0013, 0.0101, 0.0080, 0.0362, 0.0238,
        0.2449, 0.0924, 0.0011, 0.0102, 0.0005, 0.0228, 0.2023, 0.0066, 0.0698,
        0.0022, 0.1868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,409][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0544, 0.0024, 0.0293, 0.0021, 0.0290, 0.0082, 0.0347, 0.0178, 0.0279,
        0.1063, 0.0016, 0.0353, 0.0028, 0.0519, 0.0702, 0.1657, 0.0410, 0.0033,
        0.1069, 0.2093], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,410][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0148, 0.0021, 0.0020, 0.0027, 0.0017, 0.0020, 0.0034, 0.0031, 0.0057,
        0.0039, 0.0094, 0.0120, 0.0450, 0.0226, 0.0407, 0.0505, 0.1042, 0.1803,
        0.1847, 0.3090], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,411][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0048, 0.0339, 0.0026, 0.0615, 0.0018, 0.0303, 0.0040, 0.0137, 0.0075,
        0.0959, 0.1211, 0.0074, 0.0967, 0.0028, 0.0099, 0.1446, 0.0113, 0.1554,
        0.0095, 0.1852], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,412][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0838, 0.0495, 0.0331, 0.0564, 0.0326, 0.0422, 0.0349, 0.0515, 0.0371,
        0.0578, 0.0526, 0.0368, 0.0562, 0.0375, 0.0453, 0.0692, 0.0477, 0.0632,
        0.0341, 0.0787], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,415][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0628, 0.0475, 0.0218, 0.0619, 0.0246, 0.0429, 0.0287, 0.0498, 0.0512,
        0.0784, 0.0561, 0.0278, 0.0614, 0.0258, 0.0418, 0.0870, 0.0452, 0.0653,
        0.0284, 0.0917], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,419][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1534, 0.0590, 0.0429, 0.0586, 0.0377, 0.0480, 0.0409, 0.0550, 0.0448,
        0.0553, 0.0271, 0.0238, 0.0571, 0.0340, 0.0366, 0.0546, 0.0425, 0.0347,
        0.0391, 0.0549], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,423][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:41,425][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[22171],
        [11151],
        [    1],
        [12344],
        [12000],
        [13516],
        [10389],
        [ 8164],
        [32792],
        [17229],
        [28255],
        [ 1386],
        [ 3937],
        [13833],
        [17203],
        [16986],
        [11249],
        [29262],
        [20620],
        [18048]], device='cuda:0')
[2024-07-24 10:18:41,429][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[48317],
        [40023],
        [    1],
        [42647],
        [ 2581],
        [44833],
        [38446],
        [38561],
        [39738],
        [39086],
        [34903],
        [27639],
        [43586],
        [ 1499],
        [41545],
        [36124],
        [37882],
        [28621],
        [47965],
        [33958]], device='cuda:0')
[2024-07-24 10:18:41,432][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 7967],
        [ 7006],
        [  652],
        [ 1777],
        [ 1383],
        [14396],
        [ 4222],
        [ 4383],
        [ 5769],
        [ 7046],
        [ 5113],
        [ 4560],
        [ 7126],
        [ 4412],
        [15602],
        [13056],
        [10036],
        [ 7125],
        [ 7444],
        [10817]], device='cuda:0')
[2024-07-24 10:18:41,433][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[36424],
        [ 3966],
        [ 2536],
        [16078],
        [38646],
        [37370],
        [ 5924],
        [23919],
        [34861],
        [32678],
        [49255],
        [ 4031],
        [ 4617],
        [38389],
        [25408],
        [32795],
        [19767],
        [48795],
        [17580],
        [32828]], device='cuda:0')
[2024-07-24 10:18:41,435][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7151],
        [ 6810],
        [ 5979],
        [14570],
        [ 7091],
        [10173],
        [10657],
        [10899],
        [11474],
        [16622],
        [16014],
        [12421],
        [11824],
        [ 8057],
        [13439],
        [19124],
        [17890],
        [19419],
        [13819],
        [20250]], device='cuda:0')
[2024-07-24 10:18:41,437][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[46416],
        [48038],
        [28849],
        [46458],
        [37268],
        [15392],
        [24949],
        [34219],
        [35567],
        [41882],
        [38348],
        [25219],
        [43654],
        [32907],
        [ 3957],
        [36845],
        [17959],
        [25424],
        [36818],
        [33868]], device='cuda:0')
[2024-07-24 10:18:41,440][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 7586],
        [ 7215],
        [ 4255],
        [  641],
        [29775],
        [ 6123],
        [36676],
        [30949],
        [19699],
        [21203],
        [ 3387],
        [ 9465],
        [  520],
        [31712],
        [21999],
        [20288],
        [11399],
        [ 4476],
        [12937],
        [ 3466]], device='cuda:0')
[2024-07-24 10:18:41,443][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28763],
        [35719],
        [ 4847],
        [36259],
        [19864],
        [33767],
        [25817],
        [36495],
        [27489],
        [33746],
        [34644],
        [39704],
        [37006],
        [19578],
        [26742],
        [33682],
        [19141],
        [31995],
        [23460],
        [32827]], device='cuda:0')
[2024-07-24 10:18:41,445][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44970],
        [45103],
        [ 5029],
        [  483],
        [  353],
        [   16],
        [  461],
        [ 1707],
        [  238],
        [ 7305],
        [   46],
        [   47],
        [  588],
        [  340],
        [  108],
        [ 6590],
        [  235],
        [  598],
        [ 3442],
        [ 8797]], device='cuda:0')
[2024-07-24 10:18:41,447][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25465],
        [24913],
        [19908],
        [13117],
        [30368],
        [36562],
        [33148],
        [26684],
        [28219],
        [31278],
        [31172],
        [29862],
        [14934],
        [21829],
        [23405],
        [33590],
        [37981],
        [36530],
        [34049],
        [37325]], device='cuda:0')
[2024-07-24 10:18:41,449][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[13868],
        [22642],
        [ 9581],
        [27103],
        [ 7514],
        [25835],
        [17300],
        [21663],
        [16213],
        [21806],
        [21043],
        [ 9104],
        [20755],
        [ 5432],
        [13528],
        [20141],
        [13988],
        [24682],
        [13039],
        [22408]], device='cuda:0')
[2024-07-24 10:18:41,452][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31222],
        [38995],
        [38843],
        [40022],
        [36743],
        [40634],
        [38234],
        [39741],
        [39136],
        [40654],
        [39930],
        [38871],
        [38280],
        [37128],
        [38125],
        [39397],
        [39269],
        [39112],
        [36471],
        [38621]], device='cuda:0')
[2024-07-24 10:18:41,455][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3686],
        [ 4376],
        [10148],
        [ 7055],
        [32530],
        [ 5752],
        [ 1827],
        [ 4285],
        [ 6091],
        [ 6349],
        [16344],
        [12495],
        [ 8547],
        [45690],
        [ 3254],
        [ 9396],
        [10193],
        [23272],
        [41573],
        [14374]], device='cuda:0')
[2024-07-24 10:18:41,457][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29298],
        [17772],
        [11265],
        [12412],
        [11129],
        [10166],
        [ 9750],
        [ 8109],
        [ 7340],
        [ 6469],
        [ 8890],
        [ 9423],
        [ 8610],
        [ 7156],
        [ 7742],
        [ 7162],
        [ 7679],
        [ 8184],
        [ 8810],
        [ 8204]], device='cuda:0')
[2024-07-24 10:18:41,458][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[40466],
        [11555],
        [    1],
        [20937],
        [33423],
        [16251],
        [20468],
        [26975],
        [41153],
        [24208],
        [48491],
        [11899],
        [ 7419],
        [31870],
        [46151],
        [23323],
        [34000],
        [47150],
        [37574],
        [22718]], device='cuda:0')
[2024-07-24 10:18:41,461][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12624],
        [12940],
        [15205],
        [11527],
        [14367],
        [ 7912],
        [12262],
        [12483],
        [13452],
        [12956],
        [13130],
        [16377],
        [13357],
        [15571],
        [11737],
        [15858],
        [16182],
        [14844],
        [18751],
        [18307]], device='cuda:0')
[2024-07-24 10:18:41,464][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9937],
        [14358],
        [14942],
        [ 6581],
        [ 9281],
        [ 8795],
        [29205],
        [ 8763],
        [18518],
        [ 2624],
        [ 2548],
        [25203],
        [15941],
        [ 7910],
        [21851],
        [ 2710],
        [13602],
        [ 2921],
        [14714],
        [ 2641]], device='cuda:0')
[2024-07-24 10:18:41,467][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[35120],
        [30928],
        [29808],
        [39164],
        [30613],
        [33681],
        [34778],
        [34730],
        [35891],
        [29541],
        [29789],
        [34530],
        [34864],
        [34879],
        [33900],
        [27962],
        [32787],
        [29436],
        [34298],
        [27474]], device='cuda:0')
[2024-07-24 10:18:41,469][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20946],
        [20614],
        [12837],
        [24870],
        [12939],
        [21659],
        [25983],
        [30053],
        [24525],
        [31914],
        [24993],
        [18475],
        [28760],
        [19022],
        [37331],
        [36495],
        [23156],
        [28795],
        [10521],
        [33655]], device='cuda:0')
[2024-07-24 10:18:41,470][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18090],
        [18481],
        [15260],
        [22557],
        [11042],
        [20018],
        [21547],
        [23964],
        [23381],
        [20627],
        [19963],
        [10617],
        [24604],
        [11927],
        [31911],
        [27578],
        [29318],
        [25017],
        [29181],
        [27334]], device='cuda:0')
[2024-07-24 10:18:41,472][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[20883],
        [22059],
        [21306],
        [30732],
        [ 9463],
        [12684],
        [ 9440],
        [19908],
        [11406],
        [29372],
        [24485],
        [ 6542],
        [27035],
        [ 9076],
        [ 8600],
        [29757],
        [19567],
        [27558],
        [ 5216],
        [30291]], device='cuda:0')
[2024-07-24 10:18:41,476][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34877],
        [35010],
        [20150],
        [20264],
        [16811],
        [ 6991],
        [16812],
        [16548],
        [11780],
        [41333],
        [ 8955],
        [ 7661],
        [12456],
        [15818],
        [ 9562],
        [45421],
        [13228],
        [15068],
        [11273],
        [43841]], device='cuda:0')
[2024-07-24 10:18:41,479][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[39656],
        [39946],
        [36584],
        [ 5487],
        [17877],
        [25287],
        [28143],
        [27758],
        [27774],
        [20545],
        [17619],
        [17173],
        [30718],
        [29285],
        [32970],
        [27765],
        [27889],
        [22821],
        [20371],
        [20633]], device='cuda:0')
[2024-07-24 10:18:41,481][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30680],
        [12571],
        [32085],
        [17629],
        [38307],
        [21649],
        [24203],
        [19660],
        [19863],
        [18432],
        [18784],
        [24985],
        [10362],
        [33168],
        [19088],
        [15569],
        [19380],
        [12042],
        [28422],
        [14001]], device='cuda:0')
[2024-07-24 10:18:41,482][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27362],
        [23418],
        [23421],
        [25861],
        [26242],
        [28707],
        [28550],
        [30260],
        [31018],
        [30710],
        [30908],
        [30423],
        [29140],
        [28937],
        [29756],
        [29890],
        [30293],
        [30193],
        [29969],
        [29773]], device='cuda:0')
[2024-07-24 10:18:41,484][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[45048],
        [48531],
        [47848],
        [48463],
        [45614],
        [47336],
        [48416],
        [48544],
        [47266],
        [47821],
        [46801],
        [47474],
        [47909],
        [42360],
        [46347],
        [47205],
        [47146],
        [45483],
        [44765],
        [46414]], device='cuda:0')
[2024-07-24 10:18:41,488][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12328],
        [15548],
        [34944],
        [24450],
        [34102],
        [37401],
        [34463],
        [38031],
        [40055],
        [41367],
        [42406],
        [39589],
        [39350],
        [42998],
        [42171],
        [42213],
        [40012],
        [42071],
        [40968],
        [40713]], device='cuda:0')
[2024-07-24 10:18:41,491][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11715],
        [ 9668],
        [10579],
        [15100],
        [13706],
        [17361],
        [11711],
        [12739],
        [12782],
        [11366],
        [16653],
        [12358],
        [12335],
        [14523],
        [13007],
        [10059],
        [12360],
        [15731],
        [13877],
        [11592]], device='cuda:0')
[2024-07-24 10:18:41,492][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 8762],
        [35531],
        [50253],
        [26647],
        [15257],
        [31172],
        [27135],
        [20409],
        [ 8616],
        [23655],
        [ 1528],
        [34708],
        [40240],
        [16868],
        [ 3270],
        [24500],
        [14490],
        [ 2503],
        [11777],
        [25179]], device='cuda:0')
[2024-07-24 10:18:41,494][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795],
        [12795]], device='cuda:0')
[2024-07-24 10:18:41,514][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:41,516][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,516][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,518][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,519][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,520][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,520][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,521][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,523][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,524][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,525][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,525][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,526][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,527][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1296, 0.8704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,527][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9037, 0.0963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,528][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,529][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1696, 0.8304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,529][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2883, 0.7117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,530][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4108, 0.5892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,531][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5004, 0.4996], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,534][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3866, 0.6134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,534][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6538, 0.3462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,535][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0010, 0.9990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,536][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([7.3826e-04, 9.9926e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,536][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7335, 0.2665], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,537][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1300, 0.5530, 0.3170], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,541][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.2788, 0.6767, 0.0445], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,545][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.9093, 0.0359, 0.0548], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,545][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.3110, 0.3765, 0.3125], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,546][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1457, 0.4354, 0.4190], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,547][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.1952, 0.3621, 0.4427], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,547][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.3336, 0.3332, 0.3332], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,548][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1785, 0.4858, 0.3357], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,552][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.5004, 0.4756, 0.0241], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,556][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0148, 0.7891, 0.1962], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,556][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0011, 0.6960, 0.3029], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,557][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0015, 0.0030, 0.9955], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,558][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0906, 0.6001, 0.2582, 0.0511], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,558][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6535, 0.1354, 0.1534, 0.0577], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,559][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5051, 0.0169, 0.0543, 0.4237], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,563][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2522, 0.2464, 0.2757, 0.2257], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,567][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1111, 0.2785, 0.3467, 0.2636], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,567][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1200, 0.7592, 0.0431, 0.0777], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,568][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2501, 0.2498, 0.2498, 0.2504], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,569][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1451, 0.2666, 0.3469, 0.2413], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,569][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3794, 0.3103, 0.0473, 0.2630], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,570][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.3799e-04, 1.2568e-01, 4.4755e-01, 4.2652e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,574][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0048, 0.3871, 0.3280, 0.2801], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,578][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1382, 0.1820, 0.0038, 0.6759], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,578][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0953, 0.5616, 0.2202, 0.0589, 0.0640], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,579][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.1346, 0.2914, 0.0369, 0.5253, 0.0118], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,580][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.4185, 0.0323, 0.0505, 0.4300, 0.0686], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,581][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.2853, 0.1991, 0.1985, 0.1849, 0.1321], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,582][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0800, 0.2476, 0.2461, 0.2267, 0.1996], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,588][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0311, 0.2729, 0.6660, 0.0224, 0.0076], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,591][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.2001, 0.1998, 0.1998, 0.2003, 0.2001], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,592][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0914, 0.2976, 0.2515, 0.2209, 0.1386], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,592][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.3708, 0.2859, 0.0312, 0.2161, 0.0959], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,593][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0017, 0.1837, 0.1383, 0.5775, 0.0988], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,594][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0020, 0.3508, 0.2319, 0.2436, 0.1717], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,596][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0077, 0.0156, 0.0023, 0.0041, 0.9704], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,600][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0844, 0.5645, 0.1696, 0.0421, 0.0548, 0.0846], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,602][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.3164, 0.3131, 0.0412, 0.2744, 0.0135, 0.0414], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,603][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.3426, 0.0207, 0.0487, 0.2671, 0.0711, 0.2498], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,603][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.2311, 0.1688, 0.1785, 0.1384, 0.1143, 0.1689], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,604][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0649, 0.1886, 0.2150, 0.1685, 0.1676, 0.1954], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,605][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0975, 0.4592, 0.2357, 0.0232, 0.0180, 0.1665], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,608][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1667, 0.1665, 0.1665, 0.1669, 0.1668, 0.1667], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,613][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0954, 0.1563, 0.2073, 0.1725, 0.1701, 0.1984], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,613][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.2068, 0.2556, 0.0366, 0.1009, 0.0752, 0.3249], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,614][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0074, 0.1312, 0.2641, 0.4707, 0.1033, 0.0233], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,615][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0035, 0.2169, 0.2112, 0.1781, 0.1563, 0.2339], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,616][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ were] are: tensor([3.3346e-03, 9.8538e-03, 8.1641e-04, 5.4273e-03, 4.1899e-04, 9.8015e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:41,616][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0787, 0.4901, 0.2164, 0.0491, 0.0693, 0.0798, 0.0164],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,620][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1648, 0.1982, 0.0632, 0.3806, 0.0388, 0.1402, 0.0143],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,624][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.2852, 0.0200, 0.0405, 0.2540, 0.0594, 0.2247, 0.1162],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,625][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.2148, 0.1367, 0.1492, 0.1258, 0.1025, 0.1526, 0.1184],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,625][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0546, 0.1642, 0.1640, 0.1420, 0.1244, 0.1604, 0.1904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,626][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0785, 0.5936, 0.0649, 0.0433, 0.0045, 0.1307, 0.0844],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,627][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.1429, 0.1427, 0.1427, 0.1430, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,629][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0839, 0.1455, 0.1497, 0.1301, 0.1470, 0.2236, 0.1202],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,633][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2186, 0.1662, 0.0266, 0.1059, 0.0725, 0.3772, 0.0330],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,635][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0012, 0.1398, 0.1153, 0.5904, 0.0679, 0.0061, 0.0793],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,636][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0023, 0.1850, 0.1703, 0.1441, 0.1355, 0.1838, 0.1791],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,636][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([1.1749e-02, 2.2768e-02, 1.1566e-04, 9.0692e-03, 2.8473e-04, 1.9930e-04,
        9.5581e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:41,637][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0701, 0.4605, 0.2095, 0.0480, 0.0721, 0.0842, 0.0181, 0.0374],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,638][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.4037, 0.1981, 0.1330, 0.1308, 0.0485, 0.0389, 0.0222, 0.0249],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,641][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.2703, 0.0177, 0.0438, 0.1751, 0.0536, 0.1665, 0.0965, 0.1765],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,645][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.2195, 0.1232, 0.1290, 0.1108, 0.0832, 0.1284, 0.0988, 0.1071],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,646][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0492, 0.1300, 0.1474, 0.1152, 0.1124, 0.1325, 0.1652, 0.1481],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,647][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0604, 0.1362, 0.0494, 0.0073, 0.0025, 0.0069, 0.0207, 0.7166],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,648][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.1250, 0.1249, 0.1249, 0.1252, 0.1251, 0.1251, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,649][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0847, 0.1273, 0.1163, 0.1109, 0.1247, 0.1624, 0.1470, 0.1268],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,650][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.1976, 0.1894, 0.0296, 0.0957, 0.0619, 0.3388, 0.0473, 0.0398],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,655][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0014, 0.0868, 0.2840, 0.3273, 0.0476, 0.0094, 0.1971, 0.0464],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,657][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0036, 0.1329, 0.1423, 0.1211, 0.1166, 0.1525, 0.1603, 0.1706],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,657][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ about] are: tensor([4.7251e-03, 2.8580e-02, 1.8509e-04, 5.9773e-03, 9.5911e-05, 2.9597e-04,
        3.3030e-03, 9.5684e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:41,658][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0832, 0.4698, 0.1793, 0.0418, 0.0611, 0.0759, 0.0160, 0.0332, 0.0396],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,659][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.1511, 0.2820, 0.0700, 0.2992, 0.0257, 0.0520, 0.0237, 0.0859, 0.0104],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,660][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.2081, 0.0186, 0.0358, 0.1885, 0.0458, 0.1162, 0.1005, 0.2049, 0.0816],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,662][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.2066, 0.1064, 0.1187, 0.1027, 0.0758, 0.1146, 0.0929, 0.1177, 0.0646],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,667][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0418, 0.1199, 0.1279, 0.1086, 0.0968, 0.1153, 0.1501, 0.1359, 0.1037],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,668][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.1017, 0.3332, 0.0865, 0.0591, 0.0233, 0.0793, 0.1244, 0.1512, 0.0413],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,669][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1111, 0.1110, 0.1110, 0.1112, 0.1112, 0.1112, 0.1112, 0.1110, 0.1111],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,669][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0529, 0.1094, 0.1142, 0.0983, 0.1181, 0.1643, 0.1367, 0.1275, 0.0787],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,670][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1624, 0.1627, 0.0209, 0.1078, 0.0428, 0.3668, 0.0500, 0.0454, 0.0412],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,671][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0006, 0.0685, 0.1726, 0.4240, 0.0313, 0.0093, 0.1863, 0.0676, 0.0399],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,675][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0039, 0.1013, 0.1251, 0.1028, 0.1038, 0.1242, 0.1507, 0.1823, 0.1060],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,678][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ going] are: tensor([2.4513e-03, 1.0235e-02, 8.9386e-05, 2.6784e-03, 3.9961e-05, 5.3513e-04,
        5.3592e-04, 2.6876e-04, 9.8317e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:41,679][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0719, 0.4247, 0.1622, 0.0365, 0.0584, 0.0958, 0.0186, 0.0415, 0.0474,
        0.0429], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,680][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4600, 0.1562, 0.1033, 0.1260, 0.0280, 0.0411, 0.0190, 0.0344, 0.0094,
        0.0226], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,681][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1855, 0.0126, 0.0360, 0.1114, 0.0406, 0.1111, 0.0713, 0.1157, 0.0521,
        0.2636], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,681][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1999, 0.1083, 0.1112, 0.0931, 0.0707, 0.1108, 0.0805, 0.0943, 0.0492,
        0.0821], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,684][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0422, 0.1017, 0.1213, 0.0946, 0.0930, 0.1103, 0.1328, 0.1178, 0.0945,
        0.0918], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,686][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.8634e-03, 2.0227e-03, 9.9511e-03, 3.4153e-04, 6.5524e-03, 1.6129e-03,
        2.9475e-03, 6.8240e-03, 1.1122e-03, 9.6577e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,689][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1000, 0.0999, 0.0999, 0.1001, 0.1001, 0.1000, 0.1001, 0.0999, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,690][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0524, 0.0992, 0.1182, 0.0938, 0.0974, 0.1149, 0.1160, 0.1095, 0.0834,
        0.1153], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,691][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2035, 0.1677, 0.0359, 0.0885, 0.0639, 0.2509, 0.0492, 0.0412, 0.0270,
        0.0723], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,691][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.4459e-04, 6.2642e-02, 4.0557e-01, 3.0633e-01, 1.3886e-02, 6.6212e-03,
        1.5081e-01, 2.2870e-02, 1.7671e-02, 1.3358e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,692][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0080, 0.0848, 0.1119, 0.0893, 0.0921, 0.1262, 0.1286, 0.1432, 0.0803,
        0.1355], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,694][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.0759e-02, 7.3349e-02, 1.0202e-04, 5.0504e-02, 2.5828e-04, 5.4253e-03,
        4.8731e-04, 7.0565e-03, 3.8498e-03, 8.3821e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:41,699][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0642, 0.4078, 0.1589, 0.0345, 0.0639, 0.0810, 0.0185, 0.0360, 0.0447,
        0.0638, 0.0267], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,700][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.4885, 0.1694, 0.1017, 0.1126, 0.0199, 0.0276, 0.0170, 0.0199, 0.0070,
        0.0222, 0.0143], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,701][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1723, 0.0099, 0.0261, 0.0974, 0.0333, 0.0816, 0.0574, 0.0941, 0.0474,
        0.1879, 0.1928], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,702][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1858, 0.0992, 0.1057, 0.0872, 0.0663, 0.0976, 0.0744, 0.0863, 0.0471,
        0.0700, 0.0805], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,703][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0370, 0.0921, 0.1101, 0.0846, 0.0888, 0.0973, 0.1258, 0.1080, 0.0854,
        0.0781, 0.0927], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,706][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0552, 0.4822, 0.1631, 0.0059, 0.0151, 0.0277, 0.0178, 0.1233, 0.0176,
        0.0768, 0.0152], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,710][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0909, 0.0908, 0.0908, 0.0910, 0.0910, 0.0910, 0.0910, 0.0908, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,711][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0454, 0.0740, 0.1106, 0.0730, 0.0962, 0.1106, 0.1051, 0.0998, 0.0807,
        0.0870, 0.1175], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,712][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0794, 0.0981, 0.0145, 0.0411, 0.0292, 0.0965, 0.0236, 0.0198, 0.0135,
        0.0431, 0.5411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,713][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.8262e-04, 4.0010e-02, 4.7839e-01, 2.4993e-01, 9.5813e-03, 5.9566e-03,
        1.4686e-01, 1.2805e-02, 1.3926e-02, 9.2358e-03, 3.3122e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,714][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0069, 0.0714, 0.1032, 0.0803, 0.0853, 0.1067, 0.1129, 0.1284, 0.0718,
        0.1160, 0.1171], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,715][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([7.1124e-03, 1.9673e-02, 4.8527e-04, 1.9099e-02, 1.0091e-03, 5.0135e-03,
        1.0472e-03, 6.7475e-03, 3.6843e-03, 1.8473e-02, 9.1766e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:41,720][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0551, 0.3715, 0.1630, 0.0446, 0.0604, 0.0661, 0.0184, 0.0394, 0.0438,
        0.0873, 0.0317, 0.0185], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,722][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0694, 0.0880, 0.0415, 0.1971, 0.0253, 0.0719, 0.0268, 0.0982, 0.0493,
        0.1217, 0.1777, 0.0330], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,722][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.1167, 0.0155, 0.0264, 0.1222, 0.0353, 0.0927, 0.0563, 0.1062, 0.0420,
        0.1946, 0.1448, 0.0474], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,723][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.1829, 0.0894, 0.0929, 0.0840, 0.0615, 0.0922, 0.0698, 0.0825, 0.0460,
        0.0707, 0.0680, 0.0602], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,724][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0301, 0.0904, 0.0933, 0.0809, 0.0722, 0.0885, 0.1061, 0.0989, 0.0746,
        0.0727, 0.0845, 0.1078], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,725][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0621, 0.1924, 0.0698, 0.0089, 0.0188, 0.0255, 0.0040, 0.1342, 0.0226,
        0.0374, 0.1371, 0.2873], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,729][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0834, 0.0832, 0.0832, 0.0834, 0.0834, 0.0834, 0.0834, 0.0833, 0.0834,
        0.0834, 0.0833, 0.0833], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,732][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.0380, 0.0847, 0.0923, 0.0668, 0.0748, 0.1210, 0.1353, 0.1164, 0.0723,
        0.0623, 0.0795, 0.0566], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,733][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.0820, 0.0798, 0.0142, 0.0512, 0.0253, 0.1044, 0.0258, 0.0277, 0.0225,
        0.0307, 0.5234, 0.0129], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,734][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0044, 0.0702, 0.1140, 0.3631, 0.0745, 0.0121, 0.0510, 0.0587, 0.0329,
        0.0630, 0.1213, 0.0349], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,735][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.0022, 0.0792, 0.0905, 0.0764, 0.0745, 0.0901, 0.0973, 0.1156, 0.0659,
        0.1002, 0.0886, 0.1195], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,735][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ school] are: tensor([5.1160e-03, 1.7557e-02, 9.2746e-04, 5.5798e-03, 6.3018e-04, 5.3942e-04,
        9.7817e-04, 8.7572e-04, 3.1837e-04, 4.3027e-03, 4.7136e-04, 9.6270e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:41,739][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0856, 0.4574, 0.1308, 0.0317, 0.0470, 0.0646, 0.0142, 0.0276, 0.0332,
        0.0585, 0.0233, 0.0139, 0.0121], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,743][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.4669, 0.1225, 0.1012, 0.0925, 0.0153, 0.0237, 0.0162, 0.0185, 0.0052,
        0.0181, 0.0216, 0.0198, 0.0785], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,744][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1170, 0.0066, 0.0236, 0.0614, 0.0298, 0.0641, 0.0446, 0.0670, 0.0380,
        0.1272, 0.1209, 0.0450, 0.2547], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,745][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1782, 0.0835, 0.0946, 0.0738, 0.0579, 0.0823, 0.0651, 0.0712, 0.0398,
        0.0578, 0.0553, 0.0531, 0.0875], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,745][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0299, 0.0744, 0.0921, 0.0701, 0.0739, 0.0793, 0.1020, 0.0859, 0.0739,
        0.0646, 0.0752, 0.1036, 0.0750], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,746][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0937, 0.1086, 0.2536, 0.0095, 0.0450, 0.0986, 0.0194, 0.0353, 0.0687,
        0.0840, 0.0655, 0.0410, 0.0772], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,750][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0769, 0.0768, 0.0768, 0.0770, 0.0770, 0.0770, 0.0770, 0.0769, 0.0770,
        0.0769, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,753][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0387, 0.0647, 0.0882, 0.0742, 0.0784, 0.0733, 0.0764, 0.0697, 0.0564,
        0.1145, 0.1057, 0.0832, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,754][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0913, 0.1972, 0.0197, 0.0607, 0.0348, 0.0979, 0.0262, 0.0183, 0.0114,
        0.0254, 0.3324, 0.0136, 0.0711], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,755][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([7.2482e-05, 3.8846e-02, 5.4211e-01, 1.6902e-01, 7.5047e-03, 4.4254e-03,
        1.2822e-01, 1.1175e-02, 8.7712e-03, 6.2837e-03, 1.9859e-02, 4.9918e-02,
        1.3800e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,756][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0075, 0.0571, 0.0756, 0.0624, 0.0645, 0.0830, 0.0868, 0.0970, 0.0573,
        0.0912, 0.0779, 0.1010, 0.1388], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,757][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0836, 0.1208, 0.0478, 0.0732, 0.0434, 0.1239, 0.0142, 0.0388, 0.0384,
        0.0857, 0.1348, 0.0238, 0.1716], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:41,761][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0973, 0.4224, 0.1313, 0.0349, 0.0417, 0.0594, 0.0150, 0.0301, 0.0388,
        0.0643, 0.0273, 0.0144, 0.0140, 0.0092], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,764][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0353, 0.1275, 0.0177, 0.2052, 0.0041, 0.0271, 0.0091, 0.0315, 0.0085,
        0.0708, 0.0709, 0.0145, 0.3735, 0.0044], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,765][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0870, 0.0157, 0.0230, 0.0749, 0.0243, 0.0816, 0.0514, 0.0760, 0.0358,
        0.1275, 0.1120, 0.0396, 0.2098, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,766][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.1793, 0.0624, 0.0730, 0.0671, 0.0452, 0.0946, 0.0591, 0.0688, 0.0389,
        0.0637, 0.0606, 0.0502, 0.0974, 0.0397], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,767][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0251, 0.0781, 0.0778, 0.0706, 0.0627, 0.0754, 0.0928, 0.0837, 0.0617,
        0.0605, 0.0707, 0.0893, 0.0739, 0.0777], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,768][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0025, 0.0750, 0.6814, 0.0062, 0.0116, 0.0025, 0.0017, 0.0022, 0.0026,
        0.0308, 0.0082, 0.0024, 0.0687, 0.1040], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,771][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0714, 0.0713, 0.0714, 0.0715, 0.0715, 0.0715, 0.0715, 0.0714, 0.0715,
        0.0714, 0.0714, 0.0714, 0.0714, 0.0715], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,775][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0330, 0.1015, 0.0770, 0.0779, 0.0452, 0.0985, 0.0822, 0.0907, 0.0528,
        0.0673, 0.0759, 0.0741, 0.0897, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,776][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0396, 0.0570, 0.0037, 0.0134, 0.0087, 0.1660, 0.0078, 0.0074, 0.0058,
        0.0315, 0.5855, 0.0059, 0.0563, 0.0114], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,776][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0005, 0.0709, 0.0891, 0.1791, 0.0574, 0.0042, 0.0383, 0.1365, 0.0101,
        0.0852, 0.1033, 0.0210, 0.1593, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,777][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0034, 0.0736, 0.0760, 0.0691, 0.0578, 0.0857, 0.0759, 0.0880, 0.0496,
        0.0882, 0.0673, 0.0860, 0.1083, 0.0712], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,778][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([2.0826e-05, 2.0303e-03, 4.3128e-04, 6.9346e-05, 3.9347e-01, 2.1835e-05,
        8.3597e-06, 6.7162e-06, 7.7638e-06, 1.1437e-05, 1.6830e-05, 7.5524e-05,
        5.2301e-03, 5.9860e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:41,782][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0713, 0.4152, 0.1546, 0.0368, 0.0510, 0.0579, 0.0160, 0.0309, 0.0385,
        0.0541, 0.0230, 0.0132, 0.0126, 0.0094, 0.0156], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,785][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0887, 0.1536, 0.0331, 0.1503, 0.0080, 0.0296, 0.0077, 0.0239, 0.0083,
        0.0573, 0.0519, 0.0109, 0.3653, 0.0091, 0.0024], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,786][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0866, 0.0114, 0.0225, 0.0631, 0.0272, 0.0556, 0.0460, 0.0690, 0.0378,
        0.1231, 0.0972, 0.0344, 0.2051, 0.0519, 0.0692], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,787][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.1794, 0.0662, 0.0734, 0.0606, 0.0466, 0.0718, 0.0569, 0.0645, 0.0361,
        0.0589, 0.0522, 0.0469, 0.0981, 0.0409, 0.0477], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,788][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0238, 0.0705, 0.0719, 0.0622, 0.0546, 0.0684, 0.0862, 0.0785, 0.0624,
        0.0560, 0.0643, 0.0806, 0.0660, 0.0673, 0.0873], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,789][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0748, 0.2609, 0.0253, 0.0047, 0.0045, 0.1096, 0.0410, 0.0249, 0.0473,
        0.2119, 0.0661, 0.0068, 0.0647, 0.0023, 0.0551], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,792][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0667, 0.0666, 0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0667,
        0.0667, 0.0666, 0.0666, 0.0666, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,796][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0368, 0.0664, 0.0629, 0.0608, 0.0596, 0.0835, 0.0803, 0.0871, 0.0594,
        0.0571, 0.0754, 0.0780, 0.0645, 0.0471, 0.0810], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,797][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0724, 0.0844, 0.0154, 0.0343, 0.0291, 0.0949, 0.0189, 0.0150, 0.0135,
        0.0348, 0.4442, 0.0151, 0.0717, 0.0304, 0.0261], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,798][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0018, 0.0651, 0.1276, 0.2913, 0.0543, 0.0031, 0.0803, 0.0560, 0.0233,
        0.0445, 0.0945, 0.0609, 0.0614, 0.0303, 0.0056], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,799][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0027, 0.0503, 0.0651, 0.0521, 0.0525, 0.0698, 0.0745, 0.0843, 0.0545,
        0.0760, 0.0636, 0.0855, 0.1129, 0.0698, 0.0864], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,800][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([2.3845e-03, 1.4351e-02, 8.9060e-04, 2.8420e-03, 9.2488e-05, 1.0639e-03,
        2.8436e-03, 1.4868e-03, 6.6977e-03, 2.0302e-03, 7.9569e-04, 8.7571e-04,
        1.4949e-02, 2.6058e-05, 9.4867e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:41,803][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0688, 0.3892, 0.1461, 0.0316, 0.0518, 0.0839, 0.0168, 0.0355, 0.0432,
        0.0337, 0.0254, 0.0187, 0.0129, 0.0103, 0.0197, 0.0124],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,807][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3195, 0.1398, 0.0934, 0.1114, 0.0180, 0.0380, 0.0155, 0.0267, 0.0067,
        0.0205, 0.0305, 0.0198, 0.1178, 0.0131, 0.0082, 0.0210],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,808][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0880, 0.0130, 0.0284, 0.0474, 0.0273, 0.0556, 0.0429, 0.0567, 0.0276,
        0.1043, 0.0831, 0.0333, 0.1358, 0.0431, 0.0553, 0.1582],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,809][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1830, 0.0688, 0.0704, 0.0599, 0.0443, 0.0739, 0.0520, 0.0611, 0.0325,
        0.0561, 0.0533, 0.0420, 0.0786, 0.0357, 0.0410, 0.0473],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,809][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0252, 0.0607, 0.0714, 0.0566, 0.0551, 0.0657, 0.0786, 0.0699, 0.0562,
        0.0547, 0.0617, 0.0822, 0.0607, 0.0662, 0.0788, 0.0564],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,810][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.1476e-03, 7.1757e-04, 1.0601e-02, 1.7872e-04, 9.3077e-03, 2.2273e-03,
        2.9258e-03, 2.1587e-03, 1.3816e-03, 4.9718e-01, 4.1629e-03, 7.7190e-04,
        2.3046e-03, 1.2299e-02, 4.8891e-03, 4.4775e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,814][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0625, 0.0624, 0.0624, 0.0626, 0.0625, 0.0625, 0.0625, 0.0624, 0.0625,
        0.0625, 0.0625, 0.0624, 0.0625, 0.0626, 0.0626, 0.0625],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,817][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0314, 0.0581, 0.0711, 0.0562, 0.0578, 0.0671, 0.0718, 0.0649, 0.0504,
        0.0712, 0.0769, 0.0624, 0.0710, 0.0481, 0.0775, 0.0643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,818][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0754, 0.1326, 0.0187, 0.0323, 0.0303, 0.1160, 0.0225, 0.0155, 0.0099,
        0.0297, 0.3661, 0.0157, 0.0599, 0.0301, 0.0223, 0.0231],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,819][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.2579e-04, 3.5748e-02, 4.2310e-01, 1.7598e-01, 9.9856e-03, 7.8224e-03,
        1.7611e-01, 1.7609e-02, 1.8940e-02, 8.6986e-03, 4.0829e-02, 5.4225e-02,
        1.4027e-02, 3.5044e-03, 5.2502e-03, 8.0519e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,820][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0100, 0.0400, 0.0581, 0.0480, 0.0496, 0.0729, 0.0674, 0.0760, 0.0413,
        0.0750, 0.0626, 0.0720, 0.0983, 0.0670, 0.0722, 0.0897],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,821][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([6.0874e-03, 5.4776e-02, 6.8199e-05, 2.3992e-02, 1.6562e-04, 2.3758e-03,
        2.0874e-04, 2.1452e-03, 1.8796e-03, 3.3139e-01, 7.1985e-03, 6.9974e-04,
        1.6126e-01, 5.4970e-04, 9.5242e-04, 4.0625e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:41,825][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0532, 0.3445, 0.1682, 0.0372, 0.0545, 0.0628, 0.0165, 0.0329, 0.0423,
        0.0557, 0.0234, 0.0148, 0.0132, 0.0104, 0.0215, 0.0229, 0.0259],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,828][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0652, 0.1045, 0.0356, 0.1731, 0.0106, 0.0414, 0.0117, 0.0363, 0.0113,
        0.0586, 0.0885, 0.0278, 0.2513, 0.0104, 0.0097, 0.0603, 0.0039],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,829][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0734, 0.0125, 0.0208, 0.0522, 0.0249, 0.0446, 0.0389, 0.0580, 0.0275,
        0.0904, 0.0694, 0.0308, 0.1537, 0.0454, 0.0546, 0.1372, 0.0658],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,830][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1746, 0.0550, 0.0598, 0.0549, 0.0417, 0.0661, 0.0495, 0.0585, 0.0338,
        0.0534, 0.0497, 0.0412, 0.0916, 0.0390, 0.0449, 0.0470, 0.0392],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,831][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0211, 0.0601, 0.0633, 0.0532, 0.0492, 0.0599, 0.0760, 0.0668, 0.0540,
        0.0489, 0.0557, 0.0714, 0.0571, 0.0600, 0.0753, 0.0503, 0.0776],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,833][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0458, 0.1245, 0.0064, 0.0117, 0.0113, 0.0589, 0.0136, 0.0869, 0.0208,
        0.0338, 0.0749, 0.1244, 0.1580, 0.0104, 0.0772, 0.0295, 0.1120],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,837][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0588, 0.0588, 0.0588, 0.0589, 0.0589, 0.0588, 0.0589, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0589, 0.0589, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,839][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0296, 0.0574, 0.0539, 0.0464, 0.0584, 0.0815, 0.0811, 0.0750, 0.0532,
        0.0490, 0.0610, 0.0588, 0.0502, 0.0479, 0.1015, 0.0423, 0.0527],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,840][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0466, 0.0581, 0.0047, 0.0316, 0.0151, 0.1348, 0.0087, 0.0122, 0.0087,
        0.0334, 0.4856, 0.0110, 0.0637, 0.0181, 0.0227, 0.0277, 0.0174],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,841][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0004, 0.0680, 0.2453, 0.2365, 0.0250, 0.0057, 0.0998, 0.0558, 0.0178,
        0.0291, 0.0766, 0.0472, 0.0491, 0.0098, 0.0045, 0.0218, 0.0076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,842][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0031, 0.0355, 0.0524, 0.0460, 0.0468, 0.0612, 0.0629, 0.0713, 0.0424,
        0.0667, 0.0561, 0.0728, 0.1007, 0.0622, 0.0718, 0.0795, 0.0685],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,843][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([1.3698e-03, 9.9933e-03, 1.6821e-04, 2.9754e-03, 3.7230e-03, 1.4526e-04,
        7.6155e-05, 2.5579e-04, 2.7973e-04, 1.0256e-03, 3.9506e-04, 4.7679e-04,
        1.1286e-02, 1.1004e-03, 1.8353e-03, 4.9932e-04, 9.6439e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:41,846][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0526, 0.3381, 0.1672, 0.0339, 0.0598, 0.0645, 0.0160, 0.0306, 0.0416,
        0.0456, 0.0217, 0.0173, 0.0127, 0.0119, 0.0210, 0.0190, 0.0303, 0.0163],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,850][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3178, 0.1573, 0.0741, 0.1122, 0.0124, 0.0233, 0.0102, 0.0204, 0.0061,
        0.0247, 0.0243, 0.0216, 0.1356, 0.0100, 0.0056, 0.0246, 0.0060, 0.0136],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,851][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0781, 0.0098, 0.0203, 0.0384, 0.0232, 0.0403, 0.0336, 0.0470, 0.0243,
        0.0759, 0.0712, 0.0325, 0.1239, 0.0421, 0.0513, 0.1228, 0.0621, 0.1032],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,852][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1645, 0.0636, 0.0646, 0.0551, 0.0406, 0.0642, 0.0469, 0.0573, 0.0313,
        0.0488, 0.0512, 0.0394, 0.0766, 0.0345, 0.0395, 0.0419, 0.0361, 0.0439],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,853][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0215, 0.0546, 0.0607, 0.0504, 0.0495, 0.0567, 0.0703, 0.0626, 0.0480,
        0.0464, 0.0543, 0.0710, 0.0540, 0.0599, 0.0699, 0.0475, 0.0714, 0.0513],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,855][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0403, 0.1492, 0.2723, 0.0057, 0.0117, 0.0267, 0.0129, 0.0375, 0.0153,
        0.0566, 0.0324, 0.1356, 0.0320, 0.0047, 0.0163, 0.0376, 0.1060, 0.0072],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,860][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0556, 0.0555, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0556,
        0.0556, 0.0555, 0.0555, 0.0555, 0.0556, 0.0556, 0.0555, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,861][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0316, 0.0482, 0.0600, 0.0480, 0.0572, 0.0573, 0.0615, 0.0607, 0.0463,
        0.0592, 0.0717, 0.0568, 0.0601, 0.0469, 0.0707, 0.0529, 0.0485, 0.0623],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,862][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0546, 0.0620, 0.0101, 0.0257, 0.0197, 0.0757, 0.0130, 0.0106, 0.0070,
        0.0250, 0.2914, 0.0108, 0.0489, 0.0245, 0.0152, 0.0209, 0.0133, 0.2716],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,863][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.8943e-04, 2.6629e-02, 4.0759e-01, 1.5513e-01, 1.0304e-02, 9.1104e-03,
        1.8020e-01, 1.3097e-02, 2.0569e-02, 8.4265e-03, 3.9192e-02, 6.8329e-02,
        1.2898e-02, 4.0729e-03, 6.2142e-03, 8.4745e-03, 1.1331e-02, 1.8237e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,864][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0060, 0.0331, 0.0509, 0.0420, 0.0454, 0.0605, 0.0578, 0.0660, 0.0353,
        0.0618, 0.0560, 0.0689, 0.0890, 0.0617, 0.0650, 0.0730, 0.0646, 0.0631],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,866][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.8478e-04, 3.0300e-03, 2.0816e-05, 1.5498e-03, 3.6970e-05, 2.2942e-04,
        1.4250e-04, 2.8552e-04, 1.0224e-03, 4.5661e-03, 2.8389e-03, 1.5255e-04,
        1.4323e-02, 9.0541e-05, 4.6282e-04, 6.1905e-03, 2.2504e-04, 9.6405e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:41,871][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0659, 0.3585, 0.1630, 0.0383, 0.0495, 0.0585, 0.0167, 0.0301, 0.0355,
        0.0382, 0.0215, 0.0170, 0.0114, 0.0090, 0.0193, 0.0173, 0.0261, 0.0171,
        0.0071], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,872][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0304, 0.0353, 0.0195, 0.0738, 0.0119, 0.0331, 0.0128, 0.0437, 0.0178,
        0.0529, 0.0935, 0.0189, 0.2898, 0.0165, 0.0202, 0.0767, 0.0159, 0.1198,
        0.0176], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,873][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0544, 0.0125, 0.0212, 0.0471, 0.0250, 0.0447, 0.0343, 0.0512, 0.0212,
        0.0822, 0.0624, 0.0305, 0.1233, 0.0445, 0.0484, 0.1216, 0.0609, 0.0777,
        0.0370], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,874][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1584, 0.0525, 0.0609, 0.0509, 0.0395, 0.0666, 0.0442, 0.0554, 0.0301,
        0.0480, 0.0434, 0.0402, 0.0835, 0.0374, 0.0411, 0.0424, 0.0365, 0.0362,
        0.0327], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,875][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0184, 0.0567, 0.0551, 0.0505, 0.0428, 0.0540, 0.0628, 0.0589, 0.0446,
        0.0446, 0.0520, 0.0625, 0.0546, 0.0533, 0.0646, 0.0460, 0.0682, 0.0482,
        0.0623], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,878][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.1070, 0.2785, 0.0594, 0.0101, 0.0099, 0.0836, 0.0124, 0.0796, 0.0159,
        0.0228, 0.0719, 0.0311, 0.0560, 0.0033, 0.0095, 0.0132, 0.0082, 0.0369,
        0.0906], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,882][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0526, 0.0526, 0.0526, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526,
        0.0526, 0.0526, 0.0526, 0.0526, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526,
        0.0526], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,883][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0252, 0.0535, 0.0675, 0.0454, 0.0503, 0.0841, 0.0706, 0.0773, 0.0473,
        0.0373, 0.0564, 0.0402, 0.0517, 0.0359, 0.0833, 0.0331, 0.0603, 0.0479,
        0.0325], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,884][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0391, 0.0421, 0.0065, 0.0275, 0.0132, 0.0783, 0.0089, 0.0125, 0.0082,
        0.0205, 0.3287, 0.0072, 0.0549, 0.0110, 0.0241, 0.0163, 0.0183, 0.2784,
        0.0045], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,885][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0014, 0.0567, 0.1277, 0.2057, 0.0810, 0.0041, 0.0548, 0.0745, 0.0231,
        0.0364, 0.0851, 0.0414, 0.0635, 0.0350, 0.0070, 0.0259, 0.0070, 0.0430,
        0.0265], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,887][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0027, 0.0341, 0.0508, 0.0405, 0.0429, 0.0570, 0.0521, 0.0622, 0.0343,
        0.0589, 0.0501, 0.0679, 0.0857, 0.0593, 0.0600, 0.0689, 0.0588, 0.0536,
        0.0601], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,890][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([2.6075e-02, 7.0467e-02, 5.0006e-04, 1.9928e-02, 8.7033e-04, 2.9556e-03,
        2.6839e-03, 4.1785e-03, 1.7000e-03, 1.2178e-02, 1.4024e-03, 8.9414e-03,
        7.3285e-02, 7.8069e-05, 2.0831e-03, 7.5068e-03, 3.0141e-04, 7.1365e-04,
        7.6415e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:41,893][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0619, 0.3423, 0.1428, 0.0307, 0.0516, 0.0786, 0.0164, 0.0315, 0.0423,
        0.0287, 0.0228, 0.0186, 0.0120, 0.0109, 0.0239, 0.0123, 0.0378, 0.0155,
        0.0070, 0.0123], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,894][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3183, 0.1406, 0.0785, 0.1016, 0.0147, 0.0321, 0.0131, 0.0215, 0.0053,
        0.0177, 0.0255, 0.0164, 0.1181, 0.0102, 0.0060, 0.0176, 0.0053, 0.0277,
        0.0120, 0.0178], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,895][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0674, 0.0105, 0.0250, 0.0302, 0.0233, 0.0377, 0.0329, 0.0406, 0.0205,
        0.0677, 0.0554, 0.0275, 0.0937, 0.0360, 0.0409, 0.1056, 0.0601, 0.0690,
        0.0391, 0.1169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,896][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1646, 0.0611, 0.0607, 0.0518, 0.0377, 0.0619, 0.0437, 0.0521, 0.0275,
        0.0479, 0.0452, 0.0358, 0.0703, 0.0302, 0.0337, 0.0399, 0.0322, 0.0374,
        0.0302, 0.0360], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,898][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0197, 0.0471, 0.0560, 0.0440, 0.0431, 0.0513, 0.0613, 0.0544, 0.0438,
        0.0426, 0.0480, 0.0642, 0.0474, 0.0520, 0.0613, 0.0440, 0.0672, 0.0459,
        0.0634, 0.0434], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,901][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.4301e-04, 3.7262e-04, 7.1531e-03, 8.2083e-05, 4.9570e-03, 1.1122e-03,
        1.5430e-03, 1.3724e-03, 8.6801e-04, 2.7248e-01, 2.3617e-03, 6.1335e-04,
        1.5160e-03, 9.6819e-03, 3.7882e-03, 2.6186e-01, 4.9158e-04, 3.5256e-03,
        1.3533e-02, 4.1225e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,906][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0500, 0.0499, 0.0499, 0.0501, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0501, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,907][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0254, 0.0457, 0.0558, 0.0448, 0.0471, 0.0542, 0.0575, 0.0518, 0.0409,
        0.0565, 0.0626, 0.0483, 0.0562, 0.0387, 0.0609, 0.0509, 0.0490, 0.0554,
        0.0521, 0.0463], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,908][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0489, 0.0906, 0.0128, 0.0184, 0.0210, 0.0804, 0.0149, 0.0094, 0.0060,
        0.0189, 0.2561, 0.0097, 0.0396, 0.0215, 0.0143, 0.0144, 0.0108, 0.2921,
        0.0098, 0.0104], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,909][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.2430e-04, 2.9091e-02, 4.0375e-01, 1.5376e-01, 9.1459e-03, 8.0061e-03,
        1.8903e-01, 1.4856e-02, 1.9520e-02, 7.0445e-03, 3.8383e-02, 5.3765e-02,
        1.1127e-02, 3.0400e-03, 5.5877e-03, 6.6253e-03, 1.0020e-02, 1.6509e-02,
        1.3718e-02, 6.8957e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,912][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0099, 0.0284, 0.0444, 0.0370, 0.0384, 0.0556, 0.0519, 0.0587, 0.0319,
        0.0577, 0.0477, 0.0557, 0.0780, 0.0510, 0.0546, 0.0685, 0.0590, 0.0504,
        0.0546, 0.0666], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,914][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.0221e-03, 3.7104e-02, 3.6155e-05, 1.3680e-02, 8.1738e-05, 1.5195e-03,
        1.1085e-04, 1.6862e-03, 1.1323e-03, 1.9658e-01, 4.0792e-03, 3.3386e-04,
        1.1612e-01, 4.8229e-04, 6.3271e-04, 2.6436e-01, 7.2209e-04, 1.1036e-02,
        2.5648e-04, 3.4702e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:41,933][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:41,934][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,935][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,936][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,937][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,938][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,939][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,939][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,940][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,940][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,941][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,942][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,942][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:41,943][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5655, 0.4345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,944][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6931, 0.3069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,944][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9459, 0.0541], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,945][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3603, 0.6397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,946][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7067, 0.2933], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,947][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.5707e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,947][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2373, 0.7627], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,948][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3845, 0.6155], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,950][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,951][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5013, 0.4987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,952][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,953][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1873, 0.8127], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:41,953][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.4892, 0.3811, 0.1297], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,954][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.1029, 0.8145, 0.0826], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,958][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.6680, 0.1741, 0.1580], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,961][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2806, 0.4786, 0.2408], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,962][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.8033, 0.1673, 0.0294], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,963][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([1.1751e-02, 9.8818e-01, 6.6108e-05], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,963][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1060, 0.8490, 0.0450], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,964][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.1804, 0.4791, 0.3405], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,965][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1624, 0.0012, 0.8364], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,968][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.3341, 0.3323, 0.3336], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,972][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.3336, 0.3332, 0.3332], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,973][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.1649, 0.7531, 0.0820], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:41,973][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2937, 0.2501, 0.1074, 0.3487], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,974][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0757, 0.3369, 0.5811, 0.0063], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,975][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5840, 0.0993, 0.0968, 0.2200], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,977][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1969, 0.2647, 0.1929, 0.3455], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,981][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5675, 0.1995, 0.0344, 0.1986], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,983][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.6406e-05, 9.9994e-01, 2.5394e-08, 3.4892e-09], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,983][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5890, 0.3862, 0.0142, 0.0107], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,984][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1400, 0.2649, 0.3409, 0.2541], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,985][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3210, 0.0007, 0.6745, 0.0038], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,986][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2502, 0.2489, 0.2499, 0.2511], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,988][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2501, 0.2499, 0.2498, 0.2502], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,992][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0664, 0.1666, 0.0011, 0.7659], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:41,993][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.2693, 0.2143, 0.0783, 0.3213, 0.1168], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,994][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0692, 0.2386, 0.0866, 0.5907, 0.0148], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,995][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.4127, 0.1171, 0.1063, 0.2200, 0.1439], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,996][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.1593, 0.2262, 0.1409, 0.2711, 0.2026], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,996][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.6777, 0.1232, 0.0230, 0.1504, 0.0256], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:41,998][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([2.9933e-03, 9.9700e-01, 1.9627e-06, 1.8299e-08, 8.9762e-08],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,002][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0889, 0.8739, 0.0199, 0.0074, 0.0099], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,004][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0934, 0.2938, 0.2483, 0.2316, 0.1328], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,005][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([1.0438e-01, 8.7365e-04, 8.8335e-01, 3.9974e-03, 7.4001e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,006][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.2001, 0.1991, 0.1999, 0.2008, 0.2001], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,006][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2001, 0.1999, 0.1999, 0.2001, 0.1999], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,007][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0909, 0.2908, 0.0010, 0.5591, 0.0582], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,009][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1978, 0.1728, 0.0686, 0.2540, 0.0993, 0.2076], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,013][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0747, 0.5936, 0.0797, 0.2089, 0.0290, 0.0140], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,015][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.2918, 0.1229, 0.1107, 0.2412, 0.1597, 0.0736], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,016][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1267, 0.1827, 0.1339, 0.2317, 0.1866, 0.1384], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,017][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.5833, 0.1473, 0.0253, 0.1543, 0.0259, 0.0639], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,017][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([1.6191e-03, 9.9838e-01, 3.5176e-08, 2.4575e-10, 1.8420e-09, 1.4249e-11],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,018][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([3.6740e-01, 6.2393e-01, 4.9294e-03, 1.9143e-03, 1.6410e-03, 1.8731e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,021][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0930, 0.1573, 0.2092, 0.1829, 0.1619, 0.1956], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,023][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([1.4223e-01, 8.0994e-04, 8.4735e-01, 2.4128e-03, 7.1816e-03, 1.7779e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,026][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.1668, 0.1659, 0.1665, 0.1673, 0.1667, 0.1667], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,027][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.1668, 0.1666, 0.1666, 0.1668, 0.1666, 0.1667], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,027][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0590, 0.2422, 0.0012, 0.5623, 0.0015, 0.1338], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,028][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.1970, 0.1623, 0.0598, 0.2423, 0.0934, 0.2076, 0.0378],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,029][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0811, 0.3023, 0.1671, 0.2139, 0.0758, 0.1583, 0.0015],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,032][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.2523, 0.1181, 0.1079, 0.2368, 0.1583, 0.0730, 0.0536],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,036][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.1251, 0.1828, 0.1139, 0.2075, 0.1633, 0.1264, 0.0810],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,037][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.5971, 0.1273, 0.0225, 0.1340, 0.0236, 0.0581, 0.0375],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,038][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([1.3817e-03, 9.9862e-01, 3.8992e-08, 1.5076e-09, 4.9771e-09, 9.5201e-11,
        3.7650e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,039][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([3.8625e-02, 9.4600e-01, 2.1592e-03, 1.0469e-02, 1.3325e-03, 4.8317e-04,
        9.3375e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,039][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0837, 0.1448, 0.1523, 0.1385, 0.1406, 0.2176, 0.1224],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,040][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([1.5075e-02, 3.3677e-05, 8.3365e-02, 6.9798e-05, 5.4508e-04, 6.7211e-07,
        9.0091e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,044][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.1430, 0.1422, 0.1428, 0.1434, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,047][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.1430, 0.1428, 0.1428, 0.1430, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,048][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([6.6156e-02, 2.4033e-01, 6.3706e-04, 6.7748e-01, 7.9227e-04, 1.2677e-02,
        1.9233e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,049][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.1860, 0.1580, 0.0615, 0.2183, 0.0916, 0.1704, 0.0375, 0.0768],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,050][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0995, 0.5766, 0.0871, 0.1106, 0.0543, 0.0620, 0.0072, 0.0028],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,050][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2217, 0.1166, 0.1056, 0.2243, 0.1562, 0.0707, 0.0523, 0.0525],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,053][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.1131, 0.1523, 0.1064, 0.1817, 0.1624, 0.1082, 0.0822, 0.0936],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,058][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.5409, 0.1292, 0.0228, 0.1331, 0.0236, 0.0583, 0.0379, 0.0542],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,058][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([3.3879e-03, 9.9661e-01, 7.5965e-08, 2.0756e-09, 1.1265e-08, 1.2167e-10,
        5.6219e-10, 9.1544e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,059][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([9.9570e-02, 8.8738e-01, 3.7914e-03, 6.0019e-03, 1.0703e-03, 3.2434e-04,
        1.2348e-03, 6.2510e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,060][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0830, 0.1266, 0.1186, 0.1173, 0.1180, 0.1590, 0.1434, 0.1340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,061][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([7.0512e-03, 1.2500e-05, 5.3212e-02, 3.9689e-05, 2.5580e-04, 3.0491e-07,
        8.9720e-01, 4.2231e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,062][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.1251, 0.1245, 0.1250, 0.1256, 0.1251, 0.1251, 0.1251, 0.1246],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,065][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.1251, 0.1250, 0.1249, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,067][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([4.5940e-02, 2.5889e-01, 1.0199e-03, 5.7886e-01, 7.6142e-04, 1.2566e-02,
        5.4508e-04, 1.0142e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,069][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.1838, 0.1479, 0.0569, 0.2056, 0.0844, 0.1639, 0.0341, 0.0738, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,070][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0717, 0.3443, 0.1208, 0.1719, 0.0595, 0.0923, 0.0114, 0.1262, 0.0020],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,071][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2075, 0.1098, 0.0990, 0.2134, 0.1456, 0.0665, 0.0504, 0.0521, 0.0556],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,072][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0943, 0.1292, 0.0878, 0.1583, 0.1243, 0.0914, 0.0655, 0.0944, 0.1549],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,072][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.5166, 0.1228, 0.0215, 0.1271, 0.0231, 0.0571, 0.0378, 0.0542, 0.0399],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,074][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([7.8784e-03, 9.9212e-01, 9.8930e-08, 5.0104e-09, 2.1355e-08, 5.5513e-10,
        1.7987e-09, 1.7961e-09, 3.4719e-09], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,078][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.2932, 0.6666, 0.0185, 0.0112, 0.0034, 0.0011, 0.0025, 0.0021, 0.0015],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,080][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0532, 0.1101, 0.1164, 0.1058, 0.1126, 0.1570, 0.1307, 0.1312, 0.0829],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,081][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([7.5203e-03, 4.6204e-05, 3.4000e-02, 1.7101e-04, 2.6786e-04, 5.0005e-07,
        3.3073e-01, 1.1403e-01, 5.1323e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,082][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.1112, 0.1106, 0.1110, 0.1115, 0.1111, 0.1111, 0.1111, 0.1107, 0.1117],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,082][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1112, 0.1111, 0.1111, 0.1112, 0.1111, 0.1111, 0.1110, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,083][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([8.5863e-02, 2.8616e-01, 7.3869e-04, 5.8905e-01, 7.1082e-04, 1.8042e-02,
        1.7639e-04, 5.9653e-03, 1.3285e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,086][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1514, 0.1251, 0.0526, 0.1716, 0.0786, 0.1385, 0.0324, 0.0670, 0.0462,
        0.1367], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,090][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1391, 0.2262, 0.2285, 0.1105, 0.0514, 0.1560, 0.0156, 0.0653, 0.0046,
        0.0027], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,091][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1969, 0.1010, 0.0907, 0.1892, 0.1331, 0.0636, 0.0479, 0.0492, 0.0530,
        0.0755], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,092][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0807, 0.1028, 0.0718, 0.1277, 0.1108, 0.0857, 0.0563, 0.0766, 0.1336,
        0.1539], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,093][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4373, 0.1279, 0.0221, 0.1251, 0.0228, 0.0564, 0.0369, 0.0528, 0.0390,
        0.0797], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,094][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.3032e-03, 9.9670e-01, 1.5854e-07, 5.5106e-09, 3.6018e-08, 5.2618e-10,
        1.8668e-09, 1.7452e-09, 2.6006e-09, 2.5366e-08], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,096][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0993, 0.8658, 0.0096, 0.0127, 0.0027, 0.0010, 0.0031, 0.0018, 0.0015,
        0.0025], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,100][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0514, 0.0972, 0.1174, 0.0989, 0.0923, 0.1114, 0.1106, 0.1124, 0.0869,
        0.1216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,102][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.1453e-02, 2.8309e-05, 4.8112e-02, 8.1548e-05, 2.4696e-04, 4.4411e-07,
        4.0607e-01, 7.7727e-02, 4.5085e-01, 5.4273e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,102][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1000, 0.0995, 0.0999, 0.1004, 0.1000, 0.1000, 0.1000, 0.0996, 0.1005,
        0.1002], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,103][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1001, 0.1000, 0.0999, 0.1001, 0.1000, 0.1000, 0.0999, 0.1000, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,104][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.9825e-02, 1.4414e-01, 4.3392e-04, 4.2876e-01, 5.4461e-04, 1.2410e-02,
        1.5649e-04, 1.0075e-02, 5.9508e-04, 3.6306e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,105][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1304, 0.1074, 0.0449, 0.1440, 0.0680, 0.1184, 0.0283, 0.0569, 0.0399,
        0.1242, 0.1376], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,109][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1746, 0.3183, 0.1226, 0.1187, 0.0403, 0.1317, 0.0093, 0.0406, 0.0082,
        0.0295, 0.0061], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,112][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1701, 0.0820, 0.0794, 0.1672, 0.1199, 0.0584, 0.0446, 0.0475, 0.0511,
        0.0710, 0.1090], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,113][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0712, 0.0878, 0.0646, 0.1150, 0.1077, 0.0693, 0.0508, 0.0634, 0.1116,
        0.1156, 0.1430], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,114][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3522, 0.1115, 0.0202, 0.1078, 0.0217, 0.0523, 0.0357, 0.0505, 0.0381,
        0.0734, 0.1367], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,115][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([6.0272e-03, 9.9397e-01, 8.3678e-08, 2.2581e-09, 1.2360e-08, 2.1964e-10,
        8.5239e-10, 8.6504e-10, 1.8104e-09, 8.5464e-09, 1.8715e-09],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,115][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2634, 0.5891, 0.0634, 0.0280, 0.0117, 0.0036, 0.0091, 0.0080, 0.0057,
        0.0081, 0.0098], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,119][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0458, 0.0748, 0.1083, 0.0777, 0.0894, 0.1046, 0.0989, 0.0989, 0.0817,
        0.0923, 0.1277], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,123][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.1344e-02, 1.9873e-05, 3.4189e-02, 8.7421e-05, 1.6759e-04, 2.0224e-07,
        4.7138e-01, 6.3671e-02, 4.1540e-01, 3.7369e-03, 2.6161e-06],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,123][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0909, 0.0905, 0.0908, 0.0913, 0.0909, 0.0909, 0.0909, 0.0906, 0.0914,
        0.0911, 0.0907], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,124][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0910, 0.0909, 0.0909, 0.0910, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,125][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([6.7492e-02, 1.9019e-01, 9.4255e-04, 4.8710e-01, 1.5655e-03, 1.6416e-02,
        2.6241e-04, 1.0006e-02, 1.0104e-03, 1.0154e-01, 1.2348e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,126][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.1127, 0.0980, 0.0372, 0.1463, 0.0602, 0.1222, 0.0254, 0.0551, 0.0359,
        0.1276, 0.1457, 0.0337], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,130][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0236, 0.1409, 0.3587, 0.0974, 0.0670, 0.1014, 0.0298, 0.0706, 0.0149,
        0.0075, 0.0873, 0.0008], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,133][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.1639, 0.0756, 0.0715, 0.1529, 0.1061, 0.0520, 0.0393, 0.0420, 0.0452,
        0.0622, 0.0946, 0.0946], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,134][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.0664, 0.0957, 0.0584, 0.1173, 0.0916, 0.0667, 0.0430, 0.0567, 0.1021,
        0.1291, 0.1275, 0.0456], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,135][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.4019, 0.0942, 0.0165, 0.0961, 0.0179, 0.0450, 0.0300, 0.0426, 0.0316,
        0.0636, 0.1240, 0.0366], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,136][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([4.1728e-03, 9.9582e-01, 1.2059e-06, 6.5152e-08, 3.6691e-07, 1.9707e-08,
        3.1319e-08, 5.3846e-08, 1.0936e-07, 3.0556e-07, 1.3795e-07, 1.0945e-06],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,137][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.1722, 0.6074, 0.0789, 0.0317, 0.0167, 0.0042, 0.0169, 0.0145, 0.0050,
        0.0141, 0.0097, 0.0287], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,140][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0378, 0.0818, 0.0896, 0.0710, 0.0692, 0.1135, 0.1239, 0.1166, 0.0750,
        0.0693, 0.0926, 0.0597], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,144][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([4.7555e-03, 5.3808e-06, 2.3661e-02, 3.9353e-05, 7.4884e-05, 7.1497e-08,
        2.8299e-01, 7.0472e-02, 6.1345e-01, 2.0832e-03, 9.6724e-07, 2.4674e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,145][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0834, 0.0829, 0.0832, 0.0836, 0.0833, 0.0833, 0.0833, 0.0830, 0.0838,
        0.0835, 0.0832, 0.0835], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,146][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0833, 0.0834,
        0.0833, 0.0833, 0.0833], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,146][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([4.0747e-02, 2.0845e-01, 6.2690e-04, 5.7244e-01, 8.3664e-04, 1.0368e-02,
        8.9264e-05, 4.0714e-03, 1.8570e-04, 1.4984e-01, 1.0035e-02, 2.3182e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,147][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1109, 0.0950, 0.0388, 0.1350, 0.0610, 0.1107, 0.0243, 0.0505, 0.0335,
        0.1125, 0.1247, 0.0304, 0.0724], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,149][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.6688e-01, 3.8414e-01, 1.9297e-01, 2.0847e-02, 6.0190e-02, 1.7705e-02,
        2.7223e-02, 1.3306e-02, 8.4312e-03, 1.8767e-03, 2.9995e-03, 3.1414e-03,
        2.9023e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,154][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1198, 0.0729, 0.0697, 0.1362, 0.1047, 0.0519, 0.0422, 0.0440, 0.0460,
        0.0629, 0.0949, 0.0964, 0.0582], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,155][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0545, 0.0693, 0.0506, 0.0953, 0.0792, 0.0495, 0.0387, 0.0462, 0.0893,
        0.0959, 0.0942, 0.0448, 0.1926], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,156][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2564, 0.0836, 0.0164, 0.0826, 0.0175, 0.0414, 0.0277, 0.0395, 0.0302,
        0.0578, 0.1066, 0.0330, 0.2071], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,157][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([5.5173e-03, 9.9448e-01, 5.1036e-07, 1.1626e-08, 8.0502e-08, 1.9651e-09,
        4.1936e-09, 4.4466e-09, 1.2198e-08, 5.0924e-08, 1.1122e-08, 9.7954e-08,
        1.1438e-08], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,158][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1232, 0.5263, 0.0934, 0.0697, 0.0243, 0.0119, 0.0191, 0.0259, 0.0115,
        0.0180, 0.0141, 0.0376, 0.0250], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,160][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0373, 0.0640, 0.0877, 0.0761, 0.0729, 0.0710, 0.0720, 0.0699, 0.0575,
        0.1140, 0.1123, 0.0837, 0.0816], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,163][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([5.0004e-03, 8.7681e-06, 3.5995e-02, 1.9142e-05, 1.1411e-04, 2.7003e-07,
        7.1558e-01, 1.9175e-02, 2.1980e-01, 5.4239e-04, 6.2478e-07, 3.7513e-03,
        1.1906e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,166][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0769, 0.0765, 0.0768, 0.0772, 0.0769, 0.0769, 0.0769, 0.0766, 0.0773,
        0.0771, 0.0768, 0.0771, 0.0769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,166][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0770, 0.0769, 0.0769, 0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,167][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([4.4744e-02, 1.0864e-01, 1.5216e-03, 3.0653e-01, 1.9865e-03, 2.1010e-02,
        3.2566e-04, 9.4896e-03, 1.2008e-03, 1.0344e-01, 3.0843e-02, 1.7363e-03,
        3.6853e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,168][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.1114, 0.0895, 0.0321, 0.1307, 0.0484, 0.1109, 0.0221, 0.0486, 0.0323,
        0.1132, 0.1318, 0.0319, 0.0713, 0.0259], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,169][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0624, 0.1797, 0.0646, 0.2507, 0.0114, 0.0861, 0.0128, 0.0997, 0.0149,
        0.0299, 0.1064, 0.0032, 0.0692, 0.0089], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,173][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0762, 0.0708, 0.0648, 0.1297, 0.0947, 0.0546, 0.0449, 0.0504, 0.0497,
        0.0661, 0.0955, 0.0941, 0.0636, 0.0448], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,176][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0520, 0.0684, 0.0440, 0.0869, 0.0647, 0.0528, 0.0356, 0.0444, 0.0755,
        0.0918, 0.0873, 0.0346, 0.1976, 0.0643], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,177][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.3403, 0.0607, 0.0112, 0.0662, 0.0135, 0.0341, 0.0230, 0.0331, 0.0243,
        0.0495, 0.1033, 0.0294, 0.1868, 0.0247], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,178][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([5.5355e-03, 9.9446e-01, 1.5097e-06, 3.0055e-08, 1.5151e-07, 2.9780e-09,
        7.1628e-09, 8.3834e-09, 1.5457e-08, 8.4110e-08, 1.4014e-08, 1.0484e-07,
        1.7632e-08, 5.1918e-08], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,179][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0384, 0.6059, 0.0912, 0.0674, 0.0174, 0.0079, 0.0213, 0.0211, 0.0144,
        0.0236, 0.0089, 0.0539, 0.0229, 0.0054], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,180][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0325, 0.0947, 0.0743, 0.0785, 0.0431, 0.0915, 0.0754, 0.0884, 0.0544,
        0.0700, 0.0857, 0.0746, 0.0963, 0.0407], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,182][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([3.2134e-03, 2.9878e-05, 3.2168e-02, 1.0981e-04, 2.2894e-04, 3.5962e-07,
        4.4080e-01, 5.3862e-02, 4.5516e-01, 6.1358e-03, 4.6603e-06, 7.8167e-03,
        9.7592e-05, 3.7426e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,187][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0714, 0.0711, 0.0713, 0.0717, 0.0714, 0.0714, 0.0714, 0.0712, 0.0718,
        0.0716, 0.0713, 0.0716, 0.0714, 0.0715], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,188][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0715, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0714, 0.0714, 0.0714, 0.0715], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,188][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([2.7914e-02, 1.0468e-01, 3.7879e-04, 1.8875e-01, 2.1950e-02, 6.6905e-03,
        5.4582e-05, 1.2220e-03, 1.5587e-04, 4.3481e-02, 5.8823e-03, 6.0622e-04,
        5.8692e-01, 1.1322e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,189][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.1048, 0.0894, 0.0354, 0.1328, 0.0531, 0.1069, 0.0219, 0.0476, 0.0311,
        0.1055, 0.1223, 0.0294, 0.0700, 0.0280, 0.0217], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,190][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0827, 0.2836, 0.1144, 0.1251, 0.0836, 0.0635, 0.0137, 0.0421, 0.0094,
        0.0371, 0.0386, 0.0089, 0.0548, 0.0379, 0.0045], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,193][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0970, 0.0711, 0.0653, 0.1332, 0.0975, 0.0490, 0.0393, 0.0421, 0.0431,
        0.0590, 0.0879, 0.0883, 0.0543, 0.0390, 0.0339], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,198][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0453, 0.0637, 0.0452, 0.0835, 0.0660, 0.0491, 0.0329, 0.0438, 0.0717,
        0.0952, 0.0881, 0.0324, 0.1885, 0.0658, 0.0287], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,199][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.3190, 0.0747, 0.0130, 0.0738, 0.0138, 0.0343, 0.0231, 0.0328, 0.0244,
        0.0482, 0.0928, 0.0280, 0.1696, 0.0209, 0.0317], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,199][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([1.2888e-02, 9.8711e-01, 2.5113e-07, 5.2439e-09, 3.4152e-08, 1.0507e-09,
        2.5821e-09, 2.5451e-09, 7.8498e-09, 3.8073e-08, 9.0907e-09, 6.5242e-08,
        8.5066e-09, 2.1596e-08, 5.6376e-09], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,200][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0745, 0.8347, 0.0138, 0.0182, 0.0023, 0.0015, 0.0050, 0.0030, 0.0029,
        0.0051, 0.0066, 0.0128, 0.0098, 0.0044, 0.0054], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,201][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0344, 0.0626, 0.0623, 0.0618, 0.0557, 0.0790, 0.0747, 0.0863, 0.0593,
        0.0590, 0.0817, 0.0776, 0.0703, 0.0517, 0.0836], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,203][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([2.3914e-03, 5.2465e-06, 3.2751e-02, 1.2827e-05, 1.5038e-04, 8.1888e-08,
        4.6491e-01, 2.7669e-02, 4.6244e-01, 1.2125e-03, 9.0500e-07, 3.8169e-03,
        1.3449e-05, 2.5836e-04, 4.3617e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,207][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0663, 0.0666, 0.0669, 0.0667, 0.0667, 0.0666, 0.0664, 0.0670,
        0.0668, 0.0665, 0.0668, 0.0666, 0.0667, 0.0668], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,209][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0667, 0.0666, 0.0667, 0.0666, 0.0667, 0.0666, 0.0667, 0.0667,
        0.0667, 0.0667, 0.0666, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,210][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([2.9525e-02, 1.1009e-01, 2.5957e-04, 2.3849e-01, 2.6211e-04, 1.0373e-02,
        1.3817e-04, 2.9124e-03, 5.0735e-04, 9.9743e-02, 4.6841e-03, 2.4049e-04,
        4.9603e-01, 1.4390e-04, 6.6095e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,211][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0989, 0.0823, 0.0346, 0.1134, 0.0529, 0.0922, 0.0219, 0.0465, 0.0316,
        0.0898, 0.1110, 0.0272, 0.0636, 0.0285, 0.0221, 0.0834],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,212][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1634, 0.2852, 0.1745, 0.0991, 0.0458, 0.1056, 0.0103, 0.0390, 0.0036,
        0.0017, 0.0252, 0.0054, 0.0018, 0.0137, 0.0252, 0.0006],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,214][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0878, 0.0693, 0.0609, 0.1254, 0.0892, 0.0480, 0.0379, 0.0413, 0.0420,
        0.0579, 0.0845, 0.0854, 0.0538, 0.0375, 0.0332, 0.0459],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,218][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0442, 0.0545, 0.0388, 0.0692, 0.0604, 0.0467, 0.0307, 0.0416, 0.0728,
        0.0836, 0.0790, 0.0336, 0.1617, 0.0610, 0.0298, 0.0924],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,220][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2408, 0.0733, 0.0134, 0.0686, 0.0144, 0.0346, 0.0239, 0.0337, 0.0256,
        0.0482, 0.0888, 0.0288, 0.1632, 0.0224, 0.0327, 0.0878],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,221][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.9933e-03, 9.9500e-01, 8.6182e-07, 2.2732e-08, 1.8058e-07, 4.0714e-09,
        1.0681e-08, 9.2562e-09, 2.1350e-08, 1.2973e-07, 2.3875e-08, 1.6591e-07,
        2.1958e-08, 6.4748e-08, 1.4943e-08, 1.8450e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,222][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0451, 0.7630, 0.0178, 0.0395, 0.0043, 0.0034, 0.0089, 0.0061, 0.0069,
        0.0096, 0.0087, 0.0328, 0.0133, 0.0050, 0.0105, 0.0251],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,222][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0298, 0.0551, 0.0687, 0.0574, 0.0535, 0.0638, 0.0663, 0.0647, 0.0509,
        0.0731, 0.0835, 0.0629, 0.0745, 0.0513, 0.0768, 0.0678],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,224][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.7988e-03, 2.1182e-05, 4.5475e-02, 5.5699e-05, 2.0640e-04, 3.6606e-07,
        4.0776e-01, 6.7995e-02, 4.4700e-01, 3.9080e-03, 2.6428e-06, 4.7937e-03,
        3.8516e-05, 3.2814e-04, 6.4430e-03, 6.1796e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,227][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0625, 0.0622, 0.0624, 0.0627, 0.0625, 0.0625, 0.0625, 0.0622, 0.0628,
        0.0626, 0.0624, 0.0626, 0.0624, 0.0625, 0.0626, 0.0626],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,230][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0625, 0.0625, 0.0625, 0.0626, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0625, 0.0624, 0.0625, 0.0625, 0.0625, 0.0625],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,231][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.9984e-02, 7.1085e-02, 2.3941e-04, 2.1633e-01, 2.8115e-04, 6.3618e-03,
        7.4562e-05, 4.7990e-03, 3.0080e-04, 1.7936e-01, 7.6838e-03, 3.1462e-04,
        2.7636e-01, 1.7161e-04, 5.6563e-04, 2.1609e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,232][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0991, 0.0787, 0.0343, 0.1107, 0.0496, 0.0868, 0.0202, 0.0429, 0.0288,
        0.0891, 0.1035, 0.0265, 0.0601, 0.0274, 0.0209, 0.0851, 0.0363],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,233][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0892, 0.1264, 0.1822, 0.0879, 0.0956, 0.1366, 0.0131, 0.0606, 0.0088,
        0.0222, 0.0702, 0.0064, 0.0091, 0.0366, 0.0339, 0.0105, 0.0107],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,235][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1103, 0.0652, 0.0585, 0.1257, 0.0864, 0.0436, 0.0336, 0.0364, 0.0382,
        0.0529, 0.0790, 0.0786, 0.0481, 0.0340, 0.0291, 0.0409, 0.0395],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,241][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0435, 0.0548, 0.0357, 0.0715, 0.0551, 0.0428, 0.0285, 0.0397, 0.0658,
        0.0807, 0.0763, 0.0292, 0.1539, 0.0561, 0.0280, 0.0882, 0.0503],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,244][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.2851, 0.0680, 0.0117, 0.0664, 0.0123, 0.0306, 0.0205, 0.0291, 0.0216,
        0.0428, 0.0816, 0.0246, 0.1508, 0.0181, 0.0277, 0.0800, 0.0290],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,245][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.1399e-02, 9.8860e-01, 4.1919e-07, 2.3621e-08, 1.3259e-07, 4.7449e-09,
        1.1057e-08, 1.3780e-08, 3.0754e-08, 1.2924e-07, 4.1091e-08, 3.4310e-07,
        4.2169e-08, 9.1322e-08, 2.3162e-08, 2.2516e-07, 9.9843e-08],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,245][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0122, 0.9014, 0.0114, 0.0211, 0.0026, 0.0019, 0.0031, 0.0025, 0.0023,
        0.0043, 0.0047, 0.0053, 0.0060, 0.0025, 0.0040, 0.0121, 0.0027],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,246][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0277, 0.0539, 0.0528, 0.0478, 0.0542, 0.0749, 0.0735, 0.0734, 0.0529,
        0.0518, 0.0677, 0.0594, 0.0556, 0.0531, 0.1002, 0.0480, 0.0530],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,248][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([8.1816e-03, 2.4529e-05, 2.0734e-02, 9.0006e-05, 1.6524e-04, 5.8311e-07,
        3.3498e-01, 5.7942e-02, 5.3755e-01, 3.3172e-03, 4.0836e-06, 4.7672e-03,
        4.3557e-05, 2.6908e-04, 7.5163e-03, 5.1582e-03, 1.9256e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,251][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0588, 0.0585, 0.0587, 0.0590, 0.0588, 0.0588, 0.0588, 0.0586, 0.0591,
        0.0589, 0.0587, 0.0589, 0.0588, 0.0588, 0.0589, 0.0589, 0.0589],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,254][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0589, 0.0588, 0.0588, 0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0589, 0.0588],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,255][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.6674e-02, 9.9845e-02, 2.9870e-04, 2.3514e-01, 1.6507e-03, 6.4531e-03,
        9.4645e-05, 2.5546e-03, 3.8295e-04, 7.5871e-02, 5.4875e-03, 4.1015e-04,
        4.1449e-01, 8.8592e-04, 1.5298e-03, 9.1967e-02, 3.6259e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,256][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0957, 0.0743, 0.0325, 0.0973, 0.0474, 0.0758, 0.0193, 0.0385, 0.0275,
        0.0798, 0.0887, 0.0236, 0.0525, 0.0263, 0.0198, 0.0751, 0.0327, 0.0932],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,257][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1066, 0.2156, 0.0964, 0.0596, 0.0612, 0.0962, 0.0091, 0.0599, 0.0081,
        0.0235, 0.0750, 0.0042, 0.0269, 0.0302, 0.0215, 0.0110, 0.0926, 0.0024],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,260][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0828, 0.0552, 0.0537, 0.1156, 0.0800, 0.0431, 0.0337, 0.0388, 0.0393,
        0.0529, 0.0797, 0.0790, 0.0513, 0.0356, 0.0309, 0.0426, 0.0397, 0.0462],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,265][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0376, 0.0481, 0.0340, 0.0616, 0.0585, 0.0401, 0.0261, 0.0356, 0.0593,
        0.0662, 0.0769, 0.0273, 0.1446, 0.0591, 0.0252, 0.0725, 0.0438, 0.0834],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,266][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2111, 0.0602, 0.0113, 0.0576, 0.0126, 0.0301, 0.0210, 0.0297, 0.0227,
        0.0423, 0.0792, 0.0255, 0.1487, 0.0209, 0.0296, 0.0792, 0.0303, 0.0881],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,267][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1603e-02, 9.8840e-01, 5.5577e-07, 9.6009e-09, 6.4151e-08, 1.8240e-09,
        4.7705e-09, 5.3170e-09, 1.7101e-08, 5.9106e-08, 1.5198e-08, 1.8414e-07,
        1.3586e-08, 3.7634e-08, 1.0406e-08, 9.8193e-08, 4.8049e-08, 2.5941e-08],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,268][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0225, 0.7691, 0.0374, 0.0451, 0.0070, 0.0043, 0.0078, 0.0062, 0.0056,
        0.0096, 0.0070, 0.0205, 0.0116, 0.0044, 0.0078, 0.0216, 0.0048, 0.0077],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,269][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0304, 0.0466, 0.0578, 0.0493, 0.0523, 0.0542, 0.0561, 0.0589, 0.0461,
        0.0613, 0.0769, 0.0565, 0.0633, 0.0493, 0.0687, 0.0569, 0.0477, 0.0676],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,270][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.9023e-02, 3.7395e-05, 4.4653e-02, 1.4795e-04, 2.8467e-04, 6.5893e-07,
        4.4001e-01, 6.6602e-02, 3.8634e-01, 4.9891e-03, 5.1808e-06, 6.4110e-03,
        5.5066e-05, 4.3181e-04, 7.7020e-03, 7.6408e-03, 1.5663e-02, 6.4731e-06],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,276][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0556, 0.0553, 0.0555, 0.0558, 0.0555, 0.0555, 0.0555, 0.0553, 0.0558,
        0.0557, 0.0554, 0.0556, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,277][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0556, 0.0555, 0.0555, 0.0556, 0.0555, 0.0556, 0.0555, 0.0556, 0.0556,
        0.0556, 0.0556, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,278][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.1150e-02, 8.4031e-02, 5.4612e-04, 2.0679e-01, 6.4349e-04, 5.7698e-03,
        1.1207e-04, 4.8657e-03, 4.7189e-04, 7.8171e-02, 2.1151e-02, 4.6111e-04,
        3.2759e-01, 3.5240e-04, 7.7902e-04, 9.2810e-02, 1.5721e-03, 1.5274e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,279][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0724, 0.0636, 0.0240, 0.0955, 0.0380, 0.0829, 0.0166, 0.0367, 0.0242,
        0.0840, 0.0977, 0.0242, 0.0509, 0.0198, 0.0164, 0.0797, 0.0330, 0.1109,
        0.0297], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,279][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0472, 0.1417, 0.0770, 0.1230, 0.0383, 0.0555, 0.0163, 0.1523, 0.0130,
        0.0198, 0.0606, 0.0036, 0.0544, 0.0250, 0.0419, 0.0140, 0.0554, 0.0589,
        0.0023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,283][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0817, 0.0567, 0.0526, 0.1126, 0.0771, 0.0414, 0.0325, 0.0370, 0.0370,
        0.0502, 0.0750, 0.0745, 0.0490, 0.0341, 0.0297, 0.0404, 0.0378, 0.0435,
        0.0373], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,287][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0389, 0.0523, 0.0326, 0.0648, 0.0520, 0.0390, 0.0245, 0.0339, 0.0553,
        0.0698, 0.0666, 0.0243, 0.1541, 0.0520, 0.0234, 0.0761, 0.0444, 0.0722,
        0.0238], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,288][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.2680, 0.0521, 0.0092, 0.0540, 0.0104, 0.0257, 0.0173, 0.0248, 0.0183,
        0.0371, 0.0747, 0.0217, 0.1375, 0.0172, 0.0252, 0.0754, 0.0261, 0.0848,
        0.0205], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,289][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.0718e-02, 9.7928e-01, 1.6121e-06, 4.3952e-08, 2.5748e-07, 1.0623e-08,
        1.9987e-08, 2.6831e-08, 6.0597e-08, 2.1478e-07, 6.0272e-08, 4.1767e-07,
        5.8165e-08, 1.2493e-07, 3.6266e-08, 3.2417e-07, 1.3994e-07, 1.0814e-07,
        2.2451e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,290][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0092, 0.7654, 0.0261, 0.0903, 0.0058, 0.0048, 0.0206, 0.0125, 0.0040,
        0.0084, 0.0033, 0.0138, 0.0079, 0.0014, 0.0052, 0.0114, 0.0026, 0.0022,
        0.0053], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,292][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0238, 0.0489, 0.0617, 0.0454, 0.0445, 0.0745, 0.0629, 0.0744, 0.0476,
        0.0403, 0.0632, 0.0406, 0.0562, 0.0398, 0.0834, 0.0389, 0.0599, 0.0562,
        0.0377], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,295][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([2.8076e-03, 1.0206e-05, 4.7201e-02, 3.4220e-05, 1.8148e-04, 1.3963e-07,
        4.1688e-01, 5.1463e-02, 4.5051e-01, 2.3940e-03, 8.7377e-07, 4.4910e-03,
        3.2838e-05, 3.1040e-04, 6.5468e-03, 3.9294e-03, 1.3013e-02, 1.5645e-06,
        1.8530e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,298][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0526, 0.0523, 0.0526, 0.0528, 0.0526, 0.0526, 0.0526, 0.0524, 0.0529,
        0.0527, 0.0525, 0.0527, 0.0526, 0.0526, 0.0527, 0.0527, 0.0527, 0.0525,
        0.0528], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,299][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0527, 0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526,
        0.0526, 0.0526, 0.0526, 0.0526, 0.0527, 0.0526, 0.0527, 0.0526, 0.0526,
        0.0526], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,299][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([2.7948e-02, 9.0621e-02, 1.0468e-04, 2.3699e-01, 1.8673e-04, 3.5686e-03,
        3.0765e-05, 1.0022e-03, 9.7596e-05, 5.6598e-02, 4.6078e-03, 2.3867e-04,
        4.9221e-01, 1.0807e-04, 2.0433e-04, 7.8826e-02, 2.6830e-04, 3.2990e-03,
        3.0939e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,300][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0825, 0.0652, 0.0285, 0.0847, 0.0426, 0.0686, 0.0175, 0.0355, 0.0256,
        0.0673, 0.0829, 0.0216, 0.0469, 0.0235, 0.0182, 0.0629, 0.0307, 0.0862,
        0.0239, 0.0853], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,303][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1224, 0.1979, 0.1600, 0.1227, 0.0416, 0.1208, 0.0110, 0.0533, 0.0037,
        0.0020, 0.0417, 0.0059, 0.0022, 0.0150, 0.0292, 0.0008, 0.0282, 0.0257,
        0.0149, 0.0008], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,308][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0712, 0.0521, 0.0475, 0.1016, 0.0700, 0.0397, 0.0314, 0.0361, 0.0364,
        0.0492, 0.0730, 0.0736, 0.0475, 0.0331, 0.0292, 0.0397, 0.0374, 0.0430,
        0.0378, 0.0505], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,309][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0351, 0.0428, 0.0307, 0.0546, 0.0478, 0.0371, 0.0244, 0.0327, 0.0571,
        0.0663, 0.0621, 0.0265, 0.1294, 0.0483, 0.0235, 0.0732, 0.0414, 0.0671,
        0.0249, 0.0751], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,310][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1890, 0.0564, 0.0106, 0.0525, 0.0117, 0.0275, 0.0193, 0.0271, 0.0207,
        0.0380, 0.0696, 0.0234, 0.1272, 0.0188, 0.0265, 0.0689, 0.0273, 0.0761,
        0.0213, 0.0883], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,311][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4683e-03, 9.9553e-01, 1.2388e-06, 4.5985e-08, 3.0299e-07, 1.0510e-08,
        2.7724e-08, 2.2286e-08, 6.2196e-08, 2.8430e-07, 6.0864e-08, 4.1969e-07,
        5.5587e-08, 1.4897e-07, 4.3113e-08, 4.2225e-07, 1.3172e-07, 1.0237e-07,
        2.1959e-07, 7.7323e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,312][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0125, 0.6512, 0.0250, 0.0799, 0.0065, 0.0082, 0.0132, 0.0111, 0.0108,
        0.0141, 0.0096, 0.0359, 0.0177, 0.0042, 0.0130, 0.0251, 0.0086, 0.0102,
        0.0195, 0.0235], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,316][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0236, 0.0425, 0.0528, 0.0449, 0.0428, 0.0499, 0.0521, 0.0504, 0.0406,
        0.0580, 0.0675, 0.0481, 0.0580, 0.0407, 0.0584, 0.0538, 0.0468, 0.0599,
        0.0568, 0.0524], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,319][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.2120e-03, 1.7702e-05, 4.2318e-02, 4.8445e-05, 1.8109e-04, 3.0934e-07,
        4.0764e-01, 6.2631e-02, 4.3898e-01, 3.3439e-03, 2.1078e-06, 4.4068e-03,
        3.2445e-05, 2.8949e-04, 6.2449e-03, 5.3117e-03, 1.2919e-02, 4.2373e-06,
        3.7911e-04, 6.0401e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,320][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0500, 0.0497, 0.0499, 0.0502, 0.0500, 0.0500, 0.0500, 0.0498, 0.0503,
        0.0501, 0.0499, 0.0501, 0.0499, 0.0500, 0.0501, 0.0501, 0.0500, 0.0499,
        0.0502, 0.0498], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,321][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,322][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4468e-02, 5.4497e-02, 1.9192e-04, 1.6007e-01, 2.1249e-04, 4.8840e-03,
        6.3136e-05, 3.8920e-03, 2.2753e-04, 1.4036e-01, 6.0446e-03, 2.4565e-04,
        2.1266e-01, 1.3204e-04, 4.4215e-04, 1.7041e-01, 7.2453e-04, 8.1494e-03,
        4.0189e-04, 2.2191e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,325][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:42,329][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16757],
        [ 4168],
        [  114],
        [ 9876],
        [18147],
        [13119],
        [ 7410],
        [ 6052],
        [25368],
        [13096],
        [24967],
        [ 4043],
        [13922],
        [21586],
        [20271],
        [16729],
        [13150],
        [27723],
        [20493],
        [18439]], device='cuda:0')
[2024-07-24 10:18:42,332][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14211],
        [ 4804],
        [    2],
        [12025],
        [13753],
        [11795],
        [ 8750],
        [ 3599],
        [33357],
        [ 7445],
        [21308],
        [ 1226],
        [ 4400],
        [16816],
        [20752],
        [ 7818],
        [10413],
        [22195],
        [16273],
        [11125]], device='cuda:0')
[2024-07-24 10:18:42,333][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20941],
        [23263],
        [27000],
        [26150],
        [25656],
        [24909],
        [25377],
        [25008],
        [24537],
        [24494],
        [24521],
        [24691],
        [24249],
        [24185],
        [24394],
        [24067],
        [24461],
        [24317],
        [24152],
        [23749]], device='cuda:0')
[2024-07-24 10:18:42,335][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[31041],
        [31264],
        [27625],
        [26500],
        [32016],
        [32888],
        [36831],
        [29151],
        [33373],
        [31767],
        [30750],
        [34103],
        [30061],
        [31859],
        [31400],
        [30829],
        [32120],
        [30969],
        [33354],
        [31242]], device='cuda:0')
[2024-07-24 10:18:42,337][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2809],
        [2802],
        [2189],
        [1042],
        [ 843],
        [ 774],
        [1009],
        [1530],
        [2021],
        [2880],
        [3426],
        [3432],
        [3987],
        [3608],
        [3373],
        [4449],
        [3915],
        [5708],
        [5298],
        [6658]], device='cuda:0')
[2024-07-24 10:18:42,341][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[41377],
        [ 1561],
        [ 1302],
        [ 1624],
        [ 1371],
        [  913],
        [ 1028],
        [ 1026],
        [ 1005],
        [ 1100],
        [ 1137],
        [ 1057],
        [ 1054],
        [ 1032],
        [  978],
        [ 1037],
        [  968],
        [  992],
        [  921],
        [  969]], device='cuda:0')
[2024-07-24 10:18:42,344][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11374],
        [16800],
        [16384],
        [16949],
        [16694],
        [16825],
        [14965],
        [14592],
        [14085],
        [14698],
        [14936],
        [15310],
        [16002],
        [15897],
        [15000],
        [15415],
        [15036],
        [15248],
        [15607],
        [15782]], device='cuda:0')
[2024-07-24 10:18:42,345][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 7790],
        [ 2885],
        [46079],
        [ 5381],
        [48603],
        [35958],
        [10550],
        [22972],
        [17707],
        [34885],
        [26394],
        [43748],
        [48591],
        [49421],
        [18890],
        [32541],
        [27751],
        [48316],
        [28568],
        [32363]], device='cuda:0')
[2024-07-24 10:18:42,347][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23147],
        [23140],
        [23227],
        [23202],
        [23223],
        [23223],
        [23240],
        [23205],
        [23197],
        [23181],
        [23197],
        [23196],
        [23197],
        [23200],
        [23196],
        [23195],
        [23198],
        [23190],
        [23190],
        [23188]], device='cuda:0')
[2024-07-24 10:18:42,349][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35782],
        [26180],
        [ 7471],
        [ 8943],
        [10405],
        [11585],
        [13140],
        [14234],
        [13495],
        [15262],
        [16288],
        [15824],
        [17067],
        [16331],
        [16412],
        [17418],
        [17006],
        [17995],
        [16644],
        [18937]], device='cuda:0')
[2024-07-24 10:18:42,353][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15154],
        [30586],
        [35616],
        [31675],
        [26515],
        [22456],
        [18307],
        [21400],
        [21830],
        [23795],
        [26084],
        [25934],
        [28918],
        [24612],
        [24555],
        [25221],
        [24455],
        [24021],
        [24485],
        [24434]], device='cuda:0')
[2024-07-24 10:18:42,356][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[48920],
        [13455],
        [16967],
        [12425],
        [ 6812],
        [ 9585],
        [ 5576],
        [ 8821],
        [ 5942],
        [11150],
        [12990],
        [ 5267],
        [15930],
        [ 5410],
        [ 5855],
        [12192],
        [ 7733],
        [11874],
        [ 6195],
        [11637]], device='cuda:0')
[2024-07-24 10:18:42,357][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27717],
        [31165],
        [37699],
        [42857],
        [43761],
        [44049],
        [44289],
        [43763],
        [44022],
        [45181],
        [45887],
        [45932],
        [45928],
        [46132],
        [45919],
        [46382],
        [46436],
        [46207],
        [46447],
        [46590]], device='cuda:0')
[2024-07-24 10:18:42,359][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14914],
        [15251],
        [34788],
        [19513],
        [27846],
        [37353],
        [33843],
        [41262],
        [29228],
        [32011],
        [37526],
        [38338],
        [27052],
        [37870],
        [43336],
        [30812],
        [25448],
        [28228],
        [25202],
        [31234]], device='cuda:0')
[2024-07-24 10:18:42,361][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14819],
        [ 2842],
        [ 1397],
        [ 6531],
        [35421],
        [22641],
        [ 8569],
        [ 9459],
        [38678],
        [ 7903],
        [14490],
        [ 9137],
        [12293],
        [28935],
        [25289],
        [ 7959],
        [18010],
        [13237],
        [33685],
        [ 7144]], device='cuda:0')
[2024-07-24 10:18:42,364][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[33347],
        [32161],
        [30586],
        [28121],
        [28201],
        [28423],
        [28321],
        [27993],
        [28376],
        [28347],
        [28459],
        [28290],
        [27992],
        [28135],
        [28104],
        [27909],
        [27993],
        [27618],
        [27163],
        [27172]], device='cuda:0')
[2024-07-24 10:18:42,368][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12688],
        [19673],
        [27945],
        [24170],
        [26909],
        [28248],
        [24339],
        [26810],
        [25346],
        [20760],
        [21246],
        [18704],
        [21357],
        [20438],
        [17471],
        [19066],
        [14145],
        [14940],
        [18512],
        [17186]], device='cuda:0')
[2024-07-24 10:18:42,369][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14212],
        [14061],
        [13193],
        [12791],
        [12198],
        [11673],
        [11447],
        [11234],
        [11038],
        [10676],
        [10151],
        [ 9802],
        [ 9348],
        [ 8879],
        [ 9033],
        [ 8728],
        [ 8818],
        [ 8225],
        [ 8075],
        [ 7496]], device='cuda:0')
[2024-07-24 10:18:42,371][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17359],
        [ 9286],
        [ 7898],
        [ 6481],
        [ 6618],
        [ 5876],
        [ 6340],
        [ 6777],
        [ 6439],
        [ 6390],
        [ 6141],
        [ 6258],
        [ 6788],
        [ 6846],
        [ 6776],
        [ 6697],
        [ 6492],
        [ 6488],
        [ 6541],
        [ 6444]], device='cuda:0')
[2024-07-24 10:18:42,373][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[6668],
        [3182],
        [4018],
        [2205],
        [2825],
        [2252],
        [2316],
        [2095],
        [1988],
        [1656],
        [1317],
        [1487],
        [1027],
        [1228],
        [1189],
        [1012],
        [1105],
        [ 945],
        [1062],
        [ 920]], device='cuda:0')
[2024-07-24 10:18:42,376][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18874],
        [36595],
        [36510],
        [36594],
        [36571],
        [36583],
        [36584],
        [36570],
        [36536],
        [36570],
        [36554],
        [36563],
        [36555],
        [36555],
        [36500],
        [36559],
        [36509],
        [36509],
        [36433],
        [36562]], device='cuda:0')
[2024-07-24 10:18:42,380][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30263],
        [38978],
        [41160],
        [34222],
        [40968],
        [37433],
        [41077],
        [40533],
        [38870],
        [40824],
        [40943],
        [43095],
        [43557],
        [43657],
        [42106],
        [43553],
        [42256],
        [43774],
        [43490],
        [44577]], device='cuda:0')
[2024-07-24 10:18:42,381][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7238],
        [10889],
        [17501],
        [14998],
        [15894],
        [15982],
        [14912],
        [15115],
        [14946],
        [12403],
        [11677],
        [12340],
        [11216],
        [12222],
        [11989],
        [10862],
        [11100],
        [10712],
        [11526],
        [10684]], device='cuda:0')
[2024-07-24 10:18:42,383][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 3839],
        [ 3839],
        [22968],
        [18667],
        [23504],
        [23105],
        [31545],
        [32489],
        [23351],
        [23970],
        [24869],
        [23005],
        [28984],
        [24956],
        [24795],
        [23910],
        [23206],
        [24016],
        [24203],
        [23932]], device='cuda:0')
[2024-07-24 10:18:42,385][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14158],
        [14160],
        [14163],
        [14161],
        [14161],
        [14161],
        [14161],
        [14161],
        [14165],
        [14164],
        [14163],
        [14159],
        [14162],
        [14161],
        [14161],
        [14161],
        [14164],
        [14164],
        [14164],
        [14164]], device='cuda:0')
[2024-07-24 10:18:42,388][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23366],
        [23365],
        [23362],
        [23361],
        [23360],
        [23361],
        [23361],
        [23363],
        [23362],
        [23361],
        [23361],
        [23362],
        [23361],
        [23357],
        [23356],
        [23356],
        [23357],
        [23357],
        [23358],
        [23359]], device='cuda:0')
[2024-07-24 10:18:42,391][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8027],
        [13100],
        [11292],
        [12432],
        [11392],
        [10790],
        [12330],
        [11206],
        [11945],
        [11242],
        [10383],
        [11771],
        [11786],
        [12552],
        [12632],
        [11202],
        [11601],
        [ 9934],
        [12494],
        [10401]], device='cuda:0')
[2024-07-24 10:18:42,393][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[39719],
        [40899],
        [35912],
        [40443],
        [37029],
        [39341],
        [39726],
        [40054],
        [40682],
        [41502],
        [42368],
        [42193],
        [43130],
        [42779],
        [43501],
        [43378],
        [43886],
        [44124],
        [43655],
        [43898]], device='cuda:0')
[2024-07-24 10:18:42,395][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36409],
        [40991],
        [38897],
        [29923],
        [ 7511],
        [10417],
        [19373],
        [16773],
        [ 3791],
        [26784],
        [21121],
        [22935],
        [16025],
        [ 5120],
        [ 8124],
        [27112],
        [16057],
        [22157],
        [ 6770],
        [30029]], device='cuda:0')
[2024-07-24 10:18:42,397][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274],
        [31274]], device='cuda:0')
[2024-07-24 10:18:42,431][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:42,432][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,432][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,433][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,435][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,435][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,436][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,437][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,437][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,438][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,439][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,439][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,440][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,441][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6142, 0.3858], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,441][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6045, 0.3955], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,442][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4621, 0.5379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,444][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3521, 0.6479], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,449][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5429, 0.4571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,449][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1680, 0.8320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,450][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3122, 0.6878], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,451][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5332, 0.4668], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,451][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5248, 0.4752], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,452][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4741, 0.5259], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,454][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3383, 0.6617], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,455][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7033, 0.2967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,457][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.4362, 0.4605, 0.1033], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,459][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.1880, 0.3068, 0.5053], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,460][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1416, 0.2348, 0.6236], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,462][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0829, 0.1962, 0.7209], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,464][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.3439, 0.2935, 0.3627], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,465][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0732, 0.8311, 0.0958], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,467][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0907, 0.2798, 0.6295], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,468][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.3736, 0.3171, 0.3093], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,468][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.3176, 0.5041, 0.1784], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,469][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.2620, 0.4356, 0.3024], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,470][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.2131, 0.5566, 0.2303], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,471][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.3889, 0.1683, 0.4428], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,472][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1972, 0.2458, 0.3572, 0.1998], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,473][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1981, 0.2737, 0.4789, 0.0494], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,475][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0404, 0.0715, 0.7248, 0.1634], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,477][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0641, 0.1431, 0.5448, 0.2480], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,478][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2578, 0.2199, 0.2738, 0.2485], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,480][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0752, 0.4799, 0.3125, 0.1325], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,482][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1136, 0.2489, 0.4273, 0.2102], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,484][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2860, 0.2394, 0.2320, 0.2426], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,485][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1648, 0.2623, 0.2620, 0.3110], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,486][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1642, 0.2781, 0.3439, 0.2138], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,486][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0356, 0.1590, 0.0433, 0.7621], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,487][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2979, 0.1609, 0.2667, 0.2746], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,488][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.1505, 0.1283, 0.3437, 0.2891, 0.0884], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,489][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.1914, 0.3110, 0.2563, 0.0732, 0.1681], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,491][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0314, 0.0728, 0.4050, 0.3006, 0.1902], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,493][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0399, 0.0867, 0.3379, 0.1534, 0.3822], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,494][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.1940, 0.1672, 0.2064, 0.1894, 0.2430], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,496][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0555, 0.4357, 0.1609, 0.3047, 0.0432], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,498][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0650, 0.1564, 0.3268, 0.1441, 0.3078], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,500][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.2338, 0.1888, 0.1852, 0.1952, 0.1970], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,502][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.1567, 0.2538, 0.0961, 0.3701, 0.1233], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,503][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.1396, 0.2304, 0.2535, 0.2431, 0.1334], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,504][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0467, 0.1731, 0.1082, 0.5495, 0.1225], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,505][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.2592, 0.0914, 0.3285, 0.1421, 0.1788], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,505][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1777, 0.1592, 0.2096, 0.2514, 0.1641, 0.0380], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,506][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1358, 0.1485, 0.2984, 0.0578, 0.1786, 0.1810], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,507][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0304, 0.0597, 0.2098, 0.2151, 0.3990, 0.0861], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,509][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0259, 0.0584, 0.2404, 0.1068, 0.2709, 0.2977], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,511][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.1572, 0.1344, 0.1660, 0.1514, 0.1956, 0.1953], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,513][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0435, 0.3366, 0.1712, 0.2039, 0.1693, 0.0756], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,514][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0516, 0.1220, 0.2391, 0.1103, 0.2325, 0.2444], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,516][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1987, 0.1577, 0.1541, 0.1615, 0.1629, 0.1650], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,518][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.1173, 0.1772, 0.1004, 0.2415, 0.1150, 0.2486], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,520][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1347, 0.2208, 0.1916, 0.2065, 0.1512, 0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,521][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0257, 0.1213, 0.0487, 0.5373, 0.0487, 0.2183], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,522][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.2158, 0.0961, 0.2311, 0.1719, 0.1523, 0.1328], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,523][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0959, 0.1018, 0.1334, 0.2142, 0.2591, 0.1705, 0.0251],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,523][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1470, 0.1292, 0.2035, 0.0394, 0.0695, 0.1458, 0.2655],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,524][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0142, 0.0288, 0.1762, 0.1351, 0.2527, 0.2967, 0.0964],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,525][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0246, 0.0465, 0.1645, 0.0790, 0.1739, 0.2028, 0.3087],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,527][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.1236, 0.1054, 0.1288, 0.1209, 0.1529, 0.1523, 0.2160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,529][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0310, 0.2848, 0.1149, 0.2119, 0.0691, 0.2583, 0.0299],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,531][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0352, 0.0821, 0.1914, 0.0697, 0.1763, 0.1868, 0.2583],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,533][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1582, 0.1401, 0.1369, 0.1438, 0.1452, 0.1449, 0.1308],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,535][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0514, 0.0851, 0.0566, 0.1512, 0.1178, 0.4090, 0.1288],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,536][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1012, 0.1564, 0.1990, 0.1766, 0.1673, 0.1649, 0.0347],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,538][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0466, 0.0959, 0.0378, 0.3745, 0.0528, 0.2194, 0.1729],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,539][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.1741, 0.0843, 0.1773, 0.1382, 0.1256, 0.1467, 0.1538],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,540][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.1294, 0.1272, 0.0675, 0.2384, 0.2085, 0.0826, 0.0838, 0.0626],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,541][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.1512, 0.0800, 0.1136, 0.0349, 0.0819, 0.0824, 0.3260, 0.1298],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,542][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0163, 0.0328, 0.1076, 0.1159, 0.1419, 0.2132, 0.2939, 0.0783],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,542][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0203, 0.0385, 0.1344, 0.0672, 0.1421, 0.1646, 0.2615, 0.1714],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,544][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.1016, 0.0863, 0.1057, 0.0976, 0.1246, 0.1247, 0.1755, 0.1841],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,546][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0342, 0.2441, 0.1391, 0.1582, 0.1056, 0.2177, 0.0531, 0.0481],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,547][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0338, 0.0763, 0.1525, 0.0685, 0.1489, 0.1780, 0.2187, 0.1233],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,549][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1417, 0.1241, 0.1207, 0.1266, 0.1271, 0.1274, 0.1157, 0.1166],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,550][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0298, 0.0694, 0.0830, 0.1123, 0.0927, 0.2590, 0.2946, 0.0593],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,552][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.1124, 0.1633, 0.1489, 0.1602, 0.1172, 0.1387, 0.0770, 0.0823],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,554][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0456, 0.0536, 0.0366, 0.2392, 0.0405, 0.1269, 0.1923, 0.2653],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,556][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.1639, 0.0630, 0.1595, 0.1111, 0.1013, 0.1216, 0.1258, 0.1538],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,557][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.1046, 0.1037, 0.0960, 0.2617, 0.0847, 0.0607, 0.0687, 0.1995, 0.0205],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,558][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0663, 0.1312, 0.1089, 0.0317, 0.0613, 0.0874, 0.2696, 0.1791, 0.0646],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,559][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0106, 0.0204, 0.0943, 0.0862, 0.0850, 0.2104, 0.1823, 0.2919, 0.0189],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,560][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0197, 0.0335, 0.1168, 0.0579, 0.1227, 0.1430, 0.2219, 0.1440, 0.1406],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,560][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0852, 0.0723, 0.0886, 0.0826, 0.1054, 0.1042, 0.1487, 0.1546, 0.1584],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,562][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0150, 0.1994, 0.0464, 0.1520, 0.0361, 0.1376, 0.1472, 0.2608, 0.0054],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,564][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0297, 0.0639, 0.1317, 0.0568, 0.1186, 0.1619, 0.2151, 0.1185, 0.1037],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,565][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.1269, 0.1088, 0.1085, 0.1143, 0.1161, 0.1162, 0.1017, 0.1036, 0.1039],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,567][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.0324, 0.0651, 0.0369, 0.1056, 0.0561, 0.3382, 0.1589, 0.1767, 0.0301],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,568][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0890, 0.1525, 0.1307, 0.1451, 0.1288, 0.1249, 0.0631, 0.1167, 0.0491],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,571][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0185, 0.0782, 0.0289, 0.2951, 0.0344, 0.1439, 0.1337, 0.1835, 0.0839],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,573][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.1176, 0.0664, 0.1206, 0.1148, 0.0819, 0.0929, 0.1202, 0.2129, 0.0725],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,574][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0828, 0.0707, 0.1200, 0.1616, 0.0710, 0.1009, 0.1068, 0.2057, 0.0304,
        0.0501], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,575][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0597, 0.0792, 0.1507, 0.0234, 0.0841, 0.1052, 0.3270, 0.0912, 0.0530,
        0.0266], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,576][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0106, 0.0176, 0.0752, 0.0871, 0.1110, 0.2053, 0.2031, 0.1853, 0.0902,
        0.0146], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,577][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0183, 0.0310, 0.1070, 0.0536, 0.1136, 0.1292, 0.1984, 0.1344, 0.1312,
        0.0832], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,578][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0717, 0.0615, 0.0753, 0.0710, 0.0900, 0.0890, 0.1274, 0.1322, 0.1364,
        0.1455], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,578][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0212, 0.1462, 0.0793, 0.1686, 0.0623, 0.2372, 0.1417, 0.1047, 0.0139,
        0.0249], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,580][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0341, 0.0676, 0.1168, 0.0694, 0.1167, 0.1435, 0.1840, 0.1178, 0.0939,
        0.0561], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,581][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1182, 0.0981, 0.0970, 0.1021, 0.1035, 0.1036, 0.0919, 0.0935, 0.0934,
        0.0987], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,583][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0333, 0.0612, 0.0440, 0.0954, 0.0823, 0.2248, 0.2021, 0.1221, 0.0990,
        0.0357], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,585][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0936, 0.1201, 0.1385, 0.1097, 0.1095, 0.0989, 0.0844, 0.1106, 0.0781,
        0.0566], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,586][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0214, 0.0733, 0.0268, 0.2391, 0.0268, 0.1067, 0.1224, 0.1771, 0.0715,
        0.1350], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,589][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1102, 0.0636, 0.0916, 0.1302, 0.0686, 0.0988, 0.0902, 0.2092, 0.0618,
        0.0760], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,590][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0688, 0.0651, 0.1445, 0.1467, 0.0770, 0.0558, 0.0596, 0.1532, 0.0658,
        0.1203, 0.0431], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,592][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0502, 0.0596, 0.1627, 0.0193, 0.0884, 0.0994, 0.3066, 0.1028, 0.0783,
        0.0152, 0.0177], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,593][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0111, 0.0179, 0.1001, 0.1006, 0.0929, 0.1767, 0.2309, 0.1323, 0.0602,
        0.0621, 0.0153], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,594][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0173, 0.0280, 0.0989, 0.0515, 0.1052, 0.1232, 0.1823, 0.1264, 0.1226,
        0.0782, 0.0664], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,595][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0617, 0.0535, 0.0657, 0.0617, 0.0789, 0.0781, 0.1115, 0.1163, 0.1193,
        0.1275, 0.1260], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,595][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0170, 0.1474, 0.0689, 0.1384, 0.0759, 0.1636, 0.1406, 0.1571, 0.0173,
        0.0577, 0.0161], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,596][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0302, 0.0631, 0.1149, 0.0600, 0.1144, 0.1319, 0.1635, 0.1120, 0.0987,
        0.0504, 0.0610], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,598][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1066, 0.0902, 0.0888, 0.0936, 0.0946, 0.0948, 0.0844, 0.0856, 0.0854,
        0.0903, 0.0859], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,600][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0356, 0.0632, 0.0629, 0.1158, 0.0627, 0.1685, 0.1649, 0.1370, 0.0678,
        0.0893, 0.0323], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,602][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0762, 0.1213, 0.1143, 0.1045, 0.0986, 0.0816, 0.0645, 0.1149, 0.0687,
        0.0820, 0.0732], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,604][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0209, 0.0620, 0.0210, 0.2105, 0.0195, 0.0961, 0.1014, 0.1394, 0.0583,
        0.1066, 0.1644], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,606][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1073, 0.0608, 0.0826, 0.1350, 0.0595, 0.0855, 0.0779, 0.1834, 0.0510,
        0.0813, 0.0758], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,608][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0681, 0.0725, 0.0712, 0.1093, 0.1541, 0.1006, 0.0814, 0.0912, 0.0530,
        0.1143, 0.0652, 0.0193], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,610][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0496, 0.0625, 0.1105, 0.0161, 0.0667, 0.0924, 0.2041, 0.1512, 0.0780,
        0.0135, 0.0241, 0.1313], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,611][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0077, 0.0135, 0.0872, 0.0576, 0.1702, 0.1318, 0.1468, 0.1273, 0.0450,
        0.0398, 0.0646, 0.1085], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,612][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0165, 0.0263, 0.0866, 0.0456, 0.0891, 0.1084, 0.1506, 0.1013, 0.0989,
        0.0655, 0.0564, 0.1548], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,612][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0523, 0.0461, 0.0567, 0.0532, 0.0682, 0.0672, 0.0970, 0.1007, 0.1044,
        0.1116, 0.1103, 0.1322], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,613][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0202, 0.1835, 0.0609, 0.1165, 0.0588, 0.1248, 0.0847, 0.1474, 0.0214,
        0.0952, 0.0455, 0.0411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,614][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0207, 0.0481, 0.1058, 0.0429, 0.1142, 0.1178, 0.1733, 0.0921, 0.0898,
        0.0356, 0.0491, 0.1105], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,616][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.0964, 0.0829, 0.0826, 0.0874, 0.0884, 0.0882, 0.0779, 0.0788, 0.0788,
        0.0839, 0.0797, 0.0751], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,618][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.0328, 0.0621, 0.0462, 0.0859, 0.0401, 0.1401, 0.1662, 0.1333, 0.0802,
        0.0777, 0.0569, 0.0785], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,620][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0484, 0.0992, 0.1209, 0.1060, 0.0961, 0.0839, 0.0596, 0.0970, 0.0655,
        0.0550, 0.1172, 0.0511], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,622][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.0218, 0.0657, 0.0281, 0.1498, 0.0279, 0.1051, 0.0842, 0.1223, 0.0720,
        0.1085, 0.1335, 0.0811], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,624][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.1148, 0.0502, 0.1089, 0.0930, 0.0771, 0.0765, 0.1045, 0.1278, 0.0522,
        0.0509, 0.0789, 0.0653], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,626][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0898, 0.0541, 0.0635, 0.0967, 0.0540, 0.0881, 0.0594, 0.1372, 0.0734,
        0.0916, 0.1073, 0.0350, 0.0499], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,628][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0357, 0.0505, 0.0840, 0.0147, 0.0650, 0.0594, 0.2279, 0.0903, 0.0398,
        0.0183, 0.0225, 0.1209, 0.1709], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,629][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0053, 0.0075, 0.0698, 0.0416, 0.1057, 0.1547, 0.2024, 0.0895, 0.0568,
        0.0324, 0.0349, 0.1804, 0.0191], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,630][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0153, 0.0236, 0.0777, 0.0431, 0.0824, 0.1009, 0.1427, 0.0968, 0.0924,
        0.0603, 0.0518, 0.1457, 0.0673], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,631][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0478, 0.0418, 0.0513, 0.0480, 0.0615, 0.0612, 0.0870, 0.0910, 0.0934,
        0.1000, 0.0989, 0.1173, 0.1009], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,631][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0220, 0.1434, 0.0789, 0.1083, 0.0513, 0.1497, 0.0760, 0.1107, 0.0161,
        0.0742, 0.0368, 0.0864, 0.0461], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,632][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0233, 0.0527, 0.0904, 0.0479, 0.1014, 0.1023, 0.1286, 0.0869, 0.0711,
        0.0415, 0.0557, 0.1095, 0.0887], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,634][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0911, 0.0787, 0.0768, 0.0809, 0.0813, 0.0816, 0.0731, 0.0738, 0.0731,
        0.0773, 0.0732, 0.0689, 0.0702], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,636][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0443, 0.0556, 0.0491, 0.0808, 0.0554, 0.1337, 0.1298, 0.0950, 0.0645,
        0.0822, 0.0576, 0.1117, 0.0401], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,638][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0638, 0.0853, 0.0867, 0.0967, 0.0765, 0.0781, 0.0537, 0.0881, 0.0593,
        0.0687, 0.0933, 0.0681, 0.0816], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,640][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0277, 0.0507, 0.0158, 0.1952, 0.0161, 0.0616, 0.0751, 0.1235, 0.0532,
        0.0856, 0.1249, 0.0320, 0.1385], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,642][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1043, 0.0403, 0.0855, 0.1129, 0.0565, 0.0684, 0.0756, 0.1561, 0.0484,
        0.0719, 0.0876, 0.0587, 0.0338], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,644][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0550, 0.0428, 0.1296, 0.0971, 0.0308, 0.0638, 0.0743, 0.1488, 0.0781,
        0.0802, 0.0573, 0.0453, 0.0711, 0.0256], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,646][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0466, 0.0662, 0.0631, 0.0177, 0.0395, 0.0735, 0.1879, 0.0881, 0.0465,
        0.0128, 0.0208, 0.0766, 0.2012, 0.0593], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,647][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0049, 0.0135, 0.0610, 0.0570, 0.0343, 0.1192, 0.1596, 0.1278, 0.0265,
        0.0336, 0.0530, 0.2394, 0.0301, 0.0399], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,648][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0116, 0.0192, 0.0669, 0.0360, 0.0742, 0.0959, 0.1386, 0.0894, 0.0862,
        0.0555, 0.0473, 0.1495, 0.0655, 0.0641], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,649][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0419, 0.0368, 0.0450, 0.0428, 0.0544, 0.0538, 0.0771, 0.0803, 0.0834,
        0.0894, 0.0880, 0.1052, 0.0896, 0.1124], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,649][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0169, 0.1372, 0.0496, 0.1034, 0.0129, 0.1114, 0.1031, 0.1859, 0.0136,
        0.0571, 0.0444, 0.0941, 0.0612, 0.0092], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,650][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0177, 0.0424, 0.0894, 0.0400, 0.0851, 0.0985, 0.1467, 0.0771, 0.0736,
        0.0303, 0.0413, 0.1011, 0.0682, 0.0887], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,653][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0795, 0.0731, 0.0730, 0.0772, 0.0782, 0.0782, 0.0682, 0.0688, 0.0683,
        0.0728, 0.0692, 0.0650, 0.0671, 0.0615], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,655][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0325, 0.0499, 0.0177, 0.0709, 0.0246, 0.1454, 0.2141, 0.1531, 0.0296,
        0.0781, 0.0468, 0.0797, 0.0368, 0.0208], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,657][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0501, 0.0825, 0.0941, 0.0897, 0.0456, 0.0755, 0.0511, 0.0824, 0.0755,
        0.0632, 0.1001, 0.0613, 0.0911, 0.0377], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,659][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0120, 0.0649, 0.0255, 0.1575, 0.0274, 0.1034, 0.0765, 0.0803, 0.0488,
        0.0985, 0.1530, 0.0544, 0.0746, 0.0234], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,661][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0934, 0.0349, 0.1172, 0.0508, 0.0650, 0.0806, 0.1294, 0.0839, 0.0507,
        0.0367, 0.0540, 0.0895, 0.0285, 0.0855], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:42,663][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0450, 0.0403, 0.1267, 0.0937, 0.0872, 0.0504, 0.0532, 0.1168, 0.0552,
        0.0655, 0.0322, 0.0895, 0.0751, 0.0636, 0.0058], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,665][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0599, 0.0395, 0.0611, 0.0196, 0.0425, 0.0456, 0.1031, 0.0923, 0.0403,
        0.0102, 0.0103, 0.0520, 0.1206, 0.0573, 0.2458], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,667][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0065, 0.0139, 0.0540, 0.0641, 0.1190, 0.1134, 0.0959, 0.0718, 0.0323,
        0.0193, 0.0409, 0.1416, 0.0458, 0.1436, 0.0378], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,669][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0118, 0.0189, 0.0648, 0.0340, 0.0686, 0.0799, 0.1244, 0.0797, 0.0786,
        0.0520, 0.0431, 0.1323, 0.0596, 0.0618, 0.0904], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,671][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0378, 0.0327, 0.0402, 0.0378, 0.0484, 0.0477, 0.0688, 0.0716, 0.0739,
        0.0793, 0.0784, 0.0937, 0.0808, 0.1004, 0.1085], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,671][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0156, 0.1500, 0.0611, 0.0943, 0.0540, 0.0953, 0.0582, 0.1004, 0.0162,
        0.0546, 0.0466, 0.1337, 0.0595, 0.0342, 0.0263], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,672][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0162, 0.0364, 0.0836, 0.0316, 0.0794, 0.0913, 0.1326, 0.0686, 0.0651,
        0.0300, 0.0368, 0.0896, 0.0580, 0.0827, 0.0980], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,673][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0776, 0.0687, 0.0686, 0.0724, 0.0732, 0.0733, 0.0637, 0.0643, 0.0641,
        0.0680, 0.0646, 0.0607, 0.0624, 0.0575, 0.0608], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,674][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0273, 0.0519, 0.0355, 0.0723, 0.0486, 0.1721, 0.1481, 0.0878, 0.0342,
        0.0755, 0.0424, 0.0749, 0.0446, 0.0383, 0.0466], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,676][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0421, 0.0731, 0.1025, 0.0748, 0.0769, 0.0544, 0.0325, 0.0736, 0.0565,
        0.0442, 0.0917, 0.0666, 0.0924, 0.0697, 0.0490], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,678][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0095, 0.0800, 0.0221, 0.2192, 0.0232, 0.1102, 0.0538, 0.0760, 0.0473,
        0.0775, 0.1099, 0.0356, 0.0932, 0.0153, 0.0271], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,680][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0880, 0.0403, 0.0912, 0.0686, 0.0541, 0.0599, 0.0941, 0.1067, 0.0493,
        0.0454, 0.0665, 0.0624, 0.0278, 0.0657, 0.0799], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:42,682][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0547, 0.0471, 0.0864, 0.1091, 0.0505, 0.0709, 0.0840, 0.1395, 0.0213,
        0.0324, 0.0478, 0.0974, 0.0667, 0.0464, 0.0172, 0.0286],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,684][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0260, 0.0322, 0.0645, 0.0094, 0.0378, 0.0451, 0.1498, 0.0392, 0.0233,
        0.0106, 0.0132, 0.0481, 0.1109, 0.0644, 0.3120, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,686][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0062, 0.0110, 0.0465, 0.0521, 0.0696, 0.1217, 0.1236, 0.1146, 0.0564,
        0.0079, 0.0332, 0.1482, 0.0223, 0.0881, 0.0891, 0.0096],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,688][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0114, 0.0177, 0.0611, 0.0321, 0.0644, 0.0728, 0.1138, 0.0774, 0.0757,
        0.0484, 0.0411, 0.1221, 0.0569, 0.0626, 0.0888, 0.0537],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,689][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0338, 0.0293, 0.0359, 0.0341, 0.0432, 0.0427, 0.0615, 0.0640, 0.0662,
        0.0709, 0.0700, 0.0836, 0.0718, 0.0892, 0.0967, 0.1071],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,690][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0133, 0.1037, 0.0594, 0.1117, 0.0428, 0.1612, 0.0971, 0.0739, 0.0095,
        0.0175, 0.0338, 0.1145, 0.0520, 0.0287, 0.0671, 0.0137],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,691][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0206, 0.0399, 0.0706, 0.0421, 0.0704, 0.0876, 0.1126, 0.0711, 0.0570,
        0.0339, 0.0446, 0.0860, 0.0659, 0.0695, 0.0946, 0.0335],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,692][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0752, 0.0644, 0.0641, 0.0676, 0.0684, 0.0685, 0.0600, 0.0608, 0.0602,
        0.0639, 0.0607, 0.0568, 0.0586, 0.0538, 0.0571, 0.0601],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,693][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0235, 0.0433, 0.0297, 0.0655, 0.0552, 0.1421, 0.1380, 0.0860, 0.0654,
        0.0238, 0.0341, 0.0784, 0.0363, 0.0441, 0.1113, 0.0232],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,695][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0562, 0.0741, 0.0862, 0.0665, 0.0676, 0.0609, 0.0523, 0.0674, 0.0479,
        0.0337, 0.0830, 0.0622, 0.0769, 0.0616, 0.0719, 0.0316],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,697][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0124, 0.0570, 0.0152, 0.1775, 0.0152, 0.0806, 0.0612, 0.0964, 0.0433,
        0.0844, 0.1094, 0.0381, 0.1185, 0.0114, 0.0277, 0.0516],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,699][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0705, 0.0429, 0.0562, 0.0876, 0.0433, 0.0646, 0.0576, 0.1319, 0.0412,
        0.0519, 0.0704, 0.0467, 0.0320, 0.0613, 0.0966, 0.0454],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:42,700][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0536, 0.0363, 0.0704, 0.0551, 0.0880, 0.0387, 0.0502, 0.0737, 0.0825,
        0.0820, 0.0495, 0.0975, 0.0481, 0.0719, 0.0266, 0.0720, 0.0040],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,703][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0176, 0.0231, 0.0292, 0.0077, 0.0275, 0.0296, 0.1294, 0.0429, 0.0314,
        0.0046, 0.0074, 0.0383, 0.0932, 0.0503, 0.4107, 0.0056, 0.0512],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,704][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0075, 0.0128, 0.0721, 0.0445, 0.0516, 0.0950, 0.1185, 0.0895, 0.0212,
        0.0436, 0.0326, 0.0823, 0.0298, 0.0594, 0.1325, 0.0488, 0.0582],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,706][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0105, 0.0165, 0.0574, 0.0292, 0.0587, 0.0659, 0.1064, 0.0680, 0.0672,
        0.0444, 0.0378, 0.1177, 0.0535, 0.0566, 0.0804, 0.0500, 0.0799],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,707][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0299, 0.0260, 0.0320, 0.0304, 0.0387, 0.0379, 0.0552, 0.0573, 0.0594,
        0.0638, 0.0629, 0.0757, 0.0651, 0.0814, 0.0874, 0.0972, 0.0998],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,708][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0176, 0.1417, 0.0426, 0.0820, 0.0524, 0.0722, 0.0703, 0.1420, 0.0142,
        0.0496, 0.0462, 0.0874, 0.0676, 0.0335, 0.0386, 0.0354, 0.0067],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,709][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0165, 0.0343, 0.0710, 0.0295, 0.0700, 0.0814, 0.1174, 0.0637, 0.0555,
        0.0272, 0.0323, 0.0763, 0.0554, 0.0730, 0.0926, 0.0270, 0.0770],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,710][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0694, 0.0605, 0.0608, 0.0642, 0.0651, 0.0650, 0.0565, 0.0571, 0.0568,
        0.0605, 0.0574, 0.0539, 0.0556, 0.0513, 0.0543, 0.0572, 0.0545],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,712][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0313, 0.0465, 0.0243, 0.0538, 0.0438, 0.1396, 0.1391, 0.0745, 0.0327,
        0.0569, 0.0410, 0.0557, 0.0350, 0.0350, 0.0917, 0.0551, 0.0439],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,713][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0445, 0.0622, 0.0915, 0.0611, 0.0631, 0.0544, 0.0442, 0.0731, 0.0435,
        0.0379, 0.0837, 0.0706, 0.0802, 0.0561, 0.0621, 0.0359, 0.0359],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,715][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0080, 0.0556, 0.0154, 0.1766, 0.0171, 0.0928, 0.0612, 0.0933, 0.0521,
        0.0830, 0.0936, 0.0320, 0.0952, 0.0125, 0.0304, 0.0479, 0.0334],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,717][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0683, 0.0379, 0.0769, 0.0606, 0.0425, 0.0511, 0.0778, 0.1243, 0.0429,
        0.0433, 0.0637, 0.0487, 0.0241, 0.0534, 0.1005, 0.0365, 0.0474],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:42,719][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0480, 0.0469, 0.0633, 0.1111, 0.0668, 0.0186, 0.0350, 0.0882, 0.0369,
        0.0775, 0.0506, 0.0490, 0.0913, 0.0653, 0.0263, 0.0727, 0.0256, 0.0268],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,721][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0153, 0.0208, 0.0364, 0.0063, 0.0227, 0.0347, 0.1158, 0.0409, 0.0237,
        0.0042, 0.0047, 0.0312, 0.0875, 0.0383, 0.4774, 0.0054, 0.0327, 0.0020],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,723][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0089, 0.0115, 0.0497, 0.0638, 0.0436, 0.1062, 0.1007, 0.0507, 0.0226,
        0.0217, 0.0191, 0.1374, 0.0247, 0.0503, 0.0590, 0.0243, 0.1971, 0.0085],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,724][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0100, 0.0151, 0.0555, 0.0291, 0.0577, 0.0648, 0.1012, 0.0690, 0.0666,
        0.0426, 0.0357, 0.1084, 0.0505, 0.0543, 0.0787, 0.0464, 0.0738, 0.0406],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,725][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0266, 0.0232, 0.0285, 0.0275, 0.0346, 0.0341, 0.0494, 0.0513, 0.0533,
        0.0572, 0.0562, 0.0676, 0.0582, 0.0724, 0.0782, 0.0868, 0.0893, 0.1054],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,726][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0104, 0.0939, 0.0623, 0.0661, 0.0707, 0.1107, 0.0775, 0.0990, 0.0101,
        0.0446, 0.0247, 0.0926, 0.0693, 0.0469, 0.0531, 0.0330, 0.0290, 0.0062],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,727][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0165, 0.0375, 0.0630, 0.0341, 0.0667, 0.0779, 0.0991, 0.0629, 0.0533,
        0.0286, 0.0362, 0.0770, 0.0553, 0.0671, 0.0823, 0.0283, 0.0771, 0.0370],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,728][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0663, 0.0580, 0.0577, 0.0610, 0.0616, 0.0615, 0.0540, 0.0546, 0.0540,
        0.0575, 0.0545, 0.0510, 0.0526, 0.0482, 0.0512, 0.0539, 0.0513, 0.0511],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,730][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0254, 0.0386, 0.0398, 0.0683, 0.0373, 0.1082, 0.1121, 0.0676, 0.0388,
        0.0448, 0.0287, 0.0851, 0.0319, 0.0299, 0.0668, 0.0427, 0.1143, 0.0197],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,732][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0444, 0.0726, 0.0639, 0.0655, 0.0631, 0.0530, 0.0371, 0.0593, 0.0440,
        0.0499, 0.0509, 0.0510, 0.0781, 0.0551, 0.0605, 0.0463, 0.0634, 0.0419],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,733][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0107, 0.0444, 0.0132, 0.1576, 0.0125, 0.0794, 0.0552, 0.0850, 0.0421,
        0.0768, 0.0958, 0.0318, 0.1199, 0.0112, 0.0272, 0.0519, 0.0352, 0.0503],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,735][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0659, 0.0376, 0.0482, 0.0764, 0.0458, 0.0719, 0.0547, 0.0907, 0.0366,
        0.0517, 0.0547, 0.0456, 0.0275, 0.0643, 0.0824, 0.0459, 0.0589, 0.0412],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:42,737][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0446, 0.0389, 0.1221, 0.0718, 0.0640, 0.0431, 0.0547, 0.0698, 0.0393,
        0.0671, 0.0421, 0.0382, 0.0417, 0.0546, 0.0323, 0.0637, 0.0478, 0.0411,
        0.0233], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,739][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0295, 0.0227, 0.0337, 0.0056, 0.0269, 0.0315, 0.1888, 0.0650, 0.0287,
        0.0046, 0.0086, 0.0477, 0.0633, 0.0443, 0.2169, 0.0055, 0.0443, 0.0053,
        0.1271], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,741][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0039, 0.0070, 0.0426, 0.0299, 0.0691, 0.0689, 0.0632, 0.0902, 0.0286,
        0.0251, 0.0235, 0.0791, 0.0175, 0.0744, 0.0860, 0.0296, 0.1698, 0.0510,
        0.0407], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,743][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0088, 0.0140, 0.0472, 0.0261, 0.0491, 0.0599, 0.0877, 0.0583, 0.0575,
        0.0384, 0.0324, 0.0941, 0.0455, 0.0423, 0.0663, 0.0415, 0.0666, 0.0369,
        0.1273], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,744][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0236, 0.0208, 0.0256, 0.0245, 0.0310, 0.0305, 0.0443, 0.0460, 0.0478,
        0.0513, 0.0505, 0.0608, 0.0522, 0.0651, 0.0703, 0.0783, 0.0805, 0.0953,
        0.1015], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,745][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0084, 0.1204, 0.0769, 0.0626, 0.0321, 0.0837, 0.0601, 0.0930, 0.0163,
        0.0481, 0.0231, 0.1003, 0.0522, 0.0215, 0.0595, 0.0368, 0.0729, 0.0251,
        0.0070], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,746][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0135, 0.0326, 0.0588, 0.0273, 0.0589, 0.0726, 0.0963, 0.0552, 0.0557,
        0.0218, 0.0285, 0.0685, 0.0465, 0.0610, 0.0903, 0.0223, 0.0868, 0.0298,
        0.0736], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,747][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0624, 0.0551, 0.0554, 0.0586, 0.0594, 0.0593, 0.0513, 0.0519, 0.0513,
        0.0547, 0.0519, 0.0486, 0.0503, 0.0461, 0.0489, 0.0515, 0.0491, 0.0488,
        0.0455], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,749][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0302, 0.0342, 0.0254, 0.0564, 0.0342, 0.1012, 0.1014, 0.0993, 0.0463,
        0.0478, 0.0285, 0.0668, 0.0267, 0.0289, 0.0693, 0.0478, 0.0772, 0.0343,
        0.0443], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,751][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0255, 0.0500, 0.0747, 0.0509, 0.0693, 0.0483, 0.0399, 0.0636, 0.0446,
        0.0313, 0.0670, 0.0438, 0.0541, 0.0638, 0.0653, 0.0308, 0.0696, 0.0783,
        0.0291], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,753][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0073, 0.0686, 0.0201, 0.1149, 0.0205, 0.0832, 0.0549, 0.0812, 0.0439,
        0.0752, 0.0972, 0.0414, 0.0764, 0.0165, 0.0248, 0.0430, 0.0373, 0.0490,
        0.0447], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,755][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0813, 0.0294, 0.0748, 0.0508, 0.0471, 0.0573, 0.0695, 0.0694, 0.0371,
        0.0360, 0.0424, 0.0683, 0.0246, 0.0590, 0.0820, 0.0313, 0.0578, 0.0307,
        0.0513], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:42,757][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0466, 0.0400, 0.0720, 0.0931, 0.0408, 0.0615, 0.0731, 0.1174, 0.0176,
        0.0278, 0.0395, 0.0795, 0.0556, 0.0371, 0.0151, 0.0243, 0.0384, 0.0424,
        0.0534, 0.0249], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,759][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0207, 0.0256, 0.0496, 0.0069, 0.0276, 0.0378, 0.1339, 0.0300, 0.0184,
        0.0072, 0.0111, 0.0352, 0.0941, 0.0480, 0.3017, 0.0091, 0.0398, 0.0044,
        0.0940, 0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,761][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0044, 0.0075, 0.0335, 0.0348, 0.0500, 0.0858, 0.0892, 0.0750, 0.0369,
        0.0050, 0.0219, 0.1047, 0.0153, 0.0643, 0.0607, 0.0060, 0.1723, 0.0467,
        0.0814, 0.0047], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,762][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0080, 0.0124, 0.0445, 0.0233, 0.0465, 0.0513, 0.0835, 0.0567, 0.0554,
        0.0355, 0.0301, 0.0902, 0.0422, 0.0463, 0.0651, 0.0390, 0.0629, 0.0351,
        0.1284, 0.0437], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,763][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0214, 0.0188, 0.0230, 0.0222, 0.0279, 0.0276, 0.0399, 0.0414, 0.0432,
        0.0463, 0.0455, 0.0546, 0.0467, 0.0583, 0.0631, 0.0699, 0.0722, 0.0851,
        0.0905, 0.1023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,764][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0112, 0.0907, 0.0546, 0.0941, 0.0390, 0.1402, 0.0802, 0.0614, 0.0088,
        0.0153, 0.0298, 0.1039, 0.0469, 0.0263, 0.0579, 0.0121, 0.0484, 0.0188,
        0.0510, 0.0094], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,765][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0165, 0.0326, 0.0550, 0.0343, 0.0555, 0.0703, 0.0903, 0.0581, 0.0454,
        0.0273, 0.0359, 0.0686, 0.0542, 0.0547, 0.0752, 0.0269, 0.0655, 0.0373,
        0.0702, 0.0263], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,767][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0605, 0.0530, 0.0529, 0.0558, 0.0564, 0.0563, 0.0492, 0.0497, 0.0491,
        0.0523, 0.0494, 0.0462, 0.0478, 0.0436, 0.0463, 0.0488, 0.0464, 0.0462,
        0.0430, 0.0471], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,769][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0193, 0.0337, 0.0239, 0.0508, 0.0450, 0.1054, 0.1012, 0.0653, 0.0508,
        0.0181, 0.0259, 0.0659, 0.0288, 0.0365, 0.0861, 0.0176, 0.1200, 0.0307,
        0.0587, 0.0165], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,771][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0437, 0.0579, 0.0683, 0.0518, 0.0534, 0.0478, 0.0423, 0.0534, 0.0381,
        0.0260, 0.0658, 0.0493, 0.0594, 0.0480, 0.0563, 0.0243, 0.0605, 0.0736,
        0.0558, 0.0242], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,772][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0080, 0.0450, 0.0122, 0.1444, 0.0120, 0.0675, 0.0470, 0.0790, 0.0376,
        0.0721, 0.0964, 0.0258, 0.1076, 0.0097, 0.0212, 0.0422, 0.0296, 0.0399,
        0.0324, 0.0706], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,775][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0596, 0.0372, 0.0443, 0.0754, 0.0337, 0.0549, 0.0465, 0.1064, 0.0343,
        0.0433, 0.0562, 0.0384, 0.0266, 0.0459, 0.0759, 0.0373, 0.0459, 0.0420,
        0.0466, 0.0497], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:42,808][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:42,809][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,809][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,810][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,812][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,812][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,813][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,814][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,814][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,815][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,816][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,816][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,817][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:42,818][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2483, 0.7517], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,819][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9954, 0.0046], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,820][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9475, 0.0525], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,822][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5423, 0.4577], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,823][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0487, 0.9513], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,825][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1646, 0.8354], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,827][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3860, 0.6140], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,829][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3595, 0.6405], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,830][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1249, 0.8751], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,832][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8036, 0.1964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,832][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2831, 0.7169], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,833][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3414, 0.6586], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:42,834][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.2783, 0.7068, 0.0150], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,834][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.9950, 0.0028, 0.0023], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,835][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2023, 0.0033, 0.7944], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,837][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2955, 0.3502, 0.3543], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,838][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([4.6961e-04, 9.7922e-02, 9.0161e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,840][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0634, 0.3952, 0.5414], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,841][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.1396, 0.2787, 0.5817], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,843][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.2266, 0.4900, 0.2834], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,845][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0380, 0.4073, 0.5547], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,847][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.7292, 0.1591, 0.1116], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,848][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.1356, 0.3763, 0.4881], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,850][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.1855, 0.4792, 0.3353], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:42,850][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0466, 0.7001, 0.2204, 0.0329], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,851][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9790e-01, 6.5264e-04, 1.0059e-03, 4.4137e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,852][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.6282e-04, 2.5559e-05, 9.9960e-01, 1.1147e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,853][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1935, 0.2149, 0.3683, 0.2233], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,853][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.2260e-04, 4.7729e-02, 7.5184e-01, 1.9981e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,855][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0480, 0.2436, 0.4022, 0.3063], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,856][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1557, 0.2540, 0.3996, 0.1907], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,858][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2125, 0.3517, 0.2720, 0.1638], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,860][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0295, 0.2320, 0.3269, 0.4116], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,861][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7018, 0.1285, 0.0933, 0.0764], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,863][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1061, 0.2405, 0.2978, 0.3557], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,865][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1285, 0.3394, 0.1606, 0.3714], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:42,866][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.1346, 0.2531, 0.3086, 0.2689, 0.0348], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,868][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.9883, 0.0036, 0.0032, 0.0013, 0.0035], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,869][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([2.2606e-03, 2.4573e-04, 9.9550e-01, 1.2389e-03, 7.5672e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,869][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.1234, 0.1437, 0.3243, 0.1675, 0.2412], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,870][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([5.5185e-05, 8.5950e-03, 3.3827e-01, 9.2162e-02, 5.6092e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,871][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0279, 0.1678, 0.2405, 0.2252, 0.3386], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,871][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.1000, 0.1596, 0.3110, 0.1317, 0.2977], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,873][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.1587, 0.3146, 0.2145, 0.1439, 0.1682], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,875][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0159, 0.1569, 0.1996, 0.3564, 0.2713], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,877][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.5894, 0.1259, 0.0940, 0.0812, 0.1095], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,879][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0627, 0.1714, 0.2216, 0.2701, 0.2742], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,881][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.1219, 0.2197, 0.2172, 0.2562, 0.1851], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:42,883][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1028, 0.4702, 0.1493, 0.1793, 0.0948, 0.0036], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,884][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([9.9601e-01, 8.1767e-04, 8.7776e-04, 4.0902e-04, 9.5571e-04, 9.2563e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,885][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([7.5514e-05, 2.2980e-05, 9.9516e-01, 6.0134e-05, 4.6073e-03, 7.3444e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,886][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1242, 0.1222, 0.2183, 0.1601, 0.2639, 0.1114], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,886][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([9.5645e-05, 1.8986e-02, 4.1341e-02, 1.9393e-01, 3.9380e-01, 3.5185e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,887][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0211, 0.1116, 0.1936, 0.1471, 0.2581, 0.2685], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,888][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0783, 0.1266, 0.2282, 0.1005, 0.2292, 0.2370], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,889][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1453, 0.2716, 0.1881, 0.1292, 0.1538, 0.1120], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,890][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0110, 0.1011, 0.1558, 0.2094, 0.1920, 0.3307], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,892][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.5986, 0.1041, 0.0776, 0.0601, 0.0897, 0.0699], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,894][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0582, 0.1335, 0.1704, 0.2026, 0.2066, 0.2287], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,895][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0848, 0.2209, 0.1516, 0.2445, 0.1537, 0.1445], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:42,897][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0963, 0.2962, 0.0629, 0.2020, 0.2016, 0.1279, 0.0132],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,898][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([9.9204e-01, 1.4246e-03, 1.5121e-03, 6.0850e-04, 1.5275e-03, 1.3669e-03,
        1.5169e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,900][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([4.2995e-03, 2.8437e-04, 9.8040e-01, 5.4865e-04, 1.1903e-02, 2.2528e-03,
        3.1067e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,901][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0912, 0.0909, 0.1925, 0.1170, 0.2333, 0.1630, 0.1121],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,903][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([2.7171e-05, 5.9556e-03, 1.0904e-02, 4.9503e-02, 6.5614e-02, 7.2495e-01,
        1.4305e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,904][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0154, 0.0804, 0.1210, 0.1077, 0.1768, 0.2137, 0.2850],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,905][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0550, 0.0858, 0.1863, 0.0644, 0.1771, 0.1839, 0.2474],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,905][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.1216, 0.2283, 0.1611, 0.1129, 0.1368, 0.1051, 0.1341],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,906][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0082, 0.0761, 0.1015, 0.1708, 0.1409, 0.3360, 0.1665],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,907][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.5778, 0.0988, 0.0679, 0.0555, 0.0780, 0.0605, 0.0615],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,908][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0378, 0.1078, 0.1376, 0.1676, 0.1701, 0.1894, 0.1897],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,910][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0862, 0.1965, 0.1023, 0.2498, 0.1157, 0.1858, 0.0637],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:42,912][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0735, 0.3870, 0.0130, 0.2385, 0.1410, 0.0276, 0.0978, 0.0216],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,913][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([9.9296e-01, 1.0111e-03, 1.0722e-03, 4.7562e-04, 1.0873e-03, 1.0235e-03,
        1.0692e-03, 1.3044e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,914][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([2.1298e-03, 1.1993e-04, 9.4074e-01, 2.4906e-04, 1.2799e-02, 4.3461e-04,
        1.0563e-03, 4.2472e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,916][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.1070, 0.0676, 0.1413, 0.1023, 0.1557, 0.1159, 0.1831, 0.1272],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,918][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([5.4426e-06, 4.9198e-04, 1.4490e-03, 6.2915e-03, 9.2911e-03, 2.0980e-02,
        6.6288e-01, 2.9861e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,920][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0118, 0.0597, 0.0981, 0.0814, 0.1378, 0.1568, 0.2329, 0.2214],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,921][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0515, 0.0812, 0.1496, 0.0645, 0.1524, 0.1816, 0.2142, 0.1051],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,922][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.1225, 0.1956, 0.1436, 0.0950, 0.1164, 0.0846, 0.1282, 0.1141],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,923][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0069, 0.0631, 0.1005, 0.1334, 0.1257, 0.2437, 0.1667, 0.1599],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,924][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.5299, 0.0897, 0.0650, 0.0504, 0.0726, 0.0567, 0.0590, 0.0768],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,924][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0410, 0.0965, 0.1197, 0.1423, 0.1444, 0.1593, 0.1608, 0.1360],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,925][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0809, 0.1706, 0.1182, 0.2027, 0.1170, 0.1651, 0.0651, 0.0804],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:42,927][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0571, 0.2509, 0.0355, 0.2666, 0.0255, 0.0153, 0.0471, 0.2993, 0.0028],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,928][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([9.9509e-01, 6.4672e-04, 7.1908e-04, 3.1107e-04, 6.9073e-04, 6.3051e-04,
        6.7926e-04, 8.1753e-04, 4.1775e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,929][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([6.0640e-03, 1.2733e-04, 5.7563e-01, 8.0110e-04, 7.1573e-03, 2.6269e-04,
        6.3901e-04, 2.1035e-01, 1.9898e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,931][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0936, 0.0716, 0.0988, 0.1017, 0.1463, 0.0881, 0.1788, 0.1830, 0.0382],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,932][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([2.2101e-06, 1.2958e-04, 2.5974e-04, 1.8084e-03, 2.0924e-03, 1.8835e-02,
        2.9763e-02, 2.0986e-01, 7.3725e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,934][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0095, 0.0497, 0.0799, 0.0670, 0.1133, 0.1302, 0.1936, 0.1831, 0.1737],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,937][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0475, 0.0699, 0.1314, 0.0546, 0.1226, 0.1669, 0.2151, 0.1029, 0.0891],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,938][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0979, 0.1860, 0.1216, 0.0981, 0.1015, 0.0828, 0.1196, 0.1145, 0.0779],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,940][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0061, 0.0551, 0.0809, 0.1198, 0.1032, 0.2188, 0.1333, 0.1397, 0.1431],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,941][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.5128, 0.0797, 0.0560, 0.0473, 0.0643, 0.0511, 0.0531, 0.0701, 0.0656],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,942][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0317, 0.0806, 0.1011, 0.1221, 0.1238, 0.1371, 0.1399, 0.1165, 0.1471],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,942][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0552, 0.1587, 0.0831, 0.2087, 0.0835, 0.1146, 0.0568, 0.1013, 0.1381],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:42,943][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0257, 0.2541, 0.0422, 0.1257, 0.0137, 0.0339, 0.0905, 0.4028, 0.0026,
        0.0088], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,944][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9428e-01, 6.3548e-04, 7.5132e-04, 2.9426e-04, 6.8576e-04, 5.9502e-04,
        6.6469e-04, 8.1036e-04, 4.4200e-04, 8.4072e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,946][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.9540e-04, 5.5131e-05, 1.4859e-01, 4.6778e-05, 2.6048e-03, 1.5513e-04,
        6.3955e-04, 1.0778e-01, 7.3698e-01, 2.7613e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,948][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0694, 0.0680, 0.0987, 0.0945, 0.1352, 0.1059, 0.1668, 0.1638, 0.0570,
        0.0408], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,949][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.5958e-07, 7.4181e-06, 5.5984e-05, 6.5642e-05, 5.1286e-04, 1.0260e-03,
        3.0743e-03, 3.8849e-02, 9.2814e-01, 2.8267e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,951][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0091, 0.0444, 0.0777, 0.0601, 0.1052, 0.1120, 0.1799, 0.1641, 0.1585,
        0.0891], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,953][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0508, 0.0754, 0.1182, 0.0685, 0.1209, 0.1504, 0.1857, 0.1036, 0.0807,
        0.0458], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,955][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0996, 0.1637, 0.1195, 0.0847, 0.1004, 0.0759, 0.1125, 0.1095, 0.0760,
        0.0581], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,957][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0057, 0.0505, 0.0800, 0.1025, 0.0966, 0.1611, 0.1180, 0.1156, 0.1188,
        0.1513], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,958][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5672, 0.0684, 0.0462, 0.0363, 0.0536, 0.0411, 0.0419, 0.0574, 0.0533,
        0.0346], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,959][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0328, 0.0711, 0.0872, 0.1047, 0.1058, 0.1168, 0.1199, 0.1022, 0.1265,
        0.1329], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,960][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0453, 0.1426, 0.0555, 0.2053, 0.0671, 0.1151, 0.0395, 0.0866, 0.1095,
        0.1334], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:42,960][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0372, 0.1540, 0.1107, 0.1700, 0.0236, 0.0131, 0.0378, 0.2509, 0.0249,
        0.1710, 0.0068], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,961][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.9029e-01, 9.4589e-04, 1.0627e-03, 3.8170e-04, 9.8210e-04, 8.3176e-04,
        9.8344e-04, 1.1879e-03, 6.2940e-04, 1.2146e-03, 1.4882e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,962][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.0179e-04, 1.6687e-04, 2.9705e-01, 8.2408e-05, 2.0844e-03, 7.9397e-05,
        1.0882e-03, 1.3543e-01, 5.5564e-01, 5.6143e-03, 2.3663e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,964][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0665, 0.0614, 0.0808, 0.0855, 0.1276, 0.0813, 0.1407, 0.1387, 0.0593,
        0.0663, 0.0917], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,966][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.4852e-06, 4.3975e-05, 2.6171e-04, 4.0985e-04, 2.7022e-03, 2.0470e-03,
        9.6214e-03, 8.8654e-02, 5.7559e-01, 1.8339e-01, 1.3728e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,967][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0082, 0.0404, 0.0686, 0.0543, 0.0924, 0.1027, 0.1670, 0.1513, 0.1452,
        0.0826, 0.0873], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,969][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0458, 0.0711, 0.1166, 0.0599, 0.1202, 0.1399, 0.1647, 0.1015, 0.0880,
        0.0429, 0.0494], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,971][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0922, 0.1528, 0.1139, 0.0817, 0.1004, 0.0732, 0.1027, 0.0958, 0.0680,
        0.0533, 0.0660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,973][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0054, 0.0443, 0.0636, 0.0862, 0.0758, 0.1355, 0.1008, 0.1012, 0.1021,
        0.1356, 0.1495], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,975][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.5436, 0.0641, 0.0446, 0.0343, 0.0512, 0.0397, 0.0402, 0.0562, 0.0518,
        0.0343, 0.0400], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,976][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0281, 0.0616, 0.0762, 0.0919, 0.0927, 0.1029, 0.1054, 0.0900, 0.1116,
        0.1176, 0.1219], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,977][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0415, 0.1308, 0.0547, 0.2069, 0.0629, 0.0989, 0.0396, 0.0694, 0.0903,
        0.1326, 0.0723], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:42,978][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.0549, 0.2366, 0.0207, 0.0865, 0.0915, 0.0630, 0.0699, 0.0857, 0.0225,
        0.2212, 0.0432, 0.0044], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,979][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.9591, 0.0025, 0.0030, 0.0013, 0.0028, 0.0026, 0.0028, 0.0032, 0.0019,
        0.0035, 0.0042, 0.0130], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,979][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([1.1753e-03, 2.7259e-04, 3.5043e-01, 2.2483e-04, 7.4414e-03, 1.4556e-04,
        3.6748e-04, 1.5020e-01, 4.2046e-01, 3.4584e-03, 1.1901e-02, 5.3916e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,981][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.0548, 0.0483, 0.0728, 0.0630, 0.1142, 0.0729, 0.1368, 0.1489, 0.0606,
        0.0434, 0.1108, 0.0736], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,982][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([4.2320e-07, 2.0436e-05, 2.2306e-04, 1.8488e-04, 3.4365e-03, 2.6520e-03,
        3.3793e-03, 1.9184e-02, 2.3696e-01, 1.4645e-01, 1.7552e-01, 4.1199e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,984][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.0077, 0.0367, 0.0552, 0.0489, 0.0788, 0.0971, 0.1300, 0.1304, 0.1258,
        0.0733, 0.0819, 0.1341], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,986][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0342, 0.0552, 0.1077, 0.0432, 0.1218, 0.1274, 0.1807, 0.0838, 0.0806,
        0.0304, 0.0400, 0.0949], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,988][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0839, 0.1455, 0.1019, 0.0792, 0.0942, 0.0707, 0.1042, 0.0886, 0.0646,
        0.0502, 0.0613, 0.0556], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,990][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.0043, 0.0335, 0.0446, 0.0770, 0.0588, 0.1318, 0.0719, 0.0860, 0.0818,
        0.1498, 0.1382, 0.1222], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,991][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.4310, 0.0654, 0.0463, 0.0392, 0.0521, 0.0425, 0.0448, 0.0590, 0.0555,
        0.0405, 0.0459, 0.0778], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,993][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.0176, 0.0504, 0.0650, 0.0798, 0.0807, 0.0897, 0.0929, 0.0752, 0.0976,
        0.1029, 0.1065, 0.1415], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,994][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.0494, 0.1157, 0.0648, 0.1717, 0.0789, 0.1041, 0.0493, 0.0530, 0.0992,
        0.0930, 0.0755, 0.0453], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:42,995][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0599, 0.1367, 0.0188, 0.0777, 0.0153, 0.0541, 0.0243, 0.2256, 0.0381,
        0.1193, 0.1615, 0.0100, 0.0585], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,996][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([9.4088e-01, 1.9218e-03, 2.0994e-03, 7.7342e-04, 1.9707e-03, 1.7180e-03,
        2.0224e-03, 2.4027e-03, 1.3112e-03, 2.3452e-03, 2.7762e-03, 8.5819e-03,
        3.1201e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,997][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([8.8811e-04, 6.2985e-05, 8.8113e-01, 5.1463e-05, 1.4275e-02, 1.2856e-04,
        1.9438e-04, 3.2307e-03, 1.4349e-02, 9.2131e-05, 4.1484e-05, 8.5552e-02,
        3.6292e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,998][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0528, 0.0525, 0.0782, 0.0676, 0.1143, 0.1008, 0.1144, 0.1083, 0.0555,
        0.0603, 0.0850, 0.0928, 0.0176], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:42,999][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.5359e-06, 2.2001e-05, 2.4357e-04, 3.8038e-04, 6.3286e-03, 2.6156e-03,
        2.8857e-03, 5.5574e-02, 1.2108e-01, 5.4225e-02, 1.7305e-01, 2.3281e-01,
        3.5079e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,000][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0080, 0.0341, 0.0569, 0.0444, 0.0759, 0.0842, 0.1236, 0.1175, 0.1169,
        0.0682, 0.0735, 0.1326, 0.0645], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,002][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0338, 0.0602, 0.0942, 0.0492, 0.1112, 0.1119, 0.1340, 0.0819, 0.0647,
        0.0364, 0.0473, 0.0984, 0.0769], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,004][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0834, 0.1343, 0.1076, 0.0696, 0.0923, 0.0620, 0.0908, 0.0823, 0.0663,
        0.0474, 0.0597, 0.0571, 0.0472], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,005][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0049, 0.0331, 0.0491, 0.0630, 0.0613, 0.1046, 0.0706, 0.0731, 0.0744,
        0.0985, 0.1040, 0.1277, 0.1357], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,008][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.4828, 0.0551, 0.0403, 0.0297, 0.0453, 0.0355, 0.0356, 0.0509, 0.0460,
        0.0311, 0.0365, 0.0687, 0.0426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,009][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0203, 0.0469, 0.0590, 0.0710, 0.0719, 0.0795, 0.0830, 0.0693, 0.0870,
        0.0910, 0.0943, 0.1215, 0.1054], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,011][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0386, 0.0878, 0.0542, 0.1737, 0.0553, 0.0773, 0.0361, 0.0615, 0.0895,
        0.1261, 0.0837, 0.0413, 0.0747], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,012][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0415, 0.0701, 0.0830, 0.0907, 0.0087, 0.0266, 0.0472, 0.2183, 0.0488,
        0.0891, 0.0279, 0.0311, 0.2108, 0.0062], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,013][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.7123, 0.0038, 0.0037, 0.0014, 0.0035, 0.0030, 0.0039, 0.0040, 0.0024,
        0.0042, 0.0049, 0.0141, 0.0500, 0.1889], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,014][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([1.3941e-02, 9.0147e-04, 7.7284e-01, 5.6107e-04, 4.0381e-04, 1.1928e-03,
        6.6702e-04, 3.2424e-02, 2.3393e-02, 2.0262e-04, 1.6592e-04, 2.7066e-02,
        9.1539e-05, 1.2614e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,015][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0387, 0.0425, 0.0923, 0.0502, 0.0704, 0.0766, 0.1153, 0.1414, 0.0532,
        0.0435, 0.1008, 0.1115, 0.0175, 0.0460], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,016][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([1.7185e-07, 2.3226e-06, 6.6225e-05, 1.6871e-05, 1.0952e-04, 1.2263e-04,
        2.5282e-05, 2.4705e-04, 1.5021e-03, 6.0968e-03, 9.9116e-03, 3.0933e-02,
        5.4345e-02, 8.9662e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,018][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0050, 0.0276, 0.0425, 0.0381, 0.0595, 0.0849, 0.1198, 0.1180, 0.1113,
        0.0663, 0.0721, 0.1332, 0.0619, 0.0598], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,020][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0310, 0.0485, 0.0953, 0.0411, 0.0923, 0.1099, 0.1569, 0.0721, 0.0690,
        0.0266, 0.0346, 0.0895, 0.0580, 0.0753], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,022][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0734, 0.1371, 0.0979, 0.0667, 0.0788, 0.0642, 0.0873, 0.0812, 0.0539,
        0.0432, 0.0557, 0.0526, 0.0447, 0.0635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,023][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0020, 0.0206, 0.0290, 0.0489, 0.0388, 0.1048, 0.0577, 0.0622, 0.0633,
        0.1234, 0.1023, 0.1115, 0.1649, 0.0706], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,025][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.3864, 0.0554, 0.0410, 0.0332, 0.0440, 0.0363, 0.0380, 0.0516, 0.0467,
        0.0343, 0.0393, 0.0675, 0.0450, 0.0813], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,027][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0170, 0.0423, 0.0539, 0.0661, 0.0666, 0.0746, 0.0764, 0.0640, 0.0809,
        0.0857, 0.0891, 0.1132, 0.0993, 0.0710], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,029][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0401, 0.0861, 0.0810, 0.1015, 0.0665, 0.1118, 0.0660, 0.0466, 0.1025,
        0.0653, 0.0570, 0.0559, 0.0630, 0.0569], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,030][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0109, 0.0732, 0.0439, 0.0443, 0.0198, 0.0113, 0.0194, 0.1343, 0.0175,
        0.0633, 0.0120, 0.0788, 0.4532, 0.0173, 0.0006], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,031][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([8.8665e-01, 8.0840e-04, 9.0528e-04, 3.7935e-04, 8.2775e-04, 7.7944e-04,
        8.9309e-04, 1.0470e-03, 5.8009e-04, 1.0803e-03, 1.3008e-03, 4.7726e-03,
        1.7488e-02, 8.0072e-02, 2.4165e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,032][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([3.1625e-04, 2.9633e-05, 6.4537e-02, 1.4846e-05, 5.5356e-04, 2.3218e-05,
        1.9744e-05, 5.1832e-03, 1.7813e-03, 1.2012e-05, 1.9816e-05, 2.2265e-03,
        9.9559e-07, 7.1177e-01, 2.1351e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,033][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0465, 0.0429, 0.0633, 0.0554, 0.0931, 0.0448, 0.1128, 0.1365, 0.0369,
        0.0395, 0.0989, 0.0908, 0.0196, 0.0639, 0.0549], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,034][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([2.3845e-07, 3.1178e-06, 7.9132e-06, 2.0481e-05, 2.1467e-05, 8.6790e-05,
        2.3182e-04, 5.3184e-04, 2.6103e-02, 6.3648e-03, 1.0119e-02, 6.9065e-02,
        1.1055e-01, 1.3971e-01, 6.3719e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,036][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0060, 0.0281, 0.0449, 0.0382, 0.0622, 0.0731, 0.1059, 0.1040, 0.0993,
        0.0588, 0.0646, 0.1189, 0.0573, 0.0637, 0.0751], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,038][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0286, 0.0415, 0.0896, 0.0319, 0.0883, 0.0990, 0.1433, 0.0633, 0.0595,
        0.0266, 0.0308, 0.0807, 0.0499, 0.0720, 0.0952], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,039][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0692, 0.1216, 0.0900, 0.0655, 0.0765, 0.0577, 0.0794, 0.0808, 0.0577,
        0.0447, 0.0555, 0.0480, 0.0430, 0.0640, 0.0464], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,041][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0028, 0.0220, 0.0343, 0.0488, 0.0441, 0.0848, 0.0545, 0.0551, 0.0569,
        0.0964, 0.0897, 0.1034, 0.1383, 0.0757, 0.0932], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,043][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.3835, 0.0513, 0.0375, 0.0282, 0.0403, 0.0316, 0.0341, 0.0463, 0.0421,
        0.0295, 0.0342, 0.0616, 0.0396, 0.0760, 0.0642], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,045][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0152, 0.0388, 0.0493, 0.0596, 0.0606, 0.0671, 0.0696, 0.0573, 0.0727,
        0.0764, 0.0793, 0.1032, 0.0892, 0.0636, 0.0983], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,047][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0359, 0.1034, 0.0653, 0.1240, 0.0570, 0.0761, 0.0466, 0.0552, 0.1036,
        0.0868, 0.0687, 0.0388, 0.0638, 0.0475, 0.0275], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,048][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0158, 0.1363, 0.0222, 0.0720, 0.0078, 0.0197, 0.0551, 0.2609, 0.0018,
        0.0052, 0.0175, 0.1060, 0.2649, 0.0065, 0.0035, 0.0048],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,049][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([7.9530e-01, 1.9036e-03, 1.9238e-03, 7.4256e-04, 1.7893e-03, 1.5688e-03,
        1.9734e-03, 2.1909e-03, 1.3676e-03, 2.2146e-03, 2.8079e-03, 8.4308e-03,
        2.9923e-02, 1.2856e-01, 5.0633e-03, 1.4238e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,050][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.9373e-04, 1.8438e-05, 1.7146e-02, 5.0896e-06, 2.7610e-04, 1.9189e-05,
        8.8008e-05, 7.4900e-03, 2.1236e-02, 3.8070e-05, 2.8638e-04, 1.7450e-02,
        2.5202e-06, 3.6685e-01, 5.5666e-01, 1.2239e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,050][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0442, 0.0437, 0.0595, 0.0618, 0.0840, 0.0683, 0.1030, 0.1066, 0.0362,
        0.0255, 0.0945, 0.0861, 0.0214, 0.0586, 0.0873, 0.0192],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,052][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.8295e-08, 2.1627e-07, 1.0992e-06, 1.2707e-06, 8.6626e-06, 1.2915e-05,
        5.0526e-05, 5.0912e-04, 8.2533e-03, 2.6659e-04, 6.1842e-04, 6.2407e-03,
        3.4684e-03, 5.5877e-02, 8.1298e-01, 1.1171e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,054][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0058, 0.0256, 0.0449, 0.0351, 0.0593, 0.0645, 0.1020, 0.0937, 0.0916,
        0.0513, 0.0577, 0.1150, 0.0572, 0.0670, 0.0770, 0.0523],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,056][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0329, 0.0473, 0.0763, 0.0444, 0.0778, 0.0974, 0.1208, 0.0667, 0.0526,
        0.0299, 0.0391, 0.0787, 0.0577, 0.0602, 0.0908, 0.0273],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,057][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0708, 0.1134, 0.0863, 0.0602, 0.0737, 0.0557, 0.0820, 0.0789, 0.0557,
        0.0418, 0.0505, 0.0480, 0.0402, 0.0613, 0.0474, 0.0342],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,059][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0028, 0.0226, 0.0358, 0.0460, 0.0438, 0.0722, 0.0539, 0.0524, 0.0551,
        0.0646, 0.0814, 0.1037, 0.1120, 0.0742, 0.0837, 0.0959],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,061][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4536, 0.0467, 0.0313, 0.0225, 0.0345, 0.0263, 0.0278, 0.0387, 0.0346,
        0.0225, 0.0264, 0.0529, 0.0317, 0.0658, 0.0561, 0.0286],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,063][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0172, 0.0369, 0.0452, 0.0543, 0.0548, 0.0604, 0.0635, 0.0538, 0.0666,
        0.0698, 0.0721, 0.0911, 0.0804, 0.0581, 0.0870, 0.0888],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,065][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0272, 0.1013, 0.0359, 0.1460, 0.0431, 0.0768, 0.0250, 0.0566, 0.0739,
        0.0904, 0.0713, 0.0293, 0.0716, 0.0378, 0.0288, 0.0851],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,066][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0167, 0.0527, 0.0251, 0.0240, 0.0341, 0.0092, 0.0301, 0.0700, 0.0499,
        0.1242, 0.0398, 0.1066, 0.2462, 0.0318, 0.0186, 0.1206, 0.0005],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,067][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([8.1177e-01, 1.4650e-03, 1.6929e-03, 6.9521e-04, 1.5034e-03, 1.3783e-03,
        1.6163e-03, 1.8222e-03, 1.1345e-03, 1.9337e-03, 2.3425e-03, 7.7041e-03,
        2.6862e-02, 1.1601e-01, 4.2803e-03, 1.2334e-02, 5.4555e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,067][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([1.5898e-03, 4.7017e-05, 5.3041e-02, 2.1474e-05, 3.8317e-05, 4.3886e-06,
        2.8209e-05, 2.2327e-02, 8.7343e-03, 5.6987e-05, 5.8809e-05, 1.2552e-03,
        7.2407e-07, 2.0948e-02, 3.5271e-02, 4.4153e-02, 8.1243e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,068][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0476, 0.0404, 0.0475, 0.0455, 0.0833, 0.0626, 0.1216, 0.1150, 0.0271,
        0.0277, 0.0936, 0.0834, 0.0176, 0.0554, 0.0735, 0.0206, 0.0376],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,070][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([2.8821e-08, 3.2534e-07, 1.0554e-06, 2.2879e-06, 3.8026e-06, 1.3135e-05,
        6.6504e-06, 2.8506e-04, 2.5766e-03, 5.5120e-04, 1.1512e-03, 4.8495e-03,
        8.4989e-03, 2.4438e-02, 1.3763e-01, 2.6578e-01, 5.5421e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,072][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0053, 0.0241, 0.0400, 0.0329, 0.0543, 0.0610, 0.0942, 0.0885, 0.0840,
        0.0494, 0.0549, 0.1052, 0.0517, 0.0569, 0.0667, 0.0494, 0.0814],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,073][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0278, 0.0392, 0.0753, 0.0301, 0.0774, 0.0898, 0.1273, 0.0599, 0.0513,
        0.0243, 0.0274, 0.0696, 0.0486, 0.0640, 0.0921, 0.0224, 0.0734],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,075][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0657, 0.1184, 0.0802, 0.0607, 0.0680, 0.0524, 0.0788, 0.0733, 0.0508,
        0.0415, 0.0480, 0.0411, 0.0394, 0.0562, 0.0437, 0.0333, 0.0485],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,077][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0025, 0.0193, 0.0287, 0.0416, 0.0363, 0.0681, 0.0461, 0.0453, 0.0463,
        0.0697, 0.0706, 0.0860, 0.1058, 0.0601, 0.0746, 0.1098, 0.0893],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,079][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.3714, 0.0481, 0.0331, 0.0255, 0.0358, 0.0280, 0.0306, 0.0407, 0.0371,
        0.0259, 0.0297, 0.0545, 0.0341, 0.0655, 0.0560, 0.0320, 0.0521],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,081][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0132, 0.0330, 0.0410, 0.0496, 0.0501, 0.0552, 0.0579, 0.0478, 0.0605,
        0.0636, 0.0656, 0.0852, 0.0738, 0.0526, 0.0811, 0.0821, 0.0876],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,083][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0292, 0.0923, 0.0540, 0.1060, 0.0449, 0.0593, 0.0387, 0.0576, 0.0896,
        0.0822, 0.0655, 0.0314, 0.0568, 0.0393, 0.0347, 0.0749, 0.0435],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,084][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0195, 0.0704, 0.0154, 0.1225, 0.0180, 0.0012, 0.0105, 0.0721, 0.0106,
        0.0744, 0.0212, 0.0239, 0.4365, 0.0150, 0.0112, 0.0610, 0.0139, 0.0028],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,085][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7244, 0.0024, 0.0024, 0.0009, 0.0022, 0.0019, 0.0025, 0.0027, 0.0017,
        0.0028, 0.0035, 0.0101, 0.0365, 0.1537, 0.0063, 0.0175, 0.0080, 0.0204],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,086][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.0095e-05, 2.1920e-05, 1.8979e-02, 6.2782e-06, 4.9355e-05, 1.9029e-06,
        4.4135e-05, 5.6297e-03, 9.6551e-03, 3.9403e-05, 1.8051e-05, 1.9592e-03,
        2.7394e-07, 1.0481e-02, 1.3635e-02, 5.9417e-03, 9.0654e-01, 2.6929e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,087][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0352, 0.0363, 0.0489, 0.0507, 0.0731, 0.0465, 0.0919, 0.0810, 0.0392,
        0.0367, 0.0798, 0.0741, 0.0179, 0.0527, 0.0817, 0.0284, 0.0789, 0.0470],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,088][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.7741e-08, 1.2770e-07, 4.6707e-07, 7.0769e-07, 1.9376e-06, 2.9122e-06,
        1.2169e-05, 1.4548e-04, 4.2529e-04, 1.5507e-04, 1.6037e-04, 8.5694e-04,
        2.3209e-03, 6.1625e-03, 9.9954e-02, 6.8259e-02, 7.3639e-01, 8.5154e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,090][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0047, 0.0221, 0.0397, 0.0302, 0.0523, 0.0568, 0.0944, 0.0843, 0.0803,
        0.0452, 0.0479, 0.1024, 0.0473, 0.0571, 0.0668, 0.0443, 0.0780, 0.0461],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,092][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0267, 0.0444, 0.0676, 0.0358, 0.0745, 0.0868, 0.1068, 0.0601, 0.0505,
        0.0259, 0.0319, 0.0713, 0.0491, 0.0593, 0.0799, 0.0238, 0.0742, 0.0313],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,093][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0632, 0.1063, 0.0821, 0.0561, 0.0707, 0.0517, 0.0732, 0.0670, 0.0488,
        0.0373, 0.0471, 0.0452, 0.0384, 0.0592, 0.0414, 0.0305, 0.0441, 0.0378],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,095][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0023, 0.0191, 0.0309, 0.0369, 0.0357, 0.0579, 0.0506, 0.0436, 0.0458,
        0.0512, 0.0596, 0.0902, 0.0872, 0.0589, 0.0712, 0.0740, 0.0819, 0.1029],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,098][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.4196, 0.0432, 0.0287, 0.0208, 0.0314, 0.0240, 0.0257, 0.0354, 0.0316,
        0.0210, 0.0241, 0.0488, 0.0290, 0.0600, 0.0516, 0.0269, 0.0475, 0.0306],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,099][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0144, 0.0313, 0.0380, 0.0458, 0.0461, 0.0509, 0.0536, 0.0454, 0.0563,
        0.0591, 0.0610, 0.0770, 0.0681, 0.0490, 0.0736, 0.0754, 0.0795, 0.0754],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,101][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0261, 0.0891, 0.0353, 0.1262, 0.0505, 0.0823, 0.0275, 0.0401, 0.0640,
        0.0849, 0.0511, 0.0281, 0.0598, 0.0442, 0.0259, 0.0785, 0.0471, 0.0392],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,102][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0371, 0.0609, 0.0997, 0.0506, 0.0319, 0.0147, 0.0416, 0.0758, 0.0222,
        0.0892, 0.0214, 0.0336, 0.1455, 0.0310, 0.0276, 0.0864, 0.0829, 0.0160,
        0.0319], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,103][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([7.1284e-01, 1.7157e-03, 1.8265e-03, 6.8950e-04, 1.6538e-03, 1.4270e-03,
        1.9478e-03, 2.0093e-03, 1.3189e-03, 2.2123e-03, 2.6725e-03, 8.8035e-03,
        3.2764e-02, 1.5106e-01, 5.2316e-03, 1.4766e-02, 6.7495e-03, 1.7936e-02,
        3.2376e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,104][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([1.5974e-03, 5.6390e-04, 2.1955e-01, 1.7246e-04, 4.1276e-04, 2.7350e-05,
        1.7332e-04, 2.0260e-02, 1.4238e-02, 3.7736e-05, 4.4091e-05, 5.5796e-04,
        5.2665e-06, 1.9648e-02, 1.4931e-02, 3.0156e-03, 6.7699e-01, 1.9219e-02,
        8.5603e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,105][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0260, 0.0288, 0.0571, 0.0387, 0.0776, 0.0567, 0.0799, 0.1098, 0.0388,
        0.0240, 0.0578, 0.0531, 0.0105, 0.0529, 0.0882, 0.0185, 0.0809, 0.0769,
        0.0239], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,106][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([5.2717e-09, 4.0745e-08, 3.0876e-07, 2.8703e-07, 3.6199e-06, 1.9908e-06,
        2.6662e-06, 1.5585e-05, 1.1383e-04, 1.2802e-04, 1.4379e-04, 1.2674e-03,
        1.8724e-03, 2.3264e-02, 9.5950e-03, 7.0378e-02, 2.2296e-01, 1.7792e-01,
        4.9233e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,108][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0046, 0.0218, 0.0334, 0.0299, 0.0467, 0.0594, 0.0791, 0.0801, 0.0757,
        0.0445, 0.0496, 0.0835, 0.0431, 0.0462, 0.0582, 0.0426, 0.0744, 0.0494,
        0.0776], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,110][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0230, 0.0390, 0.0620, 0.0288, 0.0653, 0.0816, 0.1047, 0.0525, 0.0529,
        0.0196, 0.0245, 0.0621, 0.0416, 0.0532, 0.0907, 0.0185, 0.0867, 0.0249,
        0.0682], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,112][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0579, 0.1061, 0.0770, 0.0582, 0.0660, 0.0516, 0.0661, 0.0630, 0.0446,
        0.0377, 0.0447, 0.0422, 0.0389, 0.0539, 0.0386, 0.0306, 0.0452, 0.0392,
        0.0386], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,114][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0014, 0.0127, 0.0194, 0.0308, 0.0252, 0.0558, 0.0320, 0.0349, 0.0345,
        0.0606, 0.0550, 0.0576, 0.0948, 0.0421, 0.0590, 0.0979, 0.0753, 0.1198,
        0.0910], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,116][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.3476, 0.0408, 0.0291, 0.0219, 0.0311, 0.0248, 0.0267, 0.0366, 0.0332,
        0.0233, 0.0268, 0.0501, 0.0312, 0.0617, 0.0535, 0.0306, 0.0506, 0.0348,
        0.0455], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,118][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0096, 0.0264, 0.0336, 0.0411, 0.0416, 0.0462, 0.0488, 0.0397, 0.0510,
        0.0537, 0.0554, 0.0734, 0.0628, 0.0434, 0.0702, 0.0708, 0.0760, 0.0705,
        0.0858], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,119][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0373, 0.0801, 0.0567, 0.1067, 0.0546, 0.0777, 0.0341, 0.0374, 0.0757,
        0.0670, 0.0439, 0.0416, 0.0536, 0.0448, 0.0268, 0.0590, 0.0523, 0.0333,
        0.0174], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,120][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0125, 0.1138, 0.0171, 0.0607, 0.0065, 0.0143, 0.0397, 0.2017, 0.0015,
        0.0043, 0.0124, 0.1013, 0.2404, 0.0057, 0.0024, 0.0038, 0.0284, 0.0095,
        0.1204, 0.0034], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,121][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6160, 0.0027, 0.0028, 0.0011, 0.0026, 0.0023, 0.0030, 0.0031, 0.0020,
        0.0031, 0.0039, 0.0105, 0.0362, 0.1526, 0.0070, 0.0180, 0.0088, 0.0210,
        0.0370, 0.0666], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,122][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.4187e-05, 6.8269e-06, 3.6708e-03, 2.0313e-06, 3.3079e-05, 1.3179e-06,
        1.5002e-05, 1.2205e-03, 2.7450e-03, 2.5426e-06, 2.1836e-05, 1.1442e-03,
        2.6205e-07, 1.2575e-02, 1.1377e-02, 2.8559e-04, 4.7837e-01, 3.8027e-02,
        4.3365e-01, 1.6773e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,124][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0346, 0.0341, 0.0471, 0.0479, 0.0653, 0.0533, 0.0806, 0.0831, 0.0282,
        0.0193, 0.0730, 0.0667, 0.0166, 0.0452, 0.0672, 0.0143, 0.0851, 0.0833,
        0.0423, 0.0125], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,125][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.3913e-09, 2.5335e-08, 1.2595e-07, 1.2290e-07, 8.7939e-07, 1.3112e-06,
        3.8736e-06, 4.8605e-05, 5.8607e-04, 2.0541e-05, 4.5441e-05, 5.8996e-04,
        2.7658e-04, 3.5018e-03, 5.4552e-02, 7.2741e-03, 4.7341e-01, 5.2075e-02,
        1.4574e-01, 2.6188e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,127][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0043, 0.0192, 0.0349, 0.0268, 0.0456, 0.0485, 0.0797, 0.0714, 0.0688,
        0.0381, 0.0429, 0.0887, 0.0433, 0.0518, 0.0594, 0.0386, 0.0696, 0.0424,
        0.0857, 0.0401], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,129][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0269, 0.0397, 0.0606, 0.0373, 0.0624, 0.0797, 0.0990, 0.0557, 0.0427,
        0.0247, 0.0322, 0.0641, 0.0487, 0.0480, 0.0737, 0.0225, 0.0630, 0.0323,
        0.0654, 0.0215], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,131][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0595, 0.0958, 0.0732, 0.0524, 0.0631, 0.0481, 0.0712, 0.0675, 0.0472,
        0.0362, 0.0430, 0.0414, 0.0348, 0.0523, 0.0404, 0.0294, 0.0430, 0.0357,
        0.0417, 0.0242], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,133][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0019, 0.0159, 0.0254, 0.0315, 0.0297, 0.0464, 0.0387, 0.0349, 0.0369,
        0.0390, 0.0517, 0.0740, 0.0746, 0.0497, 0.0570, 0.0558, 0.0670, 0.0917,
        0.1085, 0.0698], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,135][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.4189, 0.0403, 0.0261, 0.0182, 0.0279, 0.0211, 0.0234, 0.0319, 0.0279,
        0.0182, 0.0209, 0.0431, 0.0252, 0.0528, 0.0454, 0.0231, 0.0419, 0.0266,
        0.0377, 0.0294], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,137][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0125, 0.0266, 0.0323, 0.0389, 0.0391, 0.0431, 0.0459, 0.0388, 0.0482,
        0.0504, 0.0519, 0.0660, 0.0581, 0.0415, 0.0629, 0.0643, 0.0680, 0.0642,
        0.0759, 0.0714], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,138][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0218, 0.0893, 0.0306, 0.1274, 0.0363, 0.0654, 0.0211, 0.0467, 0.0624,
        0.0749, 0.0575, 0.0238, 0.0610, 0.0306, 0.0230, 0.0693, 0.0375, 0.0408,
        0.0166, 0.0641], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,141][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:43,144][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17657],
        [18431],
        [ 2100],
        [17630],
        [19179],
        [12464],
        [17933],
        [16274],
        [34112],
        [15963],
        [23629],
        [ 2835],
        [12980],
        [19779],
        [24010],
        [16248],
        [17577],
        [20614],
        [16692],
        [15671]], device='cuda:0')
[2024-07-24 10:18:43,146][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16049],
        [ 7175],
        [ 2820],
        [22705],
        [24965],
        [18515],
        [15147],
        [12308],
        [33481],
        [16391],
        [30880],
        [ 6465],
        [16047],
        [25329],
        [26004],
        [18975],
        [17051],
        [27691],
        [22298],
        [19306]], device='cuda:0')
[2024-07-24 10:18:43,148][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21760],
        [16206],
        [16991],
        [26228],
        [28848],
        [24794],
        [20948],
        [17658],
        [17071],
        [15003],
        [18582],
        [16407],
        [15866],
        [16777],
        [17915],
        [14688],
        [17239],
        [17236],
        [17609],
        [14206]], device='cuda:0')
[2024-07-24 10:18:43,150][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[40296],
        [32457],
        [  214],
        [  271],
        [  959],
        [  511],
        [ 1371],
        [ 4049],
        [ 2900],
        [ 1723],
        [ 1510],
        [ 1970],
        [ 2532],
        [ 3304],
        [ 4609],
        [ 4414],
        [ 6773],
        [ 7430],
        [ 6852],
        [ 5900]], device='cuda:0')
[2024-07-24 10:18:43,152][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12297],
        [ 7560],
        [21712],
        [24460],
        [18744],
        [17368],
        [13665],
        [15267],
        [15467],
        [13369],
        [13472],
        [16737],
        [16045],
        [16894],
        [17021],
        [15724],
        [13182],
        [11660],
        [12841],
        [12805]], device='cuda:0')
[2024-07-24 10:18:43,154][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 7643],
        [ 9657],
        [14775],
        [13626],
        [13929],
        [13323],
        [12866],
        [12204],
        [11885],
        [11715],
        [11714],
        [12607],
        [12471],
        [12505],
        [12162],
        [11880],
        [11508],
        [11220],
        [11561],
        [11385]], device='cuda:0')
[2024-07-24 10:18:43,157][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38186],
        [36112],
        [35540],
        [35030],
        [34164],
        [33992],
        [33299],
        [33084],
        [32604],
        [32192],
        [31883],
        [31365],
        [31125],
        [30581],
        [30338],
        [30139],
        [29947],
        [29741],
        [29168],
        [29043]], device='cuda:0')
[2024-07-24 10:18:43,158][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[20019],
        [30549],
        [32599],
        [34340],
        [34366],
        [36209],
        [37337],
        [37471],
        [36591],
        [37760],
        [36909],
        [35554],
        [35884],
        [35628],
        [35683],
        [36958],
        [35410],
        [36390],
        [36125],
        [36870]], device='cuda:0')
[2024-07-24 10:18:43,160][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13129],
        [12384],
        [16025],
        [15151],
        [14853],
        [18683],
        [18876],
        [20070],
        [19832],
        [19895],
        [19203],
        [20205],
        [20220],
        [19747],
        [20430],
        [20627],
        [20528],
        [20056],
        [20324],
        [20355]], device='cuda:0')
[2024-07-24 10:18:43,162][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[8298],
        [9763],
        [9289],
        [9370],
        [9071],
        [9151],
        [9037],
        [8962],
        [8877],
        [8672],
        [8397],
        [8175],
        [7965],
        [7736],
        [7629],
        [7426],
        [7208],
        [6987],
        [6796],
        [6632]], device='cuda:0')
[2024-07-24 10:18:43,164][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[48677],
        [48978],
        [49042],
        [49076],
        [49037],
        [49437],
        [49729],
        [49815],
        [49825],
        [49830],
        [49777],
        [49762],
        [49696],
        [49751],
        [49705],
        [49656],
        [49637],
        [49538],
        [49528],
        [49440]], device='cuda:0')
[2024-07-24 10:18:43,166][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39146],
        [41605],
        [39339],
        [38736],
        [39562],
        [40086],
        [39756],
        [40213],
        [40527],
        [40104],
        [40794],
        [41133],
        [41288],
        [41391],
        [41225],
        [41031],
        [41191],
        [41756],
        [42198],
        [42000]], device='cuda:0')
[2024-07-24 10:18:43,168][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11900],
        [11102],
        [ 7361],
        [ 9417],
        [ 8703],
        [ 7188],
        [ 6316],
        [ 9415],
        [ 8848],
        [ 9583],
        [ 7864],
        [ 7277],
        [ 8218],
        [ 7143],
        [ 7559],
        [ 7967],
        [ 7907],
        [ 7545],
        [ 7670],
        [ 7951]], device='cuda:0')
[2024-07-24 10:18:43,171][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[41837],
        [46136],
        [45632],
        [48374],
        [46245],
        [47330],
        [46694],
        [46454],
        [46496],
        [46784],
        [48050],
        [47454],
        [47997],
        [46455],
        [47088],
        [47543],
        [46944],
        [47180],
        [45990],
        [46914]], device='cuda:0')
[2024-07-24 10:18:43,173][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16538],
        [17667],
        [10102],
        [ 1747],
        [  800],
        [ 6305],
        [ 8361],
        [ 5580],
        [12790],
        [ 8394],
        [ 4192],
        [ 1725],
        [ 2707],
        [ 1395],
        [ 7498],
        [ 7178],
        [ 5264],
        [ 2079],
        [ 6318],
        [10996]], device='cuda:0')
[2024-07-24 10:18:43,175][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13700],
        [14436],
        [14213],
        [14151],
        [ 7048],
        [10668],
        [ 9033],
        [12095],
        [10039],
        [15608],
        [ 9530],
        [12184],
        [10857],
        [11011],
        [15625],
        [14468],
        [11048],
        [12818],
        [10504],
        [15885]], device='cuda:0')
[2024-07-24 10:18:43,176][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11261],
        [11353],
        [11338],
        [11277],
        [11275],
        [11245],
        [11204],
        [11175],
        [11186],
        [11163],
        [11132],
        [10844],
        [10133],
        [ 9643],
        [10201],
        [ 9833],
        [ 9837],
        [ 9721],
        [ 9440],
        [ 9598]], device='cuda:0')
[2024-07-24 10:18:43,178][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[43386],
        [42985],
        [44180],
        [36155],
        [36286],
        [36146],
        [36398],
        [37165],
        [31271],
        [12986],
        [16017],
        [18367],
        [32032],
        [35376],
        [28382],
        [15451],
        [18768],
        [19203],
        [16819],
        [24288]], device='cuda:0')
[2024-07-24 10:18:43,180][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[29107],
        [30254],
        [34380],
        [34788],
        [34267],
        [34275],
        [35269],
        [34631],
        [34274],
        [34203],
        [33506],
        [34013],
        [34123],
        [34215],
        [34029],
        [34517],
        [34584],
        [34239],
        [34088],
        [34050]], device='cuda:0')
[2024-07-24 10:18:43,183][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[23466],
        [15461],
        [12221],
        [14485],
        [17826],
        [20249],
        [16394],
        [20715],
        [40991],
        [41854],
        [32391],
        [20372],
        [15970],
        [21900],
        [29465],
        [28303],
        [14244],
        [14467],
        [32591],
        [17690]], device='cuda:0')
[2024-07-24 10:18:43,185][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14307],
        [13605],
        [13106],
        [13667],
        [13279],
        [12806],
        [13355],
        [13666],
        [13623],
        [13673],
        [13423],
        [13289],
        [13329],
        [13413],
        [13599],
        [13700],
        [13797],
        [13828],
        [13817],
        [13899]], device='cuda:0')
[2024-07-24 10:18:43,187][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30669],
        [26981],
        [27667],
        [27476],
        [28696],
        [25461],
        [27193],
        [26649],
        [25867],
        [25740],
        [26263],
        [26424],
        [26072],
        [26655],
        [26396],
        [26055],
        [26059],
        [26130],
        [26133],
        [26189]], device='cuda:0')
[2024-07-24 10:18:43,189][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 4491],
        [ 7810],
        [ 9705],
        [ 9814],
        [10277],
        [10504],
        [ 9628],
        [ 8491],
        [ 7834],
        [ 7700],
        [ 7736],
        [ 7459],
        [ 7449],
        [ 7766],
        [ 7463],
        [ 7358],
        [ 7209],
        [ 7219],
        [ 7060],
        [ 6874]], device='cuda:0')
[2024-07-24 10:18:43,191][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[39690],
        [40637],
        [35533],
        [37290],
        [36463],
        [36247],
        [36322],
        [36270],
        [36546],
        [36379],
        [36853],
        [36851],
        [37230],
        [37281],
        [37172],
        [37239],
        [37348],
        [37619],
        [37833],
        [37642]], device='cuda:0')
[2024-07-24 10:18:43,193][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24108],
        [24207],
        [24482],
        [24439],
        [24782],
        [24865],
        [24769],
        [24804],
        [24772],
        [24666],
        [24686],
        [24842],
        [24812],
        [25012],
        [25042],
        [24943],
        [24970],
        [24931],
        [24998],
        [24955]], device='cuda:0')
[2024-07-24 10:18:43,195][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39348],
        [33529],
        [33660],
        [34308],
        [33684],
        [33473],
        [32976],
        [33522],
        [33382],
        [33431],
        [33350],
        [32764],
        [32859],
        [32672],
        [32215],
        [32111],
        [31861],
        [31873],
        [31264],
        [31271]], device='cuda:0')
[2024-07-24 10:18:43,196][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23074],
        [20510],
        [18063],
        [13391],
        [17379],
        [16868],
        [17449],
        [18709],
        [19659],
        [18871],
        [18825],
        [19646],
        [19406],
        [21035],
        [21100],
        [20168],
        [20978],
        [20105],
        [20487],
        [19807]], device='cuda:0')
[2024-07-24 10:18:43,199][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12809],
        [15797],
        [17323],
        [19012],
        [19441],
        [18451],
        [19839],
        [18103],
        [15621],
        [16913],
        [18038],
        [19344],
        [19562],
        [16807],
        [15847],
        [18139],
        [20632],
        [20509],
        [16680],
        [18630]], device='cuda:0')
[2024-07-24 10:18:43,201][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41269],
        [45207],
        [37668],
        [45934],
        [41811],
        [39112],
        [40431],
        [33616],
        [33129],
        [34507],
        [43626],
        [39383],
        [43497],
        [34917],
        [37271],
        [40795],
        [43065],
        [43415],
        [34919],
        [37956]], device='cuda:0')
[2024-07-24 10:18:43,203][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997],
        [46997]], device='cuda:0')
[2024-07-24 10:18:43,244][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:43,246][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,247][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,249][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,250][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,251][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,252][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,253][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,253][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,254][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,255][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,256][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,257][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,258][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7471, 0.2529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,258][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0711, 0.9289], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,259][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3309, 0.6691], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,260][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3016, 0.6984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,261][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6514, 0.3486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,261][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5584, 0.4416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,262][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6340, 0.3660], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,263][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5748, 0.4252], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,263][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7735, 0.2265], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,264][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5505, 0.4495], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,265][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6851, 0.3149], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,265][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4843, 0.5157], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,267][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.6597, 0.1569, 0.1834], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,269][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0527, 0.8741, 0.0732], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,270][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1810, 0.4932, 0.3258], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,272][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.1364, 0.5224, 0.3412], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,274][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.1723, 0.7979, 0.0298], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,276][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.4000, 0.3140, 0.2860], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,277][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.1162, 0.8719, 0.0119], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,279][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.4315, 0.3058, 0.2627], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,279][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0906, 0.2044, 0.7050], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,280][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.3553, 0.2970, 0.3477], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,281][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.4668, 0.2483, 0.2849], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,281][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.3241, 0.3352, 0.3407], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,282][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5257, 0.1617, 0.1305, 0.1821], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,283][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4175, 0.2541, 0.1136, 0.2147], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,285][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1307, 0.3209, 0.2533, 0.2951], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,287][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1141, 0.3443, 0.2609, 0.2807], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,288][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2210, 0.3054, 0.0924, 0.3812], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,290][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3075, 0.2449, 0.2239, 0.2237], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,292][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4265, 0.4532, 0.1007, 0.0196], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,293][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3231, 0.2394, 0.2118, 0.2258], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,295][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5668, 0.0776, 0.1481, 0.2075], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,296][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2980, 0.2225, 0.2443, 0.2352], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,297][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3620, 0.2172, 0.1808, 0.2401], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,298][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2491, 0.2474, 0.2490, 0.2545], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,299][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.5770, 0.1186, 0.0616, 0.1052, 0.1376], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,299][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.1096, 0.1543, 0.1023, 0.4111, 0.2227], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,300][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0922, 0.2435, 0.1844, 0.2487, 0.2313], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,302][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0652, 0.2745, 0.2452, 0.2283, 0.1867], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,304][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0676, 0.5155, 0.0700, 0.3123, 0.0347], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,306][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.2422, 0.1963, 0.1820, 0.1820, 0.1975], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,307][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0951, 0.6853, 0.0192, 0.1964, 0.0040], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,309][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.2685, 0.1899, 0.1664, 0.1769, 0.1983], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,311][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0289, 0.0507, 0.1506, 0.7308, 0.0389], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,313][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.1915, 0.1826, 0.2184, 0.2236, 0.1839], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,315][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.3157, 0.1293, 0.1485, 0.1619, 0.2446], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,315][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.1902, 0.1961, 0.2033, 0.2033, 0.2070], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,316][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.4899, 0.1130, 0.0782, 0.1177, 0.0628, 0.1384], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,317][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0748, 0.3610, 0.0556, 0.3169, 0.0908, 0.1008], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,318][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0798, 0.1905, 0.1677, 0.2058, 0.2074, 0.1488], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,318][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0644, 0.2118, 0.1682, 0.2025, 0.2169, 0.1361], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,320][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3088, 0.1587, 0.0853, 0.2048, 0.1267, 0.1157], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,322][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.2020, 0.1640, 0.1526, 0.1523, 0.1653, 0.1638], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,324][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3223, 0.3947, 0.0607, 0.1217, 0.0922, 0.0085], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,326][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.2163, 0.1601, 0.1450, 0.1530, 0.1714, 0.1541], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,327][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.1121, 0.0910, 0.0959, 0.4888, 0.0332, 0.1790], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,328][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2041, 0.1667, 0.1522, 0.1653, 0.1485, 0.1632], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,329][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.1123, 0.1442, 0.1425, 0.1764, 0.2928, 0.1318], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,331][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.1589, 0.1643, 0.1661, 0.1692, 0.1695, 0.1720], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,332][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.5279, 0.1114, 0.0643, 0.1134, 0.0420, 0.0924, 0.0486],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,334][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0361, 0.0759, 0.0221, 0.3624, 0.0643, 0.4107, 0.0285],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,335][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0783, 0.1684, 0.1349, 0.1737, 0.1831, 0.1334, 0.1282],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,336][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0587, 0.1875, 0.1516, 0.1726, 0.1897, 0.1341, 0.1059],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,337][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.1211, 0.2299, 0.0737, 0.2795, 0.0515, 0.1559, 0.0884],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,338][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.1769, 0.1421, 0.1308, 0.1309, 0.1432, 0.1423, 0.1337],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,338][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0761, 0.3204, 0.0440, 0.2909, 0.1008, 0.1065, 0.0614],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,339][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1994, 0.1424, 0.1243, 0.1363, 0.1507, 0.1372, 0.1098],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,341][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2450, 0.2511, 0.0133, 0.1893, 0.0032, 0.0296, 0.2685],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,343][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1498, 0.1211, 0.1400, 0.1242, 0.1125, 0.1779, 0.1746],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,345][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.1446, 0.1050, 0.0588, 0.1583, 0.2247, 0.0926, 0.2160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,347][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.1368, 0.1405, 0.1397, 0.1451, 0.1455, 0.1465, 0.1459],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,349][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.3938, 0.1056, 0.0754, 0.1146, 0.0492, 0.0990, 0.0486, 0.1138],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,350][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0601, 0.0537, 0.0380, 0.3074, 0.0899, 0.2914, 0.0587, 0.1008],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,352][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0702, 0.1433, 0.1197, 0.1455, 0.1543, 0.1283, 0.1312, 0.1075],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,354][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0489, 0.1568, 0.1236, 0.1484, 0.1708, 0.1320, 0.1359, 0.0837],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,354][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.2524, 0.0916, 0.0380, 0.1523, 0.0549, 0.0982, 0.1278, 0.1848],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,355][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.1582, 0.1261, 0.1151, 0.1153, 0.1257, 0.1255, 0.1181, 0.1161],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,356][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0758, 0.2536, 0.0681, 0.1986, 0.1886, 0.0466, 0.0292, 0.1393],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,357][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1739, 0.1277, 0.1124, 0.1215, 0.1355, 0.1238, 0.0983, 0.1069],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,358][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ about] are: tensor([2.3386e-01, 7.3794e-03, 6.4052e-04, 3.3197e-02, 2.7894e-04, 2.8012e-03,
        1.9254e-02, 7.0259e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,360][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0816, 0.0833, 0.0947, 0.0789, 0.0850, 0.1419, 0.3371, 0.0976],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,362][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.1581, 0.1015, 0.0728, 0.1341, 0.1681, 0.1013, 0.1435, 0.1205],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,363][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.1209, 0.1201, 0.1217, 0.1245, 0.1248, 0.1262, 0.1266, 0.1352],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,365][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.4146, 0.1022, 0.0619, 0.1073, 0.0454, 0.0921, 0.0349, 0.0742, 0.0675],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,367][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0557, 0.0162, 0.0374, 0.1200, 0.1119, 0.4077, 0.0261, 0.1721, 0.0528],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,369][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0647, 0.1305, 0.1067, 0.1390, 0.1338, 0.1182, 0.1175, 0.1199, 0.0698],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,370][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0555, 0.1449, 0.1298, 0.1413, 0.1507, 0.1256, 0.0957, 0.0967, 0.0597],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,372][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.1376, 0.1045, 0.0302, 0.1191, 0.0893, 0.0721, 0.1903, 0.1897, 0.0673],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,373][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.1420, 0.1129, 0.1028, 0.1033, 0.1132, 0.1129, 0.1062, 0.1036, 0.1031],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,373][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0537, 0.1024, 0.0211, 0.1039, 0.0163, 0.2718, 0.0737, 0.3177, 0.0394],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,374][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.1680, 0.1141, 0.1002, 0.1086, 0.1224, 0.1121, 0.0864, 0.0953, 0.0929],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,375][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ going] are: tensor([4.1735e-02, 4.9862e-03, 8.2496e-04, 1.8185e-02, 5.2534e-04, 4.6445e-03,
        3.3625e-02, 8.0989e-01, 8.5584e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,376][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0931, 0.0812, 0.0657, 0.0781, 0.0557, 0.1937, 0.1607, 0.1278, 0.1439],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,378][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.1639, 0.0708, 0.0555, 0.1087, 0.1478, 0.0633, 0.1767, 0.1052, 0.1080],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,380][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.1051, 0.1045, 0.1059, 0.1113, 0.1116, 0.1111, 0.1120, 0.1194, 0.1191],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,382][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3188, 0.0923, 0.0658, 0.0932, 0.0531, 0.0839, 0.0396, 0.0775, 0.0520,
        0.1237], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,383][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0894, 0.0249, 0.0472, 0.1001, 0.0904, 0.3178, 0.0292, 0.0496, 0.0460,
        0.2054], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,385][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0516, 0.1151, 0.0974, 0.1198, 0.1251, 0.1115, 0.1088, 0.1039, 0.0820,
        0.0847], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,387][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0492, 0.1277, 0.1052, 0.1091, 0.1285, 0.1075, 0.1087, 0.0866, 0.0846,
        0.0928], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,389][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2501, 0.0436, 0.0333, 0.0999, 0.0275, 0.0573, 0.0651, 0.1985, 0.0683,
        0.1565], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,390][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1299, 0.1024, 0.0932, 0.0936, 0.1027, 0.1025, 0.0963, 0.0939, 0.0935,
        0.0921], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,390][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1024, 0.3811, 0.0164, 0.0737, 0.0350, 0.0487, 0.0782, 0.0914, 0.1483,
        0.0248], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,391][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1520, 0.1059, 0.0925, 0.0995, 0.1122, 0.1025, 0.0792, 0.0867, 0.0839,
        0.0855], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,392][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0204, 0.0012, 0.0009, 0.0185, 0.0009, 0.0034, 0.0182, 0.4317, 0.1072,
        0.3976], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,393][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0744, 0.0768, 0.0657, 0.0718, 0.0730, 0.1176, 0.1838, 0.0882, 0.1984,
        0.0503], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,394][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0947, 0.0953, 0.0678, 0.1058, 0.1839, 0.0675, 0.1371, 0.0839, 0.0810,
        0.0829], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,396][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0936, 0.0916, 0.0935, 0.1008, 0.1000, 0.0980, 0.1008, 0.1059, 0.1077,
        0.1081], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,398][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2936, 0.0807, 0.0603, 0.0855, 0.0476, 0.0814, 0.0343, 0.0627, 0.0434,
        0.0929, 0.1176], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,399][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1923, 0.0154, 0.0429, 0.0461, 0.0471, 0.1405, 0.0167, 0.0244, 0.0282,
        0.1770, 0.2693], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,401][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0468, 0.1024, 0.0841, 0.1058, 0.1048, 0.0981, 0.0952, 0.0894, 0.0704,
        0.0890, 0.1139], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,403][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0433, 0.1180, 0.0980, 0.0984, 0.1180, 0.0959, 0.0847, 0.0797, 0.0652,
        0.0975, 0.1014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,405][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2910, 0.0580, 0.0406, 0.0859, 0.0313, 0.0481, 0.0542, 0.1207, 0.0575,
        0.0969, 0.1160], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,407][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1183, 0.0936, 0.0851, 0.0855, 0.0938, 0.0936, 0.0880, 0.0857, 0.0857,
        0.0847, 0.0860], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,408][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0545, 0.0987, 0.0170, 0.0612, 0.0394, 0.0461, 0.1310, 0.0865, 0.1583,
        0.2931, 0.0141], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,408][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1386, 0.0973, 0.0859, 0.0920, 0.1039, 0.0942, 0.0737, 0.0808, 0.0779,
        0.0795, 0.0761], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,409][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([6.4937e-02, 9.8294e-04, 1.5396e-04, 3.4089e-03, 1.1463e-04, 4.5892e-04,
        4.7826e-03, 1.2025e-01, 2.1843e-02, 1.3672e-01, 6.4636e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,410][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0798, 0.0681, 0.0600, 0.0684, 0.0716, 0.1125, 0.1729, 0.0937, 0.1428,
        0.0823, 0.0481], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,411][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1809, 0.0487, 0.0584, 0.0743, 0.1537, 0.0620, 0.1224, 0.0702, 0.0831,
        0.0626, 0.0837], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,413][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0842, 0.0819, 0.0851, 0.0906, 0.0903, 0.0885, 0.0904, 0.0956, 0.0969,
        0.0985, 0.0981], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,415][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.3454, 0.0839, 0.0490, 0.0850, 0.0339, 0.0671, 0.0226, 0.0554, 0.0332,
        0.0974, 0.1005, 0.0267], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,417][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0664, 0.0012, 0.0255, 0.0125, 0.0280, 0.1181, 0.0060, 0.0161, 0.0099,
        0.1193, 0.3471, 0.2499], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,418][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0360, 0.0986, 0.0710, 0.1025, 0.1039, 0.0805, 0.0782, 0.0928, 0.0604,
        0.0806, 0.1301, 0.0655], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,420][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0302, 0.1044, 0.0984, 0.0935, 0.1229, 0.0806, 0.0824, 0.0719, 0.0552,
        0.0910, 0.1039, 0.0658], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,422][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0790, 0.0857, 0.0507, 0.0838, 0.0803, 0.0630, 0.0501, 0.1628, 0.0884,
        0.0941, 0.1203, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,424][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.1073, 0.0853, 0.0784, 0.0786, 0.0857, 0.0852, 0.0803, 0.0788, 0.0788,
        0.0781, 0.0792, 0.0843], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,425][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0243, 0.1971, 0.0068, 0.0420, 0.0238, 0.0759, 0.0798, 0.1527, 0.1088,
        0.2431, 0.0188, 0.0269], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,426][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.1349, 0.0881, 0.0775, 0.0841, 0.0947, 0.0864, 0.0672, 0.0755, 0.0729,
        0.0746, 0.0714, 0.0726], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,427][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ school] are: tensor([6.2110e-04, 5.1566e-04, 3.4317e-04, 2.1250e-03, 1.6737e-04, 7.0380e-04,
        7.4325e-03, 1.8415e-01, 2.0188e-02, 9.5544e-02, 6.8528e-01, 2.9264e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,428][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0922, 0.0796, 0.0902, 0.0817, 0.0724, 0.0965, 0.0836, 0.0869, 0.1157,
        0.0674, 0.0629, 0.0708], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,429][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.1126, 0.0523, 0.0449, 0.0858, 0.1168, 0.0692, 0.0944, 0.0693, 0.0610,
        0.0703, 0.0722, 0.1513], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,430][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.0773, 0.0756, 0.0784, 0.0845, 0.0826, 0.0812, 0.0816, 0.0848, 0.0868,
        0.0884, 0.0874, 0.0916], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,432][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.2299, 0.0751, 0.0601, 0.0796, 0.0441, 0.0685, 0.0311, 0.0553, 0.0419,
        0.0869, 0.0958, 0.0299, 0.1017], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,434][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0731, 0.0456, 0.0497, 0.0489, 0.0551, 0.1421, 0.0298, 0.0462, 0.0157,
        0.1118, 0.1721, 0.1216, 0.0883], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,435][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0406, 0.0901, 0.0665, 0.0886, 0.0895, 0.0782, 0.0774, 0.0841, 0.0624,
        0.0744, 0.1144, 0.0685, 0.0652], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,437][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0383, 0.0984, 0.0788, 0.0797, 0.0936, 0.0792, 0.0797, 0.0655, 0.0548,
        0.0812, 0.0988, 0.0653, 0.0868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,439][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2451, 0.0417, 0.0415, 0.0789, 0.0306, 0.0390, 0.0305, 0.1174, 0.0474,
        0.0884, 0.0989, 0.0398, 0.1008], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,441][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0969, 0.0786, 0.0725, 0.0727, 0.0791, 0.0786, 0.0744, 0.0726, 0.0728,
        0.0719, 0.0729, 0.0776, 0.0795], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,443][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0212, 0.0560, 0.0059, 0.0496, 0.0018, 0.0416, 0.0117, 0.1057, 0.0621,
        0.1589, 0.4444, 0.0328, 0.0084], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,444][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1169, 0.0836, 0.0752, 0.0803, 0.0898, 0.0810, 0.0646, 0.0710, 0.0685,
        0.0697, 0.0666, 0.0691, 0.0637], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,444][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([3.7223e-03, 4.9547e-04, 1.0573e-04, 1.5741e-03, 4.7293e-05, 2.9611e-04,
        2.2422e-03, 1.4626e-01, 1.3509e-02, 1.2149e-01, 6.8409e-01, 2.4762e-03,
        2.3700e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,445][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0632, 0.0594, 0.0724, 0.0696, 0.0703, 0.0897, 0.1142, 0.0755, 0.1053,
        0.0650, 0.0649, 0.0983, 0.0522], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,446][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1308, 0.0897, 0.0490, 0.0768, 0.1285, 0.0586, 0.1062, 0.0569, 0.0603,
        0.0439, 0.0587, 0.0760, 0.0647], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,447][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0690, 0.0668, 0.0702, 0.0744, 0.0742, 0.0727, 0.0757, 0.0789, 0.0810,
        0.0826, 0.0840, 0.0893, 0.0811], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,449][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.3157, 0.0661, 0.0346, 0.0588, 0.0737, 0.0574, 0.0158, 0.0369, 0.0251,
        0.0732, 0.0795, 0.0146, 0.0813, 0.0673], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,451][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0821, 0.0012, 0.0081, 0.0172, 0.0093, 0.1681, 0.0047, 0.0121, 0.0027,
        0.0504, 0.1696, 0.0860, 0.2286, 0.1600], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,453][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0322, 0.0811, 0.0645, 0.0859, 0.0822, 0.0716, 0.0722, 0.0785, 0.0530,
        0.0700, 0.1156, 0.0636, 0.0671, 0.0626], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,454][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0231, 0.0930, 0.0903, 0.0793, 0.0693, 0.0700, 0.0729, 0.0600, 0.0503,
        0.0821, 0.0909, 0.0699, 0.0896, 0.0594], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,457][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0053, 0.0553, 0.0090, 0.1017, 0.0099, 0.0574, 0.0394, 0.1022, 0.1344,
        0.0809, 0.1104, 0.1119, 0.1534, 0.0289], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,458][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0884, 0.0728, 0.0682, 0.0679, 0.0732, 0.0727, 0.0686, 0.0680, 0.0673,
        0.0665, 0.0671, 0.0714, 0.0729, 0.0749], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,460][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0411, 0.2272, 0.0054, 0.0863, 0.0018, 0.0634, 0.0448, 0.1801, 0.0576,
        0.1570, 0.0572, 0.0371, 0.0365, 0.0047], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,462][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.1077, 0.0762, 0.0676, 0.0718, 0.0796, 0.0731, 0.0611, 0.0659, 0.0642,
        0.0645, 0.0621, 0.0653, 0.0600, 0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,463][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([7.7640e-04, 6.6918e-04, 4.1433e-04, 5.2829e-03, 1.5760e-04, 2.0623e-03,
        2.6407e-02, 2.4097e-01, 2.2508e-02, 7.6462e-02, 4.8168e-01, 6.3356e-03,
        1.3355e-01, 2.7231e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,463][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0666, 0.0591, 0.0762, 0.0747, 0.0612, 0.0771, 0.0890, 0.0721, 0.0706,
        0.0717, 0.0695, 0.0855, 0.0608, 0.0660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,464][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0507, 0.0412, 0.0485, 0.0721, 0.0944, 0.0666, 0.1160, 0.0523, 0.0605,
        0.0526, 0.0528, 0.1052, 0.0678, 0.1192], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,465][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0629, 0.0628, 0.0667, 0.0696, 0.0688, 0.0681, 0.0691, 0.0722, 0.0741,
        0.0761, 0.0768, 0.0802, 0.0737, 0.0788], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,467][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.2801, 0.0668, 0.0436, 0.0712, 0.0288, 0.0614, 0.0246, 0.0505, 0.0334,
        0.0869, 0.0783, 0.0170, 0.0884, 0.0269, 0.0421], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,468][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0597, 0.0052, 0.0114, 0.0303, 0.0114, 0.1250, 0.0111, 0.0189, 0.0053,
        0.0680, 0.1676, 0.0441, 0.1642, 0.2090, 0.0689], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,470][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0365, 0.0728, 0.0643, 0.0771, 0.0862, 0.0685, 0.0685, 0.0718, 0.0487,
        0.0680, 0.1060, 0.0611, 0.0598, 0.0689, 0.0420], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,472][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0294, 0.0804, 0.0725, 0.0795, 0.0882, 0.0715, 0.0598, 0.0567, 0.0356,
        0.0758, 0.0781, 0.0660, 0.0898, 0.0777, 0.0390], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,473][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.2395, 0.0550, 0.0261, 0.0472, 0.0140, 0.0393, 0.0358, 0.1532, 0.0716,
        0.0662, 0.0969, 0.0442, 0.0773, 0.0167, 0.0170], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,475][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0875, 0.0685, 0.0622, 0.0627, 0.0689, 0.0686, 0.0645, 0.0630, 0.0634,
        0.0626, 0.0636, 0.0677, 0.0701, 0.0711, 0.0557], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,477][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0411, 0.1066, 0.0136, 0.0863, 0.0437, 0.0285, 0.0220, 0.0930, 0.0832,
        0.1181, 0.1542, 0.0878, 0.0223, 0.0671, 0.0324], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,479][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.1058, 0.0721, 0.0642, 0.0697, 0.0777, 0.0708, 0.0550, 0.0611, 0.0588,
        0.0607, 0.0583, 0.0590, 0.0562, 0.0776, 0.0531], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,480][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([6.6863e-04, 1.2650e-03, 5.0216e-04, 3.9757e-03, 1.5455e-04, 1.1273e-03,
        1.4789e-02, 2.2752e-01, 1.3872e-02, 4.4731e-02, 6.0765e-01, 1.7316e-03,
        7.5168e-02, 3.6403e-03, 3.2090e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,481][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0826, 0.0574, 0.0650, 0.0562, 0.0430, 0.0899, 0.1133, 0.0569, 0.0713,
        0.0515, 0.0454, 0.0654, 0.0481, 0.0424, 0.1116], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,482][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0541, 0.0434, 0.0332, 0.0595, 0.0797, 0.0510, 0.0808, 0.0562, 0.0527,
        0.0515, 0.0449, 0.0806, 0.0620, 0.0921, 0.1582], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,482][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0604, 0.0597, 0.0625, 0.0640, 0.0645, 0.0640, 0.0637, 0.0679, 0.0683,
        0.0698, 0.0701, 0.0728, 0.0685, 0.0729, 0.0711], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,484][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2083, 0.0622, 0.0451, 0.0621, 0.0364, 0.0555, 0.0267, 0.0508, 0.0349,
        0.0826, 0.0759, 0.0221, 0.0823, 0.0337, 0.0322, 0.0894],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,486][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0521, 0.0040, 0.0153, 0.0174, 0.0141, 0.1091, 0.0060, 0.0096, 0.0044,
        0.0377, 0.0680, 0.0465, 0.1011, 0.1809, 0.1114, 0.2222],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,488][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0303, 0.0703, 0.0619, 0.0741, 0.0801, 0.0696, 0.0681, 0.0649, 0.0521,
        0.0519, 0.0964, 0.0592, 0.0575, 0.0664, 0.0515, 0.0456],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,489][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0294, 0.0780, 0.0685, 0.0655, 0.0811, 0.0652, 0.0663, 0.0513, 0.0509,
        0.0548, 0.0763, 0.0556, 0.0800, 0.0720, 0.0549, 0.0501],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,491][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2096, 0.0446, 0.0304, 0.0675, 0.0235, 0.0399, 0.0341, 0.1216, 0.0509,
        0.0794, 0.0718, 0.0389, 0.0753, 0.0221, 0.0248, 0.0656],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,493][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0828, 0.0649, 0.0593, 0.0595, 0.0654, 0.0650, 0.0612, 0.0596, 0.0600,
        0.0590, 0.0600, 0.0640, 0.0663, 0.0674, 0.0531, 0.0526],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,495][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0468, 0.1453, 0.0055, 0.0405, 0.0118, 0.0206, 0.0293, 0.0452, 0.0654,
        0.0102, 0.2187, 0.1090, 0.0189, 0.0393, 0.1702, 0.0234],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,497][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1007, 0.0698, 0.0618, 0.0665, 0.0747, 0.0676, 0.0527, 0.0575, 0.0553,
        0.0570, 0.0549, 0.0553, 0.0527, 0.0740, 0.0498, 0.0495],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,498][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.1812e-03, 5.5643e-04, 2.2609e-04, 3.2870e-03, 1.6548e-04, 6.0314e-04,
        7.6422e-03, 1.0143e-01, 1.5057e-02, 5.7365e-02, 6.2856e-01, 3.4469e-03,
        4.4428e-02, 5.5216e-03, 3.7802e-03, 1.1875e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,499][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0449, 0.0430, 0.0454, 0.0449, 0.0481, 0.0778, 0.1087, 0.0530, 0.1210,
        0.0322, 0.0404, 0.0582, 0.0378, 0.0519, 0.1617, 0.0310],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,500][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0438, 0.0484, 0.0412, 0.0588, 0.0988, 0.0453, 0.0865, 0.0464, 0.0460,
        0.0418, 0.0489, 0.0636, 0.0616, 0.1061, 0.1062, 0.0567],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,500][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0567, 0.0542, 0.0569, 0.0603, 0.0598, 0.0584, 0.0601, 0.0628, 0.0649,
        0.0650, 0.0659, 0.0702, 0.0631, 0.0680, 0.0673, 0.0663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,502][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2056, 0.0615, 0.0340, 0.0659, 0.0323, 0.0478, 0.0215, 0.0468, 0.0324,
        0.0837, 0.0707, 0.0170, 0.0793, 0.0296, 0.0291, 0.0902, 0.0526],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,504][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0213, 0.0018, 0.0116, 0.0070, 0.0121, 0.0557, 0.0062, 0.0072, 0.0029,
        0.0384, 0.0587, 0.0461, 0.1137, 0.2448, 0.0903, 0.1896, 0.0927],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,506][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0306, 0.0680, 0.0565, 0.0681, 0.0708, 0.0594, 0.0607, 0.0675, 0.0445,
        0.0642, 0.0980, 0.0530, 0.0581, 0.0583, 0.0434, 0.0572, 0.0417],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,507][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0267, 0.0762, 0.0716, 0.0718, 0.0697, 0.0612, 0.0525, 0.0520, 0.0365,
        0.0699, 0.0715, 0.0467, 0.0776, 0.0611, 0.0436, 0.0644, 0.0469],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,509][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1314, 0.0846, 0.0334, 0.0674, 0.0373, 0.0711, 0.0411, 0.0740, 0.0433,
        0.0493, 0.0916, 0.0552, 0.0711, 0.0388, 0.0341, 0.0545, 0.0218],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,511][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0758, 0.0612, 0.0563, 0.0562, 0.0610, 0.0608, 0.0574, 0.0563, 0.0566,
        0.0559, 0.0566, 0.0602, 0.0615, 0.0628, 0.0508, 0.0505, 0.0602],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,513][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0048, 0.0366, 0.0023, 0.0217, 0.0038, 0.0110, 0.0118, 0.0645, 0.0248,
        0.1629, 0.1041, 0.0346, 0.0157, 0.0116, 0.0997, 0.3867, 0.0034],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,515][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0925, 0.0636, 0.0574, 0.0610, 0.0683, 0.0620, 0.0501, 0.0546, 0.0531,
        0.0541, 0.0522, 0.0540, 0.0504, 0.0692, 0.0489, 0.0481, 0.0605],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,516][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([8.6658e-03, 2.2410e-03, 2.9355e-04, 3.2704e-03, 1.6329e-04, 6.3617e-04,
        1.2342e-02, 1.2855e-01, 1.2715e-02, 6.0660e-02, 5.0525e-01, 2.0415e-03,
        7.4563e-02, 6.3744e-03, 5.8198e-03, 1.3638e-01, 4.0041e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,517][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0494, 0.0456, 0.0520, 0.0422, 0.0447, 0.0727, 0.0890, 0.0465, 0.0602,
        0.0582, 0.0425, 0.0630, 0.0410, 0.0465, 0.1233, 0.0592, 0.0641],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,517][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0337, 0.0284, 0.0338, 0.0486, 0.0897, 0.0460, 0.0676, 0.0398, 0.0461,
        0.0400, 0.0390, 0.0791, 0.0489, 0.0941, 0.1367, 0.0526, 0.0760],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,518][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0533, 0.0521, 0.0542, 0.0566, 0.0570, 0.0557, 0.0560, 0.0589, 0.0602,
        0.0610, 0.0612, 0.0642, 0.0588, 0.0634, 0.0616, 0.0618, 0.0640],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,520][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1925, 0.0542, 0.0451, 0.0572, 0.0320, 0.0522, 0.0204, 0.0427, 0.0286,
        0.0660, 0.0722, 0.0188, 0.0737, 0.0289, 0.0256, 0.0725, 0.0298, 0.0876],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,522][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0521, 0.0125, 0.0227, 0.0206, 0.0132, 0.1380, 0.0111, 0.0166, 0.0055,
        0.0539, 0.0452, 0.0343, 0.1125, 0.0732, 0.0685, 0.1747, 0.1087, 0.0367],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,524][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0293, 0.0638, 0.0547, 0.0683, 0.0675, 0.0654, 0.0605, 0.0562, 0.0431,
        0.0551, 0.0802, 0.0512, 0.0547, 0.0551, 0.0444, 0.0492, 0.0476, 0.0536],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,525][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0265, 0.0750, 0.0602, 0.0620, 0.0638, 0.0606, 0.0553, 0.0479, 0.0403,
        0.0606, 0.0655, 0.0530, 0.0702, 0.0553, 0.0418, 0.0556, 0.0584, 0.0480],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,527][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1611, 0.0462, 0.0285, 0.0571, 0.0416, 0.0313, 0.0352, 0.0912, 0.0363,
        0.0591, 0.0726, 0.0430, 0.0722, 0.0484, 0.0218, 0.0616, 0.0324, 0.0607],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,529][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0725, 0.0579, 0.0528, 0.0529, 0.0578, 0.0576, 0.0544, 0.0531, 0.0533,
        0.0526, 0.0534, 0.0569, 0.0585, 0.0597, 0.0477, 0.0474, 0.0571, 0.0542],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,531][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0334, 0.0208, 0.0015, 0.0305, 0.0046, 0.0323, 0.0173, 0.0212, 0.0170,
        0.0982, 0.0093, 0.2183, 0.0842, 0.0220, 0.1068, 0.2395, 0.0408, 0.0024],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,533][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0855, 0.0608, 0.0548, 0.0577, 0.0648, 0.0586, 0.0481, 0.0518, 0.0502,
        0.0509, 0.0490, 0.0508, 0.0472, 0.0648, 0.0458, 0.0449, 0.0568, 0.0574],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,534][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.1875e-02, 6.3794e-04, 7.6783e-05, 1.1540e-03, 3.1876e-05, 1.3613e-04,
        3.4405e-03, 7.5970e-02, 7.4079e-03, 4.8134e-02, 2.8150e-01, 1.6804e-03,
        1.5171e-02, 1.9982e-03, 1.1334e-03, 6.9044e-02, 2.8368e-02, 4.4224e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,535][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0491, 0.0393, 0.0344, 0.0418, 0.0375, 0.0641, 0.0947, 0.0543, 0.0712,
        0.0465, 0.0284, 0.0686, 0.0332, 0.0411, 0.1046, 0.0448, 0.1204, 0.0261],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,535][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0465, 0.0287, 0.0340, 0.0446, 0.1015, 0.0400, 0.0621, 0.0374, 0.0385,
        0.0323, 0.0388, 0.0636, 0.0475, 0.1189, 0.0919, 0.0434, 0.0509, 0.0793],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,536][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0495, 0.0475, 0.0501, 0.0536, 0.0530, 0.0514, 0.0529, 0.0550, 0.0572,
        0.0579, 0.0580, 0.0619, 0.0550, 0.0597, 0.0587, 0.0586, 0.0617, 0.0583],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,538][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.2490, 0.0565, 0.0327, 0.0579, 0.0243, 0.0389, 0.0172, 0.0357, 0.0240,
        0.0640, 0.0756, 0.0143, 0.0797, 0.0229, 0.0175, 0.0722, 0.0263, 0.0610,
        0.0302], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,540][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0675, 0.0039, 0.0199, 0.0123, 0.0064, 0.2044, 0.0070, 0.0132, 0.0025,
        0.0358, 0.0512, 0.0115, 0.1081, 0.0492, 0.0530, 0.1421, 0.0743, 0.0537,
        0.0837], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,542][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0261, 0.0642, 0.0480, 0.0645, 0.0674, 0.0508, 0.0503, 0.0575, 0.0435,
        0.0532, 0.0838, 0.0453, 0.0498, 0.0521, 0.0376, 0.0466, 0.0438, 0.0664,
        0.0491], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,543][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0226, 0.0677, 0.0735, 0.0543, 0.0794, 0.0466, 0.0473, 0.0448, 0.0310,
        0.0547, 0.0628, 0.0505, 0.0601, 0.0687, 0.0361, 0.0493, 0.0489, 0.0542,
        0.0474], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,546][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0967, 0.0758, 0.0607, 0.0718, 0.0300, 0.0429, 0.0271, 0.0682, 0.1063,
        0.0653, 0.0624, 0.0441, 0.0644, 0.0280, 0.0157, 0.0537, 0.0349, 0.0435,
        0.0084], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,548][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0687, 0.0553, 0.0508, 0.0505, 0.0550, 0.0548, 0.0514, 0.0506, 0.0504,
        0.0499, 0.0505, 0.0540, 0.0551, 0.0567, 0.0455, 0.0450, 0.0543, 0.0517,
        0.0498], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,550][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0106, 0.0143, 0.0041, 0.0277, 0.0083, 0.0281, 0.0426, 0.1155, 0.0430,
        0.1204, 0.0286, 0.0589, 0.0040, 0.0231, 0.0796, 0.2510, 0.0657, 0.0308,
        0.0438], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,551][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0874, 0.0576, 0.0508, 0.0549, 0.0617, 0.0562, 0.0445, 0.0495, 0.0474,
        0.0484, 0.0466, 0.0471, 0.0452, 0.0631, 0.0432, 0.0428, 0.0543, 0.0553,
        0.0440], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,552][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([9.3811e-04, 5.1988e-04, 4.4134e-05, 1.0728e-03, 2.3491e-05, 1.6496e-04,
        3.3788e-03, 1.0154e-01, 5.9175e-03, 4.1237e-02, 2.9052e-01, 8.8950e-04,
        2.6918e-02, 9.4300e-04, 1.5714e-03, 5.6181e-02, 2.3532e-02, 4.4088e-01,
        3.7316e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,553][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0586, 0.0427, 0.0512, 0.0422, 0.0402, 0.0554, 0.0609, 0.0464, 0.0684,
        0.0423, 0.0352, 0.0613, 0.0354, 0.0439, 0.0890, 0.0426, 0.0796, 0.0355,
        0.0694], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,554][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0364, 0.0327, 0.0328, 0.0450, 0.0781, 0.0452, 0.0656, 0.0397, 0.0375,
        0.0351, 0.0335, 0.0707, 0.0414, 0.1046, 0.0859, 0.0437, 0.0694, 0.0644,
        0.0383], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,555][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0479, 0.0457, 0.0474, 0.0509, 0.0498, 0.0491, 0.0499, 0.0513, 0.0537,
        0.0545, 0.0542, 0.0579, 0.0512, 0.0554, 0.0544, 0.0547, 0.0573, 0.0547,
        0.0599], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,557][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1640, 0.0507, 0.0364, 0.0510, 0.0286, 0.0451, 0.0221, 0.0424, 0.0288,
        0.0680, 0.0623, 0.0181, 0.0673, 0.0268, 0.0266, 0.0736, 0.0307, 0.0598,
        0.0221, 0.0755], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,559][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0475, 0.0060, 0.0226, 0.0167, 0.0084, 0.1221, 0.0057, 0.0084, 0.0021,
        0.0237, 0.0361, 0.0141, 0.0799, 0.0460, 0.0436, 0.0934, 0.0542, 0.0338,
        0.0818, 0.2539], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,561][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0235, 0.0562, 0.0501, 0.0593, 0.0649, 0.0562, 0.0548, 0.0521, 0.0420,
        0.0412, 0.0775, 0.0484, 0.0461, 0.0538, 0.0415, 0.0362, 0.0460, 0.0590,
        0.0560, 0.0352], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,563][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0222, 0.0628, 0.0572, 0.0523, 0.0662, 0.0533, 0.0548, 0.0412, 0.0413,
        0.0434, 0.0622, 0.0458, 0.0651, 0.0586, 0.0449, 0.0397, 0.0510, 0.0500,
        0.0494, 0.0385], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,565][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1323, 0.0340, 0.0215, 0.0581, 0.0219, 0.0298, 0.0294, 0.1149, 0.0518,
        0.0772, 0.0589, 0.0338, 0.0616, 0.0229, 0.0201, 0.0622, 0.0241, 0.0444,
        0.0150, 0.0863], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,567][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0667, 0.0526, 0.0479, 0.0479, 0.0524, 0.0521, 0.0490, 0.0482, 0.0482,
        0.0476, 0.0482, 0.0516, 0.0528, 0.0542, 0.0428, 0.0424, 0.0516, 0.0488,
        0.0471, 0.0479], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,569][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0416, 0.0601, 0.0040, 0.0261, 0.0086, 0.0146, 0.0221, 0.0380, 0.0525,
        0.0075, 0.1605, 0.0851, 0.0123, 0.0295, 0.1419, 0.0168, 0.0165, 0.0737,
        0.1684, 0.0202], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,570][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0763, 0.0550, 0.0506, 0.0539, 0.0601, 0.0535, 0.0437, 0.0472, 0.0458,
        0.0470, 0.0449, 0.0468, 0.0429, 0.0585, 0.0417, 0.0409, 0.0518, 0.0525,
        0.0443, 0.0424], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,571][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.7973e-03, 2.9099e-04, 2.9852e-05, 9.4266e-04, 2.1546e-05, 8.7460e-05,
        1.8921e-03, 2.9898e-02, 3.6543e-03, 1.7294e-02, 1.7493e-01, 9.3168e-04,
        1.0033e-02, 1.1340e-03, 7.3106e-04, 2.8863e-02, 1.2567e-02, 2.6442e-01,
        4.1619e-03, 4.4033e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,572][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0385, 0.0361, 0.0345, 0.0386, 0.0389, 0.0587, 0.0887, 0.0441, 0.0838,
        0.0276, 0.0339, 0.0500, 0.0331, 0.0423, 0.1196, 0.0265, 0.0923, 0.0327,
        0.0531, 0.0272], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,573][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0367, 0.0335, 0.0282, 0.0447, 0.0759, 0.0354, 0.0682, 0.0362, 0.0359,
        0.0299, 0.0389, 0.0518, 0.0478, 0.0927, 0.0888, 0.0442, 0.0541, 0.0805,
        0.0279, 0.0486], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,574][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0445, 0.0427, 0.0448, 0.0481, 0.0473, 0.0459, 0.0474, 0.0490, 0.0512,
        0.0512, 0.0515, 0.0553, 0.0481, 0.0522, 0.0518, 0.0511, 0.0551, 0.0516,
        0.0580, 0.0531], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,622][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:43,624][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,625][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,626][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,627][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,628][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,629][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,629][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,630][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,631][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,631][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,632][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,633][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:43,633][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5010, 0.4990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,634][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5334, 0.4666], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,635][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2975, 0.7025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,635][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1451, 0.8549], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,636][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8572, 0.1428], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,637][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7053, 0.2947], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,637][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0278, 0.9722], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,639][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9757, 0.0243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,640][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1428, 0.8572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,641][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2217, 0.7783], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,641][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5926, 0.4074], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,642][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1621, 0.8379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:43,643][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3474, 0.3390, 0.3136], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,644][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.3351, 0.3679, 0.2970], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,646][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.1669, 0.4285, 0.4046], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,647][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0865, 0.6037, 0.3098], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,648][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.9349, 0.0297, 0.0353], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,649][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.4988, 0.2331, 0.2682], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,649][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0019, 0.0875, 0.9106], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,650][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.8663, 0.1132, 0.0205], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,651][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.1312, 0.3697, 0.4991], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,652][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0515, 0.4451, 0.5034], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,654][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.4237, 0.2930, 0.2833], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,655][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0348, 0.7478, 0.2173], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:43,657][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2568, 0.2534, 0.2349, 0.2549], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,658][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2637, 0.2699, 0.2587, 0.2077], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,660][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1112, 0.2510, 0.2378, 0.4001], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,662][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0938, 0.4117, 0.2572, 0.2373], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,664][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7905, 0.0708, 0.0840, 0.0548], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,665][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4218, 0.1802, 0.2089, 0.1891], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,666][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0036, 0.0967, 0.8144, 0.0853], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,667][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.8740, 0.0414, 0.0233, 0.0613], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,667][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0199, 0.0229, 0.1457, 0.8115], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,668][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0491, 0.2629, 0.2498, 0.4382], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,669][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3241, 0.2500, 0.2469, 0.1789], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,671][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0050, 0.7949, 0.1256, 0.0744], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:43,673][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.2071, 0.1976, 0.1841, 0.1912, 0.2199], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,674][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.1888, 0.2278, 0.2137, 0.2235, 0.1463], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,676][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0811, 0.1781, 0.1709, 0.3002, 0.2698], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,678][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0538, 0.3147, 0.1853, 0.1803, 0.2660], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,680][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.7484, 0.0478, 0.0857, 0.0398, 0.0783], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,682][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.3186, 0.1572, 0.1775, 0.1756, 0.1711], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,683][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0013, 0.0771, 0.7590, 0.0351, 0.1275], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,684][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.8474, 0.0471, 0.0148, 0.0779, 0.0128], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,685][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0673, 0.0073, 0.0560, 0.5878, 0.2816], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,686][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0150, 0.1913, 0.1475, 0.4115, 0.2347], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,686][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2721, 0.1943, 0.1824, 0.1360, 0.2152], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,687][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0353, 0.4458, 0.3064, 0.0645, 0.1480], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:43,689][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1743, 0.1672, 0.1503, 0.1615, 0.1803, 0.1664], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,691][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1905, 0.1666, 0.1679, 0.1887, 0.1351, 0.1513], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,693][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0674, 0.1346, 0.1247, 0.2143, 0.1953, 0.2637], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,694][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0417, 0.2215, 0.1441, 0.1453, 0.2131, 0.2343], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,696][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.6291, 0.0601, 0.0876, 0.0492, 0.0980, 0.0761], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,698][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.2793, 0.1285, 0.1493, 0.1428, 0.1472, 0.1530], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,700][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0016, 0.0481, 0.6667, 0.0375, 0.1383, 0.1079], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,701][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.7126, 0.0409, 0.0186, 0.0590, 0.0182, 0.1508], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,702][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0207, 0.0044, 0.0117, 0.1649, 0.2674, 0.5309], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,703][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0251, 0.1529, 0.0769, 0.2507, 0.1599, 0.3344], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,704][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2249, 0.1583, 0.1545, 0.1115, 0.1823, 0.1686], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,704][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0193, 0.5151, 0.0867, 0.0639, 0.1187, 0.1962], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:43,705][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.1565, 0.1484, 0.1277, 0.1393, 0.1527, 0.1423, 0.1331],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,707][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.1521, 0.1435, 0.1287, 0.1617, 0.1009, 0.1546, 0.1585],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,709][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0406, 0.1139, 0.1061, 0.1878, 0.1773, 0.2470, 0.1272],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,711][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0379, 0.1951, 0.1061, 0.1251, 0.1635, 0.2140, 0.1583],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,712][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.5597, 0.0662, 0.1106, 0.0475, 0.0877, 0.0641, 0.0642],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,714][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.2503, 0.1105, 0.1207, 0.1211, 0.1290, 0.1420, 0.1265],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,716][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0027, 0.0434, 0.4144, 0.0391, 0.1113, 0.1018, 0.2874],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,718][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.7022, 0.0322, 0.0094, 0.0530, 0.0114, 0.1808, 0.0110],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,719][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([1.9644e-03, 2.3699e-04, 6.9195e-04, 2.3738e-02, 4.1859e-02, 8.5012e-01,
        8.1393e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,720][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0173, 0.0926, 0.1114, 0.1599, 0.1250, 0.3382, 0.1555],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,721][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.2020, 0.1410, 0.1354, 0.0986, 0.1604, 0.1473, 0.1155],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,722][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0193, 0.2205, 0.0453, 0.0197, 0.1115, 0.1521, 0.4318],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:43,722][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.1374, 0.1331, 0.1146, 0.1234, 0.1372, 0.1265, 0.1164, 0.1114],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,723][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.1355, 0.1252, 0.1013, 0.1396, 0.0884, 0.1486, 0.1710, 0.0904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,725][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0391, 0.1004, 0.0932, 0.1671, 0.1551, 0.2174, 0.1119, 0.1157],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,727][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0391, 0.1747, 0.1063, 0.1095, 0.1578, 0.1774, 0.1535, 0.0817],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,729][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.5857, 0.0620, 0.0756, 0.0433, 0.0724, 0.0671, 0.0578, 0.0360],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,731][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.2323, 0.0991, 0.1122, 0.1061, 0.1181, 0.1205, 0.1120, 0.0996],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,733][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0016, 0.0318, 0.4069, 0.0278, 0.1152, 0.0820, 0.2381, 0.0966],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,734][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.5874, 0.0329, 0.0177, 0.0567, 0.0204, 0.2062, 0.0357, 0.0431],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,736][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([2.3346e-03, 2.9992e-04, 1.3046e-03, 1.8440e-02, 2.8171e-02, 6.0258e-01,
        1.8664e-01, 1.6023e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,737][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0100, 0.0691, 0.0658, 0.1085, 0.0784, 0.2430, 0.3578, 0.0674],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,738][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.1867, 0.1286, 0.1222, 0.0863, 0.1437, 0.1326, 0.1025, 0.0974],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,739][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0016, 0.0973, 0.0168, 0.0188, 0.0581, 0.1133, 0.6725, 0.0216],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:43,740][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.1254, 0.1190, 0.1037, 0.1132, 0.1207, 0.1141, 0.1055, 0.0996, 0.0989],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,741][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.1300, 0.1031, 0.0966, 0.1264, 0.0882, 0.1254, 0.1641, 0.0982, 0.0678],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,742][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0308, 0.0804, 0.0850, 0.1482, 0.1433, 0.2020, 0.0922, 0.0991, 0.1190],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,744][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0337, 0.1556, 0.0968, 0.0978, 0.1394, 0.1732, 0.1420, 0.0825, 0.0791],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,746][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.5286, 0.0521, 0.0689, 0.0404, 0.0819, 0.0658, 0.0684, 0.0437, 0.0502],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,747][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.1983, 0.0909, 0.0988, 0.0983, 0.1043, 0.1141, 0.1007, 0.0933, 0.1012],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,749][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0017, 0.0264, 0.2384, 0.0352, 0.1177, 0.0860, 0.2443, 0.0810, 0.1693],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,751][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.7547, 0.0215, 0.0097, 0.0345, 0.0110, 0.1119, 0.0129, 0.0299, 0.0138],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,752][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([5.7335e-03, 1.0642e-05, 1.4100e-04, 1.6413e-03, 3.3882e-03, 9.7403e-02,
        4.4555e-02, 1.5017e-01, 6.9696e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,754][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0074, 0.0493, 0.0435, 0.1057, 0.0416, 0.4690, 0.1270, 0.0807, 0.0758],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,755][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1533, 0.1139, 0.1127, 0.0807, 0.1342, 0.1219, 0.0935, 0.0875, 0.1023],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,756][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0163, 0.0396, 0.0142, 0.0036, 0.0165, 0.0663, 0.5288, 0.0332, 0.2814],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:43,757][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1066, 0.1062, 0.0938, 0.1021, 0.1099, 0.1019, 0.0965, 0.0930, 0.0932,
        0.0967], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,758][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1156, 0.0928, 0.0924, 0.0970, 0.0798, 0.1191, 0.1703, 0.0958, 0.0720,
        0.0652], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,759][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0292, 0.0734, 0.0761, 0.1317, 0.1259, 0.1773, 0.0846, 0.0887, 0.1061,
        0.1070], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,760][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0364, 0.1331, 0.0927, 0.0842, 0.1304, 0.1475, 0.1275, 0.0752, 0.0762,
        0.0968], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,762][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3185, 0.0643, 0.0840, 0.0655, 0.0863, 0.0870, 0.0861, 0.0619, 0.0794,
        0.0669], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,763][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1968, 0.0836, 0.0925, 0.0866, 0.0976, 0.1004, 0.0930, 0.0831, 0.0918,
        0.0745], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,765][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0004, 0.0121, 0.1755, 0.0226, 0.1065, 0.0443, 0.2706, 0.0583, 0.2055,
        0.1043], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,767][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.8219, 0.0116, 0.0053, 0.0147, 0.0063, 0.0471, 0.0097, 0.0097, 0.0077,
        0.0661], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,769][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.8083e-03, 8.2929e-06, 8.2284e-05, 5.0814e-04, 1.3319e-03, 2.5965e-02,
        2.1528e-02, 2.2206e-02, 3.7451e-01, 5.5105e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,771][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0115, 0.0608, 0.0492, 0.1135, 0.0754, 0.2662, 0.1837, 0.0709, 0.1157,
        0.0531], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,772][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1411, 0.1035, 0.1026, 0.0738, 0.1225, 0.1125, 0.0850, 0.0812, 0.0938,
        0.0839], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,775][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0028, 0.0253, 0.0080, 0.0041, 0.0157, 0.0262, 0.3269, 0.0231, 0.5161,
        0.0518], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:43,776][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1031, 0.0983, 0.0869, 0.0947, 0.1016, 0.0930, 0.0860, 0.0823, 0.0831,
        0.0876, 0.0835], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,778][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1084, 0.0945, 0.0917, 0.0947, 0.0771, 0.0947, 0.1448, 0.0765, 0.0663,
        0.0635, 0.0878], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,779][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0288, 0.0650, 0.0669, 0.1171, 0.1100, 0.1553, 0.0727, 0.0754, 0.0919,
        0.0957, 0.1212], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,780][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0315, 0.1190, 0.0875, 0.0739, 0.1249, 0.1345, 0.1123, 0.0671, 0.0718,
        0.0979, 0.0795], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,781][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2596, 0.0621, 0.0958, 0.0653, 0.0913, 0.0777, 0.0719, 0.0544, 0.0725,
        0.0746, 0.0747], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,781][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1680, 0.0755, 0.0887, 0.0797, 0.0919, 0.0922, 0.0838, 0.0777, 0.0847,
        0.0698, 0.0879], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,782][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0005, 0.0131, 0.1774, 0.0223, 0.0863, 0.0470, 0.2216, 0.0571, 0.1660,
        0.1059, 0.1029], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,784][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.6741, 0.0164, 0.0078, 0.0189, 0.0090, 0.0671, 0.0143, 0.0144, 0.0127,
        0.0963, 0.0689], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,785][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([6.9024e-03, 6.5905e-07, 1.8718e-05, 4.4718e-05, 1.8157e-04, 3.6739e-03,
        1.0439e-03, 3.3271e-03, 9.4558e-02, 1.8400e-01, 7.0625e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,787][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0147, 0.0536, 0.0495, 0.1080, 0.0839, 0.2532, 0.1680, 0.0720, 0.0758,
        0.0913, 0.0300], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,789][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1293, 0.0956, 0.0951, 0.0673, 0.1131, 0.1027, 0.0782, 0.0735, 0.0865,
        0.0763, 0.0825], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,790][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0220, 0.0144, 0.0116, 0.0021, 0.0215, 0.0340, 0.1754, 0.0169, 0.3140,
        0.1385, 0.2495], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:43,792][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.0947, 0.0895, 0.0813, 0.0872, 0.0961, 0.0873, 0.0784, 0.0748, 0.0757,
        0.0820, 0.0758, 0.0774], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,794][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0824, 0.0981, 0.0727, 0.0967, 0.0713, 0.1068, 0.1075, 0.0871, 0.0649,
        0.0696, 0.0975, 0.0453], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,796][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.0229, 0.0553, 0.0602, 0.1053, 0.1004, 0.1433, 0.0636, 0.0684, 0.0807,
        0.0850, 0.1118, 0.1033], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,797][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.0223, 0.1112, 0.0707, 0.0692, 0.0994, 0.1201, 0.1018, 0.0652, 0.0629,
        0.0922, 0.0739, 0.1109], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,798][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.3883, 0.0729, 0.0778, 0.0477, 0.0755, 0.0644, 0.0549, 0.0388, 0.0445,
        0.0424, 0.0450, 0.0478], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,798][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.1547, 0.0685, 0.0814, 0.0739, 0.0836, 0.0865, 0.0799, 0.0727, 0.0815,
        0.0641, 0.0817, 0.0717], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,799][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0013, 0.0081, 0.0487, 0.0131, 0.0312, 0.0204, 0.0796, 0.0176, 0.0761,
        0.0341, 0.0328, 0.6370], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,800][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.6707, 0.0151, 0.0033, 0.0210, 0.0047, 0.0789, 0.0049, 0.0209, 0.0077,
        0.0855, 0.0832, 0.0040], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,801][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([3.0545e-03, 4.5273e-08, 5.0104e-06, 4.6670e-06, 2.4334e-05, 5.7375e-04,
        1.3495e-04, 4.5912e-04, 1.6557e-02, 3.0360e-02, 2.9700e-01, 6.5182e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,803][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0077, 0.0772, 0.0798, 0.1340, 0.0958, 0.2171, 0.0755, 0.0661, 0.0766,
        0.0805, 0.0403, 0.0495], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,805][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.1169, 0.0897, 0.0878, 0.0631, 0.1057, 0.0941, 0.0713, 0.0672, 0.0775,
        0.0691, 0.0743, 0.0832], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,806][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([2.1214e-02, 2.1148e-03, 1.3839e-03, 1.0859e-04, 1.6601e-03, 5.0023e-03,
        1.1637e-02, 1.4504e-03, 1.9079e-02, 1.3094e-02, 7.3108e-02, 8.5015e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:43,808][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0834, 0.0804, 0.0746, 0.0796, 0.0869, 0.0797, 0.0767, 0.0715, 0.0716,
        0.0733, 0.0698, 0.0731, 0.0795], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,810][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0836, 0.0744, 0.0693, 0.0729, 0.0567, 0.0841, 0.1447, 0.0847, 0.0622,
        0.0578, 0.0877, 0.0566, 0.0652], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,812][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0230, 0.0537, 0.0547, 0.0943, 0.0891, 0.1256, 0.0612, 0.0631, 0.0725,
        0.0750, 0.0979, 0.0915, 0.0985], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,813][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0285, 0.1024, 0.0696, 0.0660, 0.1029, 0.1109, 0.0942, 0.0575, 0.0593,
        0.0781, 0.0690, 0.0986, 0.0628], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,815][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2745, 0.0566, 0.0899, 0.0581, 0.0796, 0.0717, 0.0576, 0.0368, 0.0523,
        0.0556, 0.0579, 0.0562, 0.0531], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,815][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1472, 0.0636, 0.0739, 0.0677, 0.0765, 0.0788, 0.0720, 0.0674, 0.0734,
        0.0610, 0.0753, 0.0654, 0.0778], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,816][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([5.5540e-05, 3.0648e-03, 8.5251e-02, 8.6270e-03, 2.4593e-02, 1.4320e-02,
        5.1964e-02, 1.4972e-02, 4.2570e-02, 2.3401e-02, 3.1403e-02, 6.8940e-01,
        1.0379e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,817][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.5767, 0.0138, 0.0062, 0.0208, 0.0070, 0.0759, 0.0105, 0.0186, 0.0117,
        0.0983, 0.0919, 0.0139, 0.0547], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,818][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.7378e-05, 9.7070e-08, 8.5915e-07, 4.9043e-06, 1.4761e-05, 3.2572e-04,
        6.4896e-05, 2.5857e-04, 8.8059e-03, 8.8762e-03, 1.9621e-01, 7.6808e-01,
        1.7324e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,819][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0110, 0.0597, 0.0555, 0.1126, 0.0749, 0.2255, 0.0998, 0.0472, 0.0644,
        0.0644, 0.0544, 0.0651, 0.0656], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,821][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1108, 0.0805, 0.0821, 0.0563, 0.0977, 0.0883, 0.0660, 0.0629, 0.0731,
        0.0650, 0.0697, 0.0814, 0.0660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,822][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.2442e-05, 7.1517e-04, 4.1846e-04, 2.4619e-04, 6.3089e-04, 1.7570e-03,
        1.2648e-02, 6.3153e-04, 2.2094e-02, 5.6496e-03, 3.5792e-02, 9.1801e-01,
        1.3723e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:43,824][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0846, 0.0769, 0.0714, 0.0750, 0.0847, 0.0743, 0.0666, 0.0625, 0.0621,
        0.0685, 0.0640, 0.0640, 0.0718, 0.0737], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,826][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0721, 0.0785, 0.0729, 0.0780, 0.0487, 0.0883, 0.1063, 0.0774, 0.0566,
        0.0590, 0.0968, 0.0466, 0.0743, 0.0446], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,828][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0198, 0.0449, 0.0502, 0.0889, 0.0827, 0.1198, 0.0526, 0.0532, 0.0627,
        0.0668, 0.0869, 0.0800, 0.0926, 0.0988], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,830][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0157, 0.0805, 0.0580, 0.0556, 0.0763, 0.1088, 0.0879, 0.0506, 0.0584,
        0.0728, 0.0588, 0.1053, 0.0569, 0.1145], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,831][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.3400, 0.0513, 0.0950, 0.0511, 0.0684, 0.0566, 0.0636, 0.0328, 0.0389,
        0.0317, 0.0378, 0.0413, 0.0353, 0.0563], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,833][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.1265, 0.0607, 0.0691, 0.0680, 0.0668, 0.0765, 0.0689, 0.0632, 0.0687,
        0.0550, 0.0717, 0.0624, 0.0786, 0.0640], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,834][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0008, 0.0091, 0.0820, 0.0133, 0.0196, 0.0217, 0.0545, 0.0196, 0.0514,
        0.0281, 0.0254, 0.3794, 0.0133, 0.2817], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,834][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.4863, 0.0143, 0.0035, 0.0220, 0.0033, 0.0893, 0.0060, 0.0267, 0.0116,
        0.1254, 0.1075, 0.0079, 0.0706, 0.0258], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,835][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([1.9762e-03, 5.7522e-08, 1.7770e-06, 3.1636e-06, 2.4801e-06, 2.6545e-04,
        3.7349e-05, 1.3298e-04, 2.3663e-03, 6.4837e-03, 8.2204e-02, 7.4563e-01,
        3.5224e-02, 1.2568e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,836][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0055, 0.0615, 0.0565, 0.1385, 0.0857, 0.1799, 0.0794, 0.0488, 0.0319,
        0.0756, 0.0447, 0.0564, 0.0813, 0.0541], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,838][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.1025, 0.0755, 0.0755, 0.0539, 0.0919, 0.0802, 0.0596, 0.0568, 0.0646,
        0.0585, 0.0624, 0.0691, 0.0585, 0.0909], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,840][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([3.1061e-02, 1.3120e-03, 1.9819e-03, 1.9879e-04, 6.8017e-04, 3.3097e-03,
        6.1608e-03, 6.6614e-04, 1.3415e-02, 6.5762e-03, 5.7181e-02, 5.9664e-01,
        4.1999e-03, 2.7662e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:43,842][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0756, 0.0719, 0.0663, 0.0707, 0.0788, 0.0714, 0.0677, 0.0629, 0.0608,
        0.0653, 0.0595, 0.0624, 0.0678, 0.0677, 0.0510], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,843][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0839, 0.0711, 0.0708, 0.0870, 0.0484, 0.0716, 0.1068, 0.0717, 0.0481,
        0.0470, 0.0870, 0.0472, 0.0671, 0.0432, 0.0491], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,845][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0171, 0.0412, 0.0457, 0.0792, 0.0765, 0.1097, 0.0483, 0.0494, 0.0568,
        0.0609, 0.0801, 0.0739, 0.0853, 0.0931, 0.0828], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,847][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0163, 0.0795, 0.0553, 0.0573, 0.0775, 0.1039, 0.0797, 0.0458, 0.0452,
        0.0648, 0.0533, 0.0861, 0.0527, 0.1055, 0.0770], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,849][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.4949, 0.0430, 0.0426, 0.0283, 0.0443, 0.0461, 0.0480, 0.0332, 0.0333,
        0.0308, 0.0359, 0.0330, 0.0296, 0.0400, 0.0170], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,850][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.1263, 0.0554, 0.0628, 0.0619, 0.0660, 0.0701, 0.0636, 0.0578, 0.0670,
        0.0525, 0.0682, 0.0596, 0.0719, 0.0621, 0.0546], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,851][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0008, 0.0079, 0.0702, 0.0125, 0.0231, 0.0202, 0.0472, 0.0159, 0.0336,
        0.0183, 0.0224, 0.2883, 0.0126, 0.2377, 0.1894], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,852][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.7445, 0.0099, 0.0031, 0.0109, 0.0033, 0.0270, 0.0035, 0.0061, 0.0034,
        0.0342, 0.0360, 0.0047, 0.0291, 0.0191, 0.0651], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,853][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([6.5233e-04, 2.7849e-08, 2.0010e-07, 1.8016e-06, 3.8895e-06, 9.7572e-05,
        1.8405e-05, 5.5197e-05, 1.3625e-03, 3.8241e-03, 5.7927e-02, 2.0950e-01,
        3.4957e-02, 2.5034e-01, 4.4126e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,854][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0078, 0.0492, 0.0463, 0.0880, 0.0547, 0.2262, 0.1216, 0.0358, 0.0497,
        0.0729, 0.0330, 0.0541, 0.0661, 0.0386, 0.0559], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,856][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0895, 0.0692, 0.0712, 0.0492, 0.0865, 0.0759, 0.0566, 0.0529, 0.0621,
        0.0546, 0.0591, 0.0674, 0.0546, 0.0877, 0.0634], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,858][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([8.0792e-03, 1.0897e-03, 3.7794e-04, 8.1196e-05, 2.7156e-04, 1.4699e-03,
        5.2861e-03, 4.6751e-04, 3.0185e-03, 2.3757e-03, 1.1923e-02, 5.4097e-02,
        2.0188e-03, 1.8726e-01, 7.2218e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:43,859][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0682, 0.0680, 0.0621, 0.0655, 0.0742, 0.0663, 0.0637, 0.0601, 0.0596,
        0.0610, 0.0577, 0.0602, 0.0652, 0.0683, 0.0489, 0.0510],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,861][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0780, 0.0627, 0.0609, 0.0662, 0.0529, 0.0820, 0.1150, 0.0640, 0.0478,
        0.0430, 0.0690, 0.0474, 0.0569, 0.0485, 0.0660, 0.0397],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,863][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0170, 0.0381, 0.0427, 0.0737, 0.0704, 0.1018, 0.0444, 0.0455, 0.0512,
        0.0532, 0.0725, 0.0659, 0.0770, 0.0833, 0.0766, 0.0867],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,865][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0227, 0.0718, 0.0560, 0.0463, 0.0741, 0.0858, 0.0716, 0.0433, 0.0455,
        0.0539, 0.0514, 0.0760, 0.0490, 0.1069, 0.0729, 0.0728],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,867][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2639, 0.0532, 0.0611, 0.0452, 0.0526, 0.0661, 0.0624, 0.0412, 0.0528,
        0.0473, 0.0484, 0.0500, 0.0383, 0.0517, 0.0393, 0.0267],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,868][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1282, 0.0544, 0.0618, 0.0572, 0.0635, 0.0656, 0.0610, 0.0545, 0.0605,
        0.0487, 0.0624, 0.0549, 0.0683, 0.0601, 0.0495, 0.0494],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,869][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1667e-04, 1.8112e-03, 3.7181e-02, 5.4255e-03, 1.6323e-02, 7.4395e-03,
        3.1037e-02, 6.1356e-03, 2.5385e-02, 9.1101e-03, 1.1627e-02, 3.9613e-01,
        4.9135e-03, 2.5606e-01, 1.4269e-01, 4.8615e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,870][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.7339, 0.0052, 0.0021, 0.0052, 0.0024, 0.0152, 0.0032, 0.0026, 0.0022,
        0.0185, 0.0185, 0.0043, 0.0149, 0.0137, 0.0578, 0.1002],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,871][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.4317e-04, 1.4414e-08, 3.2332e-07, 5.7650e-07, 1.8416e-06, 5.5484e-05,
        2.3920e-05, 2.2589e-05, 2.1324e-04, 4.6542e-04, 1.7504e-02, 5.9818e-02,
        8.0901e-03, 7.4898e-02, 4.5845e-01, 3.8011e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,872][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0078, 0.0410, 0.0366, 0.0792, 0.0539, 0.1905, 0.1296, 0.0507, 0.0799,
        0.0375, 0.0327, 0.0408, 0.0500, 0.0418, 0.0967, 0.0315],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,874][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0864, 0.0638, 0.0664, 0.0466, 0.0809, 0.0719, 0.0522, 0.0495, 0.0576,
        0.0514, 0.0548, 0.0636, 0.0511, 0.0826, 0.0602, 0.0611],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,876][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.4255e-04, 3.6893e-04, 1.9308e-04, 4.8680e-05, 2.0602e-04, 5.4493e-04,
        4.1636e-03, 2.7385e-04, 4.9354e-03, 5.3426e-04, 1.1107e-02, 1.9322e-01,
        8.8158e-04, 9.7606e-02, 6.7167e-01, 1.3798e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:43,878][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0672, 0.0645, 0.0577, 0.0628, 0.0700, 0.0639, 0.0591, 0.0559, 0.0548,
        0.0586, 0.0542, 0.0559, 0.0616, 0.0621, 0.0459, 0.0499, 0.0558],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,879][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0708, 0.0654, 0.0542, 0.0702, 0.0461, 0.0720, 0.1042, 0.0632, 0.0451,
        0.0495, 0.0741, 0.0372, 0.0619, 0.0420, 0.0598, 0.0450, 0.0393],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,881][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0139, 0.0330, 0.0390, 0.0666, 0.0646, 0.0933, 0.0396, 0.0416, 0.0462,
        0.0509, 0.0663, 0.0615, 0.0720, 0.0781, 0.0714, 0.0857, 0.0761],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,883][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0171, 0.0775, 0.0520, 0.0499, 0.0715, 0.0911, 0.0705, 0.0415, 0.0404,
        0.0540, 0.0486, 0.0737, 0.0423, 0.0918, 0.0659, 0.0723, 0.0398],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,885][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.2543, 0.0354, 0.0673, 0.0488, 0.0624, 0.0568, 0.0576, 0.0447, 0.0386,
        0.0411, 0.0484, 0.0458, 0.0334, 0.0566, 0.0372, 0.0330, 0.0385],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,886][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.1099, 0.0512, 0.0572, 0.0550, 0.0590, 0.0642, 0.0569, 0.0518, 0.0589,
        0.0480, 0.0598, 0.0525, 0.0641, 0.0562, 0.0484, 0.0483, 0.0584],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,887][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0008, 0.0040, 0.0368, 0.0081, 0.0189, 0.0126, 0.0405, 0.0108, 0.0334,
        0.0165, 0.0167, 0.2602, 0.0092, 0.2047, 0.1350, 0.0699, 0.1217],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,888][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.7438, 0.0055, 0.0017, 0.0053, 0.0019, 0.0144, 0.0019, 0.0028, 0.0019,
        0.0174, 0.0162, 0.0028, 0.0145, 0.0094, 0.0402, 0.0908, 0.0296],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,889][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([1.1404e-04, 2.4177e-09, 4.1954e-08, 1.3669e-07, 5.0711e-07, 1.7372e-05,
        3.3797e-06, 7.4311e-06, 1.6131e-04, 4.8288e-04, 5.0897e-03, 1.4466e-02,
        3.7198e-03, 2.7545e-02, 3.2126e-01, 4.8709e-01, 1.4004e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,890][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0059, 0.0421, 0.0436, 0.0632, 0.0540, 0.1870, 0.0992, 0.0327, 0.0413,
        0.0757, 0.0297, 0.0490, 0.0546, 0.0406, 0.0838, 0.0661, 0.0316],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,892][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0790, 0.0630, 0.0637, 0.0455, 0.0780, 0.0680, 0.0500, 0.0464, 0.0543,
        0.0481, 0.0517, 0.0584, 0.0476, 0.0758, 0.0543, 0.0556, 0.0605],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,894][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.7992e-03, 4.3107e-04, 2.7686e-04, 2.6497e-05, 2.3276e-04, 8.1877e-04,
        3.0459e-03, 2.4657e-04, 2.4619e-03, 1.0957e-03, 5.9088e-03, 2.0984e-01,
        8.0904e-04, 1.1690e-01, 4.9811e-01, 3.3561e-02, 1.2343e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:43,896][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0619, 0.0603, 0.0556, 0.0603, 0.0653, 0.0593, 0.0566, 0.0538, 0.0531,
        0.0550, 0.0528, 0.0546, 0.0596, 0.0595, 0.0440, 0.0465, 0.0523, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,897][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0710, 0.0607, 0.0546, 0.0611, 0.0493, 0.0650, 0.0946, 0.0560, 0.0453,
        0.0432, 0.0619, 0.0409, 0.0580, 0.0467, 0.0551, 0.0398, 0.0507, 0.0460],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,900][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0156, 0.0328, 0.0367, 0.0644, 0.0603, 0.0874, 0.0375, 0.0383, 0.0423,
        0.0457, 0.0597, 0.0537, 0.0647, 0.0668, 0.0613, 0.0726, 0.0661, 0.0941],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,901][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0161, 0.0632, 0.0479, 0.0410, 0.0661, 0.0792, 0.0638, 0.0361, 0.0402,
        0.0514, 0.0437, 0.0750, 0.0427, 0.0998, 0.0683, 0.0722, 0.0425, 0.0508],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,903][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2443, 0.0384, 0.0504, 0.0439, 0.0554, 0.0599, 0.0553, 0.0361, 0.0391,
        0.0449, 0.0527, 0.0484, 0.0369, 0.0558, 0.0377, 0.0318, 0.0410, 0.0280],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,905][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1068, 0.0477, 0.0556, 0.0508, 0.0576, 0.0576, 0.0536, 0.0492, 0.0553,
        0.0448, 0.0560, 0.0503, 0.0599, 0.0553, 0.0450, 0.0455, 0.0542, 0.0550],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,905][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.7554e-04, 1.6637e-03, 2.1844e-02, 5.1760e-03, 1.1569e-02, 6.5378e-03,
        2.8930e-02, 5.5244e-03, 2.3182e-02, 1.0593e-02, 8.9634e-03, 3.4597e-01,
        5.1695e-03, 1.5063e-01, 1.3652e-01, 5.1506e-02, 1.3523e-01, 5.0818e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,906][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.5513, 0.0048, 0.0019, 0.0041, 0.0022, 0.0115, 0.0030, 0.0020, 0.0020,
        0.0149, 0.0113, 0.0039, 0.0108, 0.0113, 0.0506, 0.0804, 0.0466, 0.1874],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,907][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([6.8645e-04, 2.8317e-09, 1.2002e-07, 1.1113e-07, 4.6682e-07, 1.2421e-05,
        3.3214e-06, 8.5759e-06, 1.2218e-04, 2.9483e-04, 6.6151e-04, 8.4217e-03,
        1.4556e-03, 1.4902e-02, 9.6371e-02, 2.1434e-01, 2.9461e-01, 3.6810e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,908][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0116, 0.0417, 0.0308, 0.0788, 0.0412, 0.1620, 0.1046, 0.0508, 0.0510,
        0.0593, 0.0205, 0.0514, 0.0440, 0.0351, 0.0654, 0.0508, 0.0855, 0.0156],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,910][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0753, 0.0580, 0.0588, 0.0417, 0.0722, 0.0634, 0.0466, 0.0431, 0.0507,
        0.0450, 0.0483, 0.0548, 0.0452, 0.0721, 0.0511, 0.0525, 0.0571, 0.0643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,912][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.4452e-03, 2.7166e-04, 1.7865e-04, 2.3703e-05, 2.2549e-04, 4.7940e-04,
        2.5285e-03, 1.7413e-04, 2.9447e-03, 9.8500e-04, 4.2026e-03, 1.0545e-01,
        6.1343e-04, 8.7423e-02, 5.0533e-01, 2.5089e-02, 2.2553e-01, 3.6108e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:43,914][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0687, 0.0629, 0.0553, 0.0590, 0.0659, 0.0575, 0.0496, 0.0474, 0.0475,
        0.0544, 0.0498, 0.0483, 0.0560, 0.0562, 0.0384, 0.0459, 0.0476, 0.0474,
        0.0422], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,916][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0578, 0.0606, 0.0589, 0.0581, 0.0491, 0.0665, 0.0880, 0.0635, 0.0377,
        0.0392, 0.0653, 0.0338, 0.0577, 0.0443, 0.0556, 0.0358, 0.0432, 0.0454,
        0.0397], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,918][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0136, 0.0294, 0.0335, 0.0590, 0.0554, 0.0813, 0.0337, 0.0349, 0.0382,
        0.0415, 0.0548, 0.0486, 0.0596, 0.0606, 0.0556, 0.0670, 0.0602, 0.0906,
        0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,920][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0137, 0.0597, 0.0403, 0.0415, 0.0552, 0.0726, 0.0574, 0.0375, 0.0371,
        0.0513, 0.0429, 0.0676, 0.0437, 0.0719, 0.0580, 0.0689, 0.0376, 0.0518,
        0.0913], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,922][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.2334, 0.0524, 0.0763, 0.0472, 0.0612, 0.0492, 0.0506, 0.0334, 0.0424,
        0.0364, 0.0419, 0.0483, 0.0262, 0.0631, 0.0305, 0.0292, 0.0346, 0.0191,
        0.0247], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,923][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.1009, 0.0463, 0.0540, 0.0486, 0.0538, 0.0570, 0.0523, 0.0466, 0.0523,
        0.0417, 0.0555, 0.0462, 0.0582, 0.0518, 0.0447, 0.0436, 0.0523, 0.0539,
        0.0403], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,924][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0010, 0.0023, 0.0116, 0.0036, 0.0064, 0.0055, 0.0173, 0.0035, 0.0150,
        0.0051, 0.0061, 0.1477, 0.0030, 0.0891, 0.0809, 0.0250, 0.0795, 0.0349,
        0.4626], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,924][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.3051, 0.0057, 0.0009, 0.0067, 0.0013, 0.0218, 0.0014, 0.0063, 0.0023,
        0.0273, 0.0234, 0.0012, 0.0159, 0.0055, 0.0440, 0.1203, 0.0333, 0.3727,
        0.0048], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,925][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([3.7261e-04, 1.7930e-10, 2.9171e-08, 8.8847e-09, 9.5922e-08, 1.6716e-06,
        1.5961e-07, 7.9923e-07, 1.5161e-05, 4.8530e-05, 3.5168e-04, 1.6774e-03,
        3.1481e-04, 4.6209e-03, 2.4590e-02, 5.1894e-02, 1.9243e-01, 5.5729e-01,
        1.6639e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,927][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0083, 0.0490, 0.0578, 0.0766, 0.0605, 0.1290, 0.0569, 0.0422, 0.0542,
        0.0569, 0.0322, 0.0580, 0.0548, 0.0411, 0.0393, 0.0500, 0.0421, 0.0271,
        0.0641], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,929][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0683, 0.0554, 0.0563, 0.0392, 0.0687, 0.0585, 0.0442, 0.0408, 0.0472,
        0.0424, 0.0457, 0.0518, 0.0428, 0.0674, 0.0470, 0.0488, 0.0527, 0.0598,
        0.0629], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,930][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([8.7527e-03, 7.3737e-05, 7.3163e-05, 3.4254e-06, 7.3513e-05, 2.0068e-04,
        3.0372e-04, 3.6081e-05, 6.4636e-04, 2.5223e-04, 1.0209e-03, 2.3650e-02,
        1.9796e-04, 3.4248e-02, 1.1893e-01, 7.0817e-03, 1.2005e-01, 4.3152e-02,
        6.4126e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:43,932][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0561, 0.0562, 0.0500, 0.0541, 0.0604, 0.0544, 0.0517, 0.0492, 0.0487,
        0.0511, 0.0481, 0.0495, 0.0539, 0.0558, 0.0395, 0.0423, 0.0475, 0.0439,
        0.0423, 0.0454], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,934][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0662, 0.0529, 0.0514, 0.0561, 0.0443, 0.0700, 0.0984, 0.0537, 0.0400,
        0.0353, 0.0582, 0.0396, 0.0477, 0.0403, 0.0551, 0.0324, 0.0432, 0.0455,
        0.0379, 0.0318], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,936][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0134, 0.0284, 0.0318, 0.0550, 0.0518, 0.0761, 0.0327, 0.0332, 0.0350,
        0.0370, 0.0505, 0.0444, 0.0542, 0.0552, 0.0509, 0.0579, 0.0547, 0.0805,
        0.0747, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,938][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0168, 0.0521, 0.0433, 0.0345, 0.0566, 0.0669, 0.0552, 0.0335, 0.0362,
        0.0415, 0.0401, 0.0628, 0.0387, 0.0798, 0.0581, 0.0556, 0.0355, 0.0445,
        0.0829, 0.0654], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,940][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2357, 0.0415, 0.0649, 0.0435, 0.0512, 0.0574, 0.0551, 0.0338, 0.0404,
        0.0335, 0.0384, 0.0407, 0.0291, 0.0523, 0.0374, 0.0277, 0.0362, 0.0248,
        0.0250, 0.0315], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,941][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1035, 0.0448, 0.0507, 0.0461, 0.0520, 0.0525, 0.0490, 0.0437, 0.0484,
        0.0399, 0.0497, 0.0448, 0.0550, 0.0497, 0.0402, 0.0408, 0.0502, 0.0506,
        0.0436, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,942][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([6.3896e-05, 6.2942e-04, 1.1658e-02, 2.6741e-03, 6.3911e-03, 2.7462e-03,
        1.2221e-02, 2.1554e-03, 1.0632e-02, 3.1121e-03, 3.6981e-03, 1.4926e-01,
        1.3149e-03, 7.9210e-02, 4.5488e-02, 1.4090e-02, 4.7164e-02, 2.4017e-02,
        5.4438e-01, 3.9100e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,942][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.9417e-01, 2.1283e-03, 7.6287e-04, 1.6467e-03, 8.7831e-04, 4.1790e-03,
        1.0156e-03, 6.5773e-04, 6.2846e-04, 4.8108e-03, 4.6662e-03, 1.3194e-03,
        4.1022e-03, 3.7138e-03, 1.5261e-02, 2.5059e-02, 1.6696e-02, 8.7267e-02,
        6.8297e-03, 1.2421e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,943][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6836e-04, 6.4748e-10, 1.5540e-08, 1.3926e-08, 5.6048e-08, 1.8374e-06,
        4.9286e-07, 5.4014e-07, 2.4707e-06, 7.3446e-06, 2.4431e-04, 5.8478e-04,
        1.6276e-04, 7.7950e-04, 4.0878e-03, 4.2858e-03, 1.9780e-02, 8.5922e-02,
        2.1269e-01, 6.7118e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,945][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0061, 0.0376, 0.0343, 0.0734, 0.0484, 0.1562, 0.1031, 0.0437, 0.0670,
        0.0323, 0.0302, 0.0343, 0.0455, 0.0367, 0.0775, 0.0271, 0.0550, 0.0257,
        0.0411, 0.0249], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,947][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0686, 0.0502, 0.0522, 0.0364, 0.0647, 0.0564, 0.0407, 0.0384, 0.0443,
        0.0395, 0.0421, 0.0485, 0.0392, 0.0640, 0.0454, 0.0460, 0.0505, 0.0559,
        0.0597, 0.0573], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,949][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0580e-03, 1.1936e-04, 6.0938e-05, 1.1121e-05, 5.7520e-05, 1.5524e-04,
        9.5442e-04, 6.8979e-05, 7.3934e-04, 9.7106e-05, 1.7394e-03, 2.8972e-02,
        1.9513e-04, 1.4291e-02, 8.1806e-02, 1.9910e-03, 1.0439e-01, 3.9751e-02,
        6.8139e-01, 4.2152e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:43,952][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:43,955][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17458],
        [12041],
        [ 4364],
        [12434],
        [ 8729],
        [ 5812],
        [14909],
        [ 8655],
        [24234],
        [ 8660],
        [11778],
        [ 3786],
        [ 9387],
        [ 9945],
        [15432],
        [12289],
        [12141],
        [ 9443],
        [11235],
        [ 8810]], device='cuda:0')
[2024-07-24 10:18:43,957][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17089],
        [24546],
        [11494],
        [19109],
        [11959],
        [ 7930],
        [15956],
        [13450],
        [30580],
        [10154],
        [17082],
        [ 2275],
        [12220],
        [10580],
        [19117],
        [10173],
        [13829],
        [11624],
        [11662],
        [10370]], device='cuda:0')
[2024-07-24 10:18:43,959][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25609],
        [25878],
        [26061],
        [24668],
        [25984],
        [24472],
        [24629],
        [24268],
        [24880],
        [24199],
        [24258],
        [24224],
        [23769],
        [24517],
        [23764],
        [23415],
        [23426],
        [23646],
        [23791],
        [23299]], device='cuda:0')
[2024-07-24 10:18:43,960][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33471],
        [32498],
        [32824],
        [34385],
        [36960],
        [35443],
        [36392],
        [36565],
        [39294],
        [38895],
        [37693],
        [39815],
        [38656],
        [38434],
        [37940],
        [38640],
        [38620],
        [38556],
        [38693],
        [39376]], device='cuda:0')
[2024-07-24 10:18:43,962][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22759],
        [21232],
        [22585],
        [20764],
        [24325],
        [24666],
        [25502],
        [26461],
        [26468],
        [26025],
        [25361],
        [25463],
        [25205],
        [25774],
        [26073],
        [25808],
        [25439],
        [25687],
        [25858],
        [25837]], device='cuda:0')
[2024-07-24 10:18:43,964][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16853],
        [16812],
        [19432],
        [19271],
        [21079],
        [19471],
        [19771],
        [20107],
        [19998],
        [20165],
        [20294],
        [20697],
        [20249],
        [20709],
        [20443],
        [20375],
        [20218],
        [20223],
        [20979],
        [20630]], device='cuda:0')
[2024-07-24 10:18:43,967][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[34286],
        [12863],
        [ 9461],
        [22767],
        [17912],
        [27916],
        [29062],
        [33669],
        [32475],
        [30189],
        [29468],
        [28222],
        [28757],
        [28430],
        [29114],
        [28863],
        [28335],
        [28122],
        [26444],
        [28219]], device='cuda:0')
[2024-07-24 10:18:43,969][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[36391],
        [38070],
        [40512],
        [41481],
        [41410],
        [41127],
        [40599],
        [40666],
        [40495],
        [40387],
        [40152],
        [39920],
        [39882],
        [39732],
        [39771],
        [39636],
        [39484],
        [39506],
        [39297],
        [39231]], device='cuda:0')
[2024-07-24 10:18:43,971][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29999],
        [27206],
        [22103],
        [22895],
        [23190],
        [27007],
        [27977],
        [31186],
        [30312],
        [27188],
        [27968],
        [26987],
        [30915],
        [27181],
        [30618],
        [31789],
        [25259],
        [23628],
        [28105],
        [34676]], device='cuda:0')
[2024-07-24 10:18:43,973][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43447],
        [43020],
        [43467],
        [43358],
        [43212],
        [42892],
        [42757],
        [42566],
        [42452],
        [42490],
        [42364],
        [42352],
        [42222],
        [42159],
        [42074],
        [41943],
        [41870],
        [41768],
        [41853],
        [41698]], device='cuda:0')
[2024-07-24 10:18:43,975][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22168],
        [31717],
        [34772],
        [31920],
        [32536],
        [32807],
        [34200],
        [21139],
        [21335],
        [20245],
        [26605],
        [26673],
        [26839],
        [26856],
        [27149],
        [26738],
        [26247],
        [21096],
        [21343],
        [19524]], device='cuda:0')
[2024-07-24 10:18:43,977][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19974],
        [22408],
        [24313],
        [20744],
        [24951],
        [23917],
        [20636],
        [17800],
        [18909],
        [19392],
        [19615],
        [22017],
        [21961],
        [23721],
        [22370],
        [22798],
        [22716],
        [21918],
        [24090],
        [23164]], device='cuda:0')
[2024-07-24 10:18:43,979][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 5674],
        [11422],
        [10909],
        [13627],
        [14350],
        [13969],
        [11797],
        [12070],
        [11906],
        [12559],
        [12022],
        [12629],
        [12131],
        [12096],
        [11405],
        [11728],
        [11491],
        [11737],
        [11751],
        [11685]], device='cuda:0')
[2024-07-24 10:18:43,980][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12385],
        [11719],
        [12681],
        [11608],
        [11834],
        [11356],
        [11223],
        [11156],
        [10943],
        [10789],
        [10801],
        [10677],
        [10620],
        [10690],
        [10580],
        [10491],
        [10480],
        [10330],
        [10309],
        [10280]], device='cuda:0')
[2024-07-24 10:18:43,983][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[37894],
        [19520],
        [21505],
        [14544],
        [19379],
        [20874],
        [35724],
        [30657],
        [43264],
        [37313],
        [35134],
        [41981],
        [33372],
        [33474],
        [41096],
        [40372],
        [37873],
        [29562],
        [36152],
        [36525]], device='cuda:0')
[2024-07-24 10:18:43,985][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13595],
        [11401],
        [10776],
        [ 9952],
        [10057],
        [ 9246],
        [ 8794],
        [ 8128],
        [ 7741],
        [ 7317],
        [ 7217],
        [ 7062],
        [ 7043],
        [ 7216],
        [ 6943],
        [ 6712],
        [ 6516],
        [ 6363],
        [ 6364],
        [ 6179]], device='cuda:0')
[2024-07-24 10:18:43,987][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[42478],
        [41705],
        [43576],
        [42538],
        [42826],
        [42111],
        [41560],
        [41100],
        [40500],
        [40299],
        [40628],
        [40303],
        [40380],
        [40506],
        [40986],
        [40929],
        [40674],
        [40705],
        [40699],
        [40622]], device='cuda:0')
[2024-07-24 10:18:43,989][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[32562],
        [32490],
        [32936],
        [33586],
        [32955],
        [32571],
        [32944],
        [33024],
        [33216],
        [33400],
        [33531],
        [33736],
        [33835],
        [33754],
        [33945],
        [34099],
        [34263],
        [34482],
        [34473],
        [34513]], device='cuda:0')
[2024-07-24 10:18:43,991][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25101],
        [21836],
        [21033],
        [20121],
        [17582],
        [17414],
        [17263],
        [16698],
        [16064],
        [15702],
        [15332],
        [15323],
        [15161],
        [14878],
        [14892],
        [14656],
        [14525],
        [14092],
        [13534],
        [13414]], device='cuda:0')
[2024-07-24 10:18:43,993][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[41433],
        [41759],
        [41803],
        [41878],
        [42636],
        [41693],
        [40278],
        [40832],
        [39725],
        [33238],
        [30529],
        [34631],
        [29546],
        [33091],
        [37992],
        [28990],
        [28918],
        [28385],
        [28600],
        [28527]], device='cuda:0')
[2024-07-24 10:18:43,996][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[31490],
        [29504],
        [26062],
        [29793],
        [25892],
        [25663],
        [24706],
        [23778],
        [23433],
        [23620],
        [23431],
        [23627],
        [24227],
        [23525],
        [23063],
        [23190],
        [23269],
        [23331],
        [23103],
        [23285]], device='cuda:0')
[2024-07-24 10:18:43,997][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14977],
        [16006],
        [11297],
        [11219],
        [11801],
        [12236],
        [13553],
        [13395],
        [14286],
        [14350],
        [14194],
        [13825],
        [13643],
        [16406],
        [17886],
        [17404],
        [17292],
        [16499],
        [16008],
        [15807]], device='cuda:0')
[2024-07-24 10:18:43,999][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23453],
        [20614],
        [13345],
        [13707],
        [13307],
        [15914],
        [16825],
        [19971],
        [15030],
        [13061],
        [18237],
        [18931],
        [21394],
        [22662],
        [15275],
        [15416],
        [15104],
        [22810],
        [27962],
        [18388]], device='cuda:0')
[2024-07-24 10:18:44,001][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[34681],
        [32375],
        [40259],
        [36030],
        [35713],
        [38915],
        [37015],
        [29345],
        [26034],
        [29879],
        [32965],
        [26388],
        [25944],
        [27472],
        [27122],
        [29013],
        [29837],
        [26381],
        [26083],
        [29044]], device='cuda:0')
[2024-07-24 10:18:44,003][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36536],
        [27574],
        [30758],
        [28493],
        [28241],
        [24341],
        [27371],
        [30913],
        [25612],
        [29447],
        [29933],
        [29092],
        [28520],
        [28838],
        [29602],
        [30592],
        [30936],
        [30882],
        [30441],
        [30569]], device='cuda:0')
[2024-07-24 10:18:44,005][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[26038],
        [23688],
        [19439],
        [19598],
        [16676],
        [15892],
        [14221],
        [13344],
        [11928],
        [11178],
        [10488],
        [ 9877],
        [ 9542],
        [ 9140],
        [ 8683],
        [ 8594],
        [ 8280],
        [ 8004],
        [ 7743],
        [ 7674]], device='cuda:0')
[2024-07-24 10:18:44,007][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5495],
        [ 5092],
        [ 5710],
        [ 5293],
        [ 6443],
        [ 5430],
        [ 6351],
        [ 7717],
        [ 7405],
        [ 6544],
        [ 6449],
        [ 6294],
        [ 7386],
        [ 5204],
        [14805],
        [12947],
        [ 9312],
        [ 9596],
        [ 3793],
        [ 3340]], device='cuda:0')
[2024-07-24 10:18:44,010][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[16981],
        [17462],
        [17185],
        [18252],
        [18826],
        [19785],
        [20804],
        [21391],
        [23676],
        [24337],
        [23086],
        [22020],
        [21876],
        [21413],
        [20189],
        [21489],
        [21929],
        [22009],
        [22816],
        [23921]], device='cuda:0')
[2024-07-24 10:18:44,012][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15385],
        [31182],
        [28562],
        [36819],
        [32922],
        [31982],
        [15409],
        [15514],
        [10091],
        [13139],
        [23101],
        [29852],
        [28286],
        [32782],
        [23943],
        [18368],
        [26124],
        [31815],
        [35581],
        [23618]], device='cuda:0')
[2024-07-24 10:18:44,014][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866],
        [27866]], device='cuda:0')
[2024-07-24 10:18:44,071][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:44,073][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,074][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,076][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,077][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,078][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,080][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,081][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,082][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,083][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,084][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,085][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,085][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,086][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3972, 0.6028], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,087][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1841, 0.8159], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,088][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4690, 0.5310], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,089][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1299, 0.8701], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,090][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7546, 0.2454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,090][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0552, 0.9448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,091][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5089, 0.4911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,092][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,092][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9393, 0.0607], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,094][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6326, 0.3674], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,096][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9840, 0.0160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,097][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([7.4405e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,098][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.2715, 0.4132, 0.3152], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,100][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0898, 0.5192, 0.3910], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,102][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.3568, 0.3745, 0.2687], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,104][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0643, 0.4559, 0.4798], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,105][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.6162, 0.2034, 0.1804], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,106][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0246, 0.5916, 0.3838], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,107][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.3383, 0.3218, 0.3400], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,108][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0007, 0.5578, 0.4416], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,108][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.8590, 0.0734, 0.0676], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,109][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.3365, 0.4696, 0.1939], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,110][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.9668, 0.0204, 0.0127], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,112][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([1.1505e-09, 9.9999e-01, 9.7417e-06], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,113][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1998, 0.3122, 0.2090, 0.2790], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,115][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0592, 0.3502, 0.2691, 0.3216], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,117][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2614, 0.3033, 0.2187, 0.2166], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,119][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0345, 0.3073, 0.3510, 0.3073], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,121][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5207, 0.1729, 0.1465, 0.1600], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,122][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0172, 0.4028, 0.2284, 0.3516], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,124][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2534, 0.2437, 0.2586, 0.2443], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,124][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.5983e-05, 2.0920e-01, 5.8574e-02, 7.3213e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,125][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7469, 0.0796, 0.0580, 0.1155], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,126][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3191, 0.2750, 0.3369, 0.0689], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,126][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9683, 0.0139, 0.0086, 0.0092], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,127][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.1254e-12, 4.2975e-03, 9.9570e-01, 1.2910e-06], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,128][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.1581, 0.2437, 0.1685, 0.2199, 0.2098], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,130][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0473, 0.2724, 0.2120, 0.2527, 0.2156], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,132][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.2124, 0.2226, 0.1811, 0.1711, 0.2128], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,133][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0349, 0.2473, 0.2681, 0.2198, 0.2300], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,135][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.4517, 0.1467, 0.1260, 0.1359, 0.1397], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,137][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0143, 0.3120, 0.1773, 0.2897, 0.2066], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,139][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.2017, 0.1906, 0.2030, 0.1917, 0.2130], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,140][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([1.4240e-04, 9.8433e-02, 9.2573e-02, 1.7060e-01, 6.3825e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,142][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.7339, 0.0603, 0.0557, 0.0939, 0.0562], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,142][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.2306, 0.2325, 0.3351, 0.0969, 0.1049], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,143][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.9559, 0.0128, 0.0081, 0.0098, 0.0135], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,144][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([1.4035e-08, 2.2369e-01, 1.0192e-02, 8.1175e-05, 7.6603e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,144][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1255, 0.1964, 0.1356, 0.1781, 0.1700, 0.1944], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,145][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0376, 0.2172, 0.1699, 0.2080, 0.1729, 0.1945], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,147][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1757, 0.1922, 0.1423, 0.1502, 0.1786, 0.1610], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,149][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0195, 0.1987, 0.2295, 0.1953, 0.1673, 0.1898], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,151][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3836, 0.1286, 0.1105, 0.1193, 0.1209, 0.1371], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,152][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0188, 0.2481, 0.1546, 0.2531, 0.1829, 0.1425], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,155][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1682, 0.1582, 0.1682, 0.1588, 0.1770, 0.1697], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,156][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ were] are: tensor([8.3714e-05, 9.4173e-02, 2.4720e-02, 1.4420e-01, 1.4868e-01, 5.8814e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,158][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.6743, 0.0604, 0.0412, 0.0796, 0.0450, 0.0995], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,159][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1267, 0.2107, 0.2421, 0.0826, 0.1025, 0.2355], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,160][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.9345, 0.0148, 0.0093, 0.0109, 0.0168, 0.0136], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,161][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ were] are: tensor([3.7764e-12, 2.5880e-06, 2.5280e-04, 8.5624e-10, 9.9970e-01, 4.9241e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,162][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.1050, 0.1633, 0.1134, 0.1464, 0.1407, 0.1603, 0.1710],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,162][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0342, 0.1818, 0.1396, 0.1728, 0.1425, 0.1641, 0.1649],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,163][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.1456, 0.1531, 0.1218, 0.1237, 0.1403, 0.1367, 0.1788],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,165][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0212, 0.1488, 0.1714, 0.1443, 0.1596, 0.1549, 0.1998],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,166][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.3263, 0.1132, 0.0971, 0.1050, 0.1066, 0.1212, 0.1306],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,168][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0124, 0.2298, 0.1406, 0.2145, 0.1634, 0.1181, 0.1211],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,170][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.1434, 0.1357, 0.1440, 0.1356, 0.1516, 0.1456, 0.1440],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,171][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([3.5861e-05, 4.0570e-02, 1.0479e-02, 6.3053e-02, 6.9163e-02, 1.6348e-01,
        6.5322e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,173][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.5782, 0.0531, 0.0394, 0.0748, 0.0422, 0.0918, 0.1205],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,175][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1467, 0.1363, 0.2438, 0.0805, 0.0751, 0.2074, 0.1101],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,176][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.8618, 0.0222, 0.0143, 0.0167, 0.0265, 0.0205, 0.0379],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,178][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([1.4495e-11, 5.5244e-05, 5.8791e-06, 3.3049e-09, 4.2824e-01, 4.1262e-01,
        1.5908e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,178][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0881, 0.1361, 0.0946, 0.1239, 0.1180, 0.1344, 0.1446, 0.1603],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,179][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0288, 0.1523, 0.1176, 0.1463, 0.1205, 0.1360, 0.1365, 0.1621],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,180][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.1294, 0.1286, 0.1076, 0.1030, 0.1319, 0.1203, 0.1618, 0.1173],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,181][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0151, 0.1391, 0.1565, 0.1359, 0.1247, 0.1338, 0.1567, 0.1383],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,182][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.2794, 0.1013, 0.0874, 0.0943, 0.0958, 0.1082, 0.1166, 0.1171],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,184][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0118, 0.1822, 0.1251, 0.1956, 0.1400, 0.1090, 0.1291, 0.1073],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,186][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.1253, 0.1185, 0.1259, 0.1182, 0.1327, 0.1271, 0.1256, 0.1266],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,187][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ about] are: tensor([1.9874e-05, 5.0160e-02, 8.5941e-03, 6.9289e-02, 5.7147e-02, 1.4988e-01,
        5.2594e-01, 1.3897e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,188][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.4665, 0.0571, 0.0411, 0.0735, 0.0420, 0.0930, 0.1226, 0.1043],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,190][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.1608, 0.1152, 0.1696, 0.0406, 0.0659, 0.2297, 0.1533, 0.0649],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,192][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.8495, 0.0216, 0.0115, 0.0147, 0.0222, 0.0180, 0.0338, 0.0287],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,194][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ about] are: tensor([5.6429e-17, 2.3906e-09, 1.2814e-06, 5.2148e-13, 7.5015e-03, 3.5323e-05,
        9.9246e-01, 2.5047e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,195][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0761, 0.1172, 0.0820, 0.1065, 0.1018, 0.1158, 0.1250, 0.1392, 0.1364],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,196][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0245, 0.1295, 0.1011, 0.1247, 0.1032, 0.1181, 0.1177, 0.1429, 0.1384],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,197][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.1069, 0.1187, 0.0814, 0.0908, 0.1156, 0.1096, 0.1364, 0.1201, 0.1204],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,198][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0117, 0.1027, 0.1275, 0.1054, 0.1163, 0.1114, 0.1461, 0.1159, 0.1630],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,199][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.2590, 0.0913, 0.0794, 0.0851, 0.0871, 0.0978, 0.1053, 0.1060, 0.0889],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,200][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0130, 0.1816, 0.1059, 0.1895, 0.1218, 0.0926, 0.1179, 0.1111, 0.0667],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,202][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1113, 0.1046, 0.1117, 0.1045, 0.1176, 0.1123, 0.1113, 0.1127, 0.1140],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,203][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ going] are: tensor([4.4798e-05, 1.7341e-02, 8.4800e-03, 1.5486e-02, 3.5529e-02, 6.9904e-02,
        2.4300e-01, 4.5503e-02, 5.6471e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,205][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.4823, 0.0393, 0.0331, 0.0608, 0.0353, 0.0781, 0.1086, 0.0918, 0.0707],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,206][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0745, 0.0831, 0.0757, 0.0427, 0.0511, 0.1893, 0.1279, 0.0997, 0.2561],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,208][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.8881, 0.0120, 0.0078, 0.0107, 0.0142, 0.0129, 0.0218, 0.0188, 0.0137],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,210][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ going] are: tensor([6.5221e-12, 7.9154e-10, 3.0424e-07, 1.7445e-13, 5.2519e-03, 2.5733e-04,
        2.4128e-03, 1.4954e-08, 9.9208e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,212][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0679, 0.1030, 0.0721, 0.0947, 0.0900, 0.1025, 0.1116, 0.1224, 0.1214,
        0.1146], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,213][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0213, 0.1172, 0.0911, 0.1098, 0.0918, 0.1037, 0.1039, 0.1238, 0.1205,
        0.1169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,214][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0954, 0.1079, 0.0791, 0.0818, 0.1003, 0.0912, 0.1237, 0.0964, 0.1130,
        0.1111], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,215][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0061, 0.0802, 0.1127, 0.0905, 0.1061, 0.0928, 0.1333, 0.1020, 0.1445,
        0.1317], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,216][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2376, 0.0869, 0.0745, 0.0786, 0.0816, 0.0905, 0.0992, 0.1000, 0.0828,
        0.0683], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,217][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0066, 0.1459, 0.0987, 0.1660, 0.1249, 0.0878, 0.1194, 0.0922, 0.0778,
        0.0806], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,218][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0996, 0.0941, 0.1005, 0.0938, 0.1058, 0.1007, 0.1003, 0.1015, 0.1027,
        0.1011], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,219][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.0649e-05, 1.6419e-02, 6.5943e-03, 1.4671e-02, 2.5300e-02, 4.7828e-02,
        1.8585e-01, 5.2837e-02, 4.3343e-01, 2.1703e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,221][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4098, 0.0433, 0.0330, 0.0597, 0.0343, 0.0824, 0.1086, 0.1007, 0.0739,
        0.0543], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,223][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1096, 0.0591, 0.1288, 0.0241, 0.0690, 0.1104, 0.1170, 0.0524, 0.2959,
        0.0338], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,225][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8845, 0.0160, 0.0070, 0.0090, 0.0114, 0.0112, 0.0218, 0.0170, 0.0123,
        0.0098], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,226][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.1071e-17, 9.4296e-16, 1.1510e-10, 7.2653e-20, 1.3535e-07, 9.2682e-10,
        2.4586e-05, 5.3541e-14, 9.9998e-01, 3.1659e-09], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,228][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0574, 0.0910, 0.0618, 0.0812, 0.0775, 0.0901, 0.0971, 0.1071, 0.1047,
        0.1003, 0.1319], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,230][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0194, 0.1074, 0.0818, 0.1001, 0.0823, 0.0932, 0.0938, 0.1125, 0.1085,
        0.1058, 0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,231][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0921, 0.1005, 0.0712, 0.0732, 0.0983, 0.0872, 0.1133, 0.0898, 0.1029,
        0.1033, 0.0681], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,232][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0055, 0.0700, 0.0948, 0.0796, 0.0967, 0.0809, 0.1165, 0.0883, 0.1334,
        0.1193, 0.1149], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,233][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2243, 0.0784, 0.0684, 0.0728, 0.0746, 0.0836, 0.0899, 0.0910, 0.0759,
        0.0617, 0.0794], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,234][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0054, 0.1423, 0.0846, 0.1447, 0.1063, 0.0810, 0.0996, 0.0813, 0.0656,
        0.0811, 0.1081], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,235][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0907, 0.0856, 0.0915, 0.0855, 0.0962, 0.0917, 0.0911, 0.0923, 0.0935,
        0.0923, 0.0896], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,236][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.0439e-04, 6.9139e-03, 6.1211e-03, 8.0585e-03, 2.7673e-02, 5.4614e-02,
        1.5187e-01, 3.5245e-02, 3.9687e-01, 1.7318e-01, 1.3935e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,238][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4117, 0.0390, 0.0314, 0.0594, 0.0343, 0.0768, 0.0978, 0.0887, 0.0701,
        0.0467, 0.0439], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,239][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0831, 0.0766, 0.1072, 0.0272, 0.0520, 0.1469, 0.1157, 0.0904, 0.2140,
        0.0457, 0.0414], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,241][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.8894, 0.0125, 0.0061, 0.0080, 0.0106, 0.0104, 0.0191, 0.0148, 0.0116,
        0.0095, 0.0080], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,242][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.2982e-12, 4.8724e-14, 3.6137e-09, 4.8942e-17, 1.7227e-06, 3.6550e-07,
        3.8773e-05, 3.3636e-11, 9.9984e-01, 1.4051e-05, 1.0885e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,244][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0521, 0.0823, 0.0569, 0.0748, 0.0711, 0.0822, 0.0882, 0.0974, 0.0948,
        0.0929, 0.1216, 0.0858], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,246][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0190, 0.0937, 0.0742, 0.0900, 0.0755, 0.0851, 0.0846, 0.1026, 0.1009,
        0.0986, 0.0879, 0.0881], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,248][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0911, 0.0901, 0.0812, 0.0687, 0.0845, 0.0854, 0.0936, 0.0796, 0.0878,
        0.0832, 0.0635, 0.0914], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,249][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0092, 0.0599, 0.0768, 0.0655, 0.0819, 0.0678, 0.0913, 0.0658, 0.1163,
        0.0989, 0.1027, 0.1640], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,250][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.2098, 0.0710, 0.0634, 0.0664, 0.0688, 0.0772, 0.0827, 0.0837, 0.0702,
        0.0570, 0.0727, 0.0771], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,251][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0096, 0.1235, 0.0728, 0.1335, 0.0946, 0.0635, 0.0864, 0.0785, 0.0603,
        0.0727, 0.1099, 0.0946], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,252][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0822, 0.0774, 0.0826, 0.0779, 0.0868, 0.0833, 0.0829, 0.0840, 0.0853,
        0.0842, 0.0824, 0.0910], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,253][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ school] are: tensor([6.6778e-05, 2.1779e-03, 2.5036e-03, 1.2458e-03, 7.9917e-03, 8.5903e-03,
        2.8460e-02, 5.3917e-03, 4.6565e-02, 3.2771e-02, 2.9568e-02, 8.3467e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,254][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.4039, 0.0362, 0.0297, 0.0527, 0.0328, 0.0677, 0.0902, 0.0755, 0.0642,
        0.0403, 0.0404, 0.0662], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,256][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0724, 0.1303, 0.0762, 0.0310, 0.0373, 0.1094, 0.0746, 0.0783, 0.2730,
        0.0440, 0.0509, 0.0227], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,257][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.8021, 0.0132, 0.0113, 0.0127, 0.0206, 0.0176, 0.0309, 0.0236, 0.0183,
        0.0127, 0.0117, 0.0253], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,259][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ school] are: tensor([2.2055e-14, 4.2341e-21, 1.7887e-17, 1.6968e-25, 1.8249e-14, 7.0059e-15,
        5.7340e-14, 2.9315e-19, 9.7141e-10, 2.5365e-14, 9.8802e-10, 1.0000e+00],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,260][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0476, 0.0743, 0.0534, 0.0686, 0.0657, 0.0762, 0.0808, 0.0885, 0.0874,
        0.0858, 0.1101, 0.0789, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,262][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0156, 0.0896, 0.0693, 0.0865, 0.0711, 0.0802, 0.0784, 0.0952, 0.0922,
        0.0926, 0.0831, 0.0784, 0.0680], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,264][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0732, 0.0831, 0.0628, 0.0634, 0.0765, 0.0728, 0.0941, 0.0784, 0.0871,
        0.0889, 0.0578, 0.0838, 0.0780], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,266][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0049, 0.0487, 0.0596, 0.0556, 0.0743, 0.0558, 0.0893, 0.0654, 0.1089,
        0.0979, 0.1003, 0.1708, 0.0685], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,267][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1830, 0.0667, 0.0596, 0.0636, 0.0647, 0.0728, 0.0769, 0.0777, 0.0658,
        0.0530, 0.0678, 0.0717, 0.0768], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,268][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0104, 0.1039, 0.0677, 0.1059, 0.0871, 0.0632, 0.0893, 0.0744, 0.0635,
        0.0592, 0.1105, 0.0883, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,269][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0747, 0.0712, 0.0760, 0.0716, 0.0797, 0.0765, 0.0761, 0.0773, 0.0786,
        0.0778, 0.0761, 0.0838, 0.0806], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,270][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([5.1449e-06, 3.2400e-03, 1.2316e-03, 5.7509e-03, 7.8031e-03, 1.1866e-02,
        4.3157e-02, 1.3250e-02, 1.1046e-01, 5.9348e-02, 4.2670e-02, 6.7556e-01,
        2.5656e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,271][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3603, 0.0402, 0.0338, 0.0554, 0.0333, 0.0651, 0.0898, 0.0791, 0.0609,
        0.0427, 0.0386, 0.0564, 0.0444], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,272][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0915, 0.0785, 0.0989, 0.0183, 0.0313, 0.1067, 0.1135, 0.0881, 0.2571,
        0.0282, 0.0494, 0.0228, 0.0156], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,274][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.8068, 0.0156, 0.0095, 0.0122, 0.0168, 0.0149, 0.0266, 0.0215, 0.0168,
        0.0150, 0.0117, 0.0188, 0.0138], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,275][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([6.9474e-24, 2.6153e-23, 2.9263e-18, 2.8143e-26, 1.9298e-15, 2.2175e-17,
        9.1453e-14, 6.0571e-21, 6.7397e-10, 2.3033e-16, 9.2608e-12, 1.0000e+00,
        1.1739e-15], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,277][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0436, 0.0685, 0.0493, 0.0634, 0.0610, 0.0705, 0.0748, 0.0827, 0.0812,
        0.0792, 0.1019, 0.0735, 0.0771, 0.0731], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,278][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0178, 0.0807, 0.0641, 0.0768, 0.0652, 0.0729, 0.0754, 0.0880, 0.0879,
        0.0855, 0.0769, 0.0759, 0.0637, 0.0692], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,280][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0744, 0.0773, 0.0610, 0.0586, 0.0704, 0.0713, 0.0786, 0.0700, 0.0745,
        0.0753, 0.0567, 0.0850, 0.0703, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,282][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0098, 0.0698, 0.0844, 0.0643, 0.0672, 0.0692, 0.0756, 0.0605, 0.0859,
        0.0702, 0.0693, 0.1073, 0.0531, 0.1133], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,284][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.1801, 0.0616, 0.0547, 0.0578, 0.0603, 0.0674, 0.0707, 0.0722, 0.0610,
        0.0496, 0.0634, 0.0668, 0.0712, 0.0633], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,285][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0093, 0.1077, 0.0612, 0.1047, 0.0680, 0.0611, 0.0705, 0.0629, 0.0480,
        0.0639, 0.1003, 0.0808, 0.0847, 0.0770], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,286][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0694, 0.0652, 0.0698, 0.0659, 0.0732, 0.0705, 0.0702, 0.0712, 0.0723,
        0.0714, 0.0698, 0.0767, 0.0740, 0.0802], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,287][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([4.6330e-05, 1.1056e-03, 2.9014e-03, 8.5735e-04, 9.6334e-03, 1.3173e-02,
        1.7517e-02, 5.9653e-03, 3.7635e-02, 2.0934e-02, 2.5804e-02, 2.6861e-01,
        9.6898e-03, 5.8613e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,288][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.3653, 0.0316, 0.0311, 0.0509, 0.0300, 0.0637, 0.0866, 0.0698, 0.0558,
        0.0370, 0.0362, 0.0570, 0.0420, 0.0430], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,289][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0876, 0.0694, 0.1094, 0.0340, 0.0339, 0.1673, 0.0682, 0.0607, 0.2088,
        0.0340, 0.0609, 0.0200, 0.0213, 0.0246], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,291][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.7260, 0.0170, 0.0123, 0.0158, 0.0210, 0.0215, 0.0373, 0.0313, 0.0258,
        0.0162, 0.0149, 0.0244, 0.0153, 0.0212], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,292][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([3.2053e-13, 1.3634e-19, 3.2861e-16, 2.3040e-24, 3.3992e-16, 1.4394e-13,
        2.0058e-13, 1.7747e-19, 6.6074e-10, 3.5092e-15, 2.7400e-10, 3.7988e-01,
        9.0025e-11, 6.2012e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,294][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0413, 0.0646, 0.0453, 0.0599, 0.0569, 0.0651, 0.0703, 0.0786, 0.0757,
        0.0731, 0.0960, 0.0681, 0.0719, 0.0674, 0.0659], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,296][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0154, 0.0751, 0.0596, 0.0731, 0.0604, 0.0683, 0.0685, 0.0831, 0.0807,
        0.0802, 0.0725, 0.0705, 0.0610, 0.0645, 0.0671], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,298][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0699, 0.0718, 0.0510, 0.0552, 0.0611, 0.0616, 0.0835, 0.0643, 0.0696,
        0.0695, 0.0504, 0.0711, 0.0669, 0.0691, 0.0849], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,300][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0084, 0.0727, 0.0907, 0.0659, 0.0609, 0.0676, 0.0705, 0.0618, 0.0688,
        0.0549, 0.0508, 0.0798, 0.0471, 0.0982, 0.1020], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,302][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.1644, 0.0585, 0.0511, 0.0542, 0.0558, 0.0631, 0.0676, 0.0685, 0.0575,
        0.0468, 0.0598, 0.0627, 0.0667, 0.0584, 0.0649], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,304][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0103, 0.1014, 0.0654, 0.1000, 0.0737, 0.0529, 0.0714, 0.0594, 0.0443,
        0.0548, 0.0944, 0.0752, 0.0735, 0.0855, 0.0379], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,306][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0649, 0.0609, 0.0649, 0.0614, 0.0688, 0.0659, 0.0654, 0.0661, 0.0669,
        0.0662, 0.0650, 0.0720, 0.0695, 0.0758, 0.0663], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,308][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([6.2099e-06, 8.2134e-04, 6.1942e-04, 7.5224e-04, 1.5945e-03, 9.5486e-03,
        1.2689e-02, 3.0860e-03, 2.6212e-02, 9.1283e-03, 5.7635e-03, 6.7901e-02,
        3.8611e-03, 8.4997e-02, 7.7302e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,309][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.3460, 0.0309, 0.0243, 0.0465, 0.0260, 0.0591, 0.0813, 0.0699, 0.0544,
        0.0391, 0.0345, 0.0516, 0.0402, 0.0399, 0.0563], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,310][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0397, 0.0918, 0.0745, 0.0430, 0.0296, 0.1063, 0.0557, 0.0698, 0.1657,
        0.0867, 0.0857, 0.0371, 0.0394, 0.0237, 0.0512], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,311][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.6523, 0.0193, 0.0151, 0.0182, 0.0274, 0.0241, 0.0420, 0.0339, 0.0251,
        0.0181, 0.0152, 0.0341, 0.0175, 0.0271, 0.0305], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,311][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([1.7553e-17, 3.5826e-23, 1.5710e-17, 2.0439e-28, 2.3619e-15, 9.9486e-19,
        4.4008e-18, 3.9814e-24, 1.8998e-15, 2.6819e-19, 1.9461e-15, 2.7673e-05,
        5.3701e-15, 9.9997e-01, 4.7360e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,312][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0396, 0.0614, 0.0413, 0.0556, 0.0522, 0.0603, 0.0663, 0.0727, 0.0715,
        0.0672, 0.0901, 0.0628, 0.0649, 0.0614, 0.0597, 0.0731],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,314][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0140, 0.0733, 0.0571, 0.0691, 0.0574, 0.0652, 0.0656, 0.0784, 0.0758,
        0.0740, 0.0669, 0.0635, 0.0557, 0.0605, 0.0623, 0.0612],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,316][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0588, 0.0673, 0.0477, 0.0495, 0.0616, 0.0571, 0.0759, 0.0585, 0.0659,
        0.0670, 0.0439, 0.0667, 0.0615, 0.0694, 0.0837, 0.0655],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,318][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0040, 0.0555, 0.0768, 0.0583, 0.0582, 0.0574, 0.0672, 0.0544, 0.0693,
        0.0591, 0.0541, 0.0964, 0.0437, 0.0958, 0.0849, 0.0647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,320][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1540, 0.0569, 0.0489, 0.0514, 0.0535, 0.0595, 0.0645, 0.0653, 0.0542,
        0.0445, 0.0563, 0.0594, 0.0632, 0.0561, 0.0609, 0.0515],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,322][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0051, 0.0865, 0.0592, 0.0959, 0.0727, 0.0514, 0.0709, 0.0553, 0.0494,
        0.0428, 0.0821, 0.0784, 0.0762, 0.0876, 0.0426, 0.0440],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,324][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0606, 0.0572, 0.0613, 0.0575, 0.0646, 0.0618, 0.0614, 0.0621, 0.0630,
        0.0623, 0.0609, 0.0677, 0.0652, 0.0712, 0.0624, 0.0610],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,325][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.3513e-06, 5.7764e-04, 4.2128e-04, 4.3839e-04, 1.1670e-03, 2.7666e-03,
        8.9338e-03, 2.0604e-03, 1.4753e-02, 6.9709e-03, 6.0099e-03, 8.5031e-02,
        3.5311e-03, 9.5034e-02, 7.0014e-01, 7.2163e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,327][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3465, 0.0338, 0.0243, 0.0431, 0.0255, 0.0574, 0.0767, 0.0698, 0.0507,
        0.0379, 0.0328, 0.0482, 0.0347, 0.0360, 0.0514, 0.0311],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,328][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0851, 0.0423, 0.1035, 0.0173, 0.0539, 0.0904, 0.0861, 0.0377, 0.2467,
        0.0243, 0.0387, 0.0233, 0.0199, 0.0479, 0.0653, 0.0176],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,329][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7936, 0.0201, 0.0078, 0.0110, 0.0124, 0.0129, 0.0255, 0.0202, 0.0148,
        0.0119, 0.0097, 0.0142, 0.0099, 0.0121, 0.0130, 0.0110],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,330][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.6860e-21, 9.0927e-26, 1.4014e-18, 4.3452e-31, 5.8576e-17, 2.5772e-19,
        2.5119e-15, 8.7996e-25, 2.6893e-12, 3.8473e-21, 4.1257e-16, 1.4899e-02,
        7.1118e-17, 8.7577e-01, 1.0933e-01, 9.7246e-11], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,330][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0375, 0.0596, 0.0378, 0.0522, 0.0487, 0.0565, 0.0626, 0.0685, 0.0667,
        0.0628, 0.0857, 0.0583, 0.0598, 0.0567, 0.0540, 0.0677, 0.0648],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,333][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0159, 0.0657, 0.0531, 0.0627, 0.0533, 0.0597, 0.0606, 0.0715, 0.0705,
        0.0687, 0.0626, 0.0608, 0.0528, 0.0576, 0.0592, 0.0591, 0.0663],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,335][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0547, 0.0617, 0.0440, 0.0446, 0.0584, 0.0522, 0.0738, 0.0561, 0.0568,
        0.0617, 0.0417, 0.0640, 0.0566, 0.0679, 0.0815, 0.0613, 0.0631],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,336][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0047, 0.0481, 0.0639, 0.0523, 0.0565, 0.0505, 0.0655, 0.0492, 0.0713,
        0.0571, 0.0523, 0.0955, 0.0437, 0.0877, 0.0700, 0.0568, 0.0748],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,338][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1491, 0.0529, 0.0461, 0.0488, 0.0508, 0.0565, 0.0609, 0.0615, 0.0512,
        0.0417, 0.0534, 0.0564, 0.0599, 0.0529, 0.0580, 0.0479, 0.0520],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,341][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0080, 0.0914, 0.0495, 0.0902, 0.0625, 0.0481, 0.0616, 0.0537, 0.0431,
        0.0573, 0.0710, 0.0677, 0.0708, 0.0720, 0.0412, 0.0581, 0.0536],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,343][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0572, 0.0537, 0.0577, 0.0544, 0.0607, 0.0582, 0.0577, 0.0584, 0.0592,
        0.0584, 0.0571, 0.0633, 0.0612, 0.0669, 0.0592, 0.0578, 0.0590],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,344][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([4.7368e-06, 5.1896e-04, 2.7215e-04, 5.5527e-04, 9.4936e-04, 4.7150e-03,
        7.9437e-03, 1.6587e-03, 9.8777e-03, 6.6487e-03, 4.8342e-03, 7.6112e-02,
        2.8797e-03, 4.3798e-02, 5.0222e-01, 5.8550e-02, 2.7846e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,345][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.3009, 0.0293, 0.0253, 0.0443, 0.0278, 0.0593, 0.0774, 0.0646, 0.0518,
        0.0342, 0.0321, 0.0514, 0.0353, 0.0418, 0.0547, 0.0292, 0.0407],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,346][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0485, 0.0617, 0.0795, 0.0237, 0.0229, 0.0636, 0.1003, 0.0578, 0.2625,
        0.0375, 0.0396, 0.0160, 0.0160, 0.0182, 0.0880, 0.0246, 0.0396],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,347][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.7658, 0.0129, 0.0094, 0.0100, 0.0171, 0.0138, 0.0256, 0.0200, 0.0146,
        0.0115, 0.0093, 0.0201, 0.0100, 0.0171, 0.0176, 0.0110, 0.0142],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,348][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([2.7955e-17, 1.2221e-23, 1.6147e-17, 1.3429e-28, 8.7701e-16, 4.6116e-17,
        7.1768e-16, 8.9798e-23, 2.6198e-13, 8.9342e-18, 9.0244e-16, 1.9792e-03,
        2.3626e-15, 9.7958e-01, 1.5697e-02, 4.8797e-08, 2.7443e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,349][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0340, 0.0549, 0.0350, 0.0482, 0.0449, 0.0522, 0.0579, 0.0641, 0.0616,
        0.0583, 0.0806, 0.0541, 0.0559, 0.0531, 0.0502, 0.0630, 0.0597, 0.0723],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,351][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0153, 0.0634, 0.0506, 0.0600, 0.0507, 0.0560, 0.0581, 0.0673, 0.0659,
        0.0641, 0.0586, 0.0563, 0.0492, 0.0537, 0.0546, 0.0543, 0.0611, 0.0608],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,353][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0532, 0.0595, 0.0429, 0.0423, 0.0582, 0.0530, 0.0666, 0.0515, 0.0560,
        0.0575, 0.0392, 0.0611, 0.0562, 0.0661, 0.0751, 0.0556, 0.0593, 0.0466],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,355][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0042, 0.0558, 0.0700, 0.0527, 0.0511, 0.0535, 0.0579, 0.0504, 0.0615,
        0.0500, 0.0442, 0.0719, 0.0402, 0.0807, 0.0756, 0.0594, 0.0709, 0.0500],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,356][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1421, 0.0504, 0.0440, 0.0466, 0.0486, 0.0538, 0.0579, 0.0584, 0.0487,
        0.0395, 0.0506, 0.0536, 0.0570, 0.0507, 0.0553, 0.0456, 0.0496, 0.0476],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,358][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0052, 0.0766, 0.0438, 0.0763, 0.0621, 0.0469, 0.0566, 0.0532, 0.0422,
        0.0496, 0.0658, 0.0676, 0.0660, 0.0731, 0.0420, 0.0507, 0.0543, 0.0681],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,360][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0542, 0.0507, 0.0546, 0.0515, 0.0575, 0.0552, 0.0545, 0.0551, 0.0559,
        0.0553, 0.0540, 0.0600, 0.0581, 0.0634, 0.0560, 0.0547, 0.0560, 0.0532],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,362][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([7.6422e-06, 4.9158e-04, 4.7458e-04, 5.1566e-04, 1.6829e-03, 3.7899e-03,
        9.5722e-03, 1.7417e-03, 1.5882e-02, 6.2356e-03, 5.7669e-03, 6.5415e-02,
        3.7188e-03, 8.0380e-02, 5.3421e-01, 5.1563e-02, 1.8501e-01, 3.3540e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,363][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3037, 0.0278, 0.0229, 0.0422, 0.0248, 0.0539, 0.0715, 0.0654, 0.0503,
        0.0341, 0.0320, 0.0499, 0.0360, 0.0372, 0.0495, 0.0283, 0.0397, 0.0308],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,364][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0693, 0.0655, 0.0672, 0.0199, 0.0421, 0.1085, 0.0888, 0.0496, 0.1677,
        0.0301, 0.0310, 0.0298, 0.0212, 0.0388, 0.0835, 0.0207, 0.0514, 0.0149],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,364][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.8118, 0.0129, 0.0061, 0.0081, 0.0111, 0.0105, 0.0202, 0.0157, 0.0117,
        0.0100, 0.0077, 0.0137, 0.0084, 0.0122, 0.0139, 0.0100, 0.0111, 0.0048],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,365][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.4272e-18, 3.1728e-23, 1.7234e-16, 1.0229e-27, 1.4852e-15, 2.9211e-16,
        1.5053e-14, 1.3165e-21, 3.0702e-12, 1.6625e-17, 8.6130e-17, 1.7901e-03,
        2.7445e-15, 2.2288e-01, 2.3879e-01, 3.2675e-08, 5.3654e-01, 3.7957e-08],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,367][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0313, 0.0501, 0.0332, 0.0443, 0.0419, 0.0480, 0.0531, 0.0596, 0.0571,
        0.0540, 0.0746, 0.0509, 0.0532, 0.0507, 0.0474, 0.0590, 0.0556, 0.0671,
        0.0687], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,369][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0146, 0.0587, 0.0473, 0.0567, 0.0473, 0.0532, 0.0544, 0.0646, 0.0639,
        0.0622, 0.0556, 0.0545, 0.0462, 0.0496, 0.0519, 0.0517, 0.0589, 0.0582,
        0.0507], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,371][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0547, 0.0590, 0.0443, 0.0437, 0.0475, 0.0517, 0.0663, 0.0508, 0.0536,
        0.0534, 0.0406, 0.0609, 0.0494, 0.0529, 0.0669, 0.0515, 0.0591, 0.0469,
        0.0466], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,372][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0039, 0.0317, 0.0459, 0.0378, 0.0499, 0.0364, 0.0598, 0.0352, 0.0648,
        0.0471, 0.0481, 0.1054, 0.0373, 0.0776, 0.0494, 0.0388, 0.0616, 0.0377,
        0.1315], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,375][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.1414, 0.0475, 0.0416, 0.0435, 0.0459, 0.0507, 0.0545, 0.0552, 0.0461,
        0.0374, 0.0481, 0.0509, 0.0542, 0.0481, 0.0523, 0.0435, 0.0468, 0.0450,
        0.0472], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,377][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0059, 0.0788, 0.0435, 0.0852, 0.0554, 0.0388, 0.0540, 0.0505, 0.0377,
        0.0494, 0.0660, 0.0618, 0.0630, 0.0629, 0.0339, 0.0484, 0.0493, 0.0682,
        0.0473], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,379][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0517, 0.0483, 0.0517, 0.0484, 0.0545, 0.0523, 0.0517, 0.0523, 0.0531,
        0.0524, 0.0512, 0.0574, 0.0555, 0.0605, 0.0532, 0.0517, 0.0530, 0.0503,
        0.0507], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,380][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([3.2143e-05, 4.7229e-04, 6.7695e-04, 2.0670e-04, 1.7093e-03, 2.8218e-03,
        6.1687e-03, 1.7659e-03, 7.4424e-03, 4.9766e-03, 4.9683e-03, 7.8711e-02,
        2.6899e-03, 1.0216e-01, 1.6332e-01, 3.5728e-02, 1.1879e-01, 2.6680e-02,
        4.4068e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,381][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2856, 0.0258, 0.0245, 0.0426, 0.0268, 0.0533, 0.0715, 0.0562, 0.0476,
        0.0302, 0.0301, 0.0526, 0.0324, 0.0375, 0.0516, 0.0266, 0.0389, 0.0313,
        0.0348], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,382][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0618, 0.0598, 0.0679, 0.0247, 0.0426, 0.1011, 0.0511, 0.0717, 0.1672,
        0.0271, 0.0449, 0.0290, 0.0204, 0.0358, 0.0620, 0.0202, 0.0515, 0.0364,
        0.0247], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,383][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.6792, 0.0166, 0.0110, 0.0122, 0.0198, 0.0151, 0.0330, 0.0270, 0.0195,
        0.0139, 0.0103, 0.0215, 0.0107, 0.0187, 0.0203, 0.0128, 0.0175, 0.0065,
        0.0344], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,384][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([7.5237e-14, 2.4217e-23, 3.2295e-18, 9.4502e-29, 2.7802e-17, 3.4555e-17,
        9.3373e-17, 3.9573e-23, 4.0427e-14, 1.8497e-19, 5.9280e-15, 4.4772e-05,
        1.8888e-15, 7.4491e-03, 4.0452e-03, 3.4570e-10, 8.6041e-04, 7.9873e-06,
        9.8759e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,385][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0304, 0.0465, 0.0319, 0.0421, 0.0398, 0.0454, 0.0499, 0.0551, 0.0540,
        0.0511, 0.0683, 0.0480, 0.0498, 0.0472, 0.0453, 0.0553, 0.0528, 0.0623,
        0.0636, 0.0612], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,387][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0122, 0.0589, 0.0466, 0.0557, 0.0465, 0.0519, 0.0523, 0.0620, 0.0599,
        0.0587, 0.0535, 0.0502, 0.0442, 0.0483, 0.0485, 0.0480, 0.0551, 0.0555,
        0.0472, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,389][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0485, 0.0551, 0.0390, 0.0397, 0.0493, 0.0468, 0.0604, 0.0476, 0.0526,
        0.0535, 0.0349, 0.0539, 0.0493, 0.0553, 0.0672, 0.0520, 0.0554, 0.0426,
        0.0424, 0.0547], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,391][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0025, 0.0408, 0.0612, 0.0459, 0.0464, 0.0436, 0.0505, 0.0396, 0.0509,
        0.0429, 0.0380, 0.0715, 0.0301, 0.0726, 0.0635, 0.0456, 0.0636, 0.0432,
        0.0962, 0.0513], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,393][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1326, 0.0463, 0.0403, 0.0420, 0.0444, 0.0489, 0.0531, 0.0537, 0.0444,
        0.0365, 0.0460, 0.0487, 0.0520, 0.0466, 0.0503, 0.0423, 0.0450, 0.0431,
        0.0450, 0.0387], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,395][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0054, 0.0636, 0.0442, 0.0734, 0.0565, 0.0423, 0.0568, 0.0468, 0.0434,
        0.0358, 0.0660, 0.0616, 0.0563, 0.0668, 0.0365, 0.0367, 0.0493, 0.0681,
        0.0534, 0.0370], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,397][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0487, 0.0458, 0.0491, 0.0463, 0.0517, 0.0496, 0.0492, 0.0498, 0.0503,
        0.0497, 0.0488, 0.0542, 0.0524, 0.0572, 0.0508, 0.0494, 0.0506, 0.0482,
        0.0485, 0.0498], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,398][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([6.2483e-06, 4.0572e-04, 3.3729e-04, 2.6787e-04, 7.5028e-04, 2.1014e-03,
        5.1776e-03, 1.3065e-03, 6.8831e-03, 3.7283e-03, 3.0390e-03, 3.4001e-02,
        2.0246e-03, 4.2502e-02, 2.9586e-01, 3.4283e-02, 1.3362e-01, 2.1380e-02,
        2.6842e-01, 1.4391e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,399][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3227, 0.0273, 0.0205, 0.0371, 0.0215, 0.0503, 0.0659, 0.0615, 0.0443,
        0.0318, 0.0284, 0.0426, 0.0300, 0.0311, 0.0444, 0.0261, 0.0372, 0.0280,
        0.0284, 0.0209], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,400][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0714, 0.0387, 0.0913, 0.0156, 0.0494, 0.0802, 0.0752, 0.0327, 0.2099,
        0.0206, 0.0333, 0.0207, 0.0186, 0.0428, 0.0563, 0.0147, 0.0375, 0.0235,
        0.0517, 0.0160], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,401][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.8096, 0.0156, 0.0055, 0.0087, 0.0085, 0.0104, 0.0199, 0.0163, 0.0115,
        0.0091, 0.0076, 0.0098, 0.0075, 0.0083, 0.0097, 0.0083, 0.0090, 0.0044,
        0.0134, 0.0066], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,402][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.8658e-21, 1.2116e-28, 7.6485e-21, 8.5805e-35, 2.7880e-20, 1.1750e-22,
        8.4818e-19, 3.6433e-28, 6.4268e-17, 8.7450e-26, 6.1907e-21, 7.4578e-08,
        4.6892e-21, 3.1758e-06, 2.7937e-07, 2.8185e-16, 5.8863e-07, 1.2334e-11,
        1.0000e+00, 4.9914e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,448][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:44,450][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,451][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,452][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,454][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,455][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,456][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,456][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,458][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,459][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,461][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,462][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,463][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,463][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0618, 0.9382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,464][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0247, 0.9753], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,465][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8114, 0.1886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,466][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3787, 0.6213], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,466][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1541, 0.8459], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,468][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5018, 0.4982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,470][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1430, 0.8570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,472][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,473][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9922, 0.0078], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,475][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2458, 0.7542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,477][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4918, 0.5082], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,478][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([7.4405e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,480][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0201, 0.9148, 0.0651], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,481][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0032, 0.8372, 0.1596], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,482][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.6914, 0.1362, 0.1724], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,482][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.1318, 0.3649, 0.5033], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,483][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0896, 0.4610, 0.4494], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,484][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.3333, 0.3343, 0.3324], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,484][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0662, 0.5208, 0.4130], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,486][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0007, 0.5578, 0.4416], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,488][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.8655, 0.1000, 0.0344], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,490][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.2201, 0.5073, 0.2726], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,491][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.2737, 0.2601, 0.4662], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,493][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([1.1505e-09, 9.9999e-01, 9.7417e-06], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,495][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0571, 0.7093, 0.0467, 0.1868], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,497][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0018, 0.5754, 0.3408, 0.0820], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,498][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4817, 0.1774, 0.1941, 0.1469], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,499][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0869, 0.2259, 0.5272, 0.1600], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,500][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0585, 0.3207, 0.2823, 0.3386], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,500][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2512, 0.2522, 0.2499, 0.2467], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,501][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0456, 0.3310, 0.3433, 0.2802], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,502][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.5983e-05, 2.0920e-01, 5.8574e-02, 7.3213e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,503][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9180, 0.0483, 0.0071, 0.0267], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,505][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1348, 0.3222, 0.4516, 0.0914], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,507][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5036, 0.2522, 0.1480, 0.0961], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,508][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.1254e-12, 4.2975e-03, 9.9570e-01, 1.2910e-06], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,510][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0128, 0.6517, 0.0494, 0.2712, 0.0149], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,512][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0073, 0.1758, 0.0956, 0.0474, 0.6739], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,514][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.4982, 0.0924, 0.1760, 0.0967, 0.1367], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,515][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0452, 0.2018, 0.3057, 0.1588, 0.2885], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,517][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0599, 0.2197, 0.1970, 0.2130, 0.3104], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,518][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.1950, 0.1944, 0.1931, 0.1905, 0.2270], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,518][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0291, 0.2637, 0.2546, 0.2409, 0.2117], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,519][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([1.4240e-04, 9.8433e-02, 9.2573e-02, 1.7060e-01, 6.3825e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,520][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.9267, 0.0308, 0.0238, 0.0127, 0.0060], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,521][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.2920, 0.1072, 0.2288, 0.0405, 0.3315], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,522][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2125, 0.1178, 0.4534, 0.0360, 0.1803], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,524][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([1.4035e-08, 2.2369e-01, 1.0192e-02, 8.1175e-05, 7.6603e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,525][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0154, 0.5562, 0.0346, 0.2862, 0.0377, 0.0698], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,527][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0036, 0.1928, 0.0621, 0.0481, 0.5208, 0.1726], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,528][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.4079, 0.0887, 0.1284, 0.1202, 0.1144, 0.1404], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,530][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0835, 0.1673, 0.2281, 0.1469, 0.2466, 0.1275], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,532][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0451, 0.1852, 0.1616, 0.1792, 0.2213, 0.2076], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,534][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1590, 0.1580, 0.1563, 0.1551, 0.1836, 0.1881], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,535][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0291, 0.2064, 0.2095, 0.1810, 0.2036, 0.1703], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,536][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([8.3714e-05, 9.4173e-02, 2.4720e-02, 1.4420e-01, 1.4868e-01, 5.8814e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,536][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.8080, 0.0617, 0.0146, 0.0461, 0.0132, 0.0563], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,537][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.1028, 0.1064, 0.0935, 0.0345, 0.3451, 0.3176], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,538][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2094, 0.1671, 0.2142, 0.0227, 0.2058, 0.1808], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,539][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([3.7764e-12, 2.5880e-06, 2.5280e-04, 8.5624e-10, 9.9970e-01, 4.9241e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,541][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0203, 0.5009, 0.0638, 0.2667, 0.0320, 0.0936, 0.0227],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,543][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0019, 0.1277, 0.0358, 0.0220, 0.1581, 0.3358, 0.3186],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,544][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.4256, 0.0642, 0.1200, 0.0920, 0.0870, 0.1203, 0.0908],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,546][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0464, 0.1410, 0.2427, 0.1076, 0.2223, 0.1236, 0.1164],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,548][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0312, 0.1639, 0.1399, 0.1668, 0.1930, 0.1643, 0.1409],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,550][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.1324, 0.1319, 0.1296, 0.1286, 0.1546, 0.1584, 0.1645],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,552][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0260, 0.1690, 0.1688, 0.1493, 0.1766, 0.1602, 0.1502],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,553][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([3.5861e-05, 4.0570e-02, 1.0479e-02, 6.3053e-02, 6.9163e-02, 1.6348e-01,
        6.5322e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,554][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.7855, 0.0470, 0.0104, 0.0306, 0.0073, 0.0553, 0.0639],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,554][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0119, 0.0255, 0.0248, 0.0094, 0.1070, 0.3088, 0.5126],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,555][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.2426, 0.1295, 0.0763, 0.0657, 0.2035, 0.0193, 0.2631],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,556][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([1.4495e-11, 5.5244e-05, 5.8791e-06, 3.3049e-09, 4.2824e-01, 4.1262e-01,
        1.5908e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:44,557][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0344, 0.4327, 0.0427, 0.1968, 0.0322, 0.1691, 0.0669, 0.0254],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,558][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([3.6739e-04, 6.3484e-02, 2.6253e-02, 1.7352e-02, 1.7994e-01, 1.4161e-01,
        5.5346e-01, 1.7528e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,560][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.3701, 0.0563, 0.1266, 0.0724, 0.1014, 0.1122, 0.0911, 0.0698],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,561][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0327, 0.1288, 0.1672, 0.1066, 0.2016, 0.1131, 0.1476, 0.1025],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,563][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0227, 0.1461, 0.1263, 0.1444, 0.1629, 0.1413, 0.1128, 0.1435],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,564][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.1132, 0.1118, 0.1109, 0.1099, 0.1335, 0.1365, 0.1423, 0.1419],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,566][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0234, 0.1449, 0.1498, 0.1306, 0.1543, 0.1385, 0.1387, 0.1198],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,567][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([1.9874e-05, 5.0160e-02, 8.5941e-03, 6.9289e-02, 5.7147e-02, 1.4988e-01,
        5.2594e-01, 1.3897e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,569][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.6580, 0.0501, 0.0115, 0.0355, 0.0107, 0.0658, 0.1053, 0.0630],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,571][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0062, 0.0183, 0.0264, 0.0064, 0.0813, 0.1512, 0.6667, 0.0436],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,572][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0963, 0.1626, 0.0845, 0.0246, 0.3074, 0.0298, 0.1911, 0.1038],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,573][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([5.6429e-17, 2.3906e-09, 1.2814e-06, 5.2148e-13, 7.5015e-03, 3.5323e-05,
        9.9246e-01, 2.5047e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:44,573][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0144, 0.3496, 0.0396, 0.2131, 0.0168, 0.1388, 0.0241, 0.1810, 0.0227],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,574][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0025, 0.0210, 0.0099, 0.0034, 0.0561, 0.1366, 0.1259, 0.0667, 0.5779],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,575][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2739, 0.0619, 0.0692, 0.0753, 0.1076, 0.1445, 0.0801, 0.1159, 0.0715],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,577][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0296, 0.1228, 0.1539, 0.1283, 0.1814, 0.1135, 0.1267, 0.1083, 0.0356],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,579][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0219, 0.1379, 0.1182, 0.1280, 0.1542, 0.1273, 0.0926, 0.1191, 0.1009],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,581][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0968, 0.0965, 0.0971, 0.0949, 0.1154, 0.1170, 0.1233, 0.1250, 0.1339],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,582][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0209, 0.1307, 0.1286, 0.1189, 0.1275, 0.1276, 0.1255, 0.1130, 0.1075],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,584][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([4.4798e-05, 1.7341e-02, 8.4800e-03, 1.5486e-02, 3.5529e-02, 6.9904e-02,
        2.4300e-01, 4.5503e-02, 5.6471e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,586][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.7553, 0.0317, 0.0087, 0.0295, 0.0047, 0.0356, 0.0681, 0.0379, 0.0284],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,587][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0229, 0.0090, 0.0085, 0.0025, 0.0334, 0.1889, 0.5225, 0.0721, 0.1403],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,589][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1601, 0.1035, 0.0470, 0.0405, 0.1248, 0.0195, 0.0955, 0.0856, 0.3236],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,590][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([6.5221e-12, 7.9154e-10, 3.0424e-07, 1.7445e-13, 5.2519e-03, 2.5733e-04,
        2.4128e-03, 1.4954e-08, 9.9208e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:44,590][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0224, 0.3043, 0.0250, 0.1337, 0.0217, 0.1248, 0.0643, 0.0620, 0.1205,
        0.1212], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,591][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.5767e-04, 2.1340e-03, 3.8505e-03, 5.1901e-04, 3.3097e-02, 2.0419e-02,
        2.8294e-02, 2.8075e-03, 8.7298e-01, 3.5346e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,592][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2837, 0.0665, 0.0886, 0.0655, 0.0915, 0.1002, 0.0879, 0.0716, 0.0879,
        0.0567], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,593][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0213, 0.1059, 0.1690, 0.0892, 0.1736, 0.1080, 0.1093, 0.1047, 0.0441,
        0.0751], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,595][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0186, 0.1185, 0.1017, 0.1188, 0.1374, 0.1149, 0.0840, 0.1029, 0.0847,
        0.1184], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,597][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0852, 0.0844, 0.0862, 0.0833, 0.1026, 0.1037, 0.1100, 0.1105, 0.1192,
        0.1150], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,599][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0165, 0.1160, 0.1174, 0.1060, 0.1142, 0.1093, 0.1127, 0.1036, 0.0998,
        0.1046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,600][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.0649e-05, 1.6419e-02, 6.5943e-03, 1.4671e-02, 2.5300e-02, 4.7828e-02,
        1.8585e-01, 5.2837e-02, 4.3343e-01, 2.1703e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,602][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6350, 0.0328, 0.0075, 0.0285, 0.0069, 0.0567, 0.0770, 0.0578, 0.0602,
        0.0377], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,604][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0105, 0.0044, 0.0086, 0.0013, 0.0374, 0.0676, 0.2670, 0.0160, 0.5042,
        0.0831], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,605][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1833, 0.1240, 0.0574, 0.0436, 0.0506, 0.0154, 0.0898, 0.2273, 0.1589,
        0.0497], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,607][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.1071e-17, 9.4296e-16, 1.1510e-10, 7.2653e-20, 1.3535e-07, 9.2682e-10,
        2.4586e-05, 5.3541e-14, 9.9998e-01, 3.1659e-09], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:44,607][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0219, 0.2672, 0.0134, 0.1215, 0.0113, 0.0608, 0.0395, 0.0559, 0.0284,
        0.3585, 0.0215], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,608][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0047, 0.0042, 0.0066, 0.0009, 0.0409, 0.0258, 0.0532, 0.0049, 0.5277,
        0.1259, 0.2052], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,609][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2680, 0.0636, 0.0838, 0.0586, 0.0941, 0.1082, 0.0668, 0.0707, 0.0707,
        0.0461, 0.0693], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,610][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0180, 0.0957, 0.1504, 0.0901, 0.1569, 0.0997, 0.0935, 0.1020, 0.0465,
        0.0837, 0.0635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,611][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0183, 0.1008, 0.0889, 0.1033, 0.1223, 0.1071, 0.0845, 0.1029, 0.0710,
        0.0998, 0.1012], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,613][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0771, 0.0761, 0.0771, 0.0749, 0.0915, 0.0925, 0.0978, 0.0990, 0.1064,
        0.1034, 0.1043], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,615][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0150, 0.1041, 0.1078, 0.0947, 0.1051, 0.0962, 0.1025, 0.0922, 0.0931,
        0.0973, 0.0920], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,616][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.0439e-04, 6.9139e-03, 6.1211e-03, 8.0585e-03, 2.7673e-02, 5.4614e-02,
        1.5187e-01, 3.5245e-02, 3.9687e-01, 1.7318e-01, 1.3935e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,618][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6030, 0.0333, 0.0091, 0.0310, 0.0079, 0.0659, 0.0605, 0.0531, 0.0590,
        0.0417, 0.0355], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,620][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0377, 0.0040, 0.0099, 0.0013, 0.0420, 0.0694, 0.2534, 0.0285, 0.2561,
        0.1343, 0.1634], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,622][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1908, 0.0737, 0.0630, 0.0223, 0.0820, 0.0520, 0.1374, 0.1798, 0.1407,
        0.0234, 0.0349], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,623][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.2982e-12, 4.8724e-14, 3.6137e-09, 4.8942e-17, 1.7227e-06, 3.6550e-07,
        3.8773e-05, 3.3636e-11, 9.9984e-01, 1.4051e-05, 1.0885e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:44,625][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.0054, 0.2949, 0.0226, 0.1242, 0.0141, 0.0363, 0.0139, 0.0437, 0.0230,
        0.3580, 0.0583, 0.0057], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,625][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([1.0087e-03, 2.3416e-05, 8.3229e-05, 3.7448e-06, 4.4575e-04, 3.4588e-04,
        3.4847e-04, 4.7983e-05, 2.5550e-03, 6.4555e-04, 3.7371e-03, 9.9076e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,626][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.2891, 0.0465, 0.1600, 0.0480, 0.0812, 0.1189, 0.0425, 0.0552, 0.0460,
        0.0246, 0.0607, 0.0273], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,627][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.0244, 0.0930, 0.1545, 0.0729, 0.1399, 0.0883, 0.0974, 0.0700, 0.0365,
        0.0678, 0.0631, 0.0922], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,628][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.0181, 0.0942, 0.0785, 0.0958, 0.1081, 0.0938, 0.0752, 0.0913, 0.0672,
        0.0903, 0.0944, 0.0932], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,629][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.0714, 0.0700, 0.0685, 0.0671, 0.0802, 0.0825, 0.0858, 0.0865, 0.0939,
        0.0911, 0.0926, 0.1104], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,631][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0131, 0.0976, 0.0922, 0.0866, 0.0935, 0.0915, 0.0969, 0.0843, 0.0824,
        0.0905, 0.0876, 0.0839], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,632][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([6.6778e-05, 2.1779e-03, 2.5036e-03, 1.2458e-03, 7.9917e-03, 8.5903e-03,
        2.8460e-02, 5.3917e-03, 4.6565e-02, 3.2771e-02, 2.9568e-02, 8.3467e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,634][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.8025, 0.0307, 0.0089, 0.0097, 0.0068, 0.0268, 0.0252, 0.0166, 0.0217,
        0.0097, 0.0158, 0.0256], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,635][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([5.3805e-02, 9.3558e-04, 1.6698e-03, 1.8003e-04, 1.3757e-02, 1.5891e-02,
        5.7277e-02, 4.3626e-03, 3.1879e-02, 1.7536e-02, 3.7458e-02, 7.6525e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,637][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.0560, 0.0529, 0.2113, 0.0139, 0.1842, 0.0220, 0.2192, 0.0513, 0.0344,
        0.0135, 0.0121, 0.1292], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,639][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([2.2055e-14, 4.2341e-21, 1.7887e-17, 1.6968e-25, 1.8249e-14, 7.0059e-15,
        5.7340e-14, 2.9315e-19, 9.7141e-10, 2.5365e-14, 9.8802e-10, 1.0000e+00],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:44,641][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0155, 0.2140, 0.0208, 0.0813, 0.0197, 0.0645, 0.0329, 0.0433, 0.0517,
        0.2846, 0.0954, 0.0140, 0.0622], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,642][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.3453e-05, 7.9362e-05, 1.2459e-04, 2.5790e-05, 5.3170e-04, 3.5271e-04,
        5.7153e-04, 1.0140e-04, 1.0334e-02, 2.1986e-03, 5.9159e-03, 9.7937e-01,
        3.8211e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,643][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2015, 0.0594, 0.0931, 0.0593, 0.0758, 0.1059, 0.0622, 0.0744, 0.0663,
        0.0481, 0.0644, 0.0235, 0.0662], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,644][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0385, 0.0738, 0.1415, 0.0613, 0.1391, 0.0676, 0.0905, 0.0732, 0.0488,
        0.0577, 0.0676, 0.0909, 0.0495], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,645][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0151, 0.0843, 0.0695, 0.0881, 0.0966, 0.0858, 0.0678, 0.0822, 0.0625,
        0.0822, 0.0837, 0.0788, 0.1033], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,646][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0660, 0.0639, 0.0630, 0.0616, 0.0747, 0.0764, 0.0800, 0.0790, 0.0852,
        0.0826, 0.0838, 0.0995, 0.0842], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,647][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0136, 0.0849, 0.0891, 0.0759, 0.0882, 0.0804, 0.0840, 0.0772, 0.0772,
        0.0835, 0.0792, 0.0829, 0.0838], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,648][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([5.1449e-06, 3.2400e-03, 1.2316e-03, 5.7509e-03, 7.8031e-03, 1.1866e-02,
        4.3157e-02, 1.3250e-02, 1.1046e-01, 5.9348e-02, 4.2670e-02, 6.7556e-01,
        2.5656e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,651][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.3288, 0.0365, 0.0138, 0.0366, 0.0124, 0.0786, 0.0968, 0.0613, 0.0776,
        0.0486, 0.0613, 0.0739, 0.0737], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,652][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.9912e-03, 9.8729e-04, 1.9111e-03, 4.6811e-04, 7.1439e-03, 2.0107e-02,
        5.7352e-02, 7.4108e-03, 8.0094e-02, 2.8401e-02, 6.1476e-02, 7.1839e-01,
        1.4266e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,654][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1463, 0.0697, 0.0473, 0.0171, 0.2637, 0.0075, 0.1299, 0.0597, 0.1009,
        0.0159, 0.0119, 0.0510, 0.0790], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,655][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([6.9474e-24, 2.6153e-23, 2.9263e-18, 2.8143e-26, 1.9298e-15, 2.2175e-17,
        9.1453e-14, 6.0571e-21, 6.7397e-10, 2.3033e-16, 9.2608e-12, 1.0000e+00,
        1.1739e-15], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:44,657][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0048, 0.2510, 0.0168, 0.1344, 0.0041, 0.0339, 0.0096, 0.0999, 0.0090,
        0.2799, 0.0695, 0.0049, 0.0778, 0.0044], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,658][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([9.9907e-04, 1.6306e-05, 4.2194e-05, 2.6115e-06, 1.1698e-04, 3.5271e-04,
        2.0398e-04, 1.7031e-05, 7.7214e-04, 2.7918e-04, 1.2364e-03, 3.3788e-01,
        4.7452e-04, 6.5761e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,660][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.2544, 0.0431, 0.0955, 0.0476, 0.0686, 0.0971, 0.0341, 0.0564, 0.0426,
        0.0278, 0.0575, 0.0352, 0.0565, 0.0837], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,661][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0230, 0.0813, 0.1144, 0.0649, 0.1154, 0.0671, 0.0670, 0.0674, 0.0261,
        0.0647, 0.0710, 0.0748, 0.0638, 0.0992], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,662][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0192, 0.0737, 0.0630, 0.0724, 0.0991, 0.0735, 0.0586, 0.0746, 0.0582,
        0.0759, 0.0738, 0.0705, 0.0835, 0.1039], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,663][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0594, 0.0577, 0.0576, 0.0566, 0.0671, 0.0693, 0.0719, 0.0720, 0.0779,
        0.0752, 0.0765, 0.0911, 0.0764, 0.0910], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,664][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0105, 0.0820, 0.0809, 0.0761, 0.0671, 0.0730, 0.0812, 0.0731, 0.0707,
        0.0776, 0.0752, 0.0784, 0.0860, 0.0682], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,664][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([4.6330e-05, 1.1056e-03, 2.9014e-03, 8.5735e-04, 9.6334e-03, 1.3173e-02,
        1.7517e-02, 5.9653e-03, 3.7635e-02, 2.0934e-02, 2.5804e-02, 2.6861e-01,
        9.6898e-03, 5.8613e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,667][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.5975, 0.0231, 0.0281, 0.0146, 0.0061, 0.0473, 0.0566, 0.0399, 0.0272,
        0.0209, 0.0279, 0.0587, 0.0414, 0.0107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,668][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([5.5658e-02, 3.4583e-04, 1.3880e-03, 1.1172e-04, 1.5320e-03, 1.0925e-02,
        8.8681e-03, 1.4667e-03, 1.3095e-02, 6.9417e-03, 2.3080e-02, 3.5629e-01,
        9.5422e-03, 5.1075e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,670][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0667, 0.0352, 0.1277, 0.0123, 0.0511, 0.0100, 0.1855, 0.2167, 0.0444,
        0.0387, 0.0084, 0.0635, 0.0879, 0.0517], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,671][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([3.2053e-13, 1.3634e-19, 3.2861e-16, 2.3040e-24, 3.3992e-16, 1.4394e-13,
        2.0058e-13, 1.7747e-19, 6.6074e-10, 3.5092e-15, 2.7400e-10, 3.7988e-01,
        9.0025e-11, 6.2012e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:44,673][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0053, 0.2340, 0.0145, 0.1301, 0.0068, 0.0483, 0.0061, 0.0551, 0.0075,
        0.3410, 0.0442, 0.0029, 0.0934, 0.0071, 0.0037], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,675][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([4.1101e-04, 2.7039e-05, 5.3155e-05, 2.1889e-06, 1.0796e-04, 1.1781e-04,
        2.0433e-04, 1.4772e-05, 4.7326e-04, 8.9154e-05, 1.2424e-03, 2.9977e-01,
        4.1143e-04, 5.5879e-01, 1.3828e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,677][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.2430, 0.0384, 0.0673, 0.0511, 0.0502, 0.0779, 0.0610, 0.0575, 0.0573,
        0.0347, 0.0631, 0.0240, 0.0579, 0.0662, 0.0504], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,678][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0324, 0.0744, 0.1232, 0.0747, 0.1198, 0.0573, 0.0645, 0.0591, 0.0297,
        0.0623, 0.0629, 0.0698, 0.0513, 0.0936, 0.0251], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,679][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0130, 0.0726, 0.0584, 0.0718, 0.0847, 0.0768, 0.0574, 0.0729, 0.0509,
        0.0683, 0.0691, 0.0632, 0.0850, 0.0858, 0.0701], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,680][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0552, 0.0540, 0.0528, 0.0527, 0.0632, 0.0657, 0.0675, 0.0678, 0.0720,
        0.0705, 0.0712, 0.0868, 0.0724, 0.0873, 0.0608], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,681][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0155, 0.0727, 0.0763, 0.0665, 0.0757, 0.0694, 0.0709, 0.0646, 0.0663,
        0.0684, 0.0667, 0.0760, 0.0713, 0.0756, 0.0642], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,682][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([6.2099e-06, 8.2134e-04, 6.1942e-04, 7.5224e-04, 1.5945e-03, 9.5486e-03,
        1.2689e-02, 3.0860e-03, 2.6212e-02, 9.1283e-03, 5.7635e-03, 6.7901e-02,
        3.8611e-03, 8.4997e-02, 7.7302e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,684][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.6492, 0.0229, 0.0064, 0.0239, 0.0030, 0.0456, 0.0363, 0.0332, 0.0364,
        0.0297, 0.0276, 0.0250, 0.0361, 0.0032, 0.0213], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,686][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([7.8869e-03, 4.0437e-04, 6.5025e-04, 6.1638e-05, 1.1695e-03, 3.5248e-03,
        5.7854e-03, 1.0704e-03, 3.4564e-03, 6.1401e-03, 1.1241e-02, 1.9652e-01,
        6.2884e-03, 3.2658e-01, 4.2922e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,687][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.1112, 0.0542, 0.0234, 0.0199, 0.0832, 0.0448, 0.0743, 0.0715, 0.1017,
        0.0301, 0.0144, 0.0368, 0.0637, 0.0823, 0.1885], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,689][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([1.7553e-17, 3.5826e-23, 1.5710e-17, 2.0439e-28, 2.3619e-15, 9.9486e-19,
        4.4008e-18, 3.9814e-24, 1.8998e-15, 2.6819e-19, 1.9461e-15, 2.7673e-05,
        5.3701e-15, 9.9997e-01, 4.7360e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:44,690][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0142, 0.2036, 0.0128, 0.0914, 0.0115, 0.1038, 0.0394, 0.0393, 0.0744,
        0.0828, 0.0717, 0.0093, 0.0786, 0.0132, 0.0670, 0.0869],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,692][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1397e-05, 5.7204e-06, 2.3631e-05, 9.5516e-07, 1.0392e-04, 1.0051e-04,
        8.5051e-05, 7.9605e-06, 1.3661e-03, 4.9389e-05, 4.5721e-04, 3.1795e-01,
        5.9578e-05, 3.1513e-01, 3.5865e-01, 5.9748e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,693][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2011, 0.0497, 0.0632, 0.0452, 0.0658, 0.0746, 0.0593, 0.0502, 0.0602,
        0.0398, 0.0461, 0.0194, 0.0566, 0.0804, 0.0535, 0.0349],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,695][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0191, 0.0681, 0.1093, 0.0591, 0.1134, 0.0619, 0.0700, 0.0669, 0.0278,
        0.0463, 0.0609, 0.0820, 0.0500, 0.0973, 0.0327, 0.0353],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,696][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0107, 0.0692, 0.0575, 0.0700, 0.0786, 0.0670, 0.0495, 0.0637, 0.0490,
        0.0681, 0.0653, 0.0593, 0.0809, 0.0825, 0.0592, 0.0694],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,697][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0522, 0.0502, 0.0495, 0.0487, 0.0595, 0.0612, 0.0639, 0.0631, 0.0677,
        0.0657, 0.0667, 0.0823, 0.0685, 0.0823, 0.0570, 0.0615],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,698][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0104, 0.0699, 0.0719, 0.0632, 0.0700, 0.0656, 0.0686, 0.0626, 0.0597,
        0.0629, 0.0639, 0.0700, 0.0690, 0.0707, 0.0601, 0.0614],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,699][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.3513e-06, 5.7764e-04, 4.2128e-04, 4.3839e-04, 1.1670e-03, 2.7666e-03,
        8.9338e-03, 2.0604e-03, 1.4753e-02, 6.9709e-03, 6.0099e-03, 8.5031e-02,
        3.5311e-03, 9.5034e-02, 7.0014e-01, 7.2163e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,700][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4418, 0.0246, 0.0070, 0.0263, 0.0059, 0.0566, 0.0573, 0.0448, 0.0536,
        0.0317, 0.0419, 0.0502, 0.0604, 0.0087, 0.0530, 0.0363],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,701][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3824e-03, 7.4672e-05, 2.2876e-04, 1.4900e-05, 6.1657e-04, 1.5065e-03,
        3.4513e-03, 2.3024e-04, 5.8612e-03, 9.1799e-04, 2.9526e-03, 5.9910e-02,
        1.6089e-03, 1.5249e-01, 7.5038e-01, 1.8368e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,703][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1225, 0.0876, 0.0428, 0.0296, 0.0318, 0.0101, 0.0639, 0.1364, 0.1093,
        0.0340, 0.0247, 0.0687, 0.0811, 0.0331, 0.0930, 0.0315],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,704][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.6860e-21, 9.0927e-26, 1.4014e-18, 4.3452e-31, 5.8576e-17, 2.5772e-19,
        2.5119e-15, 8.7996e-25, 2.6893e-12, 3.8473e-21, 4.1257e-16, 1.4899e-02,
        7.1118e-17, 8.7577e-01, 1.0933e-01, 9.7246e-11], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:44,706][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0040, 0.1424, 0.0175, 0.0754, 0.0067, 0.0452, 0.0120, 0.0762, 0.0140,
        0.2090, 0.0471, 0.0034, 0.0648, 0.0090, 0.0233, 0.2388, 0.0112],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,707][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.4694e-04, 8.1918e-06, 2.8447e-05, 1.1267e-06, 8.3923e-05, 1.4528e-04,
        1.5497e-04, 8.7961e-06, 4.3037e-04, 2.3598e-04, 3.3794e-04, 2.7058e-01,
        8.2291e-05, 2.0917e-01, 3.8796e-01, 2.4645e-02, 1.0598e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,710][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1623, 0.0437, 0.0613, 0.0419, 0.0690, 0.0708, 0.0692, 0.0566, 0.0455,
        0.0357, 0.0487, 0.0210, 0.0533, 0.0899, 0.0644, 0.0319, 0.0348],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,711][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0168, 0.0699, 0.1243, 0.0552, 0.1185, 0.0599, 0.0545, 0.0555, 0.0295,
        0.0519, 0.0492, 0.0637, 0.0514, 0.0998, 0.0228, 0.0401, 0.0369],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,713][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0101, 0.0653, 0.0511, 0.0662, 0.0738, 0.0638, 0.0464, 0.0593, 0.0487,
        0.0656, 0.0625, 0.0551, 0.0737, 0.0760, 0.0575, 0.0676, 0.0572],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,715][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0496, 0.0482, 0.0474, 0.0470, 0.0556, 0.0572, 0.0593, 0.0596, 0.0638,
        0.0617, 0.0628, 0.0743, 0.0632, 0.0749, 0.0536, 0.0580, 0.0636],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,715][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0108, 0.0667, 0.0632, 0.0591, 0.0668, 0.0628, 0.0628, 0.0585, 0.0576,
        0.0602, 0.0605, 0.0621, 0.0657, 0.0669, 0.0588, 0.0590, 0.0586],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,716][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([4.7368e-06, 5.1896e-04, 2.7215e-04, 5.5527e-04, 9.4936e-04, 4.7150e-03,
        7.9437e-03, 1.6587e-03, 9.8777e-03, 6.6487e-03, 4.8342e-03, 7.6112e-02,
        2.8797e-03, 4.3798e-02, 5.0222e-01, 5.8550e-02, 2.7846e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,717][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.5639, 0.0240, 0.0087, 0.0226, 0.0036, 0.0501, 0.0578, 0.0392, 0.0413,
        0.0281, 0.0239, 0.0236, 0.0343, 0.0047, 0.0352, 0.0243, 0.0147],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,718][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([2.5378e-03, 1.0399e-04, 2.3197e-04, 2.0952e-05, 7.8950e-04, 1.7660e-03,
        7.2719e-03, 3.7758e-04, 8.4202e-03, 2.5521e-03, 3.1762e-03, 6.2027e-02,
        1.9683e-03, 1.9002e-01, 5.8459e-01, 5.0564e-02, 8.3583e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,720][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.1637, 0.0270, 0.0882, 0.0200, 0.0434, 0.0046, 0.1344, 0.0984, 0.1776,
        0.0166, 0.0214, 0.0142, 0.0464, 0.0420, 0.0377, 0.0137, 0.0506],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,722][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([2.7955e-17, 1.2221e-23, 1.6147e-17, 1.3429e-28, 8.7701e-16, 4.6116e-17,
        7.1768e-16, 8.9798e-23, 2.6198e-13, 8.9342e-18, 9.0244e-16, 1.9792e-03,
        2.3626e-15, 9.7958e-01, 1.5697e-02, 4.8797e-08, 2.7443e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:44,724][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0117, 0.2191, 0.0066, 0.0729, 0.0056, 0.0415, 0.0207, 0.0263, 0.0172,
        0.1641, 0.0174, 0.0071, 0.0843, 0.0076, 0.0224, 0.1999, 0.0646, 0.0111],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,725][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.3608e-04, 2.6123e-05, 9.3755e-05, 3.3233e-06, 2.2164e-04, 2.2353e-04,
        3.2822e-04, 3.3799e-05, 8.5262e-04, 2.3924e-04, 3.5918e-04, 2.4676e-01,
        1.9633e-04, 2.5326e-01, 2.7404e-01, 2.0854e-02, 1.7821e-01, 2.3968e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,727][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1699, 0.0433, 0.0645, 0.0385, 0.0711, 0.0845, 0.0512, 0.0478, 0.0481,
        0.0294, 0.0444, 0.0204, 0.0539, 0.0883, 0.0544, 0.0255, 0.0322, 0.0325],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,729][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0213, 0.0628, 0.0933, 0.0599, 0.0888, 0.0611, 0.0599, 0.0606, 0.0307,
        0.0528, 0.0436, 0.0789, 0.0544, 0.0794, 0.0314, 0.0409, 0.0460, 0.0341],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,731][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0105, 0.0594, 0.0534, 0.0611, 0.0709, 0.0621, 0.0468, 0.0598, 0.0453,
        0.0572, 0.0587, 0.0554, 0.0691, 0.0733, 0.0574, 0.0599, 0.0463, 0.0534],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,732][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0470, 0.0455, 0.0448, 0.0443, 0.0526, 0.0542, 0.0561, 0.0563, 0.0593,
        0.0572, 0.0582, 0.0697, 0.0591, 0.0706, 0.0508, 0.0546, 0.0601, 0.0595],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,733][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0087, 0.0606, 0.0633, 0.0558, 0.0617, 0.0577, 0.0595, 0.0546, 0.0542,
        0.0571, 0.0576, 0.0630, 0.0635, 0.0629, 0.0551, 0.0562, 0.0595, 0.0491],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,734][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([7.6422e-06, 4.9158e-04, 4.7458e-04, 5.1566e-04, 1.6829e-03, 3.7899e-03,
        9.5722e-03, 1.7417e-03, 1.5882e-02, 6.2356e-03, 5.7669e-03, 6.5415e-02,
        3.7188e-03, 8.0380e-02, 5.3421e-01, 5.1563e-02, 1.8501e-01, 3.3540e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,735][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3442, 0.0256, 0.0098, 0.0268, 0.0061, 0.0725, 0.0444, 0.0407, 0.0532,
        0.0343, 0.0430, 0.0430, 0.0616, 0.0079, 0.0541, 0.0361, 0.0325, 0.0642],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,736][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0134e-03, 1.2212e-04, 3.0360e-04, 2.3638e-05, 9.0177e-04, 2.4580e-03,
        6.7189e-03, 6.5493e-04, 4.0563e-03, 2.0696e-03, 2.3482e-03, 5.9433e-02,
        1.7684e-03, 1.2126e-01, 5.7556e-01, 3.3186e-02, 1.4944e-01, 3.5683e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,738][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0509, 0.0611, 0.0765, 0.0123, 0.0989, 0.0244, 0.1063, 0.0632, 0.0644,
        0.0140, 0.0204, 0.0712, 0.0747, 0.1112, 0.0759, 0.0142, 0.0353, 0.0251],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,740][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.4272e-18, 3.1728e-23, 1.7234e-16, 1.0229e-27, 1.4852e-15, 2.9211e-16,
        1.5053e-14, 1.3165e-21, 3.0702e-12, 1.6625e-17, 8.6130e-17, 1.7901e-03,
        2.7445e-15, 2.2288e-01, 2.3879e-01, 3.2675e-08, 5.3654e-01, 3.7957e-08],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:44,742][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0076, 0.1362, 0.0150, 0.0868, 0.0068, 0.0130, 0.0047, 0.0429, 0.0154,
        0.3281, 0.0213, 0.0043, 0.0458, 0.0070, 0.0045, 0.2260, 0.0110, 0.0165,
        0.0072], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,743][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([2.5516e-04, 1.6451e-06, 6.5608e-06, 2.0735e-07, 8.8688e-06, 4.3344e-05,
        2.8895e-05, 2.5695e-06, 9.6966e-05, 1.6778e-05, 1.1198e-04, 3.3845e-02,
        2.6034e-05, 2.6108e-02, 4.6397e-02, 2.1559e-03, 3.6727e-02, 1.5922e-02,
        8.3825e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,745][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1801, 0.0427, 0.0761, 0.0413, 0.0489, 0.0824, 0.0609, 0.0493, 0.0437,
        0.0269, 0.0541, 0.0254, 0.0441, 0.0613, 0.0424, 0.0239, 0.0362, 0.0349,
        0.0253], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,747][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0354, 0.0540, 0.1066, 0.0475, 0.0936, 0.0468, 0.0614, 0.0509, 0.0281,
        0.0446, 0.0588, 0.0613, 0.0359, 0.0749, 0.0257, 0.0327, 0.0445, 0.0473,
        0.0498], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,749][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0120, 0.0571, 0.0483, 0.0612, 0.0689, 0.0538, 0.0463, 0.0548, 0.0397,
        0.0580, 0.0579, 0.0520, 0.0678, 0.0691, 0.0491, 0.0571, 0.0442, 0.0459,
        0.0570], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,751][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0446, 0.0428, 0.0417, 0.0410, 0.0492, 0.0511, 0.0532, 0.0527, 0.0573,
        0.0548, 0.0559, 0.0671, 0.0562, 0.0669, 0.0463, 0.0504, 0.0565, 0.0559,
        0.0566], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,751][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0091, 0.0602, 0.0605, 0.0527, 0.0599, 0.0566, 0.0565, 0.0533, 0.0499,
        0.0546, 0.0527, 0.0540, 0.0564, 0.0583, 0.0543, 0.0525, 0.0580, 0.0485,
        0.0520], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,752][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([3.2143e-05, 4.7229e-04, 6.7695e-04, 2.0670e-04, 1.7093e-03, 2.8218e-03,
        6.1687e-03, 1.7659e-03, 7.4424e-03, 4.9766e-03, 4.9683e-03, 7.8711e-02,
        2.6899e-03, 1.0216e-01, 1.6332e-01, 3.5728e-02, 1.1879e-01, 2.6680e-02,
        4.4068e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,753][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.5831, 0.0225, 0.0202, 0.0148, 0.0079, 0.0298, 0.0299, 0.0222, 0.0196,
        0.0155, 0.0292, 0.0515, 0.0314, 0.0096, 0.0353, 0.0138, 0.0157, 0.0379,
        0.0103], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,754][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([1.5448e-02, 1.0289e-04, 3.3464e-04, 1.4350e-05, 1.0545e-03, 1.5140e-03,
        2.1051e-03, 4.1639e-04, 1.1554e-03, 8.8608e-04, 2.4875e-03, 8.4432e-02,
        1.3470e-03, 1.7494e-01, 2.5149e-01, 1.5538e-02, 6.2091e-02, 5.2349e-02,
        3.3229e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,756][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0753, 0.0105, 0.0691, 0.0058, 0.0454, 0.0117, 0.0729, 0.0566, 0.0416,
        0.0056, 0.0089, 0.0248, 0.0168, 0.0483, 0.0169, 0.0057, 0.0187, 0.0087,
        0.4569], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,758][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([7.5237e-14, 2.4217e-23, 3.2295e-18, 9.4502e-29, 2.7802e-17, 3.4555e-17,
        9.3373e-17, 3.9573e-23, 4.0427e-14, 1.8497e-19, 5.9280e-15, 4.4772e-05,
        1.8888e-15, 7.4491e-03, 4.0452e-03, 3.4570e-10, 8.6041e-04, 7.9873e-06,
        9.8759e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:44,760][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0135, 0.1480, 0.0084, 0.0715, 0.0069, 0.0876, 0.0274, 0.0312, 0.0659,
        0.0627, 0.0503, 0.0060, 0.0537, 0.0074, 0.0574, 0.0648, 0.0781, 0.0528,
        0.0254, 0.0812], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,761][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0659e-04, 3.0114e-06, 1.1873e-05, 2.9010e-07, 3.0660e-05, 4.4852e-05,
        2.6547e-05, 2.7181e-06, 2.3420e-04, 9.5650e-06, 8.2998e-05, 4.0273e-02,
        1.4754e-05, 3.5614e-02, 4.7071e-02, 7.9912e-04, 1.5995e-02, 9.7987e-03,
        8.2198e-01, 2.7901e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,763][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1963, 0.0435, 0.0572, 0.0387, 0.0538, 0.0657, 0.0485, 0.0427, 0.0509,
        0.0344, 0.0403, 0.0161, 0.0504, 0.0663, 0.0452, 0.0305, 0.0328, 0.0310,
        0.0194, 0.0361], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,765][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0188, 0.0545, 0.0955, 0.0451, 0.0885, 0.0512, 0.0616, 0.0517, 0.0270,
        0.0349, 0.0472, 0.0696, 0.0421, 0.0770, 0.0291, 0.0274, 0.0421, 0.0391,
        0.0619, 0.0358], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,767][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0102, 0.0564, 0.0461, 0.0569, 0.0614, 0.0548, 0.0401, 0.0508, 0.0406,
        0.0541, 0.0532, 0.0489, 0.0654, 0.0645, 0.0491, 0.0554, 0.0429, 0.0467,
        0.0429, 0.0596], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,768][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0428, 0.0414, 0.0399, 0.0397, 0.0468, 0.0487, 0.0500, 0.0500, 0.0536,
        0.0516, 0.0528, 0.0628, 0.0533, 0.0627, 0.0440, 0.0477, 0.0532, 0.0529,
        0.0534, 0.0525], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,769][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0082, 0.0557, 0.0563, 0.0503, 0.0557, 0.0519, 0.0542, 0.0499, 0.0471,
        0.0499, 0.0506, 0.0563, 0.0551, 0.0565, 0.0470, 0.0488, 0.0538, 0.0455,
        0.0583, 0.0488], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,770][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.2483e-06, 4.0572e-04, 3.3729e-04, 2.6787e-04, 7.5028e-04, 2.1014e-03,
        5.1776e-03, 1.3065e-03, 6.8831e-03, 3.7283e-03, 3.0390e-03, 3.4001e-02,
        2.0246e-03, 4.2502e-02, 2.9586e-01, 3.4283e-02, 1.3362e-01, 2.1380e-02,
        2.6842e-01, 1.4391e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,771][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3333, 0.0222, 0.0063, 0.0243, 0.0051, 0.0560, 0.0553, 0.0440, 0.0514,
        0.0302, 0.0359, 0.0413, 0.0529, 0.0074, 0.0486, 0.0335, 0.0294, 0.0704,
        0.0182, 0.0340], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,772][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2856e-03, 5.7406e-05, 2.0816e-04, 1.0711e-05, 4.2453e-04, 1.3253e-03,
        2.0400e-03, 1.7365e-04, 3.0551e-03, 5.3016e-04, 1.5307e-03, 2.0665e-02,
        9.4985e-04, 5.9969e-02, 3.4753e-01, 8.8734e-03, 8.0718e-02, 3.4777e-02,
        3.5909e-01, 7.4795e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,774][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1059, 0.0766, 0.0397, 0.0241, 0.0277, 0.0086, 0.0657, 0.1136, 0.0968,
        0.0277, 0.0217, 0.0591, 0.0706, 0.0290, 0.0837, 0.0257, 0.0354, 0.0266,
        0.0381, 0.0236], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,776][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.8658e-21, 1.2116e-28, 7.6485e-21, 8.5805e-35, 2.7880e-20, 1.1750e-22,
        8.4818e-19, 3.6433e-28, 6.4268e-17, 8.7450e-26, 6.1907e-21, 7.4578e-08,
        4.6892e-21, 3.1758e-06, 2.7937e-07, 2.8185e-16, 5.8863e-07, 1.2334e-11,
        1.0000e+00, 4.9914e-10], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:44,780][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:44,782][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15298],
        [ 2242],
        [ 4330],
        [ 2728],
        [ 1493],
        [ 1480],
        [ 4913],
        [ 1151],
        [ 8417],
        [ 2154],
        [ 1548],
        [ 1299],
        [ 2966],
        [ 1483],
        [ 5650],
        [ 2919],
        [ 4526],
        [ 3019],
        [ 3319],
        [ 2134]], device='cuda:0')
[2024-07-24 10:18:44,784][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17172],
        [21597],
        [18114],
        [15996],
        [ 5786],
        [ 6384],
        [19397],
        [10711],
        [25728],
        [ 8460],
        [10361],
        [ 5791],
        [12016],
        [ 6842],
        [18999],
        [11049],
        [14195],
        [ 7296],
        [10149],
        [ 8491]], device='cuda:0')
[2024-07-24 10:18:44,787][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[6832],
        [6058],
        [6318],
        [6379],
        [6745],
        [6696],
        [6697],
        [6456],
        [6752],
        [6927],
        [6849],
        [6950],
        [6977],
        [7091],
        [7176],
        [7293],
        [7462],
        [7575],
        [7767],
        [7834]], device='cuda:0')
[2024-07-24 10:18:44,788][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3972],
        [2071],
        [1612],
        [1716],
        [1701],
        [1722],
        [1735],
        [1833],
        [1851],
        [1856],
        [1869],
        [1827],
        [1837],
        [1871],
        [1930],
        [1975],
        [1990],
        [2035],
        [2014],
        [2036]], device='cuda:0')
[2024-07-24 10:18:44,790][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3518],
        [5094],
        [7972],
        [5905],
        [4035],
        [3871],
        [4337],
        [4521],
        [4974],
        [4865],
        [4375],
        [3995],
        [3748],
        [3331],
        [3278],
        [3419],
        [3574],
        [3576],
        [3613],
        [3666]], device='cuda:0')
[2024-07-24 10:18:44,792][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6175],
        [20137],
        [32337],
        [34971],
        [28753],
        [27001],
        [23565],
        [24402],
        [21819],
        [21478],
        [20188],
        [19967],
        [18921],
        [19317],
        [20149],
        [19937],
        [19078],
        [19978],
        [16934],
        [18661]], device='cuda:0')
[2024-07-24 10:18:44,794][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18112],
        [18272],
        [16680],
        [16268],
        [16231],
        [15869],
        [14343],
        [14162],
        [13931],
        [14245],
        [14079],
        [13370],
        [13059],
        [13129],
        [12963],
        [13341],
        [13238],
        [13278],
        [13205],
        [13429]], device='cuda:0')
[2024-07-24 10:18:44,796][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38076],
        [43492],
        [38750],
        [44851],
        [43711],
        [43961],
        [43977],
        [43801],
        [43963],
        [43332],
        [43289],
        [42785],
        [42761],
        [42390],
        [41940],
        [41664],
        [41423],
        [41588],
        [41605],
        [41333]], device='cuda:0')
[2024-07-24 10:18:44,798][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 8502],
        [10857],
        [11163],
        [11893],
        [12128],
        [11917],
        [11430],
        [11282],
        [11156],
        [11316],
        [11219],
        [10964],
        [10826],
        [10887],
        [10708],
        [10602],
        [10592],
        [10590],
        [10449],
        [10507]], device='cuda:0')
[2024-07-24 10:18:44,801][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7634],
        [11820],
        [10466],
        [ 8346],
        [ 9686],
        [ 9489],
        [11089],
        [11296],
        [11424],
        [10871],
        [10636],
        [ 9500],
        [ 9605],
        [10271],
        [12575],
        [12200],
        [11943],
        [11896],
        [11075],
        [11122]], device='cuda:0')
[2024-07-24 10:18:44,803][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7619],
        [ 8568],
        [11104],
        [12900],
        [13997],
        [14268],
        [16283],
        [17874],
        [17836],
        [18352],
        [18061],
        [18814],
        [19354],
        [19893],
        [20684],
        [20286],
        [21150],
        [21024],
        [21619],
        [20625]], device='cuda:0')
[2024-07-24 10:18:44,805][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39272],
        [25674],
        [16620],
        [12647],
        [11719],
        [10787],
        [12343],
        [14675],
        [16488],
        [16718],
        [16225],
        [16313],
        [16858],
        [14722],
        [14801],
        [15782],
        [16474],
        [15577],
        [14850],
        [15011]], device='cuda:0')
[2024-07-24 10:18:44,806][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3754],
        [3848],
        [3726],
        [3738],
        [3774],
        [3751],
        [3944],
        [4046],
        [4008],
        [4045],
        [4017],
        [4274],
        [4413],
        [4673],
        [4819],
        [4354],
        [4474],
        [4355],
        [4731],
        [4319]], device='cuda:0')
[2024-07-24 10:18:44,808][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35612],
        [18140],
        [18139],
        [33616],
        [27037],
        [28292],
        [25983],
        [38719],
        [25960],
        [25930],
        [25928],
        [37193],
        [37193],
        [31872],
        [27880],
        [30275],
        [28253],
        [41717],
        [44326],
        [44349]], device='cuda:0')
[2024-07-24 10:18:44,810][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25308],
        [ 3627],
        [ 9544],
        [10484],
        [22271],
        [29139],
        [ 9859],
        [15713],
        [12662],
        [14948],
        [11910],
        [15099],
        [19986],
        [35724],
        [23405],
        [20777],
        [18024],
        [20961],
        [34098],
        [22633]], device='cuda:0')
[2024-07-24 10:18:44,813][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18612],
        [ 3126],
        [ 3663],
        [ 4314],
        [ 4797],
        [ 5008],
        [ 5323],
        [ 5157],
        [ 3888],
        [ 4655],
        [ 5665],
        [ 5933],
        [ 5937],
        [ 5825],
        [ 6373],
        [ 4607],
        [ 6708],
        [ 5282],
        [ 8097],
        [ 4171]], device='cuda:0')
[2024-07-24 10:18:44,815][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[28155],
        [25537],
        [18086],
        [ 9369],
        [ 5852],
        [10544],
        [11018],
        [ 5102],
        [ 4329],
        [ 3700],
        [ 5135],
        [ 5059],
        [ 5041],
        [ 5412],
        [ 6279],
        [ 9293],
        [10766],
        [ 9141],
        [11486],
        [11278]], device='cuda:0')
[2024-07-24 10:18:44,817][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[2186],
        [1625],
        [2969],
        [2836],
        [4537],
        [3920],
        [4312],
        [5263],
        [5841],
        [5853],
        [5688],
        [6008],
        [5083],
        [5449],
        [5538],
        [5881],
        [6372],
        [6201],
        [6044],
        [5768]], device='cuda:0')
[2024-07-24 10:18:44,819][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16516],
        [10756],
        [ 8574],
        [ 8703],
        [10695],
        [10186],
        [ 9355],
        [ 9372],
        [ 9523],
        [ 9526],
        [10219],
        [10363],
        [10665],
        [11538],
        [11546],
        [11378],
        [11332],
        [11425],
        [12205],
        [12060]], device='cuda:0')
[2024-07-24 10:18:44,821][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19745],
        [37344],
        [32351],
        [30410],
        [34489],
        [33317],
        [30124],
        [31075],
        [31276],
        [29670],
        [28612],
        [24354],
        [24158],
        [24948],
        [24827],
        [24381],
        [22803],
        [22461],
        [21961],
        [21163]], device='cuda:0')
[2024-07-24 10:18:44,823][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12463],
        [14148],
        [12977],
        [12690],
        [12752],
        [12757],
        [12958],
        [13080],
        [12783],
        [12487],
        [12372],
        [12488],
        [12560],
        [12849],
        [13196],
        [13314],
        [13476],
        [13763],
        [14085],
        [14091]], device='cuda:0')
[2024-07-24 10:18:44,825][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[41280],
        [38945],
        [35129],
        [35115],
        [34670],
        [34740],
        [34894],
        [35321],
        [35774],
        [36121],
        [36112],
        [36009],
        [36190],
        [35991],
        [36004],
        [36090],
        [36303],
        [36296],
        [36158],
        [36231]], device='cuda:0')
[2024-07-24 10:18:44,826][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37141],
        [32201],
        [31381],
        [32455],
        [28231],
        [26864],
        [24557],
        [25621],
        [24068],
        [25522],
        [25375],
        [17374],
        [19102],
        [24758],
        [25508],
        [25775],
        [26188],
        [26303],
        [27933],
        [28160]], device='cuda:0')
[2024-07-24 10:18:44,828][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14051],
        [14747],
        [25101],
        [20208],
        [20000],
        [25591],
        [27073],
        [28220],
        [25988],
        [26927],
        [27134],
        [24835],
        [27675],
        [26677],
        [24219],
        [23847],
        [24036],
        [24351],
        [24721],
        [24722]], device='cuda:0')
[2024-07-24 10:18:44,830][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22297],
        [20713],
        [18592],
        [17881],
        [14814],
        [15966],
        [26077],
        [30673],
        [28398],
        [22051],
        [26292],
        [34952],
        [34370],
        [19013],
        [24548],
        [21409],
        [22819],
        [23531],
        [20319],
        [20063]], device='cuda:0')
[2024-07-24 10:18:44,832][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[31083],
        [20064],
        [17809],
        [20947],
        [13312],
        [18512],
        [19942],
        [16237],
        [23811],
        [26785],
        [29257],
        [21118],
        [17294],
        [23066],
        [30848],
        [28162],
        [25546],
        [22352],
        [27560],
        [27744]], device='cuda:0')
[2024-07-24 10:18:44,834][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[29823],
        [ 6853],
        [ 6854],
        [24481],
        [12227],
        [14088],
        [13634],
        [22579],
        [28756],
        [28798],
        [28799],
        [20682],
        [20682],
        [17779],
        [16688],
        [16215],
        [16593],
        [12411],
        [14606],
        [14610]], device='cuda:0')
[2024-07-24 10:18:44,837][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25328],
        [37070],
        [38917],
        [38578],
        [41370],
        [38055],
        [35057],
        [33789],
        [33820],
        [34237],
        [32305],
        [33905],
        [33509],
        [35767],
        [34679],
        [35334],
        [34478],
        [35984],
        [34193],
        [34679]], device='cuda:0')
[2024-07-24 10:18:44,839][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27747],
        [47566],
        [45638],
        [44744],
        [43450],
        [38933],
        [47720],
        [42780],
        [44227],
        [45743],
        [44836],
        [46320],
        [46250],
        [41168],
        [43027],
        [39722],
        [42376],
        [44354],
        [35223],
        [42069]], device='cuda:0')
[2024-07-24 10:18:44,842][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913],
        [9913]], device='cuda:0')
[2024-07-24 10:18:44,907][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:44,909][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,911][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,912][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,913][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,915][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,916][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,918][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,919][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,919][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,920][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,921][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,921][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:44,922][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([3.9152e-04, 9.9961e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,923][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4570, 0.5430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,925][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4107, 0.5893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,927][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8795, 0.1205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,928][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0436, 0.9564], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,930][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2568, 0.7432], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,932][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5181, 0.4819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,934][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0134, 0.9866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,935][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9046, 0.0954], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,937][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4293, 0.5707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,937][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0304, 0.9696], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,938][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1580, 0.8420], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:44,939][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([1.6461e-04, 5.8623e-01, 4.1361e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,939][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.3244, 0.3336, 0.3420], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,940][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.2547, 0.3982, 0.3471], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,941][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.6866, 0.1167, 0.1968], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,943][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0191, 0.4237, 0.5573], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,945][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0816, 0.4516, 0.4668], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,946][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.4254, 0.4478, 0.1268], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,948][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0018, 0.0347, 0.9635], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,950][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.5869, 0.2170, 0.1961], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,952][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.2640, 0.3862, 0.3499], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,953][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0118, 0.4786, 0.5095], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,954][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0802, 0.4315, 0.4883], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:44,955][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([1.0992e-04, 4.0199e-01, 2.8449e-01, 3.1341e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,955][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2349, 0.2507, 0.2611, 0.2532], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,956][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1620, 0.2978, 0.2721, 0.2681], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,957][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6578, 0.0844, 0.1962, 0.0616], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,957][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0185, 0.2687, 0.3618, 0.3509], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,959][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0610, 0.2395, 0.4522, 0.2473], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,961][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3695, 0.2215, 0.3120, 0.0970], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,962][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.1363e-04, 5.3920e-02, 8.4484e-01, 1.0113e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,964][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4418, 0.0538, 0.4895, 0.0149], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,966][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2000, 0.2754, 0.2768, 0.2478], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,968][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0096, 0.3391, 0.3326, 0.3187], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,970][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0618, 0.3105, 0.3432, 0.2844], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:44,971][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([1.2826e-04, 2.8383e-01, 2.0265e-01, 2.2321e-01, 2.9018e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,972][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.1626, 0.2078, 0.2106, 0.2133, 0.2056], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,972][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.1370, 0.2360, 0.2073, 0.2027, 0.2169], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,973][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.7753, 0.0369, 0.1081, 0.0250, 0.0547], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,974][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0103, 0.1707, 0.2374, 0.2244, 0.3573], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,975][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0411, 0.1895, 0.3453, 0.2016, 0.2225], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,976][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.4418, 0.1449, 0.1981, 0.0610, 0.1542], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,977][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0020, 0.0209, 0.2630, 0.0642, 0.6499], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,979][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.7419, 0.0296, 0.1369, 0.0232, 0.0685], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,981][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.1576, 0.2192, 0.2175, 0.2002, 0.2055], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,982][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0073, 0.2509, 0.2413, 0.2365, 0.2641], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,984][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0460, 0.2328, 0.2628, 0.2144, 0.2440], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:44,986][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ were] are: tensor([8.3815e-05, 2.3047e-01, 1.6379e-01, 1.7992e-01, 2.3603e-01, 1.8970e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,987][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1313, 0.1714, 0.1760, 0.1743, 0.1740, 0.1730], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,988][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1211, 0.1974, 0.1785, 0.1764, 0.1925, 0.1341], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,989][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.6087, 0.0510, 0.0994, 0.0342, 0.0770, 0.1296], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,990][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0099, 0.1249, 0.1647, 0.1672, 0.2496, 0.2837], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,991][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0377, 0.1431, 0.2562, 0.1694, 0.2268, 0.1668], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,991][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1804, 0.1006, 0.1035, 0.0440, 0.3333, 0.2382], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,992][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ were] are: tensor([1.2635e-04, 4.1603e-02, 1.9371e-01, 9.3627e-02, 5.7314e-01, 9.7793e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,994][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.4422, 0.0267, 0.1508, 0.0110, 0.3496, 0.0197], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,996][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.1322, 0.1784, 0.1728, 0.1608, 0.1736, 0.1823], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,998][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0064, 0.2011, 0.1902, 0.1932, 0.2064, 0.2027], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:44,999][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0369, 0.1969, 0.2221, 0.1780, 0.2022, 0.1639], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,001][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([4.9898e-05, 1.9710e-01, 1.3780e-01, 1.5175e-01, 2.0214e-01, 1.6012e-01,
        1.5104e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,003][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1279, 0.1422, 0.1479, 0.1443, 0.1464, 0.1468, 0.1445],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,005][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.1395, 0.1692, 0.1455, 0.1463, 0.1545, 0.1120, 0.1331],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,006][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.6277, 0.0333, 0.0808, 0.0298, 0.0623, 0.1157, 0.0504],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,006][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0046, 0.1058, 0.1331, 0.1364, 0.2129, 0.2391, 0.1680],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,007][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0255, 0.1132, 0.1955, 0.1386, 0.2398, 0.1734, 0.1141],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,008][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0575, 0.0731, 0.0316, 0.0397, 0.1696, 0.4916, 0.1369],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,009][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([6.2169e-04, 1.0257e-03, 5.7511e-03, 1.0741e-03, 9.4999e-03, 1.3255e-03,
        9.8070e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,010][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.3027, 0.0530, 0.1623, 0.0174, 0.1873, 0.1616, 0.1156],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,012][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1108, 0.1476, 0.1436, 0.1341, 0.1526, 0.1651, 0.1462],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,014][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0028, 0.1721, 0.1606, 0.1613, 0.1780, 0.1690, 0.1563],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,015][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0321, 0.1714, 0.1931, 0.1528, 0.1746, 0.1399, 0.1360],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,016][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ about] are: tensor([2.7563e-05, 1.7782e-01, 1.2288e-01, 1.3501e-01, 1.8378e-01, 1.4269e-01,
        1.3429e-01, 1.0351e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,018][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.1198, 0.1211, 0.1279, 0.1245, 0.1285, 0.1286, 0.1269, 0.1227],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,020][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.1035, 0.1485, 0.1346, 0.1362, 0.1455, 0.1023, 0.1194, 0.1100],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,022][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.3556, 0.0437, 0.1045, 0.0414, 0.0974, 0.1625, 0.0933, 0.1017],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,023][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0049, 0.0924, 0.1181, 0.1198, 0.1870, 0.2063, 0.1486, 0.1230],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,024][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0266, 0.1100, 0.1875, 0.1277, 0.2044, 0.1290, 0.1248, 0.0901],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,024][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0490, 0.0698, 0.0482, 0.0237, 0.1335, 0.3262, 0.3173, 0.0324],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,025][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ about] are: tensor([1.8806e-05, 4.3446e-04, 3.1318e-03, 5.0850e-04, 4.7171e-03, 1.3592e-03,
        9.8091e-01, 8.9181e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,026][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.2488, 0.0183, 0.1597, 0.0167, 0.2107, 0.1499, 0.1468, 0.0492],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,027][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0985, 0.1313, 0.1276, 0.1186, 0.1363, 0.1460, 0.1335, 0.1083],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,029][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0023, 0.1536, 0.1428, 0.1436, 0.1572, 0.1473, 0.1299, 0.1235],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,031][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0289, 0.1552, 0.1763, 0.1401, 0.1598, 0.1254, 0.1205, 0.0939],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,032][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ going] are: tensor([2.9049e-05, 1.5693e-01, 1.0855e-01, 1.2188e-01, 1.6491e-01, 1.2938e-01,
        1.2152e-01, 9.3759e-02, 1.0303e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,034][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.1062, 0.1090, 0.1119, 0.1112, 0.1137, 0.1129, 0.1111, 0.1116, 0.1125],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,036][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0974, 0.1323, 0.1198, 0.1232, 0.1302, 0.0924, 0.1093, 0.1007, 0.0947],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,037][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.6305, 0.0210, 0.0513, 0.0176, 0.0447, 0.0826, 0.0456, 0.0838, 0.0230],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,039][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0042, 0.0721, 0.1074, 0.0988, 0.1683, 0.1844, 0.1202, 0.0975, 0.1470],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,040][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0184, 0.1008, 0.1264, 0.1336, 0.1796, 0.1293, 0.1159, 0.0998, 0.0961],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,041][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0853, 0.0201, 0.0362, 0.0144, 0.1273, 0.2993, 0.1728, 0.0379, 0.2068],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,042][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ going] are: tensor([5.7301e-05, 7.4521e-04, 2.3386e-03, 6.4464e-04, 2.7592e-03, 1.7852e-03,
        8.5242e-01, 1.7469e-02, 1.2178e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,043][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.4311, 0.0104, 0.0864, 0.0081, 0.1253, 0.0809, 0.0996, 0.0913, 0.0668],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,043][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0864, 0.1189, 0.1152, 0.1063, 0.1222, 0.1350, 0.1183, 0.1019, 0.0959],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,044][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0017, 0.1373, 0.1318, 0.1268, 0.1398, 0.1353, 0.1142, 0.1100, 0.1031],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,046][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0255, 0.1399, 0.1581, 0.1271, 0.1429, 0.1135, 0.1077, 0.0844, 0.1009],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,048][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.6987e-05, 1.4104e-01, 9.8518e-02, 1.1093e-01, 1.5047e-01, 1.1679e-01,
        1.0984e-01, 8.4499e-02, 9.3085e-02, 9.4791e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,049][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0888, 0.0977, 0.1017, 0.0990, 0.1006, 0.1021, 0.1008, 0.1001, 0.1045,
        0.1046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,051][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0767, 0.1226, 0.1131, 0.1166, 0.1238, 0.0863, 0.1016, 0.0941, 0.0856,
        0.0797], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,053][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6993, 0.0161, 0.0471, 0.0119, 0.0386, 0.0533, 0.0317, 0.0343, 0.0214,
        0.0463], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,055][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0044, 0.0636, 0.0930, 0.0887, 0.1462, 0.1611, 0.1055, 0.0865, 0.1324,
        0.1185], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,056][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0189, 0.0831, 0.1499, 0.1005, 0.1456, 0.1064, 0.0954, 0.0863, 0.1362,
        0.0776], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,058][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1579, 0.0082, 0.0201, 0.0045, 0.0573, 0.1735, 0.0926, 0.0155, 0.3805,
        0.0899], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,058][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.8798e-06, 2.4218e-04, 3.5107e-03, 3.6955e-04, 5.2517e-03, 7.2838e-04,
        8.5642e-01, 1.2576e-02, 1.1602e-01, 4.8685e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,059][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5405, 0.0032, 0.0646, 0.0030, 0.0669, 0.0676, 0.0691, 0.0320, 0.1087,
        0.0445], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,060][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0765, 0.1072, 0.1071, 0.0977, 0.1105, 0.1192, 0.1072, 0.0920, 0.0908,
        0.0917], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,061][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0021, 0.1259, 0.1165, 0.1169, 0.1255, 0.1236, 0.1045, 0.0986, 0.0922,
        0.0941], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,062][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0244, 0.1270, 0.1407, 0.1159, 0.1288, 0.1033, 0.0985, 0.0773, 0.0916,
        0.0926], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,063][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.3452e-05, 1.3076e-01, 8.9590e-02, 1.0153e-01, 1.3838e-01, 1.0802e-01,
        1.0119e-01, 7.7424e-02, 8.4893e-02, 8.7112e-02, 8.1077e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,065][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0815, 0.0884, 0.0930, 0.0899, 0.0916, 0.0922, 0.0909, 0.0910, 0.0945,
        0.0943, 0.0928], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,067][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0737, 0.1141, 0.1048, 0.1088, 0.1146, 0.0781, 0.0964, 0.0878, 0.0805,
        0.0757, 0.0654], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,069][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.6274, 0.0155, 0.0478, 0.0114, 0.0406, 0.0526, 0.0297, 0.0303, 0.0191,
        0.0467, 0.0788], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,071][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0047, 0.0554, 0.0812, 0.0773, 0.1266, 0.1414, 0.0915, 0.0743, 0.1172,
        0.1055, 0.1249], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,072][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0185, 0.0736, 0.1227, 0.0915, 0.1241, 0.0937, 0.0858, 0.0884, 0.1170,
        0.1057, 0.0790], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,074][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2534, 0.0041, 0.0219, 0.0029, 0.0478, 0.1162, 0.0733, 0.0120, 0.2768,
        0.1337, 0.0580], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,075][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.0422e-05, 3.6955e-04, 3.3807e-03, 6.1205e-04, 4.7718e-03, 9.0808e-04,
        8.7748e-01, 1.3959e-02, 7.1210e-02, 6.9206e-03, 2.0376e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,076][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5370, 0.0088, 0.0710, 0.0038, 0.0723, 0.0405, 0.0659, 0.0310, 0.0924,
        0.0580, 0.0192], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,077][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0707, 0.0983, 0.0973, 0.0904, 0.1006, 0.1085, 0.0981, 0.0834, 0.0830,
        0.0849, 0.0847], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,077][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0020, 0.1129, 0.1054, 0.1069, 0.1137, 0.1112, 0.0946, 0.0903, 0.0833,
        0.0850, 0.0944], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,078][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0223, 0.1171, 0.1320, 0.1055, 0.1185, 0.0951, 0.0903, 0.0703, 0.0826,
        0.0823, 0.0840], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,079][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ school] are: tensor([3.5553e-05, 1.1719e-01, 8.2550e-02, 9.0979e-02, 1.2204e-01, 9.6991e-02,
        9.2078e-02, 7.1464e-02, 7.8231e-02, 7.8666e-02, 7.4867e-02, 9.4904e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,081][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0677, 0.0829, 0.0853, 0.0855, 0.0839, 0.0843, 0.0845, 0.0833, 0.0855,
        0.0866, 0.0865, 0.0840], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,083][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0869, 0.0992, 0.0876, 0.0907, 0.0935, 0.0706, 0.0848, 0.0769, 0.0770,
        0.0728, 0.0657, 0.0942], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,084][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.6229, 0.0123, 0.0462, 0.0104, 0.0326, 0.0429, 0.0193, 0.0215, 0.0135,
        0.0330, 0.0945, 0.0510], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,086][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0036, 0.0442, 0.0707, 0.0634, 0.1095, 0.1258, 0.0749, 0.0606, 0.0921,
        0.0828, 0.1040, 0.1686], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,088][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0175, 0.0734, 0.1000, 0.0801, 0.1134, 0.0885, 0.0821, 0.0804, 0.1141,
        0.0883, 0.0771, 0.0851], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,090][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.1991, 0.0016, 0.0053, 0.0007, 0.0138, 0.0361, 0.0311, 0.0041, 0.1023,
        0.0262, 0.0970, 0.4826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,091][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ school] are: tensor([9.8530e-04, 4.2249e-05, 1.5260e-04, 3.5638e-05, 4.1570e-04, 1.9825e-05,
        5.8584e-02, 5.9055e-04, 5.6301e-03, 3.5695e-04, 1.5992e-03, 9.3159e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,092][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.6141, 0.0017, 0.0422, 0.0014, 0.0371, 0.0268, 0.0442, 0.0196, 0.0513,
        0.0236, 0.0487, 0.0894], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,093][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0656, 0.0917, 0.0875, 0.0825, 0.0929, 0.0995, 0.0925, 0.0800, 0.0766,
        0.0787, 0.0773, 0.0751], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,094][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.0017, 0.1017, 0.0955, 0.0940, 0.1024, 0.0996, 0.0900, 0.0813, 0.0765,
        0.0778, 0.0872, 0.0924], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,095][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.0198, 0.1057, 0.1189, 0.0949, 0.1070, 0.0855, 0.0808, 0.0627, 0.0733,
        0.0732, 0.0738, 0.1046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,095][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([3.3749e-05, 1.0818e-01, 7.5678e-02, 8.4051e-02, 1.1154e-01, 8.9216e-02,
        8.3938e-02, 6.5749e-02, 7.1448e-02, 7.2346e-02, 6.8610e-02, 8.6322e-02,
        8.2889e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,097][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0581, 0.0771, 0.0803, 0.0788, 0.0773, 0.0783, 0.0792, 0.0779, 0.0806,
        0.0808, 0.0814, 0.0778, 0.0723], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,099][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0598, 0.0967, 0.0891, 0.0886, 0.0941, 0.0666, 0.0814, 0.0729, 0.0724,
        0.0670, 0.0599, 0.0873, 0.0642], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,101][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.5721, 0.0152, 0.0434, 0.0113, 0.0342, 0.0460, 0.0213, 0.0302, 0.0135,
        0.0335, 0.0761, 0.0759, 0.0271], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,103][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0036, 0.0435, 0.0606, 0.0588, 0.0945, 0.1062, 0.0712, 0.0582, 0.0880,
        0.0784, 0.0960, 0.1543, 0.0866], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,105][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0175, 0.0587, 0.1024, 0.0702, 0.1107, 0.0861, 0.0759, 0.0727, 0.1051,
        0.0777, 0.0714, 0.0905, 0.0614], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,107][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0865, 0.0020, 0.0129, 0.0018, 0.0219, 0.0387, 0.0412, 0.0093, 0.0672,
        0.0453, 0.0666, 0.5838, 0.0228], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,108][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([4.5829e-07, 3.1590e-05, 6.5229e-04, 1.0670e-04, 1.3875e-03, 8.5172e-05,
        1.0186e-01, 2.0839e-03, 4.7544e-03, 1.1124e-03, 3.6528e-03, 8.8408e-01,
        1.8693e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,109][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3619, 0.0046, 0.0698, 0.0034, 0.0593, 0.0285, 0.0484, 0.0313, 0.0671,
        0.0325, 0.0512, 0.2233, 0.0186], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,110][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0616, 0.0836, 0.0815, 0.0758, 0.0844, 0.0907, 0.0836, 0.0719, 0.0706,
        0.0726, 0.0712, 0.0739, 0.0787], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,111][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0022, 0.0933, 0.0868, 0.0868, 0.0944, 0.0913, 0.0795, 0.0761, 0.0713,
        0.0724, 0.0795, 0.0802, 0.0860], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,112][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0180, 0.0978, 0.1107, 0.0879, 0.0988, 0.0778, 0.0740, 0.0573, 0.0668,
        0.0670, 0.0684, 0.0982, 0.0772], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,112][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([3.2361e-05, 9.9248e-02, 6.9726e-02, 7.6648e-02, 1.0161e-01, 8.1365e-02,
        7.6940e-02, 6.0373e-02, 6.5928e-02, 6.6309e-02, 6.2767e-02, 7.7885e-02,
        7.4819e-02, 8.6349e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,115][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0604, 0.0713, 0.0727, 0.0737, 0.0728, 0.0725, 0.0720, 0.0707, 0.0733,
        0.0735, 0.0732, 0.0729, 0.0688, 0.0722], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,117][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0709, 0.0903, 0.0753, 0.0756, 0.0777, 0.0586, 0.0727, 0.0675, 0.0677,
        0.0632, 0.0566, 0.0829, 0.0619, 0.0791], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,118][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.7997, 0.0034, 0.0127, 0.0022, 0.0072, 0.0098, 0.0044, 0.0054, 0.0027,
        0.0084, 0.0202, 0.0161, 0.0093, 0.0985], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,120][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0028, 0.0328, 0.0530, 0.0486, 0.0844, 0.1000, 0.0581, 0.0459, 0.0692,
        0.0622, 0.0769, 0.1269, 0.0741, 0.1651], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,122][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0118, 0.0611, 0.1117, 0.0665, 0.0680, 0.0822, 0.0655, 0.0779, 0.1006,
        0.0724, 0.0685, 0.0806, 0.0726, 0.0605], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,124][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.2777, 0.0010, 0.0067, 0.0004, 0.0036, 0.0365, 0.0193, 0.0032, 0.0366,
        0.0147, 0.0336, 0.2718, 0.0369, 0.2582], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,125][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([2.1950e-03, 2.0795e-05, 2.8191e-05, 1.8398e-05, 7.0322e-05, 9.4243e-06,
        2.0595e-02, 1.8639e-04, 3.0669e-03, 1.3166e-04, 5.2661e-04, 1.8900e-01,
        9.8550e-05, 7.8405e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,126][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.5265, 0.0016, 0.0196, 0.0007, 0.0107, 0.0253, 0.0331, 0.0135, 0.0501,
        0.0145, 0.0237, 0.1061, 0.0168, 0.1578], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,127][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0571, 0.0794, 0.0776, 0.0725, 0.0725, 0.0854, 0.0774, 0.0685, 0.0672,
        0.0693, 0.0693, 0.0685, 0.0733, 0.0621], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,128][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0018, 0.0861, 0.0807, 0.0804, 0.0877, 0.0837, 0.0750, 0.0687, 0.0650,
        0.0650, 0.0713, 0.0748, 0.0791, 0.0806], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,129][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0159, 0.0864, 0.1008, 0.0788, 0.0904, 0.0711, 0.0674, 0.0525, 0.0614,
        0.0609, 0.0626, 0.0885, 0.0704, 0.0929], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,130][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([1.9773e-05, 9.5138e-02, 6.5723e-02, 7.2217e-02, 9.7236e-02, 7.7491e-02,
        7.3120e-02, 5.6669e-02, 6.1930e-02, 6.2625e-02, 5.9052e-02, 7.3709e-02,
        7.0499e-02, 8.2172e-02, 5.2398e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,132][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0655, 0.0664, 0.0677, 0.0664, 0.0693, 0.0677, 0.0673, 0.0654, 0.0660,
        0.0678, 0.0677, 0.0666, 0.0636, 0.0688, 0.0638], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,134][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0719, 0.0830, 0.0702, 0.0724, 0.0759, 0.0547, 0.0665, 0.0628, 0.0603,
        0.0580, 0.0508, 0.0779, 0.0574, 0.0764, 0.0618], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,136][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.5901, 0.0061, 0.0204, 0.0040, 0.0158, 0.0197, 0.0090, 0.0092, 0.0052,
        0.0122, 0.0295, 0.0223, 0.0124, 0.2033, 0.0409], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,137][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0024, 0.0290, 0.0475, 0.0435, 0.0749, 0.0862, 0.0519, 0.0406, 0.0611,
        0.0540, 0.0676, 0.1112, 0.0647, 0.1468, 0.1186], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,139][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0137, 0.0561, 0.0917, 0.0746, 0.1126, 0.0651, 0.0635, 0.0549, 0.0610,
        0.0589, 0.0562, 0.0801, 0.0574, 0.1070, 0.0475], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,141][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([1.1975e-01, 8.7995e-04, 5.2460e-03, 3.0667e-04, 5.9022e-03, 1.2569e-02,
        7.0492e-03, 1.3932e-03, 1.4537e-02, 1.0448e-02, 1.9144e-02, 1.5678e-01,
        2.2602e-02, 3.6522e-01, 2.5818e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,142][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([6.4787e-04, 4.3132e-05, 5.5524e-05, 2.1178e-05, 1.3169e-04, 2.8364e-05,
        3.3227e-02, 3.0682e-04, 2.4195e-03, 1.5855e-04, 8.8975e-04, 2.6559e-01,
        1.3673e-04, 4.4331e-01, 2.5303e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,143][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.3422, 0.0015, 0.0210, 0.0004, 0.0242, 0.0104, 0.0165, 0.0077, 0.0101,
        0.0100, 0.0187, 0.0570, 0.0151, 0.4270, 0.0382], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,144][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0527, 0.0728, 0.0741, 0.0649, 0.0739, 0.0816, 0.0731, 0.0627, 0.0611,
        0.0614, 0.0618, 0.0643, 0.0676, 0.0632, 0.0647], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,145][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0014, 0.0800, 0.0775, 0.0746, 0.0828, 0.0801, 0.0690, 0.0663, 0.0596,
        0.0599, 0.0669, 0.0678, 0.0741, 0.0755, 0.0646], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,146][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0161, 0.0826, 0.0930, 0.0742, 0.0833, 0.0669, 0.0634, 0.0493, 0.0576,
        0.0573, 0.0583, 0.0811, 0.0644, 0.0847, 0.0677], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,147][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.5966e-05, 9.0574e-02, 6.2316e-02, 6.9002e-02, 9.3164e-02, 7.3768e-02,
        6.9323e-02, 5.3302e-02, 5.8280e-02, 5.8761e-02, 5.5331e-02, 7.0546e-02,
        6.7578e-02, 7.8548e-02, 4.9432e-02, 5.0059e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,149][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0584, 0.0611, 0.0638, 0.0617, 0.0641, 0.0644, 0.0635, 0.0616, 0.0635,
        0.0640, 0.0647, 0.0633, 0.0597, 0.0638, 0.0615, 0.0608],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,151][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0566, 0.0792, 0.0706, 0.0735, 0.0758, 0.0539, 0.0647, 0.0608, 0.0564,
        0.0530, 0.0466, 0.0760, 0.0548, 0.0730, 0.0586, 0.0463],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,153][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.6367, 0.0045, 0.0153, 0.0026, 0.0116, 0.0134, 0.0077, 0.0063, 0.0043,
        0.0085, 0.0183, 0.0233, 0.0088, 0.1511, 0.0535, 0.0340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,154][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0026, 0.0273, 0.0446, 0.0400, 0.0687, 0.0780, 0.0474, 0.0375, 0.0553,
        0.0499, 0.0618, 0.1014, 0.0592, 0.1324, 0.1119, 0.0818],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,157][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0123, 0.0520, 0.0934, 0.0607, 0.0911, 0.0662, 0.0581, 0.0512, 0.0817,
        0.0460, 0.0611, 0.0767, 0.0519, 0.0908, 0.0670, 0.0396],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,158][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.4487e-01, 3.7234e-04, 3.2424e-03, 1.6996e-04, 5.4753e-03, 1.4015e-02,
        7.3709e-03, 9.6182e-04, 1.8507e-02, 4.0804e-03, 1.2822e-02, 1.2827e-01,
        7.9855e-03, 2.5778e-01, 3.4145e-01, 5.2620e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,159][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([6.0061e-06, 1.4172e-05, 1.2132e-04, 1.2901e-05, 1.7529e-04, 1.6729e-05,
        2.5022e-02, 2.6803e-04, 2.3968e-03, 8.5116e-05, 4.3158e-04, 2.1955e-01,
        4.3859e-05, 4.8866e-01, 2.6219e-01, 1.0116e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,161][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3095, 0.0005, 0.0174, 0.0004, 0.0143, 0.0146, 0.0136, 0.0046, 0.0173,
        0.0059, 0.0174, 0.0726, 0.0118, 0.3061, 0.1667, 0.0273],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,161][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0488, 0.0682, 0.0681, 0.0617, 0.0694, 0.0756, 0.0691, 0.0586, 0.0573,
        0.0579, 0.0587, 0.0607, 0.0647, 0.0603, 0.0620, 0.0588],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,162][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0015, 0.0760, 0.0721, 0.0720, 0.0774, 0.0768, 0.0653, 0.0621, 0.0565,
        0.0566, 0.0638, 0.0664, 0.0702, 0.0702, 0.0580, 0.0552],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,163][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0156, 0.0789, 0.0872, 0.0713, 0.0787, 0.0636, 0.0602, 0.0471, 0.0552,
        0.0547, 0.0550, 0.0756, 0.0601, 0.0781, 0.0638, 0.0549],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,164][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([2.4326e-05, 8.3966e-02, 5.8503e-02, 6.4450e-02, 8.5823e-02, 6.8828e-02,
        6.4988e-02, 5.0381e-02, 5.5013e-02, 5.5371e-02, 5.2116e-02, 6.5889e-02,
        6.3114e-02, 7.2682e-02, 4.6652e-02, 4.7218e-02, 6.4983e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,166][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0443, 0.0593, 0.0624, 0.0609, 0.0598, 0.0601, 0.0608, 0.0597, 0.0609,
        0.0614, 0.0620, 0.0594, 0.0559, 0.0592, 0.0579, 0.0587, 0.0574],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,168][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0637, 0.0746, 0.0635, 0.0672, 0.0692, 0.0498, 0.0604, 0.0574, 0.0547,
        0.0527, 0.0453, 0.0711, 0.0510, 0.0685, 0.0554, 0.0457, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,170][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.6128, 0.0038, 0.0142, 0.0025, 0.0113, 0.0124, 0.0069, 0.0056, 0.0035,
        0.0080, 0.0196, 0.0181, 0.0077, 0.1476, 0.0373, 0.0307, 0.0581],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,171][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0021, 0.0243, 0.0423, 0.0362, 0.0651, 0.0739, 0.0436, 0.0341, 0.0493,
        0.0440, 0.0553, 0.0897, 0.0552, 0.1227, 0.1009, 0.0732, 0.0881],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,174][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0099, 0.0509, 0.0869, 0.0585, 0.0829, 0.0631, 0.0533, 0.0596, 0.0687,
        0.0558, 0.0586, 0.0690, 0.0564, 0.0776, 0.0579, 0.0450, 0.0460],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,175][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([5.0509e-02, 5.1207e-04, 3.9783e-03, 1.6653e-04, 3.5728e-03, 1.1026e-02,
        8.0729e-03, 1.3446e-03, 6.9836e-03, 6.8008e-03, 5.5862e-03, 1.1240e-01,
        6.1742e-03, 1.5731e-01, 3.9242e-01, 8.5763e-02, 1.4737e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,176][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([2.1050e-04, 4.5935e-05, 1.2144e-04, 1.4300e-05, 2.3061e-04, 2.3320e-05,
        3.4846e-02, 6.2572e-04, 2.8445e-03, 2.7471e-04, 6.6028e-04, 2.2471e-01,
        6.5150e-05, 4.6769e-01, 2.3081e-01, 2.5145e-03, 3.4301e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,178][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([4.4339e-01, 4.2814e-04, 2.4801e-02, 2.2913e-04, 1.6450e-02, 8.2984e-03,
        1.4716e-02, 7.3182e-03, 1.3870e-02, 6.7595e-03, 9.2388e-03, 4.9142e-02,
        8.1536e-03, 3.0662e-01, 4.7225e-02, 2.4092e-02, 1.9271e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,179][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0481, 0.0639, 0.0621, 0.0561, 0.0657, 0.0716, 0.0659, 0.0568, 0.0537,
        0.0549, 0.0543, 0.0564, 0.0589, 0.0564, 0.0603, 0.0554, 0.0595],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,180][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0017, 0.0705, 0.0684, 0.0671, 0.0728, 0.0699, 0.0617, 0.0586, 0.0529,
        0.0539, 0.0597, 0.0606, 0.0657, 0.0660, 0.0549, 0.0522, 0.0635],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,180][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0148, 0.0743, 0.0830, 0.0673, 0.0746, 0.0601, 0.0570, 0.0444, 0.0525,
        0.0519, 0.0524, 0.0708, 0.0564, 0.0731, 0.0601, 0.0514, 0.0559],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,181][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.6581e-05, 8.0665e-02, 5.5337e-02, 6.1803e-02, 8.2698e-02, 6.5912e-02,
        6.1376e-02, 4.7395e-02, 5.1419e-02, 5.2099e-02, 4.8824e-02, 6.2538e-02,
        6.0273e-02, 6.9546e-02, 4.4045e-02, 4.4434e-02, 6.1725e-02, 4.9895e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,183][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0405, 0.0570, 0.0593, 0.0583, 0.0565, 0.0570, 0.0579, 0.0574, 0.0582,
        0.0586, 0.0585, 0.0559, 0.0527, 0.0558, 0.0556, 0.0557, 0.0542, 0.0510],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,186][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0496, 0.0727, 0.0642, 0.0685, 0.0698, 0.0485, 0.0601, 0.0552, 0.0513,
        0.0488, 0.0416, 0.0699, 0.0498, 0.0669, 0.0544, 0.0438, 0.0483, 0.0365],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,187][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6161, 0.0044, 0.0139, 0.0020, 0.0103, 0.0105, 0.0076, 0.0057, 0.0033,
        0.0070, 0.0115, 0.0168, 0.0056, 0.1111, 0.0456, 0.0251, 0.0627, 0.0408],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,189][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0024, 0.0237, 0.0392, 0.0349, 0.0598, 0.0675, 0.0421, 0.0329, 0.0471,
        0.0424, 0.0512, 0.0821, 0.0502, 0.1070, 0.0907, 0.0670, 0.0813, 0.0785],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,191][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0141, 0.0462, 0.0707, 0.0566, 0.0738, 0.0588, 0.0546, 0.0527, 0.0592,
        0.0583, 0.0480, 0.0654, 0.0493, 0.0749, 0.0539, 0.0506, 0.0617, 0.0512],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,192][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([5.1251e-02, 3.7884e-04, 5.0360e-03, 1.5700e-04, 4.1556e-03, 1.0299e-02,
        7.2292e-03, 8.5572e-04, 1.3570e-02, 7.0202e-03, 2.7181e-03, 9.3725e-02,
        5.5908e-03, 1.1265e-01, 2.9123e-01, 8.1683e-02, 2.9383e-01, 1.8616e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,194][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([8.2575e-06, 3.2819e-05, 1.8352e-04, 1.8929e-05, 1.5696e-04, 3.3602e-05,
        3.3420e-02, 3.7679e-04, 2.7047e-03, 1.6466e-04, 3.5826e-04, 2.6133e-01,
        7.1071e-05, 2.7500e-01, 2.9072e-01, 1.6016e-03, 1.2968e-01, 4.1384e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,195][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2588, 0.0012, 0.0234, 0.0007, 0.0197, 0.0101, 0.0192, 0.0063, 0.0129,
        0.0074, 0.0086, 0.0544, 0.0129, 0.2511, 0.1233, 0.0325, 0.1445, 0.0129],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,196][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0437, 0.0601, 0.0600, 0.0548, 0.0611, 0.0669, 0.0609, 0.0519, 0.0514,
        0.0522, 0.0519, 0.0533, 0.0572, 0.0535, 0.0557, 0.0531, 0.0580, 0.0542],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,197][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0017, 0.0656, 0.0632, 0.0631, 0.0675, 0.0665, 0.0574, 0.0543, 0.0503,
        0.0499, 0.0563, 0.0587, 0.0617, 0.0617, 0.0532, 0.0491, 0.0592, 0.0606],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,198][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0139, 0.0710, 0.0793, 0.0641, 0.0707, 0.0565, 0.0538, 0.0422, 0.0494,
        0.0486, 0.0495, 0.0680, 0.0539, 0.0707, 0.0570, 0.0488, 0.0527, 0.0499],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,199][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([1.2863e-05, 7.7254e-02, 5.3044e-02, 5.8465e-02, 7.9642e-02, 6.2848e-02,
        5.8831e-02, 4.5164e-02, 4.9651e-02, 5.0044e-02, 4.7122e-02, 6.0176e-02,
        5.7784e-02, 6.6747e-02, 4.1618e-02, 4.2153e-02, 5.9104e-02, 4.7893e-02,
        4.2446e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,201][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0433, 0.0519, 0.0545, 0.0533, 0.0541, 0.0530, 0.0535, 0.0529, 0.0536,
        0.0544, 0.0547, 0.0539, 0.0508, 0.0543, 0.0526, 0.0519, 0.0523, 0.0498,
        0.0553], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,203][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0638, 0.0671, 0.0567, 0.0576, 0.0593, 0.0443, 0.0538, 0.0517, 0.0495,
        0.0478, 0.0417, 0.0632, 0.0477, 0.0611, 0.0506, 0.0428, 0.0463, 0.0381,
        0.0569], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,205][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.4327, 0.0047, 0.0170, 0.0033, 0.0118, 0.0144, 0.0057, 0.0071, 0.0036,
        0.0110, 0.0273, 0.0150, 0.0089, 0.1271, 0.0354, 0.0372, 0.0687, 0.1040,
        0.0652], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,207][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0019, 0.0200, 0.0345, 0.0306, 0.0535, 0.0637, 0.0372, 0.0291, 0.0399,
        0.0367, 0.0462, 0.0727, 0.0460, 0.0950, 0.0802, 0.0591, 0.0700, 0.0737,
        0.1100], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,209][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0110, 0.0389, 0.0534, 0.0445, 0.0651, 0.0540, 0.0540, 0.0548, 0.0681,
        0.0514, 0.0446, 0.0669, 0.0372, 0.0697, 0.0728, 0.0443, 0.0715, 0.0516,
        0.0462], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,210][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([1.6602e-01, 2.8084e-04, 2.7714e-03, 8.4909e-05, 2.7142e-03, 7.5486e-03,
        4.7269e-03, 6.9192e-04, 9.1795e-03, 2.2220e-03, 6.9184e-03, 7.4053e-02,
        4.9454e-03, 1.1997e-01, 1.9901e-01, 2.2053e-02, 1.3117e-01, 7.4092e-02,
        1.7153e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,212][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([4.9339e-04, 1.2731e-05, 1.4580e-05, 2.1008e-06, 3.0078e-05, 3.6270e-06,
        1.3794e-02, 6.0603e-05, 8.0031e-04, 3.2749e-05, 7.0485e-05, 5.5820e-02,
        1.7919e-05, 2.1970e-01, 9.3047e-02, 3.5680e-04, 5.9134e-02, 1.7304e-03,
        5.5488e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,213][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2864, 0.0006, 0.0220, 0.0004, 0.0164, 0.0135, 0.0134, 0.0059, 0.0135,
        0.0067, 0.0114, 0.0383, 0.0082, 0.2163, 0.1034, 0.0239, 0.1140, 0.0344,
        0.0712], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,213][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0434, 0.0605, 0.0572, 0.0523, 0.0577, 0.0642, 0.0591, 0.0528, 0.0480,
        0.0488, 0.0489, 0.0494, 0.0533, 0.0489, 0.0532, 0.0494, 0.0554, 0.0522,
        0.0454], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,214][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.0014, 0.0638, 0.0608, 0.0605, 0.0633, 0.0625, 0.0569, 0.0521, 0.0475,
        0.0490, 0.0535, 0.0548, 0.0588, 0.0577, 0.0475, 0.0468, 0.0541, 0.0574,
        0.0515], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,215][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0129, 0.0666, 0.0735, 0.0600, 0.0667, 0.0535, 0.0518, 0.0399, 0.0464,
        0.0457, 0.0472, 0.0640, 0.0506, 0.0657, 0.0541, 0.0460, 0.0502, 0.0468,
        0.0584], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,216][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.6800e-05, 7.3597e-02, 5.1152e-02, 5.6714e-02, 7.5570e-02, 5.9811e-02,
        5.5937e-02, 4.3281e-02, 4.7305e-02, 4.7912e-02, 4.5059e-02, 5.7537e-02,
        5.5333e-02, 6.3367e-02, 3.9670e-02, 4.0134e-02, 5.6032e-02, 4.5434e-02,
        4.0546e-02, 4.5592e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,218][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0419, 0.0498, 0.0525, 0.0501, 0.0513, 0.0511, 0.0517, 0.0505, 0.0514,
        0.0518, 0.0523, 0.0503, 0.0472, 0.0509, 0.0498, 0.0495, 0.0502, 0.0476,
        0.0535, 0.0466], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,220][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0504, 0.0665, 0.0587, 0.0600, 0.0616, 0.0442, 0.0531, 0.0507, 0.0469,
        0.0445, 0.0389, 0.0614, 0.0458, 0.0585, 0.0484, 0.0388, 0.0428, 0.0347,
        0.0545, 0.0397], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,222][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7198, 0.0025, 0.0082, 0.0011, 0.0056, 0.0058, 0.0035, 0.0026, 0.0017,
        0.0030, 0.0063, 0.0084, 0.0033, 0.0546, 0.0185, 0.0110, 0.0298, 0.0289,
        0.0459, 0.0394], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,224][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0023, 0.0199, 0.0327, 0.0296, 0.0495, 0.0586, 0.0351, 0.0280, 0.0378,
        0.0347, 0.0428, 0.0664, 0.0420, 0.0848, 0.0730, 0.0540, 0.0655, 0.0663,
        0.0995, 0.0776], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,226][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0102, 0.0402, 0.0719, 0.0474, 0.0703, 0.0515, 0.0455, 0.0404, 0.0630,
        0.0377, 0.0479, 0.0581, 0.0407, 0.0704, 0.0505, 0.0325, 0.0543, 0.0563,
        0.0740, 0.0370], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,228][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.5573e-01, 2.2471e-04, 2.4999e-03, 7.3261e-05, 2.5716e-03, 8.1252e-03,
        3.9458e-03, 5.0574e-04, 7.4962e-03, 1.6082e-03, 4.6763e-03, 3.4481e-02,
        3.3252e-03, 6.7679e-02, 9.3861e-02, 1.5422e-02, 1.1306e-01, 3.5392e-02,
        2.4836e-01, 1.0097e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,229][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([6.2198e-06, 7.3575e-06, 5.0949e-05, 4.1559e-06, 7.5738e-05, 4.8906e-06,
        8.9240e-03, 7.8756e-05, 7.2862e-04, 2.7685e-05, 9.2476e-05, 5.3120e-02,
        7.6437e-06, 1.5063e-01, 6.4690e-02, 2.1196e-04, 1.7527e-02, 1.3146e-03,
        7.0172e-01, 7.7824e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,230][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.2742e-01, 4.3307e-04, 1.4608e-02, 2.2572e-04, 1.0660e-02, 8.9141e-03,
        8.9819e-03, 2.8569e-03, 8.7591e-03, 3.0635e-03, 8.3371e-03, 3.1591e-02,
        6.8591e-03, 1.5423e-01, 6.8712e-02, 1.1877e-02, 6.2374e-02, 3.0124e-02,
        2.0966e-01, 3.0318e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,231][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0393, 0.0543, 0.0541, 0.0491, 0.0558, 0.0605, 0.0553, 0.0473, 0.0461,
        0.0463, 0.0468, 0.0488, 0.0514, 0.0489, 0.0504, 0.0472, 0.0525, 0.0490,
        0.0487, 0.0483], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,232][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0014, 0.0603, 0.0569, 0.0571, 0.0606, 0.0606, 0.0518, 0.0497, 0.0457,
        0.0457, 0.0505, 0.0532, 0.0556, 0.0553, 0.0470, 0.0444, 0.0531, 0.0541,
        0.0469, 0.0501], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,233][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0130, 0.0637, 0.0703, 0.0576, 0.0640, 0.0512, 0.0493, 0.0381, 0.0445,
        0.0442, 0.0447, 0.0604, 0.0478, 0.0621, 0.0508, 0.0435, 0.0471, 0.0440,
        0.0541, 0.0496], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,292][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:45,294][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,295][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,297][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,298][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,298][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,299][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,300][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,300][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,301][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,302][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,304][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,305][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,306][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.1086e-04, 9.9989e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,308][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2088, 0.7912], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,310][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5395, 0.4605], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,312][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7363, 0.2637], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,314][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0777, 0.9223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,315][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2048, 0.7952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,316][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5181, 0.4819], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,316][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3429, 0.6571], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,317][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6993, 0.3007], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,318][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4254, 0.5746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,318][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9912, 0.0088], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,320][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3489, 0.6511], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,321][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([4.6314e-05, 5.6334e-01, 4.3662e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,323][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0224, 0.3479, 0.6297], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,325][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2756, 0.2988, 0.4256], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,326][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.6431, 0.0999, 0.2570], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,328][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0306, 0.6767, 0.2927], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,330][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0611, 0.4197, 0.5192], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,331][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.4254, 0.4478, 0.1268], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,332][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.3590, 0.2813, 0.3597], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,333][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.6339, 0.1093, 0.2568], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,334][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.2984, 0.4198, 0.2818], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,334][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.9742, 0.0079, 0.0179], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,335][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.2765, 0.1895, 0.5339], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,336][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([3.3507e-05, 3.6566e-01, 2.9006e-01, 3.4424e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,338][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0160, 0.0986, 0.7447, 0.1407], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,340][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1741, 0.2074, 0.4023, 0.2161], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,341][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3540, 0.1346, 0.3664, 0.1451], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,343][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0297, 0.3788, 0.4626, 0.1289], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,345][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0511, 0.2421, 0.4234, 0.2834], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,347][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3695, 0.2215, 0.3120, 0.0970], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,349][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2682, 0.3548, 0.2048, 0.1721], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,351][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0618, 0.0344, 0.8996, 0.0042], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,353][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2213, 0.2669, 0.2683, 0.2434], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,354][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9785, 0.0080, 0.0086, 0.0050], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,355][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0760, 0.0564, 0.0311, 0.8364], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,356][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([3.1992e-05, 2.6544e-01, 2.0987e-01, 2.4670e-01, 2.7795e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,357][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0096, 0.1504, 0.5705, 0.1656, 0.1040], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,357][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1468, 0.1589, 0.2759, 0.1666, 0.2518], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,358][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.6287, 0.0518, 0.1504, 0.0566, 0.1124], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,360][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0486, 0.1164, 0.2456, 0.0261, 0.5633], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,362][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0337, 0.1872, 0.3121, 0.2236, 0.2434], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,363][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.4418, 0.1449, 0.1981, 0.0610, 0.1542], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,365][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.5545, 0.0775, 0.1027, 0.0383, 0.2269], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,367][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.8342, 0.0049, 0.0913, 0.0009, 0.0686], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,369][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.2033, 0.2495, 0.2307, 0.2009, 0.1156], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,371][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.9254, 0.0149, 0.0179, 0.0117, 0.0301], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,372][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.1325, 0.0663, 0.4215, 0.0349, 0.3447], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,372][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([2.6426e-05, 2.1020e-01, 1.6668e-01, 1.9494e-01, 2.2050e-01, 2.0764e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,373][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0071, 0.0727, 0.4734, 0.0958, 0.2153, 0.1356], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,374][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1632, 0.1385, 0.2327, 0.1360, 0.2167, 0.1129], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,375][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.3287, 0.0720, 0.1917, 0.0814, 0.1758, 0.1504], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,375][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0297, 0.1130, 0.1123, 0.0316, 0.3824, 0.3311], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,377][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0325, 0.1422, 0.2397, 0.1772, 0.2314, 0.1770], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,379][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.1804, 0.1006, 0.1035, 0.0440, 0.3333, 0.2382], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,381][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.2472, 0.1854, 0.0337, 0.0979, 0.1821, 0.2537], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,382][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1389, 0.0059, 0.1363, 0.0008, 0.7147, 0.0034], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,384][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.1815, 0.1983, 0.1775, 0.1772, 0.1318, 0.1338], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,386][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.9555, 0.0081, 0.0080, 0.0061, 0.0126, 0.0096], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,388][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0878, 0.0957, 0.1064, 0.1788, 0.0366, 0.4947], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,389][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([1.2992e-05, 1.7770e-01, 1.3877e-01, 1.6358e-01, 1.8692e-01, 1.7580e-01,
        1.5722e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,390][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0039, 0.0554, 0.2787, 0.0939, 0.1986, 0.1186, 0.2509],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,391][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.1653, 0.0987, 0.1752, 0.1117, 0.1809, 0.1038, 0.1645],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,391][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.4029, 0.0500, 0.1413, 0.0629, 0.1314, 0.1219, 0.0896],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,392][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0060, 0.0717, 0.0565, 0.0243, 0.2372, 0.3513, 0.2529],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,393][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0196, 0.1104, 0.1847, 0.1425, 0.2220, 0.1695, 0.1512],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,395][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0575, 0.0731, 0.0316, 0.0397, 0.1696, 0.4916, 0.1369],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,397][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0440, 0.0743, 0.0594, 0.0483, 0.1987, 0.1648, 0.4105],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,399][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.1492, 0.0144, 0.1788, 0.0015, 0.4331, 0.0456, 0.1775],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,400][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.1684, 0.1755, 0.1568, 0.1487, 0.1260, 0.1407, 0.0840],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,402][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.8940, 0.0131, 0.0146, 0.0093, 0.0226, 0.0144, 0.0319],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,403][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0469, 0.0289, 0.0194, 0.0833, 0.0485, 0.2642, 0.5087],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,405][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([7.4529e-06, 1.5771e-01, 1.2264e-01, 1.4607e-01, 1.6715e-01, 1.5622e-01,
        1.3916e-01, 1.1105e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,406][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0038, 0.0440, 0.2587, 0.0561, 0.2768, 0.1017, 0.2015, 0.0573],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,407][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.1136, 0.0939, 0.1736, 0.1082, 0.1788, 0.0931, 0.1424, 0.0963],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,408][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.2959, 0.0504, 0.1447, 0.0664, 0.1370, 0.1169, 0.1057, 0.0829],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,409][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0024, 0.0291, 0.0511, 0.0177, 0.2737, 0.2684, 0.3106, 0.0468],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,409][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0212, 0.1033, 0.1735, 0.1283, 0.1927, 0.1312, 0.1482, 0.1017],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,410][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0490, 0.0698, 0.0482, 0.0237, 0.1335, 0.3262, 0.3173, 0.0324],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,412][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0209, 0.0403, 0.0231, 0.0253, 0.0912, 0.1031, 0.6044, 0.0918],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,414][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0561, 0.0063, 0.1848, 0.0023, 0.4129, 0.0422, 0.2714, 0.0241],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,416][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.1393, 0.1530, 0.1456, 0.1436, 0.1160, 0.1254, 0.0879, 0.0891],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,417][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.9241, 0.0094, 0.0105, 0.0059, 0.0163, 0.0097, 0.0166, 0.0075],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,419][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0805, 0.0625, 0.0295, 0.2435, 0.0921, 0.1224, 0.0507, 0.3187],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,420][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([6.0464e-06, 1.4201e-01, 1.0830e-01, 1.3175e-01, 1.5035e-01, 1.4132e-01,
        1.2598e-01, 1.0013e-01, 1.0015e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,422][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0038, 0.0580, 0.1508, 0.1118, 0.1361, 0.0872, 0.2654, 0.1420, 0.0450],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,423][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.1398, 0.0777, 0.1400, 0.0897, 0.1428, 0.0823, 0.1237, 0.0849, 0.1191],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,424][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.4182, 0.0355, 0.1033, 0.0471, 0.1025, 0.0902, 0.0798, 0.0712, 0.0521],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,425][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0182, 0.0165, 0.0591, 0.0044, 0.1739, 0.1944, 0.1782, 0.0361, 0.3192],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,426][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0145, 0.0960, 0.1279, 0.1247, 0.1693, 0.1230, 0.1346, 0.1022, 0.1076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,427][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0853, 0.0201, 0.0362, 0.0144, 0.1273, 0.2993, 0.1728, 0.0379, 0.2068],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,428][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0573, 0.0250, 0.0161, 0.0079, 0.0291, 0.0945, 0.2733, 0.0844, 0.4124],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,430][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.3661, 0.0041, 0.1173, 0.0008, 0.2577, 0.0179, 0.1063, 0.0309, 0.0989],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,431][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.1439, 0.1536, 0.1166, 0.1214, 0.0973, 0.1252, 0.0755, 0.0987, 0.0676],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,433][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.8874, 0.0111, 0.0159, 0.0068, 0.0205, 0.0145, 0.0206, 0.0101, 0.0131],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,435][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0618, 0.0248, 0.0091, 0.0835, 0.0178, 0.0954, 0.0322, 0.0254, 0.6501],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,436][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.3912e-06, 1.2621e-01, 9.7698e-02, 1.1879e-01, 1.3489e-01, 1.2628e-01,
        1.1240e-01, 8.9610e-02, 8.9584e-02, 1.0453e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,438][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0059, 0.0320, 0.2307, 0.0452, 0.1634, 0.1354, 0.1796, 0.0737, 0.0893,
        0.0448], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,440][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1239, 0.0692, 0.1334, 0.0808, 0.1332, 0.0730, 0.1054, 0.0795, 0.1039,
        0.0976], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,441][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3838, 0.0333, 0.0993, 0.0422, 0.0953, 0.0838, 0.0727, 0.0572, 0.0498,
        0.0828], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,442][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0205, 0.0049, 0.0274, 0.0027, 0.0941, 0.1287, 0.1204, 0.0237, 0.3274,
        0.2500], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,442][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0163, 0.0800, 0.1386, 0.1019, 0.1405, 0.1085, 0.1119, 0.0900, 0.1264,
        0.0859], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,443][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1579, 0.0082, 0.0201, 0.0045, 0.0573, 0.1735, 0.0926, 0.0155, 0.3805,
        0.0899], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,444][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0383, 0.0093, 0.0113, 0.0062, 0.0308, 0.0373, 0.1427, 0.0657, 0.5258,
        0.1327], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,445][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1995, 0.0012, 0.0982, 0.0005, 0.1832, 0.0221, 0.1406, 0.0186, 0.2880,
        0.0482], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,447][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1106, 0.1247, 0.1206, 0.1213, 0.0903, 0.1009, 0.0746, 0.0881, 0.0826,
        0.0864], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,449][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9101, 0.0092, 0.0092, 0.0062, 0.0141, 0.0109, 0.0142, 0.0069, 0.0082,
        0.0109], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,450][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0316, 0.0400, 0.0144, 0.1672, 0.0141, 0.0348, 0.0262, 0.0379, 0.0486,
        0.5852], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,451][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([5.4990e-06, 1.1740e-01, 8.9048e-02, 1.0924e-01, 1.2361e-01, 1.1634e-01,
        1.0300e-01, 8.2409e-02, 8.1671e-02, 9.5505e-02, 8.1773e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,454][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0031, 0.0482, 0.1602, 0.0698, 0.1246, 0.1475, 0.1627, 0.1001, 0.0677,
        0.0931, 0.0230], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,456][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1185, 0.0622, 0.1141, 0.0740, 0.1175, 0.0640, 0.0896, 0.0674, 0.0914,
        0.0941, 0.1072], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,457][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2949, 0.0318, 0.1046, 0.0443, 0.1011, 0.0826, 0.0740, 0.0567, 0.0507,
        0.0887, 0.0705], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,458][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0257, 0.0020, 0.0150, 0.0010, 0.0454, 0.0667, 0.0610, 0.0115, 0.2575,
        0.1850, 0.3292], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,459][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0154, 0.0738, 0.1175, 0.0935, 0.1243, 0.0968, 0.1019, 0.0896, 0.1123,
        0.0978, 0.0772], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,460][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2534, 0.0041, 0.0219, 0.0029, 0.0478, 0.1162, 0.0733, 0.0120, 0.2768,
        0.1337, 0.0580], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,461][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0902, 0.0079, 0.0116, 0.0062, 0.0337, 0.0458, 0.1316, 0.0593, 0.2650,
        0.1626, 0.1862], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,461][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([4.2027e-01, 1.9817e-03, 9.7904e-02, 3.9130e-04, 1.6804e-01, 1.0756e-02,
        8.1146e-02, 1.2082e-02, 1.5627e-01, 3.7635e-02, 1.3523e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,464][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0831, 0.1163, 0.1128, 0.1064, 0.0911, 0.0978, 0.0739, 0.0868, 0.0772,
        0.0784, 0.0761], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,466][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9242, 0.0069, 0.0072, 0.0048, 0.0118, 0.0086, 0.0114, 0.0049, 0.0064,
        0.0084, 0.0056], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,467][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0496, 0.0303, 0.0388, 0.0638, 0.0916, 0.1584, 0.0455, 0.0564, 0.0374,
        0.0302, 0.3981], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,468][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([8.4255e-06, 1.0789e-01, 8.3286e-02, 9.8550e-02, 1.1153e-01, 1.0523e-01,
        9.4840e-02, 7.6271e-02, 7.5725e-02, 8.6797e-02, 7.5570e-02, 8.4297e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,470][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0021, 0.0413, 0.1564, 0.0459, 0.1202, 0.0794, 0.1880, 0.1054, 0.0755,
        0.0570, 0.0344, 0.0945], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,472][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.1688, 0.0500, 0.0915, 0.0567, 0.0882, 0.0580, 0.0667, 0.0513, 0.0679,
        0.0756, 0.0915, 0.1339], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,474][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.4039, 0.0230, 0.0759, 0.0307, 0.0727, 0.0588, 0.0478, 0.0373, 0.0357,
        0.0606, 0.0564, 0.0971], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,475][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([2.4386e-02, 1.0812e-04, 1.4102e-03, 2.9469e-05, 2.4079e-03, 4.2775e-03,
        3.4037e-03, 5.9655e-04, 1.1034e-02, 7.0169e-03, 4.9227e-02, 8.9610e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,476][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.0130, 0.0658, 0.0984, 0.0805, 0.1164, 0.0894, 0.0985, 0.0780, 0.1061,
        0.0809, 0.0714, 0.1016], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,477][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.1991, 0.0016, 0.0053, 0.0007, 0.0138, 0.0361, 0.0311, 0.0041, 0.1023,
        0.0262, 0.0970, 0.4826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,478][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([2.0912e-01, 1.0650e-03, 4.6055e-03, 5.9755e-04, 1.1302e-02, 6.3233e-03,
        2.7170e-02, 8.8072e-03, 3.7971e-02, 2.0060e-02, 4.3950e-02, 6.2903e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,478][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([7.6495e-01, 7.6357e-05, 1.8990e-02, 2.3882e-05, 2.8764e-02, 1.3959e-03,
        1.3549e-02, 1.9909e-03, 1.8463e-02, 2.8436e-03, 7.9972e-03, 1.4096e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,481][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0605, 0.1106, 0.1159, 0.0935, 0.0958, 0.0918, 0.0766, 0.0825, 0.0672,
        0.0717, 0.0671, 0.0669], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,483][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.8319, 0.0114, 0.0139, 0.0082, 0.0182, 0.0152, 0.0262, 0.0077, 0.0113,
        0.0120, 0.0108, 0.0331], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,484][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.0910, 0.0605, 0.0581, 0.1257, 0.0857, 0.1479, 0.0562, 0.0402, 0.0253,
        0.0301, 0.1114, 0.1678], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,486][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([9.0217e-06, 9.8592e-02, 7.7111e-02, 9.1020e-02, 1.0261e-01, 9.6719e-02,
        8.6985e-02, 7.0351e-02, 6.9823e-02, 7.9915e-02, 6.9842e-02, 7.7749e-02,
        7.9277e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,488][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0018, 0.0192, 0.1447, 0.0295, 0.1162, 0.1273, 0.2438, 0.0811, 0.0676,
        0.0472, 0.0254, 0.0756, 0.0207], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,489][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0757, 0.0510, 0.1018, 0.0593, 0.0955, 0.0526, 0.0730, 0.0569, 0.0730,
        0.0749, 0.0923, 0.1368, 0.0572], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,491][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.2661, 0.0301, 0.0831, 0.0361, 0.0750, 0.0751, 0.0556, 0.0503, 0.0366,
        0.0626, 0.0580, 0.1084, 0.0629], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,492][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.0660e-03, 2.4856e-04, 9.1526e-04, 1.4763e-04, 3.1016e-03, 3.9073e-03,
        3.9070e-03, 9.1040e-04, 1.7951e-02, 1.1652e-02, 5.4148e-02, 8.9438e-01,
        7.6672e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,493][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0145, 0.0582, 0.0969, 0.0728, 0.1095, 0.0850, 0.0872, 0.0734, 0.0969,
        0.0749, 0.0667, 0.0981, 0.0659], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,494][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0865, 0.0020, 0.0129, 0.0018, 0.0219, 0.0387, 0.0412, 0.0093, 0.0672,
        0.0453, 0.0666, 0.5838, 0.0228], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,495][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0170, 0.0034, 0.0048, 0.0032, 0.0134, 0.0118, 0.0518, 0.0258, 0.0797,
        0.0599, 0.1020, 0.5904, 0.0369], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,496][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([6.4510e-02, 6.1294e-04, 3.9685e-02, 2.1894e-04, 6.2410e-02, 3.6786e-03,
        3.4442e-02, 6.9831e-03, 6.4155e-02, 1.2837e-02, 2.0910e-02, 6.8494e-01,
        4.6209e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,498][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0638, 0.0940, 0.0939, 0.0834, 0.0765, 0.0852, 0.0648, 0.0738, 0.0654,
        0.0718, 0.0664, 0.0788, 0.0825], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,500][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.9018, 0.0074, 0.0076, 0.0044, 0.0110, 0.0088, 0.0115, 0.0051, 0.0072,
        0.0083, 0.0066, 0.0145, 0.0058], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,502][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0610, 0.0756, 0.0246, 0.3239, 0.0198, 0.0812, 0.0335, 0.0238, 0.0244,
        0.1077, 0.0274, 0.0349, 0.1622], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,503][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([8.7890e-06, 9.0107e-02, 7.0262e-02, 8.2771e-02, 9.3197e-02, 8.8208e-02,
        8.0208e-02, 6.5019e-02, 6.5383e-02, 7.4183e-02, 6.5018e-02, 7.1169e-02,
        7.2032e-02, 8.2433e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,505][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0014, 0.0460, 0.2122, 0.0475, 0.0277, 0.1139, 0.1508, 0.1203, 0.0413,
        0.0450, 0.0276, 0.0815, 0.0595, 0.0253], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,507][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1364, 0.0419, 0.0734, 0.0467, 0.0704, 0.0466, 0.0521, 0.0418, 0.0588,
        0.0637, 0.0765, 0.1112, 0.0514, 0.1290], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,508][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.4639, 0.0189, 0.0566, 0.0230, 0.0521, 0.0438, 0.0357, 0.0282, 0.0217,
        0.0408, 0.0363, 0.0719, 0.0485, 0.0587], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,509][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([1.0132e-02, 3.7152e-05, 5.4805e-04, 1.0669e-05, 8.6752e-04, 2.5820e-03,
        1.4402e-03, 2.0499e-04, 4.5778e-03, 2.2126e-03, 1.0187e-02, 3.5533e-01,
        3.4544e-03, 6.0842e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,510][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0090, 0.0575, 0.0963, 0.0701, 0.0746, 0.0815, 0.0798, 0.0770, 0.0905,
        0.0677, 0.0647, 0.0902, 0.0692, 0.0718], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,511][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.2777, 0.0010, 0.0067, 0.0004, 0.0036, 0.0365, 0.0193, 0.0032, 0.0366,
        0.0147, 0.0336, 0.2718, 0.0369, 0.2582], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,512][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([1.4557e-01, 6.0342e-04, 2.0324e-03, 3.5332e-04, 3.7325e-03, 5.0669e-03,
        1.5079e-02, 5.5254e-03, 3.6347e-02, 1.0380e-02, 2.4462e-02, 2.0567e-01,
        2.6026e-02, 5.1915e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,513][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([7.5135e-01, 5.3254e-05, 4.2538e-03, 5.9389e-06, 3.1706e-03, 7.5682e-04,
        3.3031e-03, 5.4584e-04, 5.8699e-03, 6.2843e-04, 1.4682e-03, 5.8133e-02,
        5.1508e-04, 1.6995e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,515][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0847, 0.0978, 0.0971, 0.0776, 0.0471, 0.0743, 0.0545, 0.0631, 0.0546,
        0.0612, 0.0687, 0.0836, 0.0889, 0.0469], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,517][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.7450, 0.0145, 0.0181, 0.0117, 0.0295, 0.0203, 0.0283, 0.0100, 0.0160,
        0.0158, 0.0122, 0.0301, 0.0141, 0.0343], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,519][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0699, 0.0276, 0.1981, 0.0143, 0.1535, 0.0361, 0.0280, 0.0196, 0.0143,
        0.0247, 0.1087, 0.0733, 0.0523, 0.1797], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,520][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([5.5771e-06, 8.4725e-02, 6.5778e-02, 7.7785e-02, 8.8355e-02, 8.2800e-02,
        7.4756e-02, 6.0441e-02, 5.9885e-02, 6.9348e-02, 5.9758e-02, 6.6073e-02,
        6.7060e-02, 7.7400e-02, 6.5830e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,522][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0013, 0.0285, 0.1957, 0.0478, 0.1134, 0.0417, 0.1227, 0.0661, 0.0288,
        0.0461, 0.0249, 0.0782, 0.0363, 0.1282, 0.0403], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,524][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1320, 0.0400, 0.0742, 0.0437, 0.0751, 0.0402, 0.0502, 0.0393, 0.0473,
        0.0525, 0.0617, 0.0932, 0.0436, 0.1199, 0.0871], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,526][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.3197, 0.0192, 0.0621, 0.0256, 0.0650, 0.0515, 0.0434, 0.0324, 0.0265,
        0.0468, 0.0420, 0.0775, 0.0532, 0.0747, 0.0604], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,527][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([5.2691e-03, 4.0448e-05, 3.2741e-04, 9.7812e-06, 6.7523e-04, 1.3385e-03,
        9.3310e-04, 1.2638e-04, 2.6628e-03, 9.2038e-04, 7.3975e-03, 2.1349e-01,
        2.1137e-03, 5.1499e-01, 2.4971e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,528][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0107, 0.0524, 0.0858, 0.0682, 0.1011, 0.0652, 0.0747, 0.0571, 0.0654,
        0.0573, 0.0523, 0.0871, 0.0568, 0.0987, 0.0672], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,529][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([1.1975e-01, 8.7995e-04, 5.2460e-03, 3.0667e-04, 5.9022e-03, 1.2569e-02,
        7.0492e-03, 1.3932e-03, 1.4537e-02, 1.0448e-02, 1.9144e-02, 1.5678e-01,
        2.2602e-02, 3.6522e-01, 2.5818e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,529][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([3.6637e-02, 5.1290e-04, 8.4112e-04, 2.4566e-04, 1.9167e-03, 5.5211e-03,
        1.2144e-02, 3.0953e-03, 8.0360e-03, 5.0041e-03, 1.3522e-02, 1.1422e-01,
        1.4465e-02, 2.3672e-01, 5.4712e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,530][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([7.0413e-02, 7.9763e-05, 6.6165e-03, 8.7767e-06, 1.2858e-02, 4.3355e-04,
        4.4229e-03, 5.5405e-04, 3.5500e-03, 1.1638e-03, 2.8352e-03, 9.1211e-02,
        1.0825e-03, 7.8995e-01, 1.4817e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,532][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0669, 0.0839, 0.0980, 0.0712, 0.0628, 0.0790, 0.0460, 0.0597, 0.0542,
        0.0544, 0.0575, 0.0740, 0.0800, 0.0602, 0.0523], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,535][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.7797, 0.0113, 0.0149, 0.0077, 0.0215, 0.0154, 0.0205, 0.0098, 0.0119,
        0.0135, 0.0100, 0.0207, 0.0106, 0.0248, 0.0277], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,536][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0892, 0.0360, 0.0307, 0.1039, 0.0288, 0.1042, 0.1374, 0.0218, 0.0711,
        0.0561, 0.0668, 0.0185, 0.0501, 0.0388, 0.1467], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,537][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.7165e-06, 7.9637e-02, 6.1350e-02, 7.3320e-02, 8.2847e-02, 7.7896e-02,
        6.9398e-02, 5.5810e-02, 5.5241e-02, 6.4377e-02, 5.5457e-02, 6.2068e-02,
        6.3292e-02, 7.2669e-02, 6.1601e-02, 6.5032e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,540][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0025, 0.0198, 0.1549, 0.0272, 0.1059, 0.0922, 0.1175, 0.0483, 0.0577,
        0.0268, 0.0324, 0.0662, 0.0218, 0.1193, 0.0782, 0.0296],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,541][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0877, 0.0365, 0.0727, 0.0414, 0.0710, 0.0390, 0.0503, 0.0391, 0.0500,
        0.0486, 0.0615, 0.0973, 0.0429, 0.1148, 0.0895, 0.0579],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,543][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3129, 0.0189, 0.0560, 0.0236, 0.0546, 0.0453, 0.0404, 0.0301, 0.0254,
        0.0441, 0.0373, 0.0782, 0.0501, 0.0641, 0.0648, 0.0542],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,544][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.4812e-03, 1.9394e-05, 3.6544e-04, 8.5771e-06, 6.6479e-04, 1.0917e-03,
        7.8104e-04, 1.0570e-04, 1.4028e-03, 8.2754e-04, 5.6403e-03, 1.9672e-01,
        1.4139e-03, 3.6561e-01, 3.9360e-01, 2.9258e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,545][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0103, 0.0485, 0.0829, 0.0606, 0.0854, 0.0658, 0.0663, 0.0535, 0.0752,
        0.0515, 0.0563, 0.0804, 0.0537, 0.0855, 0.0747, 0.0492],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,546][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4487e-01, 3.7234e-04, 3.2424e-03, 1.6996e-04, 5.4753e-03, 1.4015e-02,
        7.3709e-03, 9.6182e-04, 1.8507e-02, 4.0804e-03, 1.2822e-02, 1.2827e-01,
        7.9855e-03, 2.5778e-01, 3.4145e-01, 5.2620e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,547][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.2010e-02, 3.4152e-04, 8.9902e-04, 1.7944e-04, 1.9332e-03, 2.4552e-03,
        6.0910e-03, 2.6499e-03, 1.5533e-02, 3.5818e-03, 7.3624e-03, 8.7878e-02,
        5.3987e-03, 1.7336e-01, 6.4314e-01, 3.7180e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,548][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.4893e-02, 3.7502e-05, 6.1018e-03, 1.3283e-05, 9.2886e-03, 9.0660e-04,
        5.3378e-03, 5.1920e-04, 9.0512e-03, 1.2207e-03, 3.9741e-03, 1.4638e-01,
        1.3602e-03, 6.5981e-01, 1.1375e-01, 7.3458e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,550][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0737, 0.0785, 0.0816, 0.0753, 0.0579, 0.0663, 0.0458, 0.0561, 0.0505,
        0.0524, 0.0556, 0.0690, 0.0778, 0.0541, 0.0556, 0.0498],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,552][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8177, 0.0103, 0.0099, 0.0069, 0.0146, 0.0120, 0.0154, 0.0072, 0.0092,
        0.0114, 0.0079, 0.0206, 0.0081, 0.0184, 0.0188, 0.0116],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,553][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0167, 0.0232, 0.0084, 0.0908, 0.0082, 0.0202, 0.0126, 0.0189, 0.0241,
        0.3224, 0.0219, 0.0040, 0.0500, 0.0085, 0.0053, 0.3647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:45,555][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([8.1859e-06, 7.3142e-02, 5.6671e-02, 6.6866e-02, 7.4884e-02, 7.0989e-02,
        6.3969e-02, 5.1856e-02, 5.1655e-02, 5.9677e-02, 5.1817e-02, 5.7633e-02,
        5.8412e-02, 6.6304e-02, 5.6939e-02, 6.0053e-02, 7.9126e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,557][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0012, 0.0323, 0.2023, 0.0582, 0.0554, 0.0585, 0.0900, 0.0715, 0.0466,
        0.0476, 0.0320, 0.0612, 0.0665, 0.0602, 0.0413, 0.0575, 0.0176],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,559][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0906, 0.0330, 0.0635, 0.0363, 0.0625, 0.0363, 0.0476, 0.0366, 0.0447,
        0.0459, 0.0554, 0.0912, 0.0383, 0.1097, 0.0817, 0.0549, 0.0717],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,561][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.3938, 0.0114, 0.0410, 0.0162, 0.0431, 0.0306, 0.0289, 0.0202, 0.0185,
        0.0317, 0.0284, 0.0589, 0.0360, 0.0542, 0.0466, 0.0427, 0.0977],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,562][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([5.4821e-03, 4.3093e-05, 6.5915e-04, 1.0269e-05, 1.0465e-03, 1.7408e-03,
        1.1295e-03, 1.4667e-04, 1.5084e-03, 7.8380e-04, 5.8399e-03, 1.3779e-01,
        2.4381e-03, 4.1836e-01, 2.9190e-01, 2.2060e-02, 1.0906e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,562][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0082, 0.0468, 0.0743, 0.0563, 0.0743, 0.0620, 0.0629, 0.0569, 0.0669,
        0.0538, 0.0512, 0.0759, 0.0540, 0.0728, 0.0721, 0.0504, 0.0611],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,563][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([5.0509e-02, 5.1207e-04, 3.9783e-03, 1.6653e-04, 3.5728e-03, 1.1026e-02,
        8.0729e-03, 1.3446e-03, 6.9836e-03, 6.8008e-03, 5.5862e-03, 1.1240e-01,
        6.1742e-03, 1.5731e-01, 3.9242e-01, 8.5763e-02, 1.4737e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,564][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([4.1177e-02, 5.4334e-04, 1.4490e-03, 1.8545e-04, 3.3740e-03, 4.3795e-03,
        9.4494e-03, 4.0426e-03, 7.9566e-03, 7.4797e-03, 7.9954e-03, 6.4632e-02,
        7.6870e-03, 2.2426e-01, 4.5613e-01, 7.0671e-02, 8.8591e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,565][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([2.3683e-01, 2.6902e-05, 1.0179e-02, 5.2870e-06, 9.7801e-03, 4.6655e-04,
        4.3741e-03, 6.4361e-04, 5.5334e-03, 9.1227e-04, 1.4672e-03, 7.1827e-02,
        6.6780e-04, 6.1056e-01, 2.5402e-02, 4.2793e-03, 1.7052e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,567][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0659, 0.0728, 0.0726, 0.0592, 0.0588, 0.0676, 0.0508, 0.0576, 0.0464,
        0.0529, 0.0484, 0.0612, 0.0661, 0.0539, 0.0608, 0.0492, 0.0558],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,569][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.7552, 0.0123, 0.0148, 0.0081, 0.0213, 0.0122, 0.0186, 0.0090, 0.0098,
        0.0144, 0.0100, 0.0207, 0.0109, 0.0253, 0.0197, 0.0143, 0.0234],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,571][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0248, 0.0333, 0.0220, 0.1245, 0.0252, 0.0976, 0.0173, 0.0125, 0.0375,
        0.0961, 0.0693, 0.0146, 0.0647, 0.0298, 0.0239, 0.1011, 0.2059],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:45,572][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([5.3879e-06, 6.8532e-02, 5.2531e-02, 6.3353e-02, 7.0822e-02, 6.7145e-02,
        5.9502e-02, 4.8113e-02, 4.7606e-02, 5.5527e-02, 4.7988e-02, 5.3838e-02,
        5.4847e-02, 6.2184e-02, 5.2939e-02, 5.5641e-02, 7.4204e-02, 6.5222e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,574][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0012, 0.0307, 0.1066, 0.0462, 0.0576, 0.0978, 0.1125, 0.0637, 0.0373,
        0.0590, 0.0163, 0.0651, 0.0397, 0.0721, 0.0686, 0.0657, 0.0435, 0.0163],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,576][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0796, 0.0328, 0.0650, 0.0386, 0.0614, 0.0340, 0.0443, 0.0351, 0.0424,
        0.0463, 0.0522, 0.0831, 0.0382, 0.0959, 0.0780, 0.0541, 0.0665, 0.0527],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,578][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2356, 0.0151, 0.0507, 0.0207, 0.0497, 0.0375, 0.0371, 0.0250, 0.0214,
        0.0379, 0.0294, 0.0680, 0.0417, 0.0571, 0.0575, 0.0481, 0.1234, 0.0442],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,579][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.7988e-03, 5.5509e-05, 9.5118e-04, 1.4766e-05, 1.4905e-03, 1.6840e-03,
        1.5687e-03, 1.7143e-04, 2.8945e-03, 1.3566e-03, 3.6266e-03, 1.3065e-01,
        1.8081e-03, 3.1503e-01, 2.8967e-01, 2.7095e-02, 1.6357e-01, 5.4565e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,580][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0108, 0.0438, 0.0657, 0.0539, 0.0714, 0.0571, 0.0609, 0.0517, 0.0598,
        0.0544, 0.0450, 0.0686, 0.0487, 0.0735, 0.0633, 0.0520, 0.0682, 0.0510],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,581][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([5.1251e-02, 3.7884e-04, 5.0360e-03, 1.5700e-04, 4.1556e-03, 1.0299e-02,
        7.2292e-03, 8.5572e-04, 1.3570e-02, 7.0202e-03, 2.7181e-03, 9.3725e-02,
        5.5908e-03, 1.1265e-01, 2.9123e-01, 8.1683e-02, 2.9383e-01, 1.8616e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,581][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.0989e-02, 4.2607e-04, 1.1374e-03, 2.2274e-04, 1.8044e-03, 4.2811e-03,
        6.7637e-03, 2.9026e-03, 1.0646e-02, 4.7755e-03, 4.8843e-03, 8.9707e-02,
        6.0032e-03, 8.7670e-02, 3.4598e-01, 3.9280e-02, 3.3256e-01, 3.9970e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,583][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.2754e-02, 1.0156e-04, 9.9906e-03, 1.8816e-05, 1.4044e-02, 6.0188e-04,
        5.9446e-03, 6.8525e-04, 6.1487e-03, 1.2258e-03, 1.4740e-03, 8.5515e-02,
        1.2241e-03, 5.7384e-01, 6.5367e-02, 6.6954e-03, 1.3002e-01, 4.3440e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,585][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0685, 0.0719, 0.0679, 0.0624, 0.0542, 0.0586, 0.0422, 0.0503, 0.0452,
        0.0469, 0.0486, 0.0534, 0.0689, 0.0506, 0.0484, 0.0470, 0.0609, 0.0542],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,587][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7848, 0.0101, 0.0109, 0.0070, 0.0165, 0.0118, 0.0153, 0.0069, 0.0090,
        0.0108, 0.0083, 0.0197, 0.0081, 0.0194, 0.0182, 0.0106, 0.0188, 0.0139],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,589][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0496, 0.0166, 0.1217, 0.0491, 0.0922, 0.0394, 0.0088, 0.0229, 0.0430,
        0.0284, 0.0957, 0.0484, 0.0394, 0.1013, 0.0059, 0.0302, 0.0166, 0.1906],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:45,590][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([3.6458e-06, 6.5417e-02, 4.9990e-02, 6.0150e-02, 6.7806e-02, 6.4261e-02,
        5.7181e-02, 4.5786e-02, 4.5450e-02, 5.2746e-02, 4.5670e-02, 5.0769e-02,
        5.1959e-02, 5.9190e-02, 5.0133e-02, 5.2792e-02, 7.1198e-02, 6.2761e-02,
        4.6740e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,592][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0014, 0.0389, 0.0936, 0.0328, 0.0545, 0.0571, 0.1136, 0.0943, 0.0396,
        0.0445, 0.0198, 0.0650, 0.0238, 0.0658, 0.0887, 0.0473, 0.0638, 0.0241,
        0.0314], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,594][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1218, 0.0289, 0.0526, 0.0312, 0.0513, 0.0306, 0.0348, 0.0286, 0.0358,
        0.0386, 0.0469, 0.0716, 0.0335, 0.0866, 0.0648, 0.0464, 0.0588, 0.0529,
        0.0841], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,595][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.2518, 0.0132, 0.0435, 0.0179, 0.0431, 0.0354, 0.0261, 0.0218, 0.0178,
        0.0334, 0.0317, 0.0497, 0.0337, 0.0487, 0.0400, 0.0418, 0.0956, 0.0481,
        0.1065], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,596][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([7.4207e-03, 1.0895e-05, 2.0170e-04, 2.3949e-06, 2.5323e-04, 8.3948e-04,
        5.3620e-04, 6.3690e-05, 5.6560e-04, 3.7795e-04, 2.0372e-03, 4.9306e-02,
        9.8346e-04, 1.0662e-01, 1.2576e-01, 9.2597e-03, 5.9443e-02, 7.6871e-02,
        5.5945e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,597][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.0089, 0.0381, 0.0539, 0.0463, 0.0638, 0.0536, 0.0606, 0.0502, 0.0613,
        0.0487, 0.0422, 0.0672, 0.0397, 0.0653, 0.0717, 0.0457, 0.0703, 0.0513,
        0.0610], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,598][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([1.6602e-01, 2.8084e-04, 2.7714e-03, 8.4909e-05, 2.7142e-03, 7.5486e-03,
        4.7269e-03, 6.9192e-04, 9.1795e-03, 2.2220e-03, 6.9184e-03, 7.4053e-02,
        4.9454e-03, 1.1997e-01, 1.9901e-01, 2.2053e-02, 1.3117e-01, 7.4092e-02,
        1.7153e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,599][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([5.7688e-02, 2.3558e-04, 1.2404e-03, 6.9835e-05, 2.1322e-03, 2.0283e-03,
        6.6948e-03, 1.5968e-03, 4.9418e-03, 2.3404e-03, 3.5711e-03, 4.9100e-02,
        6.4834e-03, 1.8459e-01, 2.2045e-01, 2.2751e-02, 1.2759e-01, 3.9664e-02,
        2.6683e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,601][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([3.5209e-01, 3.3792e-05, 8.4827e-03, 7.2595e-06, 9.5758e-03, 6.5302e-04,
        3.2242e-03, 4.7774e-04, 3.5264e-03, 6.3048e-04, 1.3716e-03, 3.9909e-02,
        5.4698e-04, 4.0114e-01, 2.9160e-02, 2.7199e-03, 5.5988e-02, 7.0364e-03,
        8.3423e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,603][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0550, 0.0763, 0.0758, 0.0575, 0.0498, 0.0579, 0.0435, 0.0596, 0.0387,
        0.0456, 0.0437, 0.0507, 0.0589, 0.0459, 0.0493, 0.0456, 0.0601, 0.0502,
        0.0360], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,605][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.6907, 0.0107, 0.0146, 0.0082, 0.0173, 0.0132, 0.0272, 0.0089, 0.0099,
        0.0128, 0.0099, 0.0264, 0.0122, 0.0248, 0.0189, 0.0150, 0.0195, 0.0180,
        0.0420], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,607][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0587, 0.0284, 0.0324, 0.0280, 0.0742, 0.0515, 0.0329, 0.0103, 0.0184,
        0.0088, 0.1334, 0.0383, 0.0282, 0.0796, 0.0299, 0.0103, 0.0147, 0.0365,
        0.2854], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:45,608][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.6321e-06, 6.0896e-02, 4.7759e-02, 5.6930e-02, 6.3921e-02, 6.0152e-02,
        5.3780e-02, 4.3551e-02, 4.3150e-02, 4.9918e-02, 4.3331e-02, 4.8508e-02,
        4.9303e-02, 5.6039e-02, 4.7680e-02, 4.9904e-02, 6.6631e-02, 5.8775e-02,
        4.4789e-02, 5.4978e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,610][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0014, 0.0162, 0.1381, 0.0212, 0.0893, 0.0812, 0.0975, 0.0420, 0.0525,
        0.0206, 0.0250, 0.0551, 0.0159, 0.1005, 0.0697, 0.0224, 0.0420, 0.0315,
        0.0606, 0.0173], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,612][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0813, 0.0296, 0.0569, 0.0329, 0.0539, 0.0317, 0.0387, 0.0309, 0.0383,
        0.0372, 0.0457, 0.0685, 0.0322, 0.0771, 0.0639, 0.0424, 0.0571, 0.0503,
        0.0805, 0.0510], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,613][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2398, 0.0124, 0.0377, 0.0157, 0.0375, 0.0303, 0.0282, 0.0201, 0.0174,
        0.0290, 0.0245, 0.0500, 0.0350, 0.0434, 0.0425, 0.0356, 0.0934, 0.0382,
        0.1217, 0.0477], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,614][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.3481e-03, 1.5972e-05, 3.2465e-04, 5.0615e-06, 3.5192e-04, 8.7767e-04,
        4.7122e-04, 6.8793e-05, 5.1507e-04, 3.1069e-04, 1.7040e-03, 3.7945e-02,
        6.5918e-04, 7.7432e-02, 8.3330e-02, 7.0754e-03, 6.2520e-02, 5.3357e-02,
        5.5669e-01, 1.1000e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,615][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0085, 0.0375, 0.0638, 0.0470, 0.0658, 0.0510, 0.0511, 0.0419, 0.0586,
        0.0414, 0.0442, 0.0609, 0.0418, 0.0662, 0.0564, 0.0396, 0.0598, 0.0523,
        0.0710, 0.0412], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,616][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.5573e-01, 2.2471e-04, 2.4999e-03, 7.3261e-05, 2.5716e-03, 8.1252e-03,
        3.9458e-03, 5.0574e-04, 7.4962e-03, 1.6082e-03, 4.6763e-03, 3.4481e-02,
        3.3252e-03, 6.7679e-02, 9.3861e-02, 1.5422e-02, 1.1306e-01, 3.5392e-02,
        2.4836e-01, 1.0097e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,617][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.9505e-02, 3.1711e-04, 1.0528e-03, 1.3994e-04, 1.7263e-03, 2.3258e-03,
        4.3232e-03, 2.2942e-03, 7.7960e-03, 2.2949e-03, 3.9011e-03, 3.7622e-02,
        3.8904e-03, 8.3137e-02, 2.4842e-01, 1.8161e-02, 1.3585e-01, 4.1422e-02,
        2.6969e-01, 1.0613e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,619][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.8393e-02, 3.3735e-05, 5.9770e-03, 8.5988e-06, 7.3603e-03, 5.6776e-04,
        3.7193e-03, 3.3907e-04, 4.6413e-03, 6.2618e-04, 1.6874e-03, 5.5054e-02,
        7.8485e-04, 3.1774e-01, 3.9028e-02, 2.8368e-03, 6.0370e-02, 1.0918e-02,
        3.9665e-01, 1.3263e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,621][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0484, 0.0596, 0.0616, 0.0571, 0.0469, 0.0534, 0.0404, 0.0459, 0.0427,
        0.0441, 0.0456, 0.0515, 0.0597, 0.0449, 0.0454, 0.0435, 0.0570, 0.0520,
        0.0520, 0.0482], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,623][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7390, 0.0107, 0.0106, 0.0069, 0.0159, 0.0131, 0.0165, 0.0072, 0.0098,
        0.0114, 0.0083, 0.0206, 0.0085, 0.0203, 0.0196, 0.0119, 0.0214, 0.0145,
        0.0239, 0.0099], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,625][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0131, 0.0177, 0.0062, 0.0669, 0.0064, 0.0161, 0.0085, 0.0133, 0.0160,
        0.2204, 0.0160, 0.0033, 0.0366, 0.0065, 0.0037, 0.2471, 0.0122, 0.0171,
        0.0153, 0.2575], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:45,628][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:45,630][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14482],
        [ 4030],
        [ 9694],
        [ 1526],
        [  826],
        [  627],
        [ 1870],
        [  522],
        [ 4222],
        [  943],
        [  589],
        [  841],
        [ 1430],
        [ 1158],
        [ 3226],
        [ 1921],
        [ 3494],
        [ 1705],
        [ 2120],
        [  759]], device='cuda:0')
[2024-07-24 10:18:45,632][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14973],
        [ 5926],
        [21827],
        [ 4466],
        [ 2824],
        [ 2110],
        [ 8448],
        [ 1922],
        [10586],
        [ 2873],
        [ 1581],
        [ 2753],
        [ 5733],
        [ 2823],
        [ 7697],
        [ 3579],
        [ 6597],
        [ 2928],
        [ 4222],
        [ 2275]], device='cuda:0')
[2024-07-24 10:18:45,634][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[33509],
        [36728],
        [38653],
        [38830],
        [39609],
        [39519],
        [39367],
        [39176],
        [39135],
        [38989],
        [38855],
        [39113],
        [39173],
        [39377],
        [39401],
        [39355],
        [39252],
        [39214],
        [39223],
        [39201]], device='cuda:0')
[2024-07-24 10:18:45,636][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17806],
        [16883],
        [20389],
        [16680],
        [15967],
        [15348],
        [15186],
        [15405],
        [15431],
        [15563],
        [15410],
        [15433],
        [15542],
        [15879],
        [15924],
        [16042],
        [16142],
        [16326],
        [16186],
        [16297]], device='cuda:0')
[2024-07-24 10:18:45,638][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9862],
        [12235],
        [11383],
        [10835],
        [10452],
        [10509],
        [10945],
        [11317],
        [11978],
        [12510],
        [12831],
        [13489],
        [13571],
        [13626],
        [13557],
        [13726],
        [13933],
        [14054],
        [14066],
        [14054]], device='cuda:0')
[2024-07-24 10:18:45,640][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 4023],
        [22254],
        [45878],
        [45692],
        [41430],
        [46399],
        [45426],
        [46777],
        [43346],
        [40829],
        [42603],
        [43055],
        [43894],
        [35968],
        [45185],
        [42991],
        [42819],
        [41651],
        [43897],
        [36948]], device='cuda:0')
[2024-07-24 10:18:45,642][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13533],
        [42034],
        [46278],
        [46786],
        [46806],
        [45919],
        [45282],
        [45180],
        [45253],
        [45323],
        [45316],
        [44765],
        [44779],
        [44732],
        [44911],
        [44916],
        [45009],
        [44735],
        [44269],
        [44229]], device='cuda:0')
[2024-07-24 10:18:45,644][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[46364],
        [18031],
        [ 9644],
        [ 9111],
        [ 9692],
        [10828],
        [11973],
        [11737],
        [11920],
        [11209],
        [10811],
        [10988],
        [11399],
        [11234],
        [11800],
        [11896],
        [11924],
        [12144],
        [12683],
        [12506]], device='cuda:0')
[2024-07-24 10:18:45,646][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34471],
        [26737],
        [26521],
        [26693],
        [30253],
        [29260],
        [27589],
        [30118],
        [28832],
        [28178],
        [27568],
        [21981],
        [21987],
        [26376],
        [33967],
        [36328],
        [37460],
        [36746],
        [37517],
        [37268]], device='cuda:0')
[2024-07-24 10:18:45,648][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31339],
        [24218],
        [27516],
        [26885],
        [16764],
        [15992],
        [ 6058],
        [ 6047],
        [ 6010],
        [ 5987],
        [ 6108],
        [ 3418],
        [ 3332],
        [ 5270],
        [ 4276],
        [ 4527],
        [ 4705],
        [ 5300],
        [ 4534],
        [ 4238]], device='cuda:0')
[2024-07-24 10:18:45,650][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19627],
        [16121],
        [ 8306],
        [ 8460],
        [10550],
        [ 4784],
        [ 6391],
        [ 7514],
        [10472],
        [11959],
        [12207],
        [15873],
        [17384],
        [16691],
        [16078],
        [21184],
        [16668],
        [18894],
        [18789],
        [19452]], device='cuda:0')
[2024-07-24 10:18:45,651][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[9610],
        [6834],
        [9509],
        [9805],
        [9536],
        [9077],
        [8569],
        [8454],
        [8403],
        [8197],
        [8122],
        [8252],
        [8165],
        [8190],
        [8239],
        [8164],
        [8054],
        [7971],
        [8006],
        [7927]], device='cuda:0')
[2024-07-24 10:18:45,654][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15185],
        [17751],
        [ 9896],
        [13537],
        [14561],
        [14813],
        [15680],
        [15848],
        [16275],
        [16885],
        [17249],
        [17209],
        [17392],
        [17346],
        [17927],
        [18239],
        [18311],
        [18609],
        [19097],
        [19185]], device='cuda:0')
[2024-07-24 10:18:45,656][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27561],
        [12453],
        [ 8815],
        [ 9584],
        [ 9753],
        [10225],
        [10254],
        [10200],
        [10329],
        [10657],
        [10929],
        [11060],
        [11033],
        [10948],
        [10920],
        [11076],
        [10996],
        [11184],
        [11434],
        [11655]], device='cuda:0')
[2024-07-24 10:18:45,658][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25465],
        [10515],
        [ 8426],
        [ 7154],
        [12307],
        [19030],
        [ 3506],
        [ 6881],
        [17002],
        [ 5309],
        [15949],
        [10515],
        [ 9611],
        [19547],
        [18839],
        [ 9783],
        [19757],
        [23874],
        [ 7081],
        [ 9361]], device='cuda:0')
[2024-07-24 10:18:45,660][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16144],
        [17973],
        [16136],
        [16776],
        [16362],
        [16746],
        [16804],
        [16808],
        [16857],
        [16766],
        [16735],
        [16890],
        [17131],
        [17090],
        [16912],
        [16700],
        [16613],
        [16495],
        [16447],
        [16454]], device='cuda:0')
[2024-07-24 10:18:45,662][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5823],
        [25680],
        [32159],
        [30241],
        [30411],
        [31890],
        [30625],
        [31770],
        [29378],
        [32101],
        [30796],
        [31000],
        [30811],
        [29675],
        [31704],
        [32419],
        [30697],
        [30824],
        [31044],
        [31555]], device='cuda:0')
[2024-07-24 10:18:45,664][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18997],
        [38597],
        [39517],
        [39857],
        [39242],
        [38641],
        [39369],
        [39084],
        [39264],
        [38994],
        [38707],
        [37719],
        [37920],
        [36789],
        [36666],
        [36629],
        [35666],
        [35779],
        [35945],
        [35869]], device='cuda:0')
[2024-07-24 10:18:45,666][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15385],
        [26261],
        [29030],
        [31141],
        [29576],
        [32130],
        [32627],
        [33553],
        [33337],
        [33600],
        [34231],
        [33753],
        [34347],
        [33209],
        [34109],
        [34309],
        [34487],
        [35430],
        [35557],
        [35757]], device='cuda:0')
[2024-07-24 10:18:45,668][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15745],
        [37850],
        [38369],
        [42703],
        [47992],
        [47702],
        [46073],
        [45248],
        [48554],
        [48638],
        [48236],
        [39932],
        [40144],
        [48638],
        [48259],
        [47076],
        [47653],
        [46394],
        [44237],
        [44259]], device='cuda:0')
[2024-07-24 10:18:45,669][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4574],
        [36230],
        [36121],
        [36586],
        [37052],
        [38047],
        [37594],
        [37197],
        [37239],
        [37145],
        [37459],
        [37257],
        [37492],
        [37569],
        [37592],
        [37722],
        [37839],
        [37971],
        [37890],
        [37909]], device='cuda:0')
[2024-07-24 10:18:45,671][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30821],
        [43382],
        [37862],
        [36098],
        [36225],
        [39456],
        [43023],
        [43699],
        [46165],
        [48047],
        [48445],
        [42358],
        [39479],
        [39332],
        [40978],
        [42597],
        [43250],
        [43584],
        [43116],
        [43753]], device='cuda:0')
[2024-07-24 10:18:45,674][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26815],
        [33333],
        [40488],
        [34480],
        [36517],
        [32913],
        [28000],
        [24357],
        [25921],
        [29306],
        [27826],
        [28048],
        [28882],
        [34336],
        [37389],
        [38326],
        [38026],
        [37876],
        [36404],
        [36418]], device='cuda:0')
[2024-07-24 10:18:45,676][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22142],
        [38541],
        [37119],
        [41574],
        [24898],
        [43141],
        [42495],
        [42366],
        [40555],
        [40557],
        [39016],
        [26051],
        [37622],
        [26751],
        [38284],
        [38551],
        [38085],
        [39288],
        [36103],
        [34257]], device='cuda:0')
[2024-07-24 10:18:45,677][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41689],
        [43195],
        [40057],
        [38896],
        [38365],
        [37526],
        [37280],
        [36244],
        [35600],
        [34547],
        [33715],
        [33566],
        [33903],
        [34235],
        [33857],
        [33665],
        [33645],
        [33563],
        [33690],
        [33509]], device='cuda:0')
[2024-07-24 10:18:45,680][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[42128],
        [42146],
        [42284],
        [42171],
        [42225],
        [42296],
        [42506],
        [42479],
        [42668],
        [42586],
        [42505],
        [43005],
        [42802],
        [42807],
        [43246],
        [43260],
        [43298],
        [43342],
        [43266],
        [43405]], device='cuda:0')
[2024-07-24 10:18:45,682][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5823],
        [38771],
        [ 3848],
        [28381],
        [ 2257],
        [26609],
        [12416],
        [26983],
        [ 9026],
        [29409],
        [26931],
        [20158],
        [30781],
        [ 6462],
        [18645],
        [29814],
        [25619],
        [13947],
        [11891],
        [27773]], device='cuda:0')
[2024-07-24 10:18:45,684][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24921],
        [ 2666],
        [ 4901],
        [ 2565],
        [ 6066],
        [ 2487],
        [ 3144],
        [ 2510],
        [ 2272],
        [ 1264],
        [ 1225],
        [ 4507],
        [ 3517],
        [ 4219],
        [ 2131],
        [ 1738],
        [ 1788],
        [ 2264],
        [ 2740],
        [ 2235]], device='cuda:0')
[2024-07-24 10:18:45,685][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38094],
        [21753],
        [18940],
        [33597],
        [23140],
        [14429],
        [26868],
        [31240],
        [25163],
        [34140],
        [27073],
        [25899],
        [26798],
        [22862],
        [18326],
        [29530],
        [20940],
        [20025],
        [35056],
        [32667]], device='cuda:0')
[2024-07-24 10:18:45,687][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070],
        [23070]], device='cuda:0')
[2024-07-24 10:18:45,761][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:45,762][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,763][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,763][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,764][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,765][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,765][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,766][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,767][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,768][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,769][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,769][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,770][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:45,771][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3121, 0.6879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,771][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2841, 0.7159], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,772][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2753, 0.7247], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,773][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0579, 0.9421], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,773][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1455, 0.8545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,774][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5355, 0.4645], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,775][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9240, 0.0760], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,776][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8944, 0.1056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,778][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9790, 0.0210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,779][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1673, 0.8327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,781][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8278, 0.1722], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,783][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:45,784][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.1729, 0.3885, 0.4385], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,786][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.3452, 0.4497, 0.2052], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,787][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.1670, 0.4289, 0.4041], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,788][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0289, 0.4991, 0.4719], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,789][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0839, 0.5281, 0.3880], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,789][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2313, 0.1728, 0.5958], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,790][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.7429, 0.0790, 0.1781], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,791][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.7216, 0.1439, 0.1344], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,792][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.9971, 0.0016, 0.0012], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,794][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0348, 0.9578, 0.0074], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,795][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.5770, 0.2185, 0.2045], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,797][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0706, 0.6087, 0.3207], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:45,799][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1338, 0.2944, 0.3554, 0.2164], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,801][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0332, 0.6022, 0.3444, 0.0202], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,802][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1236, 0.3128, 0.2907, 0.2729], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,804][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0192, 0.3397, 0.3315, 0.3097], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,805][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0698, 0.3345, 0.2733, 0.3224], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,805][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1588, 0.1397, 0.5491, 0.1525], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,806][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8198, 0.0304, 0.0484, 0.1015], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,807][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6272, 0.1157, 0.2193, 0.0378], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,807][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9462, 0.0186, 0.0233, 0.0119], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,808][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0232, 0.1562, 0.8010, 0.0197], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,810][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5736, 0.1722, 0.1224, 0.1318], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,812][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0501, 0.3843, 0.4905, 0.0751], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:45,814][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.1027, 0.2208, 0.2393, 0.1876, 0.2496], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,815][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.2893, 0.2567, 0.2209, 0.0066, 0.2266], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,817][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.1012, 0.2430, 0.2286, 0.2118, 0.2154], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,819][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0152, 0.2559, 0.2476, 0.2351, 0.2462], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,821][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0579, 0.2528, 0.2053, 0.2413, 0.2427], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,822][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0773, 0.0483, 0.3119, 0.2517, 0.3108], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,823][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.5956, 0.0429, 0.1159, 0.0421, 0.2035], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,823][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.4714, 0.1803, 0.1745, 0.0674, 0.1064], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,824][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.9924, 0.0017, 0.0018, 0.0011, 0.0030], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,825][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([1.2683e-02, 5.2182e-01, 1.5417e-01, 3.1107e-01, 2.5699e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,825][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.4333, 0.1544, 0.1229, 0.1277, 0.1617], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,827][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.1105, 0.1644, 0.3156, 0.0208, 0.3886], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:45,829][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1033, 0.1725, 0.1893, 0.1404, 0.2092, 0.1853], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,831][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0994, 0.4465, 0.0914, 0.0150, 0.2954, 0.0523], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,833][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0834, 0.2091, 0.1951, 0.1824, 0.1842, 0.1457], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,834][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0137, 0.2093, 0.2028, 0.1907, 0.2003, 0.1832], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,836][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0410, 0.2007, 0.1540, 0.1851, 0.1905, 0.2288], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,838][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0606, 0.0682, 0.2203, 0.1720, 0.3143, 0.1647], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,839][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3061, 0.0476, 0.0930, 0.0708, 0.1652, 0.3173], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,840][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.4352, 0.1901, 0.1631, 0.0598, 0.0983, 0.0536], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,841][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.9227, 0.0122, 0.0125, 0.0090, 0.0270, 0.0168], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,841][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0130, 0.1778, 0.3487, 0.3105, 0.1329, 0.0170], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,842][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.3644, 0.1591, 0.1084, 0.1206, 0.1442, 0.1032], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,843][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0529, 0.1632, 0.1369, 0.0388, 0.4303, 0.1778], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:45,845][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0654, 0.1474, 0.1702, 0.1275, 0.1811, 0.1687, 0.1397],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,847][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0696, 0.2526, 0.1323, 0.0043, 0.2428, 0.0305, 0.2679],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,849][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0668, 0.1816, 0.1708, 0.1599, 0.1614, 0.1270, 0.1325],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,850][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0121, 0.1720, 0.1621, 0.1600, 0.1651, 0.1565, 0.1722],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,852][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0286, 0.1852, 0.1250, 0.1725, 0.1635, 0.2050, 0.1202],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,854][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0440, 0.0602, 0.2217, 0.1301, 0.1707, 0.2987, 0.0747],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,855][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.4228, 0.0358, 0.0743, 0.0381, 0.1094, 0.1873, 0.1324],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,857][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.5568, 0.1106, 0.1104, 0.0351, 0.0679, 0.0329, 0.0863],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,857][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.9804, 0.0024, 0.0022, 0.0017, 0.0046, 0.0036, 0.0051],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,858][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0251, 0.3232, 0.0708, 0.0753, 0.1063, 0.3706, 0.0288],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,859][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.3345, 0.1614, 0.1017, 0.1207, 0.1489, 0.0938, 0.0391],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,860][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0120, 0.1497, 0.0845, 0.0228, 0.2712, 0.2495, 0.2103],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:45,861][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0499, 0.1365, 0.1512, 0.1122, 0.1660, 0.1431, 0.1298, 0.1114],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,863][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0533, 0.2127, 0.1023, 0.0124, 0.2155, 0.0653, 0.3225, 0.0159],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,864][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0606, 0.1611, 0.1516, 0.1424, 0.1433, 0.1135, 0.1188, 0.1088],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,866][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0088, 0.1464, 0.1441, 0.1349, 0.1418, 0.1325, 0.1462, 0.1453],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,868][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0191, 0.1528, 0.1180, 0.1500, 0.1452, 0.1758, 0.1115, 0.1276],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,870][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0569, 0.0427, 0.1794, 0.1188, 0.2018, 0.2103, 0.1247, 0.0654],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,872][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.5714, 0.0184, 0.0630, 0.0248, 0.0869, 0.1192, 0.0618, 0.0545],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,874][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.3284, 0.1253, 0.1760, 0.0406, 0.0990, 0.0581, 0.1254, 0.0472],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,876][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.9063, 0.0089, 0.0095, 0.0076, 0.0203, 0.0153, 0.0190, 0.0132],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,878][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0094, 0.1907, 0.2089, 0.2125, 0.1277, 0.0332, 0.2136, 0.0040],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,879][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.3209, 0.1694, 0.1001, 0.1046, 0.1334, 0.0821, 0.0359, 0.0536],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,880][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0072, 0.1130, 0.1230, 0.0220, 0.4116, 0.1090, 0.1904, 0.0237],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:45,881][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0508, 0.1203, 0.1368, 0.1030, 0.1494, 0.1295, 0.1122, 0.0962, 0.1018],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,881][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.1670, 0.1072, 0.1353, 0.0041, 0.2961, 0.0363, 0.1681, 0.0061, 0.0798],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,882][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0537, 0.1437, 0.1326, 0.1271, 0.1288, 0.1018, 0.1061, 0.0966, 0.1095],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,883][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0080, 0.1285, 0.1238, 0.1218, 0.1248, 0.1179, 0.1302, 0.1296, 0.1154],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,885][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0217, 0.1479, 0.1017, 0.1327, 0.1322, 0.1627, 0.1007, 0.1231, 0.0773],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,887][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0255, 0.0248, 0.1246, 0.0777, 0.2149, 0.1731, 0.2129, 0.0828, 0.0637],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,889][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.3682, 0.0300, 0.0652, 0.0392, 0.1033, 0.1845, 0.1049, 0.0493, 0.0553],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,890][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.3316, 0.1321, 0.1509, 0.0505, 0.0910, 0.0489, 0.1021, 0.0565, 0.0364],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,892][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.9523, 0.0033, 0.0041, 0.0027, 0.0079, 0.0047, 0.0077, 0.0049, 0.0124],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,893][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ going] are: tensor([1.4904e-03, 1.8182e-01, 1.7223e-03, 2.5261e-01, 5.4007e-02, 1.4862e-02,
        4.2653e-01, 6.6807e-02, 1.4817e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,895][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.3592, 0.1370, 0.0822, 0.0951, 0.1031, 0.0772, 0.0334, 0.0481, 0.0647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,896][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0171, 0.0401, 0.0912, 0.0063, 0.3159, 0.1852, 0.1393, 0.0202, 0.1847],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:45,897][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0376, 0.1104, 0.1222, 0.0884, 0.1370, 0.1169, 0.1088, 0.0888, 0.0966,
        0.0934], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,898][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0699, 0.0507, 0.0895, 0.0035, 0.3423, 0.0353, 0.2187, 0.0071, 0.1070,
        0.0760], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,899][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0500, 0.1288, 0.1211, 0.1147, 0.1160, 0.0912, 0.0953, 0.0870, 0.0994,
        0.0967], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,899][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0066, 0.1146, 0.1113, 0.1062, 0.1100, 0.1063, 0.1144, 0.1151, 0.1048,
        0.1107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,901][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0165, 0.1241, 0.0940, 0.1203, 0.1215, 0.1537, 0.0933, 0.1039, 0.0710,
        0.1016], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,903][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0446, 0.0223, 0.1481, 0.0535, 0.1679, 0.1394, 0.1808, 0.0444, 0.1313,
        0.0679], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,904][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3367, 0.0108, 0.0325, 0.0301, 0.0679, 0.0898, 0.0493, 0.0293, 0.0149,
        0.3386], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,906][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4730, 0.0802, 0.1263, 0.0277, 0.0723, 0.0424, 0.0921, 0.0382, 0.0288,
        0.0192], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,907][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.9122, 0.0043, 0.0065, 0.0038, 0.0124, 0.0071, 0.0113, 0.0062, 0.0210,
        0.0152], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,910][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0268, 0.0266, 0.1542, 0.0108, 0.0787, 0.0925, 0.3078, 0.0317, 0.2686,
        0.0025], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,911][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.4207, 0.1158, 0.0616, 0.0803, 0.0728, 0.0609, 0.0254, 0.0357, 0.0531,
        0.0737], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,913][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0584, 0.0186, 0.1053, 0.0046, 0.2109, 0.0795, 0.0793, 0.0129, 0.2771,
        0.1534], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:45,914][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0291, 0.1021, 0.1160, 0.0835, 0.1284, 0.1085, 0.0951, 0.0815, 0.0872,
        0.0889, 0.0797], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,915][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1213, 0.0607, 0.0943, 0.0029, 0.2585, 0.0282, 0.1037, 0.0059, 0.0984,
        0.0857, 0.1403], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,915][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0441, 0.1185, 0.1105, 0.1057, 0.1062, 0.0842, 0.0875, 0.0800, 0.0913,
        0.0892, 0.0827], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,916][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0058, 0.1028, 0.1027, 0.0959, 0.1010, 0.0961, 0.1039, 0.1029, 0.0943,
        0.0998, 0.0947], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,917][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0164, 0.1143, 0.0861, 0.1089, 0.1103, 0.1370, 0.0838, 0.0936, 0.0629,
        0.0908, 0.0958], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,919][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0510, 0.0276, 0.1046, 0.0459, 0.1766, 0.1064, 0.1188, 0.0644, 0.1097,
        0.0795, 0.1156], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,921][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2308, 0.0180, 0.0434, 0.0325, 0.0806, 0.1182, 0.0543, 0.0264, 0.0164,
        0.1659, 0.2136], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,923][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.3270, 0.1049, 0.1436, 0.0385, 0.0882, 0.0498, 0.1048, 0.0475, 0.0397,
        0.0295, 0.0265], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,924][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.7844, 0.0081, 0.0146, 0.0085, 0.0291, 0.0149, 0.0232, 0.0130, 0.0476,
        0.0416, 0.0151], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,927][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0060, 0.1736, 0.0462, 0.1991, 0.0167, 0.0317, 0.2454, 0.0468, 0.0341,
        0.1965, 0.0038], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,928][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3699, 0.1080, 0.0644, 0.0836, 0.0865, 0.0643, 0.0243, 0.0354, 0.0510,
        0.0729, 0.0398], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,930][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0583, 0.0087, 0.0701, 0.0028, 0.1422, 0.0625, 0.0478, 0.0098, 0.2083,
        0.1589, 0.2305], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:45,931][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0389, 0.0907, 0.1017, 0.0763, 0.1085, 0.0982, 0.0847, 0.0728, 0.0788,
        0.0847, 0.0761, 0.0886], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,932][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ school] are: tensor([7.0693e-02, 2.9067e-04, 2.4136e-03, 1.0617e-05, 2.0932e-03, 4.9171e-04,
        8.5234e-04, 3.4087e-05, 1.4172e-03, 6.9444e-04, 1.9126e-03, 9.1910e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,933][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0396, 0.1065, 0.1023, 0.0948, 0.0982, 0.0760, 0.0777, 0.0712, 0.0818,
        0.0804, 0.0751, 0.0963], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,933][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0054, 0.0958, 0.0905, 0.0865, 0.0918, 0.0851, 0.0942, 0.0949, 0.0843,
        0.0917, 0.0866, 0.0931], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,934][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0187, 0.1000, 0.0769, 0.0979, 0.0984, 0.1196, 0.0764, 0.0867, 0.0559,
        0.0791, 0.0841, 0.1063], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,936][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0688, 0.0113, 0.0921, 0.0277, 0.0884, 0.0825, 0.0584, 0.0749, 0.0610,
        0.0407, 0.0789, 0.3153], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,938][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.1324, 0.0207, 0.0422, 0.0153, 0.0594, 0.0375, 0.0332, 0.0121, 0.0102,
        0.1172, 0.0673, 0.4526], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,940][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.4395, 0.0973, 0.1018, 0.0283, 0.0632, 0.0313, 0.0776, 0.0338, 0.0272,
        0.0170, 0.0209, 0.0620], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,942][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.9611, 0.0013, 0.0018, 0.0013, 0.0034, 0.0022, 0.0033, 0.0021, 0.0060,
        0.0055, 0.0027, 0.0094], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,944][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0024, 0.0726, 0.0182, 0.0649, 0.0534, 0.0805, 0.0317, 0.1233, 0.0751,
        0.3011, 0.1752, 0.0016], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,946][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.1597, 0.1114, 0.0839, 0.0782, 0.1126, 0.0694, 0.0276, 0.0366, 0.0574,
        0.0794, 0.0477, 0.1360], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,947][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ school] are: tensor([1.3039e-02, 3.6126e-04, 4.1803e-03, 4.9060e-05, 4.4806e-03, 4.6269e-03,
        2.2951e-03, 3.0334e-04, 6.4786e-03, 5.0333e-03, 2.0002e-02, 9.3915e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:45,948][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0277, 0.0801, 0.0952, 0.0652, 0.1039, 0.0889, 0.0794, 0.0700, 0.0783,
        0.0736, 0.0714, 0.0879, 0.0782], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,949][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.0322e-04, 3.7501e-04, 4.8239e-04, 2.2152e-05, 2.3191e-03, 1.6814e-04,
        8.8572e-04, 5.7168e-05, 1.1884e-03, 5.0831e-04, 1.6265e-03, 9.9168e-01,
        4.8410e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,950][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0338, 0.0988, 0.0937, 0.0887, 0.0897, 0.0704, 0.0728, 0.0664, 0.0765,
        0.0743, 0.0697, 0.0899, 0.0754], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,950][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0057, 0.0862, 0.0847, 0.0791, 0.0834, 0.0792, 0.0865, 0.0866, 0.0780,
        0.0833, 0.0796, 0.0861, 0.0818], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,951][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0159, 0.0914, 0.0704, 0.0908, 0.0858, 0.0998, 0.0672, 0.0770, 0.0525,
        0.0747, 0.0806, 0.0987, 0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,953][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0189, 0.0123, 0.0601, 0.0318, 0.0902, 0.0718, 0.0956, 0.0258, 0.0803,
        0.0418, 0.0681, 0.3591, 0.0442], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,955][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1498, 0.0092, 0.0234, 0.0164, 0.0599, 0.0491, 0.0221, 0.0151, 0.0066,
        0.0893, 0.0735, 0.1535, 0.3321], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,957][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.3110, 0.0841, 0.1108, 0.0316, 0.0717, 0.0480, 0.0871, 0.0442, 0.0386,
        0.0273, 0.0331, 0.0706, 0.0418], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,959][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.7523, 0.0081, 0.0117, 0.0068, 0.0232, 0.0141, 0.0183, 0.0119, 0.0374,
        0.0312, 0.0138, 0.0600, 0.0112], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,961][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0063, 0.0072, 0.1317, 0.0064, 0.0792, 0.0688, 0.4396, 0.0473, 0.0964,
        0.0347, 0.0569, 0.0211, 0.0046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,963][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2015, 0.1075, 0.0786, 0.0786, 0.1058, 0.0555, 0.0206, 0.0279, 0.0425,
        0.0682, 0.0341, 0.0907, 0.0885], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,964][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([3.3715e-03, 1.1359e-03, 5.1516e-03, 4.4269e-04, 9.2821e-03, 4.5614e-03,
        5.0406e-03, 1.2311e-03, 1.5962e-02, 1.5455e-02, 3.2593e-02, 8.9218e-01,
        1.3596e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:45,965][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0326, 0.0742, 0.0854, 0.0646, 0.0884, 0.0829, 0.0731, 0.0619, 0.0637,
        0.0688, 0.0662, 0.0731, 0.0785, 0.0864], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,966][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([2.8385e-02, 2.6535e-04, 1.6168e-03, 7.6366e-06, 1.2757e-03, 3.8704e-04,
        7.4301e-04, 2.3337e-05, 6.7259e-04, 2.0874e-04, 8.5568e-04, 4.6971e-01,
        2.9642e-04, 4.9555e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,967][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0367, 0.0928, 0.0877, 0.0809, 0.0833, 0.0651, 0.0669, 0.0616, 0.0700,
        0.0686, 0.0643, 0.0825, 0.0697, 0.0700], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,967][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0047, 0.0798, 0.0778, 0.0738, 0.0776, 0.0733, 0.0796, 0.0803, 0.0726,
        0.0761, 0.0727, 0.0796, 0.0774, 0.0746], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,968][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0135, 0.0830, 0.0647, 0.0835, 0.0812, 0.1003, 0.0660, 0.0709, 0.0458,
        0.0617, 0.0686, 0.0941, 0.0877, 0.0790], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,970][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0215, 0.0049, 0.0541, 0.0297, 0.0593, 0.0456, 0.0427, 0.0312, 0.0345,
        0.0285, 0.0477, 0.3733, 0.0460, 0.1810], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,972][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.1537, 0.0140, 0.0446, 0.0128, 0.0794, 0.0322, 0.0150, 0.0110, 0.0062,
        0.0796, 0.0655, 0.1142, 0.1980, 0.1738], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,974][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.3180, 0.1021, 0.1053, 0.0407, 0.0628, 0.0295, 0.0694, 0.0360, 0.0271,
        0.0219, 0.0186, 0.0603, 0.0456, 0.0627], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,975][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([9.6428e-01, 7.8642e-04, 1.0636e-03, 7.1156e-04, 1.8504e-03, 1.4079e-03,
        2.0879e-03, 1.1987e-03, 4.4192e-03, 3.9231e-03, 1.5120e-03, 8.2122e-03,
        1.4346e-03, 7.1150e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,977][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([2.0122e-03, 8.4066e-02, 2.6479e-02, 4.4161e-02, 5.8633e-05, 9.9979e-02,
        1.2595e-01, 1.9675e-01, 1.5917e-01, 5.8473e-02, 6.4206e-02, 2.8838e-02,
        1.0978e-01, 7.5445e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,979][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.1964, 0.0973, 0.0766, 0.0635, 0.1057, 0.0516, 0.0197, 0.0258, 0.0412,
        0.0628, 0.0309, 0.0887, 0.0758, 0.0640], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,980][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([1.2361e-02, 2.7939e-04, 3.1070e-03, 4.6272e-05, 2.4278e-03, 3.7865e-03,
        1.5927e-03, 2.7070e-04, 3.8277e-03, 2.7065e-03, 9.0199e-03, 3.4032e-01,
        9.5111e-03, 6.1074e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:45,982][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0344, 0.0665, 0.0838, 0.0574, 0.0880, 0.0786, 0.0623, 0.0572, 0.0595,
        0.0611, 0.0644, 0.0720, 0.0674, 0.0864, 0.0608], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,983][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([5.2875e-03, 1.6183e-04, 3.4353e-04, 4.4915e-06, 8.3403e-04, 1.7578e-04,
        3.5830e-04, 1.6647e-05, 2.2219e-04, 1.6693e-04, 3.9489e-04, 5.2354e-01,
        2.0000e-04, 3.6357e-01, 1.0472e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,984][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0341, 0.0887, 0.0840, 0.0781, 0.0788, 0.0614, 0.0636, 0.0581, 0.0664,
        0.0649, 0.0606, 0.0777, 0.0658, 0.0641, 0.0538], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,985][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0063, 0.0750, 0.0705, 0.0702, 0.0699, 0.0674, 0.0731, 0.0746, 0.0666,
        0.0730, 0.0701, 0.0734, 0.0701, 0.0682, 0.0715], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,985][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0115, 0.0805, 0.0584, 0.0766, 0.0746, 0.0974, 0.0594, 0.0718, 0.0456,
        0.0622, 0.0674, 0.0919, 0.0825, 0.0743, 0.0459], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,987][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0121, 0.0084, 0.0371, 0.0240, 0.0542, 0.0610, 0.0607, 0.0288, 0.0316,
        0.0282, 0.0602, 0.3241, 0.0494, 0.1636, 0.0564], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,989][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0364, 0.0143, 0.0170, 0.0134, 0.0320, 0.0512, 0.0324, 0.0142, 0.0120,
        0.1156, 0.0648, 0.1794, 0.2357, 0.0674, 0.1143], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,991][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.2541, 0.1049, 0.0912, 0.0371, 0.0540, 0.0377, 0.0741, 0.0381, 0.0326,
        0.0263, 0.0318, 0.0804, 0.0406, 0.0514, 0.0458], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,993][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.9281, 0.0018, 0.0023, 0.0017, 0.0041, 0.0025, 0.0038, 0.0023, 0.0067,
        0.0063, 0.0028, 0.0110, 0.0028, 0.0110, 0.0130], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,995][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0022, 0.0711, 0.0503, 0.1063, 0.1912, 0.0094, 0.0440, 0.0112, 0.0015,
        0.0482, 0.0449, 0.0747, 0.0574, 0.2871, 0.0005], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,997][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.2530, 0.0797, 0.0611, 0.0536, 0.0905, 0.0501, 0.0194, 0.0252, 0.0385,
        0.0517, 0.0292, 0.0834, 0.0740, 0.0642, 0.0264], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,998][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([7.8997e-03, 5.0886e-04, 3.3288e-03, 7.1414e-05, 2.9906e-03, 3.6333e-03,
        2.2206e-03, 2.8493e-04, 2.9558e-03, 3.2346e-03, 9.2697e-03, 2.2345e-01,
        1.0211e-02, 5.3376e-01, 1.9618e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:45,999][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0230, 0.0643, 0.0756, 0.0526, 0.0848, 0.0720, 0.0657, 0.0539, 0.0598,
        0.0560, 0.0566, 0.0703, 0.0642, 0.0828, 0.0638, 0.0549],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,000][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.9068e-04, 3.9687e-05, 3.8732e-04, 3.6095e-06, 9.9436e-04, 8.4497e-05,
        3.4083e-04, 6.8815e-06, 1.5402e-04, 7.9878e-05, 2.2917e-04, 5.1960e-01,
        9.3633e-05, 3.2200e-01, 1.5253e-01, 2.5709e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,001][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0335, 0.0822, 0.0781, 0.0732, 0.0735, 0.0590, 0.0612, 0.0560, 0.0636,
        0.0622, 0.0577, 0.0731, 0.0622, 0.0607, 0.0521, 0.0517],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,002][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0043, 0.0678, 0.0660, 0.0633, 0.0654, 0.0634, 0.0682, 0.0687, 0.0622,
        0.0660, 0.0645, 0.0697, 0.0667, 0.0654, 0.0696, 0.0688],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,003][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0087, 0.0767, 0.0563, 0.0758, 0.0729, 0.0922, 0.0549, 0.0617, 0.0423,
        0.0618, 0.0649, 0.0830, 0.0793, 0.0712, 0.0426, 0.0557],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,005][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0160, 0.0059, 0.0530, 0.0136, 0.0564, 0.0430, 0.0497, 0.0111, 0.0399,
        0.0177, 0.0358, 0.2889, 0.0337, 0.1993, 0.1053, 0.0307],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,007][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0378, 0.0035, 0.0118, 0.0100, 0.0250, 0.0222, 0.0167, 0.0102, 0.0047,
        0.1111, 0.0421, 0.1835, 0.1789, 0.0684, 0.0443, 0.2298],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,009][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3306, 0.0620, 0.1062, 0.0238, 0.0581, 0.0344, 0.0717, 0.0302, 0.0235,
        0.0161, 0.0254, 0.0604, 0.0292, 0.0613, 0.0526, 0.0144],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,010][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.8081, 0.0032, 0.0057, 0.0032, 0.0103, 0.0056, 0.0087, 0.0044, 0.0172,
        0.0126, 0.0053, 0.0278, 0.0055, 0.0301, 0.0362, 0.0162],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,012][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0179, 0.0220, 0.0820, 0.0076, 0.0586, 0.0664, 0.2020, 0.0207, 0.2026,
        0.0018, 0.1121, 0.0447, 0.0353, 0.0681, 0.0556, 0.0026],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,014][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2706, 0.0800, 0.0528, 0.0520, 0.0724, 0.0458, 0.0184, 0.0242, 0.0386,
        0.0556, 0.0302, 0.0667, 0.0659, 0.0552, 0.0241, 0.0477],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,015][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.8490e-03, 1.9547e-04, 2.8958e-03, 3.9234e-05, 3.2449e-03, 1.8821e-03,
        1.2219e-03, 1.8153e-04, 3.5688e-03, 1.7639e-03, 4.6037e-03, 2.2804e-01,
        3.7454e-03, 4.0437e-01, 3.0789e-01, 3.0503e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,016][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0288, 0.0607, 0.0690, 0.0521, 0.0728, 0.0698, 0.0574, 0.0505, 0.0531,
        0.0567, 0.0543, 0.0620, 0.0630, 0.0718, 0.0575, 0.0579, 0.0624],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,017][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([1.4182e-02, 1.9304e-04, 9.9697e-04, 5.9843e-06, 7.3499e-04, 3.0542e-04,
        7.4920e-04, 1.9959e-05, 4.1046e-04, 2.2984e-04, 7.4150e-04, 3.3297e-01,
        2.8680e-04, 2.6860e-01, 1.3995e-01, 4.6238e-03, 2.3501e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,018][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0312, 0.0786, 0.0745, 0.0701, 0.0703, 0.0561, 0.0581, 0.0532, 0.0603,
        0.0589, 0.0545, 0.0686, 0.0589, 0.0577, 0.0493, 0.0491, 0.0507],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,019][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0044, 0.0640, 0.0613, 0.0605, 0.0602, 0.0602, 0.0642, 0.0647, 0.0571,
        0.0626, 0.0608, 0.0649, 0.0621, 0.0589, 0.0635, 0.0656, 0.0651],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,020][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0100, 0.0728, 0.0540, 0.0673, 0.0688, 0.0830, 0.0535, 0.0588, 0.0401,
        0.0556, 0.0608, 0.0777, 0.0749, 0.0668, 0.0424, 0.0509, 0.0626],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,022][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0214, 0.0119, 0.0384, 0.0380, 0.0356, 0.0549, 0.0327, 0.0241, 0.0215,
        0.0432, 0.0574, 0.2252, 0.0867, 0.1080, 0.0823, 0.0741, 0.0446],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,024][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0500, 0.0092, 0.0158, 0.0119, 0.0252, 0.0305, 0.0226, 0.0100, 0.0069,
        0.0928, 0.0430, 0.1494, 0.1615, 0.0641, 0.0607, 0.1919, 0.0544],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,026][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2925, 0.0724, 0.0886, 0.0276, 0.0535, 0.0368, 0.0600, 0.0318, 0.0254,
        0.0198, 0.0240, 0.0624, 0.0333, 0.0553, 0.0513, 0.0176, 0.0476],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,027][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.9158, 0.0011, 0.0018, 0.0011, 0.0030, 0.0019, 0.0033, 0.0017, 0.0056,
        0.0047, 0.0021, 0.0100, 0.0019, 0.0080, 0.0112, 0.0058, 0.0208],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,029][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0045, 0.0576, 0.2238, 0.0519, 0.0058, 0.0346, 0.0628, 0.1040, 0.0575,
        0.0634, 0.0978, 0.0309, 0.1152, 0.0091, 0.0077, 0.0728, 0.0005],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,031][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.2677, 0.0687, 0.0530, 0.0469, 0.0763, 0.0454, 0.0180, 0.0239, 0.0371,
        0.0515, 0.0282, 0.0740, 0.0627, 0.0531, 0.0243, 0.0444, 0.0249],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,033][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([4.7373e-03, 3.4294e-04, 2.3200e-03, 3.2401e-05, 2.8042e-03, 3.1045e-03,
        1.8116e-03, 1.9546e-04, 2.3214e-03, 2.1194e-03, 5.7964e-03, 2.0176e-01,
        4.3900e-03, 3.7691e-01, 2.4400e-01, 3.2974e-02, 1.1438e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,033][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0239, 0.0569, 0.0669, 0.0491, 0.0708, 0.0632, 0.0558, 0.0498, 0.0533,
        0.0519, 0.0485, 0.0609, 0.0576, 0.0690, 0.0575, 0.0522, 0.0620, 0.0507],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,034][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.1427e-03, 1.6088e-04, 1.1811e-03, 1.2915e-05, 1.4799e-03, 2.3500e-04,
        8.5245e-04, 2.9615e-05, 5.7408e-04, 2.2884e-04, 7.3414e-04, 4.0048e-01,
        2.9636e-04, 2.7613e-01, 1.2711e-01, 4.7919e-03, 1.7194e-01, 8.6241e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,035][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0301, 0.0755, 0.0706, 0.0670, 0.0672, 0.0537, 0.0555, 0.0510, 0.0577,
        0.0564, 0.0520, 0.0662, 0.0566, 0.0550, 0.0469, 0.0468, 0.0482, 0.0436],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,036][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0039, 0.0591, 0.0596, 0.0561, 0.0579, 0.0555, 0.0605, 0.0599, 0.0550,
        0.0577, 0.0560, 0.0631, 0.0586, 0.0580, 0.0611, 0.0602, 0.0631, 0.0545],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,037][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0097, 0.0685, 0.0504, 0.0669, 0.0632, 0.0777, 0.0472, 0.0547, 0.0362,
        0.0541, 0.0549, 0.0717, 0.0719, 0.0642, 0.0406, 0.0501, 0.0596, 0.0584],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,040][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0142, 0.0116, 0.0431, 0.0165, 0.0619, 0.0396, 0.0411, 0.0195, 0.0308,
        0.0274, 0.0391, 0.2476, 0.0432, 0.1621, 0.0950, 0.0426, 0.0333, 0.0314],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,041][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0302, 0.0076, 0.0141, 0.0120, 0.0267, 0.0251, 0.0158, 0.0090, 0.0039,
        0.0681, 0.0456, 0.1990, 0.1719, 0.0530, 0.0374, 0.1519, 0.0249, 0.1037],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,043][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2622, 0.0709, 0.0870, 0.0269, 0.0559, 0.0328, 0.0632, 0.0347, 0.0246,
        0.0192, 0.0199, 0.0580, 0.0320, 0.0605, 0.0612, 0.0174, 0.0549, 0.0188],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,045][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5940, 0.0047, 0.0090, 0.0051, 0.0159, 0.0079, 0.0131, 0.0065, 0.0238,
        0.0215, 0.0069, 0.0432, 0.0080, 0.0403, 0.0468, 0.0264, 0.1037, 0.0234],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,047][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0014, 0.1935, 0.0364, 0.2730, 0.0108, 0.0435, 0.1399, 0.0248, 0.0107,
        0.0398, 0.0075, 0.0307, 0.0834, 0.0122, 0.0081, 0.0644, 0.0190, 0.0009],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,049][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2543, 0.0752, 0.0537, 0.0520, 0.0740, 0.0460, 0.0182, 0.0244, 0.0368,
        0.0496, 0.0277, 0.0699, 0.0636, 0.0504, 0.0225, 0.0409, 0.0230, 0.0180],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,051][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([7.3951e-03, 4.1112e-04, 3.7589e-03, 7.8860e-05, 4.2027e-03, 3.7011e-03,
        2.0532e-03, 3.8648e-04, 4.0432e-03, 3.2451e-03, 4.8666e-03, 1.7210e-01,
        5.5558e-03, 2.8837e-01, 2.2151e-01, 3.9275e-02, 1.7002e-01, 6.9034e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,051][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0304, 0.0534, 0.0654, 0.0458, 0.0671, 0.0620, 0.0515, 0.0483, 0.0464,
        0.0514, 0.0493, 0.0540, 0.0547, 0.0661, 0.0499, 0.0515, 0.0545, 0.0516,
        0.0466], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,052][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.2299e-02, 3.1522e-05, 4.1214e-04, 9.5931e-07, 3.7430e-04, 5.5562e-05,
        1.2960e-04, 5.8241e-06, 1.7048e-04, 5.9862e-05, 1.1649e-04, 7.8931e-02,
        5.0253e-05, 1.3169e-01, 3.3382e-02, 1.1260e-03, 6.3558e-02, 5.8589e-03,
        6.7175e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,053][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0284, 0.0741, 0.0702, 0.0657, 0.0661, 0.0514, 0.0526, 0.0484, 0.0551,
        0.0537, 0.0494, 0.0643, 0.0536, 0.0537, 0.0445, 0.0444, 0.0456, 0.0409,
        0.0380], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,054][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0039, 0.0563, 0.0547, 0.0529, 0.0561, 0.0523, 0.0586, 0.0580, 0.0507,
        0.0549, 0.0530, 0.0585, 0.0541, 0.0551, 0.0565, 0.0576, 0.0597, 0.0537,
        0.0534], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,056][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0102, 0.0660, 0.0487, 0.0608, 0.0625, 0.0781, 0.0458, 0.0538, 0.0325,
        0.0474, 0.0517, 0.0765, 0.0672, 0.0608, 0.0356, 0.0446, 0.0551, 0.0564,
        0.0461], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,058][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0093, 0.0080, 0.0466, 0.0236, 0.0412, 0.0437, 0.0322, 0.0245, 0.0248,
        0.0318, 0.0302, 0.2187, 0.0450, 0.1262, 0.0842, 0.0520, 0.0484, 0.0370,
        0.0725], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,060][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0774, 0.0140, 0.0269, 0.0110, 0.0307, 0.0213, 0.0167, 0.0078, 0.0042,
        0.0476, 0.0370, 0.1232, 0.1325, 0.0719, 0.0242, 0.1047, 0.0249, 0.0674,
        0.1564], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,062][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.4198, 0.0457, 0.0716, 0.0173, 0.0439, 0.0285, 0.0529, 0.0280, 0.0230,
        0.0124, 0.0148, 0.0489, 0.0210, 0.0442, 0.0379, 0.0111, 0.0386, 0.0184,
        0.0222], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,064][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([9.5527e-01, 4.9272e-04, 7.2538e-04, 4.9136e-04, 1.2075e-03, 9.0047e-04,
        1.4310e-03, 8.0305e-04, 2.4019e-03, 2.1034e-03, 9.4506e-04, 3.5733e-03,
        8.6209e-04, 3.3573e-03, 4.7450e-03, 2.6454e-03, 9.2813e-03, 2.7779e-03,
        5.9891e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,065][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([3.1877e-04, 5.5636e-02, 8.9862e-03, 5.6174e-02, 7.6712e-03, 5.8380e-02,
        8.3108e-02, 1.2887e-01, 1.5882e-02, 1.1573e-01, 3.4485e-02, 8.4667e-03,
        3.4198e-02, 7.2618e-03, 5.7109e-02, 1.4480e-01, 1.5682e-01, 2.5977e-02,
        1.3056e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,067][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.2483, 0.0713, 0.0694, 0.0499, 0.1046, 0.0406, 0.0160, 0.0208, 0.0307,
        0.0474, 0.0227, 0.0736, 0.0549, 0.0524, 0.0178, 0.0346, 0.0186, 0.0132,
        0.0132], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,068][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([5.7063e-03, 8.8428e-05, 1.4289e-03, 9.1489e-06, 1.1178e-03, 1.0586e-03,
        6.6258e-04, 7.8446e-05, 8.8382e-04, 7.0389e-04, 2.1830e-03, 6.6550e-02,
        1.9155e-03, 1.5104e-01, 8.1292e-02, 1.0460e-02, 5.5253e-02, 4.1103e-02,
        5.7846e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,069][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0197, 0.0511, 0.0590, 0.0427, 0.0652, 0.0570, 0.0530, 0.0447, 0.0481,
        0.0445, 0.0452, 0.0562, 0.0504, 0.0632, 0.0520, 0.0438, 0.0574, 0.0486,
        0.0531, 0.0452], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,070][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5939e-03, 1.6133e-05, 2.4316e-04, 1.4739e-06, 3.6847e-04, 4.8364e-05,
        1.8120e-04, 3.6647e-06, 6.7497e-05, 2.5970e-05, 6.7313e-05, 9.2262e-02,
        3.0581e-05, 6.0393e-02, 2.6919e-02, 4.7995e-04, 3.6275e-02, 2.8537e-03,
        7.7258e-01, 5.5866e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,071][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0289, 0.0701, 0.0666, 0.0621, 0.0634, 0.0493, 0.0507, 0.0465, 0.0528,
        0.0512, 0.0472, 0.0613, 0.0512, 0.0512, 0.0429, 0.0422, 0.0437, 0.0393,
        0.0374, 0.0419], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,072][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0032, 0.0533, 0.0522, 0.0500, 0.0517, 0.0499, 0.0538, 0.0541, 0.0491,
        0.0521, 0.0508, 0.0552, 0.0527, 0.0518, 0.0549, 0.0542, 0.0563, 0.0503,
        0.0507, 0.0536], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,075][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0069, 0.0604, 0.0457, 0.0610, 0.0581, 0.0708, 0.0432, 0.0485, 0.0334,
        0.0487, 0.0513, 0.0646, 0.0633, 0.0569, 0.0341, 0.0445, 0.0534, 0.0523,
        0.0414, 0.0614], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,076][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0170, 0.0047, 0.0450, 0.0102, 0.0466, 0.0356, 0.0375, 0.0083, 0.0286,
        0.0122, 0.0261, 0.1883, 0.0258, 0.1406, 0.0722, 0.0201, 0.0361, 0.0432,
        0.1635, 0.0385], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,078][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0220, 0.0029, 0.0090, 0.0063, 0.0167, 0.0144, 0.0123, 0.0071, 0.0034,
        0.0782, 0.0259, 0.1480, 0.1015, 0.0438, 0.0327, 0.1726, 0.0208, 0.0650,
        0.0784, 0.1391], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,080][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3003, 0.0514, 0.0901, 0.0203, 0.0496, 0.0305, 0.0625, 0.0263, 0.0205,
        0.0135, 0.0224, 0.0508, 0.0252, 0.0510, 0.0449, 0.0118, 0.0580, 0.0240,
        0.0347, 0.0122], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,082][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7362, 0.0024, 0.0046, 0.0024, 0.0081, 0.0041, 0.0070, 0.0032, 0.0124,
        0.0087, 0.0034, 0.0200, 0.0037, 0.0201, 0.0250, 0.0105, 0.0532, 0.0120,
        0.0409, 0.0221], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,084][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0133, 0.0163, 0.0639, 0.0053, 0.0543, 0.0504, 0.1521, 0.0158, 0.1612,
        0.0014, 0.0809, 0.0362, 0.0258, 0.0631, 0.0403, 0.0021, 0.0984, 0.0332,
        0.0838, 0.0023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,085][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2700, 0.0720, 0.0532, 0.0494, 0.0733, 0.0378, 0.0159, 0.0216, 0.0336,
        0.0507, 0.0235, 0.0592, 0.0592, 0.0459, 0.0184, 0.0376, 0.0193, 0.0147,
        0.0123, 0.0325], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,086][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.3445e-02, 1.6525e-04, 2.5494e-03, 2.7888e-05, 1.8626e-03, 1.9251e-03,
        9.8312e-04, 1.8000e-04, 1.8046e-03, 9.7100e-04, 2.3130e-03, 5.6264e-02,
        2.4133e-03, 1.1823e-01, 1.0993e-01, 1.1690e-02, 6.6145e-02, 4.6087e-02,
        4.5476e-01, 1.0825e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,156][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:46,157][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,157][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,158][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,159][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,159][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,161][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,162][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,163][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,164][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,166][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,168][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,169][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,171][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4940, 0.5060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,171][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2477, 0.7523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,172][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8961, 0.1039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,173][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8907, 0.1093], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,173][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9954, 0.0046], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,174][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3057, 0.6943], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,175][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9968, 0.0032], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,177][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6140, 0.3860], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,179][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7702, 0.2298], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,180][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2739, 0.7261], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,182][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9546, 0.0454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,184][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,186][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3273, 0.4794, 0.1934], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,188][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.3044, 0.4266, 0.2691], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,189][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.3648, 0.3630, 0.2723], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,190][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.6782, 0.1419, 0.1799], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,191][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.9342, 0.0509, 0.0149], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,191][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.1521, 0.4875, 0.3604], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,192][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.9835, 0.0036, 0.0129], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,193][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.4772, 0.3304, 0.1924], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,194][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.6597, 0.2638, 0.0765], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,196][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0812, 0.7455, 0.1733], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,198][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.6141, 0.2391, 0.1468], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,199][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0706, 0.6087, 0.3207], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,201][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2600, 0.3497, 0.3355, 0.0548], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,203][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0467, 0.4789, 0.3585, 0.1159], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,204][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6689, 0.1487, 0.1585, 0.0238], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,206][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7044, 0.1142, 0.1497, 0.0316], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,207][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9625, 0.0232, 0.0064, 0.0079], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,208][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1419, 0.4211, 0.3012, 0.1358], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,209][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9466e-01, 1.4715e-03, 2.9017e-03, 9.6975e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,209][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3818, 0.2901, 0.2053, 0.1228], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,210][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4677, 0.2348, 0.2574, 0.0401], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,211][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0705, 0.3730, 0.1930, 0.3635], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,213][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7892, 0.1172, 0.0529, 0.0407], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,215][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0501, 0.3843, 0.4905, 0.0751], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,216][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.2772, 0.1945, 0.1360, 0.0290, 0.3633], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,218][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.2451, 0.1470, 0.2454, 0.0326, 0.3299], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,220][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.4613, 0.2152, 0.1814, 0.0372, 0.1049], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,222][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.7303, 0.0672, 0.1079, 0.0198, 0.0747], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,224][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.9228, 0.0395, 0.0163, 0.0103, 0.0112], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,226][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.1552, 0.1576, 0.2178, 0.0457, 0.4237], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,226][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([9.9101e-01, 1.0465e-03, 4.3086e-03, 3.7652e-04, 3.2618e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,227][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.3902, 0.1692, 0.1872, 0.0486, 0.2049], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,228][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.7587, 0.0414, 0.0749, 0.0069, 0.1180], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,228][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.2848, 0.2053, 0.1160, 0.3747, 0.0192], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,229][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.5876, 0.1567, 0.0945, 0.0891, 0.0721], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,231][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.1105, 0.1644, 0.3156, 0.0208, 0.3886], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,233][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1415, 0.1796, 0.1231, 0.0309, 0.3263, 0.1986], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,235][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0805, 0.2321, 0.0854, 0.0511, 0.3473, 0.2036], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,236][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.4972, 0.1550, 0.1691, 0.0307, 0.0985, 0.0495], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,238][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.5642, 0.0900, 0.1285, 0.0271, 0.1050, 0.0851], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,240][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.8933, 0.0346, 0.0166, 0.0108, 0.0182, 0.0265], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,242][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0997, 0.1928, 0.1232, 0.0599, 0.2791, 0.2453], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,243][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.9815, 0.0021, 0.0056, 0.0010, 0.0037, 0.0061], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,244][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.2932, 0.1251, 0.1180, 0.0572, 0.1928, 0.2136], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,245][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.3872, 0.1353, 0.0892, 0.0231, 0.1909, 0.1743], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,246][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0205, 0.2843, 0.0816, 0.3285, 0.1542, 0.1308], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,246][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.5383, 0.1769, 0.0906, 0.0638, 0.0736, 0.0568], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,247][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0529, 0.1632, 0.1369, 0.0388, 0.4303, 0.1778], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,249][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0488, 0.1174, 0.0932, 0.0207, 0.3050, 0.2854, 0.1296],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,251][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0320, 0.1315, 0.1173, 0.0204, 0.3179, 0.1413, 0.2398],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,253][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.2433, 0.2127, 0.1712, 0.0417, 0.1226, 0.0905, 0.1179],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,255][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.2144, 0.1421, 0.1227, 0.0437, 0.1477, 0.2212, 0.1083],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,256][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.8082, 0.0508, 0.0182, 0.0235, 0.0188, 0.0456, 0.0347],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,258][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0328, 0.1740, 0.0866, 0.0433, 0.2040, 0.2650, 0.1943],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,260][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.9731, 0.0027, 0.0066, 0.0010, 0.0046, 0.0067, 0.0053],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,261][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0970, 0.1184, 0.0924, 0.0400, 0.1899, 0.2643, 0.1979],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,262][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0995, 0.1073, 0.0577, 0.0192, 0.2172, 0.2481, 0.2510],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,263][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0462, 0.2920, 0.0852, 0.2420, 0.0859, 0.1811, 0.0676],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,264][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.4356, 0.0895, 0.0883, 0.1006, 0.0680, 0.0957, 0.1223],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,265][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0120, 0.1497, 0.0845, 0.0228, 0.2712, 0.2495, 0.2103],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,266][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0378, 0.1162, 0.0714, 0.0351, 0.3483, 0.1830, 0.1484, 0.0599],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,268][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0248, 0.1050, 0.0781, 0.0412, 0.2382, 0.2194, 0.2528, 0.0405],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,270][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2878, 0.1581, 0.1701, 0.0376, 0.1036, 0.0637, 0.1297, 0.0495],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,271][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.2689, 0.0938, 0.1371, 0.0381, 0.1147, 0.1508, 0.1495, 0.0471],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,273][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.7782, 0.0511, 0.0320, 0.0153, 0.0271, 0.0388, 0.0372, 0.0202],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,275][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0319, 0.1283, 0.0838, 0.0439, 0.2479, 0.2000, 0.2078, 0.0564],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,276][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.9721, 0.0025, 0.0065, 0.0010, 0.0045, 0.0054, 0.0038, 0.0041],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,278][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.1205, 0.0899, 0.1105, 0.0375, 0.2191, 0.1671, 0.2064, 0.0491],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,279][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0865, 0.0781, 0.0696, 0.0306, 0.2602, 0.1986, 0.2329, 0.0435],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,280][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0441, 0.1723, 0.1908, 0.1851, 0.1162, 0.1537, 0.1006, 0.0372],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,281][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.3819, 0.1495, 0.0802, 0.0756, 0.0519, 0.0837, 0.0919, 0.0852],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,282][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0072, 0.1130, 0.1230, 0.0220, 0.4116, 0.1090, 0.1904, 0.0237],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,282][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0769, 0.0558, 0.0858, 0.0086, 0.2651, 0.2192, 0.0892, 0.0394, 0.1600],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,283][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.1495, 0.0420, 0.0996, 0.0122, 0.3078, 0.1392, 0.1378, 0.0248, 0.0871],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,285][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2996, 0.1529, 0.1445, 0.0312, 0.0890, 0.0800, 0.1096, 0.0482, 0.0449],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,287][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.3940, 0.0569, 0.1117, 0.0218, 0.0928, 0.1230, 0.0703, 0.0333, 0.0962],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,289][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.8695, 0.0293, 0.0176, 0.0081, 0.0157, 0.0186, 0.0181, 0.0151, 0.0080],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,291][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0608, 0.0559, 0.0749, 0.0171, 0.1936, 0.1712, 0.1627, 0.0406, 0.2232],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,292][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([9.7803e-01, 1.9007e-03, 4.4112e-03, 7.6135e-04, 3.1969e-03, 4.9398e-03,
        3.2627e-03, 1.9680e-03, 1.5282e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,294][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.1815, 0.0586, 0.0873, 0.0172, 0.1576, 0.1519, 0.1358, 0.0692, 0.1410],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,296][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.3124, 0.0265, 0.0596, 0.0050, 0.1640, 0.1253, 0.1518, 0.0334, 0.1221],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,298][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.1445, 0.1711, 0.0498, 0.1429, 0.1066, 0.0944, 0.1508, 0.1171, 0.0229],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,299][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.5145, 0.0612, 0.0577, 0.0440, 0.0354, 0.0645, 0.0925, 0.0718, 0.0585],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,299][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0171, 0.0401, 0.0912, 0.0063, 0.3159, 0.1852, 0.1393, 0.0202, 0.1847],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,300][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2356, 0.0273, 0.0653, 0.0064, 0.1809, 0.1187, 0.0626, 0.0224, 0.1277,
        0.1532], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,301][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1213, 0.0234, 0.0583, 0.0104, 0.2178, 0.1321, 0.1379, 0.0275, 0.0984,
        0.1729], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,302][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4571, 0.1076, 0.1305, 0.0191, 0.0608, 0.0416, 0.0706, 0.0267, 0.0327,
        0.0533], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,304][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5798, 0.0224, 0.0706, 0.0095, 0.0544, 0.0592, 0.0662, 0.0238, 0.0641,
        0.0500], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,306][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.9034, 0.0157, 0.0105, 0.0054, 0.0081, 0.0168, 0.0164, 0.0101, 0.0064,
        0.0073], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,308][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1284, 0.0371, 0.0636, 0.0135, 0.1363, 0.1202, 0.1141, 0.0297, 0.1867,
        0.1704], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,309][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8990e-01, 6.0141e-04, 1.9381e-03, 3.2378e-04, 1.5225e-03, 1.8041e-03,
        1.2528e-03, 9.8860e-04, 3.6977e-04, 1.2962e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,311][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2700, 0.0350, 0.0608, 0.0149, 0.0966, 0.1017, 0.0937, 0.0359, 0.1523,
        0.1391], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,313][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5738, 0.0054, 0.0276, 0.0018, 0.0682, 0.0506, 0.0528, 0.0103, 0.1302,
        0.0793], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,314][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2431, 0.0925, 0.1066, 0.0816, 0.0411, 0.1066, 0.0948, 0.0742, 0.1088,
        0.0507], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,316][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7396, 0.0416, 0.0303, 0.0193, 0.0154, 0.0239, 0.0397, 0.0318, 0.0413,
        0.0172], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,317][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0584, 0.0186, 0.1053, 0.0046, 0.2109, 0.0795, 0.0793, 0.0129, 0.2771,
        0.1534], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,317][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2272, 0.0126, 0.0573, 0.0051, 0.1684, 0.0814, 0.0287, 0.0176, 0.0839,
        0.1244, 0.1935], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,318][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1740, 0.0191, 0.0496, 0.0056, 0.1391, 0.0810, 0.0603, 0.0162, 0.0807,
        0.1396, 0.2348], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,319][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4051, 0.0879, 0.1231, 0.0200, 0.0641, 0.0349, 0.0769, 0.0296, 0.0359,
        0.0501, 0.0723], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,321][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.6394, 0.0187, 0.0517, 0.0069, 0.0391, 0.0455, 0.0381, 0.0169, 0.0439,
        0.0367, 0.0632], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,322][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8601, 0.0244, 0.0149, 0.0067, 0.0123, 0.0203, 0.0159, 0.0124, 0.0086,
        0.0100, 0.0144], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,324][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1491, 0.0234, 0.0515, 0.0094, 0.1043, 0.0861, 0.0610, 0.0208, 0.1233,
        0.1238, 0.2472], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,325][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.8615e-01, 9.4733e-04, 2.4278e-03, 3.5968e-04, 1.8697e-03, 2.4091e-03,
        1.5730e-03, 1.0087e-03, 4.8796e-04, 9.8661e-04, 1.7773e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,327][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2797, 0.0179, 0.0439, 0.0098, 0.0775, 0.0705, 0.0646, 0.0240, 0.1218,
        0.1275, 0.1626], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,329][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.5740, 0.0028, 0.0220, 0.0015, 0.0476, 0.0301, 0.0233, 0.0064, 0.0701,
        0.0905, 0.1317], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,331][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0388, 0.1941, 0.0742, 0.1637, 0.0469, 0.1029, 0.0961, 0.0713, 0.0880,
        0.0945, 0.0295], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,332][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.6115, 0.0664, 0.0423, 0.0248, 0.0278, 0.0325, 0.0499, 0.0421, 0.0471,
        0.0234, 0.0322], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,334][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0583, 0.0087, 0.0701, 0.0028, 0.1422, 0.0625, 0.0478, 0.0098, 0.2083,
        0.1589, 0.2305], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,335][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([1.2396e-01, 1.7218e-03, 9.5221e-03, 4.9693e-04, 1.9619e-02, 2.9091e-02,
        5.2291e-03, 2.6099e-03, 1.4371e-02, 2.1261e-02, 6.5236e-02, 7.0688e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,335][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([7.1684e-02, 6.5609e-04, 4.8168e-03, 1.7518e-04, 6.8054e-03, 9.3690e-03,
        3.0939e-03, 8.8020e-04, 7.9566e-03, 1.0440e-02, 2.9968e-02, 8.5415e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,336][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.3300, 0.0858, 0.1305, 0.0154, 0.0893, 0.0441, 0.0698, 0.0261, 0.0346,
        0.0363, 0.0640, 0.0740], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,337][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.6304, 0.0090, 0.0367, 0.0028, 0.0232, 0.0397, 0.0208, 0.0076, 0.0208,
        0.0212, 0.0474, 0.1403], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,339][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.8508, 0.0232, 0.0199, 0.0057, 0.0124, 0.0205, 0.0165, 0.0100, 0.0068,
        0.0082, 0.0124, 0.0137], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,340][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.0936, 0.0048, 0.0176, 0.0013, 0.0238, 0.0315, 0.0176, 0.0052, 0.0289,
        0.0278, 0.0747, 0.6732], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,341][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([9.8628e-01, 8.3776e-04, 2.7475e-03, 2.3494e-04, 1.7458e-03, 1.4793e-03,
        1.2951e-03, 7.4538e-04, 4.4798e-04, 8.1668e-04, 8.7139e-04, 2.4933e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,343][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.1909, 0.0057, 0.0164, 0.0015, 0.0196, 0.0360, 0.0166, 0.0056, 0.0236,
        0.0261, 0.0602, 0.5978], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,344][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([2.9715e-01, 1.4720e-04, 1.6539e-03, 4.3039e-05, 2.3844e-03, 3.6498e-03,
        1.9564e-03, 3.6409e-04, 3.3879e-03, 4.5504e-03, 1.6442e-02, 6.6827e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,347][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0314, 0.0782, 0.0558, 0.1340, 0.0404, 0.1215, 0.0851, 0.0889, 0.0943,
        0.1329, 0.1112, 0.0263], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,349][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.3238, 0.0722, 0.0475, 0.0469, 0.0388, 0.0526, 0.0789, 0.0673, 0.0786,
        0.0550, 0.0574, 0.0811], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,350][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([1.3039e-02, 3.6126e-04, 4.1803e-03, 4.9060e-05, 4.4806e-03, 4.6269e-03,
        2.2951e-03, 3.0334e-04, 6.4786e-03, 5.0333e-03, 2.0002e-02, 9.3915e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,352][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0406, 0.0042, 0.0126, 0.0015, 0.0291, 0.0190, 0.0084, 0.0049, 0.0180,
        0.0221, 0.0638, 0.7449, 0.0310], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,353][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([5.3074e-03, 1.9762e-03, 3.4692e-03, 5.9708e-04, 1.3677e-02, 6.0879e-03,
        7.2393e-03, 2.0334e-03, 9.1604e-03, 9.5622e-03, 2.7416e-02, 9.0099e-01,
        1.2483e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,353][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3651, 0.0827, 0.1118, 0.0177, 0.0545, 0.0333, 0.0604, 0.0246, 0.0305,
        0.0417, 0.0615, 0.0737, 0.0424], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,354][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.3462, 0.0184, 0.0491, 0.0084, 0.0385, 0.0486, 0.0411, 0.0201, 0.0520,
        0.0457, 0.0825, 0.1892, 0.0601], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,355][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.8010, 0.0226, 0.0219, 0.0089, 0.0170, 0.0257, 0.0166, 0.0109, 0.0093,
        0.0108, 0.0132, 0.0185, 0.0237], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,357][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0342, 0.0092, 0.0144, 0.0048, 0.0326, 0.0308, 0.0215, 0.0083, 0.0451,
        0.0497, 0.1010, 0.5818, 0.0667], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,358][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.7534e-01, 1.0024e-03, 2.9016e-03, 5.1474e-04, 2.8867e-03, 2.5924e-03,
        1.6949e-03, 1.2999e-03, 5.2471e-04, 1.4661e-03, 1.6089e-03, 2.6111e-03,
        5.5532e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,360][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0796, 0.0080, 0.0200, 0.0040, 0.0329, 0.0261, 0.0287, 0.0116, 0.0496,
        0.0462, 0.0733, 0.5756, 0.0446], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,361][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.0926e-02, 6.1712e-04, 2.3475e-03, 2.3585e-04, 4.3425e-03, 3.9407e-03,
        3.1510e-03, 1.0225e-03, 8.8652e-03, 1.0233e-02, 2.6999e-02, 8.9555e-01,
        1.1774e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,363][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0231, 0.1172, 0.0950, 0.1213, 0.0692, 0.0948, 0.0784, 0.0595, 0.0757,
        0.0694, 0.0551, 0.0747, 0.0665], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,365][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.4794, 0.0688, 0.0383, 0.0337, 0.0221, 0.0310, 0.0565, 0.0520, 0.0581,
        0.0297, 0.0524, 0.0364, 0.0415], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,366][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([3.3715e-03, 1.1359e-03, 5.1516e-03, 4.4269e-04, 9.2821e-03, 4.5614e-03,
        5.0406e-03, 1.2311e-03, 1.5962e-02, 1.5455e-02, 3.2593e-02, 8.9218e-01,
        1.3596e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,368][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([5.4916e-02, 1.0422e-03, 4.3540e-03, 2.0853e-04, 7.2302e-03, 9.7164e-03,
        2.4981e-03, 1.0851e-03, 3.3931e-03, 7.6732e-03, 2.0773e-02, 1.7844e-01,
        1.7504e-02, 6.9116e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,369][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([1.4257e-02, 4.7721e-04, 2.4390e-03, 9.4972e-05, 2.9813e-03, 4.6644e-03,
        2.3453e-03, 3.6965e-04, 2.5905e-03, 2.4406e-03, 1.0503e-02, 4.7931e-01,
        6.2072e-03, 4.7132e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,370][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1899, 0.0866, 0.1038, 0.0199, 0.0562, 0.0535, 0.0765, 0.0269, 0.0273,
        0.0431, 0.0593, 0.0993, 0.0564, 0.1011], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,371][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.3980, 0.0074, 0.0318, 0.0027, 0.0153, 0.0366, 0.0181, 0.0069, 0.0173,
        0.0175, 0.0336, 0.1102, 0.0447, 0.2599], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,372][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.6519, 0.0450, 0.0389, 0.0122, 0.0191, 0.0401, 0.0330, 0.0166, 0.0108,
        0.0157, 0.0201, 0.0284, 0.0380, 0.0303], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,373][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.0431, 0.0027, 0.0098, 0.0009, 0.0150, 0.0196, 0.0113, 0.0028, 0.0139,
        0.0140, 0.0297, 0.2862, 0.0326, 0.5185], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,373][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([9.5971e-01, 1.1949e-03, 5.4227e-03, 3.9516e-04, 4.2080e-03, 2.5743e-03,
        1.5102e-03, 1.3875e-03, 6.0702e-04, 1.1770e-03, 1.4220e-03, 2.6956e-03,
        5.0463e-03, 1.2648e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,375][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0904, 0.0045, 0.0153, 0.0015, 0.0134, 0.0271, 0.0143, 0.0057, 0.0178,
        0.0222, 0.0419, 0.3698, 0.0439, 0.3322], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,377][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([2.5457e-01, 1.2305e-04, 1.6909e-03, 2.7167e-05, 1.5491e-03, 2.3619e-03,
        1.2094e-03, 2.3109e-04, 1.9461e-03, 1.9183e-03, 4.6005e-03, 3.3855e-01,
        6.6237e-03, 3.8460e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,379][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0329, 0.0815, 0.0426, 0.1311, 0.0127, 0.0959, 0.0802, 0.0776, 0.1273,
        0.1058, 0.0627, 0.0722, 0.0648, 0.0127], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,381][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2162, 0.0755, 0.0378, 0.0451, 0.0309, 0.0563, 0.0810, 0.0689, 0.1143,
        0.0486, 0.0707, 0.0630, 0.0593, 0.0325], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,382][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([1.2361e-02, 2.7939e-04, 3.1070e-03, 4.6272e-05, 2.4278e-03, 3.7865e-03,
        1.5927e-03, 2.7070e-04, 3.8277e-03, 2.7065e-03, 9.0199e-03, 3.4032e-01,
        9.5111e-03, 6.1074e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,384][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([1.5817e-02, 7.1805e-04, 3.8865e-03, 1.3539e-04, 8.3884e-03, 5.4573e-03,
        1.6636e-03, 6.5971e-04, 2.3061e-03, 2.6594e-03, 1.0521e-02, 1.2576e-01,
        1.0427e-02, 6.5547e-01, 1.5613e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,385][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([8.0081e-03, 5.0284e-04, 9.2538e-04, 1.0028e-04, 2.4484e-03, 3.5115e-03,
        1.4484e-03, 4.4323e-04, 1.1569e-03, 2.4547e-03, 6.7096e-03, 4.4293e-01,
        5.3409e-03, 3.6782e-01, 1.5620e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,387][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1750, 0.1072, 0.0958, 0.0210, 0.0608, 0.0364, 0.0595, 0.0244, 0.0268,
        0.0410, 0.0653, 0.0745, 0.0504, 0.1026, 0.0594], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,388][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.2495, 0.0120, 0.0471, 0.0034, 0.0223, 0.0320, 0.0248, 0.0088, 0.0304,
        0.0242, 0.0482, 0.1093, 0.0436, 0.2465, 0.0982], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,389][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.7922, 0.0248, 0.0148, 0.0076, 0.0127, 0.0173, 0.0173, 0.0136, 0.0069,
        0.0125, 0.0144, 0.0132, 0.0204, 0.0187, 0.0136], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,390][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0231, 0.0044, 0.0086, 0.0011, 0.0131, 0.0203, 0.0122, 0.0026, 0.0131,
        0.0135, 0.0305, 0.2245, 0.0331, 0.3755, 0.2245], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,391][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([9.4760e-01, 2.0366e-03, 5.0842e-03, 6.3069e-04, 3.4371e-03, 4.5988e-03,
        3.0126e-03, 2.0274e-03, 1.1542e-03, 1.9718e-03, 2.1225e-03, 3.1713e-03,
        6.9651e-03, 1.1046e-02, 5.1425e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,392][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0432, 0.0034, 0.0090, 0.0012, 0.0132, 0.0204, 0.0146, 0.0047, 0.0187,
        0.0175, 0.0259, 0.2680, 0.0260, 0.3370, 0.1972], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,393][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([6.7020e-02, 1.8951e-04, 1.5858e-03, 3.7422e-05, 1.7892e-03, 2.1450e-03,
        1.3824e-03, 2.6379e-04, 1.5754e-03, 2.1637e-03, 5.2862e-03, 4.1108e-01,
        8.3212e-03, 3.6942e-01, 1.2774e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,395][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0315, 0.1337, 0.0505, 0.0892, 0.0663, 0.0642, 0.0487, 0.0386, 0.0242,
        0.0645, 0.0546, 0.0774, 0.1265, 0.1040, 0.0262], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,397][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.3350, 0.0673, 0.0456, 0.0382, 0.0275, 0.0342, 0.0575, 0.0482, 0.0816,
        0.0353, 0.0525, 0.0361, 0.0427, 0.0272, 0.0709], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,398][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([7.8997e-03, 5.0886e-04, 3.3288e-03, 7.1414e-05, 2.9906e-03, 3.6333e-03,
        2.2206e-03, 2.8493e-04, 2.9558e-03, 3.2346e-03, 9.2697e-03, 2.2345e-01,
        1.0211e-02, 5.3376e-01, 1.9618e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,400][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.8547e-02, 4.8999e-04, 3.6755e-03, 1.2007e-04, 5.7906e-03, 4.4854e-03,
        1.5903e-03, 5.7372e-04, 2.8580e-03, 3.6044e-03, 7.8662e-03, 1.6017e-01,
        6.0216e-03, 4.2909e-01, 2.8901e-01, 5.6100e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,401][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.4576e-03, 1.7691e-04, 1.1067e-03, 7.2096e-05, 2.8599e-03, 1.9516e-03,
        1.5887e-03, 2.6845e-04, 9.6662e-04, 1.4782e-03, 4.5673e-03, 3.7559e-01,
        3.2693e-03, 3.7502e-01, 2.0848e-01, 1.7140e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,403][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3575, 0.0630, 0.0931, 0.0137, 0.0422, 0.0306, 0.0448, 0.0153, 0.0188,
        0.0301, 0.0433, 0.0440, 0.0334, 0.0731, 0.0531, 0.0440],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,405][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4261, 0.0043, 0.0221, 0.0020, 0.0124, 0.0176, 0.0137, 0.0055, 0.0139,
        0.0105, 0.0250, 0.0830, 0.0205, 0.1819, 0.1151, 0.0463],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,407][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8221, 0.0138, 0.0124, 0.0055, 0.0080, 0.0160, 0.0163, 0.0093, 0.0063,
        0.0072, 0.0118, 0.0130, 0.0164, 0.0135, 0.0184, 0.0099],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,409][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0480, 0.0022, 0.0077, 0.0007, 0.0117, 0.0121, 0.0085, 0.0020, 0.0123,
        0.0101, 0.0217, 0.1950, 0.0203, 0.3248, 0.2529, 0.0700],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,411][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.7381e-01, 5.0376e-04, 2.2205e-03, 2.6888e-04, 1.7786e-03, 1.6516e-03,
        1.1698e-03, 1.0075e-03, 3.2815e-04, 1.0690e-03, 9.5637e-04, 1.8029e-03,
        3.4743e-03, 6.4121e-03, 1.7768e-03, 1.7731e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,412][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0846, 0.0026, 0.0087, 0.0011, 0.0114, 0.0139, 0.0104, 0.0036, 0.0140,
        0.0144, 0.0241, 0.2395, 0.0223, 0.2724, 0.2086, 0.0685],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,413][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.2101e-01, 7.1274e-05, 1.3321e-03, 2.3373e-05, 1.6843e-03, 1.4465e-03,
        1.0549e-03, 1.8127e-04, 2.2277e-03, 1.2142e-03, 3.8339e-03, 3.2169e-01,
        4.0749e-03, 3.3138e-01, 1.7676e-01, 3.2002e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,413][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1651, 0.0641, 0.0555, 0.0477, 0.0277, 0.0651, 0.0570, 0.0436, 0.0647,
        0.0319, 0.0435, 0.0595, 0.0850, 0.0383, 0.0987, 0.0524],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,414][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6150, 0.0419, 0.0263, 0.0180, 0.0121, 0.0208, 0.0388, 0.0280, 0.0417,
        0.0143, 0.0317, 0.0182, 0.0233, 0.0144, 0.0397, 0.0158],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,415][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.8490e-03, 1.9547e-04, 2.8958e-03, 3.9234e-05, 3.2449e-03, 1.8821e-03,
        1.2219e-03, 1.8153e-04, 3.5688e-03, 1.7639e-03, 4.6037e-03, 2.2804e-01,
        3.7454e-03, 4.0437e-01, 3.0789e-01, 3.0503e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,416][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.1876e-02, 5.8015e-04, 3.2207e-03, 1.0975e-04, 4.6163e-03, 5.1772e-03,
        1.8794e-03, 5.3509e-04, 2.6909e-03, 4.1732e-03, 6.2279e-03, 1.2988e-01,
        5.3137e-03, 3.1943e-01, 2.6797e-01, 5.7334e-02, 1.7899e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,418][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.1163e-02, 4.2246e-04, 1.6386e-03, 8.0945e-05, 1.9272e-03, 3.8468e-03,
        2.6383e-03, 4.0704e-04, 1.5742e-03, 2.4513e-03, 9.0030e-03, 2.5935e-01,
        6.3970e-03, 2.7713e-01, 2.0201e-01, 2.3864e-02, 1.9609e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,420][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.2429, 0.0646, 0.0978, 0.0141, 0.0539, 0.0359, 0.0551, 0.0187, 0.0221,
        0.0249, 0.0463, 0.0611, 0.0411, 0.0899, 0.0562, 0.0360, 0.0394],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,421][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.4006, 0.0070, 0.0280, 0.0022, 0.0118, 0.0234, 0.0151, 0.0051, 0.0152,
        0.0093, 0.0239, 0.0916, 0.0195, 0.1618, 0.0857, 0.0323, 0.0672],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,423][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.7810, 0.0210, 0.0210, 0.0057, 0.0125, 0.0194, 0.0167, 0.0104, 0.0062,
        0.0074, 0.0106, 0.0128, 0.0162, 0.0165, 0.0156, 0.0084, 0.0186],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,425][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0298, 0.0029, 0.0090, 0.0008, 0.0108, 0.0158, 0.0094, 0.0023, 0.0099,
        0.0098, 0.0196, 0.1587, 0.0225, 0.2830, 0.2136, 0.0646, 0.1378],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,426][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([9.5137e-01, 1.1784e-03, 4.3377e-03, 4.2656e-04, 2.8372e-03, 3.1543e-03,
        2.2061e-03, 1.4514e-03, 7.0958e-04, 1.3859e-03, 1.5244e-03, 2.8399e-03,
        5.2817e-03, 1.0278e-02, 3.5466e-03, 2.2109e-03, 5.2578e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,428][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0851, 0.0025, 0.0119, 0.0008, 0.0118, 0.0142, 0.0119, 0.0030, 0.0096,
        0.0125, 0.0177, 0.1699, 0.0190, 0.2620, 0.1881, 0.0524, 0.1276],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,429][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([7.6642e-02, 1.2362e-04, 1.6277e-03, 3.3049e-05, 1.3365e-03, 2.7870e-03,
        2.0116e-03, 2.2840e-04, 1.8050e-03, 2.0093e-03, 4.6514e-03, 3.1946e-01,
        5.0097e-03, 2.0259e-01, 1.5962e-01, 4.1664e-02, 1.7840e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,430][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0372, 0.0347, 0.1102, 0.0428, 0.0226, 0.0819, 0.0630, 0.0627, 0.0748,
        0.0686, 0.0639, 0.0538, 0.0576, 0.0490, 0.0508, 0.1051, 0.0212],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,431][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2945, 0.0623, 0.0422, 0.0307, 0.0298, 0.0369, 0.0645, 0.0549, 0.0677,
        0.0356, 0.0399, 0.0450, 0.0412, 0.0288, 0.0491, 0.0356, 0.0413],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,432][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([4.7373e-03, 3.4294e-04, 2.3200e-03, 3.2401e-05, 2.8042e-03, 3.1045e-03,
        1.8116e-03, 1.9546e-04, 2.3214e-03, 2.1194e-03, 5.7964e-03, 2.0176e-01,
        4.3900e-03, 3.7691e-01, 2.4400e-01, 3.2974e-02, 1.1438e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,433][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.0505e-02, 9.7620e-04, 5.5969e-03, 2.5937e-04, 8.8245e-03, 6.5044e-03,
        1.8931e-03, 1.1238e-03, 2.8185e-03, 5.2698e-03, 7.0358e-03, 1.0451e-01,
        9.1432e-03, 3.1920e-01, 1.9731e-01, 5.4678e-02, 1.6879e-01, 7.5557e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,435][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.7822e-02, 4.7717e-04, 2.4595e-03, 1.5612e-04, 3.6506e-03, 3.3860e-03,
        2.8874e-03, 6.1843e-04, 2.1841e-03, 2.6030e-03, 8.5788e-03, 2.6865e-01,
        6.5479e-03, 2.9510e-01, 1.7538e-01, 2.2455e-02, 1.4817e-01, 3.8872e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,437][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2653, 0.0671, 0.0896, 0.0151, 0.0435, 0.0279, 0.0500, 0.0192, 0.0197,
        0.0288, 0.0500, 0.0452, 0.0367, 0.0676, 0.0475, 0.0399, 0.0338, 0.0533],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,439][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4357, 0.0065, 0.0275, 0.0026, 0.0121, 0.0184, 0.0167, 0.0062, 0.0148,
        0.0119, 0.0219, 0.0563, 0.0190, 0.1164, 0.0700, 0.0412, 0.0775, 0.0453],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,440][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7153, 0.0234, 0.0181, 0.0074, 0.0131, 0.0211, 0.0162, 0.0124, 0.0084,
        0.0105, 0.0125, 0.0166, 0.0245, 0.0189, 0.0225, 0.0126, 0.0277, 0.0187],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,443][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0458, 0.0035, 0.0096, 0.0011, 0.0129, 0.0146, 0.0094, 0.0028, 0.0104,
        0.0113, 0.0197, 0.1398, 0.0234, 0.2155, 0.1787, 0.0627, 0.1373, 0.1014],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,444][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.6249e-01, 9.2358e-04, 2.6484e-03, 3.6470e-04, 2.1182e-03, 2.2955e-03,
        1.4616e-03, 1.1999e-03, 3.9160e-04, 1.0829e-03, 1.4001e-03, 2.4565e-03,
        4.4516e-03, 7.1601e-03, 1.9719e-03, 1.7664e-03, 2.5595e-03, 3.2609e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,446][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1099, 0.0025, 0.0096, 0.0010, 0.0113, 0.0129, 0.0110, 0.0034, 0.0135,
        0.0144, 0.0167, 0.1315, 0.0170, 0.1761, 0.1652, 0.0560, 0.1775, 0.0705],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,447][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.3621e-01, 1.7255e-04, 2.1100e-03, 5.4951e-05, 2.2562e-03, 2.0051e-03,
        1.6001e-03, 3.0584e-04, 2.0803e-03, 2.4968e-03, 3.7292e-03, 2.3623e-01,
        6.3693e-03, 2.0376e-01, 8.7855e-02, 4.1262e-02, 2.0608e-01, 6.5427e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,448][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0180, 0.1434, 0.0664, 0.1139, 0.0388, 0.0656, 0.0467, 0.0345, 0.0323,
        0.0381, 0.0245, 0.0539, 0.0739, 0.0354, 0.0619, 0.0723, 0.0598, 0.0206],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,449][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4078, 0.0649, 0.0360, 0.0251, 0.0205, 0.0282, 0.0429, 0.0390, 0.0476,
        0.0234, 0.0358, 0.0316, 0.0366, 0.0193, 0.0490, 0.0240, 0.0379, 0.0302],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,450][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.3951e-03, 4.1112e-04, 3.7589e-03, 7.8860e-05, 4.2027e-03, 3.7011e-03,
        2.0532e-03, 3.8648e-04, 4.0432e-03, 3.2451e-03, 4.8666e-03, 1.7210e-01,
        5.5558e-03, 2.8837e-01, 2.2151e-01, 3.9275e-02, 1.7002e-01, 6.9034e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,451][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([2.2033e-02, 2.4696e-04, 2.2064e-03, 5.9378e-05, 2.2952e-03, 3.5229e-03,
        8.0209e-04, 3.5597e-04, 1.1094e-03, 1.7913e-03, 5.0597e-03, 5.5249e-02,
        3.6809e-03, 1.5434e-01, 8.7176e-02, 2.2855e-02, 7.6949e-02, 5.9334e-02,
        5.0093e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,453][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([1.1046e-02, 1.3639e-04, 1.1900e-03, 2.7182e-05, 1.5348e-03, 1.3961e-03,
        7.0406e-04, 1.7443e-04, 1.0914e-03, 1.2073e-03, 2.6117e-03, 1.0057e-01,
        2.2472e-03, 1.8105e-01, 8.6385e-02, 1.0517e-02, 8.9696e-02, 4.0159e-02,
        4.6826e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,455][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1627, 0.0720, 0.0852, 0.0142, 0.0448, 0.0376, 0.0491, 0.0214, 0.0222,
        0.0250, 0.0489, 0.0519, 0.0377, 0.0808, 0.0600, 0.0368, 0.0415, 0.0582,
        0.0497], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,457][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.3490, 0.0048, 0.0167, 0.0014, 0.0079, 0.0181, 0.0111, 0.0042, 0.0093,
        0.0072, 0.0175, 0.0481, 0.0172, 0.1184, 0.0688, 0.0301, 0.0794, 0.0430,
        0.1479], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,458][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.7977, 0.0131, 0.0236, 0.0032, 0.0119, 0.0160, 0.0126, 0.0056, 0.0039,
        0.0059, 0.0060, 0.0166, 0.0133, 0.0142, 0.0127, 0.0060, 0.0138, 0.0104,
        0.0133], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,460][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.2828e-02, 1.3830e-03, 4.3525e-03, 3.6747e-04, 4.5781e-03, 1.0061e-02,
        4.8347e-03, 1.2036e-03, 5.0093e-03, 5.7659e-03, 1.0278e-02, 7.3517e-02,
        1.2328e-02, 1.2350e-01, 1.0619e-01, 3.5153e-02, 6.0096e-02, 6.6940e-02,
        4.5161e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,461][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([9.5837e-01, 9.1625e-04, 3.6712e-03, 3.2533e-04, 2.3011e-03, 2.0257e-03,
        1.3549e-03, 1.0049e-03, 4.6888e-04, 8.5964e-04, 1.1580e-03, 1.8988e-03,
        3.9631e-03, 7.9699e-03, 1.9805e-03, 1.3332e-03, 2.6992e-03, 2.1058e-03,
        5.5981e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,463][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0921, 0.0017, 0.0078, 0.0005, 0.0072, 0.0118, 0.0085, 0.0021, 0.0071,
        0.0061, 0.0106, 0.0947, 0.0118, 0.1482, 0.0987, 0.0262, 0.1058, 0.0594,
        0.2997], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,464][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([1.2855e-01, 4.3716e-05, 7.8961e-04, 1.0051e-05, 5.6106e-04, 1.1910e-03,
        7.4118e-04, 1.0261e-04, 5.5575e-04, 6.5015e-04, 1.7137e-03, 6.7326e-02,
        2.8266e-03, 9.5357e-02, 5.3687e-02, 1.3695e-02, 9.1172e-02, 5.4486e-02,
        4.8654e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,465][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0041, 0.0569, 0.0430, 0.0889, 0.0392, 0.0640, 0.0450, 0.0360, 0.0492,
        0.0642, 0.0520, 0.0581, 0.0713, 0.0334, 0.0478, 0.0901, 0.0817, 0.0581,
        0.0168], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,466][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.2000, 0.0578, 0.0363, 0.0297, 0.0318, 0.0395, 0.0604, 0.0445, 0.0616,
        0.0359, 0.0431, 0.0446, 0.0440, 0.0287, 0.0579, 0.0344, 0.0462, 0.0461,
        0.0573], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,467][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([5.7063e-03, 8.8428e-05, 1.4289e-03, 9.1489e-06, 1.1178e-03, 1.0586e-03,
        6.6258e-04, 7.8446e-05, 8.8382e-04, 7.0389e-04, 2.1830e-03, 6.6550e-02,
        1.9155e-03, 1.5104e-01, 8.1292e-02, 1.0460e-02, 5.5253e-02, 4.1103e-02,
        5.7846e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,468][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.5291e-02, 3.4872e-04, 2.8586e-03, 7.7054e-05, 2.9564e-03, 3.6712e-03,
        9.6342e-04, 4.4380e-04, 1.3486e-03, 1.7179e-03, 3.6102e-03, 3.7046e-02,
        3.5506e-03, 1.1844e-01, 8.6189e-02, 1.8924e-02, 8.1855e-02, 5.5889e-02,
        4.1447e-01, 1.2035e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,469][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.1624e-02, 1.2802e-04, 9.6234e-04, 4.7733e-05, 1.5221e-03, 1.6242e-03,
        1.2949e-03, 2.1689e-04, 5.8628e-04, 7.4019e-04, 2.1513e-03, 1.1878e-01,
        2.0013e-03, 1.1498e-01, 6.9897e-02, 5.9185e-03, 5.4002e-02, 2.7394e-02,
        5.4226e-01, 4.3868e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,471][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3017, 0.0537, 0.0760, 0.0120, 0.0361, 0.0284, 0.0406, 0.0135, 0.0161,
        0.0241, 0.0352, 0.0365, 0.0276, 0.0569, 0.0415, 0.0340, 0.0304, 0.0482,
        0.0416, 0.0459], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,473][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5098, 0.0027, 0.0148, 0.0012, 0.0065, 0.0112, 0.0080, 0.0035, 0.0072,
        0.0056, 0.0121, 0.0291, 0.0119, 0.0758, 0.0457, 0.0208, 0.0387, 0.0311,
        0.1064, 0.0580], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,475][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7645, 0.0145, 0.0160, 0.0051, 0.0085, 0.0156, 0.0152, 0.0099, 0.0056,
        0.0068, 0.0098, 0.0125, 0.0149, 0.0130, 0.0157, 0.0087, 0.0222, 0.0159,
        0.0149, 0.0108], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,476][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0672, 0.0014, 0.0053, 0.0004, 0.0059, 0.0079, 0.0055, 0.0014, 0.0055,
        0.0046, 0.0090, 0.0532, 0.0107, 0.0991, 0.0826, 0.0241, 0.0564, 0.0516,
        0.4070, 0.1010], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,478][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.7106e-01, 4.3524e-04, 2.0381e-03, 2.0808e-04, 1.4260e-03, 1.3590e-03,
        9.9333e-04, 8.9350e-04, 2.6484e-04, 8.8074e-04, 7.4327e-04, 1.4146e-03,
        2.5596e-03, 4.9829e-03, 1.3651e-03, 1.3864e-03, 1.6186e-03, 1.6560e-03,
        3.0188e-03, 1.6992e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,480][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0972, 0.0014, 0.0060, 0.0006, 0.0058, 0.0082, 0.0058, 0.0023, 0.0062,
        0.0067, 0.0104, 0.0728, 0.0118, 0.0934, 0.0730, 0.0259, 0.0919, 0.0531,
        0.3192, 0.1082], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,481][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.2525e-01, 4.4143e-05, 9.1941e-04, 1.2700e-05, 7.1237e-04, 9.4191e-04,
        6.0376e-04, 1.1683e-04, 8.0220e-04, 4.4431e-04, 1.2753e-03, 4.9571e-02,
        1.7796e-03, 6.1835e-02, 3.7029e-02, 7.3230e-03, 7.6171e-02, 3.8271e-02,
        4.1191e-01, 8.4994e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,483][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1198, 0.0490, 0.0484, 0.0316, 0.0283, 0.0509, 0.0418, 0.0317, 0.0486,
        0.0238, 0.0302, 0.0536, 0.0567, 0.0372, 0.0699, 0.0414, 0.0660, 0.0375,
        0.1009, 0.0325], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,483][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5020, 0.0371, 0.0258, 0.0192, 0.0136, 0.0211, 0.0385, 0.0294, 0.0406,
        0.0156, 0.0305, 0.0219, 0.0256, 0.0153, 0.0404, 0.0167, 0.0298, 0.0274,
        0.0343, 0.0152], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,484][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.3445e-02, 1.6525e-04, 2.5494e-03, 2.7888e-05, 1.8626e-03, 1.9251e-03,
        9.8312e-04, 1.8000e-04, 1.8046e-03, 9.7100e-04, 2.3130e-03, 5.6264e-02,
        2.4133e-03, 1.1823e-01, 1.0993e-01, 1.1690e-02, 6.6145e-02, 4.6087e-02,
        4.5476e-01, 1.0825e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,488][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:46,490][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12865],
        [ 4910],
        [ 6375],
        [ 2466],
        [  317],
        [  175],
        [  409],
        [  210],
        [  856],
        [  293],
        [  114],
        [  202],
        [  253],
        [  209],
        [  535],
        [  403],
        [ 1112],
        [  409],
        [  239],
        [  213]], device='cuda:0')
[2024-07-24 10:18:46,492][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14371],
        [ 8153],
        [19939],
        [ 3057],
        [ 1093],
        [  939],
        [ 4125],
        [ 1472],
        [ 7352],
        [ 1743],
        [ 1148],
        [ 1489],
        [ 2393],
        [ 1536],
        [ 4853],
        [ 2725],
        [ 5369],
        [ 2490],
        [ 2656],
        [ 1343]], device='cuda:0')
[2024-07-24 10:18:46,494][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38966],
        [44909],
        [42603],
        [42479],
        [43273],
        [43821],
        [44940],
        [44949],
        [44572],
        [44504],
        [44459],
        [44537],
        [44618],
        [44588],
        [44692],
        [44754],
        [44817],
        [44972],
        [45044],
        [45136]], device='cuda:0')
[2024-07-24 10:18:46,497][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18350],
        [12495],
        [14236],
        [15412],
        [17255],
        [16307],
        [10884],
        [10706],
        [15505],
        [17643],
        [20204],
        [21085],
        [21187],
        [20276],
        [19683],
        [19462],
        [21175],
        [20782],
        [13890],
        [13427]], device='cuda:0')
[2024-07-24 10:18:46,499][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[915],
        [446],
        [395],
        [383],
        [358],
        [310],
        [281],
        [259],
        [243],
        [227],
        [214],
        [215],
        [213],
        [214],
        [213],
        [208],
        [207],
        [204],
        [205],
        [200]], device='cuda:0')
[2024-07-24 10:18:46,501][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[15607],
        [21127],
        [21594],
        [19914],
        [19790],
        [18644],
        [18221],
        [17370],
        [17925],
        [17415],
        [17215],
        [17345],
        [17105],
        [17194],
        [17129],
        [16708],
        [16422],
        [16250],
        [16381],
        [16171]], device='cuda:0')
[2024-07-24 10:18:46,503][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[18672],
        [24579],
        [ 5443],
        [ 6698],
        [ 7557],
        [ 7486],
        [ 8165],
        [ 8313],
        [ 8233],
        [ 8800],
        [ 9174],
        [ 9473],
        [ 9758],
        [ 9562],
        [10202],
        [10699],
        [10574],
        [10719],
        [10834],
        [11262]], device='cuda:0')
[2024-07-24 10:18:46,504][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 3633],
        [13812],
        [ 4203],
        [ 3527],
        [11563],
        [10539],
        [ 5843],
        [ 8680],
        [10681],
        [ 7500],
        [ 8749],
        [ 2079],
        [ 1817],
        [ 3386],
        [ 3397],
        [ 3941],
        [ 2899],
        [ 4036],
        [ 3189],
        [ 3735]], device='cuda:0')
[2024-07-24 10:18:46,507][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16964],
        [17862],
        [ 3533],
        [ 4114],
        [ 2959],
        [ 3406],
        [ 6944],
        [ 6988],
        [ 8343],
        [ 7980],
        [ 6413],
        [16880],
        [12690],
        [ 9674],
        [14805],
        [15270],
        [16001],
        [17294],
        [17203],
        [18792]], device='cuda:0')
[2024-07-24 10:18:46,509][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3929],
        [11532],
        [14853],
        [15610],
        [21944],
        [21910],
        [19637],
        [21931],
        [22570],
        [20099],
        [22229],
        [21281],
        [22265],
        [22547],
        [23088],
        [21300],
        [21432],
        [21625],
        [20116],
        [21296]], device='cuda:0')
[2024-07-24 10:18:46,511][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19706],
        [18759],
        [19591],
        [17947],
        [19452],
        [17157],
        [19008],
        [16655],
        [17822],
        [16455],
        [13833],
        [18309],
        [14133],
        [18407],
        [17429],
        [15172],
        [17639],
        [15161],
        [18583],
        [15955]], device='cuda:0')
[2024-07-24 10:18:46,513][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[33785],
        [45861],
        [46391],
        [50257],
        [50106],
        [50254],
        [48829],
        [50196],
        [46602],
        [49785],
        [48853],
        [47574],
        [49637],
        [48094],
        [46327],
        [49330],
        [50241],
        [49021],
        [45729],
        [48103]], device='cuda:0')
[2024-07-24 10:18:46,515][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3088],
        [1853],
        [1758],
        [1551],
        [1709],
        [1661],
        [1591],
        [1497],
        [1380],
        [1293],
        [1272],
        [1291],
        [1330],
        [1425],
        [1413],
        [1386],
        [1406],
        [1411],
        [1458],
        [1417]], device='cuda:0')
[2024-07-24 10:18:46,517][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38767],
        [42003],
        [44799],
        [45223],
        [44729],
        [43817],
        [41621],
        [41552],
        [41805],
        [44105],
        [44147],
        [48881],
        [48861],
        [47126],
        [46465],
        [46570],
        [46711],
        [46809],
        [35201],
        [39551]], device='cuda:0')
[2024-07-24 10:18:46,519][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[36023],
        [27747],
        [30829],
        [23501],
        [28091],
        [17789],
        [19550],
        [19165],
        [19679],
        [23851],
        [18687],
        [24694],
        [19897],
        [28361],
        [25338],
        [23644],
        [22435],
        [20838],
        [22682],
        [21932]], device='cuda:0')
[2024-07-24 10:18:46,521][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20542],
        [26134],
        [29619],
        [24665],
        [20211],
        [20023],
        [22226],
        [24525],
        [22938],
        [21611],
        [23168],
        [22234],
        [23431],
        [17954],
        [16061],
        [15277],
        [14736],
        [16362],
        [10821],
        [11631]], device='cuda:0')
[2024-07-24 10:18:46,522][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9655],
        [15327],
        [13541],
        [19866],
        [11855],
        [14156],
        [15950],
        [17279],
        [16477],
        [17216],
        [17327],
        [14918],
        [15170],
        [11267],
        [12208],
        [12375],
        [12873],
        [12917],
        [14927],
        [16005]], device='cuda:0')
[2024-07-24 10:18:46,525][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[16784],
        [13105],
        [ 2260],
        [ 2392],
        [ 2607],
        [ 2686],
        [ 3219],
        [ 2926],
        [ 3176],
        [ 2418],
        [ 1902],
        [ 1698],
        [ 1698],
        [ 1799],
        [ 1942],
        [ 2039],
        [ 1973],
        [ 1745],
        [ 1644],
        [ 1678]], device='cuda:0')
[2024-07-24 10:18:46,527][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[12561],
        [13039],
        [26280],
        [22476],
        [20704],
        [29900],
        [40941],
        [40548],
        [36748],
        [29595],
        [23065],
        [23960],
        [31228],
        [32431],
        [34106],
        [31688],
        [31611],
        [28549],
        [27351],
        [24498]], device='cuda:0')
[2024-07-24 10:18:46,529][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31285],
        [30938],
        [26257],
        [29006],
        [26280],
        [25314],
        [24355],
        [24049],
        [26157],
        [27943],
        [26177],
        [26520],
        [24848],
        [23261],
        [24326],
        [26202],
        [25945],
        [26019],
        [27426],
        [27533]], device='cuda:0')
[2024-07-24 10:18:46,531][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17023],
        [42583],
        [47966],
        [47945],
        [47157],
        [49013],
        [49424],
        [49298],
        [49644],
        [49560],
        [49218],
        [48453],
        [49006],
        [45528],
        [47390],
        [47745],
        [48341],
        [48629],
        [47168],
        [47115]], device='cuda:0')
[2024-07-24 10:18:46,534][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[39753],
        [39407],
        [39507],
        [39552],
        [39592],
        [39116],
        [38616],
        [38655],
        [38859],
        [39396],
        [39283],
        [39463],
        [39186],
        [39483],
        [38943],
        [39449],
        [38973],
        [38971],
        [39437],
        [39431]], device='cuda:0')
[2024-07-24 10:18:46,536][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[48848],
        [45521],
        [37100],
        [32317],
        [24323],
        [27140],
        [23622],
        [21752],
        [25385],
        [29344],
        [26495],
        [38388],
        [34914],
        [30667],
        [34857],
        [36543],
        [36419],
        [37303],
        [40987],
        [41388]], device='cuda:0')
[2024-07-24 10:18:46,538][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13799],
        [14358],
        [17096],
        [26498],
        [23264],
        [32839],
        [37263],
        [38022],
        [35488],
        [28716],
        [24577],
        [33367],
        [37549],
        [35011],
        [36542],
        [35110],
        [36008],
        [34755],
        [34193],
        [32442]], device='cuda:0')
[2024-07-24 10:18:46,539][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35313],
        [ 8368],
        [ 7859],
        [ 4806],
        [ 4481],
        [ 4109],
        [ 4400],
        [ 4504],
        [ 4227],
        [ 4461],
        [ 4149],
        [ 4353],
        [ 4637],
        [ 4283],
        [ 5755],
        [ 5568],
        [ 4947],
        [ 4755],
        [ 4558],
        [ 5760]], device='cuda:0')
[2024-07-24 10:18:46,541][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[40793],
        [44762],
        [44294],
        [46655],
        [41541],
        [40696],
        [37141],
        [38166],
        [39273],
        [43653],
        [42330],
        [38827],
        [41476],
        [38463],
        [38924],
        [42843],
        [39200],
        [40573],
        [37981],
        [41969]], device='cuda:0')
[2024-07-24 10:18:46,543][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 1536],
        [14574],
        [23437],
        [29578],
        [26574],
        [24182],
        [22606],
        [23242],
        [22456],
        [19682],
        [19543],
        [22332],
        [22533],
        [23380],
        [26291],
        [29437],
        [28097],
        [28917],
        [37441],
        [36568]], device='cuda:0')
[2024-07-24 10:18:46,545][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[16816],
        [21430],
        [15554],
        [16185],
        [22218],
        [16591],
        [13723],
        [13598],
        [13847],
        [16252],
        [19197],
        [18067],
        [15131],
        [20132],
        [16572],
        [15868],
        [16753],
        [17206],
        [17475],
        [17131]], device='cuda:0')
[2024-07-24 10:18:46,547][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18975],
        [20339],
        [22821],
        [23320],
        [26838],
        [36102],
        [35132],
        [34856],
        [35139],
        [32827],
        [39349],
        [32166],
        [34966],
        [30905],
        [32024],
        [33092],
        [33481],
        [35787],
        [35072],
        [35252]], device='cuda:0')
[2024-07-24 10:18:46,549][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269],
        [9269]], device='cuda:0')
[2024-07-24 10:18:46,624][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:46,626][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,627][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,628][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,630][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,630][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,630][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,631][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,631][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,631][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,632][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,632][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,632][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,633][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0189, 0.9811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,633][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8600, 0.1400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,633][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0058, 0.9942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,633][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1750, 0.8250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,634][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0108, 0.9892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,634][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3363, 0.6637], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,636][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5422, 0.4578], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,638][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3912, 0.6088], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,639][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.9998e-01, 2.0574e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,640][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3170, 0.6830], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,641][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,642][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6162, 0.3838], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,642][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0119, 0.4625, 0.5257], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,643][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.6488, 0.1577, 0.1934], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,643][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([6.0817e-04, 9.8708e-01, 1.2313e-02], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,643][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0621, 0.4834, 0.4545], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,644][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0073, 0.7679, 0.2248], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,644][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.2401, 0.2781, 0.4818], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,644][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.3551, 0.3163, 0.3286], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,646][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.1436, 0.5040, 0.3524], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,647][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([9.9985e-01, 2.0082e-05, 1.2721e-04], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,649][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.1219, 0.4088, 0.4692], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,650][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0020, 0.2922, 0.7058], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,650][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.3800, 0.3460, 0.2740], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,651][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0064, 0.3616, 0.4353, 0.1966], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,651][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6006, 0.1304, 0.1594, 0.1096], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,651][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0051, 0.2859, 0.3118, 0.3972], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,652][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0475, 0.3283, 0.3147, 0.3095], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,652][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0020, 0.3952, 0.4757, 0.1271], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,652][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1423, 0.1766, 0.3834, 0.2977], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,653][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2800, 0.2272, 0.2529, 0.2399], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,653][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3330, 0.1835, 0.3702, 0.1132], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,653][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.9867e-01, 1.0372e-04, 1.2146e-03, 1.0149e-05], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,654][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0414, 0.0433, 0.8918, 0.0235], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,654][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0031, 0.2225, 0.4801, 0.2943], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,656][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4504, 0.2264, 0.1772, 0.1461], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,658][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0062, 0.2641, 0.2780, 0.1617, 0.2901], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,659][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.4734, 0.1267, 0.1577, 0.1091, 0.1332], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,660][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0027, 0.4582, 0.1593, 0.3609, 0.0188], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,662][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0342, 0.2226, 0.2247, 0.2182, 0.3003], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,664][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0069, 0.3526, 0.1879, 0.0449, 0.4078], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,665][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.1047, 0.1325, 0.2468, 0.2985, 0.2175], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,667][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.2108, 0.1828, 0.1967, 0.1892, 0.2205], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,668][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.2027, 0.2024, 0.3034, 0.1015, 0.1900], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,668][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([9.9947e-01, 2.4161e-05, 4.5945e-04, 1.6223e-06, 4.3289e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,668][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0354, 0.1352, 0.4080, 0.1445, 0.2770], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,669][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0030, 0.0903, 0.6441, 0.1417, 0.1208], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,669][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.2883, 0.2263, 0.1719, 0.1626, 0.1509], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,669][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0034, 0.1957, 0.2345, 0.1257, 0.2874, 0.1533], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,670][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.4634, 0.1076, 0.1281, 0.0944, 0.1118, 0.0948], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,670][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0005, 0.4215, 0.0327, 0.4360, 0.0861, 0.0232], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,670][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0255, 0.1810, 0.1758, 0.1864, 0.2594, 0.1719], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,671][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0063, 0.2737, 0.0904, 0.0513, 0.2247, 0.3536], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,671][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0792, 0.1025, 0.2209, 0.2155, 0.1918, 0.1902], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,672][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1813, 0.1484, 0.1656, 0.1542, 0.1900, 0.1606], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,674][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1213, 0.1701, 0.2508, 0.0888, 0.1763, 0.1926], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,675][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ were] are: tensor([9.9874e-01, 1.2732e-04, 7.5077e-04, 1.5416e-05, 1.5054e-04, 2.1193e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,676][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0163, 0.0575, 0.1942, 0.1125, 0.5823, 0.0372], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,677][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0008, 0.1118, 0.1555, 0.1392, 0.5183, 0.0744], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,679][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3250, 0.1822, 0.1409, 0.1140, 0.1174, 0.1204], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,680][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0035, 0.1894, 0.1910, 0.1208, 0.2204, 0.1315, 0.1433],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,682][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.4572, 0.0905, 0.1121, 0.0794, 0.0957, 0.0788, 0.0863],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,684][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0011, 0.4536, 0.0153, 0.3600, 0.0496, 0.0862, 0.0342],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,685][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0169, 0.1603, 0.1422, 0.1634, 0.2038, 0.1423, 0.1712],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,685][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([4.3080e-04, 8.9918e-02, 3.9470e-02, 1.6947e-02, 1.6584e-01, 4.4499e-01,
        2.4240e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,686][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0538, 0.0869, 0.1977, 0.2138, 0.1756, 0.1675, 0.1048],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,686][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.1606, 0.1352, 0.1517, 0.1400, 0.1730, 0.1429, 0.0965],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,687][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0767, 0.1509, 0.2348, 0.0850, 0.1278, 0.1908, 0.1340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,687][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([9.9634e-01, 2.0518e-04, 1.1422e-03, 1.3327e-05, 3.1560e-04, 7.9996e-04,
        1.1844e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,687][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0153, 0.1242, 0.1158, 0.1773, 0.2138, 0.1962, 0.1574],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,688][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0006, 0.2346, 0.2253, 0.1320, 0.1495, 0.2268, 0.0312],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,688][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.2090, 0.1707, 0.1318, 0.1148, 0.1143, 0.1106, 0.1488],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,688][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0016, 0.1500, 0.1818, 0.0971, 0.2322, 0.1201, 0.1504, 0.0668],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,689][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.5393, 0.0712, 0.0882, 0.0574, 0.0740, 0.0574, 0.0640, 0.0487],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,689][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0006, 0.2529, 0.0636, 0.3199, 0.1405, 0.1465, 0.0634, 0.0125],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,691][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0164, 0.1440, 0.1338, 0.1504, 0.1842, 0.1269, 0.1534, 0.0909],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,692][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ about] are: tensor([2.4180e-04, 8.9602e-02, 4.7291e-02, 2.6605e-02, 2.1596e-01, 3.1247e-01,
        2.8022e-01, 2.7609e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,694][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0477, 0.0799, 0.1772, 0.1774, 0.1581, 0.1404, 0.1044, 0.1149],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,695][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.1578, 0.1221, 0.1380, 0.1259, 0.1565, 0.1283, 0.0872, 0.0842],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,696][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0677, 0.1442, 0.1868, 0.0754, 0.1330, 0.1661, 0.1261, 0.1006],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,697][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ about] are: tensor([9.9357e-01, 4.0401e-04, 2.1415e-03, 4.6356e-05, 5.5957e-04, 6.6962e-04,
        2.1728e-03, 4.3756e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,699][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0118, 0.0688, 0.1189, 0.1114, 0.2510, 0.0679, 0.3437, 0.0265],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,700][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ about] are: tensor([8.2672e-05, 6.3356e-02, 4.2952e-01, 6.9559e-02, 2.6367e-01, 1.1797e-01,
        5.2079e-02, 3.7653e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,702][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.2172, 0.1467, 0.1157, 0.0943, 0.0955, 0.0936, 0.1303, 0.1066],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,703][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0034, 0.1492, 0.1704, 0.1000, 0.1893, 0.1080, 0.1325, 0.0643, 0.0829],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,703][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.4714, 0.0700, 0.0904, 0.0594, 0.0774, 0.0601, 0.0683, 0.0524, 0.0505],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,703][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ going] are: tensor([1.3038e-04, 4.6123e-01, 1.8506e-03, 3.3922e-01, 1.6452e-02, 4.4213e-02,
        1.7610e-02, 1.1636e-01, 2.9314e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,704][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0185, 0.1280, 0.1267, 0.1330, 0.1725, 0.1145, 0.1300, 0.0766, 0.1002],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,704][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0007, 0.0422, 0.0461, 0.0133, 0.1847, 0.3645, 0.1866, 0.0153, 0.1467],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,705][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0435, 0.0722, 0.1418, 0.1568, 0.1203, 0.1274, 0.0998, 0.1070, 0.1312],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,705][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1358, 0.1118, 0.1255, 0.1167, 0.1447, 0.1198, 0.0815, 0.0782, 0.0861],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,705][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.1979, 0.0655, 0.1996, 0.0420, 0.1208, 0.1085, 0.0957, 0.0978, 0.0722],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,706][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ going] are: tensor([9.9867e-01, 2.4155e-05, 5.8810e-04, 2.4804e-06, 9.1822e-05, 1.8097e-04,
        3.1741e-04, 6.7740e-05, 5.3797e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,706][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0049, 0.0354, 0.1105, 0.0457, 0.2062, 0.0966, 0.3166, 0.0754, 0.1087],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,707][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ going] are: tensor([2.7054e-04, 1.1444e-01, 1.5602e-01, 8.9685e-02, 3.2511e-01, 1.0908e-01,
        7.9923e-02, 4.2771e-02, 8.2708e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,709][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.2201, 0.1273, 0.1013, 0.0810, 0.0830, 0.0805, 0.1109, 0.0914, 0.1046],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,710][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0016, 0.1242, 0.1494, 0.0777, 0.1843, 0.1001, 0.1369, 0.0585, 0.0884,
        0.0789], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,712][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5062, 0.0596, 0.0776, 0.0527, 0.0644, 0.0531, 0.0580, 0.0436, 0.0423,
        0.0426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,713][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0036, 0.1361, 0.0353, 0.2307, 0.0817, 0.1938, 0.0597, 0.0419, 0.0688,
        0.1486], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,715][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0192, 0.1116, 0.1089, 0.1149, 0.1488, 0.1037, 0.1188, 0.0682, 0.0918,
        0.1140], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,717][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0016, 0.0400, 0.0458, 0.0161, 0.1678, 0.2912, 0.1927, 0.0156, 0.1171,
        0.1120], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,718][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0391, 0.0629, 0.1307, 0.1267, 0.1074, 0.1139, 0.0908, 0.0925, 0.1312,
        0.1047], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,719][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1362, 0.0967, 0.1089, 0.1032, 0.1256, 0.1080, 0.0766, 0.0725, 0.0806,
        0.0916], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,720][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4525, 0.0296, 0.1061, 0.0215, 0.0629, 0.0681, 0.0692, 0.0680, 0.0786,
        0.0436], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,720][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9979e-01, 2.6346e-06, 8.4001e-05, 4.0090e-07, 1.4352e-05, 2.8330e-05,
        4.0629e-05, 8.5069e-06, 1.1307e-05, 1.6248e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,721][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0083, 0.0143, 0.0832, 0.0200, 0.2481, 0.0642, 0.3419, 0.0226, 0.1552,
        0.0422], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,721][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.1142e-04, 2.9697e-02, 2.5166e-01, 4.7430e-02, 1.6333e-01, 1.5151e-01,
        9.4710e-02, 1.6450e-02, 1.9574e-01, 4.9253e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,722][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1804, 0.1109, 0.0896, 0.0722, 0.0727, 0.0727, 0.1057, 0.0832, 0.0962,
        0.1164], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,722][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0008, 0.1127, 0.1423, 0.0759, 0.1746, 0.0926, 0.1229, 0.0553, 0.0790,
        0.0801, 0.0638], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,722][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.4209, 0.0659, 0.0841, 0.0548, 0.0685, 0.0553, 0.0626, 0.0484, 0.0467,
        0.0473, 0.0455], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,723][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.6315e-04, 1.2044e-01, 1.3301e-02, 2.2131e-01, 3.0638e-02, 2.7479e-02,
        2.1200e-02, 3.1031e-02, 1.2899e-02, 5.1014e-01, 1.1299e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,723][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0148, 0.1002, 0.0970, 0.1069, 0.1374, 0.0975, 0.1008, 0.0603, 0.0818,
        0.1042, 0.0990], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,724][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0057, 0.0369, 0.0696, 0.0156, 0.1639, 0.1799, 0.1028, 0.0131, 0.1251,
        0.1340, 0.1535], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,725][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0391, 0.0579, 0.1155, 0.1182, 0.0996, 0.1086, 0.0786, 0.0838, 0.1107,
        0.0927, 0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,726][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1080, 0.0895, 0.1024, 0.0966, 0.1160, 0.1000, 0.0718, 0.0690, 0.0762,
        0.0857, 0.0848], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,728][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2380, 0.0595, 0.1350, 0.0328, 0.0749, 0.0962, 0.0800, 0.0673, 0.0900,
        0.0560, 0.0703], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,729][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.9914e-01, 7.6284e-06, 3.7403e-04, 1.7759e-06, 6.6432e-05, 7.2067e-05,
        8.7893e-05, 1.7857e-05, 4.1456e-05, 8.5863e-05, 1.0968e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,730][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0145, 0.0175, 0.1199, 0.0310, 0.1866, 0.0642, 0.2481, 0.0537, 0.1359,
        0.0944, 0.0341], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,731][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.7201e-04, 4.0762e-02, 1.6146e-01, 8.8516e-02, 2.0173e-01, 1.3623e-01,
        1.0470e-01, 1.3334e-02, 1.9499e-01, 4.1667e-02, 1.6442e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,733][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1311, 0.1078, 0.0843, 0.0695, 0.0686, 0.0679, 0.0960, 0.0788, 0.0920,
        0.1136, 0.0904], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:46,735][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0037, 0.1182, 0.1222, 0.0726, 0.1392, 0.0841, 0.0937, 0.0470, 0.0656,
        0.0774, 0.0696, 0.1067], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,736][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.4419, 0.0623, 0.0752, 0.0484, 0.0614, 0.0494, 0.0538, 0.0415, 0.0408,
        0.0418, 0.0408, 0.0428], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,737][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ school] are: tensor([1.3807e-04, 5.7341e-02, 5.6521e-03, 1.2419e-01, 1.1294e-02, 2.2338e-02,
        8.7828e-03, 3.8270e-02, 9.9854e-03, 5.5537e-01, 1.5541e-01, 1.1233e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,738][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0132, 0.0967, 0.0891, 0.0942, 0.1272, 0.0803, 0.0844, 0.0531, 0.0681,
        0.0963, 0.0937, 0.1037], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,738][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0023, 0.0050, 0.0094, 0.0014, 0.0187, 0.0362, 0.0084, 0.0011, 0.0108,
        0.0130, 0.0320, 0.8618], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,739][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0368, 0.0560, 0.1028, 0.1073, 0.0962, 0.0936, 0.0747, 0.0798, 0.0929,
        0.0808, 0.0776, 0.1014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,739][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.1098, 0.0802, 0.0924, 0.0836, 0.1042, 0.0897, 0.0648, 0.0624, 0.0695,
        0.0791, 0.0785, 0.0859], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,739][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.1331, 0.0413, 0.1021, 0.0316, 0.0652, 0.1077, 0.0592, 0.0596, 0.0702,
        0.0587, 0.1064, 0.1651], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,740][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ school] are: tensor([9.9962e-01, 2.4649e-07, 2.6433e-05, 4.0335e-08, 2.4987e-06, 6.4153e-06,
        5.2109e-06, 1.0600e-06, 1.6203e-06, 3.4719e-06, 1.1534e-05, 3.2501e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,740][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0199, 0.0070, 0.0670, 0.0088, 0.0540, 0.0423, 0.0362, 0.0129, 0.0329,
        0.0349, 0.0420, 0.6420], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,741][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ school] are: tensor([4.4574e-05, 5.1350e-02, 2.5977e-01, 6.9053e-02, 1.0481e-01, 1.6421e-01,
        5.3316e-02, 1.2461e-02, 1.0379e-01, 7.3091e-02, 6.2481e-02, 4.5632e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,741][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.1037, 0.0978, 0.0766, 0.0631, 0.0671, 0.0664, 0.0917, 0.0744, 0.0886,
        0.1065, 0.0886, 0.0755], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:46,743][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0011, 0.0887, 0.1134, 0.0537, 0.1399, 0.0765, 0.1062, 0.0474, 0.0721,
        0.0638, 0.0610, 0.1155, 0.0608], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,744][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5783, 0.0460, 0.0562, 0.0344, 0.0454, 0.0352, 0.0393, 0.0291, 0.0285,
        0.0279, 0.0283, 0.0290, 0.0226], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,746][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0010, 0.0133, 0.0176, 0.0815, 0.0946, 0.1097, 0.0900, 0.0687, 0.0240,
        0.1882, 0.1942, 0.1039, 0.0132], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,747][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0164, 0.0766, 0.0789, 0.0810, 0.1155, 0.0749, 0.0829, 0.0506, 0.0701,
        0.0883, 0.0866, 0.1013, 0.0768], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,748][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([7.2702e-04, 8.3545e-03, 7.7846e-03, 3.5763e-03, 1.6266e-02, 3.2422e-02,
        1.4810e-02, 2.4702e-03, 1.9581e-02, 2.5467e-02, 3.8462e-02, 7.9008e-01,
        4.0000e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,750][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0343, 0.0456, 0.0960, 0.0957, 0.0830, 0.0929, 0.0657, 0.0702, 0.1010,
        0.0742, 0.0825, 0.0979, 0.0610], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,752][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0970, 0.0734, 0.0874, 0.0800, 0.1010, 0.0843, 0.0590, 0.0576, 0.0643,
        0.0740, 0.0730, 0.0823, 0.0668], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,753][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1862, 0.0338, 0.0981, 0.0256, 0.0587, 0.0746, 0.0510, 0.0574, 0.0569,
        0.0419, 0.0674, 0.1237, 0.1248], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,754][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([9.9885e-01, 2.1530e-06, 5.3660e-05, 5.0173e-07, 8.2595e-06, 1.8468e-05,
        2.5586e-05, 8.6985e-06, 6.8258e-06, 1.8575e-05, 2.9808e-05, 9.4724e-04,
        3.0420e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,755][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0031, 0.0010, 0.0491, 0.0014, 0.0486, 0.0164, 0.0773, 0.0047, 0.0244,
        0.0066, 0.0151, 0.7497, 0.0026], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,755][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.0705e-04, 4.0777e-02, 2.8383e-01, 5.6774e-02, 2.1419e-01, 9.1513e-02,
        5.5130e-02, 1.0015e-02, 9.5084e-02, 4.0565e-02, 2.2107e-02, 6.2801e-02,
        2.7009e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,756][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1116, 0.0969, 0.0729, 0.0531, 0.0574, 0.0562, 0.0861, 0.0685, 0.0855,
        0.1012, 0.0827, 0.0628, 0.0652], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:46,756][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0022, 0.0960, 0.1107, 0.0608, 0.1134, 0.0719, 0.0804, 0.0409, 0.0586,
        0.0626, 0.0601, 0.0960, 0.0609, 0.0855], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,757][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.2903, 0.0638, 0.0769, 0.0510, 0.0659, 0.0545, 0.0601, 0.0480, 0.0480,
        0.0482, 0.0447, 0.0477, 0.0379, 0.0630], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,757][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0003, 0.0716, 0.0240, 0.0630, 0.0034, 0.1077, 0.0269, 0.1370, 0.0431,
        0.2341, 0.0897, 0.0522, 0.1446, 0.0024], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,757][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0119, 0.0705, 0.0760, 0.0786, 0.1099, 0.0714, 0.0678, 0.0422, 0.0556,
        0.0783, 0.0787, 0.0853, 0.0758, 0.0980], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,758][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([1.3177e-03, 1.0389e-03, 2.8488e-03, 2.4189e-04, 4.2821e-03, 9.8320e-03,
        2.2054e-03, 1.5845e-04, 2.0229e-03, 3.0489e-03, 6.5150e-03, 3.0891e-01,
        1.4142e-02, 6.4344e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,758][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0280, 0.0402, 0.0840, 0.1050, 0.0735, 0.0833, 0.0531, 0.0611, 0.0847,
        0.0751, 0.0775, 0.1005, 0.0706, 0.0634], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,759][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0905, 0.0703, 0.0807, 0.0721, 0.0912, 0.0779, 0.0559, 0.0534, 0.0591,
        0.0678, 0.0676, 0.0751, 0.0618, 0.0765], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,761][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0399, 0.0332, 0.0753, 0.0247, 0.0540, 0.0709, 0.0476, 0.0543, 0.0589,
        0.0603, 0.0866, 0.1206, 0.1454, 0.1283], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,762][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([9.9792e-01, 9.6462e-07, 7.2614e-05, 1.4808e-07, 7.1332e-06, 1.8356e-05,
        2.0703e-05, 4.0657e-06, 4.1973e-06, 5.8473e-06, 2.0265e-05, 7.1293e-04,
        4.4789e-05, 1.1674e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,764][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0048, 0.0031, 0.0285, 0.0038, 0.0160, 0.0174, 0.0229, 0.0091, 0.0241,
        0.0192, 0.0188, 0.7042, 0.0155, 0.1125], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,765][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([1.4898e-04, 3.0121e-02, 2.9261e-01, 5.5276e-02, 7.3293e-02, 1.1491e-01,
        4.7636e-02, 9.5021e-03, 1.9881e-01, 5.1492e-02, 3.0047e-02, 2.6767e-02,
        1.7027e-02, 5.2354e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,766][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0756, 0.0824, 0.0632, 0.0552, 0.0553, 0.0579, 0.0867, 0.0706, 0.0799,
        0.0940, 0.0785, 0.0660, 0.0671, 0.0675], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:46,768][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0025, 0.0877, 0.1030, 0.0618, 0.1102, 0.0684, 0.0755, 0.0385, 0.0511,
        0.0608, 0.0542, 0.0893, 0.0597, 0.0828, 0.0544], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,770][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.2706, 0.0616, 0.0741, 0.0498, 0.0632, 0.0520, 0.0567, 0.0456, 0.0441,
        0.0445, 0.0436, 0.0460, 0.0363, 0.0598, 0.0521], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,771][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([1.4580e-04, 2.1242e-01, 2.1284e-02, 1.3435e-01, 3.7385e-02, 1.7529e-02,
        7.4316e-03, 8.6428e-03, 4.8318e-03, 1.6230e-01, 5.5083e-02, 1.2853e-02,
        2.9512e-01, 2.8665e-02, 1.9519e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,772][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0101, 0.0706, 0.0666, 0.0742, 0.0941, 0.0642, 0.0700, 0.0447, 0.0551,
        0.0773, 0.0787, 0.0802, 0.0677, 0.0872, 0.0593], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,772][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([3.5537e-04, 1.7061e-03, 3.9395e-03, 4.2407e-04, 5.1338e-03, 1.3592e-02,
        3.8150e-03, 2.9687e-04, 2.9218e-03, 3.5882e-03, 7.0590e-03, 2.7085e-01,
        1.4643e-02, 5.5539e-01, 1.1628e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,773][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0242, 0.0417, 0.0792, 0.0913, 0.0715, 0.0777, 0.0564, 0.0624, 0.0820,
        0.0698, 0.0735, 0.0870, 0.0588, 0.0609, 0.0635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,773][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0880, 0.0672, 0.0773, 0.0697, 0.0887, 0.0731, 0.0514, 0.0494, 0.0547,
        0.0624, 0.0622, 0.0696, 0.0574, 0.0714, 0.0573], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,774][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0578, 0.0376, 0.0822, 0.0261, 0.0436, 0.0663, 0.0521, 0.0512, 0.0563,
        0.0416, 0.0779, 0.1271, 0.1135, 0.0734, 0.0933], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,774][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([9.9827e-01, 9.9873e-07, 5.4206e-05, 1.2194e-07, 4.7492e-06, 1.6714e-05,
        2.3752e-05, 6.4167e-06, 4.2693e-06, 5.6432e-06, 1.2199e-05, 6.8891e-04,
        3.0351e-05, 7.4999e-04, 1.3117e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,775][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0019, 0.0055, 0.0200, 0.0100, 0.0432, 0.0146, 0.0188, 0.0033, 0.0077,
        0.0113, 0.0343, 0.4416, 0.0357, 0.2920, 0.0600], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,775][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0003, 0.0267, 0.1915, 0.0384, 0.1263, 0.0979, 0.0234, 0.0095, 0.0646,
        0.0364, 0.0346, 0.0385, 0.0227, 0.2480, 0.0411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,775][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.1118, 0.0769, 0.0596, 0.0475, 0.0501, 0.0509, 0.0737, 0.0604, 0.0695,
        0.0830, 0.0703, 0.0583, 0.0627, 0.0619, 0.0632], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:46,777][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0011, 0.0784, 0.0942, 0.0490, 0.1155, 0.0636, 0.0839, 0.0362, 0.0574,
        0.0492, 0.0483, 0.0851, 0.0513, 0.0837, 0.0578, 0.0454],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,778][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3412, 0.0529, 0.0648, 0.0443, 0.0530, 0.0448, 0.0486, 0.0374, 0.0370,
        0.0364, 0.0364, 0.0364, 0.0299, 0.0507, 0.0466, 0.0398],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,780][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0025, 0.0761, 0.0221, 0.1177, 0.0468, 0.0922, 0.0346, 0.0206, 0.0380,
        0.0657, 0.2580, 0.0480, 0.0578, 0.0395, 0.0153, 0.0650],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,782][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0111, 0.0655, 0.0678, 0.0674, 0.0900, 0.0613, 0.0699, 0.0389, 0.0525,
        0.0666, 0.0707, 0.0805, 0.0609, 0.0829, 0.0592, 0.0550],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,782][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([4.2768e-04, 1.4746e-03, 3.3958e-03, 7.7783e-04, 7.3215e-03, 1.7918e-02,
        6.9498e-03, 5.5694e-04, 5.3933e-03, 4.9522e-03, 8.1620e-03, 2.5913e-01,
        1.0730e-02, 4.4525e-01, 1.8208e-01, 4.5481e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,784][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0240, 0.0386, 0.0817, 0.0823, 0.0696, 0.0708, 0.0543, 0.0570, 0.0811,
        0.0662, 0.0717, 0.0849, 0.0523, 0.0590, 0.0568, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,786][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0888, 0.0618, 0.0715, 0.0660, 0.0834, 0.0701, 0.0486, 0.0465, 0.0511,
        0.0581, 0.0585, 0.0660, 0.0550, 0.0679, 0.0551, 0.0514],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,788][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3230, 0.0209, 0.0686, 0.0129, 0.0344, 0.0396, 0.0396, 0.0402, 0.0403,
        0.0226, 0.0376, 0.0661, 0.0516, 0.0878, 0.0859, 0.0289],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,789][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9943e-01, 1.9325e-07, 1.9342e-05, 3.8064e-08, 1.9739e-06, 4.4101e-06,
        5.3837e-06, 1.3325e-06, 1.4736e-06, 1.5690e-06, 3.3547e-06, 1.8533e-04,
        7.1650e-06, 2.8698e-04, 4.5179e-05, 8.9143e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,789][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0012, 0.0010, 0.0117, 0.0013, 0.0257, 0.0076, 0.0326, 0.0020, 0.0144,
        0.0030, 0.0095, 0.6168, 0.0044, 0.1722, 0.0889, 0.0077],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,790][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0003, 0.0139, 0.2330, 0.0214, 0.0847, 0.0768, 0.0467, 0.0072, 0.0980,
        0.0201, 0.0158, 0.0416, 0.0186, 0.1822, 0.1125, 0.0272],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,790][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1142, 0.0703, 0.0557, 0.0446, 0.0467, 0.0474, 0.0712, 0.0559, 0.0648,
        0.0769, 0.0646, 0.0538, 0.0560, 0.0566, 0.0589, 0.0621],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:46,791][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0014, 0.0799, 0.0861, 0.0528, 0.0935, 0.0597, 0.0699, 0.0354, 0.0468,
        0.0549, 0.0473, 0.0725, 0.0538, 0.0674, 0.0498, 0.0514, 0.0774],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,791][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.2706, 0.0539, 0.0668, 0.0434, 0.0551, 0.0462, 0.0503, 0.0399, 0.0391,
        0.0392, 0.0380, 0.0388, 0.0311, 0.0519, 0.0475, 0.0417, 0.0468],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,792][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([1.6791e-04, 6.7587e-02, 8.9312e-03, 5.0065e-02, 6.1779e-03, 1.0436e-02,
        4.8753e-03, 2.3419e-02, 9.5789e-03, 2.5002e-01, 8.1332e-02, 8.9276e-03,
        1.5719e-01, 4.3069e-03, 1.9499e-03, 3.1324e-01, 1.7989e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,792][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0094, 0.0639, 0.0646, 0.0642, 0.0858, 0.0571, 0.0634, 0.0382, 0.0469,
        0.0679, 0.0671, 0.0710, 0.0612, 0.0787, 0.0510, 0.0560, 0.0535],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,793][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([3.2297e-04, 1.5342e-03, 3.1175e-03, 3.5822e-04, 4.7151e-03, 1.5374e-02,
        5.3397e-03, 3.5913e-04, 3.1249e-03, 2.8333e-03, 6.0176e-03, 2.1133e-01,
        1.1852e-02, 3.8850e-01, 1.4629e-01, 2.7109e-02, 1.7184e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,794][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0244, 0.0386, 0.0751, 0.0812, 0.0635, 0.0682, 0.0543, 0.0578, 0.0730,
        0.0598, 0.0645, 0.0727, 0.0539, 0.0544, 0.0555, 0.0467, 0.0565],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,795][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0739, 0.0599, 0.0692, 0.0644, 0.0797, 0.0679, 0.0478, 0.0455, 0.0503,
        0.0564, 0.0562, 0.0620, 0.0518, 0.0644, 0.0520, 0.0496, 0.0490],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,797][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.1124, 0.0400, 0.0802, 0.0197, 0.0424, 0.0600, 0.0455, 0.0451, 0.0340,
        0.0305, 0.0517, 0.0868, 0.0820, 0.0732, 0.0897, 0.0362, 0.0704],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,798][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([9.9716e-01, 1.0860e-06, 8.3650e-05, 1.4944e-07, 8.9049e-06, 2.1100e-05,
        3.0997e-05, 6.1804e-06, 4.3493e-06, 8.7999e-06, 1.5782e-05, 8.1748e-04,
        3.5309e-05, 1.1291e-03, 2.3624e-04, 4.6671e-05, 3.9280e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,800][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0029, 0.0022, 0.0390, 0.0058, 0.0415, 0.0162, 0.0229, 0.0046, 0.0243,
        0.0233, 0.0178, 0.2776, 0.0148, 0.2676, 0.1390, 0.0617, 0.0387],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,801][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([3.3253e-04, 1.5755e-02, 3.9927e-01, 2.3257e-02, 6.9266e-02, 1.1199e-01,
        3.3330e-02, 5.7711e-03, 7.3001e-02, 2.1635e-02, 2.0823e-02, 2.0643e-02,
        1.5536e-02, 9.8521e-02, 5.2021e-02, 2.3480e-02, 1.5364e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,803][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.1004, 0.0638, 0.0533, 0.0442, 0.0467, 0.0458, 0.0653, 0.0527, 0.0609,
        0.0740, 0.0623, 0.0525, 0.0541, 0.0564, 0.0565, 0.0599, 0.0512],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:46,804][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0008, 0.0669, 0.0830, 0.0456, 0.0934, 0.0572, 0.0686, 0.0334, 0.0480,
        0.0466, 0.0410, 0.0716, 0.0463, 0.0673, 0.0496, 0.0461, 0.0808, 0.0539],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,806][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3298, 0.0490, 0.0589, 0.0389, 0.0475, 0.0394, 0.0441, 0.0342, 0.0334,
        0.0334, 0.0326, 0.0329, 0.0269, 0.0454, 0.0418, 0.0359, 0.0415, 0.0345],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,806][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([6.3947e-05, 1.0323e-01, 7.5687e-03, 1.5818e-01, 1.8279e-02, 3.3647e-02,
        1.0272e-02, 2.1280e-02, 4.2486e-03, 2.0675e-01, 1.5870e-02, 2.7660e-02,
        9.3140e-02, 9.6549e-03, 6.3810e-03, 2.6506e-01, 1.4262e-02, 4.4553e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,807][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0091, 0.0582, 0.0591, 0.0615, 0.0768, 0.0567, 0.0607, 0.0364, 0.0482,
        0.0622, 0.0600, 0.0722, 0.0568, 0.0706, 0.0550, 0.0521, 0.0529, 0.0516],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,807][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0010, 0.0019, 0.0060, 0.0009, 0.0078, 0.0205, 0.0070, 0.0010, 0.0055,
        0.0072, 0.0094, 0.2204, 0.0154, 0.2675, 0.1378, 0.0435, 0.1737, 0.0735],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,808][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0228, 0.0360, 0.0683, 0.0781, 0.0564, 0.0637, 0.0475, 0.0526, 0.0695,
        0.0614, 0.0603, 0.0699, 0.0505, 0.0511, 0.0533, 0.0482, 0.0597, 0.0505],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,808][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0712, 0.0576, 0.0664, 0.0613, 0.0768, 0.0634, 0.0446, 0.0426, 0.0475,
        0.0534, 0.0531, 0.0598, 0.0492, 0.0617, 0.0497, 0.0470, 0.0467, 0.0480],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,809][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1255, 0.0262, 0.0718, 0.0186, 0.0374, 0.0461, 0.0356, 0.0393, 0.0407,
        0.0310, 0.0440, 0.0624, 0.0772, 0.0734, 0.0980, 0.0369, 0.0825, 0.0533],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,809][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.9690e-01, 1.6878e-06, 1.0598e-04, 3.6924e-07, 1.2387e-05, 2.5830e-05,
        3.5527e-05, 8.7676e-06, 7.6367e-06, 1.3182e-05, 1.3762e-05, 7.3526e-04,
        4.0450e-05, 9.0146e-04, 2.5390e-04, 6.2395e-05, 7.2420e-04, 1.5865e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,810][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0016, 0.0023, 0.0155, 0.0021, 0.0453, 0.0109, 0.0274, 0.0039, 0.0118,
        0.0115, 0.0064, 0.4520, 0.0086, 0.2243, 0.0497, 0.0263, 0.0957, 0.0047],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,810][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.3591e-04, 7.9199e-02, 2.5279e-01, 6.5381e-02, 1.4630e-01, 5.2115e-02,
        5.8853e-02, 5.0503e-03, 5.1356e-02, 1.7983e-02, 1.0693e-02, 2.0950e-02,
        1.2838e-02, 1.0056e-01, 5.9207e-02, 1.6359e-02, 3.5666e-02, 1.4459e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,812][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0876, 0.0662, 0.0522, 0.0416, 0.0440, 0.0420, 0.0614, 0.0503, 0.0595,
        0.0729, 0.0598, 0.0484, 0.0510, 0.0505, 0.0528, 0.0565, 0.0479, 0.0557],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:46,814][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0023, 0.0721, 0.0745, 0.0463, 0.0807, 0.0519, 0.0562, 0.0308, 0.0411,
        0.0495, 0.0421, 0.0648, 0.0455, 0.0607, 0.0412, 0.0451, 0.0661, 0.0557,
        0.0733], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,816][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.2566, 0.0487, 0.0607, 0.0393, 0.0507, 0.0418, 0.0474, 0.0372, 0.0355,
        0.0346, 0.0330, 0.0365, 0.0292, 0.0489, 0.0439, 0.0367, 0.0434, 0.0354,
        0.0404], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,817][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([3.3342e-06, 2.6128e-02, 7.9199e-04, 7.6937e-02, 3.6819e-03, 8.1199e-03,
        6.2699e-03, 3.6127e-02, 2.7686e-03, 2.8736e-01, 2.3366e-02, 1.1421e-02,
        6.1854e-02, 2.1614e-03, 4.0827e-03, 4.0614e-01, 2.7485e-02, 1.4896e-02,
        4.0782e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,819][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0075, 0.0561, 0.0542, 0.0591, 0.0761, 0.0510, 0.0510, 0.0323, 0.0418,
        0.0611, 0.0598, 0.0630, 0.0560, 0.0701, 0.0440, 0.0527, 0.0459, 0.0536,
        0.0646], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,820][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([3.1283e-04, 4.9856e-04, 6.3354e-04, 1.0041e-04, 8.0527e-04, 4.8328e-03,
        1.4149e-03, 1.4322e-04, 7.6361e-04, 9.5744e-04, 2.0411e-03, 4.2171e-02,
        3.8290e-03, 6.7925e-02, 4.2655e-02, 9.5542e-03, 4.6274e-02, 2.8933e-02,
        7.4615e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,822][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0242, 0.0343, 0.0607, 0.0669, 0.0588, 0.0572, 0.0420, 0.0496, 0.0572,
        0.0558, 0.0566, 0.0686, 0.0474, 0.0546, 0.0477, 0.0476, 0.0595, 0.0539,
        0.0575], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,823][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0626, 0.0557, 0.0640, 0.0587, 0.0739, 0.0609, 0.0442, 0.0417, 0.0468,
        0.0533, 0.0514, 0.0574, 0.0470, 0.0576, 0.0462, 0.0455, 0.0444, 0.0458,
        0.0429], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,824][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0163, 0.0279, 0.0523, 0.0230, 0.0355, 0.0560, 0.0373, 0.0331, 0.0426,
        0.0394, 0.0582, 0.0721, 0.0908, 0.0517, 0.0812, 0.0404, 0.0585, 0.0783,
        0.1054], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,824][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([9.9695e-01, 4.3980e-07, 3.9961e-05, 4.3929e-08, 3.2661e-06, 8.1720e-06,
        8.3994e-06, 2.1559e-06, 1.5716e-06, 3.3664e-06, 9.1034e-06, 3.0422e-04,
        2.7462e-05, 4.3895e-04, 8.9533e-05, 1.6899e-05, 2.2806e-04, 8.7122e-05,
        1.7792e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,825][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.0036, 0.0012, 0.0439, 0.0016, 0.0141, 0.0095, 0.0194, 0.0064, 0.0088,
        0.0095, 0.0155, 0.5026, 0.0095, 0.0919, 0.1232, 0.0280, 0.0403, 0.0234,
        0.0476], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,825][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([4.6375e-05, 2.4515e-02, 3.7125e-01, 2.3000e-02, 1.3896e-01, 5.8977e-02,
        5.6012e-02, 4.5507e-03, 6.0706e-02, 1.3526e-02, 1.0749e-02, 1.2453e-02,
        6.9911e-03, 9.8488e-02, 4.5641e-02, 7.6408e-03, 2.6868e-02, 1.6976e-02,
        2.2652e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,826][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0401, 0.0578, 0.0466, 0.0436, 0.0430, 0.0430, 0.0605, 0.0509, 0.0591,
        0.0728, 0.0581, 0.0478, 0.0498, 0.0519, 0.0540, 0.0584, 0.0495, 0.0568,
        0.0561], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:46,826][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0008, 0.0587, 0.0729, 0.0374, 0.0900, 0.0498, 0.0656, 0.0292, 0.0452,
        0.0374, 0.0376, 0.0643, 0.0383, 0.0640, 0.0446, 0.0341, 0.0711, 0.0488,
        0.0776, 0.0328], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,827][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3033, 0.0455, 0.0557, 0.0373, 0.0455, 0.0375, 0.0420, 0.0324, 0.0314,
        0.0308, 0.0300, 0.0315, 0.0257, 0.0438, 0.0396, 0.0336, 0.0395, 0.0316,
        0.0356, 0.0277], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,827][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0019, 0.0583, 0.0180, 0.0845, 0.0383, 0.0583, 0.0287, 0.0164, 0.0319,
        0.0519, 0.1908, 0.0410, 0.0466, 0.0318, 0.0115, 0.0516, 0.0829, 0.0967,
        0.0163, 0.0426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,828][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0083, 0.0516, 0.0533, 0.0554, 0.0742, 0.0509, 0.0551, 0.0302, 0.0415,
        0.0535, 0.0564, 0.0658, 0.0483, 0.0662, 0.0465, 0.0433, 0.0477, 0.0478,
        0.0620, 0.0419], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,830][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.7947e-04, 8.7371e-04, 1.8942e-03, 4.3111e-04, 2.9916e-03, 1.1344e-02,
        2.6167e-03, 2.9291e-04, 1.8704e-03, 1.8628e-03, 2.9680e-03, 5.8111e-02,
        5.1348e-03, 7.4195e-02, 3.7376e-02, 1.2112e-02, 6.2823e-02, 3.2517e-02,
        6.0281e-01, 8.7093e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,831][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0197, 0.0310, 0.0637, 0.0624, 0.0554, 0.0591, 0.0447, 0.0480, 0.0682,
        0.0526, 0.0580, 0.0694, 0.0409, 0.0467, 0.0476, 0.0390, 0.0542, 0.0464,
        0.0542, 0.0390], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,833][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0663, 0.0518, 0.0598, 0.0563, 0.0712, 0.0591, 0.0414, 0.0395, 0.0434,
        0.0495, 0.0489, 0.0548, 0.0452, 0.0559, 0.0448, 0.0428, 0.0428, 0.0444,
        0.0418, 0.0401], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,834][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2947, 0.0170, 0.0532, 0.0107, 0.0251, 0.0282, 0.0308, 0.0328, 0.0308,
        0.0179, 0.0266, 0.0455, 0.0379, 0.0606, 0.0571, 0.0209, 0.0543, 0.0325,
        0.0935, 0.0299], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,836][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.9974e-01, 6.2088e-08, 5.7335e-06, 1.3946e-08, 4.3713e-07, 1.5134e-06,
        1.5898e-06, 5.0464e-07, 2.7933e-07, 3.4645e-07, 7.6076e-07, 2.2284e-05,
        2.6016e-06, 3.5578e-05, 8.3230e-06, 1.7453e-06, 2.3649e-05, 7.7430e-06,
        1.4176e-04, 7.5837e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,838][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0020, 0.0011, 0.0135, 0.0013, 0.0260, 0.0086, 0.0294, 0.0021, 0.0131,
        0.0027, 0.0095, 0.4689, 0.0047, 0.1374, 0.0719, 0.0062, 0.0454, 0.0157,
        0.1215, 0.0191], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,839][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.3003e-04, 6.5772e-03, 1.3644e-01, 1.1167e-02, 6.5816e-02, 4.0374e-02,
        4.3751e-02, 4.7502e-03, 7.0250e-02, 1.0029e-02, 6.9464e-03, 2.3851e-02,
        8.6247e-03, 1.3738e-01, 6.9271e-02, 1.4007e-02, 5.6874e-02, 1.8668e-02,
        2.5772e-01, 1.7380e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,840][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0584, 0.0556, 0.0444, 0.0388, 0.0391, 0.0402, 0.0588, 0.0480, 0.0556,
        0.0672, 0.0543, 0.0442, 0.0470, 0.0482, 0.0506, 0.0547, 0.0461, 0.0518,
        0.0515, 0.0456], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:46,887][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:46,888][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,890][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,891][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,892][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,894][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,894][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,894][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,894][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,895][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,895][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,895][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,896][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:46,896][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4333, 0.5667], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,896][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9097, 0.0903], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,897][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([4.9341e-04, 9.9951e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,897][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5551, 0.4449], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,897][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9263, 0.0737], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,898][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9599, 0.0401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,908][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9929, 0.0071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,910][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2120, 0.7880], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,911][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1958, 0.8042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,911][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7846, 0.2154], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,911][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0047, 0.9953], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,912][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6494, 0.3506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:46,912][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.3137, 0.4094, 0.2768], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,912][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.9601, 0.0197, 0.0202], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,913][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([4.9545e-04, 9.2970e-01, 6.9800e-02], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,913][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.3391, 0.3796, 0.2812], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,913][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.8774, 0.0640, 0.0586], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,914][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.9692, 0.0181, 0.0127], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,914][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.9496, 0.0226, 0.0277], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,914][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0486, 0.6661, 0.2853], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,916][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0929, 0.4543, 0.4528], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,918][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.8564, 0.0873, 0.0563], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,919][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0085, 0.6697, 0.3218], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,921][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.2982, 0.3645, 0.3373], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:46,922][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([1.0580e-02, 3.5333e-01, 6.3553e-01, 5.6661e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,924][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8937, 0.0304, 0.0312, 0.0447], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,925][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0045, 0.2541, 0.0502, 0.6912], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,927][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2636, 0.3364, 0.3603, 0.0397], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,928][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6975, 0.1034, 0.1491, 0.0499], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,930][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8995, 0.0315, 0.0539, 0.0151], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,932][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9462, 0.0188, 0.0204, 0.0146], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,933][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2661, 0.2402, 0.4356, 0.0580], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,933][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0263, 0.4703, 0.4691, 0.0344], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,934][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7092, 0.1233, 0.1222, 0.0453], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,934][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0031, 0.2278, 0.1832, 0.5860], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,934][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4694, 0.2177, 0.2083, 0.1047], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:46,935][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([3.3477e-01, 3.7129e-02, 4.1608e-01, 9.8025e-05, 2.1192e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,935][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.9681, 0.0054, 0.0087, 0.0076, 0.0101], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,935][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0040, 0.2303, 0.0609, 0.5742, 0.1307], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,936][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.4207, 0.1588, 0.2535, 0.0093, 0.1578], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,936][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.7306, 0.0779, 0.0763, 0.0434, 0.0718], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,936][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.9077, 0.0216, 0.0255, 0.0245, 0.0208], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,937][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.8424, 0.0382, 0.0365, 0.0367, 0.0461], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,938][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.1208, 0.3043, 0.3158, 0.0593, 0.1997], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,940][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0529, 0.1467, 0.4260, 0.0078, 0.3665], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,941][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.8942, 0.0427, 0.0341, 0.0110, 0.0180], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,943][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0203, 0.2004, 0.3465, 0.2763, 0.1565], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,944][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.3733, 0.2743, 0.1433, 0.1140, 0.0951], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:46,946][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0469, 0.2086, 0.2736, 0.0006, 0.4579, 0.0124], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,947][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.7795, 0.0249, 0.0389, 0.0481, 0.0367, 0.0718], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,949][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0005, 0.2460, 0.0191, 0.4247, 0.2111, 0.0986], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,950][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.2282, 0.1993, 0.1683, 0.0261, 0.1655, 0.2126], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,951][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.7243, 0.0586, 0.0574, 0.0362, 0.0719, 0.0516], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,951][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.8454, 0.0245, 0.0370, 0.0184, 0.0357, 0.0390], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,951][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.9385, 0.0137, 0.0133, 0.0129, 0.0128, 0.0088], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,952][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1247, 0.2138, 0.2823, 0.0550, 0.2004, 0.1238], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,952][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0373, 0.2874, 0.2303, 0.0251, 0.3138, 0.1061], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,953][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.6478, 0.0663, 0.0432, 0.0191, 0.0321, 0.1915], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,953][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0015, 0.1387, 0.0678, 0.2533, 0.4774, 0.0613], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,953][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.2742, 0.1780, 0.1318, 0.0896, 0.1314, 0.1950], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:46,954][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([1.6812e-01, 8.1401e-02, 1.3585e-01, 2.1790e-04, 3.6018e-01, 2.5079e-02,
        2.2914e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,954][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.8539, 0.0130, 0.0173, 0.0201, 0.0149, 0.0412, 0.0395],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,955][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0005, 0.2555, 0.0213, 0.4439, 0.1458, 0.1017, 0.0311],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,957][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0777, 0.2350, 0.1092, 0.0174, 0.1494, 0.2413, 0.1700],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,958][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.7476, 0.0362, 0.0366, 0.0275, 0.0508, 0.0372, 0.0641],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,960][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.8148, 0.0262, 0.0315, 0.0233, 0.0369, 0.0362, 0.0312],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,961][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.6698, 0.0406, 0.0417, 0.0428, 0.0473, 0.0459, 0.1120],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,963][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0641, 0.1934, 0.2890, 0.0614, 0.1323, 0.1492, 0.1105],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,965][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0094, 0.1674, 0.1693, 0.0109, 0.3726, 0.1072, 0.1633],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,966][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.4760, 0.0778, 0.0380, 0.0228, 0.0314, 0.2819, 0.0721],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,968][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0040, 0.2539, 0.1114, 0.2522, 0.2219, 0.1324, 0.0242],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,968][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.2383, 0.1842, 0.1344, 0.0691, 0.1069, 0.1415, 0.1256],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:46,968][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([2.7439e-03, 1.1198e-01, 9.7574e-02, 4.2675e-04, 5.5390e-01, 7.1361e-03,
        2.2455e-01, 1.6915e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,969][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.7166, 0.0247, 0.0384, 0.0194, 0.0336, 0.0413, 0.0734, 0.0526],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,969][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0005, 0.2014, 0.0286, 0.3813, 0.1509, 0.1439, 0.0436, 0.0498],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,970][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0417, 0.1728, 0.1542, 0.0237, 0.2156, 0.1880, 0.1787, 0.0253],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,970][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.1595, 0.0778, 0.1585, 0.0657, 0.1584, 0.0931, 0.2249, 0.0620],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,970][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.7687, 0.0242, 0.0392, 0.0195, 0.0430, 0.0271, 0.0383, 0.0400],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,971][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.5284, 0.1073, 0.0725, 0.0931, 0.0379, 0.0340, 0.0779, 0.0488],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,971][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.1021, 0.1797, 0.2319, 0.0497, 0.1409, 0.1167, 0.1114, 0.0677],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,971][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0048, 0.1772, 0.1634, 0.0120, 0.4108, 0.0581, 0.1626, 0.0110],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,972][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.3276, 0.0929, 0.0468, 0.0345, 0.0502, 0.3241, 0.0985, 0.0255],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,974][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0011, 0.1310, 0.1872, 0.1717, 0.3390, 0.0858, 0.0494, 0.0349],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,976][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.1548, 0.1084, 0.1033, 0.0890, 0.1025, 0.1729, 0.1445, 0.1247],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:46,977][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([1.0931e-01, 1.2773e-02, 1.7154e-01, 9.8470e-05, 4.0944e-01, 1.0439e-02,
        1.2797e-01, 9.0733e-04, 1.5752e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,978][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.4973, 0.0301, 0.0364, 0.0376, 0.0388, 0.0658, 0.1129, 0.1074, 0.0737],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,980][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0012, 0.1729, 0.0198, 0.3004, 0.1693, 0.1106, 0.0430, 0.1131, 0.0699],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,982][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0936, 0.0773, 0.1713, 0.0081, 0.1999, 0.1891, 0.1264, 0.0203, 0.1140],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,983][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.3482, 0.0615, 0.0922, 0.0481, 0.0984, 0.0660, 0.1620, 0.0520, 0.0714],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,985][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.7253, 0.0264, 0.0301, 0.0219, 0.0310, 0.0390, 0.0500, 0.0490, 0.0274],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,985][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.7624, 0.0195, 0.0426, 0.0199, 0.0294, 0.0265, 0.0542, 0.0287, 0.0167],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,986][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.1657, 0.0773, 0.2862, 0.0263, 0.1504, 0.0722, 0.0862, 0.0697, 0.0660],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,986][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0195, 0.0508, 0.2891, 0.0033, 0.3701, 0.0582, 0.1391, 0.0087, 0.0613],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,986][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.4911, 0.0374, 0.0432, 0.0148, 0.0326, 0.2157, 0.0610, 0.0208, 0.0834],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,987][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0052, 0.1323, 0.0768, 0.1408, 0.3562, 0.0619, 0.0525, 0.1312, 0.0429],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,987][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.3453, 0.1061, 0.0781, 0.0409, 0.0532, 0.1024, 0.0952, 0.0981, 0.0809],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:46,988][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.1391e-02, 1.3770e-02, 1.9764e-01, 1.4080e-04, 3.2311e-01, 5.4808e-03,
        1.1062e-01, 4.3675e-04, 2.3647e-01, 7.0941e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,988][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.8005, 0.0099, 0.0164, 0.0161, 0.0131, 0.0292, 0.0336, 0.0343, 0.0323,
        0.0146], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,988][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0032, 0.0921, 0.0201, 0.2632, 0.0764, 0.0866, 0.0568, 0.0835, 0.1547,
        0.1635], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,989][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2955, 0.0485, 0.1414, 0.0070, 0.1239, 0.1304, 0.0989, 0.0119, 0.0764,
        0.0660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,990][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3926, 0.0578, 0.1006, 0.0393, 0.0849, 0.0625, 0.1301, 0.0362, 0.0580,
        0.0380], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,991][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6983, 0.0248, 0.0320, 0.0161, 0.0387, 0.0383, 0.0563, 0.0426, 0.0359,
        0.0171], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,993][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8051, 0.0238, 0.0246, 0.0259, 0.0166, 0.0108, 0.0404, 0.0273, 0.0148,
        0.0108], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,995][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3750, 0.0359, 0.1506, 0.0166, 0.0934, 0.0500, 0.0741, 0.0485, 0.1074,
        0.0485], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,996][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0662, 0.0498, 0.2160, 0.0038, 0.3040, 0.0646, 0.1287, 0.0088, 0.0931,
        0.0650], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,998][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7740, 0.0132, 0.0183, 0.0051, 0.0125, 0.0757, 0.0186, 0.0052, 0.0248,
        0.0524], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:46,999][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0128, 0.0722, 0.1792, 0.1107, 0.2262, 0.0676, 0.0600, 0.0643, 0.1119,
        0.0950], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,001][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3239, 0.0722, 0.0531, 0.0330, 0.0469, 0.0813, 0.1044, 0.0995, 0.1028,
        0.0830], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,002][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.2319e-02, 6.1491e-03, 1.8487e-01, 1.5134e-04, 3.1922e-01, 3.5547e-03,
        7.2383e-02, 5.6655e-04, 1.9839e-01, 1.3247e-01, 5.9924e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,003][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.2545, 0.0350, 0.0423, 0.0443, 0.0458, 0.0851, 0.1186, 0.1067, 0.1317,
        0.0704, 0.0657], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,003][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0006, 0.1221, 0.0171, 0.2776, 0.0930, 0.0921, 0.0290, 0.0593, 0.0757,
        0.1662, 0.0673], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,003][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2537, 0.0314, 0.1190, 0.0060, 0.1028, 0.1148, 0.0627, 0.0131, 0.0905,
        0.0673, 0.1388], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,004][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0987, 0.0737, 0.1201, 0.0572, 0.1111, 0.0847, 0.1777, 0.0556, 0.0788,
        0.0872, 0.0551], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,004][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5941, 0.0325, 0.0444, 0.0219, 0.0477, 0.0561, 0.0679, 0.0564, 0.0376,
        0.0212, 0.0201], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,005][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8886, 0.0143, 0.0129, 0.0150, 0.0099, 0.0070, 0.0223, 0.0131, 0.0070,
        0.0058, 0.0041], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,005][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1633, 0.1000, 0.1861, 0.0266, 0.0990, 0.0699, 0.0830, 0.0478, 0.1072,
        0.0546, 0.0625], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,005][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0674, 0.0242, 0.2255, 0.0034, 0.2610, 0.0453, 0.0762, 0.0064, 0.0716,
        0.0742, 0.1449], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,006][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4612, 0.0211, 0.0347, 0.0075, 0.0265, 0.1184, 0.0303, 0.0087, 0.0553,
        0.1222, 0.1141], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,006][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0022, 0.0800, 0.0762, 0.1514, 0.2021, 0.0651, 0.0522, 0.0552, 0.1198,
        0.1210, 0.0748], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,008][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2142, 0.1109, 0.0598, 0.0427, 0.0443, 0.0749, 0.1027, 0.0997, 0.0932,
        0.0838, 0.0738], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,009][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([1.5343e-02, 9.2520e-06, 1.3413e-03, 2.0788e-07, 6.6875e-04, 5.0173e-05,
        4.1384e-04, 1.9036e-06, 7.7611e-04, 2.4486e-04, 5.3178e-04, 9.8062e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,010][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.6674, 0.0114, 0.0172, 0.0257, 0.0163, 0.0543, 0.0437, 0.0455, 0.0325,
        0.0255, 0.0397, 0.0208], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,012][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.0002, 0.0828, 0.0149, 0.2108, 0.0620, 0.0954, 0.0276, 0.0595, 0.0563,
        0.2062, 0.1168, 0.0674], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,013][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([1.2080e-01, 4.1721e-03, 2.6358e-02, 5.2185e-04, 1.3876e-02, 3.5038e-02,
        7.8966e-03, 1.2566e-03, 8.1770e-03, 7.7727e-03, 2.8176e-02, 7.4596e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,015][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.5393, 0.0415, 0.0458, 0.0252, 0.0599, 0.0302, 0.0730, 0.0239, 0.0351,
        0.0385, 0.0263, 0.0614], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,017][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.7223, 0.0251, 0.0259, 0.0188, 0.0289, 0.0252, 0.0392, 0.0388, 0.0213,
        0.0134, 0.0121, 0.0289], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,018][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.5251, 0.0317, 0.0385, 0.0433, 0.0366, 0.0335, 0.1053, 0.0548, 0.0259,
        0.0281, 0.0202, 0.0570], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,020][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0931, 0.0469, 0.1107, 0.0189, 0.0719, 0.0668, 0.0514, 0.0322, 0.0702,
        0.0506, 0.0940, 0.2933], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,020][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([1.4864e-02, 7.0517e-04, 1.5782e-02, 6.7157e-05, 8.8515e-03, 4.3871e-03,
        2.6099e-03, 1.4851e-04, 2.6059e-03, 2.8993e-03, 1.7091e-02, 9.2999e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,020][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.5731, 0.0085, 0.0203, 0.0037, 0.0124, 0.0629, 0.0153, 0.0041, 0.0232,
        0.0484, 0.0474, 0.1808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,021][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.0024, 0.0670, 0.1307, 0.1110, 0.1543, 0.0790, 0.0327, 0.0441, 0.0670,
        0.1064, 0.1186, 0.0867], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,021][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.1076, 0.0654, 0.0646, 0.0404, 0.0860, 0.0860, 0.0864, 0.0643, 0.0821,
        0.0916, 0.1230, 0.1025], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,022][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([5.3309e-04, 1.3806e-04, 1.5946e-03, 4.4864e-06, 2.8932e-03, 8.5457e-05,
        9.8239e-04, 2.3969e-05, 1.9094e-03, 1.6036e-03, 1.4461e-03, 9.8868e-01,
        1.0521e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,022][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.5688, 0.0182, 0.0279, 0.0191, 0.0207, 0.0369, 0.0597, 0.0548, 0.0619,
        0.0259, 0.0379, 0.0439, 0.0243], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,023][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0006, 0.1056, 0.0225, 0.1787, 0.1075, 0.0796, 0.0326, 0.0505, 0.0635,
        0.1258, 0.0814, 0.0906, 0.0612], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,023][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0657, 0.0127, 0.0277, 0.0024, 0.0254, 0.0353, 0.0196, 0.0047, 0.0251,
        0.0188, 0.0490, 0.6803, 0.0334], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,023][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3907, 0.0349, 0.0545, 0.0224, 0.0710, 0.0565, 0.0887, 0.0327, 0.0372,
        0.0342, 0.0402, 0.0986, 0.0385], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,025][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.7013, 0.0154, 0.0272, 0.0121, 0.0276, 0.0328, 0.0464, 0.0385, 0.0314,
        0.0110, 0.0139, 0.0344, 0.0079], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,027][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.7130, 0.0301, 0.0231, 0.0275, 0.0127, 0.0143, 0.0458, 0.0492, 0.0193,
        0.0161, 0.0114, 0.0175, 0.0201], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,028][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1133, 0.0397, 0.1283, 0.0173, 0.0744, 0.0477, 0.0392, 0.0361, 0.0553,
        0.0381, 0.0661, 0.2366, 0.1079], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,029][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.6254e-03, 3.1764e-03, 1.2689e-02, 3.7527e-04, 1.4481e-02, 3.7651e-03,
        8.8532e-03, 8.2167e-04, 6.9116e-03, 6.2585e-03, 1.8644e-02, 9.1366e-01,
        6.7380e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,031][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.4029, 0.0115, 0.0166, 0.0048, 0.0113, 0.0702, 0.0159, 0.0059, 0.0278,
        0.0606, 0.0762, 0.2592, 0.0371], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,033][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0016, 0.0526, 0.0979, 0.0922, 0.2038, 0.0417, 0.0265, 0.0342, 0.0484,
        0.0682, 0.0567, 0.1694, 0.1069], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,034][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1119, 0.0703, 0.0580, 0.0351, 0.0583, 0.0664, 0.0886, 0.0812, 0.0848,
        0.0827, 0.0941, 0.0663, 0.1023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,035][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([2.7452e-02, 6.0543e-07, 3.1082e-04, 2.1389e-08, 6.5675e-05, 8.7428e-06,
        5.7984e-05, 2.7665e-07, 1.3592e-04, 3.2073e-05, 4.8540e-05, 2.2623e-01,
        1.8760e-05, 7.4564e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,037][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.6235, 0.0076, 0.0167, 0.0094, 0.0207, 0.0367, 0.0456, 0.0400, 0.0451,
        0.0217, 0.0225, 0.0289, 0.0147, 0.0669], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,037][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0002, 0.0593, 0.0165, 0.1689, 0.0633, 0.0696, 0.0223, 0.0524, 0.0795,
        0.1576, 0.0881, 0.0829, 0.0936, 0.0458], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,038][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([9.1682e-02, 2.8613e-03, 2.1928e-02, 3.2689e-04, 8.8346e-03, 2.1395e-02,
        5.4624e-03, 7.7182e-04, 5.2093e-03, 4.2042e-03, 1.2875e-02, 3.4550e-01,
        1.7553e-02, 4.6140e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,038][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.6744, 0.0246, 0.0292, 0.0154, 0.0272, 0.0181, 0.0388, 0.0137, 0.0165,
        0.0206, 0.0178, 0.0374, 0.0340, 0.0325], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,038][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.7182, 0.0155, 0.0241, 0.0213, 0.0195, 0.0310, 0.0282, 0.0300, 0.0216,
        0.0129, 0.0155, 0.0331, 0.0156, 0.0135], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,039][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.3819, 0.0433, 0.0382, 0.0509, 0.0377, 0.0450, 0.0844, 0.0552, 0.0320,
        0.0423, 0.0286, 0.0457, 0.0565, 0.0581], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,039][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0356, 0.0385, 0.0871, 0.0136, 0.0581, 0.0460, 0.0397, 0.0396, 0.0519,
        0.0463, 0.0642, 0.1789, 0.1130, 0.1874], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,040][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([6.0153e-03, 6.4967e-04, 1.1114e-02, 7.4647e-05, 7.3283e-03, 3.8499e-03,
        3.4657e-03, 2.3479e-04, 2.1626e-03, 1.7601e-03, 8.7881e-03, 4.0651e-01,
        6.9462e-03, 5.4110e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,040][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.7653, 0.0030, 0.0060, 0.0009, 0.0032, 0.0233, 0.0059, 0.0012, 0.0069,
        0.0157, 0.0138, 0.0681, 0.0099, 0.0766], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,041][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0019, 0.0616, 0.1328, 0.1062, 0.0938, 0.0483, 0.0273, 0.0290, 0.0953,
        0.0824, 0.0686, 0.1049, 0.0890, 0.0591], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,043][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0467, 0.0673, 0.0352, 0.0448, 0.0415, 0.0668, 0.0814, 0.0742, 0.0854,
        0.0857, 0.0910, 0.0950, 0.1170, 0.0680], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,044][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([1.2673e-02, 2.9194e-06, 2.8409e-04, 3.7076e-08, 9.3113e-05, 8.5428e-06,
        6.2548e-05, 5.0172e-07, 8.3260e-05, 5.7756e-05, 6.4197e-05, 1.5430e-01,
        2.4461e-05, 7.6612e-01, 6.6233e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,046][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.6247, 0.0089, 0.0203, 0.0149, 0.0184, 0.0283, 0.0348, 0.0457, 0.0309,
        0.0163, 0.0286, 0.0233, 0.0129, 0.0470, 0.0450], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,047][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0002, 0.0954, 0.0137, 0.1345, 0.0749, 0.0545, 0.0206, 0.0432, 0.0393,
        0.1397, 0.0842, 0.0692, 0.1187, 0.0492, 0.0626], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,049][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0342, 0.0040, 0.0162, 0.0004, 0.0093, 0.0169, 0.0061, 0.0012, 0.0050,
        0.0044, 0.0121, 0.2267, 0.0153, 0.3852, 0.2630], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,051][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.3700, 0.0383, 0.0411, 0.0284, 0.0484, 0.0372, 0.0690, 0.0345, 0.0381,
        0.0418, 0.0371, 0.0616, 0.0460, 0.0518, 0.0566], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,052][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.5407, 0.0262, 0.0351, 0.0242, 0.0355, 0.0398, 0.0495, 0.0496, 0.0374,
        0.0187, 0.0209, 0.0495, 0.0136, 0.0252, 0.0341], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,054][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.5221, 0.0559, 0.0330, 0.0510, 0.0299, 0.0229, 0.0594, 0.0374, 0.0151,
        0.0279, 0.0111, 0.0293, 0.0450, 0.0361, 0.0238], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,054][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0562, 0.0341, 0.0899, 0.0143, 0.0410, 0.0419, 0.0386, 0.0335, 0.0558,
        0.0297, 0.0662, 0.1957, 0.0857, 0.0959, 0.1216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,055][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([2.9218e-03, 9.5286e-04, 1.0043e-02, 6.6998e-05, 5.9454e-03, 2.8842e-03,
        3.7799e-03, 2.8981e-04, 1.9060e-03, 1.6898e-03, 5.5393e-03, 4.7772e-01,
        4.4074e-03, 3.5865e-01, 1.2320e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,055][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.5840, 0.0027, 0.0068, 0.0008, 0.0032, 0.0203, 0.0045, 0.0010, 0.0052,
        0.0104, 0.0114, 0.0546, 0.0086, 0.0625, 0.2238], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,056][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0019, 0.0485, 0.0763, 0.0854, 0.1627, 0.0461, 0.0150, 0.0286, 0.0305,
        0.0556, 0.0701, 0.0967, 0.0905, 0.1632, 0.0288], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,056][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0969, 0.0596, 0.0469, 0.0333, 0.0383, 0.0733, 0.0596, 0.0533, 0.0644,
        0.0672, 0.0891, 0.0568, 0.1176, 0.0634, 0.0803], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,057][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.4705e-04, 2.4684e-06, 2.6970e-04, 6.4619e-08, 1.6620e-04, 4.1995e-06,
        3.6797e-05, 2.1268e-07, 8.9323e-05, 3.3628e-05, 3.6637e-05, 1.2132e-01,
        8.1493e-06, 8.1528e-01, 6.0814e-02, 9.8415e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,057][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.6818, 0.0078, 0.0123, 0.0120, 0.0100, 0.0241, 0.0226, 0.0287, 0.0260,
        0.0110, 0.0226, 0.0176, 0.0135, 0.0349, 0.0631, 0.0118],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,057][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0036, 0.0659, 0.0179, 0.1276, 0.0548, 0.0478, 0.0442, 0.0543, 0.0908,
        0.0913, 0.0575, 0.0475, 0.0535, 0.0492, 0.1185, 0.0757],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,059][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0820, 0.0021, 0.0154, 0.0004, 0.0086, 0.0121, 0.0065, 0.0008, 0.0044,
        0.0034, 0.0100, 0.1647, 0.0091, 0.3424, 0.3124, 0.0256],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,060][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2837, 0.0367, 0.0653, 0.0251, 0.0546, 0.0404, 0.0814, 0.0249, 0.0356,
        0.0256, 0.0364, 0.0901, 0.0511, 0.0608, 0.0657, 0.0225],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,062][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6230, 0.0179, 0.0257, 0.0129, 0.0313, 0.0327, 0.0482, 0.0346, 0.0314,
        0.0134, 0.0162, 0.0438, 0.0088, 0.0239, 0.0276, 0.0085],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,063][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7615, 0.0196, 0.0171, 0.0222, 0.0109, 0.0093, 0.0301, 0.0214, 0.0135,
        0.0099, 0.0062, 0.0184, 0.0183, 0.0152, 0.0167, 0.0096],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,065][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2291, 0.0161, 0.0785, 0.0066, 0.0391, 0.0212, 0.0279, 0.0196, 0.0397,
        0.0175, 0.0357, 0.1193, 0.0473, 0.1572, 0.1193, 0.0257],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,066][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.2487e-03, 6.0374e-04, 9.4833e-03, 4.8920e-05, 8.6560e-03, 1.8006e-03,
        3.0544e-03, 2.1806e-04, 1.7977e-03, 1.1311e-03, 3.7029e-03, 3.6260e-01,
        2.6852e-03, 4.2999e-01, 1.5612e-01, 1.2853e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,068][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5507, 0.0021, 0.0058, 0.0008, 0.0029, 0.0180, 0.0040, 0.0008, 0.0048,
        0.0090, 0.0106, 0.0430, 0.0065, 0.0527, 0.2226, 0.0657],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,069][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0098, 0.0320, 0.1047, 0.0477, 0.1194, 0.0329, 0.0291, 0.0294, 0.0501,
        0.0384, 0.0434, 0.1122, 0.0728, 0.1381, 0.0790, 0.0609],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,071][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2169, 0.0440, 0.0334, 0.0190, 0.0308, 0.0450, 0.0568, 0.0489, 0.0578,
        0.0476, 0.0736, 0.0498, 0.0762, 0.0568, 0.0826, 0.0609],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,071][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([4.6898e-03, 2.3476e-06, 4.3881e-04, 3.3251e-08, 1.3817e-04, 6.6651e-06,
        1.0574e-04, 4.7899e-07, 1.0046e-04, 4.8303e-05, 3.2931e-05, 1.9612e-01,
        1.3548e-05, 6.6811e-01, 8.2946e-02, 1.4952e-03, 4.5743e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,072][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.4365, 0.0107, 0.0190, 0.0162, 0.0198, 0.0493, 0.0454, 0.0599, 0.0405,
        0.0230, 0.0325, 0.0265, 0.0172, 0.0454, 0.0715, 0.0210, 0.0656],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,072][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0007, 0.0370, 0.0216, 0.0864, 0.0546, 0.0473, 0.0313, 0.0558, 0.0633,
        0.1386, 0.0781, 0.0556, 0.0694, 0.0355, 0.0649, 0.1283, 0.0317],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,073][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0448, 0.0025, 0.0174, 0.0003, 0.0071, 0.0154, 0.0046, 0.0009, 0.0042,
        0.0033, 0.0086, 0.2222, 0.0099, 0.2725, 0.2421, 0.0236, 0.1206],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,073][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.3227, 0.0325, 0.0310, 0.0258, 0.0424, 0.0348, 0.0758, 0.0249, 0.0367,
        0.0323, 0.0300, 0.0558, 0.0500, 0.0505, 0.0635, 0.0255, 0.0658],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,074][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.5047, 0.0280, 0.0338, 0.0212, 0.0347, 0.0418, 0.0595, 0.0558, 0.0335,
        0.0148, 0.0186, 0.0372, 0.0140, 0.0231, 0.0314, 0.0095, 0.0383],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,074][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.6688, 0.0180, 0.0211, 0.0220, 0.0242, 0.0194, 0.0365, 0.0244, 0.0097,
        0.0151, 0.0092, 0.0213, 0.0216, 0.0310, 0.0222, 0.0156, 0.0199],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,075][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.1036, 0.0462, 0.0971, 0.0092, 0.0433, 0.0364, 0.0330, 0.0248, 0.0269,
        0.0211, 0.0409, 0.1280, 0.0617, 0.1039, 0.1115, 0.0255, 0.0869],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,076][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([4.2647e-03, 4.6491e-04, 9.3841e-03, 3.3587e-05, 6.0610e-03, 1.8452e-03,
        2.8458e-03, 1.6821e-04, 1.0244e-03, 1.1141e-03, 3.2515e-03, 2.9690e-01,
        2.4212e-03, 3.4018e-01, 1.4984e-01, 1.1899e-02, 1.6831e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,077][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.4330, 0.0018, 0.0054, 0.0006, 0.0025, 0.0173, 0.0041, 0.0008, 0.0043,
        0.0094, 0.0081, 0.0367, 0.0061, 0.0413, 0.1803, 0.0647, 0.1836],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,079][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0035, 0.0289, 0.1370, 0.0547, 0.1015, 0.0545, 0.0258, 0.0262, 0.0505,
        0.0587, 0.0731, 0.0718, 0.0838, 0.0886, 0.0484, 0.0641, 0.0292],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,081][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1226, 0.0312, 0.0351, 0.0211, 0.0337, 0.0491, 0.0553, 0.0408, 0.0583,
        0.0516, 0.0799, 0.0655, 0.0848, 0.0678, 0.0774, 0.0742, 0.0516],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,082][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.1847e-04, 9.0304e-06, 6.1602e-04, 4.3416e-07, 4.5330e-04, 1.2564e-05,
        1.8764e-04, 1.3639e-06, 2.3444e-04, 1.5728e-04, 5.9808e-05, 2.0814e-01,
        2.6016e-05, 5.9575e-01, 9.0316e-02, 3.1625e-03, 9.9598e-02, 1.0625e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,084][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3235, 0.0119, 0.0147, 0.0156, 0.0143, 0.0369, 0.0406, 0.0472, 0.0472,
        0.0261, 0.0301, 0.0294, 0.0225, 0.0546, 0.1066, 0.0274, 0.1122, 0.0392],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,085][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0004, 0.0845, 0.0153, 0.1614, 0.0619, 0.0508, 0.0279, 0.0397, 0.0427,
        0.1017, 0.0340, 0.0456, 0.0573, 0.0313, 0.0776, 0.0944, 0.0400, 0.0335],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,087][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0699, 0.0030, 0.0182, 0.0005, 0.0093, 0.0149, 0.0070, 0.0012, 0.0048,
        0.0040, 0.0083, 0.1645, 0.0118, 0.2565, 0.2271, 0.0245, 0.1138, 0.0607],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,088][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0778, 0.0439, 0.0608, 0.0348, 0.0598, 0.0517, 0.0882, 0.0300, 0.0386,
        0.0434, 0.0399, 0.0945, 0.0620, 0.0703, 0.0612, 0.0397, 0.0741, 0.0291],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,089][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5262, 0.0226, 0.0270, 0.0182, 0.0280, 0.0386, 0.0444, 0.0397, 0.0296,
        0.0181, 0.0156, 0.0376, 0.0127, 0.0208, 0.0288, 0.0122, 0.0615, 0.0182],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,089][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8706, 0.0122, 0.0099, 0.0105, 0.0062, 0.0056, 0.0164, 0.0067, 0.0060,
        0.0039, 0.0026, 0.0053, 0.0108, 0.0099, 0.0070, 0.0040, 0.0086, 0.0038],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,090][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0806, 0.0225, 0.0790, 0.0099, 0.0395, 0.0247, 0.0255, 0.0200, 0.0383,
        0.0233, 0.0342, 0.0966, 0.0627, 0.1101, 0.1422, 0.0301, 0.1187, 0.0423],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,090][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([6.4703e-03, 8.0420e-04, 1.3108e-02, 9.1752e-05, 9.4268e-03, 2.5016e-03,
        4.0946e-03, 3.2313e-04, 1.7954e-03, 1.8006e-03, 3.0451e-03, 2.4190e-01,
        2.8678e-03, 2.6407e-01, 1.4072e-01, 1.3416e-02, 2.5794e-01, 3.5632e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,091][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2634, 0.0020, 0.0061, 0.0006, 0.0031, 0.0152, 0.0038, 0.0009, 0.0041,
        0.0089, 0.0078, 0.0440, 0.0067, 0.0532, 0.1947, 0.0602, 0.2200, 0.1052],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,091][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0014, 0.0657, 0.0534, 0.0863, 0.1539, 0.0289, 0.0278, 0.0190, 0.0269,
        0.0333, 0.0311, 0.0748, 0.0779, 0.0859, 0.0578, 0.0588, 0.0634, 0.0536],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,092][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0787, 0.0522, 0.0337, 0.0316, 0.0352, 0.0501, 0.0467, 0.0508, 0.0499,
        0.0536, 0.0735, 0.0467, 0.0931, 0.0471, 0.0826, 0.0708, 0.0431, 0.0605],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,092][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([5.4455e-03, 7.4109e-07, 1.4077e-04, 9.8523e-09, 4.2552e-05, 3.8403e-06,
        3.9582e-05, 1.8191e-07, 4.0967e-05, 1.5761e-05, 1.7689e-05, 8.1176e-02,
        6.2361e-06, 2.8055e-01, 3.8175e-02, 6.3662e-04, 2.8219e-02, 7.0254e-04,
        5.6478e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,094][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.5318, 0.0064, 0.0155, 0.0169, 0.0183, 0.0435, 0.0367, 0.0396, 0.0270,
        0.0156, 0.0181, 0.0203, 0.0136, 0.0470, 0.0450, 0.0119, 0.0469, 0.0220,
        0.0241], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,095][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([2.6480e-05, 3.4422e-02, 6.9004e-03, 1.0479e-01, 5.2655e-02, 4.2044e-02,
        1.7375e-02, 3.1854e-02, 4.1949e-02, 1.3201e-01, 5.8060e-02, 5.9124e-02,
        6.1750e-02, 2.5842e-02, 6.8026e-02, 1.2601e-01, 4.3555e-02, 7.5481e-02,
        1.8127e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,096][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([3.3809e-02, 1.3749e-03, 7.4181e-03, 1.6988e-04, 3.6068e-03, 9.6926e-03,
        3.0360e-03, 4.8876e-04, 1.7634e-03, 1.7685e-03, 4.8914e-03, 8.4740e-02,
        8.0712e-03, 1.4219e-01, 9.7822e-02, 1.1625e-02, 5.1864e-02, 4.2278e-02,
        4.9339e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,098][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.5361, 0.0228, 0.0208, 0.0165, 0.0310, 0.0179, 0.0397, 0.0179, 0.0206,
        0.0281, 0.0169, 0.0358, 0.0313, 0.0326, 0.0344, 0.0227, 0.0364, 0.0162,
        0.0223], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,099][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.6409, 0.0187, 0.0205, 0.0160, 0.0275, 0.0209, 0.0255, 0.0292, 0.0160,
        0.0139, 0.0147, 0.0287, 0.0110, 0.0173, 0.0167, 0.0090, 0.0342, 0.0189,
        0.0205], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,101][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.3602, 0.0175, 0.0221, 0.0254, 0.0256, 0.0353, 0.0654, 0.0602, 0.0237,
        0.0216, 0.0243, 0.0466, 0.0309, 0.0403, 0.0699, 0.0209, 0.0418, 0.0324,
        0.0360], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,103][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0109, 0.0225, 0.0534, 0.0111, 0.0382, 0.0329, 0.0294, 0.0190, 0.0362,
        0.0266, 0.0429, 0.1062, 0.0655, 0.0704, 0.1169, 0.0302, 0.0801, 0.0728,
        0.1350], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,104][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([4.7464e-03, 2.4157e-04, 5.2785e-03, 1.4697e-05, 2.3892e-03, 1.1588e-03,
        1.0712e-03, 7.8869e-05, 4.4787e-04, 5.2735e-04, 2.5422e-03, 1.0376e-01,
        2.0851e-03, 1.4034e-01, 5.1495e-02, 4.9995e-03, 9.4637e-02, 3.7705e-02,
        5.4648e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,106][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.2143, 0.0021, 0.0057, 0.0007, 0.0025, 0.0147, 0.0046, 0.0011, 0.0053,
        0.0096, 0.0088, 0.0402, 0.0057, 0.0410, 0.1842, 0.0576, 0.1796, 0.1248,
        0.0976], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,106][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0004, 0.0277, 0.0843, 0.0492, 0.1563, 0.0312, 0.0282, 0.0227, 0.0392,
        0.0336, 0.0350, 0.0603, 0.0543, 0.0893, 0.0596, 0.0430, 0.0684, 0.0926,
        0.0245], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,107][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0302, 0.0415, 0.0329, 0.0287, 0.0465, 0.0498, 0.0622, 0.0436, 0.0523,
        0.0549, 0.0673, 0.0555, 0.0660, 0.0557, 0.0525, 0.0597, 0.0436, 0.1086,
        0.0485], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,107][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.0942e-03, 3.1664e-06, 4.8099e-04, 1.3741e-07, 1.8640e-04, 1.3137e-05,
        7.9730e-05, 5.3085e-07, 9.3173e-05, 3.1681e-05, 3.2730e-05, 6.3155e-02,
        1.2835e-05, 2.7582e-01, 3.7707e-02, 6.8925e-04, 3.3963e-02, 8.8645e-04,
        5.7395e-01, 1.0799e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,107][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.5303, 0.0080, 0.0114, 0.0112, 0.0099, 0.0246, 0.0258, 0.0324, 0.0291,
        0.0118, 0.0216, 0.0201, 0.0140, 0.0351, 0.0694, 0.0124, 0.0697, 0.0234,
        0.0292, 0.0107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,108][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0024, 0.0573, 0.0149, 0.1070, 0.0477, 0.0368, 0.0396, 0.0465, 0.0754,
        0.0825, 0.0432, 0.0441, 0.0423, 0.0383, 0.0899, 0.0672, 0.0498, 0.0397,
        0.0305, 0.0449], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,108][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3873e-01, 1.6156e-03, 1.3710e-02, 2.8564e-04, 5.1070e-03, 1.1119e-02,
        5.1333e-03, 8.1349e-04, 2.7349e-03, 2.1808e-03, 5.8578e-03, 5.8358e-02,
        6.7129e-03, 1.2687e-01, 1.2612e-01, 1.1823e-02, 6.2874e-02, 3.9878e-02,
        3.1698e-01, 6.3096e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,109][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2446, 0.0290, 0.0585, 0.0208, 0.0473, 0.0359, 0.0725, 0.0218, 0.0286,
        0.0211, 0.0288, 0.0745, 0.0412, 0.0488, 0.0542, 0.0177, 0.0591, 0.0346,
        0.0462, 0.0148], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,110][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4210, 0.0201, 0.0320, 0.0152, 0.0380, 0.0430, 0.0654, 0.0455, 0.0380,
        0.0150, 0.0203, 0.0521, 0.0105, 0.0277, 0.0296, 0.0094, 0.0571, 0.0217,
        0.0297, 0.0087], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,112][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8064, 0.0125, 0.0112, 0.0140, 0.0070, 0.0066, 0.0216, 0.0155, 0.0097,
        0.0062, 0.0041, 0.0112, 0.0114, 0.0098, 0.0120, 0.0060, 0.0135, 0.0041,
        0.0127, 0.0048], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,113][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1923, 0.0118, 0.0573, 0.0051, 0.0273, 0.0141, 0.0208, 0.0153, 0.0292,
        0.0136, 0.0240, 0.0820, 0.0352, 0.1029, 0.0756, 0.0182, 0.0756, 0.0311,
        0.1407, 0.0278], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,115][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.0593e-02, 4.9374e-04, 8.5136e-03, 4.5692e-05, 5.1451e-03, 1.9607e-03,
        2.9509e-03, 2.6094e-04, 1.1261e-03, 7.7612e-04, 2.3226e-03, 9.2933e-02,
        2.3207e-03, 1.4083e-01, 6.6175e-02, 6.5064e-03, 1.2138e-01, 2.9487e-02,
        4.5369e-01, 5.2495e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,116][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.7985e-01, 7.7856e-04, 2.6479e-03, 2.5273e-04, 1.0429e-03, 6.8371e-03,
        1.6171e-03, 3.3274e-04, 1.6104e-03, 2.6970e-03, 2.8473e-03, 1.1489e-02,
        2.0898e-03, 1.3866e-02, 5.4732e-02, 1.5916e-02, 5.2598e-02, 3.9855e-02,
        3.0251e-02, 7.8686e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,116][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0064, 0.0216, 0.0756, 0.0287, 0.1029, 0.0208, 0.0227, 0.0220, 0.0375,
        0.0253, 0.0264, 0.0831, 0.0440, 0.1080, 0.0517, 0.0394, 0.0690, 0.0655,
        0.1186, 0.0306], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,118][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1504, 0.0335, 0.0276, 0.0175, 0.0275, 0.0398, 0.0470, 0.0391, 0.0499,
        0.0420, 0.0611, 0.0455, 0.0589, 0.0483, 0.0681, 0.0518, 0.0412, 0.0511,
        0.0569, 0.0429], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,120][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:47,122][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14763],
        [ 2620],
        [ 9027],
        [  126],
        [  381],
        [   61],
        [ 1070],
        [   76],
        [  934],
        [  146],
        [   47],
        [  173],
        [  116],
        [  238],
        [  370],
        [  110],
        [  453],
        [   65],
        [  195],
        [   53]], device='cuda:0')
[2024-07-24 10:18:47,124][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15187],
        [18472],
        [25469],
        [ 2803],
        [ 1421],
        [  988],
        [ 6232],
        [ 2794],
        [ 7579],
        [ 3368],
        [ 1786],
        [ 2497],
        [ 2543],
        [ 1592],
        [ 4671],
        [ 2907],
        [ 5057],
        [ 2492],
        [ 1862],
        [ 1892]], device='cuda:0')
[2024-07-24 10:18:47,125][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38959],
        [33913],
        [29017],
        [28939],
        [29893],
        [32174],
        [33061],
        [33236],
        [33375],
        [33274],
        [33611],
        [33868],
        [33473],
        [33036],
        [33267],
        [33417],
        [33400],
        [33661],
        [33344],
        [33313]], device='cuda:0')
[2024-07-24 10:18:47,126][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43591],
        [45333],
        [47941],
        [46761],
        [45465],
        [44162],
        [43065],
        [42827],
        [41643],
        [41121],
        [39702],
        [39451],
        [40804],
        [36987],
        [36540],
        [36695],
        [35817],
        [35983],
        [35106],
        [35338]], device='cuda:0')
[2024-07-24 10:18:47,127][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25991],
        [41463],
        [42926],
        [50229],
        [49593],
        [42702],
        [43399],
        [47276],
        [38362],
        [44955],
        [29308],
        [26237],
        [39921],
        [38755],
        [38287],
        [41475],
        [26582],
        [30186],
        [22126],
        [38181]], device='cuda:0')
[2024-07-24 10:18:47,129][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11862],
        [14966],
        [27433],
        [21278],
        [16836],
        [14287],
        [13313],
        [13900],
        [13506],
        [12697],
        [12265],
        [11914],
        [11196],
        [11163],
        [10937],
        [10877],
        [10912],
        [10554],
        [ 9724],
        [ 9696]], device='cuda:0')
[2024-07-24 10:18:47,131][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1294],
        [1488],
        [1349],
        [1349],
        [1244],
        [1194],
        [ 969],
        [ 896],
        [1199],
        [1297],
        [1586],
        [2473],
        [2397],
        [1212],
        [1477],
        [1759],
        [1695],
        [2052],
        [3592],
        [3399]], device='cuda:0')
[2024-07-24 10:18:47,132][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43905],
        [40102],
        [ 6923],
        [11383],
        [22244],
        [22183],
        [23951],
        [25385],
        [25374],
        [26439],
        [27769],
        [27915],
        [27991],
        [29673],
        [29570],
        [29701],
        [29719],
        [30155],
        [31261],
        [30831]], device='cuda:0')
[2024-07-24 10:18:47,134][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[409],
        [239],
        [366],
        [443],
        [962],
        [857],
        [635],
        [440],
        [350],
        [279],
        [247],
        [242],
        [233],
        [238],
        [237],
        [230],
        [228],
        [219],
        [199],
        [194]], device='cuda:0')
[2024-07-24 10:18:47,136][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35615],
        [32949],
        [39104],
        [40543],
        [40400],
        [39265],
        [37255],
        [36126],
        [38530],
        [38952],
        [36928],
        [33467],
        [33085],
        [33116],
        [31283],
        [33267],
        [30920],
        [29930],
        [26056],
        [28315]], device='cuda:0')
[2024-07-24 10:18:47,138][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26365],
        [26365],
        [26375],
        [26431],
        [26400],
        [26425],
        [26497],
        [26639],
        [26430],
        [26374],
        [26413],
        [26360],
        [26335],
        [26385],
        [26369],
        [26376],
        [26362],
        [26348],
        [26418],
        [26376]], device='cuda:0')
[2024-07-24 10:18:47,139][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19757],
        [30003],
        [   55],
        [   11],
        [  605],
        [15116],
        [ 9239],
        [ 5873],
        [ 5117],
        [ 7396],
        [ 5066],
        [14001],
        [15031],
        [19156],
        [22856],
        [20487],
        [19939],
        [21865],
        [15436],
        [19102]], device='cuda:0')
[2024-07-24 10:18:47,141][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[20829],
        [13693],
        [49606],
        [47076],
        [49378],
        [32029],
        [36596],
        [46803],
        [31794],
        [40377],
        [33417],
        [41524],
        [42637],
        [43324],
        [38158],
        [40438],
        [46971],
        [40727],
        [46085],
        [31970]], device='cuda:0')
[2024-07-24 10:18:47,142][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23393],
        [14255],
        [19294],
        [18639],
        [19962],
        [19595],
        [18123],
        [17696],
        [17708],
        [17084],
        [17134],
        [17464],
        [17486],
        [18128],
        [18159],
        [18003],
        [18191],
        [18035],
        [17872],
        [17860]], device='cuda:0')
[2024-07-24 10:18:47,143][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[27531],
        [ 1425],
        [  992],
        [  964],
        [ 3179],
        [ 2273],
        [ 7096],
        [ 1239],
        [11763],
        [ 4052],
        [ 6009],
        [ 6193],
        [ 4190],
        [ 8415],
        [ 1613],
        [ 2931],
        [ 7475],
        [ 3557],
        [ 7755],
        [ 4246]], device='cuda:0')
[2024-07-24 10:18:47,144][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 8530],
        [21625],
        [22328],
        [28727],
        [25647],
        [28269],
        [31698],
        [31640],
        [30645],
        [31437],
        [31071],
        [37406],
        [37376],
        [29622],
        [28678],
        [28126],
        [30082],
        [30936],
        [27855],
        [27831]], device='cuda:0')
[2024-07-24 10:18:47,146][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[30048],
        [30651],
        [28261],
        [25095],
        [28184],
        [17313],
        [21523],
        [12444],
        [ 9564],
        [16945],
        [ 9040],
        [11297],
        [ 9341],
        [ 9394],
        [ 9516],
        [10577],
        [ 8372],
        [ 8102],
        [ 8589],
        [ 8479]], device='cuda:0')
[2024-07-24 10:18:47,147][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28770],
        [ 2953],
        [ 2043],
        [ 3860],
        [ 2689],
        [ 2856],
        [ 3321],
        [ 3660],
        [ 3522],
        [ 4997],
        [ 4337],
        [ 6424],
        [ 5740],
        [ 6069],
        [ 6327],
        [ 8078],
        [ 7791],
        [ 8316],
        [10693],
        [10329]], device='cuda:0')
[2024-07-24 10:18:47,149][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31747],
        [39171],
        [34612],
        [32205],
        [37362],
        [37846],
        [37700],
        [35934],
        [35654],
        [36157],
        [32938],
        [15495],
        [16603],
        [22470],
        [32008],
        [35705],
        [30198],
        [32401],
        [19874],
        [25131]], device='cuda:0')
[2024-07-24 10:18:47,151][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[27677],
        [11298],
        [ 6374],
        [ 1923],
        [ 1856],
        [ 1631],
        [ 1481],
        [ 1056],
        [ 1193],
        [ 1219],
        [ 1239],
        [ 1167],
        [ 1043],
        [ 1253],
        [ 1087],
        [ 1059],
        [ 1100],
        [ 1106],
        [ 1191],
        [ 1144]], device='cuda:0')
[2024-07-24 10:18:47,153][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11317],
        [12149],
        [13162],
        [23337],
        [17078],
        [25210],
        [26787],
        [30988],
        [33395],
        [33616],
        [33864],
        [32691],
        [33715],
        [32013],
        [30046],
        [32226],
        [28220],
        [27506],
        [31522],
        [24179]], device='cuda:0')
[2024-07-24 10:18:47,154][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34849],
        [34382],
        [32890],
        [33494],
        [29463],
        [33393],
        [31436],
        [36060],
        [32426],
        [31873],
        [33862],
        [38949],
        [32788],
        [35759],
        [34570],
        [33994],
        [33061],
        [35094],
        [37714],
        [35311]], device='cuda:0')
[2024-07-24 10:18:47,156][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[46997],
        [31891],
        [29963],
        [33715],
        [31622],
        [30511],
        [32979],
        [34781],
        [36168],
        [40847],
        [38156],
        [41420],
        [41268],
        [39860],
        [40504],
        [41269],
        [41208],
        [41402],
        [41002],
        [42681]], device='cuda:0')
[2024-07-24 10:18:47,158][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32578],
        [34747],
        [11509],
        [12872],
        [ 8763],
        [14427],
        [22399],
        [20677],
        [19230],
        [22534],
        [23058],
        [18263],
        [18283],
        [12844],
        [19014],
        [20464],
        [24265],
        [27292],
        [22057],
        [22232]], device='cuda:0')
[2024-07-24 10:18:47,160][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39233],
        [28924],
        [31310],
        [25299],
        [35064],
        [29462],
        [30500],
        [31105],
        [32503],
        [33779],
        [33756],
        [33444],
        [33304],
        [36769],
        [33331],
        [33395],
        [37102],
        [36532],
        [36050],
        [36283]], device='cuda:0')
[2024-07-24 10:18:47,161][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46934],
        [46656],
        [36783],
        [32384],
        [16424],
        [ 9710],
        [23580],
        [11678],
        [11583],
        [13748],
        [18527],
        [22617],
        [20849],
        [22321],
        [17516],
        [20017],
        [20875],
        [19905],
        [17426],
        [19710]], device='cuda:0')
[2024-07-24 10:18:47,162][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14029],
        [16549],
        [16334],
        [16351],
        [14531],
        [13676],
        [12923],
        [10420],
        [11644],
        [10999],
        [10227],
        [ 7431],
        [ 6543],
        [ 5871],
        [ 6187],
        [ 6271],
        [ 5352],
        [ 5446],
        [ 5487],
        [ 5648]], device='cuda:0')
[2024-07-24 10:18:47,163][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7511],
        [14839],
        [27272],
        [28214],
        [30773],
        [34008],
        [25864],
        [28597],
        [30396],
        [24186],
        [26152],
        [24191],
        [26268],
        [31510],
        [29112],
        [26132],
        [27383],
        [25607],
        [31460],
        [28837]], device='cuda:0')
[2024-07-24 10:18:47,164][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 5612],
        [38970],
        [45177],
        [43761],
        [45163],
        [44097],
        [38798],
        [44251],
        [43525],
        [40993],
        [44256],
        [46216],
        [46913],
        [42757],
        [46221],
        [44737],
        [44928],
        [45694],
        [41606],
        [44318]], device='cuda:0')
[2024-07-24 10:18:47,166][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612],
        [9612]], device='cuda:0')
[2024-07-24 10:18:47,218][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:47,218][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,219][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,219][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,219][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,219][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,220][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,220][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,220][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,221][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,222][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,224][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,225][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,226][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9687, 0.0313], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,228][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0158, 0.9842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,229][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5011, 0.4989], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,231][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5590, 0.4410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,233][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,234][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0496, 0.9504], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,235][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0523, 0.9477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,235][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1547, 0.8453], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,235][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6877, 0.3123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,236][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6503, 0.3497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,236][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8095, 0.1905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,236][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3354, 0.6646], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,237][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.9377, 0.0376, 0.0246], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,237][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0056, 0.6449, 0.3495], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,237][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.3441, 0.3087, 0.3472], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,238][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.2515, 0.4006, 0.3479], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,238][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0018, 0.6569, 0.3413], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,239][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0581, 0.1385, 0.8035], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,240][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0394, 0.4354, 0.5252], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,242][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0300, 0.7703, 0.1998], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,244][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.4364, 0.3859, 0.1777], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,245][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.4496, 0.3432, 0.2072], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,247][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.8355, 0.1154, 0.0490], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,248][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.1868, 0.4143, 0.3990], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,250][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9397, 0.0265, 0.0181, 0.0156], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,251][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.7416e-04, 9.1038e-02, 8.2554e-01, 8.2648e-02], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,252][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3180, 0.2186, 0.2651, 0.1983], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,252][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2497, 0.2833, 0.4294, 0.0375], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,252][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0012, 0.5278, 0.2682, 0.2028], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,253][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0125, 0.0850, 0.7942, 0.1084], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,253][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0227, 0.2889, 0.3518, 0.3365], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,253][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0338, 0.5635, 0.3298, 0.0729], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,254][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3915, 0.3260, 0.2727, 0.0098], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,254][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4142, 0.3148, 0.2363, 0.0347], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,254][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7239, 0.1724, 0.0620, 0.0417], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,255][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1245, 0.2967, 0.3119, 0.2670], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,255][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.9507, 0.0240, 0.0130, 0.0088, 0.0035], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,256][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0099, 0.2291, 0.3579, 0.3614, 0.0417], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,258][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.3421, 0.1647, 0.1755, 0.1459, 0.1718], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,259][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.2357, 0.3411, 0.2806, 0.0172, 0.1255], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,261][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0009, 0.3698, 0.2082, 0.1274, 0.2937], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,262][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0252, 0.0396, 0.4389, 0.0425, 0.4538], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,264][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0231, 0.2135, 0.2560, 0.2345, 0.2729], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,265][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0285, 0.3545, 0.3642, 0.0243, 0.2284], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,267][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.2502, 0.4668, 0.2206, 0.0067, 0.0558], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,268][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.4211, 0.3074, 0.1975, 0.0158, 0.0581], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,269][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.8682, 0.0502, 0.0194, 0.0103, 0.0518], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,270][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0819, 0.2270, 0.2298, 0.1981, 0.2632], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,270][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.9281, 0.0167, 0.0119, 0.0078, 0.0041, 0.0314], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,270][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0030, 0.1503, 0.4524, 0.1527, 0.2360, 0.0056], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,271][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.2775, 0.1459, 0.1700, 0.1367, 0.1543, 0.1156], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,271][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.1543, 0.2333, 0.3030, 0.0358, 0.1829, 0.0908], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,271][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0012, 0.3138, 0.1315, 0.1122, 0.1963, 0.2449], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,272][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0029, 0.0500, 0.3924, 0.0543, 0.4757, 0.0248], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,272][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0113, 0.1638, 0.2176, 0.1921, 0.2378, 0.1774], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,272][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0805, 0.2551, 0.0583, 0.0341, 0.0851, 0.4870], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,273][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.5268, 0.1890, 0.1601, 0.0072, 0.0555, 0.0613], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,274][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.3762, 0.2048, 0.1742, 0.0244, 0.0660, 0.1544], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,275][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.7186, 0.0908, 0.0388, 0.0211, 0.0911, 0.0396], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,277][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0700, 0.1780, 0.1833, 0.1677, 0.2140, 0.1871], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,279][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.8047, 0.0382, 0.0229, 0.0143, 0.0065, 0.0638, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,280][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0047, 0.1166, 0.3641, 0.2057, 0.1087, 0.1846, 0.0157],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,282][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.2264, 0.1331, 0.1458, 0.1235, 0.1357, 0.1050, 0.1305],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,283][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0543, 0.2053, 0.2439, 0.0234, 0.1621, 0.1207, 0.1903],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,285][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0003, 0.2996, 0.0923, 0.0862, 0.1710, 0.2005, 0.1500],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,286][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0236, 0.0393, 0.1545, 0.0443, 0.2995, 0.0190, 0.4199],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,287][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0153, 0.1369, 0.1654, 0.1538, 0.1810, 0.1461, 0.2016],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,287][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0188, 0.3404, 0.0185, 0.0166, 0.0678, 0.4319, 0.1058],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,288][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.1381, 0.4312, 0.1681, 0.0071, 0.0654, 0.1156, 0.0746],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,288][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.2808, 0.2199, 0.1618, 0.0173, 0.0675, 0.1463, 0.1064],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,288][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.5397, 0.1289, 0.0295, 0.0251, 0.0643, 0.0392, 0.1733],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,289][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0574, 0.1484, 0.1494, 0.1238, 0.1722, 0.1583, 0.1904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,289][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.8064, 0.0307, 0.0242, 0.0143, 0.0075, 0.0497, 0.0436, 0.0237],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,289][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0032, 0.0834, 0.4750, 0.1181, 0.1625, 0.0831, 0.0705, 0.0041],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,290][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.1301, 0.1290, 0.1410, 0.1213, 0.1408, 0.1048, 0.1276, 0.1053],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,290][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0242, 0.2533, 0.2293, 0.0348, 0.1436, 0.0851, 0.1791, 0.0506],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,292][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0004, 0.3005, 0.0923, 0.0823, 0.1743, 0.1603, 0.1377, 0.0521],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,294][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0017, 0.0200, 0.1729, 0.0231, 0.3242, 0.0104, 0.4276, 0.0199],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,295][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0091, 0.1175, 0.1465, 0.1342, 0.1585, 0.1281, 0.1777, 0.1282],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,296][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0093, 0.3379, 0.0423, 0.0354, 0.1879, 0.2204, 0.1283, 0.0385],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,297][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.1033, 0.3462, 0.2548, 0.0116, 0.1016, 0.0806, 0.0861, 0.0158],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,299][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.2819, 0.1898, 0.1775, 0.0220, 0.0820, 0.1276, 0.0953, 0.0239],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,301][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.2427, 0.1755, 0.0773, 0.0593, 0.1171, 0.0667, 0.1800, 0.0814],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,303][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0503, 0.1277, 0.1398, 0.1129, 0.1559, 0.1355, 0.1661, 0.1118],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,304][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.8442, 0.0211, 0.0132, 0.0076, 0.0037, 0.0402, 0.0282, 0.0132, 0.0287],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,304][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0024, 0.2334, 0.0988, 0.4918, 0.0861, 0.0341, 0.0325, 0.0167, 0.0043],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,305][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.2031, 0.1010, 0.1073, 0.0959, 0.1110, 0.0806, 0.1046, 0.0845, 0.1121],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,305][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0544, 0.1560, 0.2739, 0.0180, 0.1380, 0.0879, 0.1611, 0.0578, 0.0528],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,306][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0003, 0.2125, 0.1122, 0.0657, 0.1878, 0.1795, 0.1193, 0.0348, 0.0879],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,306][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0041, 0.0148, 0.2403, 0.0325, 0.2904, 0.0136, 0.3203, 0.0190, 0.0651],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,306][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0092, 0.1021, 0.1326, 0.1159, 0.1381, 0.1074, 0.1507, 0.1123, 0.1318],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,307][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0114, 0.1378, 0.0827, 0.0140, 0.1918, 0.3583, 0.1316, 0.0248, 0.0476],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,307][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1499, 0.2324, 0.3049, 0.0054, 0.0986, 0.0796, 0.0926, 0.0127, 0.0237],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,308][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.3801, 0.1123, 0.1620, 0.0105, 0.0579, 0.1224, 0.1024, 0.0198, 0.0326],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,308][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.4310, 0.1108, 0.0417, 0.0357, 0.0784, 0.0422, 0.1474, 0.0509, 0.0618],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,310][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0480, 0.1105, 0.1145, 0.0902, 0.1322, 0.1204, 0.1464, 0.0923, 0.1454],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,312][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8396, 0.0201, 0.0133, 0.0098, 0.0050, 0.0298, 0.0245, 0.0160, 0.0272,
        0.0147], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,313][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0134, 0.0380, 0.5002, 0.1055, 0.1485, 0.0668, 0.0616, 0.0074, 0.0537,
        0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,315][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1234, 0.0960, 0.1107, 0.0946, 0.1015, 0.0806, 0.1025, 0.0859, 0.1194,
        0.0855], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,316][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0797, 0.1498, 0.2237, 0.0195, 0.1089, 0.0669, 0.1648, 0.0439, 0.0539,
        0.0888], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,318][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0004, 0.2144, 0.1019, 0.0650, 0.1767, 0.1613, 0.1011, 0.0314, 0.0805,
        0.0673], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,320][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0015, 0.0133, 0.2527, 0.0206, 0.2932, 0.0118, 0.3020, 0.0127, 0.0742,
        0.0181], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,321][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0071, 0.0923, 0.1148, 0.1067, 0.1251, 0.0976, 0.1345, 0.0989, 0.1166,
        0.1066], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,322][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0555, 0.0704, 0.1132, 0.0141, 0.1714, 0.2726, 0.0578, 0.0163, 0.0422,
        0.1866], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,322][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2945, 0.1871, 0.2419, 0.0045, 0.0744, 0.0713, 0.0621, 0.0114, 0.0260,
        0.0268], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,322][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.5207, 0.1049, 0.1416, 0.0086, 0.0392, 0.0700, 0.0529, 0.0134, 0.0253,
        0.0234], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,323][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2785, 0.1306, 0.0534, 0.0368, 0.0841, 0.0426, 0.1367, 0.0544, 0.0616,
        0.1213], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,323][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0407, 0.0972, 0.1021, 0.0816, 0.1175, 0.1025, 0.1241, 0.0815, 0.1273,
        0.1256], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,324][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8041, 0.0228, 0.0153, 0.0122, 0.0057, 0.0391, 0.0299, 0.0185, 0.0341,
        0.0161, 0.0022], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,324][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0022, 0.2030, 0.1298, 0.3895, 0.0776, 0.0286, 0.0472, 0.0153, 0.0261,
        0.0788, 0.0020], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,324][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1346, 0.0883, 0.1059, 0.0823, 0.0947, 0.0722, 0.0915, 0.0751, 0.1009,
        0.0734, 0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,325][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0819, 0.1236, 0.2306, 0.0185, 0.1077, 0.0557, 0.1405, 0.0521, 0.0519,
        0.0877, 0.0497], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,325][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0005, 0.1827, 0.1003, 0.0626, 0.1676, 0.1492, 0.0915, 0.0289, 0.0808,
        0.0668, 0.0691], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,327][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0019, 0.0144, 0.2435, 0.0278, 0.3293, 0.0132, 0.2200, 0.0146, 0.0775,
        0.0394, 0.0183], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,329][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0063, 0.0836, 0.1105, 0.0961, 0.1166, 0.0856, 0.1255, 0.0881, 0.1060,
        0.0950, 0.0868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,330][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0164, 0.0380, 0.1064, 0.0160, 0.1234, 0.2006, 0.0386, 0.0135, 0.0500,
        0.2614, 0.1358], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,332][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3377, 0.1460, 0.2410, 0.0051, 0.0734, 0.0624, 0.0439, 0.0113, 0.0196,
        0.0244, 0.0351], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,332][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4057, 0.1065, 0.1724, 0.0090, 0.0441, 0.0802, 0.0675, 0.0160, 0.0298,
        0.0272, 0.0415], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,334][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3708, 0.0801, 0.0437, 0.0330, 0.0889, 0.0465, 0.1047, 0.0377, 0.0466,
        0.1077, 0.0402], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,336][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0350, 0.0841, 0.0904, 0.0744, 0.1039, 0.0903, 0.1080, 0.0738, 0.1123,
        0.1126, 0.1151], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,337][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ school] are: tensor([7.9549e-01, 2.8794e-02, 1.0873e-02, 8.5227e-03, 3.2445e-03, 4.2028e-02,
        2.9826e-02, 1.2563e-02, 2.4508e-02, 1.0065e-02, 7.2737e-04, 3.3361e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,338][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0029, 0.0847, 0.1506, 0.2207, 0.1380, 0.0197, 0.0362, 0.0221, 0.0462,
        0.0867, 0.0692, 0.1230], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,339][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0947, 0.0866, 0.0950, 0.0836, 0.0874, 0.0716, 0.0854, 0.0702, 0.0954,
        0.0737, 0.0794, 0.0770], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,340][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0422, 0.0895, 0.1467, 0.0080, 0.0651, 0.0661, 0.1216, 0.0304, 0.0378,
        0.0685, 0.0391, 0.2851], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,340][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ school] are: tensor([3.5088e-04, 1.2000e-01, 7.5365e-02, 3.7443e-02, 1.1309e-01, 1.2336e-01,
        5.1349e-02, 1.5564e-02, 3.6963e-02, 3.4430e-02, 3.6687e-02, 3.5540e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,340][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0276, 0.0070, 0.1166, 0.0217, 0.1189, 0.0116, 0.0911, 0.0058, 0.0387,
        0.0145, 0.0118, 0.5348], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,341][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0132, 0.0741, 0.0940, 0.0803, 0.0954, 0.0770, 0.1082, 0.0792, 0.0953,
        0.0866, 0.0823, 0.1144], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,341][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.0064, 0.0038, 0.0152, 0.0009, 0.0093, 0.0696, 0.0038, 0.0011, 0.0037,
        0.0280, 0.0316, 0.8265], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,342][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.2930, 0.1031, 0.1646, 0.0010, 0.0161, 0.0628, 0.0172, 0.0031, 0.0059,
        0.0064, 0.0148, 0.3118], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,342][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.3981, 0.0880, 0.1178, 0.0037, 0.0177, 0.0544, 0.0362, 0.0076, 0.0097,
        0.0102, 0.0182, 0.2383], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,342][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.5110, 0.0754, 0.0256, 0.0182, 0.0561, 0.0231, 0.0655, 0.0255, 0.0252,
        0.0612, 0.0246, 0.0884], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,343][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.0301, 0.0725, 0.0786, 0.0599, 0.0874, 0.0812, 0.0936, 0.0617, 0.0956,
        0.0945, 0.1005, 0.1445], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,345][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.8263, 0.0179, 0.0112, 0.0075, 0.0032, 0.0270, 0.0225, 0.0122, 0.0237,
        0.0097, 0.0010, 0.0293, 0.0085], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,347][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0020, 0.0177, 0.2034, 0.0248, 0.2491, 0.0625, 0.0736, 0.0128, 0.0371,
        0.0161, 0.0309, 0.2603, 0.0099], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,348][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0925, 0.0766, 0.0931, 0.0747, 0.0776, 0.0671, 0.0783, 0.0673, 0.0858,
        0.0646, 0.0731, 0.0751, 0.0742], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,350][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0831, 0.0806, 0.1638, 0.0117, 0.0752, 0.0442, 0.0732, 0.0293, 0.0371,
        0.0538, 0.0401, 0.2393, 0.0686], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,351][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([3.5608e-04, 1.1653e-01, 5.3057e-02, 3.6795e-02, 8.5292e-02, 8.4137e-02,
        5.2275e-02, 1.9424e-02, 4.5299e-02, 3.9658e-02, 4.3278e-02, 3.5643e-01,
        6.7468e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,353][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0014, 0.0107, 0.1109, 0.0178, 0.1681, 0.0094, 0.1237, 0.0113, 0.0495,
        0.0219, 0.0135, 0.4535, 0.0083], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,354][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0055, 0.0666, 0.0912, 0.0762, 0.0930, 0.0712, 0.1019, 0.0723, 0.0878,
        0.0786, 0.0720, 0.1090, 0.0746], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,356][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0107, 0.0132, 0.0074, 0.0047, 0.0101, 0.0436, 0.0077, 0.0059, 0.0097,
        0.0567, 0.0577, 0.5832, 0.1894], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,356][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2235, 0.0608, 0.1169, 0.0025, 0.0288, 0.0263, 0.0209, 0.0050, 0.0153,
        0.0128, 0.0232, 0.4388, 0.0252], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,357][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2959, 0.0665, 0.1081, 0.0068, 0.0289, 0.0582, 0.0359, 0.0106, 0.0217,
        0.0184, 0.0328, 0.2575, 0.0587], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,357][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2924, 0.0739, 0.0337, 0.0219, 0.0662, 0.0303, 0.0843, 0.0411, 0.0544,
        0.0966, 0.0413, 0.1100, 0.0540], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,358][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0249, 0.0631, 0.0706, 0.0582, 0.0791, 0.0692, 0.0867, 0.0598, 0.0933,
        0.0903, 0.0922, 0.1299, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,358][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([8.3630e-01, 2.0285e-02, 9.4754e-03, 6.6338e-03, 2.2099e-03, 2.7952e-02,
        2.2492e-02, 1.0804e-02, 1.8645e-02, 7.0011e-03, 4.9560e-04, 2.7203e-02,
        7.5382e-03, 2.9632e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,358][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0024, 0.0691, 0.1067, 0.1295, 0.0194, 0.0549, 0.0462, 0.0592, 0.0778,
        0.0715, 0.0290, 0.1649, 0.1452, 0.0241], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,359][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.1239, 0.0714, 0.0755, 0.0665, 0.0748, 0.0576, 0.0681, 0.0536, 0.0750,
        0.0575, 0.0681, 0.0623, 0.0656, 0.0802], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,359][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0573, 0.1062, 0.1477, 0.0056, 0.0491, 0.0487, 0.0689, 0.0195, 0.0270,
        0.0313, 0.0230, 0.2051, 0.0644, 0.1463], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,360][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0003, 0.0837, 0.0671, 0.0290, 0.0888, 0.0968, 0.0414, 0.0121, 0.0284,
        0.0247, 0.0265, 0.2473, 0.0487, 0.2053], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,361][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.0528, 0.0026, 0.0558, 0.0067, 0.0518, 0.0040, 0.0309, 0.0015, 0.0136,
        0.0063, 0.0043, 0.3063, 0.0040, 0.4595], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,363][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0053, 0.0626, 0.0846, 0.0706, 0.0843, 0.0659, 0.0956, 0.0679, 0.0823,
        0.0738, 0.0666, 0.1020, 0.0690, 0.0695], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,364][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([2.0791e-03, 7.6988e-04, 5.3237e-03, 1.7592e-04, 3.0951e-03, 1.8756e-02,
        9.6909e-04, 2.2892e-04, 1.0974e-03, 1.0193e-02, 8.1195e-03, 4.3434e-01,
        8.6880e-02, 4.2797e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,365][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0800, 0.0914, 0.1086, 0.0016, 0.0168, 0.0541, 0.0217, 0.0038, 0.0070,
        0.0069, 0.0142, 0.3598, 0.0328, 0.2014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,367][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.1674, 0.0722, 0.0862, 0.0045, 0.0239, 0.0584, 0.0478, 0.0087, 0.0113,
        0.0126, 0.0160, 0.2146, 0.0556, 0.2207], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,369][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.5635, 0.0408, 0.0167, 0.0096, 0.0409, 0.0189, 0.0502, 0.0180, 0.0170,
        0.0418, 0.0179, 0.0443, 0.0284, 0.0921], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,370][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0215, 0.0581, 0.0620, 0.0479, 0.0678, 0.0636, 0.0784, 0.0511, 0.0769,
        0.0753, 0.0781, 0.1192, 0.0712, 0.1288], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,371][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([7.6386e-01, 2.0885e-02, 1.0924e-02, 8.9119e-03, 3.5460e-03, 4.0889e-02,
        2.7561e-02, 1.0899e-02, 2.6837e-02, 9.0889e-03, 7.1765e-04, 3.7367e-02,
        9.7309e-03, 4.9964e-03, 2.3786e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,373][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0007, 0.0978, 0.1408, 0.1310, 0.0880, 0.0062, 0.0118, 0.0045, 0.0102,
        0.0149, 0.0431, 0.2210, 0.1440, 0.0826, 0.0034], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,374][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1027, 0.0668, 0.0689, 0.0614, 0.0717, 0.0506, 0.0630, 0.0524, 0.0736,
        0.0520, 0.0607, 0.0581, 0.0619, 0.0777, 0.0785], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,374][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0271, 0.0514, 0.1096, 0.0042, 0.0421, 0.0328, 0.0393, 0.0157, 0.0188,
        0.0279, 0.0200, 0.3044, 0.0553, 0.1337, 0.1177], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,374][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0002, 0.0811, 0.0491, 0.0250, 0.0702, 0.0838, 0.0385, 0.0113, 0.0262,
        0.0234, 0.0248, 0.2230, 0.0453, 0.1676, 0.1304], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,375][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0070, 0.0029, 0.0506, 0.0084, 0.0573, 0.0032, 0.0377, 0.0028, 0.0131,
        0.0062, 0.0051, 0.2492, 0.0042, 0.4945, 0.0577], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,375][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0047, 0.0577, 0.0756, 0.0679, 0.0795, 0.0624, 0.0887, 0.0655, 0.0763,
        0.0707, 0.0639, 0.0934, 0.0631, 0.0657, 0.0648], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,376][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([3.3979e-03, 2.1472e-03, 4.3885e-03, 3.4664e-04, 3.1418e-03, 2.7174e-02,
        1.6700e-03, 4.5517e-04, 9.5104e-04, 1.4515e-02, 8.4474e-03, 3.1106e-01,
        9.8071e-02, 3.5932e-01, 1.6492e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,376][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0852, 0.0322, 0.0680, 0.0008, 0.0110, 0.0298, 0.0170, 0.0022, 0.0062,
        0.0060, 0.0098, 0.2829, 0.0189, 0.1852, 0.2448], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,377][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.1873, 0.0467, 0.0740, 0.0037, 0.0179, 0.0531, 0.0326, 0.0072, 0.0137,
        0.0102, 0.0166, 0.1991, 0.0429, 0.1540, 0.1411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,377][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.2015, 0.0718, 0.0292, 0.0272, 0.0547, 0.0344, 0.0912, 0.0297, 0.0466,
        0.0753, 0.0296, 0.0714, 0.0355, 0.0981, 0.1039], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,379][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0230, 0.0537, 0.0529, 0.0418, 0.0602, 0.0568, 0.0662, 0.0424, 0.0648,
        0.0663, 0.0708, 0.1073, 0.0670, 0.1189, 0.1078], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,381][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7775, 0.0180, 0.0111, 0.0082, 0.0039, 0.0286, 0.0211, 0.0129, 0.0240,
        0.0124, 0.0013, 0.0305, 0.0093, 0.0054, 0.0237, 0.0119],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,382][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0089, 0.0191, 0.2496, 0.0519, 0.0740, 0.0321, 0.0303, 0.0031, 0.0260,
        0.0022, 0.0408, 0.2032, 0.0307, 0.1617, 0.0627, 0.0038],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,384][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0770, 0.0597, 0.0687, 0.0581, 0.0636, 0.0493, 0.0641, 0.0541, 0.0739,
        0.0539, 0.0584, 0.0573, 0.0567, 0.0691, 0.0783, 0.0578],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,385][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0421, 0.0381, 0.1005, 0.0050, 0.0482, 0.0257, 0.0492, 0.0171, 0.0205,
        0.0349, 0.0208, 0.1471, 0.0405, 0.1341, 0.1879, 0.0884],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,386][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.9251e-04, 6.7221e-02, 4.5994e-02, 2.1026e-02, 6.9900e-02, 6.3651e-02,
        3.1974e-02, 9.1974e-03, 2.4109e-02, 2.0580e-02, 2.1529e-02, 2.1385e-01,
        3.9133e-02, 1.8332e-01, 1.3636e-01, 5.1967e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,388][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0012, 0.0035, 0.1051, 0.0080, 0.0949, 0.0049, 0.0562, 0.0030, 0.0225,
        0.0061, 0.0035, 0.1862, 0.0028, 0.4086, 0.0798, 0.0137],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,390][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0037, 0.0565, 0.0688, 0.0659, 0.0752, 0.0599, 0.0843, 0.0614, 0.0729,
        0.0658, 0.0608, 0.0874, 0.0586, 0.0593, 0.0611, 0.0584],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,391][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0097, 0.0021, 0.0141, 0.0007, 0.0117, 0.0192, 0.0023, 0.0006, 0.0018,
        0.0097, 0.0088, 0.2130, 0.0447, 0.4137, 0.1767, 0.0713],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,391][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1670, 0.0268, 0.0903, 0.0008, 0.0196, 0.0179, 0.0125, 0.0023, 0.0052,
        0.0047, 0.0087, 0.1821, 0.0102, 0.1842, 0.2520, 0.0157],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,392][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3194, 0.0287, 0.0729, 0.0029, 0.0187, 0.0312, 0.0223, 0.0061, 0.0111,
        0.0092, 0.0152, 0.1387, 0.0288, 0.1558, 0.1116, 0.0273],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,392][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1486, 0.0754, 0.0360, 0.0251, 0.0502, 0.0298, 0.0842, 0.0340, 0.0431,
        0.0811, 0.0364, 0.0882, 0.0355, 0.0839, 0.0732, 0.0755],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,393][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0204, 0.0471, 0.0511, 0.0390, 0.0576, 0.0513, 0.0604, 0.0397, 0.0621,
        0.0616, 0.0653, 0.0960, 0.0595, 0.1096, 0.0993, 0.0799],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,393][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([7.9303e-01, 1.5690e-02, 8.4091e-03, 6.3065e-03, 2.3742e-03, 3.0698e-02,
        2.1639e-02, 8.6894e-03, 1.9541e-02, 7.2425e-03, 4.1961e-04, 2.9779e-02,
        7.1485e-03, 3.2956e-03, 1.7744e-02, 6.8993e-03, 2.1099e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,393][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0028, 0.0415, 0.1940, 0.1131, 0.0611, 0.0471, 0.0377, 0.0187, 0.0405,
        0.0240, 0.0361, 0.1652, 0.0867, 0.0631, 0.0292, 0.0366, 0.0028],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,394][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0863, 0.0575, 0.0622, 0.0545, 0.0592, 0.0486, 0.0560, 0.0488, 0.0657,
        0.0485, 0.0522, 0.0516, 0.0560, 0.0645, 0.0715, 0.0522, 0.0647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,394][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0337, 0.0280, 0.1202, 0.0027, 0.0393, 0.0226, 0.0418, 0.0131, 0.0138,
        0.0209, 0.0126, 0.1717, 0.0401, 0.1474, 0.1686, 0.0559, 0.0677],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,396][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0002, 0.0648, 0.0457, 0.0209, 0.0647, 0.0704, 0.0336, 0.0099, 0.0210,
        0.0191, 0.0196, 0.1837, 0.0378, 0.1446, 0.1123, 0.0462, 0.1053],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,398][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0016, 0.0031, 0.0770, 0.0093, 0.0760, 0.0050, 0.0706, 0.0031, 0.0193,
        0.0075, 0.0036, 0.2490, 0.0027, 0.3273, 0.0733, 0.0195, 0.0520],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,400][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0051, 0.0525, 0.0647, 0.0604, 0.0689, 0.0552, 0.0798, 0.0581, 0.0684,
        0.0617, 0.0578, 0.0806, 0.0553, 0.0556, 0.0568, 0.0549, 0.0643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,401][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0022, 0.0017, 0.0077, 0.0003, 0.0032, 0.0239, 0.0026, 0.0005, 0.0012,
        0.0099, 0.0057, 0.2170, 0.0572, 0.1906, 0.1903, 0.0851, 0.2009],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,403][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1247, 0.0285, 0.0605, 0.0005, 0.0114, 0.0158, 0.0116, 0.0020, 0.0031,
        0.0031, 0.0069, 0.1858, 0.0121, 0.1707, 0.2280, 0.0108, 0.1244],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,405][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.2379, 0.0388, 0.0748, 0.0024, 0.0180, 0.0344, 0.0254, 0.0060, 0.0085,
        0.0072, 0.0119, 0.1153, 0.0295, 0.1583, 0.1148, 0.0198, 0.0970],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,406][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.2414, 0.0571, 0.0284, 0.0173, 0.0521, 0.0271, 0.0750, 0.0240, 0.0296,
        0.0574, 0.0222, 0.0558, 0.0292, 0.0919, 0.0698, 0.0535, 0.0683],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,408][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0155, 0.0417, 0.0464, 0.0371, 0.0522, 0.0465, 0.0590, 0.0383, 0.0592,
        0.0585, 0.0598, 0.0883, 0.0551, 0.0994, 0.0951, 0.0779, 0.0699],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,408][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7645, 0.0193, 0.0099, 0.0082, 0.0034, 0.0311, 0.0215, 0.0114, 0.0243,
        0.0091, 0.0009, 0.0304, 0.0080, 0.0047, 0.0224, 0.0085, 0.0216, 0.0009],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,409][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0006, 0.1043, 0.0361, 0.2952, 0.0898, 0.0106, 0.0119, 0.0080, 0.0082,
        0.0415, 0.0071, 0.0935, 0.1110, 0.0799, 0.0158, 0.0618, 0.0235, 0.0010],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,409][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0772, 0.0546, 0.0623, 0.0508, 0.0580, 0.0436, 0.0554, 0.0483, 0.0628,
        0.0460, 0.0522, 0.0524, 0.0533, 0.0627, 0.0633, 0.0489, 0.0590, 0.0491],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,410][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0497, 0.0438, 0.0955, 0.0042, 0.0417, 0.0205, 0.0462, 0.0193, 0.0156,
        0.0269, 0.0162, 0.1719, 0.0393, 0.1137, 0.1295, 0.0627, 0.0588, 0.0445],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,410][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0002, 0.0621, 0.0402, 0.0204, 0.0583, 0.0599, 0.0329, 0.0107, 0.0224,
        0.0194, 0.0206, 0.1738, 0.0377, 0.1341, 0.0999, 0.0432, 0.0978, 0.0665],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,411][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0008, 0.0039, 0.0941, 0.0088, 0.0949, 0.0051, 0.0622, 0.0041, 0.0212,
        0.0103, 0.0042, 0.2086, 0.0035, 0.3265, 0.0662, 0.0208, 0.0575, 0.0074],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,411][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0027, 0.0500, 0.0666, 0.0602, 0.0693, 0.0528, 0.0773, 0.0551, 0.0655,
        0.0594, 0.0523, 0.0789, 0.0514, 0.0520, 0.0540, 0.0511, 0.0584, 0.0430],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,412][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0054, 0.0033, 0.0115, 0.0011, 0.0053, 0.0273, 0.0038, 0.0015, 0.0027,
        0.0191, 0.0104, 0.1904, 0.0712, 0.1225, 0.0971, 0.1009, 0.1977, 0.1288],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,414][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2523, 0.0243, 0.0702, 0.0007, 0.0136, 0.0126, 0.0084, 0.0022, 0.0035,
        0.0031, 0.0072, 0.1571, 0.0100, 0.1182, 0.1670, 0.0090, 0.1066, 0.0340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,415][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2461, 0.0331, 0.0731, 0.0028, 0.0162, 0.0302, 0.0227, 0.0069, 0.0109,
        0.0082, 0.0140, 0.1317, 0.0288, 0.1100, 0.0925, 0.0236, 0.0988, 0.0503],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,417][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2944, 0.0413, 0.0235, 0.0177, 0.0432, 0.0265, 0.0560, 0.0235, 0.0259,
        0.0544, 0.0229, 0.0639, 0.0270, 0.0826, 0.0553, 0.0540, 0.0500, 0.0380],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,418][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0152, 0.0397, 0.0429, 0.0364, 0.0489, 0.0434, 0.0548, 0.0371, 0.0566,
        0.0563, 0.0564, 0.0806, 0.0518, 0.0899, 0.0869, 0.0741, 0.0657, 0.0634],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,420][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([7.2309e-01, 2.5758e-02, 1.1200e-02, 8.0315e-03, 2.8183e-03, 3.8597e-02,
        2.4449e-02, 1.0829e-02, 2.1359e-02, 7.8792e-03, 4.7330e-04, 3.7771e-02,
        8.8850e-03, 3.8642e-03, 2.1926e-02, 7.4421e-03, 2.6247e-02, 4.3702e-04,
        1.8947e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,421][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([1.9173e-04, 4.2855e-02, 3.4809e-02, 2.1280e-01, 8.1830e-02, 2.1599e-02,
        2.8619e-02, 2.9802e-02, 1.5632e-02, 7.9914e-02, 1.8860e-02, 7.8461e-02,
        7.8212e-02, 5.4102e-02, 3.1136e-02, 1.0969e-01, 2.9034e-02, 1.2783e-02,
        3.9673e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,423][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.1018, 0.0541, 0.0594, 0.0506, 0.0534, 0.0417, 0.0500, 0.0430, 0.0543,
        0.0412, 0.0485, 0.0458, 0.0481, 0.0560, 0.0608, 0.0448, 0.0561, 0.0461,
        0.0443], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,424][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0180, 0.0299, 0.0634, 0.0028, 0.0323, 0.0191, 0.0420, 0.0148, 0.0139,
        0.0187, 0.0118, 0.1476, 0.0369, 0.0977, 0.1070, 0.0443, 0.0604, 0.0374,
        0.2021], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,425][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0002, 0.0543, 0.0385, 0.0181, 0.0517, 0.0610, 0.0282, 0.0088, 0.0170,
        0.0159, 0.0171, 0.1381, 0.0320, 0.1087, 0.0828, 0.0372, 0.0792, 0.0607,
        0.1505], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,426][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.0200, 0.0017, 0.0386, 0.0057, 0.0325, 0.0027, 0.0188, 0.0014, 0.0074,
        0.0028, 0.0024, 0.1391, 0.0020, 0.1808, 0.0396, 0.0103, 0.0303, 0.0068,
        0.4571], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,426][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0053, 0.0465, 0.0585, 0.0515, 0.0610, 0.0481, 0.0706, 0.0514, 0.0611,
        0.0553, 0.0513, 0.0722, 0.0492, 0.0499, 0.0505, 0.0494, 0.0587, 0.0447,
        0.0650], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,427][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([3.5346e-03, 7.2618e-04, 2.1050e-03, 1.5919e-04, 7.4231e-04, 1.5641e-02,
        7.3625e-04, 2.6396e-04, 5.3718e-04, 5.0320e-03, 3.5415e-03, 6.8972e-02,
        3.9924e-02, 4.3789e-02, 5.9366e-02, 4.4048e-02, 7.2134e-02, 9.1025e-02,
        5.4772e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,427][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.1074, 0.0259, 0.0555, 0.0004, 0.0073, 0.0158, 0.0074, 0.0011, 0.0019,
        0.0018, 0.0037, 0.1154, 0.0084, 0.0994, 0.1448, 0.0065, 0.0782, 0.0274,
        0.2919], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,428][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([0.1468, 0.0261, 0.0428, 0.0018, 0.0101, 0.0317, 0.0186, 0.0039, 0.0060,
        0.0052, 0.0094, 0.0916, 0.0232, 0.0794, 0.0831, 0.0150, 0.0718, 0.0339,
        0.2997], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,428][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.3904, 0.0364, 0.0140, 0.0102, 0.0372, 0.0178, 0.0519, 0.0174, 0.0193,
        0.0372, 0.0131, 0.0477, 0.0209, 0.0773, 0.0439, 0.0358, 0.0505, 0.0235,
        0.0555], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,429][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0142, 0.0368, 0.0387, 0.0303, 0.0433, 0.0405, 0.0497, 0.0318, 0.0486,
        0.0480, 0.0509, 0.0776, 0.0471, 0.0830, 0.0804, 0.0639, 0.0604, 0.0596,
        0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,429][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7110, 0.0189, 0.0115, 0.0083, 0.0042, 0.0316, 0.0216, 0.0128, 0.0251,
        0.0125, 0.0012, 0.0327, 0.0093, 0.0057, 0.0247, 0.0120, 0.0247, 0.0011,
        0.0193, 0.0118], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,431][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0056, 0.0121, 0.1319, 0.0294, 0.0416, 0.0175, 0.0165, 0.0019, 0.0151,
        0.0015, 0.0236, 0.1077, 0.0181, 0.0833, 0.0299, 0.0024, 0.0301, 0.0489,
        0.3800, 0.0029], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,433][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0584, 0.0476, 0.0574, 0.0472, 0.0510, 0.0402, 0.0523, 0.0444, 0.0595,
        0.0436, 0.0473, 0.0475, 0.0452, 0.0550, 0.0614, 0.0461, 0.0555, 0.0442,
        0.0458, 0.0505], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,435][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0413, 0.0280, 0.0835, 0.0036, 0.0352, 0.0215, 0.0363, 0.0145, 0.0142,
        0.0224, 0.0139, 0.0985, 0.0302, 0.0876, 0.1058, 0.0517, 0.0482, 0.0408,
        0.1398, 0.0829], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,436][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0002, 0.0493, 0.0345, 0.0157, 0.0486, 0.0514, 0.0256, 0.0080, 0.0164,
        0.0142, 0.0155, 0.1259, 0.0300, 0.1076, 0.0815, 0.0318, 0.0766, 0.0538,
        0.1413, 0.0722], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,438][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0012, 0.0033, 0.0904, 0.0073, 0.0679, 0.0055, 0.0509, 0.0028, 0.0173,
        0.0049, 0.0024, 0.1186, 0.0024, 0.1800, 0.0506, 0.0087, 0.0339, 0.0048,
        0.3325, 0.0146], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,440][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0032, 0.0453, 0.0565, 0.0534, 0.0615, 0.0475, 0.0676, 0.0493, 0.0584,
        0.0528, 0.0484, 0.0704, 0.0461, 0.0466, 0.0478, 0.0462, 0.0533, 0.0397,
        0.0585, 0.0476], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,442][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0331, 0.0017, 0.0131, 0.0005, 0.0052, 0.0234, 0.0022, 0.0007, 0.0010,
        0.0055, 0.0046, 0.0566, 0.0356, 0.0663, 0.0494, 0.0269, 0.0600, 0.0660,
        0.3427, 0.2055], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,444][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1903, 0.0191, 0.0668, 0.0006, 0.0094, 0.0141, 0.0096, 0.0021, 0.0035,
        0.0033, 0.0053, 0.0843, 0.0073, 0.0770, 0.1344, 0.0098, 0.0769, 0.0300,
        0.2221, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,445][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3060, 0.0178, 0.0507, 0.0017, 0.0098, 0.0192, 0.0133, 0.0043, 0.0061,
        0.0050, 0.0083, 0.0665, 0.0168, 0.0746, 0.0543, 0.0130, 0.0659, 0.0304,
        0.2053, 0.0309], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,447][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0880, 0.0545, 0.0304, 0.0202, 0.0404, 0.0259, 0.0760, 0.0303, 0.0360,
        0.0646, 0.0315, 0.0716, 0.0274, 0.0654, 0.0573, 0.0593, 0.0799, 0.0454,
        0.0369, 0.0589], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,448][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0143, 0.0350, 0.0387, 0.0304, 0.0423, 0.0376, 0.0459, 0.0309, 0.0477,
        0.0473, 0.0486, 0.0682, 0.0432, 0.0768, 0.0720, 0.0601, 0.0567, 0.0541,
        0.0840, 0.0662], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,499][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:47,499][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,500][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,500][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,500][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,500][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,501][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,501][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,501][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,502][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,502][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,503][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,504][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,506][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7939, 0.2061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,507][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0218, 0.9782], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,509][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8056, 0.1944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,510][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5590, 0.4410], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,521][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0174, 0.9826], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,522][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2578, 0.7422], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,524][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6546, 0.3454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,525][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1066, 0.8934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,526][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6877, 0.3123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,528][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6503, 0.3497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,530][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3340, 0.6660], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,531][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2461, 0.7539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,533][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.7956, 0.1859, 0.0184], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,533][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0091, 0.6074, 0.3835], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,534][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.2552, 0.2172, 0.5276], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,534][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.2515, 0.4006, 0.3479], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,534][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0130, 0.8460, 0.1410], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,535][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.2464, 0.6267, 0.1269], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,535][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.5343, 0.3180, 0.1477], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,535][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0195, 0.8719, 0.1086], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,536][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.4364, 0.3859, 0.1777], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,536][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.4496, 0.3432, 0.2072], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,536][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.1932, 0.5187, 0.2881], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,537][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0399, 0.8366, 0.1235], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,538][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8782, 0.0927, 0.0096, 0.0195], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,539][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0387, 0.2094, 0.6173, 0.1346], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,541][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3236, 0.2061, 0.4579, 0.0124], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,542][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2497, 0.2833, 0.4294, 0.0375], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,544][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0041, 0.8618, 0.1210, 0.0131], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,545][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0740, 0.6886, 0.2312, 0.0062], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,547][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7930, 0.1035, 0.0945, 0.0090], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,549][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0087, 0.7908, 0.1973, 0.0032], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,550][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3915, 0.3260, 0.2727, 0.0098], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,551][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4142, 0.3148, 0.2363, 0.0347], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,551][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2412, 0.4226, 0.3188, 0.0174], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,551][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0532, 0.6197, 0.2683, 0.0588], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,552][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.8509, 0.0850, 0.0093, 0.0205, 0.0343], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,552][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0598, 0.1666, 0.4397, 0.1271, 0.2068], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,552][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.2608, 0.1580, 0.4232, 0.0089, 0.1492], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,553][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.2357, 0.3411, 0.2806, 0.0172, 0.1255], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,553][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0211, 0.4947, 0.2210, 0.0030, 0.2602], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,553][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.2580, 0.4286, 0.2209, 0.0011, 0.0914], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,554][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.8645, 0.0475, 0.0713, 0.0026, 0.0141], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,555][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0282, 0.4802, 0.2470, 0.0008, 0.2437], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,556][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.2502, 0.4668, 0.2206, 0.0067, 0.0558], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,558][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.4211, 0.3074, 0.1975, 0.0158, 0.0581], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,559][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2458, 0.3620, 0.2895, 0.0085, 0.0941], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,561][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0248, 0.6156, 0.1067, 0.0214, 0.2314], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,562][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.8926, 0.0665, 0.0053, 0.0173, 0.0165, 0.0017], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,564][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0427, 0.2229, 0.2717, 0.0767, 0.3080, 0.0779], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,566][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.4093, 0.1538, 0.2634, 0.0121, 0.1230, 0.0385], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,567][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.1543, 0.2333, 0.3030, 0.0358, 0.1829, 0.0908], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,568][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0109, 0.6831, 0.0535, 0.0133, 0.1197, 0.1195], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,568][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1596, 0.5369, 0.1021, 0.0070, 0.0927, 0.1016], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,569][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.7719, 0.0712, 0.0954, 0.0045, 0.0364, 0.0206], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,569][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0384, 0.5673, 0.0893, 0.0039, 0.1698, 0.1313], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,569][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.5268, 0.1890, 0.1601, 0.0072, 0.0555, 0.0613], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,570][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.3762, 0.2048, 0.1742, 0.0244, 0.0660, 0.1544], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,570][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2267, 0.2968, 0.2655, 0.0148, 0.1063, 0.0900], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,570][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0521, 0.3265, 0.1201, 0.0362, 0.2828, 0.1823], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,571][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.8199, 0.1168, 0.0058, 0.0221, 0.0260, 0.0040, 0.0053],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,571][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0172, 0.1976, 0.2344, 0.1126, 0.1422, 0.2313, 0.0647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,572][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.1668, 0.1584, 0.2556, 0.0168, 0.1500, 0.0686, 0.1839],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,573][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0543, 0.2053, 0.2439, 0.0234, 0.1621, 0.1207, 0.1903],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,575][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0012, 0.6015, 0.0235, 0.0056, 0.1066, 0.1094, 0.1522],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,576][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0241, 0.7228, 0.0391, 0.0034, 0.0607, 0.0946, 0.0552],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,578][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.3735, 0.1917, 0.1520, 0.0206, 0.0768, 0.1102, 0.0752],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,579][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0054, 0.6705, 0.0243, 0.0013, 0.0899, 0.0796, 0.1291],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,580][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.1381, 0.4312, 0.1681, 0.0071, 0.0654, 0.1156, 0.0746],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,582][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.2808, 0.2199, 0.1618, 0.0173, 0.0675, 0.1463, 0.1064],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,584][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0803, 0.3485, 0.2250, 0.0106, 0.1081, 0.1119, 0.1155],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,585][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0073, 0.3157, 0.0691, 0.0172, 0.1816, 0.2015, 0.2076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,586][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.6474, 0.1290, 0.0083, 0.0294, 0.0374, 0.0039, 0.0056, 0.1390],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,586][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0130, 0.1870, 0.2930, 0.0700, 0.1750, 0.1392, 0.0856, 0.0372],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,587][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2600, 0.1462, 0.2307, 0.0131, 0.1113, 0.0372, 0.1694, 0.0321],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,587][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0242, 0.2533, 0.2293, 0.0348, 0.1436, 0.0851, 0.1791, 0.0506],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,587][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0019, 0.4758, 0.0360, 0.0071, 0.2422, 0.0533, 0.1701, 0.0137],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,588][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0146, 0.5731, 0.0710, 0.0058, 0.1657, 0.0576, 0.1036, 0.0086],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,588][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.5094, 0.1067, 0.1495, 0.0106, 0.0499, 0.0701, 0.0615, 0.0424],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,588][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0026, 0.5486, 0.0375, 0.0028, 0.2318, 0.0280, 0.1429, 0.0058],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,589][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.1033, 0.3462, 0.2548, 0.0116, 0.1016, 0.0806, 0.0861, 0.0158],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,590][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.2819, 0.1898, 0.1775, 0.0220, 0.0820, 0.1276, 0.0953, 0.0239],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,591][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0502, 0.3017, 0.2533, 0.0169, 0.1374, 0.0994, 0.1175, 0.0236],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,593][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0075, 0.1901, 0.1274, 0.0195, 0.2752, 0.1387, 0.2133, 0.0283],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,595][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.8300, 0.0537, 0.0046, 0.0108, 0.0264, 0.0021, 0.0030, 0.0634, 0.0061],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,596][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0563, 0.1065, 0.1721, 0.0585, 0.1894, 0.2009, 0.0971, 0.0547, 0.0646],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,598][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.1594, 0.0893, 0.2486, 0.0139, 0.1040, 0.0524, 0.1785, 0.0615, 0.0924],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,599][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0544, 0.1560, 0.2739, 0.0180, 0.1380, 0.0879, 0.1611, 0.0578, 0.0528],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,601][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0036, 0.2842, 0.0881, 0.0025, 0.2669, 0.1166, 0.1660, 0.0056, 0.0667],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,602][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0487, 0.3646, 0.1646, 0.0034, 0.1778, 0.1141, 0.0828, 0.0099, 0.0342],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,603][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.6467, 0.0629, 0.1179, 0.0070, 0.0395, 0.0416, 0.0396, 0.0330, 0.0118],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,603][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0122, 0.2548, 0.0978, 0.0007, 0.3280, 0.0745, 0.1966, 0.0038, 0.0315],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,604][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1499, 0.2324, 0.3049, 0.0054, 0.0986, 0.0796, 0.0926, 0.0127, 0.0237],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,604][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.3801, 0.1123, 0.1620, 0.0105, 0.0579, 0.1224, 0.1024, 0.0198, 0.0326],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,605][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1211, 0.2591, 0.2502, 0.0079, 0.1086, 0.0967, 0.1030, 0.0186, 0.0349],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,605][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0172, 0.1791, 0.0925, 0.0088, 0.1702, 0.1597, 0.2413, 0.0194, 0.1119],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,605][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7856, 0.0492, 0.0021, 0.0119, 0.0145, 0.0012, 0.0015, 0.0457, 0.0027,
        0.0856], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,606][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1968, 0.0555, 0.2172, 0.0356, 0.1273, 0.0728, 0.0879, 0.0338, 0.1210,
        0.0521], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,606][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3178, 0.1054, 0.2240, 0.0074, 0.0746, 0.0324, 0.1336, 0.0207, 0.0581,
        0.0260], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,607][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0797, 0.1498, 0.2237, 0.0195, 0.1089, 0.0669, 0.1648, 0.0439, 0.0539,
        0.0888], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,607][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0114, 0.2995, 0.0913, 0.0026, 0.2811, 0.0980, 0.1017, 0.0064, 0.0553,
        0.0527], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,609][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2114, 0.2087, 0.2180, 0.0021, 0.1561, 0.0810, 0.0578, 0.0050, 0.0378,
        0.0222], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,611][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8595, 0.0225, 0.0375, 0.0021, 0.0164, 0.0196, 0.0157, 0.0134, 0.0061,
        0.0073], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,612][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0641, 0.1303, 0.1566, 0.0009, 0.3631, 0.0617, 0.1206, 0.0037, 0.0403,
        0.0588], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,614][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2945, 0.1871, 0.2419, 0.0045, 0.0744, 0.0713, 0.0621, 0.0114, 0.0260,
        0.0268], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,615][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5207, 0.1049, 0.1416, 0.0086, 0.0392, 0.0700, 0.0529, 0.0134, 0.0253,
        0.0234], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,617][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2008, 0.2081, 0.2677, 0.0081, 0.0958, 0.0724, 0.0885, 0.0142, 0.0221,
        0.0224], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,619][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0120, 0.1690, 0.1004, 0.0096, 0.1935, 0.1221, 0.1404, 0.0174, 0.1025,
        0.1332], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,620][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([2.0952e-01, 1.4890e-02, 1.1347e-03, 3.6973e-03, 5.3871e-03, 3.8111e-04,
        7.4237e-04, 1.6449e-02, 1.2197e-03, 2.4425e-02, 7.2215e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,620][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0384, 0.1327, 0.1714, 0.0584, 0.1423, 0.0923, 0.0776, 0.0404, 0.0984,
        0.0921, 0.0560], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,621][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2912, 0.1014, 0.1933, 0.0095, 0.0692, 0.0361, 0.1441, 0.0274, 0.0618,
        0.0264, 0.0394], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,621][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0819, 0.1236, 0.2306, 0.0185, 0.1077, 0.0557, 0.1405, 0.0521, 0.0519,
        0.0877, 0.0497], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,622][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0151, 0.1184, 0.1206, 0.0034, 0.2871, 0.0969, 0.0668, 0.0055, 0.0748,
        0.0673, 0.1442], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,622][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2721, 0.1101, 0.2109, 0.0025, 0.1671, 0.0766, 0.0364, 0.0055, 0.0328,
        0.0353, 0.0508], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,622][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6992, 0.0566, 0.0796, 0.0049, 0.0248, 0.0281, 0.0361, 0.0255, 0.0120,
        0.0153, 0.0180], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,623][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0417, 0.0627, 0.1780, 0.0012, 0.3218, 0.0518, 0.0862, 0.0034, 0.0570,
        0.0843, 0.1118], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,623][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3377, 0.1460, 0.2410, 0.0051, 0.0734, 0.0624, 0.0439, 0.0113, 0.0196,
        0.0244, 0.0351], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,624][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.4057, 0.1065, 0.1724, 0.0090, 0.0441, 0.0802, 0.0675, 0.0160, 0.0298,
        0.0272, 0.0415], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,624][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1930, 0.1494, 0.2569, 0.0099, 0.0815, 0.0881, 0.0946, 0.0172, 0.0317,
        0.0272, 0.0505], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,626][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0205, 0.1049, 0.0856, 0.0102, 0.1916, 0.0976, 0.1204, 0.0201, 0.1029,
        0.1397, 0.1064], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,627][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([2.5791e-01, 8.9529e-03, 9.4986e-04, 1.7047e-03, 4.5618e-03, 3.3922e-04,
        4.0060e-04, 1.0994e-02, 7.3305e-04, 2.1701e-02, 6.9082e-01, 9.2514e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,629][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0287, 0.1012, 0.1532, 0.0351, 0.0991, 0.0532, 0.0480, 0.0256, 0.0486,
        0.0529, 0.0676, 0.2869], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,630][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.2175, 0.0845, 0.1978, 0.0082, 0.0588, 0.0347, 0.1330, 0.0249, 0.0599,
        0.0272, 0.0405, 0.1128], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,632][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.0422, 0.0895, 0.1467, 0.0080, 0.0651, 0.0661, 0.1216, 0.0304, 0.0378,
        0.0685, 0.0391, 0.2851], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,634][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([3.9975e-03, 3.1164e-03, 5.1406e-03, 2.1232e-05, 5.4594e-03, 6.3613e-03,
        1.4565e-03, 8.8156e-05, 5.6372e-04, 1.3094e-03, 4.4801e-03, 9.6801e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,634][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([9.6892e-02, 1.1277e-02, 3.8445e-02, 1.1999e-04, 1.1914e-02, 2.6555e-02,
        3.9315e-03, 3.9238e-04, 2.5935e-03, 2.8753e-03, 8.7003e-03, 7.9631e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,636][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.6980, 0.0433, 0.0541, 0.0028, 0.0158, 0.0265, 0.0251, 0.0136, 0.0090,
        0.0123, 0.0176, 0.0819], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,637][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([5.4391e-03, 7.6104e-04, 4.9621e-03, 5.1940e-06, 2.9846e-03, 4.0291e-03,
        1.1884e-03, 3.2697e-05, 4.2801e-04, 8.8733e-04, 3.4413e-03, 9.7584e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,638][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.2930, 0.1031, 0.1646, 0.0010, 0.0161, 0.0628, 0.0172, 0.0031, 0.0059,
        0.0064, 0.0148, 0.3118], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,638][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.3981, 0.0880, 0.1178, 0.0037, 0.0177, 0.0544, 0.0362, 0.0076, 0.0097,
        0.0102, 0.0182, 0.2383], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,638][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.1303, 0.0901, 0.1364, 0.0026, 0.0323, 0.0509, 0.0352, 0.0058, 0.0084,
        0.0101, 0.0185, 0.4793], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,639][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.0060, 0.0555, 0.0265, 0.0018, 0.0351, 0.0579, 0.0244, 0.0029, 0.0160,
        0.0282, 0.0353, 0.7105], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,639][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.0408e-01, 1.2928e-02, 9.9739e-04, 3.2819e-03, 4.3632e-03, 3.5347e-04,
        5.3181e-04, 1.7608e-02, 1.0015e-03, 2.3004e-02, 7.1003e-01, 7.8189e-04,
        2.1041e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,640][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0323, 0.0588, 0.1624, 0.0230, 0.1090, 0.0436, 0.0397, 0.0191, 0.0516,
        0.0370, 0.0319, 0.3145, 0.0771], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,640][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3841, 0.0769, 0.1335, 0.0071, 0.0498, 0.0276, 0.1050, 0.0216, 0.0416,
        0.0184, 0.0316, 0.0826, 0.0203], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,640][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0831, 0.0806, 0.1638, 0.0117, 0.0752, 0.0442, 0.0732, 0.0293, 0.0371,
        0.0538, 0.0401, 0.2393, 0.0686], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,641][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.3592e-03, 8.4257e-03, 2.9845e-03, 1.5709e-04, 5.9972e-03, 3.2642e-03,
        2.3831e-03, 4.8593e-04, 2.2348e-03, 3.1881e-03, 9.5119e-03, 9.5095e-01,
        9.0560e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,642][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0946, 0.0349, 0.0308, 0.0009, 0.0205, 0.0197, 0.0106, 0.0028, 0.0082,
        0.0089, 0.0195, 0.7270, 0.0216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,644][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6626, 0.0386, 0.0870, 0.0032, 0.0211, 0.0220, 0.0289, 0.0154, 0.0107,
        0.0106, 0.0141, 0.0719, 0.0140], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,645][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.2180e-03, 5.4109e-03, 2.9640e-03, 1.0758e-04, 5.9870e-03, 2.7546e-03,
        4.5569e-03, 4.5178e-04, 2.5359e-03, 4.2126e-03, 1.4263e-02, 9.4376e-01,
        8.7804e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,646][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2235, 0.0608, 0.1169, 0.0025, 0.0288, 0.0263, 0.0209, 0.0050, 0.0153,
        0.0128, 0.0232, 0.4388, 0.0252], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,648][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2959, 0.0665, 0.1081, 0.0068, 0.0289, 0.0582, 0.0359, 0.0106, 0.0217,
        0.0184, 0.0328, 0.2575, 0.0587], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,650][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1479, 0.0761, 0.1261, 0.0046, 0.0413, 0.0370, 0.0400, 0.0091, 0.0154,
        0.0130, 0.0229, 0.4218, 0.0448], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,652][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0054, 0.0239, 0.0165, 0.0028, 0.0366, 0.0250, 0.0203, 0.0042, 0.0228,
        0.0351, 0.0330, 0.6941, 0.0803], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,653][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([1.5052e-01, 1.1417e-02, 1.5921e-03, 3.3989e-03, 5.7638e-03, 5.9367e-04,
        7.6086e-04, 1.6140e-02, 1.0841e-03, 2.2361e-02, 6.4440e-01, 1.6324e-03,
        2.9154e-02, 1.1118e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,654][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0057, 0.0345, 0.0782, 0.0310, 0.0576, 0.0516, 0.0305, 0.0222, 0.0388,
        0.0562, 0.0418, 0.2732, 0.0957, 0.1831], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,655][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1424, 0.0738, 0.1877, 0.0086, 0.0651, 0.0268, 0.1249, 0.0273, 0.0418,
        0.0223, 0.0209, 0.1162, 0.0226, 0.1195], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,655][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.0573, 0.1062, 0.1477, 0.0056, 0.0491, 0.0487, 0.0689, 0.0195, 0.0270,
        0.0313, 0.0230, 0.2051, 0.0644, 0.1463], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,656][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([1.9402e-03, 1.6610e-03, 5.4535e-03, 2.0687e-05, 3.4415e-03, 3.9781e-03,
        9.6577e-04, 5.3644e-05, 4.7800e-04, 6.7540e-04, 2.2191e-03, 4.3743e-01,
        4.2662e-03, 5.3741e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,656][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([1.4486e-01, 5.4974e-03, 2.5424e-02, 5.1822e-05, 5.8779e-03, 1.2583e-02,
        2.0885e-03, 2.3511e-04, 1.0020e-03, 1.0837e-03, 2.8051e-03, 2.4222e-01,
        8.3622e-03, 5.4791e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,656][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.5899, 0.0325, 0.0708, 0.0025, 0.0182, 0.0273, 0.0225, 0.0157, 0.0135,
        0.0135, 0.0140, 0.0734, 0.0192, 0.0871], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,657][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([2.2295e-03, 3.2644e-04, 2.2787e-03, 2.6307e-06, 1.3421e-03, 1.2454e-03,
        5.3908e-04, 1.6053e-05, 2.2623e-04, 4.1704e-04, 1.0378e-03, 3.1467e-01,
        2.3620e-03, 6.7331e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,657][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0800, 0.0914, 0.1086, 0.0016, 0.0168, 0.0541, 0.0217, 0.0038, 0.0070,
        0.0069, 0.0142, 0.3598, 0.0328, 0.2014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,658][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.1674, 0.0722, 0.0862, 0.0045, 0.0239, 0.0584, 0.0478, 0.0087, 0.0113,
        0.0126, 0.0160, 0.2146, 0.0556, 0.2207], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,658][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.0729, 0.0504, 0.0944, 0.0019, 0.0243, 0.0400, 0.0322, 0.0044, 0.0077,
        0.0076, 0.0106, 0.2987, 0.0377, 0.3171], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,659][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0021, 0.0334, 0.0141, 0.0015, 0.0181, 0.0307, 0.0221, 0.0024, 0.0088,
        0.0127, 0.0140, 0.6130, 0.0437, 0.1834], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,660][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([1.5857e-01, 8.5906e-03, 8.7325e-04, 2.4317e-03, 5.5692e-03, 3.1455e-04,
        4.4079e-04, 9.3947e-03, 7.0785e-04, 1.8485e-02, 6.8171e-01, 7.5379e-04,
        2.0008e-02, 8.2075e-02, 1.0080e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,662][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0078, 0.0614, 0.0639, 0.0244, 0.0633, 0.0413, 0.0326, 0.0161, 0.0289,
        0.0327, 0.0421, 0.2573, 0.0818, 0.1616, 0.0849], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,664][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.2203, 0.0760, 0.1179, 0.0083, 0.0462, 0.0313, 0.0701, 0.0261, 0.0341,
        0.0265, 0.0323, 0.0838, 0.0266, 0.0951, 0.1055], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,665][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0271, 0.0514, 0.1096, 0.0042, 0.0421, 0.0328, 0.0393, 0.0157, 0.0188,
        0.0279, 0.0200, 0.3044, 0.0553, 0.1337, 0.1177], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,666][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([1.2346e-03, 4.6134e-03, 2.6409e-03, 2.4055e-05, 2.3838e-03, 4.2122e-03,
        1.3536e-03, 7.2452e-05, 5.6567e-04, 8.2563e-04, 2.6208e-03, 4.1558e-01,
        5.9000e-03, 4.2035e-01, 1.3762e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,667][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([3.0512e-02, 6.9200e-03, 1.4575e-02, 7.3561e-05, 5.8220e-03, 9.8522e-03,
        2.0255e-03, 2.6578e-04, 7.8133e-04, 1.1718e-03, 2.8311e-03, 2.5027e-01,
        8.6796e-03, 4.9880e-01, 1.6743e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,669][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.3647, 0.0427, 0.0644, 0.0045, 0.0240, 0.0238, 0.0266, 0.0262, 0.0107,
        0.0192, 0.0215, 0.1589, 0.0238, 0.0979, 0.0911], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,670][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([1.4739e-03, 6.8912e-04, 1.7215e-03, 3.1263e-06, 1.1946e-03, 1.4474e-03,
        6.7073e-04, 1.7991e-05, 1.1738e-04, 4.4901e-04, 7.7013e-04, 2.2964e-01,
        2.2808e-03, 6.0857e-01, 1.5095e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,672][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0852, 0.0322, 0.0680, 0.0008, 0.0110, 0.0298, 0.0170, 0.0022, 0.0062,
        0.0060, 0.0098, 0.2829, 0.0189, 0.1852, 0.2448], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,672][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.1873, 0.0467, 0.0740, 0.0037, 0.0179, 0.0531, 0.0326, 0.0072, 0.0137,
        0.0102, 0.0166, 0.1991, 0.0429, 0.1540, 0.1411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,673][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0344, 0.0427, 0.0752, 0.0014, 0.0186, 0.0253, 0.0178, 0.0033, 0.0055,
        0.0050, 0.0075, 0.2778, 0.0278, 0.2590, 0.1987], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,673][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0016, 0.0173, 0.0066, 0.0007, 0.0110, 0.0142, 0.0139, 0.0016, 0.0068,
        0.0130, 0.0125, 0.5241, 0.0398, 0.1686, 0.1683], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,674][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.5674e-01, 1.1814e-02, 5.7556e-04, 3.2043e-03, 3.8501e-03, 3.4125e-04,
        4.0346e-04, 1.1637e-02, 7.0461e-04, 1.9787e-02, 5.7766e-01, 4.5250e-04,
        1.9997e-02, 6.5419e-02, 9.7463e-03, 1.7674e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,674][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1039, 0.0146, 0.0699, 0.0091, 0.0367, 0.0214, 0.0257, 0.0098, 0.0311,
        0.0147, 0.0156, 0.1577, 0.0281, 0.2372, 0.1921, 0.0323],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,675][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2254, 0.0668, 0.1335, 0.0058, 0.0435, 0.0187, 0.0869, 0.0147, 0.0382,
        0.0173, 0.0265, 0.0760, 0.0166, 0.1073, 0.1045, 0.0183],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,675][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0421, 0.0381, 0.1005, 0.0050, 0.0482, 0.0257, 0.0492, 0.0171, 0.0205,
        0.0349, 0.0208, 0.1471, 0.0405, 0.1341, 0.1879, 0.0884],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,675][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4451e-04, 2.0856e-03, 3.7186e-03, 2.1842e-05, 4.7781e-03, 1.8974e-03,
        1.0168e-03, 6.5519e-05, 5.7249e-04, 6.0495e-04, 1.7304e-03, 3.0187e-01,
        2.7789e-03, 5.0893e-01, 1.6285e-01, 6.1334e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,676][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.0661e-02, 5.5926e-03, 2.5254e-02, 8.8024e-05, 8.4798e-03, 6.3864e-03,
        2.5878e-03, 2.5936e-04, 1.6987e-03, 1.0655e-03, 1.8725e-03, 1.9228e-01,
        4.2408e-03, 4.4736e-01, 2.3174e-01, 1.0438e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,678][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7626, 0.0105, 0.0221, 0.0010, 0.0090, 0.0101, 0.0088, 0.0066, 0.0034,
        0.0038, 0.0064, 0.0304, 0.0059, 0.0760, 0.0368, 0.0066],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,679][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.4696e-03, 2.9731e-04, 2.9170e-03, 3.2452e-06, 2.7935e-03, 5.6408e-04,
        5.8381e-04, 1.5413e-05, 1.6163e-04, 2.4538e-04, 6.5472e-04, 1.4340e-01,
        7.7400e-04, 6.6216e-01, 1.7678e-01, 5.1888e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,681][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1670, 0.0268, 0.0903, 0.0008, 0.0196, 0.0179, 0.0125, 0.0023, 0.0052,
        0.0047, 0.0087, 0.1821, 0.0102, 0.1842, 0.2520, 0.0157],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,682][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3194, 0.0287, 0.0729, 0.0029, 0.0187, 0.0312, 0.0223, 0.0061, 0.0111,
        0.0092, 0.0152, 0.1387, 0.0288, 0.1558, 0.1116, 0.0273],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,684][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0878, 0.0434, 0.0928, 0.0019, 0.0277, 0.0229, 0.0216, 0.0038, 0.0057,
        0.0055, 0.0086, 0.1869, 0.0205, 0.2904, 0.1637, 0.0167],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,686][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0024, 0.0144, 0.0165, 0.0010, 0.0236, 0.0167, 0.0182, 0.0023, 0.0129,
        0.0158, 0.0128, 0.4263, 0.0289, 0.1840, 0.1693, 0.0551],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,687][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.0528e-01, 1.1409e-02, 1.2012e-03, 2.3735e-03, 4.7999e-03, 3.9427e-04,
        6.4906e-04, 1.2524e-02, 9.5560e-04, 2.0593e-02, 5.9955e-01, 9.0287e-04,
        2.0961e-02, 8.0700e-02, 1.5166e-02, 2.0207e-02, 2.3270e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,689][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0356, 0.0180, 0.0758, 0.0105, 0.0349, 0.0414, 0.0379, 0.0175, 0.0338,
        0.0305, 0.0332, 0.1806, 0.0569, 0.1552, 0.1274, 0.0663, 0.0445],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,689][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.2165, 0.0583, 0.1335, 0.0065, 0.0454, 0.0218, 0.0771, 0.0152, 0.0309,
        0.0150, 0.0212, 0.0662, 0.0162, 0.0880, 0.1031, 0.0171, 0.0678],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,690][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0337, 0.0280, 0.1202, 0.0027, 0.0393, 0.0226, 0.0418, 0.0131, 0.0138,
        0.0209, 0.0126, 0.1717, 0.0401, 0.1474, 0.1686, 0.0559, 0.0677],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,690][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([1.1875e-03, 2.8979e-03, 3.8979e-03, 1.8000e-05, 3.3323e-03, 3.2876e-03,
        1.5176e-03, 7.8302e-05, 3.7987e-04, 6.7040e-04, 1.6918e-03, 3.2674e-01,
        4.0932e-03, 4.0044e-01, 1.4634e-01, 8.0595e-03, 9.5366e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,691][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.0816e-02, 6.9122e-03, 1.8906e-02, 6.6769e-05, 5.2540e-03, 1.0740e-02,
        3.4022e-03, 3.2586e-04, 1.2365e-03, 1.4500e-03, 2.1855e-03, 1.9714e-01,
        5.9365e-03, 3.3159e-01, 2.5014e-01, 1.4011e-02, 1.1989e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,691][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.5738, 0.0268, 0.0517, 0.0024, 0.0129, 0.0205, 0.0207, 0.0139, 0.0047,
        0.0081, 0.0147, 0.0456, 0.0133, 0.0699, 0.0734, 0.0139, 0.0336],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,692][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([2.0478e-03, 4.8912e-04, 3.5501e-03, 2.6033e-06, 1.4118e-03, 1.4036e-03,
        1.0681e-03, 2.0435e-05, 1.6199e-04, 2.9605e-04, 5.2108e-04, 1.9273e-01,
        1.4235e-03, 4.6405e-01, 2.2554e-01, 6.8494e-03, 9.8434e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,692][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1247, 0.0285, 0.0605, 0.0005, 0.0114, 0.0158, 0.0116, 0.0020, 0.0031,
        0.0031, 0.0069, 0.1858, 0.0121, 0.1707, 0.2280, 0.0108, 0.1244],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,692][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.2379, 0.0388, 0.0748, 0.0024, 0.0180, 0.0344, 0.0254, 0.0060, 0.0085,
        0.0072, 0.0119, 0.1153, 0.0295, 0.1583, 0.1148, 0.0198, 0.0970],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,693][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0475, 0.0370, 0.0812, 0.0013, 0.0191, 0.0228, 0.0184, 0.0030, 0.0045,
        0.0040, 0.0065, 0.2092, 0.0209, 0.2270, 0.1746, 0.0135, 0.1094],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,695][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0024, 0.0112, 0.0115, 0.0006, 0.0162, 0.0143, 0.0157, 0.0021, 0.0082,
        0.0108, 0.0102, 0.3904, 0.0365, 0.1724, 0.1692, 0.0423, 0.0861],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:47,696][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.7904e-01, 8.4360e-03, 4.9959e-04, 1.8085e-03, 2.5607e-03, 2.2161e-04,
        3.9245e-04, 1.0567e-02, 5.5438e-04, 1.2909e-02, 3.9441e-01, 3.2582e-04,
        1.1981e-02, 4.2424e-02, 6.1250e-03, 1.0900e-02, 1.1848e-03, 3.1566e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,698][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0232, 0.0290, 0.0533, 0.0154, 0.0579, 0.0257, 0.0198, 0.0105, 0.0226,
        0.0202, 0.0236, 0.1466, 0.0553, 0.2085, 0.1379, 0.0465, 0.0778, 0.0263],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,700][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1994, 0.0528, 0.1097, 0.0049, 0.0326, 0.0191, 0.0840, 0.0147, 0.0330,
        0.0145, 0.0203, 0.0712, 0.0150, 0.0762, 0.1186, 0.0160, 0.0803, 0.0377],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,701][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0497, 0.0438, 0.0955, 0.0042, 0.0417, 0.0205, 0.0462, 0.0193, 0.0156,
        0.0269, 0.0162, 0.1719, 0.0393, 0.1137, 0.1295, 0.0627, 0.0588, 0.0445],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,703][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.8542e-03, 4.6386e-03, 5.9639e-03, 7.4390e-05, 6.1707e-03, 4.6740e-03,
        2.5913e-03, 2.5492e-04, 1.1509e-03, 1.2312e-03, 2.9924e-03, 3.7136e-01,
        5.8926e-03, 3.1244e-01, 1.2490e-01, 8.3144e-03, 1.1343e-01, 3.2070e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,704][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([8.9694e-02, 1.0012e-02, 3.1198e-02, 1.8031e-04, 1.0178e-02, 1.2959e-02,
        3.9833e-03, 7.4924e-04, 2.3658e-03, 2.3961e-03, 3.3928e-03, 1.9278e-01,
        8.0462e-03, 2.8285e-01, 1.6951e-01, 1.6186e-02, 1.4735e-01, 1.6165e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,705][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6392, 0.0180, 0.0479, 0.0017, 0.0109, 0.0122, 0.0160, 0.0100, 0.0056,
        0.0074, 0.0093, 0.0510, 0.0094, 0.0574, 0.0473, 0.0109, 0.0266, 0.0191],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,706][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([4.1066e-03, 1.2676e-03, 6.8203e-03, 1.8335e-05, 3.5912e-03, 2.2251e-03,
        2.4123e-03, 1.0392e-04, 5.3798e-04, 1.0246e-03, 1.4561e-03, 2.1807e-01,
        2.8702e-03, 3.9349e-01, 1.6806e-01, 1.3404e-02, 1.4348e-01, 3.7069e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,707][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2523, 0.0243, 0.0702, 0.0007, 0.0136, 0.0126, 0.0084, 0.0022, 0.0035,
        0.0031, 0.0072, 0.1571, 0.0100, 0.1182, 0.1670, 0.0090, 0.1066, 0.0340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,707][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2461, 0.0331, 0.0731, 0.0028, 0.0162, 0.0302, 0.0227, 0.0069, 0.0109,
        0.0082, 0.0140, 0.1317, 0.0288, 0.1100, 0.0925, 0.0236, 0.0988, 0.0503],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,708][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0830, 0.0388, 0.0738, 0.0018, 0.0183, 0.0226, 0.0218, 0.0043, 0.0059,
        0.0054, 0.0085, 0.2010, 0.0233, 0.1894, 0.1517, 0.0162, 0.1036, 0.0307],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,708][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0043, 0.0139, 0.0112, 0.0012, 0.0175, 0.0142, 0.0161, 0.0030, 0.0106,
        0.0154, 0.0135, 0.3075, 0.0375, 0.1432, 0.1520, 0.0608, 0.1052, 0.0727],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:47,709][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([1.1149e-01, 5.2967e-03, 7.4092e-04, 1.7627e-03, 3.0156e-03, 2.3383e-04,
        3.4134e-04, 7.8023e-03, 4.3062e-04, 1.2740e-02, 4.0744e-01, 5.4867e-04,
        1.2925e-02, 4.4770e-02, 7.2320e-03, 1.1336e-02, 1.5130e-03, 3.6811e-01,
        2.2684e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,709][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0013, 0.0239, 0.0326, 0.0174, 0.0457, 0.0416, 0.0265, 0.0088, 0.0191,
        0.0271, 0.0236, 0.1404, 0.0534, 0.1138, 0.0857, 0.0474, 0.0441, 0.0483,
        0.1993], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,710][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.1194, 0.0678, 0.1307, 0.0062, 0.0492, 0.0180, 0.0882, 0.0154, 0.0373,
        0.0140, 0.0191, 0.0731, 0.0124, 0.0685, 0.0763, 0.0143, 0.0696, 0.0365,
        0.0839], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,711][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.0180, 0.0299, 0.0634, 0.0028, 0.0323, 0.0191, 0.0420, 0.0148, 0.0139,
        0.0187, 0.0118, 0.1476, 0.0369, 0.0977, 0.1070, 0.0443, 0.0604, 0.0374,
        0.2021], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,712][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([1.6073e-03, 1.4995e-03, 2.6243e-03, 1.3422e-05, 1.4839e-03, 2.5340e-03,
        8.9916e-04, 5.9447e-05, 2.4433e-04, 4.3653e-04, 1.2263e-03, 1.4872e-01,
        2.9739e-03, 1.5714e-01, 6.0800e-02, 5.1365e-03, 4.6720e-02, 3.0096e-02,
        5.3579e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,713][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([7.0492e-02, 2.9924e-03, 8.5161e-03, 3.5205e-05, 1.7525e-03, 6.3435e-03,
        1.0523e-03, 2.3668e-04, 4.0524e-04, 5.4242e-04, 1.5463e-03, 6.0130e-02,
        4.6931e-03, 1.4205e-01, 6.7608e-02, 5.8231e-03, 4.4909e-02, 1.5557e-02,
        5.6532e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,715][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.2660, 0.0291, 0.0483, 0.0026, 0.0198, 0.0203, 0.0200, 0.0137, 0.0084,
        0.0119, 0.0127, 0.0675, 0.0165, 0.0860, 0.0639, 0.0183, 0.0437, 0.0330,
        0.2183], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,716][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([4.2369e-03, 2.3401e-04, 1.3032e-03, 1.6945e-06, 3.6860e-04, 1.1723e-03,
        3.8596e-04, 1.6418e-05, 8.4633e-05, 1.6236e-04, 4.0092e-04, 4.5810e-02,
        1.1805e-03, 1.1343e-01, 6.6469e-02, 3.3639e-03, 3.0716e-02, 1.9317e-02,
        7.1134e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,717][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.1074, 0.0259, 0.0555, 0.0004, 0.0073, 0.0158, 0.0074, 0.0011, 0.0019,
        0.0018, 0.0037, 0.1154, 0.0084, 0.0994, 0.1448, 0.0065, 0.0782, 0.0274,
        0.2919], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,719][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.1468, 0.0261, 0.0428, 0.0018, 0.0101, 0.0317, 0.0186, 0.0039, 0.0060,
        0.0052, 0.0094, 0.0916, 0.0232, 0.0794, 0.0831, 0.0150, 0.0718, 0.0339,
        0.2997], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,721][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.0289, 0.0254, 0.0449, 0.0011, 0.0119, 0.0198, 0.0142, 0.0025, 0.0040,
        0.0036, 0.0057, 0.1413, 0.0192, 0.1327, 0.1285, 0.0117, 0.0728, 0.0238,
        0.3081], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,723][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0013, 0.0089, 0.0054, 0.0005, 0.0084, 0.0090, 0.0098, 0.0011, 0.0048,
        0.0064, 0.0074, 0.2348, 0.0234, 0.1047, 0.0870, 0.0249, 0.0458, 0.0484,
        0.3680], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:47,724][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.6527e-01, 8.4073e-03, 4.1662e-04, 2.4694e-03, 2.6614e-03, 2.4329e-04,
        2.8160e-04, 8.8620e-03, 4.8401e-04, 1.3995e-02, 4.1637e-01, 2.9833e-04,
        1.4147e-02, 4.0508e-02, 5.4931e-03, 1.1636e-02, 8.9356e-04, 2.9388e-01,
        1.3912e-03, 1.2291e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,724][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0662, 0.0120, 0.0460, 0.0074, 0.0236, 0.0154, 0.0184, 0.0083, 0.0231,
        0.0121, 0.0117, 0.0921, 0.0189, 0.1221, 0.1065, 0.0227, 0.0509, 0.0180,
        0.2894, 0.0355], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,725][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1390, 0.0577, 0.1163, 0.0060, 0.0441, 0.0175, 0.0786, 0.0142, 0.0354,
        0.0157, 0.0248, 0.0604, 0.0161, 0.0817, 0.0739, 0.0166, 0.0562, 0.0389,
        0.0916, 0.0152], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,725][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0413, 0.0280, 0.0835, 0.0036, 0.0352, 0.0215, 0.0363, 0.0145, 0.0142,
        0.0224, 0.0139, 0.0985, 0.0302, 0.0876, 0.1058, 0.0517, 0.0482, 0.0408,
        0.1398, 0.0829], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,726][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([3.8803e-03, 2.4030e-03, 5.3091e-03, 3.0869e-05, 3.6367e-03, 3.5347e-03,
        1.4733e-03, 1.5335e-04, 4.9814e-04, 5.3601e-04, 1.5822e-03, 1.0504e-01,
        4.1258e-03, 1.9014e-01, 7.1398e-02, 3.6691e-03, 5.7969e-02, 2.6830e-02,
        4.7157e-01, 4.6221e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,726][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.4048e-01, 3.9575e-03, 2.3874e-02, 8.4413e-05, 4.2361e-03, 8.4274e-03,
        2.3683e-03, 3.8116e-04, 1.1001e-03, 7.2618e-04, 1.2479e-03, 4.8404e-02,
        4.0053e-03, 1.1643e-01, 8.0862e-02, 4.9661e-03, 5.4196e-02, 9.0280e-03,
        4.5729e-01, 3.7936e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,727][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6633, 0.0089, 0.0182, 0.0010, 0.0074, 0.0079, 0.0076, 0.0066, 0.0031,
        0.0039, 0.0059, 0.0257, 0.0049, 0.0578, 0.0271, 0.0063, 0.0181, 0.0161,
        0.0981, 0.0122], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,727][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.1193e-02, 3.6415e-04, 4.9526e-03, 4.6212e-06, 1.9292e-03, 1.3479e-03,
        1.0003e-03, 4.1995e-05, 1.2856e-04, 2.1414e-04, 5.3297e-04, 3.4711e-02,
        1.1431e-03, 1.6544e-01, 6.1686e-02, 2.5314e-03, 3.1631e-02, 1.7258e-02,
        6.0240e-01, 5.1496e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,728][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1903, 0.0191, 0.0668, 0.0006, 0.0094, 0.0141, 0.0096, 0.0021, 0.0035,
        0.0033, 0.0053, 0.0843, 0.0073, 0.0770, 0.1344, 0.0098, 0.0769, 0.0300,
        0.2221, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,730][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3060, 0.0178, 0.0507, 0.0017, 0.0098, 0.0192, 0.0133, 0.0043, 0.0061,
        0.0050, 0.0083, 0.0665, 0.0168, 0.0746, 0.0543, 0.0130, 0.0659, 0.0304,
        0.2053, 0.0309], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,732][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1009, 0.0312, 0.0819, 0.0014, 0.0187, 0.0184, 0.0155, 0.0034, 0.0039,
        0.0038, 0.0058, 0.1016, 0.0157, 0.1630, 0.0890, 0.0103, 0.0678, 0.0182,
        0.2211, 0.0282], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,733][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0023, 0.0100, 0.0114, 0.0007, 0.0122, 0.0114, 0.0111, 0.0016, 0.0079,
        0.0094, 0.0075, 0.1728, 0.0171, 0.0755, 0.0689, 0.0280, 0.0587, 0.0342,
        0.3634, 0.0961], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:47,734][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:47,737][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14428],
        [  281],
        [ 9237],
        [   55],
        [  243],
        [   25],
        [ 1040],
        [   50],
        [  633],
        [  143],
        [   32],
        [   89],
        [   75],
        [  149],
        [  305],
        [  119],
        [  214],
        [   28],
        [  124],
        [   70]], device='cuda:0')
[2024-07-24 10:18:47,739][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15395],
        [ 3537],
        [16662],
        [   85],
        [  532],
        [   86],
        [ 2892],
        [  240],
        [ 2321],
        [  453],
        [  140],
        [  654],
        [  433],
        [  593],
        [ 1435],
        [  412],
        [  957],
        [  218],
        [  729],
        [  322]], device='cuda:0')
[2024-07-24 10:18:47,741][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13432],
        [14433],
        [15988],
        [15830],
        [15399],
        [15291],
        [17160],
        [17254],
        [16487],
        [16793],
        [17393],
        [17390],
        [17198],
        [16952],
        [17994],
        [17975],
        [17141],
        [17693],
        [18072],
        [18323]], device='cuda:0')
[2024-07-24 10:18:47,742][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5963],
        [ 3632],
        [43059],
        [50168],
        [45887],
        [48916],
        [48626],
        [49552],
        [20852],
        [49549],
        [21819],
        [28491],
        [39657],
        [22271],
        [30901],
        [44568],
        [37311],
        [14423],
        [14859],
        [39297]], device='cuda:0')
[2024-07-24 10:18:47,743][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 533],
        [2398],
        [ 284],
        [ 617],
        [1156],
        [1417],
        [1843],
        [2504],
        [2171],
        [2466],
        [2954],
        [2990],
        [3143],
        [3558],
        [4122],
        [4476],
        [4468],
        [4983],
        [5043],
        [5682]], device='cuda:0')
[2024-07-24 10:18:47,744][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[17983],
        [24889],
        [24228],
        [24468],
        [24548],
        [26409],
        [30054],
        [29740],
        [29930],
        [31001],
        [31133],
        [34641],
        [33872],
        [31012],
        [34118],
        [34175],
        [35279],
        [35259],
        [32731],
        [32400]], device='cuda:0')
[2024-07-24 10:18:47,745][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38710],
        [23112],
        [30124],
        [31130],
        [33703],
        [34662],
        [33166],
        [33061],
        [34767],
        [34846],
        [35778],
        [40545],
        [41008],
        [41727],
        [41419],
        [41461],
        [42244],
        [42152],
        [42302],
        [42092]], device='cuda:0')
[2024-07-24 10:18:47,747][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1084],
        [ 592],
        [5153],
        [4790],
        [4149],
        [3919],
        [1607],
        [1827],
        [2101],
        [2179],
        [2264],
        [2367],
        [2220],
        [6371],
        [6944],
        [6229],
        [5486],
        [5566],
        [6710],
        [5877]], device='cuda:0')
[2024-07-24 10:18:47,749][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[16751],
        [12773],
        [13879],
        [ 9925],
        [11600],
        [10392],
        [10167],
        [ 9247],
        [ 9040],
        [ 9111],
        [ 8998],
        [ 9008],
        [ 8915],
        [ 9291],
        [ 9180],
        [ 9147],
        [ 8997],
        [ 8871],
        [ 8935],
        [ 8948]], device='cuda:0')
[2024-07-24 10:18:47,751][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40709],
        [35020],
        [36129],
        [37704],
        [38869],
        [41965],
        [41777],
        [41399],
        [43146],
        [45358],
        [46596],
        [44752],
        [45795],
        [44801],
        [45380],
        [45722],
        [45526],
        [45925],
        [47063],
        [47723]], device='cuda:0')
[2024-07-24 10:18:47,752][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17839],
        [23468],
        [42663],
        [46570],
        [43367],
        [43767],
        [41508],
        [45107],
        [46672],
        [45660],
        [45723],
        [32253],
        [24046],
        [24204],
        [24229],
        [27913],
        [26955],
        [27021],
        [21313],
        [23059]], device='cuda:0')
[2024-07-24 10:18:47,754][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 3556],
        [ 4945],
        [ 5348],
        [ 5942],
        [ 6129],
        [ 5201],
        [ 7116],
        [ 8019],
        [ 7580],
        [ 6630],
        [ 8807],
        [11817],
        [13803],
        [16894],
        [16696],
        [16483],
        [16138],
        [16189],
        [12923],
        [12914]], device='cuda:0')
[2024-07-24 10:18:47,756][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[41852],
        [29743],
        [36334],
        [29886],
        [34909],
        [28232],
        [17946],
        [17440],
        [16464],
        [14868],
        [14800],
        [15483],
        [12447],
        [17247],
        [13105],
        [12673],
        [13225],
        [12916],
        [12727],
        [11055]], device='cuda:0')
[2024-07-24 10:18:47,758][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 4530],
        [ 3530],
        [48563],
        [44175],
        [42295],
        [39323],
        [37046],
        [34372],
        [33828],
        [31117],
        [28749],
        [31883],
        [31109],
        [32975],
        [31069],
        [29387],
        [27423],
        [25743],
        [23904],
        [22770]], device='cuda:0')
[2024-07-24 10:18:47,759][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24890],
        [23101],
        [21065],
        [22009],
        [21254],
        [19575],
        [21891],
        [19148],
        [23255],
        [23124],
        [21718],
        [17513],
        [24920],
        [14226],
        [17009],
        [18758],
        [16934],
        [17975],
        [16288],
        [20074]], device='cuda:0')
[2024-07-24 10:18:47,760][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[22903],
        [ 3523],
        [ 3401],
        [ 7374],
        [ 5096],
        [ 7896],
        [ 4335],
        [ 4607],
        [ 6413],
        [ 7660],
        [ 7374],
        [ 7592],
        [ 7177],
        [ 5421],
        [ 5908],
        [ 6216],
        [ 5857],
        [ 6523],
        [ 6401],
        [ 6536]], device='cuda:0')
[2024-07-24 10:18:47,762][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8330],
        [ 8528],
        [10212],
        [10969],
        [12716],
        [14677],
        [14076],
        [13242],
        [16624],
        [17342],
        [15600],
        [10071],
        [10156],
        [ 9530],
        [ 8382],
        [ 8588],
        [ 8916],
        [ 9185],
        [ 4236],
        [ 2688]], device='cuda:0')
[2024-07-24 10:18:47,763][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[44821],
        [44188],
        [11531],
        [12655],
        [17196],
        [24054],
        [20278],
        [20499],
        [17905],
        [18769],
        [23154],
        [19631],
        [24788],
        [17848],
        [22434],
        [20347],
        [19837],
        [21300],
        [20060],
        [20279]], device='cuda:0')
[2024-07-24 10:18:47,764][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[35677],
        [22001],
        [10879],
        [11764],
        [12251],
        [15614],
        [21363],
        [21874],
        [23781],
        [26132],
        [26601],
        [31095],
        [29495],
        [28421],
        [30879],
        [31515],
        [30716],
        [31144],
        [31601],
        [31402]], device='cuda:0')
[2024-07-24 10:18:47,766][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[29234],
        [48441],
        [48736],
        [48754],
        [46608],
        [48578],
        [47683],
        [45897],
        [43542],
        [45412],
        [42973],
        [40096],
        [40242],
        [26756],
        [29657],
        [27835],
        [28111],
        [30343],
        [19482],
        [21229]], device='cuda:0')
[2024-07-24 10:18:47,767][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[42702],
        [38110],
        [33884],
        [31698],
        [28749],
        [29712],
        [32757],
        [30180],
        [27043],
        [26490],
        [26173],
        [19811],
        [19669],
        [16997],
        [17751],
        [17898],
        [17872],
        [17808],
        [17682],
        [17895]], device='cuda:0')
[2024-07-24 10:18:47,769][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32271],
        [31247],
        [28613],
        [33982],
        [34336],
        [32650],
        [26239],
        [29793],
        [32010],
        [36447],
        [34356],
        [32956],
        [32706],
        [32995],
        [30282],
        [36104],
        [35547],
        [36144],
        [35187],
        [38570]], device='cuda:0')
[2024-07-24 10:18:47,771][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5517],
        [26958],
        [29278],
        [30273],
        [34113],
        [31552],
        [27547],
        [29704],
        [27990],
        [27919],
        [27638],
        [12834],
        [13018],
        [25313],
        [24500],
        [25515],
        [24856],
        [25702],
        [19664],
        [20163]], device='cuda:0')
[2024-07-24 10:18:47,773][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30501],
        [42373],
        [43903],
        [42125],
        [41169],
        [39284],
        [38336],
        [37272],
        [35733],
        [37379],
        [36979],
        [32175],
        [30496],
        [29728],
        [27711],
        [29389],
        [29287],
        [29946],
        [34458],
        [34985]], device='cuda:0')
[2024-07-24 10:18:47,774][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28826],
        [28759],
        [20096],
        [19269],
        [19238],
        [20389],
        [21808],
        [20757],
        [21102],
        [21553],
        [19536],
        [12218],
        [11337],
        [10490],
        [10613],
        [11184],
        [10888],
        [11500],
        [11841],
        [12842]], device='cuda:0')
[2024-07-24 10:18:47,776][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[13342],
        [ 8136],
        [ 9342],
        [10317],
        [13083],
        [15464],
        [17144],
        [19143],
        [18789],
        [18569],
        [20175],
        [27902],
        [27786],
        [30669],
        [27536],
        [27292],
        [23104],
        [22337],
        [23206],
        [23192]], device='cuda:0')
[2024-07-24 10:18:47,778][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3489],
        [  552],
        [ 1657],
        [ 5315],
        [  308],
        [  309],
        [  951],
        [  909],
        [ 2993],
        [ 1183],
        [ 1298],
        [ 3734],
        [ 3699],
        [ 1720],
        [ 3786],
        [ 3275],
        [ 5234],
        [ 5980],
        [11199],
        [12946]], device='cuda:0')
[2024-07-24 10:18:47,779][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20156],
        [17945],
        [26018],
        [20123],
        [23890],
        [18459],
        [21953],
        [22638],
        [20368],
        [17507],
        [19492],
        [28250],
        [28317],
        [30808],
        [29893],
        [27892],
        [28435],
        [26636],
        [29161],
        [27620]], device='cuda:0')
[2024-07-24 10:18:47,780][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18286],
        [ 7847],
        [21866],
        [20802],
        [26931],
        [26216],
        [19956],
        [24614],
        [23542],
        [23058],
        [24649],
        [32944],
        [29041],
        [40502],
        [37298],
        [36218],
        [38099],
        [36128],
        [39373],
        [36329]], device='cuda:0')
[2024-07-24 10:18:47,781][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932],
        [6932]], device='cuda:0')
[2024-07-24 10:18:47,835][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:47,835][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,835][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,836][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,836][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,837][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,838][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,838][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,839][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,839][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,839][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,839][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,840][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:47,841][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,843][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0273, 0.9727], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,844][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2162, 0.7838], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,845][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9965, 0.0035], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,847][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4206, 0.5794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,849][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8764, 0.1236], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,850][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0177, 0.9823], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,851][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1997, 0.8003], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,852][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8947, 0.1053], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,853][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([6.6493e-04, 9.9933e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,853][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0398, 0.9602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,853][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:47,854][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.4924, 0.2027, 0.3049], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,854][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0018, 0.0949, 0.9034], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,854][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.3221, 0.3971, 0.2809], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,855][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([9.9440e-01, 4.9738e-03, 6.2235e-04], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,855][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0744, 0.2007, 0.7249], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,855][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.7813, 0.1700, 0.0487], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,855][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0060, 0.3326, 0.6613], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,856][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.0832, 0.4722, 0.4446], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,857][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.9497, 0.0231, 0.0272], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,858][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([7.8530e-04, 8.5876e-01, 1.4045e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,860][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0177, 0.9455, 0.0369], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,861][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0030, 0.9173, 0.0797], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:47,863][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6120, 0.2243, 0.1563, 0.0073], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,863][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.6395e-04, 5.4544e-02, 8.0342e-01, 1.4157e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,865][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1713, 0.3318, 0.2203, 0.2766], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,866][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([8.6882e-01, 5.7708e-02, 7.2842e-02, 6.2885e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,868][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2851, 0.1897, 0.4599, 0.0652], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,869][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8740, 0.0830, 0.0360, 0.0070], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,870][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0081, 0.2382, 0.5509, 0.2029], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,870][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0562, 0.3362, 0.3558, 0.2518], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,870][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9173, 0.0446, 0.0278, 0.0104], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,871][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0009, 0.3945, 0.1216, 0.4831], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,871][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.8216e-03, 8.4131e-01, 1.5557e-01, 2.9690e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,871][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0027, 0.4837, 0.0600, 0.4536], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:47,872][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.3990, 0.3472, 0.1963, 0.0137, 0.0438], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,872][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0007, 0.0279, 0.4008, 0.0317, 0.5388], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,872][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.2418, 0.1815, 0.1358, 0.1437, 0.2972], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,873][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([9.8450e-01, 9.5596e-03, 3.5164e-03, 3.2535e-05, 2.3927e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,873][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.1819, 0.2474, 0.4390, 0.0721, 0.0595], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,875][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.8763, 0.0765, 0.0249, 0.0039, 0.0184], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,876][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0047, 0.1695, 0.3890, 0.1442, 0.2926], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,878][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0542, 0.2565, 0.2669, 0.1682, 0.2542], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,879][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.9211, 0.0158, 0.0094, 0.0050, 0.0487], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,880][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([3.3516e-04, 2.9355e-01, 4.2679e-02, 3.0996e-01, 3.5347e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,881][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([1.0379e-02, 8.6944e-01, 1.0791e-01, 4.9225e-05, 1.2218e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,883][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0030, 0.4270, 0.0410, 0.4402, 0.0887], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:47,885][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.5796, 0.2086, 0.1189, 0.0130, 0.0288, 0.0512], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,885][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ were] are: tensor([2.7600e-04, 2.7264e-02, 2.7976e-01, 6.7229e-02, 5.8951e-01, 3.5958e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,887][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1304, 0.1749, 0.0998, 0.1335, 0.2853, 0.1761], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,887][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ were] are: tensor([9.0265e-01, 4.6712e-02, 1.7195e-02, 6.8961e-04, 3.2536e-02, 2.1642e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,887][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0992, 0.1257, 0.5084, 0.0627, 0.0833, 0.1207], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,888][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.8543, 0.0571, 0.0278, 0.0068, 0.0176, 0.0363], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,888][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0030, 0.1252, 0.2721, 0.1193, 0.2494, 0.2310], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,889][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0504, 0.1944, 0.1995, 0.1405, 0.2002, 0.2150], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,889][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.8381, 0.0376, 0.0284, 0.0080, 0.0363, 0.0515], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,889][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ were] are: tensor([2.9111e-04, 1.6885e-01, 6.2715e-02, 1.7164e-01, 4.0145e-01, 1.9505e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,890][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ were] are: tensor([1.3309e-02, 9.2048e-01, 2.8097e-02, 5.1357e-04, 1.0164e-02, 2.7438e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,890][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0066, 0.3919, 0.0445, 0.2782, 0.0716, 0.2071], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:47,890][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.3857, 0.2358, 0.1664, 0.0112, 0.0425, 0.0821, 0.0763],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,891][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([3.0514e-04, 1.8690e-02, 2.5693e-01, 3.5375e-02, 6.1928e-01, 2.8736e-02,
        4.0685e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,893][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0722, 0.1319, 0.0675, 0.1122, 0.2200, 0.1224, 0.2739],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,894][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([8.2126e-01, 1.5497e-01, 7.6413e-03, 5.9595e-04, 1.4080e-02, 1.3457e-04,
        1.3163e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,895][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0397, 0.1363, 0.4633, 0.0670, 0.0673, 0.1974, 0.0291],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,897][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.5901, 0.1321, 0.0531, 0.0075, 0.0415, 0.0699, 0.1058],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,898][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0018, 0.1161, 0.2099, 0.1110, 0.2048, 0.1986, 0.1577],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,899][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0379, 0.1659, 0.1592, 0.1067, 0.1632, 0.1793, 0.1877],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,901][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.4214, 0.1514, 0.0153, 0.0309, 0.0561, 0.1589, 0.1660],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,902][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([2.2914e-04, 1.3297e-01, 5.7437e-02, 1.1633e-01, 3.3818e-01, 2.9788e-01,
        5.6961e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,903][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([1.3198e-03, 9.5560e-01, 6.0315e-03, 8.8846e-05, 4.6628e-03, 1.0962e-02,
        2.1338e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,904][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0007, 0.3047, 0.0175, 0.3865, 0.0456, 0.2124, 0.0325],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:47,905][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.2786, 0.2886, 0.1980, 0.0106, 0.0516, 0.0380, 0.1233, 0.0113],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,905][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ about] are: tensor([2.9497e-04, 1.2741e-02, 3.3143e-01, 3.4318e-02, 4.6204e-01, 3.8115e-02,
        8.6463e-02, 3.4599e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,906][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0455, 0.1265, 0.0731, 0.1204, 0.2208, 0.1039, 0.2301, 0.0797],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,906][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ about] are: tensor([1.3173e-01, 3.1709e-01, 9.9255e-02, 3.3770e-03, 4.2259e-01, 1.2107e-03,
        2.4343e-02, 4.0439e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,906][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0553, 0.1598, 0.4580, 0.0558, 0.0751, 0.1367, 0.0289, 0.0303],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,907][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.3987, 0.1102, 0.0960, 0.0150, 0.0808, 0.0936, 0.1755, 0.0304],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,907][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0019, 0.1027, 0.2045, 0.0918, 0.1911, 0.1742, 0.1358, 0.0981],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,907][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0293, 0.1455, 0.1408, 0.1054, 0.1549, 0.1518, 0.1672, 0.1052],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,908][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.4420, 0.0916, 0.0629, 0.0376, 0.0510, 0.0670, 0.1875, 0.0603],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,908][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ about] are: tensor([1.8080e-04, 1.5888e-01, 1.0782e-01, 1.1191e-01, 3.6397e-01, 1.6932e-01,
        5.6091e-02, 3.1830e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,909][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ about] are: tensor([8.1682e-04, 8.5903e-01, 1.7588e-02, 3.5102e-04, 3.8367e-02, 8.6021e-03,
        7.4858e-02, 3.9170e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,911][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0030, 0.3992, 0.0214, 0.3183, 0.0465, 0.1540, 0.0337, 0.0239],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:47,912][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.4568, 0.1627, 0.1732, 0.0077, 0.0467, 0.0558, 0.0701, 0.0105, 0.0165],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,914][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0006, 0.0120, 0.2727, 0.0243, 0.5096, 0.0261, 0.0634, 0.0275, 0.0638],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,915][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0417, 0.1469, 0.0665, 0.1143, 0.1658, 0.1232, 0.1955, 0.0631, 0.0831],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,916][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ going] are: tensor([8.3807e-01, 3.5567e-02, 4.3635e-02, 6.0314e-04, 8.0638e-02, 1.4461e-04,
        1.0793e-03, 3.2638e-05, 2.2720e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,918][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.1171, 0.1285, 0.3921, 0.0439, 0.0589, 0.1275, 0.0283, 0.0380, 0.0657],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,920][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.6166, 0.0875, 0.0562, 0.0054, 0.0493, 0.0495, 0.0995, 0.0146, 0.0214],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,921][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0022, 0.0928, 0.1918, 0.0832, 0.1671, 0.1444, 0.1236, 0.0849, 0.1102],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,922][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0248, 0.1216, 0.1318, 0.0881, 0.1350, 0.1326, 0.1501, 0.0915, 0.1246],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,922][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.4687, 0.0929, 0.0176, 0.0148, 0.0436, 0.1064, 0.1850, 0.0514, 0.0196],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,923][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ going] are: tensor([2.5254e-04, 1.2965e-01, 4.5711e-02, 9.1656e-02, 3.3939e-01, 1.4195e-01,
        4.1482e-02, 4.3732e-02, 1.6617e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,923][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ going] are: tensor([2.6914e-03, 7.1808e-01, 1.2221e-01, 1.0802e-04, 6.8008e-02, 2.7259e-02,
        5.6596e-02, 1.5139e-04, 4.8988e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,923][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0019, 0.3054, 0.0123, 0.2922, 0.0353, 0.1361, 0.0322, 0.0219, 0.1625],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:47,924][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5055, 0.2241, 0.1403, 0.0054, 0.0261, 0.0252, 0.0532, 0.0042, 0.0086,
        0.0075], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,924][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.0149, 0.2573, 0.0335, 0.3398, 0.0345, 0.0974, 0.0434, 0.1139,
        0.0645], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,925][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0333, 0.1199, 0.0676, 0.0883, 0.1807, 0.1082, 0.1953, 0.0568, 0.0710,
        0.0790], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,925][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.0644e-01, 2.6590e-02, 4.6836e-02, 5.7715e-04, 1.1358e-01, 3.0574e-04,
        3.5425e-03, 9.9198e-05, 1.5184e-03, 5.0601e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,925][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1424, 0.0985, 0.4414, 0.0421, 0.0468, 0.0806, 0.0205, 0.0250, 0.0319,
        0.0707], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,926][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.7644, 0.0405, 0.0405, 0.0036, 0.0252, 0.0283, 0.0701, 0.0082, 0.0109,
        0.0083], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,928][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0021, 0.0757, 0.1669, 0.0730, 0.1461, 0.1370, 0.1089, 0.0751, 0.1075,
        0.1077], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,930][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0238, 0.1070, 0.1167, 0.0820, 0.1269, 0.1175, 0.1277, 0.0825, 0.1132,
        0.1027], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,931][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6543, 0.0364, 0.0256, 0.0099, 0.0369, 0.0384, 0.1648, 0.0190, 0.0108,
        0.0041], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,932][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0004, 0.0634, 0.0662, 0.0539, 0.2250, 0.1064, 0.0351, 0.0292, 0.2097,
        0.2107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,934][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.7402e-02, 5.6076e-01, 2.1762e-01, 1.2467e-04, 1.0462e-01, 3.1020e-02,
        5.6706e-02, 2.0137e-04, 6.9550e-03, 4.5991e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,935][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0029, 0.2326, 0.0203, 0.1518, 0.0361, 0.1109, 0.0501, 0.0393, 0.1537,
        0.2023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:47,937][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5074, 0.2022, 0.1435, 0.0058, 0.0242, 0.0252, 0.0626, 0.0058, 0.0090,
        0.0058, 0.0085], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,938][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0004, 0.0136, 0.2786, 0.0234, 0.3617, 0.0223, 0.0597, 0.0230, 0.0586,
        0.0350, 0.1236], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,939][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0458, 0.0904, 0.0686, 0.0794, 0.1759, 0.0891, 0.1656, 0.0483, 0.0718,
        0.0785, 0.0866], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,939][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([3.8915e-01, 9.2772e-02, 1.8616e-01, 1.8436e-03, 3.1658e-01, 8.3117e-04,
        4.3899e-03, 1.7809e-04, 2.9223e-03, 3.9304e-03, 1.2429e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,940][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1396, 0.0997, 0.3303, 0.0413, 0.0465, 0.1175, 0.0293, 0.0195, 0.0520,
        0.0851, 0.0390], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,940][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7569, 0.0403, 0.0409, 0.0043, 0.0256, 0.0305, 0.0624, 0.0088, 0.0141,
        0.0087, 0.0076], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,941][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0035, 0.0707, 0.1527, 0.0644, 0.1419, 0.1204, 0.1061, 0.0668, 0.0941,
        0.0936, 0.0857], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,941][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0204, 0.0966, 0.1071, 0.0757, 0.1157, 0.1086, 0.1172, 0.0748, 0.1039,
        0.0955, 0.0845], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,941][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([9.2386e-01, 4.7465e-03, 3.8053e-03, 8.2057e-04, 1.2527e-02, 8.8933e-03,
        3.7776e-02, 2.9581e-03, 2.2608e-03, 3.9440e-04, 1.9609e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,942][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0003, 0.0815, 0.0460, 0.0529, 0.1960, 0.0886, 0.0372, 0.0265, 0.1539,
        0.2325, 0.0848], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,942][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.0306e-02, 3.7948e-01, 3.3677e-01, 3.7992e-04, 1.3869e-01, 4.3322e-02,
        4.8076e-02, 3.3795e-04, 1.3530e-02, 8.8454e-03, 1.0264e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,943][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0017, 0.2560, 0.0168, 0.1410, 0.0356, 0.0951, 0.0388, 0.0233, 0.1293,
        0.1281, 0.1343], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:47,944][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.6639, 0.1731, 0.0754, 0.0024, 0.0089, 0.0146, 0.0328, 0.0026, 0.0030,
        0.0027, 0.0043, 0.0162], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,945][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ school] are: tensor([2.8249e-04, 1.1233e-02, 1.6741e-01, 1.0145e-02, 1.8565e-01, 1.1828e-02,
        2.0758e-02, 1.0004e-02, 2.1962e-02, 1.8668e-02, 6.5867e-02, 4.7620e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,947][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0662, 0.1004, 0.0533, 0.0649, 0.1580, 0.0833, 0.1696, 0.0441, 0.0529,
        0.0544, 0.0627, 0.0902], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,948][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ school] are: tensor([9.6402e-01, 1.1876e-02, 8.1822e-03, 1.1952e-04, 1.4603e-02, 3.7959e-05,
        1.2372e-04, 5.9415e-06, 6.0523e-05, 1.2133e-04, 9.6248e-05, 7.5079e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,949][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.0585, 0.1244, 0.3123, 0.0519, 0.0416, 0.1068, 0.0212, 0.0267, 0.0393,
        0.1063, 0.0724, 0.0386], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,951][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.8568, 0.0314, 0.0207, 0.0022, 0.0098, 0.0234, 0.0297, 0.0035, 0.0037,
        0.0042, 0.0034, 0.0111], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,953][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0017, 0.0658, 0.1182, 0.0569, 0.1123, 0.0997, 0.0884, 0.0596, 0.0734,
        0.0811, 0.0824, 0.1605], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,955][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.0297, 0.0932, 0.1045, 0.0590, 0.0927, 0.0998, 0.0932, 0.0585, 0.0818,
        0.0781, 0.0714, 0.1380], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,956][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.5690, 0.0701, 0.0178, 0.0111, 0.0342, 0.0859, 0.0564, 0.0261, 0.0093,
        0.0079, 0.0766, 0.0357], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,958][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ school] are: tensor([0.0003, 0.0784, 0.0508, 0.0450, 0.1610, 0.1478, 0.0205, 0.0142, 0.0844,
        0.1096, 0.0697, 0.2182], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,959][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ school] are: tensor([1.3781e-02, 1.5990e-02, 3.2347e-02, 3.2596e-06, 2.3722e-03, 5.6149e-03,
        7.5523e-04, 3.8470e-06, 1.2644e-04, 1.1462e-04, 3.6473e-04, 9.2853e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,961][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.0018, 0.1586, 0.0123, 0.1326, 0.0322, 0.1027, 0.0179, 0.0160, 0.0804,
        0.1593, 0.1599, 0.1263], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:47,961][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4526, 0.1864, 0.1521, 0.0064, 0.0231, 0.0253, 0.0520, 0.0063, 0.0086,
        0.0089, 0.0105, 0.0455, 0.0223], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,962][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([8.3682e-05, 4.3451e-03, 9.7907e-02, 7.0224e-03, 1.3632e-01, 6.8517e-03,
        1.9670e-02, 6.1101e-03, 2.2540e-02, 1.0096e-02, 3.7887e-02, 6.2954e-01,
        2.1631e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,962][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0176, 0.0836, 0.0443, 0.0716, 0.1473, 0.0745, 0.1122, 0.0384, 0.0521,
        0.0612, 0.1120, 0.0989, 0.0863], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,963][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.4804, 0.0837, 0.0579, 0.0042, 0.2648, 0.0017, 0.0106, 0.0008, 0.0103,
        0.0086, 0.0073, 0.0681, 0.0016], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,963][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0990, 0.0989, 0.3233, 0.0375, 0.0437, 0.0910, 0.0205, 0.0187, 0.0350,
        0.0734, 0.0474, 0.0326, 0.0791], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,963][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.8417, 0.0328, 0.0235, 0.0023, 0.0130, 0.0199, 0.0348, 0.0048, 0.0067,
        0.0047, 0.0037, 0.0080, 0.0042], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,964][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0017, 0.0546, 0.1035, 0.0498, 0.1163, 0.0852, 0.0827, 0.0569, 0.0687,
        0.0737, 0.0744, 0.1548, 0.0778], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,964][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0206, 0.0773, 0.0875, 0.0565, 0.0881, 0.0855, 0.0855, 0.0601, 0.0821,
        0.0762, 0.0695, 0.1276, 0.0837], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,965][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.5134, 0.0711, 0.0169, 0.0125, 0.0613, 0.0751, 0.0727, 0.0475, 0.0315,
        0.0043, 0.0409, 0.0322, 0.0206], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,965][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([7.8289e-05, 2.6314e-02, 2.6674e-02, 2.4754e-02, 1.2454e-01, 7.0085e-02,
        1.1980e-02, 1.2515e-02, 6.4586e-02, 1.0298e-01, 5.4382e-02, 2.9626e-01,
        1.8486e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,967][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([8.3008e-03, 5.5831e-02, 8.7993e-03, 4.0920e-05, 2.5932e-03, 2.8295e-03,
        3.1644e-03, 6.0274e-05, 8.3368e-04, 6.0057e-04, 1.6579e-03, 9.1052e-01,
        4.7683e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,968][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0017, 0.1907, 0.0103, 0.1180, 0.0212, 0.0695, 0.0250, 0.0172, 0.0890,
        0.1080, 0.1185, 0.0905, 0.1405], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:47,970][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.1168, 0.1975, 0.1600, 0.0107, 0.0396, 0.0512, 0.0551, 0.0072, 0.0175,
        0.0136, 0.0215, 0.0911, 0.0567, 0.1614], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,971][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([1.1727e-04, 4.9769e-03, 7.5847e-02, 6.0009e-03, 1.1257e-01, 9.7663e-03,
        1.7827e-02, 7.5902e-03, 2.0272e-02, 1.4088e-02, 4.0893e-02, 3.6851e-01,
        1.8574e-02, 3.0297e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,972][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0543, 0.0751, 0.0442, 0.0552, 0.1078, 0.0722, 0.1136, 0.0336, 0.0455,
        0.0505, 0.0527, 0.0809, 0.0858, 0.1286], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,974][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([9.9132e-01, 2.1527e-03, 1.8011e-03, 1.6896e-05, 1.2009e-03, 7.9594e-06,
        1.6593e-05, 7.4487e-07, 7.2791e-06, 1.5352e-05, 9.6846e-06, 9.8612e-05,
        1.5057e-05, 3.3405e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,976][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0139, 0.0705, 0.1949, 0.0403, 0.0412, 0.0750, 0.0112, 0.0152, 0.0356,
        0.1271, 0.0786, 0.0664, 0.1668, 0.0633], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,977][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([0.6129, 0.0746, 0.0433, 0.0053, 0.0255, 0.0517, 0.0606, 0.0081, 0.0135,
        0.0101, 0.0099, 0.0229, 0.0127, 0.0488], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,978][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0009, 0.0485, 0.1091, 0.0445, 0.0815, 0.0921, 0.0671, 0.0488, 0.0581,
        0.0593, 0.0674, 0.1397, 0.0744, 0.1087], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,979][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.0201, 0.0735, 0.0839, 0.0470, 0.0770, 0.0827, 0.0766, 0.0473, 0.0668,
        0.0642, 0.0565, 0.1134, 0.0749, 0.1161], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,979][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.6035, 0.0201, 0.0108, 0.0059, 0.0482, 0.0849, 0.0500, 0.0171, 0.0159,
        0.0022, 0.0108, 0.0453, 0.0129, 0.0724], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,980][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([5.8958e-05, 4.4093e-02, 1.6543e-02, 3.9232e-02, 8.6319e-02, 8.5280e-02,
        1.1589e-02, 7.5552e-03, 5.4262e-02, 9.8655e-02, 3.8259e-02, 1.8129e-01,
        1.8601e-01, 1.5085e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,980][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([6.3907e-03, 1.6239e-02, 2.5189e-02, 2.6544e-06, 1.4686e-03, 4.1151e-03,
        7.0520e-04, 3.0743e-06, 6.2809e-05, 9.7364e-05, 1.5004e-04, 6.1632e-01,
        2.0646e-03, 3.2719e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,980][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0016, 0.1767, 0.0087, 0.1276, 0.0247, 0.0660, 0.0111, 0.0084, 0.0544,
        0.1376, 0.1045, 0.1073, 0.1308, 0.0408], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:47,981][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.2247, 0.1460, 0.1267, 0.0073, 0.0240, 0.0410, 0.0709, 0.0093, 0.0135,
        0.0119, 0.0151, 0.0888, 0.0405, 0.0961, 0.0843], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,981][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([5.7741e-05, 3.1627e-03, 4.7549e-02, 6.5573e-03, 9.9045e-02, 6.3692e-03,
        1.4302e-02, 6.8084e-03, 2.0728e-02, 1.2511e-02, 4.1521e-02, 4.1709e-01,
        2.1466e-02, 2.7257e-01, 3.0272e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,982][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0197, 0.0662, 0.0366, 0.0557, 0.1024, 0.0701, 0.1231, 0.0360, 0.0539,
        0.0486, 0.0618, 0.0673, 0.0600, 0.1100, 0.0886], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,982][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([8.7351e-01, 1.9574e-02, 1.7731e-02, 5.5531e-04, 2.2260e-02, 1.7758e-04,
        9.6392e-04, 6.3125e-05, 2.3235e-04, 5.4327e-04, 5.5742e-04, 3.5072e-03,
        4.7139e-04, 5.8252e-02, 1.6001e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,984][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0231, 0.0539, 0.2986, 0.0270, 0.0329, 0.0763, 0.0090, 0.0172, 0.0442,
        0.1191, 0.0783, 0.0563, 0.0904, 0.0409, 0.0327], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,986][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.6144, 0.0539, 0.0378, 0.0033, 0.0216, 0.0459, 0.0550, 0.0072, 0.0110,
        0.0066, 0.0069, 0.0175, 0.0091, 0.0403, 0.0695], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,988][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0012, 0.0462, 0.0895, 0.0464, 0.0859, 0.0722, 0.0611, 0.0462, 0.0587,
        0.0625, 0.0669, 0.1160, 0.0636, 0.1128, 0.0708], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,989][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0163, 0.0630, 0.0702, 0.0431, 0.0689, 0.0727, 0.0688, 0.0443, 0.0636,
        0.0589, 0.0527, 0.1028, 0.0682, 0.1056, 0.1012], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,991][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.1583, 0.0624, 0.0229, 0.0177, 0.0808, 0.1227, 0.1582, 0.0708, 0.0370,
        0.0038, 0.0691, 0.0571, 0.0094, 0.0602, 0.0697], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,992][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([3.1036e-05, 1.3126e-02, 9.4942e-03, 1.6062e-02, 7.8942e-02, 4.2080e-02,
        8.1635e-03, 8.3363e-03, 3.9399e-02, 8.0181e-02, 3.4411e-02, 2.1682e-01,
        1.1903e-01, 2.9242e-01, 4.1501e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,993][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([3.9144e-03, 1.6759e-02, 7.4405e-03, 1.6465e-06, 6.1398e-04, 2.2842e-03,
        6.6460e-04, 2.8414e-06, 4.1655e-05, 4.7218e-05, 8.6401e-05, 3.5725e-01,
        1.6428e-03, 1.9119e-01, 4.1807e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,995][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0028, 0.1879, 0.0098, 0.1158, 0.0243, 0.0638, 0.0103, 0.0110, 0.0446,
        0.1118, 0.0905, 0.0825, 0.1200, 0.0425, 0.0823], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:47,996][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4814, 0.1319, 0.1075, 0.0036, 0.0184, 0.0176, 0.0459, 0.0031, 0.0063,
        0.0046, 0.0067, 0.0400, 0.0127, 0.0657, 0.0485, 0.0060],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,996][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.3997e-05, 2.8259e-03, 4.8920e-02, 6.3435e-03, 8.1482e-02, 6.5337e-03,
        2.0596e-02, 7.2802e-03, 2.3600e-02, 1.2069e-02, 3.7496e-02, 3.7979e-01,
        2.0047e-02, 2.9917e-01, 3.9356e-02, 1.4408e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,997][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0136, 0.0693, 0.0328, 0.0561, 0.0940, 0.0627, 0.1028, 0.0315, 0.0471,
        0.0468, 0.0794, 0.0863, 0.0611, 0.0923, 0.0719, 0.0521],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,997][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.4152e-01, 1.3237e-02, 4.2414e-02, 7.2118e-04, 1.0492e-01, 3.2065e-04,
        1.7889e-03, 8.8271e-05, 1.5095e-03, 4.8077e-04, 7.0194e-04, 8.7674e-03,
        2.6399e-04, 2.7416e-01, 8.6596e-03, 4.4689e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,997][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1238, 0.0561, 0.3265, 0.0259, 0.0408, 0.0545, 0.0183, 0.0178, 0.0237,
        0.0519, 0.0329, 0.0255, 0.0454, 0.0535, 0.0417, 0.0618],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,998][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.7192, 0.0275, 0.0448, 0.0025, 0.0202, 0.0244, 0.0492, 0.0062, 0.0079,
        0.0053, 0.0039, 0.0136, 0.0038, 0.0266, 0.0357, 0.0093],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,998][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0011, 0.0427, 0.0916, 0.0424, 0.0781, 0.0783, 0.0612, 0.0428, 0.0587,
        0.0610, 0.0624, 0.1005, 0.0561, 0.0975, 0.0669, 0.0587],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,999][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0133, 0.0555, 0.0668, 0.0441, 0.0702, 0.0649, 0.0652, 0.0436, 0.0608,
        0.0544, 0.0505, 0.0931, 0.0627, 0.1002, 0.0895, 0.0653],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:47,999][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4315, 0.0400, 0.0258, 0.0176, 0.0344, 0.0665, 0.1670, 0.0276, 0.0193,
        0.0080, 0.0303, 0.0228, 0.0119, 0.0532, 0.0375, 0.0066],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,001][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0003, 0.0212, 0.0281, 0.0186, 0.0884, 0.0426, 0.0132, 0.0129, 0.0732,
        0.0874, 0.0382, 0.1358, 0.0972, 0.2145, 0.0440, 0.0846],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,002][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.1601e-03, 3.1591e-03, 9.4768e-03, 1.1346e-06, 1.7597e-03, 5.6910e-04,
        5.0092e-04, 1.5992e-06, 5.4116e-05, 3.2368e-05, 5.7242e-05, 2.7645e-01,
        3.2486e-04, 2.5982e-01, 4.4586e-01, 7.7674e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,004][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0018, 0.1285, 0.0099, 0.0900, 0.0213, 0.0574, 0.0174, 0.0169, 0.0549,
        0.1128, 0.0906, 0.0802, 0.0974, 0.0446, 0.0873, 0.0890],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,005][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.4820, 0.0994, 0.1632, 0.0022, 0.0167, 0.0203, 0.0306, 0.0030, 0.0058,
        0.0027, 0.0056, 0.0250, 0.0113, 0.0623, 0.0402, 0.0047, 0.0250],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,006][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([1.4541e-04, 4.8778e-03, 7.3623e-02, 7.2464e-03, 1.0707e-01, 7.6563e-03,
        1.5178e-02, 7.4064e-03, 1.6802e-02, 1.1790e-02, 4.6162e-02, 3.3386e-01,
        1.9267e-02, 2.6796e-01, 2.8648e-02, 1.0593e-02, 4.1719e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,008][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0304, 0.0622, 0.0353, 0.0489, 0.0946, 0.0607, 0.0987, 0.0275, 0.0429,
        0.0406, 0.0544, 0.0654, 0.0557, 0.1009, 0.0682, 0.0490, 0.0647],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,009][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([9.2257e-01, 1.1276e-02, 1.2481e-02, 2.0516e-04, 1.4866e-02, 1.2522e-04,
        4.5493e-04, 1.4851e-05, 1.0159e-04, 1.1195e-04, 1.0686e-04, 1.4151e-03,
        1.9276e-04, 3.3546e-02, 1.0953e-03, 1.1094e-04, 1.3220e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,011][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0529, 0.0677, 0.2776, 0.0246, 0.0302, 0.0566, 0.0136, 0.0117, 0.0215,
        0.0633, 0.0396, 0.0432, 0.0656, 0.0448, 0.0512, 0.0842, 0.0519],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,013][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.7112, 0.0324, 0.0325, 0.0024, 0.0122, 0.0252, 0.0390, 0.0061, 0.0069,
        0.0049, 0.0047, 0.0154, 0.0059, 0.0249, 0.0402, 0.0095, 0.0266],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,013][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0010, 0.0400, 0.0877, 0.0377, 0.0788, 0.0715, 0.0535, 0.0409, 0.0478,
        0.0521, 0.0591, 0.1045, 0.0538, 0.1051, 0.0667, 0.0508, 0.0490],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,014][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0169, 0.0572, 0.0635, 0.0399, 0.0609, 0.0618, 0.0612, 0.0396, 0.0540,
        0.0503, 0.0459, 0.0864, 0.0583, 0.0868, 0.0833, 0.0611, 0.0728],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,014][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.4359, 0.0657, 0.0148, 0.0093, 0.0345, 0.0711, 0.1358, 0.0393, 0.0144,
        0.0036, 0.0595, 0.0230, 0.0066, 0.0261, 0.0331, 0.0032, 0.0240],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,014][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.7738e-04, 1.8341e-02, 2.1226e-02, 1.6844e-02, 8.2973e-02, 5.3668e-02,
        1.1711e-02, 1.0025e-02, 4.8779e-02, 7.7419e-02, 4.5550e-02, 1.2987e-01,
        1.2295e-01, 2.0287e-01, 4.7174e-02, 7.0553e-02, 3.9867e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,015][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([2.0125e-03, 7.8692e-03, 1.3098e-02, 1.4411e-06, 1.2599e-03, 2.1721e-03,
        9.3573e-04, 2.5707e-06, 4.4791e-05, 3.4735e-05, 5.3326e-05, 3.0973e-01,
        7.8692e-04, 1.7623e-01, 4.0131e-01, 8.1007e-04, 8.3648e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,015][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0017, 0.1236, 0.0073, 0.0984, 0.0204, 0.0633, 0.0093, 0.0102, 0.0476,
        0.1063, 0.1028, 0.0706, 0.1194, 0.0366, 0.0649, 0.0780, 0.0393],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,016][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5949, 0.0940, 0.0923, 0.0026, 0.0136, 0.0139, 0.0318, 0.0028, 0.0051,
        0.0025, 0.0040, 0.0209, 0.0076, 0.0466, 0.0330, 0.0038, 0.0221, 0.0084],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,016][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([6.7875e-05, 2.9316e-03, 4.4193e-02, 4.4978e-03, 9.3239e-02, 4.5993e-03,
        1.4226e-02, 4.1485e-03, 1.5302e-02, 7.5003e-03, 2.4484e-02, 3.8089e-01,
        1.6062e-02, 2.7011e-01, 2.9023e-02, 9.8757e-03, 4.2744e-02, 3.6110e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,018][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0190, 0.0542, 0.0378, 0.0440, 0.0941, 0.0564, 0.0927, 0.0283, 0.0436,
        0.0391, 0.0563, 0.0634, 0.0507, 0.1054, 0.0637, 0.0453, 0.0574, 0.0486],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,019][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.5542e-01, 1.7237e-02, 4.4124e-02, 1.0884e-03, 7.8595e-02, 4.2505e-04,
        1.4262e-03, 1.3940e-04, 1.5062e-03, 1.4556e-03, 6.9278e-04, 6.2394e-03,
        4.1492e-04, 1.6559e-01, 5.2616e-03, 1.2321e-03, 1.8162e-02, 9.8804e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,021][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1163, 0.0592, 0.2999, 0.0214, 0.0291, 0.0416, 0.0142, 0.0130, 0.0186,
        0.0356, 0.0363, 0.0447, 0.0505, 0.0471, 0.0346, 0.0435, 0.0572, 0.0374],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,022][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7253, 0.0312, 0.0323, 0.0030, 0.0157, 0.0216, 0.0435, 0.0070, 0.0112,
        0.0059, 0.0052, 0.0080, 0.0044, 0.0208, 0.0271, 0.0090, 0.0162, 0.0126],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,023][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0014, 0.0393, 0.0828, 0.0362, 0.0704, 0.0659, 0.0567, 0.0372, 0.0512,
        0.0522, 0.0513, 0.1006, 0.0525, 0.0922, 0.0622, 0.0520, 0.0485, 0.0473],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,025][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0143, 0.0510, 0.0582, 0.0395, 0.0591, 0.0580, 0.0566, 0.0393, 0.0534,
        0.0489, 0.0447, 0.0784, 0.0553, 0.0827, 0.0761, 0.0578, 0.0679, 0.0588],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,027][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8052, 0.0095, 0.0054, 0.0024, 0.0140, 0.0216, 0.0476, 0.0065, 0.0028,
        0.0009, 0.0056, 0.0175, 0.0054, 0.0259, 0.0161, 0.0008, 0.0048, 0.0080],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,028][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0074e-04, 3.0779e-02, 2.0486e-02, 2.1872e-02, 7.1347e-02, 3.2509e-02,
        1.3311e-02, 1.0343e-02, 5.0279e-02, 5.5964e-02, 3.2936e-02, 1.7965e-01,
        1.0744e-01, 1.4302e-01, 4.3005e-02, 6.2777e-02, 6.0333e-02, 6.3843e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,029][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.7789e-03, 1.4602e-02, 1.5416e-02, 1.0782e-05, 1.9486e-03, 2.6498e-03,
        1.7675e-03, 1.8595e-05, 1.8627e-04, 1.5738e-04, 1.9680e-04, 2.9152e-01,
        1.6515e-03, 1.3333e-01, 3.8928e-01, 1.9291e-03, 1.3436e-01, 7.2023e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,030][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0011, 0.1371, 0.0086, 0.0979, 0.0174, 0.0607, 0.0156, 0.0125, 0.0535,
        0.0832, 0.0745, 0.0733, 0.0935, 0.0307, 0.0866, 0.0626, 0.0335, 0.0576],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,030][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.3232, 0.1190, 0.1043, 0.0036, 0.0186, 0.0166, 0.0472, 0.0049, 0.0066,
        0.0064, 0.0086, 0.0455, 0.0213, 0.0732, 0.0449, 0.0092, 0.0383, 0.0167,
        0.0918], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,031][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([4.5807e-05, 2.1782e-03, 6.0468e-02, 3.5538e-03, 7.8247e-02, 4.7978e-03,
        1.0659e-02, 3.7125e-03, 1.0772e-02, 6.3622e-03, 1.7613e-02, 1.9187e-01,
        8.2542e-03, 1.7305e-01, 1.6783e-02, 7.0238e-03, 2.6588e-02, 2.2989e-02,
        3.5503e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,031][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0549, 0.0619, 0.0328, 0.0414, 0.0788, 0.0530, 0.0840, 0.0229, 0.0333,
        0.0392, 0.0388, 0.0514, 0.0519, 0.0865, 0.0514, 0.0502, 0.0545, 0.0341,
        0.0793], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,032][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([9.7245e-01, 5.1272e-03, 3.3699e-03, 1.7504e-04, 4.9024e-03, 4.4085e-05,
        1.3827e-04, 1.6640e-05, 5.8451e-05, 1.5923e-04, 9.8548e-05, 4.6509e-04,
        7.3336e-05, 1.0939e-02, 3.1067e-04, 1.4711e-04, 6.8277e-04, 2.6307e-04,
        5.7680e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,032][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.0149, 0.0338, 0.2171, 0.0180, 0.0371, 0.0421, 0.0101, 0.0106, 0.0418,
        0.0652, 0.0444, 0.0590, 0.0622, 0.0465, 0.0383, 0.0768, 0.0639, 0.0669,
        0.0512], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,033][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([0.5084, 0.0342, 0.0296, 0.0030, 0.0147, 0.0314, 0.0412, 0.0076, 0.0087,
        0.0062, 0.0063, 0.0180, 0.0074, 0.0307, 0.0458, 0.0117, 0.0287, 0.0176,
        0.1486], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,033][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0009, 0.0370, 0.0698, 0.0348, 0.0598, 0.0632, 0.0567, 0.0380, 0.0471,
        0.0453, 0.0445, 0.0993, 0.0497, 0.0834, 0.0568, 0.0472, 0.0465, 0.0477,
        0.0724], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,035][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.0171, 0.0485, 0.0523, 0.0320, 0.0492, 0.0520, 0.0498, 0.0336, 0.0446,
        0.0438, 0.0390, 0.0754, 0.0514, 0.0760, 0.0749, 0.0557, 0.0646, 0.0556,
        0.0848], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,036][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.2891, 0.0371, 0.0045, 0.0113, 0.0483, 0.1029, 0.0409, 0.0246, 0.0099,
        0.0055, 0.0336, 0.0424, 0.0270, 0.0561, 0.0467, 0.0053, 0.0176, 0.0312,
        0.1660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,037][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([2.0795e-05, 8.6518e-03, 8.7279e-03, 1.0066e-02, 6.9808e-02, 3.8599e-02,
        8.4562e-03, 4.6778e-03, 3.1034e-02, 5.4956e-02, 2.6739e-02, 1.6637e-01,
        9.4773e-02, 1.9686e-01, 3.5459e-02, 5.8863e-02, 4.4009e-02, 9.3500e-02,
        4.8426e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,038][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([3.7265e-03, 2.9619e-03, 3.1987e-03, 7.9730e-07, 1.9028e-04, 9.4991e-04,
        1.8839e-04, 2.0698e-06, 1.4631e-05, 1.7505e-05, 4.5056e-05, 4.2131e-02,
        5.9413e-04, 2.7046e-02, 6.0524e-02, 3.6443e-04, 1.8595e-02, 3.4231e-03,
        8.3603e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,040][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0007, 0.0918, 0.0064, 0.0875, 0.0225, 0.0657, 0.0103, 0.0073, 0.0365,
        0.0812, 0.0691, 0.0828, 0.0995, 0.0376, 0.0740, 0.0634, 0.0351, 0.0675,
        0.0611], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,042][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4921, 0.1089, 0.1071, 0.0035, 0.0141, 0.0153, 0.0407, 0.0031, 0.0054,
        0.0035, 0.0059, 0.0296, 0.0100, 0.0413, 0.0306, 0.0043, 0.0259, 0.0102,
        0.0412, 0.0075], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,043][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.8782e-05, 1.9798e-03, 3.6081e-02, 3.5381e-03, 4.7400e-02, 4.1044e-03,
        1.1481e-02, 4.0461e-03, 1.3435e-02, 6.6966e-03, 2.0382e-02, 2.2596e-01,
        1.1213e-02, 1.5775e-01, 2.1118e-02, 7.6369e-03, 3.0230e-02, 3.1230e-02,
        3.4863e-01, 1.7018e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,045][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0064, 0.0487, 0.0241, 0.0455, 0.0734, 0.0506, 0.0783, 0.0257, 0.0364,
        0.0387, 0.0687, 0.0658, 0.0514, 0.0730, 0.0507, 0.0435, 0.0484, 0.0524,
        0.0677, 0.0508], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,046][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([5.2774e-01, 1.3358e-02, 5.8319e-02, 1.3338e-03, 1.1299e-01, 5.4984e-04,
        3.5125e-03, 1.8175e-04, 1.7799e-03, 6.5261e-04, 7.6449e-04, 8.5458e-03,
        4.0900e-04, 2.1441e-01, 8.5634e-03, 4.9799e-04, 1.3119e-02, 1.7461e-03,
        3.1024e-02, 5.0666e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,047][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0975, 0.0422, 0.2793, 0.0219, 0.0290, 0.0431, 0.0168, 0.0162, 0.0183,
        0.0392, 0.0292, 0.0240, 0.0342, 0.0413, 0.0336, 0.0472, 0.0513, 0.0354,
        0.0469, 0.0533], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,047][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6665, 0.0186, 0.0278, 0.0022, 0.0124, 0.0192, 0.0401, 0.0057, 0.0057,
        0.0044, 0.0034, 0.0079, 0.0030, 0.0163, 0.0210, 0.0073, 0.0159, 0.0085,
        0.1029, 0.0114], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,048][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0008, 0.0330, 0.0718, 0.0338, 0.0620, 0.0630, 0.0488, 0.0352, 0.0458,
        0.0476, 0.0500, 0.0802, 0.0436, 0.0775, 0.0531, 0.0460, 0.0478, 0.0457,
        0.0677, 0.0465], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,048][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0116, 0.0423, 0.0505, 0.0338, 0.0523, 0.0495, 0.0501, 0.0346, 0.0460,
        0.0421, 0.0395, 0.0689, 0.0489, 0.0746, 0.0669, 0.0502, 0.0592, 0.0506,
        0.0760, 0.0523], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,049][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2730, 0.0379, 0.0324, 0.0193, 0.0342, 0.0570, 0.1862, 0.0312, 0.0184,
        0.0096, 0.0342, 0.0195, 0.0111, 0.0460, 0.0318, 0.0073, 0.0247, 0.0409,
        0.0762, 0.0091], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,049][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0002, 0.0154, 0.0214, 0.0179, 0.0683, 0.0357, 0.0111, 0.0118, 0.0551,
        0.0714, 0.0301, 0.1026, 0.0722, 0.1370, 0.0269, 0.0677, 0.0455, 0.0720,
        0.0499, 0.0879], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,050][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.4123e-03, 1.9726e-03, 6.6708e-03, 1.0103e-06, 6.1797e-04, 6.8117e-04,
        4.2765e-04, 2.5042e-06, 2.9020e-05, 1.7155e-05, 3.4304e-05, 3.8948e-02,
        2.7299e-04, 3.5393e-02, 8.5334e-02, 2.3448e-04, 2.2644e-02, 1.8765e-03,
        8.0022e-01, 2.2101e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,050][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0011, 0.0799, 0.0078, 0.0607, 0.0153, 0.0384, 0.0144, 0.0131, 0.0418,
        0.0819, 0.0689, 0.0598, 0.0735, 0.0348, 0.0626, 0.0664, 0.0299, 0.0576,
        0.0561, 0.1360], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,108][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:48,109][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,111][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,112][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,113][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,114][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,116][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,117][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,118][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,119][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,120][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,120][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,120][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,120][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8790, 0.1210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,121][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1921, 0.8079], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,121][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7874, 0.2126], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,121][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8950, 0.1050], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,121][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4206, 0.5794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,122][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8764, 0.1236], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,122][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0057, 0.9943], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,122][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5231, 0.4769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,122][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8418, 0.1582], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,123][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([6.6493e-04, 9.9933e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,123][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0398, 0.9602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,124][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0577, 0.9423], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,125][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.4924, 0.2027, 0.3049], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,127][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0125, 0.2127, 0.7747], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,128][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.3855, 0.3002, 0.3143], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,130][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.6771, 0.2761, 0.0468], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,130][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0744, 0.2007, 0.7249], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,132][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.7813, 0.1700, 0.0487], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,134][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0012, 0.4705, 0.5283], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,135][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0860, 0.7579, 0.1561], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,137][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.5898, 0.3042, 0.1060], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,137][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([7.8530e-04, 8.5876e-01, 1.4045e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,137][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0177, 0.9455, 0.0369], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,138][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0154, 0.7535, 0.2311], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,138][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6120, 0.2243, 0.1563, 0.0073], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,138][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0549, 0.1243, 0.8095, 0.0113], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,138][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3259, 0.3636, 0.3005, 0.0101], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,139][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.5672e-01, 6.2272e-01, 2.1999e-01, 5.6796e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,139][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2851, 0.1897, 0.4599, 0.0652], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,139][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8740, 0.0830, 0.0360, 0.0070], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,139][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0046, 0.3365, 0.5606, 0.0982], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,140][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0567, 0.6514, 0.2860, 0.0058], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,140][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7574, 0.1605, 0.0705, 0.0117], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,140][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0009, 0.3945, 0.1216, 0.4831], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,141][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.8216e-03, 8.4131e-01, 1.5557e-01, 2.9690e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,143][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0407, 0.5922, 0.1845, 0.1826], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,144][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.3990, 0.3472, 0.1963, 0.0137, 0.0438], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,146][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0171, 0.0739, 0.7079, 0.0050, 0.1961], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,147][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.3162, 0.3241, 0.2911, 0.0064, 0.0623], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,148][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([4.0291e-01, 3.7297e-01, 1.9974e-01, 6.6384e-05, 2.4315e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,150][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.1819, 0.2474, 0.4390, 0.0721, 0.0595], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,151][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.8763, 0.0765, 0.0249, 0.0039, 0.0184], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,153][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0013, 0.2459, 0.5134, 0.1104, 0.1291], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,154][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0619, 0.5939, 0.2923, 0.0019, 0.0501], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,154][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.6471, 0.2308, 0.0761, 0.0108, 0.0351], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,155][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([3.3516e-04, 2.9355e-01, 4.2679e-02, 3.0996e-01, 3.5347e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,155][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([1.0379e-02, 8.6944e-01, 1.0791e-01, 4.9225e-05, 1.2218e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,155][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0195, 0.5222, 0.1010, 0.1932, 0.1641], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,155][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.5796, 0.2086, 0.1189, 0.0130, 0.0288, 0.0512], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,156][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0390, 0.1181, 0.5778, 0.0142, 0.2154, 0.0355], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,156][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.3000, 0.2387, 0.2776, 0.0137, 0.0933, 0.0768], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,156][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([6.6157e-01, 2.9497e-01, 2.0078e-02, 3.8137e-04, 9.6609e-03, 1.3340e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,157][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0992, 0.1257, 0.5084, 0.0627, 0.0833, 0.1207], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,157][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.8543, 0.0571, 0.0278, 0.0068, 0.0176, 0.0363], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,157][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0020, 0.2338, 0.3950, 0.0785, 0.1705, 0.1202], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,157][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1593, 0.4209, 0.2341, 0.0054, 0.0621, 0.1181], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,158][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.6747, 0.1113, 0.1069, 0.0125, 0.0534, 0.0412], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,159][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([2.9111e-04, 1.6885e-01, 6.2715e-02, 1.7164e-01, 4.0145e-01, 1.9505e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,160][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([1.3309e-02, 9.2048e-01, 2.8097e-02, 5.1357e-04, 1.0164e-02, 2.7438e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,162][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0284, 0.4522, 0.1282, 0.0764, 0.1203, 0.1945], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,163][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.3857, 0.2358, 0.1664, 0.0112, 0.0425, 0.0821, 0.0763],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,165][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0199, 0.1447, 0.4568, 0.0094, 0.2909, 0.0452, 0.0330],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,166][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.2767, 0.1873, 0.3065, 0.0064, 0.0581, 0.0786, 0.0864],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,168][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([6.8711e-02, 8.9602e-01, 6.9729e-03, 1.2270e-04, 5.6281e-03, 9.2320e-03,
        1.3309e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,169][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0397, 0.1363, 0.4633, 0.0670, 0.0673, 0.1974, 0.0291],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,171][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.5901, 0.1321, 0.0531, 0.0075, 0.0415, 0.0699, 0.1058],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,171][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0005, 0.2201, 0.3125, 0.0869, 0.1596, 0.1839, 0.0365],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,172][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0243, 0.5695, 0.1473, 0.0022, 0.0573, 0.1162, 0.0832],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,172][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.4438, 0.2723, 0.1040, 0.0122, 0.0458, 0.0575, 0.0643],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,172][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([2.2914e-04, 1.3297e-01, 5.7437e-02, 1.1633e-01, 3.3818e-01, 2.9788e-01,
        5.6961e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,173][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([1.3198e-03, 9.5560e-01, 6.0315e-03, 8.8846e-05, 4.6628e-03, 1.0962e-02,
        2.1338e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,173][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0073, 0.2360, 0.0513, 0.1580, 0.1343, 0.2982, 0.1149],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,173][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.2786, 0.2886, 0.1980, 0.0106, 0.0516, 0.0380, 0.1233, 0.0113],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,174][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0234, 0.0784, 0.6008, 0.0112, 0.1740, 0.0343, 0.0617, 0.0163],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,174][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.1135, 0.2684, 0.3455, 0.0089, 0.0715, 0.0609, 0.1217, 0.0096],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,174][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([1.9090e-02, 8.2633e-01, 1.9364e-02, 5.8868e-04, 5.7389e-02, 7.0689e-03,
        6.9091e-02, 1.0796e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,174][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0553, 0.1598, 0.4580, 0.0558, 0.0751, 0.1367, 0.0289, 0.0303],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,175][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.3987, 0.1102, 0.0960, 0.0150, 0.0808, 0.0936, 0.1755, 0.0304],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,175][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0005, 0.1760, 0.3958, 0.0612, 0.1957, 0.0937, 0.0489, 0.0282],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,177][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0228, 0.4584, 0.1529, 0.0077, 0.1288, 0.0942, 0.1314, 0.0036],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,178][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.3585, 0.2557, 0.1254, 0.0226, 0.1013, 0.0717, 0.0507, 0.0142],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,179][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([1.8080e-04, 1.5888e-01, 1.0782e-01, 1.1191e-01, 3.6397e-01, 1.6932e-01,
        5.6091e-02, 3.1830e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,180][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([8.1682e-04, 8.5903e-01, 1.7588e-02, 3.5102e-04, 3.8367e-02, 8.6021e-03,
        7.4858e-02, 3.9170e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,182][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0098, 0.3959, 0.0572, 0.1112, 0.0794, 0.1478, 0.1019, 0.0969],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,183][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.4568, 0.1627, 0.1732, 0.0077, 0.0467, 0.0558, 0.0701, 0.0105, 0.0165],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,185][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0375, 0.0983, 0.5157, 0.0056, 0.2267, 0.0300, 0.0445, 0.0090, 0.0329],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,187][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.1504, 0.2185, 0.3422, 0.0076, 0.0753, 0.0571, 0.1030, 0.0107, 0.0351],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,187][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([1.3944e-01, 5.1364e-01, 1.3306e-01, 1.8475e-04, 1.0778e-01, 2.9972e-02,
        7.0948e-02, 8.8596e-04, 4.0924e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,189][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.1171, 0.1285, 0.3921, 0.0439, 0.0589, 0.1275, 0.0283, 0.0380, 0.0657],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,189][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.6166, 0.0875, 0.0562, 0.0054, 0.0493, 0.0495, 0.0995, 0.0146, 0.0214],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,189][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0010, 0.1418, 0.2873, 0.0582, 0.2479, 0.1021, 0.0496, 0.0374, 0.0747],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,190][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0169, 0.4070, 0.2555, 0.0025, 0.0961, 0.0802, 0.1285, 0.0023, 0.0111],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,190][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.5083, 0.1959, 0.0923, 0.0147, 0.0643, 0.0543, 0.0380, 0.0112, 0.0210],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,190][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([2.5254e-04, 1.2965e-01, 4.5711e-02, 9.1656e-02, 3.3939e-01, 1.4195e-01,
        4.1482e-02, 4.3732e-02, 1.6617e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,190][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([2.6914e-03, 7.1808e-01, 1.2221e-01, 1.0802e-04, 6.8008e-02, 2.7259e-02,
        5.6596e-02, 1.5139e-04, 4.8988e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,191][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0058, 0.2200, 0.0231, 0.0888, 0.0535, 0.1423, 0.0922, 0.0851, 0.2892],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,191][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5055, 0.2241, 0.1403, 0.0054, 0.0261, 0.0252, 0.0532, 0.0042, 0.0086,
        0.0075], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,191][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0489, 0.1073, 0.5495, 0.0055, 0.1487, 0.0225, 0.0510, 0.0103, 0.0414,
        0.0149], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,192][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2341, 0.2527, 0.3390, 0.0054, 0.0572, 0.0333, 0.0516, 0.0062, 0.0155,
        0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,192][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.4167e-01, 2.0467e-01, 1.7472e-01, 1.6073e-04, 1.0956e-01, 1.8871e-02,
        4.1702e-02, 5.0030e-04, 3.8168e-03, 4.3349e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,193][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1424, 0.0985, 0.4414, 0.0421, 0.0468, 0.0806, 0.0205, 0.0250, 0.0319,
        0.0707], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,195][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7644, 0.0405, 0.0405, 0.0036, 0.0252, 0.0283, 0.0701, 0.0082, 0.0109,
        0.0083], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,197][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0013, 0.1113, 0.4545, 0.0302, 0.1515, 0.0479, 0.0411, 0.0278, 0.0533,
        0.0810], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,198][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0431, 0.3542, 0.2597, 0.0032, 0.1706, 0.0718, 0.0742, 0.0024, 0.0119,
        0.0088], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,199][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6247, 0.1364, 0.0838, 0.0087, 0.0369, 0.0430, 0.0305, 0.0070, 0.0128,
        0.0163], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,201][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0004, 0.0634, 0.0662, 0.0539, 0.2250, 0.1064, 0.0351, 0.0292, 0.2097,
        0.2107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,202][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.7402e-02, 5.6076e-01, 2.1762e-01, 1.2467e-04, 1.0462e-01, 3.1020e-02,
        5.6706e-02, 2.0137e-04, 6.9550e-03, 4.5991e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,204][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0218, 0.2474, 0.0447, 0.0438, 0.0466, 0.0814, 0.0984, 0.0983, 0.1794,
        0.1382], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,205][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.5074, 0.2022, 0.1435, 0.0058, 0.0242, 0.0252, 0.0626, 0.0058, 0.0090,
        0.0058, 0.0085], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,206][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0288, 0.0767, 0.5801, 0.0059, 0.1702, 0.0198, 0.0392, 0.0089, 0.0332,
        0.0101, 0.0273], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,206][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2648, 0.2200, 0.2909, 0.0060, 0.0636, 0.0441, 0.0609, 0.0087, 0.0226,
        0.0076, 0.0107], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,207][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([5.5163e-01, 8.0949e-02, 1.7928e-01, 2.4970e-04, 1.4386e-01, 1.1152e-02,
        1.8621e-02, 5.8170e-04, 4.6460e-03, 6.0371e-03, 2.9883e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,207][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1396, 0.0997, 0.3303, 0.0413, 0.0465, 0.1175, 0.0293, 0.0195, 0.0520,
        0.0851, 0.0390], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,207][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7569, 0.0403, 0.0409, 0.0043, 0.0256, 0.0305, 0.0624, 0.0088, 0.0141,
        0.0087, 0.0076], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,208][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0008, 0.1400, 0.3356, 0.0393, 0.1073, 0.0618, 0.0352, 0.0262, 0.0569,
        0.1512, 0.0456], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,208][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0699, 0.3096, 0.2756, 0.0040, 0.1452, 0.0825, 0.0746, 0.0029, 0.0136,
        0.0120, 0.0101], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,208][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6475, 0.1404, 0.0760, 0.0087, 0.0385, 0.0274, 0.0201, 0.0056, 0.0091,
        0.0141, 0.0127], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,209][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0003, 0.0815, 0.0460, 0.0529, 0.1960, 0.0886, 0.0372, 0.0265, 0.1539,
        0.2325, 0.0848], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,209][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.0306e-02, 3.7948e-01, 3.3677e-01, 3.7992e-04, 1.3869e-01, 4.3322e-02,
        4.8076e-02, 3.3795e-04, 1.3530e-02, 8.8454e-03, 1.0264e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,209][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0087, 0.2594, 0.0322, 0.0352, 0.0430, 0.0651, 0.0870, 0.0633, 0.1829,
        0.0787, 0.1446], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,210][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.6639, 0.1731, 0.0754, 0.0024, 0.0089, 0.0146, 0.0328, 0.0026, 0.0030,
        0.0027, 0.0043, 0.0162], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,212][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0146, 0.1067, 0.5501, 0.0037, 0.1506, 0.0173, 0.0128, 0.0032, 0.0100,
        0.0075, 0.0169, 0.1067], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,213][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.3712, 0.1579, 0.3304, 0.0024, 0.0215, 0.0377, 0.0300, 0.0034, 0.0062,
        0.0021, 0.0056, 0.0317], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,214][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([8.0133e-01, 6.6897e-03, 2.9622e-02, 3.2353e-06, 2.4577e-03, 3.2849e-03,
        4.5820e-04, 1.0758e-05, 4.2276e-05, 1.0818e-04, 2.0203e-04, 1.5579e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,216][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.0585, 0.1244, 0.3123, 0.0519, 0.0416, 0.1068, 0.0212, 0.0267, 0.0393,
        0.1063, 0.0724, 0.0386], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,217][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.8568, 0.0314, 0.0207, 0.0022, 0.0098, 0.0234, 0.0297, 0.0035, 0.0037,
        0.0042, 0.0034, 0.0111], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,219][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0007, 0.1148, 0.2833, 0.0380, 0.1057, 0.0798, 0.0229, 0.0167, 0.0370,
        0.0993, 0.0578, 0.1441], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,221][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0640, 0.1978, 0.2825, 0.0005, 0.0267, 0.0779, 0.0240, 0.0005, 0.0023,
        0.0029, 0.0035, 0.3174], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,222][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.8681, 0.0434, 0.0378, 0.0016, 0.0074, 0.0091, 0.0046, 0.0016, 0.0017,
        0.0033, 0.0045, 0.0169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,223][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0003, 0.0784, 0.0508, 0.0450, 0.1610, 0.1478, 0.0205, 0.0142, 0.0844,
        0.1096, 0.0697, 0.2182], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,223][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([1.3781e-02, 1.5990e-02, 3.2347e-02, 3.2596e-06, 2.3722e-03, 5.6149e-03,
        7.5523e-04, 3.8470e-06, 1.2644e-04, 1.1462e-04, 3.6473e-04, 9.2853e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,224][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.0070, 0.1000, 0.0173, 0.0282, 0.0358, 0.0850, 0.0386, 0.0476, 0.1065,
        0.0870, 0.1810, 0.2660], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,224][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4526, 0.1864, 0.1521, 0.0064, 0.0231, 0.0253, 0.0520, 0.0063, 0.0086,
        0.0089, 0.0105, 0.0455, 0.0223], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,225][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0327, 0.0576, 0.5630, 0.0044, 0.1132, 0.0188, 0.0348, 0.0060, 0.0223,
        0.0076, 0.0178, 0.0917, 0.0300], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,225][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3205, 0.1241, 0.3363, 0.0031, 0.0444, 0.0298, 0.0486, 0.0052, 0.0150,
        0.0041, 0.0062, 0.0456, 0.0170], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,225][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([6.2429e-01, 4.3131e-02, 7.6540e-03, 9.9565e-05, 5.4401e-03, 2.8562e-03,
        4.5481e-03, 4.2144e-04, 8.6900e-04, 1.4594e-03, 2.4555e-03, 2.9683e-01,
        9.9478e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,226][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0990, 0.0989, 0.3233, 0.0375, 0.0437, 0.0910, 0.0205, 0.0187, 0.0350,
        0.0734, 0.0474, 0.0326, 0.0791], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,226][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.8417, 0.0328, 0.0235, 0.0023, 0.0130, 0.0199, 0.0348, 0.0048, 0.0067,
        0.0047, 0.0037, 0.0080, 0.0042], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,226][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0008, 0.0982, 0.3103, 0.0238, 0.1073, 0.0472, 0.0216, 0.0141, 0.0299,
        0.0578, 0.0337, 0.1503, 0.1049], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,227][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0900, 0.1314, 0.1833, 0.0017, 0.0573, 0.0522, 0.0312, 0.0018, 0.0077,
        0.0060, 0.0079, 0.4015, 0.0278], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,227][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.7593, 0.0747, 0.0570, 0.0037, 0.0163, 0.0117, 0.0123, 0.0030, 0.0045,
        0.0069, 0.0067, 0.0306, 0.0133], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,229][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([7.8289e-05, 2.6314e-02, 2.6674e-02, 2.4754e-02, 1.2454e-01, 7.0085e-02,
        1.1980e-02, 1.2515e-02, 6.4586e-02, 1.0298e-01, 5.4382e-02, 2.9626e-01,
        1.8486e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,229][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([8.3008e-03, 5.5831e-02, 8.7993e-03, 4.0920e-05, 2.5932e-03, 2.8295e-03,
        3.1644e-03, 6.0274e-05, 8.3368e-04, 6.0057e-04, 1.6579e-03, 9.1052e-01,
        4.7683e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,231][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0112, 0.1865, 0.0161, 0.0244, 0.0173, 0.0431, 0.0706, 0.0512, 0.1368,
        0.0559, 0.1311, 0.1154, 0.1402], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,233][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.1168, 0.1975, 0.1600, 0.0107, 0.0396, 0.0512, 0.0551, 0.0072, 0.0175,
        0.0136, 0.0215, 0.0911, 0.0567, 0.1614], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,234][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0059, 0.0436, 0.3560, 0.0037, 0.1120, 0.0201, 0.0178, 0.0035, 0.0141,
        0.0075, 0.0176, 0.1092, 0.0350, 0.2540], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,236][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.1545, 0.1174, 0.2664, 0.0028, 0.0364, 0.0448, 0.0406, 0.0046, 0.0148,
        0.0041, 0.0066, 0.0830, 0.0310, 0.1929], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,237][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([3.8328e-01, 4.3682e-03, 2.8049e-02, 2.4777e-06, 1.5794e-03, 2.7394e-03,
        2.6631e-04, 5.7807e-06, 2.2170e-05, 6.2189e-05, 8.4205e-05, 1.0765e-01,
        1.9117e-03, 4.6998e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,238][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0139, 0.0705, 0.1949, 0.0403, 0.0412, 0.0750, 0.0112, 0.0152, 0.0356,
        0.1271, 0.0786, 0.0664, 0.1668, 0.0633], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,240][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([0.6129, 0.0746, 0.0433, 0.0053, 0.0255, 0.0517, 0.0606, 0.0081, 0.0135,
        0.0101, 0.0099, 0.0229, 0.0127, 0.0488], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,240][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([1.9688e-04, 6.3762e-02, 2.1127e-01, 3.9012e-02, 7.7314e-02, 5.9327e-02,
        1.6021e-02, 1.1894e-02, 2.5283e-02, 5.0420e-02, 3.7129e-02, 1.3218e-01,
        1.6492e-01, 1.1127e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,241][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([1.9337e-02, 8.7665e-02, 1.2023e-01, 4.2607e-04, 1.9862e-02, 5.4747e-02,
        1.6817e-02, 3.9054e-04, 1.8350e-03, 2.6812e-03, 2.4493e-03, 2.5397e-01,
        2.3706e-02, 3.9588e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,241][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.4296, 0.1784, 0.0974, 0.0077, 0.0239, 0.0307, 0.0204, 0.0071, 0.0079,
        0.0150, 0.0158, 0.0587, 0.0537, 0.0536], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,241][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([5.8958e-05, 4.4093e-02, 1.6543e-02, 3.9232e-02, 8.6319e-02, 8.5280e-02,
        1.1589e-02, 7.5552e-03, 5.4262e-02, 9.8655e-02, 3.8259e-02, 1.8129e-01,
        1.8601e-01, 1.5085e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,242][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([6.3907e-03, 1.6239e-02, 2.5189e-02, 2.6544e-06, 1.4686e-03, 4.1151e-03,
        7.0520e-04, 3.0743e-06, 6.2809e-05, 9.7364e-05, 1.5004e-04, 6.1632e-01,
        2.0646e-03, 3.2719e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,242][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0021, 0.1273, 0.0142, 0.0359, 0.0224, 0.0504, 0.0350, 0.0308, 0.0912,
        0.0867, 0.1060, 0.1583, 0.1645, 0.0753], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,242][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.2247, 0.1460, 0.1267, 0.0073, 0.0240, 0.0410, 0.0709, 0.0093, 0.0135,
        0.0119, 0.0151, 0.0888, 0.0405, 0.0961, 0.0843], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,243][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0075, 0.0523, 0.2514, 0.0049, 0.1068, 0.0193, 0.0194, 0.0052, 0.0246,
        0.0108, 0.0253, 0.1215, 0.0422, 0.2462, 0.0625], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,243][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1373, 0.0843, 0.3104, 0.0016, 0.0273, 0.0240, 0.0342, 0.0033, 0.0113,
        0.0024, 0.0037, 0.0419, 0.0143, 0.1134, 0.1905], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,244][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([3.5492e-01, 1.2027e-02, 1.1557e-02, 2.9883e-06, 9.7258e-04, 2.9320e-03,
        5.8985e-04, 1.0034e-05, 3.3522e-05, 8.9419e-05, 1.0357e-04, 9.3465e-02,
        3.2364e-03, 4.1487e-01, 1.0519e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,244][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0231, 0.0539, 0.2986, 0.0270, 0.0329, 0.0763, 0.0090, 0.0172, 0.0442,
        0.1191, 0.0783, 0.0563, 0.0904, 0.0409, 0.0327], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,246][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.6144, 0.0539, 0.0378, 0.0033, 0.0216, 0.0459, 0.0550, 0.0072, 0.0110,
        0.0066, 0.0069, 0.0175, 0.0091, 0.0403, 0.0695], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,246][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([1.2355e-04, 4.2624e-02, 1.4194e-01, 1.8974e-02, 8.0824e-02, 5.2038e-02,
        1.3084e-02, 9.8934e-03, 2.2437e-02, 7.2673e-02, 2.9891e-02, 1.6937e-01,
        1.2472e-01, 1.5306e-01, 6.8349e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,248][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([1.7241e-02, 5.7524e-02, 6.2558e-02, 2.3804e-04, 1.1930e-02, 2.8431e-02,
        9.7570e-03, 2.7441e-04, 1.2729e-03, 1.3196e-03, 1.6993e-03, 1.9209e-01,
        1.4358e-02, 3.7879e-01, 2.2251e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,249][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.4436, 0.0962, 0.1402, 0.0056, 0.0352, 0.0392, 0.0181, 0.0042, 0.0106,
        0.0097, 0.0165, 0.0668, 0.0286, 0.0469, 0.0387], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,250][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([3.1036e-05, 1.3126e-02, 9.4942e-03, 1.6062e-02, 7.8942e-02, 4.2080e-02,
        8.1635e-03, 8.3363e-03, 3.9399e-02, 8.0181e-02, 3.4411e-02, 2.1682e-01,
        1.1903e-01, 2.9242e-01, 4.1501e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,251][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([3.9144e-03, 1.6759e-02, 7.4405e-03, 1.6465e-06, 6.1398e-04, 2.2842e-03,
        6.6460e-04, 2.8414e-06, 4.1655e-05, 4.7218e-05, 8.6401e-05, 3.5725e-01,
        1.6428e-03, 1.9119e-01, 4.1807e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,253][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0043, 0.1212, 0.0176, 0.0270, 0.0235, 0.0464, 0.0261, 0.0385, 0.0597,
        0.0545, 0.0822, 0.1228, 0.1664, 0.0897, 0.1199], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,255][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4814, 0.1319, 0.1075, 0.0036, 0.0184, 0.0176, 0.0459, 0.0031, 0.0063,
        0.0046, 0.0067, 0.0400, 0.0127, 0.0657, 0.0485, 0.0060],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,256][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0282, 0.0457, 0.3234, 0.0032, 0.0893, 0.0120, 0.0292, 0.0058, 0.0224,
        0.0097, 0.0164, 0.0696, 0.0231, 0.2427, 0.0657, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,258][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2785, 0.1194, 0.2282, 0.0024, 0.0265, 0.0182, 0.0256, 0.0039, 0.0072,
        0.0026, 0.0040, 0.0268, 0.0103, 0.0969, 0.1449, 0.0044],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,258][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.1325e-02, 2.5834e-03, 1.9299e-02, 3.9495e-06, 3.8594e-03, 1.1050e-03,
        7.1932e-04, 9.6614e-06, 6.2397e-05, 7.8932e-05, 7.5288e-05, 1.0726e-01,
        8.8542e-04, 5.8082e-01, 2.0041e-01, 1.5053e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,258][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1238, 0.0561, 0.3265, 0.0259, 0.0408, 0.0545, 0.0183, 0.0178, 0.0237,
        0.0519, 0.0329, 0.0255, 0.0454, 0.0535, 0.0417, 0.0618],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,259][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7192, 0.0275, 0.0448, 0.0025, 0.0202, 0.0244, 0.0492, 0.0062, 0.0079,
        0.0053, 0.0039, 0.0136, 0.0038, 0.0266, 0.0357, 0.0093],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,259][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0009, 0.0402, 0.2874, 0.0132, 0.0935, 0.0283, 0.0203, 0.0130, 0.0276,
        0.0362, 0.0201, 0.1062, 0.0586, 0.1588, 0.0574, 0.0382],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,259][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.6110e-02, 3.8743e-02, 7.4635e-02, 3.8893e-04, 2.9598e-02, 1.3926e-02,
        8.9406e-03, 3.3388e-04, 1.5938e-03, 9.9832e-04, 1.7502e-03, 1.4785e-01,
        9.7715e-03, 5.1481e-01, 1.3655e-01, 4.0003e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,260][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5091, 0.0851, 0.1070, 0.0051, 0.0252, 0.0261, 0.0193, 0.0041, 0.0079,
        0.0085, 0.0090, 0.0642, 0.0179, 0.0480, 0.0546, 0.0089],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,260][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0003, 0.0212, 0.0281, 0.0186, 0.0884, 0.0426, 0.0132, 0.0129, 0.0732,
        0.0874, 0.0382, 0.1358, 0.0972, 0.2145, 0.0440, 0.0846],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,261][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.1601e-03, 3.1591e-03, 9.4768e-03, 1.1346e-06, 1.7597e-03, 5.6910e-04,
        5.0092e-04, 1.5992e-06, 5.4116e-05, 3.2368e-05, 5.7242e-05, 2.7645e-01,
        3.2486e-04, 2.5982e-01, 4.4586e-01, 7.7674e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,261][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0143, 0.1007, 0.0189, 0.0203, 0.0190, 0.0340, 0.0423, 0.0481, 0.0738,
        0.0624, 0.0859, 0.0989, 0.0948, 0.0879, 0.1162, 0.0825],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,261][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.4820, 0.0994, 0.1632, 0.0022, 0.0167, 0.0203, 0.0306, 0.0030, 0.0058,
        0.0027, 0.0056, 0.0250, 0.0113, 0.0623, 0.0402, 0.0047, 0.0250],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,263][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0225, 0.0569, 0.2813, 0.0037, 0.0748, 0.0168, 0.0176, 0.0046, 0.0150,
        0.0075, 0.0235, 0.0896, 0.0330, 0.2091, 0.0693, 0.0099, 0.0649],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,265][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.2175, 0.0630, 0.2169, 0.0012, 0.0210, 0.0192, 0.0266, 0.0026, 0.0065,
        0.0015, 0.0032, 0.0321, 0.0094, 0.0875, 0.2030, 0.0035, 0.0855],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,266][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([2.0648e-01, 7.1671e-03, 2.5662e-02, 2.2535e-06, 1.6437e-03, 3.2532e-03,
        9.1170e-04, 1.0431e-05, 4.1173e-05, 5.8073e-05, 5.4619e-05, 1.4160e-01,
        1.7665e-03, 3.7378e-01, 1.9039e-01, 1.0231e-03, 4.6169e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,267][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0529, 0.0677, 0.2776, 0.0246, 0.0302, 0.0566, 0.0136, 0.0117, 0.0215,
        0.0633, 0.0396, 0.0432, 0.0656, 0.0448, 0.0512, 0.0842, 0.0519],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,269][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.7112, 0.0324, 0.0325, 0.0024, 0.0122, 0.0252, 0.0390, 0.0061, 0.0069,
        0.0049, 0.0047, 0.0154, 0.0059, 0.0249, 0.0402, 0.0095, 0.0266],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,270][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0005, 0.0519, 0.2582, 0.0162, 0.0744, 0.0390, 0.0138, 0.0092, 0.0204,
        0.0492, 0.0299, 0.0799, 0.0973, 0.1084, 0.0564, 0.0529, 0.0424],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,272][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([2.4455e-02, 7.0906e-02, 1.0669e-01, 2.6511e-04, 1.5278e-02, 2.0118e-02,
        1.4405e-02, 3.3237e-04, 1.1592e-03, 1.0014e-03, 1.2813e-03, 1.7319e-01,
        1.0176e-02, 3.1425e-01, 1.9924e-01, 4.3855e-03, 4.2863e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,273][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.5783, 0.0659, 0.0876, 0.0028, 0.0190, 0.0201, 0.0111, 0.0027, 0.0060,
        0.0065, 0.0079, 0.0483, 0.0183, 0.0287, 0.0352, 0.0076, 0.0540],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,274][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.7738e-04, 1.8341e-02, 2.1226e-02, 1.6844e-02, 8.2973e-02, 5.3668e-02,
        1.1711e-02, 1.0025e-02, 4.8779e-02, 7.7419e-02, 4.5550e-02, 1.2987e-01,
        1.2295e-01, 2.0287e-01, 4.7174e-02, 7.0553e-02, 3.9867e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,275][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([2.0125e-03, 7.8692e-03, 1.3098e-02, 1.4411e-06, 1.2599e-03, 2.1721e-03,
        9.3573e-04, 2.5707e-06, 4.4791e-05, 3.4735e-05, 5.3326e-05, 3.0973e-01,
        7.8692e-04, 1.7623e-01, 4.0131e-01, 8.1007e-04, 8.3648e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,276][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0113, 0.0731, 0.0154, 0.0206, 0.0213, 0.0478, 0.0225, 0.0327, 0.0613,
        0.0457, 0.0996, 0.0892, 0.1523, 0.0790, 0.0872, 0.0682, 0.0729],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,276][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5949, 0.0940, 0.0923, 0.0026, 0.0136, 0.0139, 0.0318, 0.0028, 0.0051,
        0.0025, 0.0040, 0.0209, 0.0076, 0.0466, 0.0330, 0.0038, 0.0221, 0.0084],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,276][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0236, 0.0377, 0.2924, 0.0032, 0.1120, 0.0106, 0.0230, 0.0045, 0.0147,
        0.0061, 0.0150, 0.0575, 0.0198, 0.2366, 0.0525, 0.0092, 0.0588, 0.0228],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,277][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3310, 0.0730, 0.1452, 0.0019, 0.0197, 0.0154, 0.0228, 0.0033, 0.0069,
        0.0021, 0.0033, 0.0268, 0.0084, 0.0917, 0.1581, 0.0035, 0.0753, 0.0115],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,277][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.0123e-01, 7.1954e-03, 1.9493e-02, 1.9391e-05, 4.0187e-03, 2.8240e-03,
        1.8143e-03, 8.2116e-05, 1.5531e-04, 2.7735e-04, 1.8786e-04, 8.0506e-02,
        2.6280e-03, 3.5703e-01, 1.4656e-01, 2.9364e-03, 6.7552e-02, 5.4894e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,278][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1163, 0.0592, 0.2999, 0.0214, 0.0291, 0.0416, 0.0142, 0.0130, 0.0186,
        0.0356, 0.0363, 0.0447, 0.0505, 0.0471, 0.0346, 0.0435, 0.0572, 0.0374],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,278][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7253, 0.0312, 0.0323, 0.0030, 0.0157, 0.0216, 0.0435, 0.0070, 0.0112,
        0.0059, 0.0052, 0.0080, 0.0044, 0.0208, 0.0271, 0.0090, 0.0162, 0.0126],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,278][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0005, 0.0606, 0.2141, 0.0172, 0.0805, 0.0264, 0.0164, 0.0119, 0.0227,
        0.0368, 0.0231, 0.1043, 0.0685, 0.1114, 0.0685, 0.0395, 0.0584, 0.0393],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,279][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0385, 0.0535, 0.1123, 0.0006, 0.0288, 0.0222, 0.0131, 0.0007, 0.0025,
        0.0015, 0.0021, 0.1247, 0.0104, 0.3885, 0.1392, 0.0047, 0.0447, 0.0120],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,280][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5446, 0.1006, 0.0919, 0.0064, 0.0246, 0.0178, 0.0124, 0.0042, 0.0054,
        0.0076, 0.0076, 0.0320, 0.0150, 0.0319, 0.0254, 0.0071, 0.0520, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,281][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.0074e-04, 3.0779e-02, 2.0486e-02, 2.1872e-02, 7.1347e-02, 3.2509e-02,
        1.3311e-02, 1.0343e-02, 5.0279e-02, 5.5964e-02, 3.2936e-02, 1.7965e-01,
        1.0744e-01, 1.4302e-01, 4.3005e-02, 6.2777e-02, 6.0333e-02, 6.3843e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,282][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.7789e-03, 1.4602e-02, 1.5416e-02, 1.0782e-05, 1.9486e-03, 2.6498e-03,
        1.7675e-03, 1.8595e-05, 1.8627e-04, 1.5738e-04, 1.9680e-04, 2.9152e-01,
        1.6515e-03, 1.3333e-01, 3.8928e-01, 1.9291e-03, 1.3436e-01, 7.2023e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,284][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0059, 0.1062, 0.0150, 0.0205, 0.0138, 0.0390, 0.0418, 0.0361, 0.0769,
        0.0383, 0.0666, 0.0880, 0.0815, 0.0494, 0.1341, 0.0482, 0.0492, 0.0897],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,285][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.3232, 0.1190, 0.1043, 0.0036, 0.0186, 0.0166, 0.0472, 0.0049, 0.0066,
        0.0064, 0.0086, 0.0455, 0.0213, 0.0732, 0.0449, 0.0092, 0.0383, 0.0167,
        0.0918], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,287][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0027, 0.0307, 0.1643, 0.0024, 0.1018, 0.0103, 0.0158, 0.0027, 0.0101,
        0.0047, 0.0109, 0.0698, 0.0193, 0.2312, 0.0359, 0.0076, 0.0532, 0.0237,
        0.2029], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,289][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0865, 0.0436, 0.1987, 0.0018, 0.0210, 0.0239, 0.0290, 0.0031, 0.0078,
        0.0023, 0.0038, 0.0319, 0.0120, 0.1031, 0.1716, 0.0046, 0.1045, 0.0195,
        0.1314], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,290][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([6.3854e-01, 2.0489e-03, 4.9028e-03, 1.1027e-06, 1.9337e-04, 1.1386e-03,
        1.6233e-04, 5.6944e-06, 7.2224e-06, 1.3516e-05, 2.9161e-05, 1.0662e-02,
        7.3150e-04, 3.8889e-02, 1.7218e-02, 2.1990e-04, 6.7180e-03, 1.5310e-03,
        2.7699e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,291][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.0149, 0.0338, 0.2171, 0.0180, 0.0371, 0.0421, 0.0101, 0.0106, 0.0418,
        0.0652, 0.0444, 0.0590, 0.0622, 0.0465, 0.0383, 0.0768, 0.0639, 0.0669,
        0.0512], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,292][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([0.5084, 0.0342, 0.0296, 0.0030, 0.0147, 0.0314, 0.0412, 0.0076, 0.0087,
        0.0062, 0.0063, 0.0180, 0.0074, 0.0307, 0.0458, 0.0117, 0.0287, 0.0176,
        0.1486], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,293][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([9.0340e-05, 2.9040e-02, 1.2974e-01, 1.2192e-02, 8.0526e-02, 3.2141e-02,
        1.7027e-02, 7.3462e-03, 1.7427e-02, 3.9252e-02, 1.7753e-02, 1.3699e-01,
        8.8421e-02, 1.4939e-01, 5.8423e-02, 3.9112e-02, 5.8830e-02, 4.8671e-02,
        3.7626e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,293][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([1.8965e-02, 4.8612e-02, 4.6193e-02, 1.6307e-04, 7.0363e-03, 1.4577e-02,
        6.9068e-03, 2.5853e-04, 6.5211e-04, 1.0938e-03, 1.0320e-03, 9.8832e-02,
        9.5226e-03, 1.9849e-01, 1.5076e-01, 5.5579e-03, 3.0502e-02, 1.0992e-02,
        3.4985e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,294][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.4442, 0.0955, 0.0905, 0.0047, 0.0172, 0.0168, 0.0122, 0.0027, 0.0066,
        0.0065, 0.0105, 0.0489, 0.0206, 0.0251, 0.0307, 0.0073, 0.0451, 0.0228,
        0.0918], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,294][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([2.0795e-05, 8.6518e-03, 8.7279e-03, 1.0066e-02, 6.9808e-02, 3.8599e-02,
        8.4562e-03, 4.6778e-03, 3.1034e-02, 5.4956e-02, 2.6739e-02, 1.6637e-01,
        9.4773e-02, 1.9686e-01, 3.5459e-02, 5.8863e-02, 4.4009e-02, 9.3500e-02,
        4.8426e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,294][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([3.7265e-03, 2.9619e-03, 3.1987e-03, 7.9730e-07, 1.9028e-04, 9.4991e-04,
        1.8839e-04, 2.0698e-06, 1.4631e-05, 1.7505e-05, 4.5056e-05, 4.2131e-02,
        5.9413e-04, 2.7046e-02, 6.0524e-02, 3.6443e-04, 1.8595e-02, 3.4231e-03,
        8.3603e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,295][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0012, 0.0347, 0.0082, 0.0147, 0.0251, 0.0391, 0.0163, 0.0155, 0.0346,
        0.0378, 0.0443, 0.1457, 0.1092, 0.0740, 0.0863, 0.0536, 0.0664, 0.0959,
        0.0974], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,295][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4921, 0.1089, 0.1071, 0.0035, 0.0141, 0.0153, 0.0407, 0.0031, 0.0054,
        0.0035, 0.0059, 0.0296, 0.0100, 0.0413, 0.0306, 0.0043, 0.0259, 0.0102,
        0.0412, 0.0075], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,296][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0207, 0.0357, 0.2239, 0.0022, 0.0671, 0.0079, 0.0190, 0.0044, 0.0160,
        0.0073, 0.0122, 0.0508, 0.0159, 0.1708, 0.0411, 0.0098, 0.0460, 0.0188,
        0.2156, 0.0149], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,296][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3467, 0.0831, 0.1757, 0.0020, 0.0169, 0.0139, 0.0211, 0.0032, 0.0062,
        0.0017, 0.0029, 0.0169, 0.0071, 0.0567, 0.0929, 0.0027, 0.0424, 0.0075,
        0.0958, 0.0046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,297][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.7933e-01, 1.9320e-03, 1.8480e-02, 4.2132e-06, 1.4815e-03, 1.9463e-03,
        8.4782e-04, 2.5064e-05, 3.6758e-05, 5.6556e-05, 5.2667e-05, 1.7399e-02,
        1.0414e-03, 8.8508e-02, 5.2107e-02, 6.1251e-04, 2.1087e-02, 2.4660e-03,
        4.0630e-01, 6.2915e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,298][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0975, 0.0422, 0.2793, 0.0219, 0.0290, 0.0431, 0.0168, 0.0162, 0.0183,
        0.0392, 0.0292, 0.0240, 0.0342, 0.0413, 0.0336, 0.0472, 0.0513, 0.0354,
        0.0469, 0.0533], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,300][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6665, 0.0186, 0.0278, 0.0022, 0.0124, 0.0192, 0.0401, 0.0057, 0.0057,
        0.0044, 0.0034, 0.0079, 0.0030, 0.0163, 0.0210, 0.0073, 0.0159, 0.0085,
        0.1029, 0.0114], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,302][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0007, 0.0322, 0.2512, 0.0110, 0.0893, 0.0220, 0.0176, 0.0124, 0.0214,
        0.0315, 0.0158, 0.0859, 0.0459, 0.1379, 0.0452, 0.0304, 0.0417, 0.0365,
        0.0356, 0.0354], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,303][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0327, 0.0382, 0.0753, 0.0004, 0.0215, 0.0161, 0.0092, 0.0005, 0.0014,
        0.0010, 0.0018, 0.0734, 0.0101, 0.2979, 0.0845, 0.0034, 0.0348, 0.0093,
        0.2814, 0.0071], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,305][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4034, 0.0845, 0.1065, 0.0054, 0.0235, 0.0278, 0.0182, 0.0052, 0.0081,
        0.0088, 0.0091, 0.0497, 0.0173, 0.0333, 0.0368, 0.0085, 0.0573, 0.0216,
        0.0610, 0.0139], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,307][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0002, 0.0154, 0.0214, 0.0179, 0.0683, 0.0357, 0.0111, 0.0118, 0.0551,
        0.0714, 0.0301, 0.1026, 0.0722, 0.1370, 0.0269, 0.0677, 0.0455, 0.0720,
        0.0499, 0.0879], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,308][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.4123e-03, 1.9726e-03, 6.6708e-03, 1.0103e-06, 6.1797e-04, 6.8117e-04,
        4.2765e-04, 2.5042e-06, 2.9020e-05, 1.7155e-05, 3.4304e-05, 3.8948e-02,
        2.7299e-04, 3.5393e-02, 8.5334e-02, 2.3448e-04, 2.2644e-02, 1.8765e-03,
        8.0022e-01, 2.2101e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,310][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0065, 0.0618, 0.0130, 0.0131, 0.0128, 0.0214, 0.0291, 0.0329, 0.0548,
        0.0521, 0.0650, 0.0730, 0.0693, 0.0665, 0.0716, 0.0681, 0.0415, 0.0872,
        0.0794, 0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,311][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:48,312][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[20795],
        [ 1304],
        [ 7170],
        [   21],
        [  509],
        [   73],
        [  586],
        [  226],
        [  464],
        [   82],
        [    9],
        [  111],
        [   24],
        [  274],
        [  173],
        [   39],
        [  110],
        [   15],
        [  126],
        [   18]], device='cuda:0')
[2024-07-24 10:18:48,313][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14004],
        [ 1432],
        [ 9649],
        [   62],
        [  859],
        [  137],
        [  920],
        [  354],
        [  778],
        [  128],
        [   20],
        [  162],
        [   37],
        [  325],
        [  218],
        [   59],
        [  137],
        [   20],
        [  135],
        [   27]], device='cuda:0')
[2024-07-24 10:18:48,314][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 8764],
        [12379],
        [49309],
        [45865],
        [45833],
        [43108],
        [44753],
        [45436],
        [46422],
        [44234],
        [44580],
        [38332],
        [44076],
        [42092],
        [39958],
        [40884],
        [45508],
        [40331],
        [34881],
        [38839]], device='cuda:0')
[2024-07-24 10:18:48,316][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19266],
        [17779],
        [27846],
        [26650],
        [27129],
        [26247],
        [26055],
        [25199],
        [24196],
        [21564],
        [23121],
        [29377],
        [30544],
        [29587],
        [30028],
        [29689],
        [29891],
        [30194],
        [24585],
        [24458]], device='cuda:0')
[2024-07-24 10:18:48,318][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7833],
        [16486],
        [ 2054],
        [ 4989],
        [10231],
        [11819],
        [12500],
        [11786],
        [10575],
        [10606],
        [10133],
        [ 9519],
        [ 9459],
        [10310],
        [ 9650],
        [ 9170],
        [ 9000],
        [ 8749],
        [ 8812],
        [ 8462]], device='cuda:0')
[2024-07-24 10:18:48,319][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36901],
        [36741],
        [36624],
        [25754],
        [36014],
        [31535],
        [27423],
        [ 4749],
        [26771],
        [24999],
        [ 4423],
        [34976],
        [ 9977],
        [36525],
        [31321],
        [13677],
        [33582],
        [18180],
        [35904],
        [13005]], device='cuda:0')
[2024-07-24 10:18:48,321][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[  821],
        [11082],
        [  551],
        [  733],
        [ 1037],
        [  798],
        [ 1203],
        [ 1184],
        [ 1326],
        [ 1205],
        [ 2159],
        [ 3058],
        [ 2688],
        [ 5289],
        [ 3625],
        [ 2250],
        [ 3987],
        [ 2915],
        [ 4959],
        [ 3482]], device='cuda:0')
[2024-07-24 10:18:48,323][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48765],
        [50022],
        [49158],
        [48996],
        [49154],
        [48872],
        [45645],
        [38374],
        [43118],
        [45322],
        [45420],
        [48145],
        [47862],
        [42922],
        [43369],
        [42868],
        [45113],
        [45460],
        [46238],
        [47124]], device='cuda:0')
[2024-07-24 10:18:48,324][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[49316],
        [38248],
        [   43],
        [  139],
        [ 2289],
        [ 9124],
        [12483],
        [12987],
        [14830],
        [17420],
        [19814],
        [19940],
        [21615],
        [24335],
        [28800],
        [27668],
        [28516],
        [29337],
        [32657],
        [32653]], device='cuda:0')
[2024-07-24 10:18:48,326][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3008],
        [22897],
        [27421],
        [28382],
        [27881],
        [29008],
        [29532],
        [29880],
        [30409],
        [30181],
        [29477],
        [27224],
        [27172],
        [26080],
        [26142],
        [26297],
        [26174],
        [26132],
        [25805],
        [26435]], device='cuda:0')
[2024-07-24 10:18:48,328][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5872],
        [28875],
        [ 2985],
        [ 7535],
        [ 2632],
        [ 7916],
        [33140],
        [24306],
        [31565],
        [18957],
        [ 7828],
        [34289],
        [29910],
        [10349],
        [31721],
        [26790],
        [34364],
        [13271],
        [37610],
        [33280]], device='cuda:0')
[2024-07-24 10:18:48,329][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 1241],
        [13645],
        [36020],
        [17245],
        [27293],
        [37339],
        [36689],
        [41469],
        [32009],
        [32068],
        [29386],
        [36947],
        [35422],
        [36157],
        [40839],
        [38834],
        [38312],
        [36959],
        [37329],
        [34081]], device='cuda:0')
[2024-07-24 10:18:48,330][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[28484],
        [28094],
        [28222],
        [28737],
        [28471],
        [28330],
        [28002],
        [27648],
        [28166],
        [28591],
        [29026],
        [37328],
        [37078],
        [33000],
        [30297],
        [28847],
        [29889],
        [29996],
        [27666],
        [27629]], device='cuda:0')
[2024-07-24 10:18:48,331][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13969],
        [ 8528],
        [12486],
        [ 6074],
        [ 7140],
        [ 6679],
        [ 4913],
        [ 5322],
        [ 4305],
        [ 4734],
        [ 4712],
        [ 5321],
        [ 4397],
        [ 5202],
        [ 5107],
        [ 4921],
        [ 4634],
        [ 4703],
        [ 5151],
        [ 4950]], device='cuda:0')
[2024-07-24 10:18:48,332][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[39541],
        [31412],
        [36615],
        [32851],
        [30880],
        [28434],
        [31345],
        [35959],
        [22862],
        [31049],
        [36343],
        [30937],
        [20932],
        [32866],
        [31685],
        [30148],
        [26901],
        [22803],
        [28723],
        [27305]], device='cuda:0')
[2024-07-24 10:18:48,334][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 5775],
        [20192],
        [33122],
        [33503],
        [32276],
        [33191],
        [33749],
        [33195],
        [33677],
        [34127],
        [34412],
        [34099],
        [36772],
        [37528],
        [38208],
        [36147],
        [36089],
        [35271],
        [38881],
        [37794]], device='cuda:0')
[2024-07-24 10:18:48,335][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15627],
        [21847],
        [13451],
        [13191],
        [11275],
        [10402],
        [ 9033],
        [10342],
        [ 8859],
        [ 9489],
        [ 9189],
        [12182],
        [11432],
        [ 8357],
        [ 7886],
        [ 7511],
        [ 7039],
        [ 6292],
        [ 5158],
        [ 5445]], device='cuda:0')
[2024-07-24 10:18:48,337][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42271],
        [48665],
        [38784],
        [40190],
        [40512],
        [40781],
        [37961],
        [38182],
        [37311],
        [38180],
        [39057],
        [36007],
        [35489],
        [40268],
        [37198],
        [40012],
        [37043],
        [39888],
        [38047],
        [40955]], device='cuda:0')
[2024-07-24 10:18:48,339][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8564],
        [12883],
        [20308],
        [30117],
        [22269],
        [20820],
        [37201],
        [34253],
        [24228],
        [13280],
        [ 8535],
        [ 5664],
        [ 4844],
        [ 1827],
        [ 1617],
        [ 1300],
        [ 1311],
        [ 1315],
        [ 1964],
        [ 1385]], device='cuda:0')
[2024-07-24 10:18:48,340][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[33281],
        [20375],
        [12804],
        [12841],
        [11979],
        [ 9060],
        [ 8917],
        [ 9760],
        [10480],
        [11319],
        [11789],
        [12789],
        [12723],
        [15003],
        [13555],
        [12228],
        [13649],
        [12921],
        [14220],
        [13408]], device='cuda:0')
[2024-07-24 10:18:48,342][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[2774],
        [1233],
        [2492],
        [1970],
        [2089],
        [1938],
        [3617],
        [4766],
        [4387],
        [4014],
        [3815],
        [2019],
        [2357],
        [3590],
        [4216],
        [4003],
        [2986],
        [3179],
        [3298],
        [2928]], device='cuda:0')
[2024-07-24 10:18:48,344][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10738],
        [ 2502],
        [ 1307],
        [ 1477],
        [ 1925],
        [ 1812],
        [ 1770],
        [ 1963],
        [ 2140],
        [ 1704],
        [ 1779],
        [ 2249],
        [ 2562],
        [ 4027],
        [ 4287],
        [ 3396],
        [ 3073],
        [ 3093],
        [ 4080],
        [ 3296]], device='cuda:0')
[2024-07-24 10:18:48,345][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6622],
        [4885],
        [4852],
        [4929],
        [4905],
        [3897],
        [4225],
        [4493],
        [4863],
        [4747],
        [4511],
        [2706],
        [2343],
        [3672],
        [3067],
        [3875],
        [2753],
        [3216],
        [1942],
        [2095]], device='cuda:0')
[2024-07-24 10:18:48,347][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38083],
        [38404],
        [38136],
        [35519],
        [38772],
        [35118],
        [40486],
        [40132],
        [40043],
        [39506],
        [40159],
        [33137],
        [35356],
        [40905],
        [39619],
        [40466],
        [40143],
        [41060],
        [41961],
        [42244]], device='cuda:0')
[2024-07-24 10:18:48,348][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21976],
        [45341],
        [43549],
        [38950],
        [37133],
        [37493],
        [38535],
        [37567],
        [36978],
        [37475],
        [37227],
        [33961],
        [30992],
        [32531],
        [31633],
        [32929],
        [31762],
        [30221],
        [31696],
        [33287]], device='cuda:0')
[2024-07-24 10:18:48,349][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2010],
        [18431],
        [18692],
        [18665],
        [18468],
        [17954],
        [18144],
        [16576],
        [15730],
        [14635],
        [13542],
        [ 6092],
        [ 6336],
        [ 6570],
        [ 9660],
        [10272],
        [10241],
        [10706],
        [13761],
        [13570]], device='cuda:0')
[2024-07-24 10:18:48,350][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[11512],
        [ 4200],
        [ 5913],
        [ 6483],
        [ 5103],
        [ 7506],
        [ 8361],
        [ 6665],
        [ 6485],
        [ 6715],
        [ 5581],
        [ 8299],
        [ 6276],
        [ 7104],
        [ 9489],
        [ 9646],
        [ 9777],
        [10216],
        [10782],
        [ 9685]], device='cuda:0')
[2024-07-24 10:18:48,351][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44615],
        [33283],
        [39322],
        [37610],
        [39405],
        [41642],
        [38002],
        [38024],
        [40616],
        [42458],
        [43814],
        [46896],
        [46584],
        [44195],
        [43449],
        [43105],
        [44574],
        [43961],
        [43659],
        [43337]], device='cuda:0')
[2024-07-24 10:18:48,353][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15299],
        [22033],
        [16647],
        [17783],
        [19986],
        [24200],
        [21750],
        [17618],
        [28523],
        [20649],
        [14886],
        [21866],
        [33997],
        [20876],
        [22288],
        [28047],
        [29636],
        [35007],
        [26455],
        [30431]], device='cuda:0')
[2024-07-24 10:18:48,355][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860],
        [11860]], device='cuda:0')
[2024-07-24 10:18:48,399][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:48,399][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,400][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,400][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,400][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,401][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,401][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,402][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,403][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,403][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,403][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,404][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,405][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,406][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8906, 0.1094], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,407][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.1228e-04, 9.9959e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,408][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9840, 0.0160], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,409][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6890, 0.3110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,411][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8757, 0.1243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,413][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2909, 0.7091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,414][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1867, 0.8133], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,416][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9477, 0.0523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,416][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0490, 0.9510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,417][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,417][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0784, 0.9216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,417][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0789, 0.9211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,418][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0519, 0.2944, 0.6537], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,418][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([3.4964e-05, 2.6860e-01, 7.3136e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,418][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0632, 0.0208, 0.9160], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,419][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0604, 0.8199, 0.1196], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,419][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.5275, 0.4558, 0.0168], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,419][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([0.0307, 0.9500, 0.0193], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,420][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0405, 0.2625, 0.6970], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,420][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.5939, 0.0414, 0.3647], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,422][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.0072, 0.6490, 0.3438], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,424][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.0089, 0.9790, 0.0121], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,425][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.0033, 0.0855, 0.9112], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,427][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.0081, 0.5381, 0.4538], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,428][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1813, 0.2411, 0.4826, 0.0950], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,430][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.1378e-04, 2.8076e-01, 6.9209e-01, 2.6931e-02], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,431][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7569, 0.0012, 0.2387, 0.0032], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,433][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4151, 0.4533, 0.0688, 0.0628], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,433][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5441, 0.4331, 0.0104, 0.0124], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,434][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([3.6725e-04, 9.6364e-01, 3.5981e-02, 6.9876e-06], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,434][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0792, 0.2949, 0.5893, 0.0365], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,434][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8929, 0.0370, 0.0685, 0.0016], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,435][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0853, 0.6976, 0.1819, 0.0352], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,435][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.6911e-05, 9.8902e-01, 1.0950e-02, 2.1639e-07], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,435][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0029, 0.0898, 0.8588, 0.0485], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,436][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1739, 0.2307, 0.5690, 0.0264], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,436][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.3150, 0.1892, 0.4085, 0.0124, 0.0749], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,436][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([6.9627e-05, 1.0934e-01, 8.6041e-01, 1.5346e-02, 1.4838e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,437][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.1719, 0.0221, 0.3017, 0.0136, 0.4907], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,437][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.2777, 0.4818, 0.0961, 0.0635, 0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,439][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.5583, 0.3781, 0.0193, 0.0080, 0.0362], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,440][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([1.4148e-02, 8.2439e-01, 1.5438e-01, 8.3006e-07, 7.0719e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,442][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0295, 0.1678, 0.6082, 0.0337, 0.1609], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,443][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([9.5639e-01, 1.1241e-02, 2.9205e-02, 7.1882e-04, 2.4458e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,444][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0659, 0.5768, 0.3055, 0.0436, 0.0083], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,445][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([3.3418e-03, 8.5136e-01, 1.4370e-01, 3.2063e-08, 1.6003e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,447][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0024, 0.0512, 0.6363, 0.0268, 0.2833], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,448][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0623, 0.2196, 0.4555, 0.0330, 0.2297], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,450][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.6280, 0.0664, 0.1930, 0.0240, 0.0578, 0.0308], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,451][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ were] are: tensor([3.1007e-04, 3.0538e-01, 5.8173e-01, 2.3684e-02, 4.7674e-02, 4.1227e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,451][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.8194, 0.0010, 0.0699, 0.0022, 0.0877, 0.0199], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,451][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.4675, 0.2690, 0.0338, 0.0544, 0.0446, 0.1308], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,452][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.6991, 0.1474, 0.0055, 0.0051, 0.0272, 0.1157], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,452][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ were] are: tensor([1.7117e-02, 9.6730e-01, 4.7806e-03, 2.2031e-05, 3.8991e-03, 6.8786e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,452][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0983, 0.1081, 0.3305, 0.0242, 0.2221, 0.2167], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,453][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.8959, 0.0284, 0.0685, 0.0010, 0.0027, 0.0035], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,453][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.1793, 0.5191, 0.2194, 0.0245, 0.0051, 0.0526], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,454][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ were] are: tensor([6.4523e-03, 9.9134e-01, 1.1956e-03, 6.4956e-07, 2.5939e-04, 7.5640e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,454][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0011, 0.0509, 0.5554, 0.0255, 0.3240, 0.0431], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,454][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.1255, 0.1166, 0.4117, 0.0296, 0.1709, 0.1457], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,455][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0914, 0.1072, 0.1716, 0.0125, 0.0574, 0.0513, 0.5087],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,456][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([1.3365e-04, 4.0089e-01, 4.3356e-01, 2.1573e-02, 4.0343e-02, 7.7502e-02,
        2.6003e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,458][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.3732, 0.0088, 0.0979, 0.0040, 0.1710, 0.0409, 0.3041],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,460][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.1314, 0.4830, 0.0423, 0.0337, 0.0757, 0.1624, 0.0715],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,461][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.3310, 0.3413, 0.0091, 0.0077, 0.0227, 0.2464, 0.0419],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,462][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([5.2770e-04, 9.9510e-01, 2.3165e-04, 1.1611e-06, 6.1600e-04, 8.6578e-04,
        2.6529e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,464][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0372, 0.1321, 0.2239, 0.0156, 0.1088, 0.4118, 0.0705],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,465][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([8.3280e-01, 6.2981e-02, 9.1334e-02, 7.9069e-04, 4.3533e-03, 4.9039e-03,
        2.8348e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,466][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0534, 0.6984, 0.1232, 0.0252, 0.0053, 0.0540, 0.0406],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,468][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([5.9009e-05, 9.9946e-01, 2.9369e-05, 9.6655e-09, 1.7801e-05, 3.6355e-05,
        3.9957e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,469][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0005, 0.0310, 0.4267, 0.0294, 0.3674, 0.0592, 0.0857],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,471][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.1103, 0.2438, 0.2302, 0.0218, 0.0725, 0.2613, 0.0602],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,472][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.1386, 0.1732, 0.3403, 0.0217, 0.0251, 0.0431, 0.2448, 0.0133],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,473][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ about] are: tensor([5.9916e-05, 3.4196e-01, 5.6977e-01, 1.3913e-02, 2.6914e-02, 1.7769e-02,
        2.2784e-02, 6.8289e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,473][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.1934, 0.0202, 0.2637, 0.0159, 0.1446, 0.0776, 0.1952, 0.0893],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,474][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.1360, 0.5277, 0.0224, 0.0393, 0.0591, 0.0931, 0.1064, 0.0160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,474][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.1759, 0.4256, 0.0225, 0.0152, 0.0523, 0.2017, 0.0795, 0.0274],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,475][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ about] are: tensor([3.3494e-05, 9.6510e-01, 8.1903e-04, 7.6300e-06, 1.4922e-02, 4.4042e-04,
        1.8679e-02, 2.9719e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,475][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0162, 0.1426, 0.2797, 0.0169, 0.2108, 0.2237, 0.0690, 0.0412],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,475][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.5658, 0.1428, 0.2395, 0.0019, 0.0142, 0.0123, 0.0120, 0.0114],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,476][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0689, 0.5714, 0.1472, 0.0237, 0.0023, 0.0370, 0.0294, 0.1200],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,476][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ about] are: tensor([1.8454e-06, 9.9655e-01, 1.5309e-04, 1.9195e-07, 7.5365e-04, 1.9746e-05,
        2.5233e-03, 1.7628e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,476][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ about] are: tensor([3.5277e-04, 3.4461e-02, 4.6250e-01, 2.7536e-02, 3.3868e-01, 4.6033e-02,
        7.1411e-02, 1.9018e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,477][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0480, 0.2920, 0.4094, 0.0107, 0.0948, 0.0790, 0.0359, 0.0302],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,479][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.2018, 0.5014, 0.0511, 0.0170, 0.0186, 0.0385, 0.1201, 0.0068, 0.0446],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,480][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ going] are: tensor([2.6256e-04, 3.2404e-01, 4.6678e-01, 1.6950e-02, 5.2578e-02, 5.1329e-02,
        3.8312e-02, 1.4776e-02, 3.4976e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,482][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.3586, 0.0048, 0.0913, 0.0063, 0.1674, 0.0591, 0.2140, 0.0319, 0.0668],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,483][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.1268, 0.4187, 0.0282, 0.0408, 0.0428, 0.1088, 0.1020, 0.0260, 0.1060],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,484][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.1179, 0.3692, 0.0111, 0.0149, 0.0279, 0.3445, 0.0610, 0.0400, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,485][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ going] are: tensor([2.4106e-04, 9.4113e-01, 1.4202e-02, 1.6620e-06, 3.1684e-02, 2.1861e-03,
        1.0412e-02, 3.2092e-07, 1.4036e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,487][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0216, 0.1228, 0.2771, 0.0094, 0.1940, 0.1956, 0.0494, 0.0509, 0.0792],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,489][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.6693, 0.1461, 0.1336, 0.0022, 0.0149, 0.0111, 0.0062, 0.0152, 0.0013],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,490][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1092, 0.3809, 0.1963, 0.0211, 0.0078, 0.0526, 0.0566, 0.1166, 0.0589],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,491][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ going] are: tensor([3.5675e-05, 9.7686e-01, 1.4076e-02, 3.3029e-08, 5.5160e-03, 1.7377e-04,
        3.3336e-03, 2.7083e-08, 7.6933e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,491][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ going] are: tensor([2.3375e-04, 2.7383e-02, 4.5356e-01, 2.6220e-02, 3.2243e-01, 4.9323e-02,
        6.9759e-02, 2.0859e-02, 3.0230e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,491][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.2073, 0.1279, 0.2768, 0.0070, 0.0919, 0.1365, 0.0494, 0.0254, 0.0777],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,492][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0200, 0.4692, 0.1450, 0.0736, 0.0230, 0.0660, 0.0776, 0.0065, 0.0588,
        0.0604], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,492][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.4814e-04, 2.2456e-01, 6.2241e-01, 1.0570e-02, 3.4815e-02, 1.9029e-02,
        2.1062e-02, 8.9921e-03, 2.5690e-02, 3.2726e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,492][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0816, 0.0132, 0.2679, 0.0260, 0.1116, 0.1311, 0.0799, 0.0956, 0.1325,
        0.0606], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,493][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1732, 0.3496, 0.0439, 0.0317, 0.0549, 0.0939, 0.1212, 0.0170, 0.0909,
        0.0237], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,493][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1925, 0.3059, 0.0090, 0.0131, 0.0232, 0.2722, 0.0664, 0.0298, 0.0152,
        0.0725], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,494][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.7193e-03, 8.0514e-01, 6.5738e-02, 2.8489e-06, 1.1460e-01, 2.6012e-03,
        9.9240e-03, 7.0305e-07, 2.4777e-04, 2.8456e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,495][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0340, 0.1317, 0.3119, 0.0086, 0.1555, 0.1238, 0.0599, 0.0434, 0.0796,
        0.0516], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,496][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6629, 0.1424, 0.1253, 0.0022, 0.0112, 0.0110, 0.0101, 0.0208, 0.0018,
        0.0123], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,498][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0684, 0.5751, 0.1296, 0.0154, 0.0016, 0.0247, 0.0235, 0.1099, 0.0222,
        0.0296], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,499][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.4823e-04, 9.1451e-01, 6.2643e-02, 1.2666e-07, 1.7909e-02, 3.1008e-04,
        4.0422e-03, 1.2341e-07, 2.6055e-05, 1.0913e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,500][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([4.5403e-04, 2.7980e-02, 4.6276e-01, 1.8215e-02, 3.0054e-01, 3.3097e-02,
        7.9286e-02, 1.5961e-02, 3.5390e-02, 2.6323e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,501][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.6856, 0.0622, 0.1529, 0.0019, 0.0279, 0.0180, 0.0215, 0.0073, 0.0177,
        0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,503][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.5894, 0.0314, 0.1620, 0.0059, 0.0523, 0.0127, 0.0964, 0.0021, 0.0300,
        0.0150, 0.0027], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,504][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.6133e-04, 2.8500e-01, 5.1241e-01, 1.2087e-02, 2.5229e-02, 2.6147e-02,
        2.0743e-02, 1.0914e-02, 2.4495e-02, 3.8222e-02, 4.4587e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,505][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.4903, 0.0007, 0.1054, 0.0060, 0.1505, 0.0326, 0.1252, 0.0275, 0.0320,
        0.0085, 0.0213], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,507][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2599, 0.2989, 0.0294, 0.0269, 0.0305, 0.0851, 0.0897, 0.0192, 0.0914,
        0.0255, 0.0435], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,507][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3804, 0.1884, 0.0082, 0.0093, 0.0309, 0.1681, 0.0504, 0.0258, 0.0094,
        0.0426, 0.0863], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,508][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([3.0733e-03, 5.1044e-01, 1.6658e-01, 1.2770e-05, 2.9997e-01, 3.9127e-03,
        1.4680e-02, 1.8962e-06, 1.0700e-03, 1.1533e-04, 1.4288e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,508][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0425, 0.1227, 0.2464, 0.0097, 0.1285, 0.1284, 0.0520, 0.0505, 0.0915,
        0.0517, 0.0761], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,509][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.8188, 0.0561, 0.0860, 0.0014, 0.0053, 0.0058, 0.0068, 0.0109, 0.0011,
        0.0033, 0.0046], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,509][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0310, 0.5389, 0.1084, 0.0145, 0.0021, 0.0288, 0.0384, 0.1254, 0.0286,
        0.0400, 0.0439], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,509][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.8887e-04, 7.1663e-01, 1.8427e-01, 8.1374e-07, 9.1347e-02, 5.3012e-04,
        6.4842e-03, 5.6109e-07, 1.2368e-04, 7.5702e-05, 4.9153e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,510][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.7735e-04, 2.7539e-02, 5.1354e-01, 1.2162e-02, 2.9550e-01, 2.0843e-02,
        6.2343e-02, 9.7511e-03, 2.4197e-02, 1.9171e-02, 1.4670e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,510][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1572, 0.0682, 0.2483, 0.0084, 0.1004, 0.1184, 0.0652, 0.0325, 0.1328,
        0.0291, 0.0395], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,511][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.0702, 0.2438, 0.1112, 0.0121, 0.0849, 0.0488, 0.1207, 0.0067, 0.0952,
        0.0439, 0.0154, 0.1471], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,511][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ school] are: tensor([2.0708e-04, 2.9429e-01, 4.7911e-01, 1.3302e-02, 1.9186e-02, 3.2999e-02,
        1.7382e-02, 5.4207e-03, 2.0045e-02, 3.1348e-02, 3.5761e-02, 5.0946e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,513][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.1547, 0.0091, 0.0837, 0.0052, 0.0914, 0.0223, 0.1077, 0.0165, 0.0134,
        0.0141, 0.0246, 0.4574], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,515][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.1631, 0.4374, 0.0500, 0.0325, 0.0322, 0.0899, 0.0335, 0.0089, 0.0256,
        0.0206, 0.0293, 0.0770], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,516][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ school] are: tensor([0.2820, 0.0718, 0.0019, 0.0017, 0.0026, 0.0807, 0.0032, 0.0036, 0.0008,
        0.0074, 0.0218, 0.5225], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,517][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ school] are: tensor([4.5337e-02, 5.7089e-02, 3.3471e-02, 2.5094e-07, 3.0721e-03, 2.5689e-03,
        2.2972e-04, 3.2458e-08, 4.2169e-06, 3.3080e-06, 6.8467e-06, 8.5822e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,519][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0572, 0.0853, 0.3650, 0.0052, 0.0548, 0.0882, 0.0327, 0.0230, 0.0289,
        0.0129, 0.0251, 0.2218], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,520][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ school] are: tensor([9.4326e-01, 9.7831e-03, 3.8727e-02, 1.3474e-04, 9.1777e-04, 8.3568e-04,
        3.8440e-04, 4.0370e-04, 3.2511e-05, 1.7804e-04, 4.0434e-04, 4.9351e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,522][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.1648, 0.5167, 0.1000, 0.0121, 0.0019, 0.0249, 0.0175, 0.0574, 0.0219,
        0.0212, 0.0465, 0.0151], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,523][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ school] are: tensor([1.8561e-02, 1.9548e-02, 1.9653e-02, 2.5952e-09, 1.5274e-04, 1.8875e-04,
        3.1033e-05, 1.4560e-09, 7.1572e-08, 1.8021e-07, 3.9751e-07, 9.4187e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,524][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.0007, 0.0155, 0.3975, 0.0117, 0.2431, 0.0216, 0.0615, 0.0096, 0.0211,
        0.0172, 0.0142, 0.1865], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,525][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ school] are: tensor([0.3084, 0.1479, 0.1954, 0.0047, 0.0469, 0.0862, 0.0233, 0.0096, 0.0515,
        0.0099, 0.0218, 0.0944], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,525][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1081, 0.0940, 0.1748, 0.0073, 0.0647, 0.0540, 0.2328, 0.0086, 0.0800,
        0.0167, 0.0200, 0.0802, 0.0586], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,526][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.6842e-04, 2.0437e-01, 5.8324e-01, 9.6311e-03, 2.0165e-02, 2.2787e-02,
        1.7011e-02, 8.3412e-03, 1.8362e-02, 2.1864e-02, 1.9700e-02, 4.0519e-02,
        3.3833e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,526][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1410, 0.0053, 0.2901, 0.0045, 0.1988, 0.0329, 0.0678, 0.0359, 0.0251,
        0.0106, 0.0889, 0.0926, 0.0064], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,527][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.3787, 0.2697, 0.0213, 0.0167, 0.0147, 0.0573, 0.0685, 0.0093, 0.0531,
        0.0099, 0.0213, 0.0513, 0.0282], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,527][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1582, 0.0961, 0.0025, 0.0034, 0.0040, 0.0517, 0.0119, 0.0105, 0.0020,
        0.0124, 0.0388, 0.5024, 0.1059], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,527][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([2.1662e-02, 1.5332e-01, 1.3780e-03, 2.1819e-06, 1.6915e-03, 3.9981e-04,
        1.0332e-03, 7.8917e-07, 5.6077e-05, 1.4087e-05, 4.5174e-05, 8.1908e-01,
        1.3229e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,528][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0312, 0.0630, 0.2079, 0.0055, 0.0648, 0.0784, 0.0318, 0.0268, 0.0485,
        0.0250, 0.0293, 0.2696, 0.1183], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,528][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([9.0728e-01, 3.0223e-02, 4.2154e-02, 4.5960e-04, 1.2713e-03, 2.1506e-03,
        1.7725e-03, 2.9308e-03, 3.5882e-04, 1.2159e-03, 1.2343e-03, 1.6709e-03,
        7.2783e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,529][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1613, 0.4423, 0.1392, 0.0148, 0.0013, 0.0202, 0.0246, 0.0972, 0.0192,
        0.0182, 0.0343, 0.0075, 0.0199], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,530][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.7416e-03, 8.0480e-02, 5.6044e-04, 7.2422e-08, 1.3970e-04, 3.9391e-05,
        1.9844e-04, 1.3865e-07, 3.6558e-06, 3.9185e-06, 1.2744e-05, 9.1661e-01,
        2.1288e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,532][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0004, 0.0200, 0.3601, 0.0133, 0.2112, 0.0226, 0.0557, 0.0093, 0.0272,
        0.0182, 0.0144, 0.2326, 0.0149], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,534][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0878, 0.0811, 0.3024, 0.0067, 0.0612, 0.0863, 0.0421, 0.0212, 0.0792,
        0.0242, 0.0295, 0.1124, 0.0659], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,535][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0808, 0.2167, 0.0708, 0.0053, 0.0174, 0.0746, 0.0335, 0.0052, 0.0240,
        0.0311, 0.0046, 0.0939, 0.2348, 0.1073], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,536][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([1.0454e-04, 1.2119e-01, 5.6744e-01, 1.3284e-02, 2.1613e-02, 3.6862e-02,
        1.6996e-02, 5.1168e-03, 1.7980e-02, 2.3872e-02, 2.5773e-02, 5.3289e-02,
        4.9792e-02, 4.6683e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,538][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0549, 0.0262, 0.0685, 0.0099, 0.0779, 0.0456, 0.1173, 0.0424, 0.0297,
        0.0535, 0.0481, 0.1857, 0.0235, 0.2166], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,540][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.1953, 0.3359, 0.0381, 0.0324, 0.0233, 0.0766, 0.0528, 0.0072, 0.0530,
        0.0091, 0.0174, 0.0410, 0.0560, 0.0619], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,541][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0686, 0.0525, 0.0029, 0.0013, 0.0037, 0.0460, 0.0053, 0.0036, 0.0008,
        0.0058, 0.0108, 0.5425, 0.1248, 0.1314], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,542][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([1.7722e-02, 8.7616e-03, 3.2298e-02, 3.3539e-08, 6.6595e-04, 4.3596e-04,
        5.7396e-05, 6.5709e-09, 6.9308e-07, 3.0642e-07, 4.3511e-07, 1.4893e-01,
        1.4718e-04, 7.9098e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,542][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0062, 0.0356, 0.1228, 0.0052, 0.0390, 0.0783, 0.0161, 0.0096, 0.0185,
        0.0101, 0.0170, 0.1486, 0.0923, 0.4007], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,543][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([8.4644e-01, 1.9031e-02, 8.9869e-02, 6.0743e-04, 2.8966e-03, 2.8692e-03,
        2.2180e-03, 1.7116e-03, 3.7139e-04, 1.2573e-03, 1.3642e-03, 5.0277e-03,
        7.6512e-03, 1.8689e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,543][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0402, 0.3934, 0.1191, 0.0341, 0.0028, 0.0341, 0.0219, 0.0686, 0.0279,
        0.0435, 0.0967, 0.0264, 0.0842, 0.0072], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,544][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([8.8453e-03, 1.3896e-02, 7.0122e-02, 1.8707e-09, 1.8528e-04, 1.9910e-04,
        1.5297e-05, 5.7501e-10, 4.1876e-08, 9.1090e-08, 8.3380e-08, 2.3687e-01,
        2.8083e-05, 6.6984e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,544][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.0006, 0.0162, 0.3605, 0.0134, 0.1926, 0.0272, 0.0650, 0.0121, 0.0248,
        0.0169, 0.0154, 0.1684, 0.0156, 0.0714], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,544][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([0.0177, 0.0814, 0.2130, 0.0144, 0.0552, 0.1389, 0.0271, 0.0133, 0.0538,
        0.0225, 0.0570, 0.0913, 0.1320, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,545][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0859, 0.0551, 0.0871, 0.0089, 0.0258, 0.0229, 0.1482, 0.0066, 0.0902,
        0.0177, 0.0068, 0.0695, 0.1090, 0.1133, 0.1532], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,545][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([1.0629e-04, 1.2697e-01, 5.5986e-01, 6.1754e-03, 2.3124e-02, 1.5978e-02,
        2.0299e-02, 5.8790e-03, 1.6747e-02, 3.2686e-02, 1.5022e-02, 5.6900e-02,
        2.8735e-02, 7.2696e-02, 1.8826e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,546][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1221, 0.0022, 0.0491, 0.0067, 0.0875, 0.0456, 0.0963, 0.0197, 0.0298,
        0.0120, 0.0380, 0.1762, 0.0059, 0.1706, 0.1382], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,548][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.1176, 0.3805, 0.0205, 0.0271, 0.0185, 0.0703, 0.0268, 0.0083, 0.0307,
        0.0171, 0.0230, 0.0510, 0.0549, 0.0378, 0.1157], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,550][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.1729, 0.0449, 0.0016, 0.0007, 0.0028, 0.0290, 0.0033, 0.0036, 0.0006,
        0.0071, 0.0100, 0.3590, 0.0699, 0.1164, 0.1780], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,551][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([1.7911e-02, 1.5914e-02, 1.7653e-03, 3.8392e-08, 1.7061e-04, 5.4464e-04,
        5.4642e-05, 1.8674e-08, 4.5220e-07, 3.5289e-07, 1.0702e-06, 1.0427e-01,
        4.3760e-04, 5.6604e-01, 2.9289e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,552][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0046, 0.0137, 0.0814, 0.0016, 0.0188, 0.0355, 0.0069, 0.0074, 0.0149,
        0.0063, 0.0090, 0.1313, 0.0328, 0.3141, 0.3216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,554][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([8.5808e-01, 2.7587e-02, 8.5511e-02, 2.4096e-04, 1.4874e-03, 2.1572e-03,
        9.1809e-04, 1.2270e-03, 2.1676e-04, 6.1251e-04, 8.6555e-04, 4.2471e-03,
        4.6168e-03, 7.4218e-03, 4.8065e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,555][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0867, 0.3797, 0.1140, 0.0176, 0.0022, 0.0259, 0.0208, 0.0794, 0.0309,
        0.0443, 0.0755, 0.0225, 0.0762, 0.0109, 0.0134], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,556][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([8.9369e-03, 2.4766e-02, 2.0270e-03, 7.1795e-10, 1.3855e-05, 9.5566e-05,
        1.2226e-05, 1.2660e-09, 2.7802e-08, 4.9932e-08, 1.2189e-07, 1.5175e-01,
        8.8952e-05, 3.3129e-01, 4.8102e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,557][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([2.3695e-04, 1.4689e-02, 3.1602e-01, 1.0780e-02, 2.1252e-01, 2.0099e-02,
        4.8190e-02, 7.4055e-03, 1.7671e-02, 1.4588e-02, 1.1144e-02, 1.8277e-01,
        1.1563e-02, 7.0165e-02, 6.2156e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,559][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.1218, 0.1036, 0.2350, 0.0059, 0.0313, 0.0576, 0.0252, 0.0097, 0.0329,
        0.0144, 0.0141, 0.0625, 0.0372, 0.0660, 0.1829], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,559][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0182, 0.2514, 0.0690, 0.0473, 0.0129, 0.0696, 0.0379, 0.0067, 0.0619,
        0.0474, 0.0306, 0.0334, 0.0755, 0.0187, 0.1719, 0.0475],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,560][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.5779e-04, 1.3572e-01, 4.6079e-01, 1.0531e-02, 2.9436e-02, 1.8447e-02,
        1.9413e-02, 1.0898e-02, 2.1360e-02, 3.8325e-02, 2.5751e-02, 6.0868e-02,
        3.5080e-02, 6.2211e-02, 2.0362e-02, 5.0544e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,560][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0308, 0.0083, 0.0925, 0.0211, 0.0357, 0.0841, 0.0327, 0.0792, 0.0881,
        0.0541, 0.1506, 0.0245, 0.0067, 0.0321, 0.2098, 0.0497],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,561][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1278, 0.1650, 0.0335, 0.0173, 0.0389, 0.0572, 0.0618, 0.0134, 0.0547,
        0.0159, 0.0289, 0.0595, 0.0444, 0.0996, 0.1610, 0.0210],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,561][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0437, 0.0420, 0.0022, 0.0027, 0.0037, 0.0496, 0.0111, 0.0069, 0.0018,
        0.0109, 0.0231, 0.3366, 0.0818, 0.0731, 0.2843, 0.0266],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,562][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.2412e-04, 2.6415e-03, 2.9250e-03, 2.7735e-08, 1.2458e-03, 4.1159e-05,
        3.3671e-05, 4.6785e-09, 1.1359e-06, 1.4544e-07, 3.4851e-07, 7.9507e-02,
        2.1282e-05, 7.3421e-01, 1.7924e-01, 6.7249e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,562][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0054, 0.0147, 0.0465, 0.0015, 0.0219, 0.0229, 0.0080, 0.0109, 0.0127,
        0.0093, 0.0109, 0.0964, 0.0475, 0.4464, 0.2272, 0.0178],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,563][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6410, 0.1276, 0.0705, 0.0017, 0.0073, 0.0062, 0.0070, 0.0149, 0.0018,
        0.0100, 0.0057, 0.0111, 0.0221, 0.0438, 0.0164, 0.0129],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,564][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0652, 0.4441, 0.1059, 0.0186, 0.0019, 0.0235, 0.0254, 0.1048, 0.0231,
        0.0401, 0.0505, 0.0195, 0.0253, 0.0040, 0.0123, 0.0358],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,565][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.6482e-05, 1.9296e-03, 3.6495e-03, 7.0362e-10, 1.6791e-04, 3.7624e-06,
        8.2679e-06, 4.9850e-10, 6.3868e-08, 3.2384e-08, 4.4958e-08, 1.0696e-01,
        1.7580e-06, 5.5622e-01, 3.3098e-01, 3.2396e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,566][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.7082e-04, 1.4586e-02, 3.0111e-01, 9.7650e-03, 1.8279e-01, 1.8672e-02,
        4.7618e-02, 7.4668e-03, 2.0415e-02, 1.4076e-02, 1.1610e-02, 1.9768e-01,
        1.1762e-02, 7.2424e-02, 7.2038e-02, 1.7713e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,568][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3988, 0.0319, 0.1024, 0.0014, 0.0128, 0.0181, 0.0167, 0.0057, 0.0155,
        0.0048, 0.0048, 0.0528, 0.0136, 0.0543, 0.2583, 0.0080],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,569][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.1394, 0.1022, 0.0837, 0.0045, 0.0222, 0.0252, 0.1498, 0.0035, 0.0272,
        0.0079, 0.0046, 0.0587, 0.1026, 0.0947, 0.0747, 0.0074, 0.0918],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,570][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([4.0182e-04, 1.4329e-01, 5.1059e-01, 9.0305e-03, 1.6212e-02, 2.6062e-02,
        2.0668e-02, 6.2129e-03, 1.2394e-02, 2.3125e-02, 2.6022e-02, 5.2835e-02,
        3.9046e-02, 3.9745e-02, 2.4364e-02, 3.5206e-02, 1.4797e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,572][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.2019, 0.0007, 0.0507, 0.0011, 0.0995, 0.0238, 0.0631, 0.0076, 0.0065,
        0.0019, 0.0119, 0.0838, 0.0011, 0.3005, 0.0687, 0.0037, 0.0734],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,574][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1660, 0.1520, 0.0140, 0.0141, 0.0221, 0.0524, 0.0189, 0.0069, 0.0309,
        0.0135, 0.0285, 0.0538, 0.0539, 0.0841, 0.1680, 0.0201, 0.1008],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,575][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1136, 0.0196, 0.0015, 0.0008, 0.0023, 0.0402, 0.0032, 0.0027, 0.0006,
        0.0049, 0.0115, 0.2208, 0.0889, 0.1176, 0.2309, 0.0157, 0.1249],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,576][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([3.2396e-03, 1.1357e-02, 3.9350e-03, 2.3756e-08, 4.0739e-04, 3.6731e-04,
        7.2961e-05, 9.2998e-09, 4.7187e-07, 2.0335e-07, 4.0286e-07, 1.1462e-01,
        1.1150e-04, 4.5961e-01, 3.8339e-01, 1.1094e-05, 2.2881e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,577][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0097, 0.0139, 0.1050, 0.0012, 0.0178, 0.0299, 0.0105, 0.0076, 0.0157,
        0.0043, 0.0102, 0.0911, 0.0394, 0.2627, 0.3323, 0.0084, 0.0403],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,577][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([8.5706e-01, 1.6036e-02, 7.4533e-02, 2.0140e-04, 2.9432e-03, 1.4585e-03,
        1.2202e-03, 9.5827e-04, 1.4705e-04, 5.0603e-04, 9.2638e-04, 7.3718e-03,
        5.8546e-03, 1.6831e-02, 7.3616e-03, 1.0137e-03, 5.5785e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,578][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.1503, 0.2792, 0.0905, 0.0119, 0.0023, 0.0206, 0.0214, 0.0743, 0.0229,
        0.0406, 0.0866, 0.0330, 0.0722, 0.0109, 0.0109, 0.0503, 0.0222],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,578][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([3.1374e-04, 5.6067e-03, 9.4785e-03, 7.3984e-10, 6.7595e-05, 6.3573e-05,
        3.3516e-05, 7.9173e-10, 2.7613e-08, 6.5225e-08, 4.1555e-08, 1.3764e-01,
        1.6391e-05, 2.6894e-01, 5.6086e-01, 8.6979e-06, 1.6971e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,578][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([2.0524e-04, 1.1363e-02, 2.8176e-01, 8.3843e-03, 1.7757e-01, 2.0248e-02,
        4.8134e-02, 7.2314e-03, 1.6967e-02, 1.2820e-02, 1.0568e-02, 1.5685e-01,
        9.3667e-03, 5.8383e-02, 6.0733e-02, 1.6049e-02, 1.0337e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,579][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.1545, 0.0450, 0.0981, 0.0034, 0.0288, 0.0686, 0.0296, 0.0078, 0.0346,
        0.0085, 0.0202, 0.0481, 0.0333, 0.0571, 0.2507, 0.0131, 0.0985],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,579][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4140, 0.0209, 0.0813, 0.0063, 0.0234, 0.0144, 0.0687, 0.0021, 0.0239,
        0.0127, 0.0052, 0.0380, 0.0380, 0.1222, 0.0618, 0.0191, 0.0374, 0.0106],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,580][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0423e-04, 1.2278e-01, 4.9268e-01, 7.1571e-03, 2.5094e-02, 1.7167e-02,
        1.8597e-02, 7.6374e-03, 1.5467e-02, 1.6301e-02, 1.6092e-02, 6.3281e-02,
        2.7160e-02, 6.5178e-02, 3.1871e-02, 2.7770e-02, 2.2632e-02, 2.2825e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,582][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0843, 0.0005, 0.0708, 0.0037, 0.1053, 0.0160, 0.0515, 0.0187, 0.0209,
        0.0054, 0.0241, 0.1627, 0.0049, 0.3162, 0.0669, 0.0073, 0.0261, 0.0147],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,583][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1836, 0.1229, 0.0235, 0.0188, 0.0143, 0.0379, 0.0629, 0.0114, 0.0473,
        0.0085, 0.0204, 0.0433, 0.0341, 0.0466, 0.1828, 0.0108, 0.0789, 0.0520],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,585][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1071, 0.0256, 0.0011, 0.0017, 0.0029, 0.0301, 0.0060, 0.0060, 0.0011,
        0.0056, 0.0158, 0.2542, 0.0513, 0.0608, 0.2010, 0.0105, 0.1476, 0.0715],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,586][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.9683e-03, 1.6627e-02, 3.2330e-03, 4.1265e-07, 1.4380e-03, 2.9385e-04,
        4.4024e-04, 1.4012e-07, 1.1262e-05, 1.7784e-06, 2.9873e-06, 1.2087e-01,
        2.0843e-04, 5.9131e-01, 2.2493e-01, 4.1088e-05, 3.7389e-02, 2.3950e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,587][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0106, 0.0193, 0.0935, 0.0019, 0.0232, 0.0174, 0.0117, 0.0090, 0.0173,
        0.0058, 0.0082, 0.0960, 0.0293, 0.3099, 0.2607, 0.0120, 0.0414, 0.0328],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,588][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([8.5317e-01, 4.2055e-02, 3.8864e-02, 1.0935e-03, 2.2695e-03, 3.2006e-03,
        3.0885e-03, 4.2761e-03, 4.5863e-04, 1.5164e-03, 2.6142e-03, 5.9575e-03,
        1.2642e-02, 1.4426e-02, 4.6009e-03, 2.1020e-03, 3.9835e-03, 3.6813e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,590][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1189, 0.3171, 0.1303, 0.0209, 0.0024, 0.0227, 0.0320, 0.0885, 0.0256,
        0.0363, 0.0575, 0.0181, 0.0314, 0.0066, 0.0149, 0.0321, 0.0266, 0.0181],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,591][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.2294e-04, 1.1294e-02, 4.7716e-03, 1.5396e-08, 3.2242e-04, 4.2523e-05,
        8.0164e-05, 1.9952e-08, 4.1441e-07, 6.8031e-07, 4.7459e-07, 1.6941e-01,
        2.7037e-05, 4.9695e-01, 2.7446e-01, 3.3394e-05, 4.2092e-02, 8.2721e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,592][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.6986e-04, 1.2782e-02, 3.1114e-01, 6.7060e-03, 1.7735e-01, 1.2370e-02,
        3.5348e-02, 4.5931e-03, 1.2871e-02, 9.5504e-03, 7.0715e-03, 1.7965e-01,
        7.4411e-03, 5.4251e-02, 4.4760e-02, 1.2999e-02, 9.4711e-02, 1.6233e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,593][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1269, 0.0299, 0.1397, 0.0024, 0.0308, 0.0323, 0.0129, 0.0071, 0.0339,
        0.0060, 0.0067, 0.0756, 0.0289, 0.0970, 0.2472, 0.0114, 0.0967, 0.0146],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,594][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0082, 0.0510, 0.0190, 0.0100, 0.0122, 0.0231, 0.0364, 0.0081, 0.0302,
        0.0132, 0.0081, 0.0260, 0.0862, 0.0399, 0.0253, 0.0185, 0.0410, 0.0133,
        0.5301], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,594][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([7.2190e-05, 5.6641e-02, 2.7282e-01, 6.4594e-03, 2.8477e-02, 2.1779e-02,
        2.6535e-02, 3.6939e-03, 1.7928e-02, 2.5011e-02, 2.2079e-02, 1.0918e-01,
        5.1373e-02, 1.0243e-01, 3.1196e-02, 3.3295e-02, 2.8964e-02, 2.8192e-02,
        1.3386e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,595][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0859, 0.0018, 0.0183, 0.0020, 0.0308, 0.0143, 0.0640, 0.0146, 0.0128,
        0.0071, 0.0140, 0.2046, 0.0035, 0.1703, 0.0612, 0.0128, 0.0667, 0.0240,
        0.1913], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,595][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.1022, 0.0894, 0.0192, 0.0179, 0.0310, 0.0668, 0.0404, 0.0093, 0.0387,
        0.0126, 0.0232, 0.0560, 0.0365, 0.0605, 0.1511, 0.0140, 0.0876, 0.0628,
        0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,596][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([0.1272, 0.0237, 0.0023, 0.0010, 0.0026, 0.0232, 0.0033, 0.0026, 0.0008,
        0.0053, 0.0076, 0.1516, 0.0450, 0.0760, 0.1719, 0.0120, 0.1056, 0.0457,
        0.1929], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,596][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([2.1693e-02, 4.5339e-03, 1.5085e-03, 3.6143e-08, 7.3668e-05, 3.4892e-04,
        1.9202e-05, 1.9657e-08, 3.0169e-07, 2.9837e-07, 1.0158e-06, 2.0892e-02,
        1.9571e-04, 6.9831e-02, 5.5461e-02, 1.7440e-05, 5.2987e-03, 2.6727e-04,
        8.1986e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,597][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0029, 0.0093, 0.0566, 0.0018, 0.0228, 0.0277, 0.0082, 0.0072, 0.0121,
        0.0044, 0.0105, 0.1028, 0.0407, 0.2204, 0.2314, 0.0090, 0.0324, 0.0408,
        0.1590], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,598][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([8.4333e-01, 2.1859e-02, 8.9297e-02, 4.3206e-04, 2.2670e-03, 1.8640e-03,
        1.0777e-03, 1.3977e-03, 2.5528e-04, 8.2781e-04, 1.2705e-03, 5.2506e-03,
        5.0010e-03, 8.6236e-03, 7.4759e-03, 1.0879e-03, 3.9943e-03, 1.9620e-03,
        2.7285e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,599][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0739, 0.1865, 0.0975, 0.0231, 0.0039, 0.0429, 0.0422, 0.0629, 0.0321,
        0.0350, 0.0662, 0.0506, 0.0850, 0.0157, 0.0212, 0.0333, 0.0415, 0.0316,
        0.0549], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,601][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([1.1426e-02, 4.0785e-03, 1.8614e-03, 1.2767e-09, 8.9887e-06, 6.2222e-05,
        6.4164e-06, 1.6262e-09, 1.2194e-08, 3.4535e-08, 1.0278e-07, 1.8475e-02,
        2.9430e-05, 3.4749e-02, 6.0856e-02, 4.3151e-06, 3.5727e-03, 6.4683e-05,
        8.6481e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,602][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([2.0198e-04, 8.6485e-03, 2.4188e-01, 5.3590e-03, 1.2634e-01, 1.2728e-02,
        4.4091e-02, 5.4400e-03, 1.2369e-02, 8.4855e-03, 5.9072e-03, 9.3269e-02,
        6.0736e-03, 4.0606e-02, 3.8804e-02, 1.1206e-02, 7.5400e-02, 1.5049e-02,
        2.4814e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,603][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([0.0631, 0.0279, 0.1297, 0.0076, 0.0399, 0.0696, 0.0254, 0.0095, 0.0364,
        0.0103, 0.0269, 0.0329, 0.0336, 0.0637, 0.1701, 0.0147, 0.0683, 0.0174,
        0.1532], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,604][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0116, 0.1356, 0.0428, 0.0426, 0.0088, 0.0605, 0.0307, 0.0069, 0.0543,
        0.0389, 0.0371, 0.0216, 0.0551, 0.0113, 0.1438, 0.0373, 0.0439, 0.0508,
        0.1162, 0.0504], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,606][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.2323e-04, 9.5021e-02, 3.8299e-01, 9.3962e-03, 2.3037e-02, 1.5320e-02,
        1.9796e-02, 1.1893e-02, 2.0649e-02, 3.1261e-02, 2.4751e-02, 5.7441e-02,
        3.1562e-02, 5.2703e-02, 1.7620e-02, 4.0431e-02, 1.7689e-02, 2.7726e-02,
        5.3911e-02, 6.6482e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,608][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0243, 0.0062, 0.0634, 0.0209, 0.0206, 0.0733, 0.0259, 0.0769, 0.0630,
        0.0464, 0.1340, 0.0159, 0.0055, 0.0189, 0.1610, 0.0403, 0.0624, 0.0597,
        0.0241, 0.0573], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,609][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1031, 0.1098, 0.0256, 0.0140, 0.0283, 0.0457, 0.0479, 0.0132, 0.0405,
        0.0117, 0.0269, 0.0498, 0.0359, 0.0724, 0.1186, 0.0149, 0.0745, 0.0731,
        0.0648, 0.0294], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,611][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0346, 0.0236, 0.0013, 0.0022, 0.0022, 0.0325, 0.0077, 0.0055, 0.0012,
        0.0068, 0.0194, 0.1732, 0.0553, 0.0409, 0.1248, 0.0148, 0.1660, 0.0977,
        0.1590, 0.0313], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,611][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.9270e-04, 3.6985e-03, 4.6150e-03, 7.5793e-08, 1.0180e-03, 1.4544e-04,
        1.1248e-04, 3.3022e-08, 1.8887e-06, 2.4340e-07, 6.6453e-07, 2.8438e-02,
        5.5937e-05, 2.1047e-01, 8.7724e-02, 6.0327e-06, 8.6026e-03, 7.7347e-05,
        6.5411e-01, 3.4206e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,612][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0070, 0.0140, 0.0530, 0.0015, 0.0203, 0.0184, 0.0085, 0.0120, 0.0133,
        0.0083, 0.0086, 0.0658, 0.0344, 0.3360, 0.1606, 0.0152, 0.0324, 0.0409,
        0.1225, 0.0273], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,612][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6181, 0.1037, 0.1156, 0.0016, 0.0059, 0.0053, 0.0081, 0.0139, 0.0020,
        0.0077, 0.0056, 0.0103, 0.0153, 0.0311, 0.0188, 0.0091, 0.0096, 0.0081,
        0.0026, 0.0078], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,613][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0786, 0.3869, 0.1034, 0.0157, 0.0016, 0.0209, 0.0226, 0.1044, 0.0225,
        0.0354, 0.0450, 0.0179, 0.0194, 0.0037, 0.0107, 0.0302, 0.0176, 0.0140,
        0.0155, 0.0339], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,613][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.6758e-04, 2.0804e-03, 5.4568e-03, 1.9101e-09, 9.4742e-05, 1.4961e-05,
        2.2668e-05, 3.3731e-09, 8.8296e-08, 4.4788e-08, 7.7771e-08, 2.1973e-02,
        4.6862e-06, 7.9271e-02, 1.0950e-01, 2.0707e-06, 9.3801e-03, 1.9050e-05,
        7.7179e-01, 2.4681e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,614][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.9470e-04, 8.1494e-03, 2.2953e-01, 4.2103e-03, 1.0903e-01, 8.6563e-03,
        3.1694e-02, 3.4882e-03, 1.1175e-02, 6.5001e-03, 4.8091e-03, 1.0545e-01,
        4.8521e-03, 3.9710e-02, 3.9989e-02, 8.5430e-03, 6.4220e-02, 1.2527e-02,
        2.9092e-01, 1.6347e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,614][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.5096, 0.0243, 0.0736, 0.0014, 0.0091, 0.0118, 0.0139, 0.0044, 0.0101,
        0.0028, 0.0041, 0.0326, 0.0080, 0.0317, 0.1455, 0.0042, 0.0278, 0.0048,
        0.0751, 0.0053], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,664][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:48,665][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,666][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,667][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,668][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,669][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,670][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,670][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,671][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,672][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,672][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,673][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,674][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:48,674][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2795, 0.7205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,675][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.1228e-04, 9.9959e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,677][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0919, 0.9081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,679][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6890, 0.3110], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,681][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8757, 0.1243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,683][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2909, 0.7091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,684][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1867, 0.8133], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,686][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9710, 0.0290], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,687][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0490, 0.9510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,687][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0637, 0.9363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,688][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3276, 0.6724], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,689][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0789, 0.9211], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:48,689][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0432, 0.7149, 0.2419], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,690][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([3.4964e-05, 2.6860e-01, 7.3136e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,692][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([0.0149, 0.5830, 0.4021], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,694][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0604, 0.8199, 0.1196], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,695][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.5275, 0.4558, 0.0168], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,697][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([0.0307, 0.9500, 0.0193], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,699][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0405, 0.2625, 0.6970], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,701][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.7273, 0.0401, 0.2326], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,702][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([0.0072, 0.6490, 0.3438], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,704][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([0.0089, 0.9790, 0.0121], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,704][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.0041, 0.0149, 0.9810], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,705][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0081, 0.5381, 0.4538], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:48,706][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0524, 0.6967, 0.1980, 0.0529], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,706][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.1378e-04, 2.8076e-01, 6.9209e-01, 2.6931e-02], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,707][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1005, 0.3933, 0.2192, 0.2870], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,708][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4151, 0.4533, 0.0688, 0.0628], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,710][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5441, 0.4331, 0.0104, 0.0124], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,711][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.6725e-04, 9.6364e-01, 3.5981e-02, 6.9876e-06], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,713][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0792, 0.2949, 0.5893, 0.0365], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,714][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9264, 0.0253, 0.0470, 0.0013], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,716][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0853, 0.6976, 0.1819, 0.0352], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,718][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.6911e-05, 9.8902e-01, 1.0950e-02, 2.1639e-07], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,719][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.8713e-03, 8.3699e-03, 9.8757e-01, 1.8802e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,720][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1739, 0.2307, 0.5690, 0.0264], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:48,721][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0499, 0.7461, 0.1221, 0.0399, 0.0421], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,722][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([6.9627e-05, 1.0934e-01, 8.6041e-01, 1.5346e-02, 1.4838e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,722][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0294, 0.3501, 0.1964, 0.3379, 0.0861], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,723][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.2777, 0.4818, 0.0961, 0.0635, 0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,724][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.5583, 0.3781, 0.0193, 0.0080, 0.0362], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,725][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([1.4148e-02, 8.2439e-01, 1.5438e-01, 8.3006e-07, 7.0719e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,727][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0295, 0.1678, 0.6082, 0.0337, 0.1609], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,728][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([9.7164e-01, 7.6508e-03, 1.8355e-02, 5.2544e-04, 1.8340e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,730][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0659, 0.5768, 0.3055, 0.0436, 0.0083], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,731][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([3.3418e-03, 8.5136e-01, 1.4370e-01, 3.2063e-08, 1.6003e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,732][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([4.6969e-03, 6.4867e-03, 9.8853e-01, 1.7956e-04, 1.0697e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,734][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0623, 0.2196, 0.4555, 0.0330, 0.2297], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:48,735][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1375, 0.4364, 0.1595, 0.0301, 0.0358, 0.2007], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,737][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([3.1007e-04, 3.0538e-01, 5.8173e-01, 2.3684e-02, 4.7674e-02, 4.1227e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,738][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1005, 0.2915, 0.1057, 0.2215, 0.0598, 0.2210], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,739][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.4675, 0.2690, 0.0338, 0.0544, 0.0446, 0.1308], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,740][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.6991, 0.1474, 0.0055, 0.0051, 0.0272, 0.1157], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,740][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([1.7117e-02, 9.6730e-01, 4.7806e-03, 2.2031e-05, 3.8991e-03, 6.8786e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,741][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0983, 0.1081, 0.3305, 0.0242, 0.2221, 0.2167], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,742][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([9.3665e-01, 1.7032e-02, 3.9737e-02, 8.5381e-04, 2.3507e-03, 3.3764e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,744][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1793, 0.5191, 0.2194, 0.0245, 0.0051, 0.0526], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,745][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([6.4523e-03, 9.9134e-01, 1.1956e-03, 6.4956e-07, 2.5939e-04, 7.5640e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,746][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([9.3230e-03, 7.0891e-03, 9.8312e-01, 2.0642e-04, 1.5529e-04, 1.0547e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,748][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.1255, 0.1166, 0.4117, 0.0296, 0.1709, 0.1457], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:48,749][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0355, 0.4036, 0.1693, 0.0167, 0.0388, 0.2163, 0.1198],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,751][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([1.3365e-04, 4.0089e-01, 4.3356e-01, 2.1573e-02, 4.0343e-02, 7.7502e-02,
        2.6003e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,753][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0456, 0.2109, 0.1643, 0.1451, 0.0619, 0.3018, 0.0704],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,754][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.1314, 0.4830, 0.0423, 0.0337, 0.0757, 0.1624, 0.0715],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,756][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.3310, 0.3413, 0.0091, 0.0077, 0.0227, 0.2464, 0.0419],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,756][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([5.2770e-04, 9.9510e-01, 2.3165e-04, 1.1611e-06, 6.1600e-04, 8.6578e-04,
        2.6529e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,757][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0372, 0.1321, 0.2239, 0.0156, 0.1088, 0.4118, 0.0705],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,758][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([8.7243e-01, 4.6114e-02, 6.7765e-02, 8.0896e-04, 4.1239e-03, 5.3396e-03,
        3.4152e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,759][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0534, 0.6984, 0.1232, 0.0252, 0.0053, 0.0540, 0.0406],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,759][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([5.9009e-05, 9.9946e-01, 2.9369e-05, 9.6655e-09, 1.7801e-05, 3.6355e-05,
        3.9957e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,760][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([2.9023e-03, 1.0595e-02, 9.8425e-01, 2.6755e-04, 3.3200e-04, 3.3017e-04,
        1.3219e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,762][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.1103, 0.2438, 0.2302, 0.0218, 0.0725, 0.2613, 0.0602],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:48,764][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0145, 0.3342, 0.2394, 0.0149, 0.0537, 0.1277, 0.2024, 0.0133],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,765][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([5.9916e-05, 3.4196e-01, 5.6977e-01, 1.3913e-02, 2.6914e-02, 1.7769e-02,
        2.2784e-02, 6.8289e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,766][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0287, 0.2212, 0.1436, 0.1161, 0.0771, 0.1562, 0.0515, 0.2056],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,768][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.1360, 0.5277, 0.0224, 0.0393, 0.0591, 0.0931, 0.1064, 0.0160],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,770][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.1759, 0.4256, 0.0225, 0.0152, 0.0523, 0.2017, 0.0795, 0.0274],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,771][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([3.3494e-05, 9.6510e-01, 8.1903e-04, 7.6300e-06, 1.4922e-02, 4.4042e-04,
        1.8679e-02, 2.9719e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,773][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0162, 0.1426, 0.2797, 0.0169, 0.2108, 0.2237, 0.0690, 0.0412],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,774][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.6413, 0.1147, 0.1886, 0.0023, 0.0147, 0.0140, 0.0139, 0.0105],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,774][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0689, 0.5714, 0.1472, 0.0237, 0.0023, 0.0370, 0.0294, 0.1200],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,775][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([1.8454e-06, 9.9655e-01, 1.5309e-04, 1.9195e-07, 7.5365e-04, 1.9746e-05,
        2.5233e-03, 1.7628e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,776][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([1.0500e-03, 8.7241e-03, 9.8786e-01, 2.3548e-04, 2.5914e-04, 1.8999e-04,
        1.4999e-03, 1.8117e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,777][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0480, 0.2920, 0.4094, 0.0107, 0.0948, 0.0790, 0.0359, 0.0302],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:48,779][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0160, 0.3968, 0.1491, 0.0201, 0.0578, 0.1684, 0.1114, 0.0183, 0.0620],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,780][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([2.6256e-04, 3.2404e-01, 4.6678e-01, 1.6950e-02, 5.2578e-02, 5.1329e-02,
        3.8312e-02, 1.4776e-02, 3.4976e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,782][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0348, 0.1958, 0.1062, 0.0917, 0.0837, 0.1467, 0.0642, 0.2105, 0.0665],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,783][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.1268, 0.4187, 0.0282, 0.0408, 0.0428, 0.1088, 0.1020, 0.0260, 0.1060],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,786][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.1179, 0.3692, 0.0111, 0.0149, 0.0279, 0.3445, 0.0610, 0.0400, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,787][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([2.4106e-04, 9.4113e-01, 1.4202e-02, 1.6620e-06, 3.1684e-02, 2.1861e-03,
        1.0412e-02, 3.2092e-07, 1.4036e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,789][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0216, 0.1228, 0.2771, 0.0094, 0.1940, 0.1956, 0.0494, 0.0509, 0.0792],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,790][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.8239, 0.0685, 0.0747, 0.0014, 0.0090, 0.0081, 0.0049, 0.0085, 0.0010],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,791][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1092, 0.3809, 0.1963, 0.0211, 0.0078, 0.0526, 0.0566, 0.1166, 0.0589],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,792][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([3.5675e-05, 9.7686e-01, 1.4076e-02, 3.3029e-08, 5.5160e-03, 1.7377e-04,
        3.3336e-03, 2.7083e-08, 7.6933e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,792][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([2.9466e-03, 1.1140e-02, 9.8326e-01, 2.5261e-04, 2.7928e-04, 2.1741e-04,
        1.6234e-03, 1.8171e-04, 1.0419e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,793][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.2073, 0.1279, 0.2768, 0.0070, 0.0919, 0.1365, 0.0494, 0.0254, 0.0777],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:48,794][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0237, 0.4390, 0.2378, 0.0089, 0.0269, 0.0685, 0.1367, 0.0074, 0.0220,
        0.0289], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,796][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.4814e-04, 2.2456e-01, 6.2241e-01, 1.0570e-02, 3.4815e-02, 1.9029e-02,
        2.1062e-02, 8.9921e-03, 2.5690e-02, 3.2726e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,798][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0428, 0.1738, 0.1067, 0.0607, 0.0700, 0.0830, 0.0422, 0.1966, 0.0581,
        0.1661], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,799][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1732, 0.3496, 0.0439, 0.0317, 0.0549, 0.0939, 0.1212, 0.0170, 0.0909,
        0.0237], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,801][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1925, 0.3059, 0.0090, 0.0131, 0.0232, 0.2722, 0.0664, 0.0298, 0.0152,
        0.0725], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,803][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.7193e-03, 8.0514e-01, 6.5738e-02, 2.8489e-06, 1.1460e-01, 2.6012e-03,
        9.9240e-03, 7.0305e-07, 2.4777e-04, 2.8456e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,805][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0340, 0.1317, 0.3119, 0.0086, 0.1555, 0.1238, 0.0599, 0.0434, 0.0796,
        0.0516], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,806][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.8122, 0.0700, 0.0733, 0.0015, 0.0077, 0.0084, 0.0078, 0.0112, 0.0014,
        0.0065], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,808][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0684, 0.5751, 0.1296, 0.0154, 0.0016, 0.0247, 0.0235, 0.1099, 0.0222,
        0.0296], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,808][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.4823e-04, 9.1451e-01, 6.2643e-02, 1.2666e-07, 1.7909e-02, 3.1008e-04,
        4.0422e-03, 1.2341e-07, 2.6055e-05, 1.0913e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,809][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.5663e-03, 8.3573e-03, 9.8881e-01, 8.7812e-05, 9.4399e-05, 6.2863e-05,
        8.2156e-04, 1.1087e-04, 5.7063e-05, 3.2028e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,810][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.6856, 0.0622, 0.1529, 0.0019, 0.0279, 0.0180, 0.0215, 0.0073, 0.0177,
        0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:48,811][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0381, 0.4523, 0.1467, 0.0111, 0.0413, 0.0892, 0.1091, 0.0098, 0.0334,
        0.0371, 0.0318], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,812][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.6133e-04, 2.8500e-01, 5.1241e-01, 1.2087e-02, 2.5229e-02, 2.6147e-02,
        2.0743e-02, 1.0914e-02, 2.4495e-02, 3.8222e-02, 4.4587e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,814][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0477, 0.0993, 0.0719, 0.0535, 0.0449, 0.0880, 0.0491, 0.1697, 0.0722,
        0.2014, 0.1023], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,815][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2599, 0.2989, 0.0294, 0.0269, 0.0305, 0.0851, 0.0897, 0.0192, 0.0914,
        0.0255, 0.0435], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,817][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3804, 0.1884, 0.0082, 0.0093, 0.0309, 0.1681, 0.0504, 0.0258, 0.0094,
        0.0426, 0.0863], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,818][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.0733e-03, 5.1044e-01, 1.6658e-01, 1.2770e-05, 2.9997e-01, 3.9127e-03,
        1.4680e-02, 1.8962e-06, 1.0700e-03, 1.1533e-04, 1.4288e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,821][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0425, 0.1227, 0.2464, 0.0097, 0.1285, 0.1284, 0.0520, 0.0505, 0.0915,
        0.0517, 0.0761], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,822][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.8655, 0.0374, 0.0616, 0.0013, 0.0050, 0.0060, 0.0070, 0.0080, 0.0011,
        0.0028, 0.0043], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,824][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0310, 0.5389, 0.1084, 0.0145, 0.0021, 0.0288, 0.0384, 0.1254, 0.0286,
        0.0400, 0.0439], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,825][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.8887e-04, 7.1663e-01, 1.8427e-01, 8.1374e-07, 9.1347e-02, 5.3012e-04,
        6.4842e-03, 5.6109e-07, 1.2368e-04, 7.5702e-05, 4.9153e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,826][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.1319e-03, 7.3762e-03, 9.8696e-01, 1.0444e-04, 1.0051e-04, 7.0303e-05,
        1.0533e-03, 9.3102e-05, 5.0660e-05, 3.2132e-05, 3.1186e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,826][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1572, 0.0682, 0.2483, 0.0084, 0.1004, 0.1184, 0.0652, 0.0325, 0.1328,
        0.0291, 0.0395], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:48,827][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.0441, 0.2042, 0.0847, 0.0056, 0.0073, 0.0807, 0.0280, 0.0061, 0.0148,
        0.0193, 0.0184, 0.4867], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,828][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([2.0708e-04, 2.9429e-01, 4.7911e-01, 1.3302e-02, 1.9186e-02, 3.2999e-02,
        1.7382e-02, 5.4207e-03, 2.0045e-02, 3.1348e-02, 3.5761e-02, 5.0946e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,830][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.0481, 0.1534, 0.0842, 0.0709, 0.0359, 0.0988, 0.0143, 0.1243, 0.0307,
        0.1403, 0.0885, 0.1105], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,832][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([0.1631, 0.4374, 0.0500, 0.0325, 0.0322, 0.0899, 0.0335, 0.0089, 0.0256,
        0.0206, 0.0293, 0.0770], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,834][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([0.2820, 0.0718, 0.0019, 0.0017, 0.0026, 0.0807, 0.0032, 0.0036, 0.0008,
        0.0074, 0.0218, 0.5225], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,835][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([4.5337e-02, 5.7089e-02, 3.3471e-02, 2.5094e-07, 3.0721e-03, 2.5689e-03,
        2.2972e-04, 3.2458e-08, 4.2169e-06, 3.3080e-06, 6.8467e-06, 8.5822e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,837][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0572, 0.0853, 0.3650, 0.0052, 0.0548, 0.0882, 0.0327, 0.0230, 0.0289,
        0.0129, 0.0251, 0.2218], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,838][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([9.6175e-01, 6.8667e-03, 2.4405e-02, 1.2708e-04, 7.7839e-04, 8.9189e-04,
        4.5993e-04, 3.9999e-04, 4.1558e-05, 1.5808e-04, 3.9730e-04, 3.7293e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,840][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.1648, 0.5167, 0.1000, 0.0121, 0.0019, 0.0249, 0.0175, 0.0574, 0.0219,
        0.0212, 0.0465, 0.0151], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,841][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([1.8561e-02, 1.9548e-02, 1.9653e-02, 2.5952e-09, 1.5274e-04, 1.8875e-04,
        3.1033e-05, 1.4560e-09, 7.1572e-08, 1.8021e-07, 3.9751e-07, 9.4187e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,842][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([5.5031e-03, 5.2801e-03, 9.8842e-01, 6.0719e-05, 8.8358e-05, 7.0874e-05,
        4.4023e-04, 4.8788e-05, 2.7789e-05, 1.8461e-05, 2.2570e-05, 1.8622e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,843][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.3084, 0.1479, 0.1954, 0.0047, 0.0469, 0.0862, 0.0233, 0.0096, 0.0515,
        0.0099, 0.0218, 0.0944], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:48,844][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0216, 0.2631, 0.1214, 0.0053, 0.0098, 0.0573, 0.0558, 0.0060, 0.0232,
        0.0160, 0.0154, 0.3416, 0.0634], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,845][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.6842e-04, 2.0437e-01, 5.8324e-01, 9.6311e-03, 2.0165e-02, 2.2787e-02,
        1.7011e-02, 8.3412e-03, 1.8362e-02, 2.1864e-02, 1.9700e-02, 4.0519e-02,
        3.3833e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,846][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0524, 0.1108, 0.1052, 0.0462, 0.0393, 0.0733, 0.0292, 0.0958, 0.0397,
        0.0955, 0.0696, 0.0796, 0.1634], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,848][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.3787, 0.2697, 0.0213, 0.0167, 0.0147, 0.0573, 0.0685, 0.0093, 0.0531,
        0.0099, 0.0213, 0.0513, 0.0282], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,850][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1582, 0.0961, 0.0025, 0.0034, 0.0040, 0.0517, 0.0119, 0.0105, 0.0020,
        0.0124, 0.0388, 0.5024, 0.1059], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,851][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([2.1662e-02, 1.5332e-01, 1.3780e-03, 2.1819e-06, 1.6915e-03, 3.9981e-04,
        1.0332e-03, 7.8917e-07, 5.6077e-05, 1.4087e-05, 4.5174e-05, 8.1908e-01,
        1.3229e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,853][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0312, 0.0630, 0.2079, 0.0055, 0.0648, 0.0784, 0.0318, 0.0268, 0.0485,
        0.0250, 0.0293, 0.2696, 0.1183], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,854][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([9.2482e-01, 2.1835e-02, 3.3518e-02, 4.8716e-04, 1.3916e-03, 2.4904e-03,
        2.1711e-03, 2.6051e-03, 4.2505e-04, 1.1074e-03, 1.3545e-03, 2.0213e-03,
        5.7700e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,856][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1613, 0.4423, 0.1392, 0.0148, 0.0013, 0.0202, 0.0246, 0.0972, 0.0192,
        0.0182, 0.0343, 0.0075, 0.0199], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,857][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.7416e-03, 8.0480e-02, 5.6044e-04, 7.2422e-08, 1.3970e-04, 3.9391e-05,
        1.9844e-04, 1.3865e-07, 3.6558e-06, 3.9185e-06, 1.2744e-05, 9.1661e-01,
        2.1288e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,858][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.6378e-03, 2.8382e-03, 9.9406e-01, 2.7927e-05, 3.2343e-05, 2.3992e-05,
        3.1699e-04, 2.7142e-05, 1.6778e-05, 8.0782e-06, 7.2660e-06, 5.4551e-06,
        5.1242e-07], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,859][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0878, 0.0811, 0.3024, 0.0067, 0.0612, 0.0863, 0.0421, 0.0212, 0.0792,
        0.0242, 0.0295, 0.1124, 0.0659], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:48,860][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0233, 0.2102, 0.0899, 0.0047, 0.0125, 0.0739, 0.0412, 0.0036, 0.0137,
        0.0148, 0.0090, 0.3415, 0.0728, 0.0889], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,861][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([1.0454e-04, 1.2119e-01, 5.6744e-01, 1.3284e-02, 2.1613e-02, 3.6862e-02,
        1.6996e-02, 5.1168e-03, 1.7980e-02, 2.3872e-02, 2.5773e-02, 5.3289e-02,
        4.9792e-02, 4.6683e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,862][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([0.0107, 0.0912, 0.0872, 0.0631, 0.0314, 0.0740, 0.0108, 0.0478, 0.0163,
        0.0927, 0.0445, 0.0971, 0.2906, 0.0425], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,863][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([0.1953, 0.3359, 0.0381, 0.0324, 0.0233, 0.0766, 0.0528, 0.0072, 0.0530,
        0.0091, 0.0174, 0.0410, 0.0560, 0.0619], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,865][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0686, 0.0525, 0.0029, 0.0013, 0.0037, 0.0460, 0.0053, 0.0036, 0.0008,
        0.0058, 0.0108, 0.5425, 0.1248, 0.1314], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,866][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([1.7722e-02, 8.7616e-03, 3.2298e-02, 3.3539e-08, 6.6595e-04, 4.3596e-04,
        5.7396e-05, 6.5709e-09, 6.9308e-07, 3.0642e-07, 4.3511e-07, 1.4893e-01,
        1.4718e-04, 7.9098e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,868][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0062, 0.0356, 0.1228, 0.0052, 0.0390, 0.0783, 0.0161, 0.0096, 0.0185,
        0.0101, 0.0170, 0.1486, 0.0923, 0.4007], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,869][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([8.7509e-01, 1.6254e-02, 6.4456e-02, 6.3695e-04, 2.8470e-03, 3.2648e-03,
        2.6319e-03, 1.7595e-03, 4.6094e-04, 1.1865e-03, 1.5135e-03, 5.1723e-03,
        6.2019e-03, 1.8528e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,871][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([0.0402, 0.3934, 0.1191, 0.0341, 0.0028, 0.0341, 0.0219, 0.0686, 0.0279,
        0.0435, 0.0967, 0.0264, 0.0842, 0.0072], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,872][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([8.8453e-03, 1.3896e-02, 7.0122e-02, 1.8707e-09, 1.8528e-04, 1.9910e-04,
        1.5297e-05, 5.7501e-10, 4.1876e-08, 9.1090e-08, 8.3380e-08, 2.3687e-01,
        2.8083e-05, 6.6984e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,874][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([4.4734e-03, 4.8421e-03, 9.8979e-01, 1.1630e-04, 1.1763e-04, 9.6940e-05,
        4.1947e-04, 4.6319e-05, 2.6006e-05, 1.7572e-05, 2.7156e-05, 1.9057e-05,
        3.4110e-06, 6.3349e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,876][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0177, 0.0814, 0.2130, 0.0144, 0.0552, 0.1389, 0.0271, 0.0133, 0.0538,
        0.0225, 0.0570, 0.0913, 0.1320, 0.0826], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:48,876][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0133, 0.0793, 0.1091, 0.0025, 0.0096, 0.0477, 0.0214, 0.0036, 0.0108,
        0.0118, 0.0109, 0.3093, 0.0565, 0.0790, 0.2352], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,877][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([1.0629e-04, 1.2697e-01, 5.5986e-01, 6.1754e-03, 2.3124e-02, 1.5978e-02,
        2.0299e-02, 5.8790e-03, 1.6747e-02, 3.2686e-02, 1.5022e-02, 5.6900e-02,
        2.8735e-02, 7.2696e-02, 1.8826e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,878][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0190, 0.0735, 0.0707, 0.0370, 0.0217, 0.0558, 0.0123, 0.0584, 0.0261,
        0.1050, 0.0650, 0.1298, 0.1990, 0.0535, 0.0732], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,879][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.1176, 0.3805, 0.0205, 0.0271, 0.0185, 0.0703, 0.0268, 0.0083, 0.0307,
        0.0171, 0.0230, 0.0510, 0.0549, 0.0378, 0.1157], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,880][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.1729, 0.0449, 0.0016, 0.0007, 0.0028, 0.0290, 0.0033, 0.0036, 0.0006,
        0.0071, 0.0100, 0.3590, 0.0699, 0.1164, 0.1780], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,882][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([1.7911e-02, 1.5914e-02, 1.7653e-03, 3.8392e-08, 1.7061e-04, 5.4464e-04,
        5.4642e-05, 1.8674e-08, 4.5220e-07, 3.5289e-07, 1.0702e-06, 1.0427e-01,
        4.3760e-04, 5.6604e-01, 2.9289e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,884][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0046, 0.0137, 0.0814, 0.0016, 0.0188, 0.0355, 0.0069, 0.0074, 0.0149,
        0.0063, 0.0090, 0.1313, 0.0328, 0.3141, 0.3216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,885][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([8.7700e-01, 2.3532e-02, 6.6489e-02, 3.2249e-04, 1.7874e-03, 2.7722e-03,
        1.4215e-03, 1.4463e-03, 3.2965e-04, 6.9436e-04, 1.1002e-03, 4.6927e-03,
        4.0521e-03, 8.7881e-03, 5.5687e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,886][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0867, 0.3797, 0.1140, 0.0176, 0.0022, 0.0259, 0.0208, 0.0794, 0.0309,
        0.0443, 0.0755, 0.0225, 0.0762, 0.0109, 0.0134], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,888][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([8.9369e-03, 2.4766e-02, 2.0270e-03, 7.1795e-10, 1.3855e-05, 9.5566e-05,
        1.2226e-05, 1.2660e-09, 2.7802e-08, 4.9932e-08, 1.2189e-07, 1.5175e-01,
        8.8952e-05, 3.3129e-01, 4.8102e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,889][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([2.3478e-03, 2.6060e-03, 9.9416e-01, 4.0646e-05, 8.2108e-05, 5.3355e-05,
        3.9810e-04, 4.7128e-05, 2.7504e-05, 1.5150e-05, 1.6229e-05, 2.1628e-05,
        1.7971e-06, 7.4956e-06, 1.7992e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,891][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.1218, 0.1036, 0.2350, 0.0059, 0.0313, 0.0576, 0.0252, 0.0097, 0.0329,
        0.0144, 0.0141, 0.0625, 0.0372, 0.0660, 0.1829], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:48,893][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0183, 0.1281, 0.1748, 0.0026, 0.0106, 0.0290, 0.0434, 0.0036, 0.0073,
        0.0099, 0.0079, 0.2677, 0.0270, 0.0602, 0.1939, 0.0156],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,893][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.5779e-04, 1.3572e-01, 4.6079e-01, 1.0531e-02, 2.9436e-02, 1.8447e-02,
        1.9413e-02, 1.0898e-02, 2.1360e-02, 3.8325e-02, 2.5751e-02, 6.0868e-02,
        3.5080e-02, 6.2211e-02, 2.0362e-02, 5.0544e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,894][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0275, 0.0660, 0.1234, 0.0293, 0.0464, 0.0387, 0.0223, 0.1075, 0.0260,
        0.0977, 0.0558, 0.0483, 0.0816, 0.0618, 0.0441, 0.1233],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,895][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1278, 0.1650, 0.0335, 0.0173, 0.0389, 0.0572, 0.0618, 0.0134, 0.0547,
        0.0159, 0.0289, 0.0595, 0.0444, 0.0996, 0.1610, 0.0210],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,896][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0437, 0.0420, 0.0022, 0.0027, 0.0037, 0.0496, 0.0111, 0.0069, 0.0018,
        0.0109, 0.0231, 0.3366, 0.0818, 0.0731, 0.2843, 0.0266],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,897][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.2412e-04, 2.6415e-03, 2.9250e-03, 2.7735e-08, 1.2458e-03, 4.1159e-05,
        3.3671e-05, 4.6785e-09, 1.1359e-06, 1.4544e-07, 3.4851e-07, 7.9507e-02,
        2.1282e-05, 7.3421e-01, 1.7924e-01, 6.7249e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,899][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0054, 0.0147, 0.0465, 0.0015, 0.0219, 0.0229, 0.0080, 0.0109, 0.0127,
        0.0093, 0.0109, 0.0964, 0.0475, 0.4464, 0.2272, 0.0178],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,901][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.7493, 0.0745, 0.0521, 0.0014, 0.0060, 0.0057, 0.0065, 0.0095, 0.0016,
        0.0064, 0.0045, 0.0097, 0.0140, 0.0371, 0.0139, 0.0079],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,902][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0652, 0.4441, 0.1059, 0.0186, 0.0019, 0.0235, 0.0254, 0.1048, 0.0231,
        0.0401, 0.0505, 0.0195, 0.0253, 0.0040, 0.0123, 0.0358],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,904][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.6482e-05, 1.9296e-03, 3.6495e-03, 7.0362e-10, 1.6791e-04, 3.7624e-06,
        8.2679e-06, 4.9850e-10, 6.3868e-08, 3.2384e-08, 4.4958e-08, 1.0696e-01,
        1.7580e-06, 5.5622e-01, 3.3098e-01, 3.2396e-06], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,905][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.7202e-03, 4.2478e-03, 9.9286e-01, 5.7377e-05, 6.2579e-05, 5.4196e-05,
        5.5109e-04, 7.7721e-05, 4.5537e-05, 2.6556e-05, 1.7687e-05, 1.8258e-05,
        2.3000e-06, 4.1493e-06, 1.9858e-04, 5.8724e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,907][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3988, 0.0319, 0.1024, 0.0014, 0.0128, 0.0181, 0.0167, 0.0057, 0.0155,
        0.0048, 0.0048, 0.0528, 0.0136, 0.0543, 0.2583, 0.0080],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:48,909][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0225, 0.0649, 0.0954, 0.0015, 0.0093, 0.0272, 0.0209, 0.0017, 0.0057,
        0.0065, 0.0073, 0.2404, 0.0427, 0.0769, 0.2397, 0.0126, 0.1248],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,910][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([4.0182e-04, 1.4329e-01, 5.1059e-01, 9.0305e-03, 1.6212e-02, 2.6062e-02,
        2.0668e-02, 6.2129e-03, 1.2394e-02, 2.3125e-02, 2.6022e-02, 5.2835e-02,
        3.9046e-02, 3.9745e-02, 2.4364e-02, 3.5206e-02, 1.4797e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,911][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0452, 0.0429, 0.0547, 0.0311, 0.0180, 0.0527, 0.0108, 0.0697, 0.0205,
        0.0902, 0.0497, 0.0596, 0.1390, 0.0379, 0.0548, 0.1423, 0.0808],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,911][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.1660, 0.1520, 0.0140, 0.0141, 0.0221, 0.0524, 0.0189, 0.0069, 0.0309,
        0.0135, 0.0285, 0.0538, 0.0539, 0.0841, 0.1680, 0.0201, 0.1008],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,912][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1136, 0.0196, 0.0015, 0.0008, 0.0023, 0.0402, 0.0032, 0.0027, 0.0006,
        0.0049, 0.0115, 0.2208, 0.0889, 0.1176, 0.2309, 0.0157, 0.1249],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,913][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.2396e-03, 1.1357e-02, 3.9350e-03, 2.3756e-08, 4.0739e-04, 3.6731e-04,
        7.2961e-05, 9.2998e-09, 4.7187e-07, 2.0335e-07, 4.0286e-07, 1.1462e-01,
        1.1150e-04, 4.5961e-01, 3.8339e-01, 1.1094e-05, 2.2881e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,915][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0097, 0.0139, 0.1050, 0.0012, 0.0178, 0.0299, 0.0105, 0.0076, 0.0157,
        0.0043, 0.0102, 0.0911, 0.0394, 0.2627, 0.3323, 0.0084, 0.0403],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,917][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([8.8073e-01, 1.3470e-02, 5.3891e-02, 2.4404e-04, 2.8533e-03, 1.8318e-03,
        1.6147e-03, 1.0531e-03, 2.1080e-04, 5.3444e-04, 1.0620e-03, 7.0422e-03,
        4.6738e-03, 1.6635e-02, 7.4451e-03, 9.1462e-04, 5.7936e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,919][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.1503, 0.2792, 0.0905, 0.0119, 0.0023, 0.0206, 0.0214, 0.0743, 0.0229,
        0.0406, 0.0866, 0.0330, 0.0722, 0.0109, 0.0109, 0.0503, 0.0222],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,920][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([3.1374e-04, 5.6067e-03, 9.4785e-03, 7.3984e-10, 6.7595e-05, 6.3573e-05,
        3.3516e-05, 7.9173e-10, 2.7613e-08, 6.5225e-08, 4.1555e-08, 1.3764e-01,
        1.6391e-05, 2.6894e-01, 5.6086e-01, 8.6979e-06, 1.6971e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,922][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([5.9993e-03, 2.4562e-03, 9.9032e-01, 4.5195e-05, 6.9845e-05, 5.9924e-05,
        5.6214e-04, 5.8878e-05, 3.2594e-05, 1.4784e-05, 2.3448e-05, 2.2992e-05,
        2.2308e-06, 5.4267e-06, 1.6951e-04, 3.1217e-05, 1.2256e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,924][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1545, 0.0450, 0.0981, 0.0034, 0.0288, 0.0686, 0.0296, 0.0078, 0.0346,
        0.0085, 0.0202, 0.0481, 0.0333, 0.0571, 0.2507, 0.0131, 0.0985],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:48,926][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0164, 0.1196, 0.0809, 0.0035, 0.0091, 0.0273, 0.0250, 0.0036, 0.0094,
        0.0086, 0.0100, 0.2138, 0.0386, 0.0704, 0.2011, 0.0147, 0.0909, 0.0572],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,927][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0423e-04, 1.2278e-01, 4.9268e-01, 7.1571e-03, 2.5094e-02, 1.7167e-02,
        1.8597e-02, 7.6374e-03, 1.5467e-02, 1.6301e-02, 1.6092e-02, 6.3281e-02,
        2.7160e-02, 6.5178e-02, 3.1871e-02, 2.7770e-02, 2.2632e-02, 2.2825e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,927][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0416, 0.0730, 0.0672, 0.0368, 0.0309, 0.0321, 0.0216, 0.0895, 0.0249,
        0.0707, 0.0409, 0.0410, 0.0875, 0.0405, 0.0550, 0.0982, 0.1010, 0.0479],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,928][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1836, 0.1229, 0.0235, 0.0188, 0.0143, 0.0379, 0.0629, 0.0114, 0.0473,
        0.0085, 0.0204, 0.0433, 0.0341, 0.0466, 0.1828, 0.0108, 0.0789, 0.0520],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,929][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1071, 0.0256, 0.0011, 0.0017, 0.0029, 0.0301, 0.0060, 0.0060, 0.0011,
        0.0056, 0.0158, 0.2542, 0.0513, 0.0608, 0.2010, 0.0105, 0.1476, 0.0715],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,930][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.9683e-03, 1.6627e-02, 3.2330e-03, 4.1265e-07, 1.4380e-03, 2.9385e-04,
        4.4024e-04, 1.4012e-07, 1.1262e-05, 1.7784e-06, 2.9873e-06, 1.2087e-01,
        2.0843e-04, 5.9131e-01, 2.2493e-01, 4.1088e-05, 3.7389e-02, 2.3950e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,932][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0106, 0.0193, 0.0935, 0.0019, 0.0232, 0.0174, 0.0117, 0.0090, 0.0173,
        0.0058, 0.0082, 0.0960, 0.0293, 0.3099, 0.2607, 0.0120, 0.0414, 0.0328],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,934][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([8.7691e-01, 2.8298e-02, 3.0710e-02, 1.0091e-03, 2.2963e-03, 3.4113e-03,
        3.4248e-03, 3.4588e-03, 5.1902e-04, 1.3509e-03, 2.5432e-03, 6.0764e-03,
        9.4903e-03, 1.5124e-02, 5.2781e-03, 1.8122e-03, 4.5779e-03, 3.7084e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,936][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1189, 0.3171, 0.1303, 0.0209, 0.0024, 0.0227, 0.0320, 0.0885, 0.0256,
        0.0363, 0.0575, 0.0181, 0.0314, 0.0066, 0.0149, 0.0321, 0.0266, 0.0181],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,937][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.2294e-04, 1.1294e-02, 4.7716e-03, 1.5396e-08, 3.2242e-04, 4.2523e-05,
        8.0164e-05, 1.9952e-08, 4.1441e-07, 6.8031e-07, 4.7459e-07, 1.6941e-01,
        2.7037e-05, 4.9695e-01, 2.7446e-01, 3.3394e-05, 4.2092e-02, 8.2721e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,938][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.6375e-03, 3.4558e-03, 9.9050e-01, 5.6871e-05, 6.4497e-05, 3.9151e-05,
        6.2266e-04, 6.5820e-05, 3.8420e-05, 1.3252e-05, 1.8095e-05, 1.9551e-05,
        1.8084e-06, 3.8714e-06, 1.7538e-04, 3.1353e-05, 2.2782e-04, 3.0801e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,941][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1269, 0.0299, 0.1397, 0.0024, 0.0308, 0.0323, 0.0129, 0.0071, 0.0339,
        0.0060, 0.0067, 0.0756, 0.0289, 0.0970, 0.2472, 0.0114, 0.0967, 0.0146],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:48,942][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0094, 0.0413, 0.0821, 0.0022, 0.0116, 0.0274, 0.0283, 0.0029, 0.0112,
        0.0073, 0.0075, 0.2239, 0.0395, 0.0586, 0.1509, 0.0130, 0.0754, 0.0400,
        0.1674], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,943][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([7.2190e-05, 5.6641e-02, 2.7282e-01, 6.4594e-03, 2.8477e-02, 2.1779e-02,
        2.6535e-02, 3.6939e-03, 1.7928e-02, 2.5011e-02, 2.2079e-02, 1.0918e-01,
        5.1373e-02, 1.0243e-01, 3.1196e-02, 3.3295e-02, 2.8964e-02, 2.8192e-02,
        1.3386e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,944][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0187, 0.0294, 0.0315, 0.0297, 0.0316, 0.0491, 0.0152, 0.0451, 0.0198,
        0.0628, 0.0425, 0.0938, 0.1155, 0.0706, 0.0509, 0.0842, 0.0891, 0.0726,
        0.0481], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,945][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([0.1022, 0.0894, 0.0192, 0.0179, 0.0310, 0.0668, 0.0404, 0.0093, 0.0387,
        0.0126, 0.0232, 0.0560, 0.0365, 0.0605, 0.1511, 0.0140, 0.0876, 0.0628,
        0.0808], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,946][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([0.1272, 0.0237, 0.0023, 0.0010, 0.0026, 0.0232, 0.0033, 0.0026, 0.0008,
        0.0053, 0.0076, 0.1516, 0.0450, 0.0760, 0.1719, 0.0120, 0.1056, 0.0457,
        0.1929], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,947][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([2.1693e-02, 4.5339e-03, 1.5085e-03, 3.6143e-08, 7.3668e-05, 3.4892e-04,
        1.9202e-05, 1.9657e-08, 3.0169e-07, 2.9837e-07, 1.0158e-06, 2.0892e-02,
        1.9571e-04, 6.9831e-02, 5.5461e-02, 1.7440e-05, 5.2987e-03, 2.6727e-04,
        8.1986e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,949][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0029, 0.0093, 0.0566, 0.0018, 0.0228, 0.0277, 0.0082, 0.0072, 0.0121,
        0.0044, 0.0105, 0.1028, 0.0407, 0.2204, 0.2314, 0.0090, 0.0324, 0.0408,
        0.1590], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,951][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([8.3889e-01, 2.2047e-02, 7.6572e-02, 6.2302e-04, 3.0173e-03, 2.8888e-03,
        1.8912e-03, 1.8594e-03, 4.4636e-04, 1.1060e-03, 1.8293e-03, 6.9237e-03,
        5.4508e-03, 1.1944e-02, 9.6770e-03, 1.3402e-03, 5.7450e-03, 2.7349e-03,
        5.0109e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,952][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([0.0739, 0.1865, 0.0975, 0.0231, 0.0039, 0.0429, 0.0422, 0.0629, 0.0321,
        0.0350, 0.0662, 0.0506, 0.0850, 0.0157, 0.0212, 0.0333, 0.0415, 0.0316,
        0.0549], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,954][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([1.1426e-02, 4.0785e-03, 1.8614e-03, 1.2767e-09, 8.9887e-06, 6.2222e-05,
        6.4164e-06, 1.6262e-09, 1.2194e-08, 3.4535e-08, 1.0278e-07, 1.8475e-02,
        2.9430e-05, 3.4749e-02, 6.0856e-02, 4.3151e-06, 3.5727e-03, 6.4683e-05,
        8.6481e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,955][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([4.3183e-03, 2.5022e-03, 9.8590e-01, 8.5373e-05, 2.4984e-04, 1.6735e-04,
        1.3776e-03, 1.2059e-04, 8.8117e-05, 3.2616e-05, 4.8126e-05, 7.9488e-05,
        5.4771e-06, 2.3612e-05, 5.3830e-04, 7.6733e-05, 6.0914e-04, 1.2916e-04,
        3.6480e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,957][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0631, 0.0279, 0.1297, 0.0076, 0.0399, 0.0696, 0.0254, 0.0095, 0.0364,
        0.0103, 0.0269, 0.0329, 0.0336, 0.0637, 0.1701, 0.0147, 0.0683, 0.0174,
        0.1532], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:48,959][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0179, 0.0923, 0.1413, 0.0025, 0.0078, 0.0233, 0.0342, 0.0035, 0.0063,
        0.0086, 0.0069, 0.1931, 0.0216, 0.0354, 0.1050, 0.0129, 0.0782, 0.0426,
        0.1449, 0.0216], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,960][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.2323e-04, 9.5021e-02, 3.8299e-01, 9.3962e-03, 2.3037e-02, 1.5320e-02,
        1.9796e-02, 1.1893e-02, 2.0649e-02, 3.1261e-02, 2.4751e-02, 5.7441e-02,
        3.1562e-02, 5.2703e-02, 1.7620e-02, 4.0431e-02, 1.7689e-02, 2.7726e-02,
        5.3911e-02, 6.6482e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,961][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0261, 0.0483, 0.0812, 0.0244, 0.0307, 0.0252, 0.0195, 0.1035, 0.0211,
        0.0827, 0.0408, 0.0271, 0.0620, 0.0406, 0.0357, 0.0968, 0.0437, 0.0392,
        0.0142, 0.1372], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,962][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1031, 0.1098, 0.0256, 0.0140, 0.0283, 0.0457, 0.0479, 0.0132, 0.0405,
        0.0117, 0.0269, 0.0498, 0.0359, 0.0724, 0.1186, 0.0149, 0.0745, 0.0731,
        0.0648, 0.0294], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,963][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0346, 0.0236, 0.0013, 0.0022, 0.0022, 0.0325, 0.0077, 0.0055, 0.0012,
        0.0068, 0.0194, 0.1732, 0.0553, 0.0409, 0.1248, 0.0148, 0.1660, 0.0977,
        0.1590, 0.0313], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,964][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.9270e-04, 3.6985e-03, 4.6150e-03, 7.5793e-08, 1.0180e-03, 1.4544e-04,
        1.1248e-04, 3.3022e-08, 1.8887e-06, 2.4340e-07, 6.6453e-07, 2.8438e-02,
        5.5937e-05, 2.1047e-01, 8.7724e-02, 6.0327e-06, 8.6026e-03, 7.7347e-05,
        6.5411e-01, 3.4206e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,967][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0070, 0.0140, 0.0530, 0.0015, 0.0203, 0.0184, 0.0085, 0.0120, 0.0133,
        0.0083, 0.0086, 0.0658, 0.0344, 0.3360, 0.1606, 0.0152, 0.0324, 0.0409,
        0.1225, 0.0273], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,968][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.7164, 0.0648, 0.0814, 0.0014, 0.0053, 0.0051, 0.0075, 0.0090, 0.0017,
        0.0053, 0.0046, 0.0096, 0.0109, 0.0290, 0.0165, 0.0062, 0.0092, 0.0070,
        0.0037, 0.0052], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,970][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0786, 0.3869, 0.1034, 0.0157, 0.0016, 0.0209, 0.0226, 0.1044, 0.0225,
        0.0354, 0.0450, 0.0179, 0.0194, 0.0037, 0.0107, 0.0302, 0.0176, 0.0140,
        0.0155, 0.0339], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,972][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.6758e-04, 2.0804e-03, 5.4568e-03, 1.9101e-09, 9.4742e-05, 1.4961e-05,
        2.2668e-05, 3.3731e-09, 8.8296e-08, 4.4788e-08, 7.7771e-08, 2.1973e-02,
        4.6862e-06, 7.9271e-02, 1.0950e-01, 2.0707e-06, 9.3801e-03, 1.9050e-05,
        7.7179e-01, 2.4681e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,973][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.6172e-03, 3.3584e-03, 9.9288e-01, 5.9549e-05, 6.4664e-05, 5.3843e-05,
        5.1981e-04, 9.6068e-05, 4.8929e-05, 2.7465e-05, 2.0351e-05, 1.6576e-05,
        2.4332e-06, 4.0260e-06, 1.6018e-04, 5.7582e-05, 1.9409e-04, 4.5532e-05,
        7.1142e-04, 5.8318e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,975][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.5096, 0.0243, 0.0736, 0.0014, 0.0091, 0.0118, 0.0139, 0.0044, 0.0101,
        0.0028, 0.0041, 0.0326, 0.0080, 0.0317, 0.1455, 0.0042, 0.0278, 0.0048,
        0.0751, 0.0053], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:48,978][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:48,981][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6525],
        [ 396],
        [ 324],
        [   6],
        [ 167],
        [  15],
        [  37],
        [   3],
        [  92],
        [   7],
        [   3],
        [  24],
        [   3],
        [  77],
        [  16],
        [   3],
        [  12],
        [   7],
        [  15],
        [   2]], device='cuda:0')
[2024-07-24 10:18:48,983][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[5757],
        [ 448],
        [1607],
        [  15],
        [ 370],
        [  28],
        [  94],
        [  20],
        [ 166],
        [  16],
        [   5],
        [  29],
        [   7],
        [ 136],
        [  37],
        [  10],
        [  20],
        [   7],
        [  28],
        [   8]], device='cuda:0')
[2024-07-24 10:18:48,984][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[24428],
        [15990],
        [    3],
        [   13],
        [   10],
        [   36],
        [ 1501],
        [   88],
        [ 7182],
        [ 2663],
        [   96],
        [ 1802],
        [  672],
        [ 1629],
        [ 2296],
        [ 5926],
        [ 2128],
        [ 1006],
        [ 4941],
        [ 7021]], device='cuda:0')
[2024-07-24 10:18:48,986][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37517],
        [34430],
        [43036],
        [42951],
        [43359],
        [42273],
        [41245],
        [42244],
        [41720],
        [42795],
        [42384],
        [42151],
        [42641],
        [42232],
        [41914],
        [41453],
        [41820],
        [41523],
        [36871],
        [40656]], device='cuda:0')
[2024-07-24 10:18:48,988][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6845],
        [ 7250],
        [    3],
        [    8],
        [  666],
        [  300],
        [ 1745],
        [  172],
        [ 1643],
        [  213],
        [ 1052],
        [ 6792],
        [  325],
        [ 5244],
        [ 5339],
        [ 3248],
        [ 4675],
        [ 5062],
        [22851],
        [ 5739]], device='cuda:0')
[2024-07-24 10:18:48,990][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[32347],
        [24769],
        [29283],
        [28714],
        [31653],
        [29685],
        [28956],
        [26968],
        [25605],
        [27737],
        [26057],
        [27984],
        [27289],
        [29084],
        [27559],
        [30205],
        [27858],
        [27909],
        [28043],
        [28113]], device='cuda:0')
[2024-07-24 10:18:48,992][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10972],
        [12339],
        [18857],
        [18398],
        [18754],
        [16832],
        [22004],
        [22961],
        [23375],
        [23781],
        [23280],
        [30741],
        [30993],
        [31452],
        [32068],
        [33177],
        [34559],
        [35498],
        [35337],
        [36511]], device='cuda:0')
[2024-07-24 10:18:48,994][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17346],
        [37677],
        [38002],
        [38108],
        [38928],
        [37975],
        [37895],
        [38107],
        [38294],
        [39304],
        [41006],
        [38507],
        [38690],
        [41298],
        [41154],
        [41269],
        [41094],
        [41373],
        [41289],
        [41711]], device='cuda:0')
[2024-07-24 10:18:48,996][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[46939],
        [46143],
        [49511],
        [49478],
        [49379],
        [48611],
        [47132],
        [48240],
        [48120],
        [48378],
        [47999],
        [48028],
        [46345],
        [47031],
        [45569],
        [45953],
        [45839],
        [46049],
        [45186],
        [45918]], device='cuda:0')
[2024-07-24 10:18:48,999][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42191],
        [39299],
        [    1],
        [  451],
        [12686],
        [  430],
        [   78],
        [    1],
        [   23],
        [   40],
        [  118],
        [ 6383],
        [ 4347],
        [   82],
        [   99],
        [  878],
        [  284],
        [ 4861],
        [   87],
        [  105]], device='cuda:0')
[2024-07-24 10:18:49,001][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[33220],
        [14857],
        [ 5481],
        [ 8806],
        [ 5960],
        [ 7339],
        [10920],
        [11678],
        [10682],
        [12361],
        [13874],
        [12477],
        [11910],
        [12992],
        [13212],
        [13685],
        [14270],
        [12915],
        [14988],
        [14160]], device='cuda:0')
[2024-07-24 10:18:49,002][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37678],
        [43949],
        [44215],
        [44152],
        [47464],
        [43873],
        [43818],
        [43863],
        [44418],
        [46001],
        [48782],
        [49930],
        [49857],
        [49776],
        [49608],
        [49548],
        [49605],
        [49590],
        [49119],
        [49254]], device='cuda:0')
[2024-07-24 10:18:49,004][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24908],
        [17320],
        [50160],
        [50115],
        [47732],
        [45233],
        [36649],
        [39737],
        [39332],
        [40055],
        [43162],
        [37198],
        [35022],
        [34704],
        [30305],
        [29359],
        [26089],
        [29217],
        [18459],
        [17160]], device='cuda:0')
[2024-07-24 10:18:49,006][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[40326],
        [13904],
        [30823],
        [39261],
        [34727],
        [38381],
        [35211],
        [35462],
        [39071],
        [42136],
        [40360],
        [37824],
        [39656],
        [38553],
        [40435],
        [42424],
        [41426],
        [41339],
        [40952],
        [42508]], device='cuda:0')
[2024-07-24 10:18:49,008][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[24720],
        [ 3524],
        [ 4473],
        [ 1374],
        [ 2257],
        [ 1200],
        [ 2796],
        [  886],
        [ 3173],
        [ 3154],
        [ 2316],
        [ 3740],
        [ 2694],
        [ 2252],
        [ 2967],
        [ 3456],
        [ 4134],
        [ 2892],
        [ 4366],
        [ 3574]], device='cuda:0')
[2024-07-24 10:18:49,010][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25113],
        [39807],
        [40102],
        [39910],
        [39258],
        [39235],
        [38499],
        [38145],
        [37989],
        [39149],
        [38612],
        [32249],
        [35044],
        [32690],
        [32208],
        [34853],
        [33956],
        [33896],
        [29762],
        [32475]], device='cuda:0')
[2024-07-24 10:18:49,012][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39011],
        [26002],
        [30531],
        [30509],
        [32163],
        [30807],
        [30695],
        [30681],
        [31480],
        [31817],
        [31304],
        [30922],
        [31363],
        [32000],
        [32368],
        [32382],
        [32108],
        [32301],
        [31590],
        [32504]], device='cuda:0')
[2024-07-24 10:18:49,014][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[43429],
        [34530],
        [15678],
        [22291],
        [24250],
        [25533],
        [20750],
        [24318],
        [24752],
        [30896],
        [33247],
        [32267],
        [32115],
        [34981],
        [35136],
        [34951],
        [37228],
        [36148],
        [37579],
        [37999]], device='cuda:0')
[2024-07-24 10:18:49,016][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22411],
        [25466],
        [21605],
        [22637],
        [22259],
        [19246],
        [19252],
        [20568],
        [20382],
        [19838],
        [20052],
        [21778],
        [21868],
        [20658],
        [18738],
        [17059],
        [19032],
        [17934],
        [17340],
        [17782]], device='cuda:0')
[2024-07-24 10:18:49,018][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22086],
        [18281],
        [16668],
        [16564],
        [17323],
        [20456],
        [22157],
        [22061],
        [23771],
        [22504],
        [22262],
        [25522],
        [25891],
        [26289],
        [27730],
        [27443],
        [25659],
        [24628],
        [22633],
        [21170]], device='cuda:0')
[2024-07-24 10:18:49,020][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30625],
        [21826],
        [20767],
        [20602],
        [20034],
        [20688],
        [20745],
        [20631],
        [20426],
        [19637],
        [17573],
        [26781],
        [26506],
        [18089],
        [18619],
        [17348],
        [19643],
        [19216],
        [25230],
        [23956]], device='cuda:0')
[2024-07-24 10:18:49,021][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15842],
        [19110],
        [20388],
        [20473],
        [17636],
        [17223],
        [22110],
        [18677],
        [18229],
        [18866],
        [19328],
        [13156],
        [10502],
        [10495],
        [ 8331],
        [ 8816],
        [ 8752],
        [ 8780],
        [ 9329],
        [ 9736]], device='cuda:0')
[2024-07-24 10:18:49,024][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9254],
        [ 8773],
        [16381],
        [ 9285],
        [ 9220],
        [ 9279],
        [ 9449],
        [13747],
        [ 9286],
        [ 8900],
        [ 8989],
        [ 9138],
        [ 8799],
        [ 9474],
        [ 9424],
        [ 7529],
        [ 8978],
        [ 8090],
        [ 9112],
        [ 7743]], device='cuda:0')
[2024-07-24 10:18:49,026][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8936],
        [16254],
        [17097],
        [16526],
        [16880],
        [16956],
        [17315],
        [18161],
        [19233],
        [18390],
        [18704],
        [17885],
        [18302],
        [18600],
        [18978],
        [19060],
        [19624],
        [19362],
        [20367],
        [19298]], device='cuda:0')
[2024-07-24 10:18:49,028][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[34295],
        [17786],
        [17283],
        [17274],
        [14650],
        [17484],
        [17483],
        [17460],
        [17100],
        [15971],
        [12292],
        [10530],
        [10743],
        [ 6750],
        [ 6424],
        [ 6376],
        [ 6419],
        [ 6347],
        [24628],
        [22179]], device='cuda:0')
[2024-07-24 10:18:49,030][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19143],
        [ 8636],
        [24778],
        [24833],
        [24850],
        [24839],
        [24809],
        [24831],
        [24805],
        [24841],
        [24842],
        [24864],
        [24883],
        [24869],
        [24883],
        [24876],
        [24882],
        [24879],
        [24899],
        [24884]], device='cuda:0')
[2024-07-24 10:18:49,032][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6703],
        [29527],
        [33435],
        [31369],
        [33874],
        [32350],
        [31490],
        [33205],
        [30068],
        [ 9972],
        [28805],
        [29943],
        [32677],
        [32010],
        [30797],
        [21121],
        [25787],
        [28390],
        [30734],
        [17971]], device='cuda:0')
[2024-07-24 10:18:49,034][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21898],
        [22594],
        [18232],
        [19290],
        [19785],
        [18966],
        [18673],
        [16726],
        [18803],
        [23738],
        [19038],
        [20968],
        [20269],
        [23100],
        [24814],
        [27795],
        [24795],
        [25323],
        [17875],
        [21765]], device='cuda:0')
[2024-07-24 10:18:49,036][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[21828],
        [36840],
        [37848],
        [45881],
        [41349],
        [44670],
        [38440],
        [46272],
        [38157],
        [39433],
        [42238],
        [36404],
        [40466],
        [39872],
        [35876],
        [35477],
        [34245],
        [40790],
        [36364],
        [37238]], device='cuda:0')
[2024-07-24 10:18:49,038][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554],
        [11554]], device='cuda:0')
[2024-07-24 10:18:49,150][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:49,151][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,153][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,153][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,154][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,155][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,155][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,156][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,157][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,158][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,159][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,161][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,162][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,163][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0139, 0.9861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,163][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,164][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0375, 0.9625], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,165][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0299, 0.9701], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,165][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.9964e-04, 9.9970e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,166][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([5.9799e-04, 9.9940e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,168][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,170][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7791, 0.2209], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,171][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3399, 0.6601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,173][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9771, 0.0229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,175][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4231, 0.5769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,177][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8999, 0.1001], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,179][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Katie] are: tensor([0.0029, 0.6298, 0.3672], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,180][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Katie] are: tensor([0.0017, 0.8692, 0.1292], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,180][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Katie] are: tensor([0.0051, 0.1608, 0.8341], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,181][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Katie] are: tensor([0.0012, 0.3602, 0.6386], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,182][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Katie] are: tensor([0.0010, 0.5777, 0.4212], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,182][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Katie] are: tensor([1.6078e-04, 7.1515e-01, 2.8469e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,183][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Katie] are: tensor([0.0016, 0.5977, 0.4007], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,185][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Katie] are: tensor([0.6591, 0.2193, 0.1216], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,186][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Katie] are: tensor([0.4249, 0.2933, 0.2817], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,188][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Katie] are: tensor([0.9653, 0.0102, 0.0244], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,189][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Katie] are: tensor([0.8168, 0.0765, 0.1066], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,191][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Katie] are: tensor([0.7586, 0.0130, 0.2284], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,193][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0028, 0.6670, 0.2904, 0.0399], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,195][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0299, 0.8253, 0.1027, 0.0420], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,196][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0026, 0.0318, 0.9620, 0.0035], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,197][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0011, 0.0904, 0.9067, 0.0018], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,198][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([6.0741e-04, 6.3928e-01, 2.2301e-01, 1.3710e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,198][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0010, 0.7869, 0.1779, 0.0341], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,199][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0090, 0.6058, 0.3709, 0.0144], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,200][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6718, 0.1917, 0.1091, 0.0275], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,201][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4059, 0.3037, 0.2282, 0.0622], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,203][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9326, 0.0394, 0.0220, 0.0060], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,204][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5810, 0.1860, 0.0292, 0.2038], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,206][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.9425e-02, 1.9074e-01, 7.8932e-01, 5.1667e-04], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,207][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0352, 0.6476, 0.1467, 0.0235, 0.1469], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,209][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0016, 0.8377, 0.0683, 0.0598, 0.0326], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,211][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0170, 0.1125, 0.8127, 0.0054, 0.0524], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,213][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([0.0036, 0.5236, 0.4130, 0.0012, 0.0586], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,214][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([0.0008, 0.5952, 0.1258, 0.1067, 0.1715], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,215][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([5.3507e-04, 5.8265e-01, 3.3472e-01, 4.1409e-02, 4.0693e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,216][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0158, 0.5409, 0.4145, 0.0227, 0.0062], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,217][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.5553, 0.2016, 0.1509, 0.0304, 0.0618], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,217][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.1827, 0.3274, 0.2887, 0.0802, 0.1211], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,218][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.9086, 0.0029, 0.0062, 0.0009, 0.0814], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,220][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.7824, 0.0621, 0.0467, 0.0434, 0.0654], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,221][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([3.1652e-01, 1.1881e-02, 6.7016e-01, 7.5024e-06, 1.4293e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,223][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0151, 0.6160, 0.2249, 0.0117, 0.0860, 0.0464], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,224][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0524, 0.6072, 0.0602, 0.0340, 0.0233, 0.2227], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,225][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0918, 0.0459, 0.5426, 0.0020, 0.3146, 0.0031], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,227][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0058, 0.1365, 0.5453, 0.0016, 0.3031, 0.0077], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,229][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0007, 0.3866, 0.0750, 0.0647, 0.1799, 0.2931], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,231][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0022, 0.6910, 0.1986, 0.0399, 0.0237, 0.0445], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,232][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0629, 0.5850, 0.2972, 0.0105, 0.0032, 0.0413], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,233][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.6321, 0.1812, 0.0823, 0.0227, 0.0476, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,233][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.5058, 0.2034, 0.1391, 0.0375, 0.0847, 0.0295], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,234][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.5501, 0.0380, 0.0219, 0.0046, 0.2917, 0.0937], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,235][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.6137, 0.0393, 0.0058, 0.0402, 0.0194, 0.2815], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,235][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ were] are: tensor([8.4355e-01, 7.8958e-03, 1.4269e-01, 6.0698e-05, 2.1068e-03, 3.7057e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,237][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0122, 0.7230, 0.1491, 0.0089, 0.0501, 0.0434, 0.0133],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,239][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0071, 0.7219, 0.0272, 0.0277, 0.0160, 0.1694, 0.0308],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,241][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.1097, 0.1970, 0.4784, 0.0032, 0.0805, 0.0064, 0.1246],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,243][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0037, 0.5843, 0.2414, 0.0021, 0.1423, 0.0065, 0.0197],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,244][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0010, 0.4122, 0.0453, 0.0440, 0.1555, 0.3212, 0.0209],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,246][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([4.1871e-04, 6.6894e-01, 7.5555e-02, 3.7828e-02, 2.7561e-02, 9.3632e-02,
        9.6068e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,247][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0179, 0.6251, 0.1735, 0.0130, 0.0051, 0.0977, 0.0677],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,249][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.4972, 0.1614, 0.1242, 0.0295, 0.0816, 0.0667, 0.0393],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,250][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2241, 0.2520, 0.1993, 0.0504, 0.1045, 0.0489, 0.1207],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,251][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.4933, 0.0097, 0.0164, 0.0024, 0.3318, 0.0834, 0.0630],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,251][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0996, 0.0374, 0.0087, 0.0603, 0.0747, 0.7094, 0.0098],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,252][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([9.4637e-01, 2.5242e-02, 2.6209e-02, 3.7746e-06, 2.2053e-04, 1.2032e-03,
        7.5490e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,253][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0059, 0.4093, 0.2447, 0.0142, 0.0990, 0.0466, 0.0224, 0.1579],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,255][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0069, 0.4862, 0.0607, 0.0401, 0.0471, 0.2394, 0.0411, 0.0785],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,257][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0336, 0.0663, 0.6673, 0.0048, 0.1394, 0.0066, 0.0654, 0.0165],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,258][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ about] are: tensor([1.7144e-04, 1.1978e-01, 3.2537e-01, 7.0639e-03, 4.7531e-01, 1.0434e-02,
        5.9944e-02, 1.9200e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,259][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0008, 0.3778, 0.0297, 0.0875, 0.1820, 0.2900, 0.0176, 0.0145],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,261][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ about] are: tensor([1.1406e-04, 4.5251e-01, 1.3628e-01, 3.6321e-02, 4.6445e-02, 5.7216e-02,
        1.4156e-01, 1.2956e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,263][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0056, 0.5914, 0.1481, 0.0267, 0.0076, 0.1118, 0.0697, 0.0391],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,265][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.2417, 0.2057, 0.1717, 0.0458, 0.1250, 0.0887, 0.0538, 0.0675],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,266][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.4281, 0.2039, 0.1336, 0.0313, 0.0786, 0.0258, 0.0499, 0.0488],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,267][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0534, 0.0347, 0.0180, 0.0072, 0.4782, 0.2699, 0.1189, 0.0197],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,268][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0407, 0.0722, 0.0082, 0.0662, 0.1209, 0.5817, 0.0271, 0.0830],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,269][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ about] are: tensor([3.6710e-02, 2.9063e-01, 6.0794e-01, 3.5295e-04, 1.3436e-02, 1.1415e-02,
        3.9472e-02, 4.9798e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,269][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0093, 0.5178, 0.0767, 0.0099, 0.0474, 0.0362, 0.0317, 0.1158, 0.1550],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,270][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0058, 0.6462, 0.0240, 0.0417, 0.0307, 0.1458, 0.0265, 0.0368, 0.0425],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,272][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.2437, 0.0763, 0.3931, 0.0027, 0.1499, 0.0046, 0.0921, 0.0097, 0.0279],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,274][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0012, 0.3574, 0.4111, 0.0029, 0.1819, 0.0130, 0.0258, 0.0017, 0.0050],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,275][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ going] are: tensor([1.2047e-04, 2.9304e-01, 2.8520e-02, 5.5288e-02, 2.1709e-01, 2.3864e-01,
        1.1022e-02, 8.7379e-03, 1.4755e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,277][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0010, 0.5135, 0.0995, 0.0399, 0.0386, 0.0475, 0.0831, 0.1039, 0.0730],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,279][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0057, 0.5484, 0.1778, 0.0209, 0.0093, 0.0852, 0.0952, 0.0258, 0.0317],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,281][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.3021, 0.1649, 0.1450, 0.0393, 0.1009, 0.0868, 0.0502, 0.0585, 0.0521],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,283][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1492, 0.1975, 0.1948, 0.0506, 0.0978, 0.0470, 0.0982, 0.0928, 0.0721],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,284][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0884, 0.0187, 0.0359, 0.0071, 0.4671, 0.1444, 0.1311, 0.0139, 0.0933],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,284][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.1166, 0.0414, 0.0197, 0.0466, 0.1017, 0.6283, 0.0116, 0.0189, 0.0153],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,285][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ going] are: tensor([4.9090e-01, 6.8204e-02, 4.1555e-01, 4.1920e-05, 7.7965e-03, 9.6956e-03,
        7.6255e-03, 1.7535e-05, 1.7144e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,286][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0156, 0.2478, 0.1190, 0.0111, 0.0837, 0.0361, 0.0175, 0.1360, 0.1771,
        0.1563], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,287][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0025, 0.5912, 0.0449, 0.0827, 0.0262, 0.1325, 0.0115, 0.0448, 0.0289,
        0.0349], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,288][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0058, 0.0419, 0.5671, 0.0102, 0.2383, 0.0054, 0.0593, 0.0087, 0.0291,
        0.0343], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,289][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.8583e-04, 6.7361e-02, 5.9086e-01, 6.8982e-03, 2.6618e-01, 9.8554e-03,
        2.5557e-02, 1.7404e-03, 1.3722e-02, 1.7346e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,291][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.9125e-05, 1.9805e-01, 2.2248e-02, 6.6510e-02, 7.4730e-02, 1.2414e-01,
        5.4282e-03, 5.1442e-03, 6.5776e-02, 4.3794e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,292][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.1263e-04, 4.9224e-01, 1.4343e-01, 3.4539e-02, 3.3020e-02, 2.4575e-02,
        4.2516e-02, 8.2770e-02, 4.1702e-02, 1.0490e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,294][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0030, 0.4326, 0.2777, 0.0377, 0.0100, 0.0747, 0.0658, 0.0174, 0.0206,
        0.0606], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,296][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3022, 0.1776, 0.1324, 0.0385, 0.0832, 0.0632, 0.0479, 0.0516, 0.0441,
        0.0592], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,298][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1457, 0.1996, 0.1737, 0.0450, 0.0837, 0.0402, 0.0871, 0.0796, 0.0642,
        0.0813], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,300][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0267, 0.0186, 0.0217, 0.0058, 0.5509, 0.1508, 0.1013, 0.0129, 0.0898,
        0.0214], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,301][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1062, 0.0857, 0.0121, 0.0489, 0.1750, 0.3590, 0.0203, 0.0356, 0.0194,
        0.1378], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,302][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([3.0178e-01, 4.6141e-02, 6.4556e-01, 1.1525e-05, 1.7138e-03, 1.8370e-03,
        2.7828e-03, 4.9605e-06, 1.3032e-04, 3.5243e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,302][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0147, 0.2986, 0.0886, 0.0060, 0.0374, 0.0284, 0.0123, 0.1275, 0.1481,
        0.1421, 0.0963], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,303][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0065, 0.4678, 0.0245, 0.0356, 0.0150, 0.1387, 0.0161, 0.0391, 0.0343,
        0.0355, 0.1868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,304][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0032, 0.0092, 0.5963, 0.0014, 0.3422, 0.0013, 0.0256, 0.0026, 0.0062,
        0.0107, 0.0015], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,305][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.0420e-04, 1.1489e-01, 4.6347e-01, 7.2571e-03, 3.3299e-01, 2.1659e-02,
        1.5658e-02, 1.3065e-03, 1.2431e-02, 1.8328e-02, 1.1814e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,306][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([5.7290e-05, 1.2940e-01, 7.8032e-03, 3.4004e-02, 3.6164e-02, 1.1749e-01,
        3.4070e-03, 3.4946e-03, 5.3188e-02, 3.2878e-01, 2.8621e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,308][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0004, 0.3363, 0.0696, 0.0229, 0.0136, 0.0255, 0.0637, 0.0791, 0.0553,
        0.0997, 0.2338], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,310][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0083, 0.4840, 0.2190, 0.0172, 0.0037, 0.0600, 0.0638, 0.0119, 0.0135,
        0.0521, 0.0664], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,312][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2784, 0.1818, 0.1370, 0.0344, 0.0887, 0.0571, 0.0445, 0.0422, 0.0388,
        0.0502, 0.0470], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,314][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0725, 0.1991, 0.1531, 0.0425, 0.0609, 0.0398, 0.0867, 0.1011, 0.0654,
        0.0958, 0.0830], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,316][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1298, 0.0178, 0.0197, 0.0057, 0.4297, 0.1418, 0.0955, 0.0119, 0.1048,
        0.0163, 0.0269], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,317][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1301, 0.0280, 0.0183, 0.0611, 0.1514, 0.3487, 0.0148, 0.0266, 0.0227,
        0.0742, 0.1242], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,318][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.8744e-01, 2.5043e-02, 5.7624e-01, 2.3374e-05, 3.6505e-03, 2.3228e-03,
        4.8347e-03, 1.0875e-05, 1.5748e-04, 5.9436e-05, 2.2063e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,319][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ school] are: tensor([0.1130, 0.2404, 0.1675, 0.0029, 0.0235, 0.0342, 0.0052, 0.0771, 0.0447,
        0.0841, 0.0403, 0.1671], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,320][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ school] are: tensor([0.0255, 0.4880, 0.0359, 0.0263, 0.0152, 0.1372, 0.0090, 0.0242, 0.0144,
        0.0424, 0.1476, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,321][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ school] are: tensor([0.0591, 0.1153, 0.3470, 0.0039, 0.1463, 0.0124, 0.0719, 0.0141, 0.0386,
        0.0569, 0.0172, 0.1174], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,321][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ school] are: tensor([0.0041, 0.5517, 0.2625, 0.0017, 0.1255, 0.0052, 0.0061, 0.0006, 0.0015,
        0.0177, 0.0038, 0.0196], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,323][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ school] are: tensor([2.6131e-04, 8.3295e-02, 6.2711e-03, 8.6639e-03, 2.5422e-02, 4.3434e-02,
        1.1359e-03, 1.0803e-03, 1.8742e-02, 1.1927e-01, 1.3812e-01, 5.5431e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,324][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ school] are: tensor([0.0015, 0.3780, 0.0733, 0.0086, 0.0147, 0.0157, 0.0398, 0.0452, 0.0193,
        0.0367, 0.0795, 0.2879], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,326][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ school] are: tensor([0.0345, 0.6714, 0.1517, 0.0082, 0.0022, 0.0359, 0.0242, 0.0057, 0.0077,
        0.0223, 0.0262, 0.0101], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,328][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ school] are: tensor([0.4712, 0.1181, 0.1024, 0.0198, 0.0577, 0.0385, 0.0272, 0.0267, 0.0224,
        0.0297, 0.0288, 0.0575], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,329][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ school] are: tensor([0.0209, 0.1716, 0.1445, 0.0420, 0.0443, 0.0521, 0.1042, 0.1267, 0.0679,
        0.0856, 0.0699, 0.0703], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,330][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ school] are: tensor([6.1710e-01, 1.8388e-03, 5.1665e-03, 6.1265e-04, 1.3941e-01, 3.0132e-02,
        2.9093e-02, 4.9523e-03, 2.6327e-02, 2.2504e-03, 5.0294e-03, 1.3810e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,332][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ school] are: tensor([0.7685, 0.0120, 0.0085, 0.0054, 0.0192, 0.1336, 0.0010, 0.0020, 0.0023,
        0.0058, 0.0094, 0.0324], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,333][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ school] are: tensor([9.9521e-01, 1.7194e-04, 4.5582e-03, 2.0920e-08, 1.7072e-06, 1.0813e-05,
        3.8919e-06, 1.5462e-08, 7.2364e-08, 3.2983e-08, 3.2562e-07, 4.6613e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,335][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0606, 0.2106, 0.1185, 0.0034, 0.0151, 0.0250, 0.0067, 0.0877, 0.0540,
        0.0865, 0.0472, 0.0906, 0.1941], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,336][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0186, 0.3811, 0.0233, 0.0253, 0.0047, 0.0675, 0.0074, 0.0242, 0.0101,
        0.0215, 0.0929, 0.0086, 0.3147], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,337][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0088, 0.0347, 0.5451, 0.0022, 0.1609, 0.0030, 0.0503, 0.0057, 0.0159,
        0.0115, 0.0033, 0.0638, 0.0948], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,338][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0107, 0.2195, 0.3604, 0.0037, 0.1677, 0.0129, 0.0196, 0.0041, 0.0116,
        0.0444, 0.0111, 0.1197, 0.0146], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,338][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([7.9482e-05, 2.5914e-02, 2.0645e-03, 5.1529e-03, 5.7369e-03, 1.9615e-02,
        6.0113e-04, 5.8463e-04, 7.6249e-03, 4.8143e-02, 3.7151e-02, 9.8508e-02,
        7.4882e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,340][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0015, 0.2458, 0.1021, 0.0086, 0.0076, 0.0073, 0.0331, 0.0285, 0.0172,
        0.0242, 0.0451, 0.0794, 0.3997], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,341][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0232, 0.5192, 0.3169, 0.0085, 0.0019, 0.0232, 0.0278, 0.0062, 0.0056,
        0.0223, 0.0179, 0.0047, 0.0227], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,343][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.2644, 0.1460, 0.1319, 0.0311, 0.0752, 0.0548, 0.0334, 0.0361, 0.0301,
        0.0412, 0.0431, 0.0733, 0.0395], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,345][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0478, 0.2004, 0.1292, 0.0391, 0.0394, 0.0394, 0.0797, 0.1068, 0.0530,
        0.0831, 0.0683, 0.0631, 0.0507], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,347][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0454, 0.0072, 0.0156, 0.0042, 0.4046, 0.1090, 0.0716, 0.0082, 0.0627,
        0.0103, 0.0155, 0.1997, 0.0460], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,349][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1895, 0.0250, 0.0075, 0.0165, 0.0387, 0.1635, 0.0028, 0.0109, 0.0099,
        0.0300, 0.0547, 0.0597, 0.3914], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,350][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([8.4758e-01, 6.2601e-03, 1.3861e-01, 3.9291e-06, 1.4666e-04, 2.1890e-04,
        2.6987e-04, 2.0705e-06, 1.9536e-05, 5.5865e-06, 5.1635e-05, 6.3520e-03,
        4.7565e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,352][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Patrick] are: tensor([0.0463, 0.1635, 0.0356, 0.0012, 0.0098, 0.0146, 0.0037, 0.0294, 0.0168,
        0.0534, 0.0210, 0.1848, 0.3487, 0.0711], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,353][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Patrick] are: tensor([0.0024, 0.2497, 0.0085, 0.0127, 0.0097, 0.1232, 0.0062, 0.0124, 0.0089,
        0.0215, 0.0795, 0.0260, 0.4251, 0.0142], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,354][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Patrick] are: tensor([0.0214, 0.0618, 0.1137, 0.0016, 0.0132, 0.0100, 0.0620, 0.0077, 0.0236,
        0.0302, 0.0098, 0.0876, 0.4863, 0.0711], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,354][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Patrick] are: tensor([1.3406e-02, 8.3020e-01, 4.3583e-02, 5.7799e-04, 8.9219e-03, 4.1294e-03,
        3.3743e-03, 4.3669e-04, 9.4279e-04, 7.8806e-03, 1.5420e-03, 1.5303e-02,
        3.2624e-02, 3.7080e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,355][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Patrick] are: tensor([5.1612e-05, 7.3739e-03, 3.2269e-04, 7.1399e-04, 2.0847e-03, 8.3856e-03,
        3.6593e-04, 2.2986e-04, 4.4650e-03, 2.5415e-02, 3.2210e-02, 1.5666e-01,
        6.3976e-01, 1.2197e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,356][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Patrick] are: tensor([8.4276e-05, 4.0634e-02, 2.3748e-02, 3.6289e-03, 8.1075e-03, 8.1542e-03,
        1.9943e-02, 1.5098e-02, 1.3375e-02, 1.3050e-02, 4.4740e-02, 1.6575e-01,
        6.1233e-01, 3.1354e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,358][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Patrick] are: tensor([0.0807, 0.4701, 0.1149, 0.0098, 0.0037, 0.0644, 0.0405, 0.0074, 0.0130,
        0.0396, 0.0414, 0.0203, 0.0885, 0.0057], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,360][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Patrick] are: tensor([0.1886, 0.1274, 0.1317, 0.0328, 0.0749, 0.0693, 0.0302, 0.0325, 0.0269,
        0.0412, 0.0457, 0.0742, 0.0497, 0.0749], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,362][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Patrick] are: tensor([0.0253, 0.1397, 0.1284, 0.0388, 0.0356, 0.0483, 0.0934, 0.1223, 0.0591,
        0.0746, 0.0646, 0.0639, 0.0503, 0.0556], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,364][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Patrick] are: tensor([0.0408, 0.0014, 0.0122, 0.0023, 0.1132, 0.0587, 0.0251, 0.0047, 0.0378,
        0.0052, 0.0074, 0.0841, 0.0193, 0.5878], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,366][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Patrick] are: tensor([0.2753, 0.0130, 0.0248, 0.0070, 0.0434, 0.2126, 0.0020, 0.0021, 0.0033,
        0.0040, 0.0070, 0.0325, 0.0716, 0.3014], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,367][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Patrick] are: tensor([9.6598e-01, 2.2298e-04, 3.3144e-02, 2.0279e-08, 4.4470e-06, 2.3823e-05,
        1.7232e-05, 1.8101e-08, 8.2602e-07, 3.1934e-08, 3.2825e-07, 3.6369e-04,
        1.4360e-05, 2.3261e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,369][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0526, 0.2388, 0.1105, 0.0019, 0.0157, 0.0174, 0.0030, 0.0175, 0.0166,
        0.0359, 0.0136, 0.0711, 0.1885, 0.0489, 0.1682], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,370][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0082, 0.1567, 0.0102, 0.0065, 0.0088, 0.0653, 0.0082, 0.0124, 0.0128,
        0.0236, 0.0727, 0.0340, 0.5134, 0.0257, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,371][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1619, 0.0211, 0.0724, 0.0007, 0.0341, 0.0032, 0.0365, 0.0038, 0.0108,
        0.0172, 0.0062, 0.0550, 0.1884, 0.3711, 0.0176], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,371][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0076, 0.5703, 0.1326, 0.0013, 0.0506, 0.0063, 0.0107, 0.0008, 0.0014,
        0.0110, 0.0066, 0.0381, 0.0184, 0.1252, 0.0193], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,372][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([6.3618e-05, 4.8129e-03, 2.9810e-04, 6.8637e-04, 2.6684e-03, 1.0190e-02,
        3.9653e-04, 2.2337e-04, 5.5595e-03, 2.6564e-02, 3.2381e-02, 1.4025e-01,
        5.6460e-01, 1.7581e-01, 3.5494e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,373][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([3.3046e-04, 8.4513e-02, 1.0527e-02, 3.5681e-03, 3.8415e-03, 1.0047e-02,
        2.3598e-02, 2.2113e-02, 1.7948e-02, 3.4972e-02, 7.7573e-02, 9.0928e-02,
        3.9782e-01, 2.1763e-02, 2.0046e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,375][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0731, 0.3214, 0.0639, 0.0034, 0.0025, 0.0593, 0.0523, 0.0109, 0.0188,
        0.0427, 0.0523, 0.0308, 0.0778, 0.0066, 0.1843], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,377][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.2944, 0.1011, 0.1037, 0.0206, 0.0630, 0.0464, 0.0269, 0.0255, 0.0243,
        0.0345, 0.0389, 0.0691, 0.0370, 0.0740, 0.0406], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,379][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0249, 0.1498, 0.1133, 0.0374, 0.0370, 0.0420, 0.0842, 0.1106, 0.0514,
        0.0788, 0.0638, 0.0584, 0.0445, 0.0509, 0.0529], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,381][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0154, 0.0010, 0.0047, 0.0012, 0.0796, 0.0248, 0.0147, 0.0024, 0.0209,
        0.0030, 0.0045, 0.0534, 0.0104, 0.5623, 0.2018], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,383][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.2876, 0.0176, 0.0120, 0.0092, 0.0298, 0.1507, 0.0034, 0.0034, 0.0023,
        0.0064, 0.0144, 0.0312, 0.1296, 0.2070, 0.0953], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,384][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([9.9384e-01, 5.3884e-05, 5.7689e-03, 4.1292e-09, 5.5842e-07, 2.6849e-06,
        3.0303e-06, 3.2176e-09, 4.8867e-08, 4.1311e-09, 5.3222e-08, 1.0292e-04,
        2.2748e-06, 5.0366e-05, 1.7751e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,386][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0137, 0.0860, 0.0340, 0.0021, 0.0141, 0.0112, 0.0040, 0.0420, 0.0376,
        0.0424, 0.0229, 0.1183, 0.1878, 0.0584, 0.1421, 0.1834],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,387][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0044, 0.2907, 0.0196, 0.0391, 0.0124, 0.0717, 0.0070, 0.0294, 0.0180,
        0.0276, 0.0949, 0.0104, 0.3191, 0.0095, 0.0191, 0.0271],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,388][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0105, 0.0236, 0.2318, 0.0044, 0.0881, 0.0036, 0.0315, 0.0046, 0.0196,
        0.0205, 0.0054, 0.0546, 0.1164, 0.3625, 0.0093, 0.0135],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,388][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0012, 0.0957, 0.3315, 0.0059, 0.1239, 0.0111, 0.0174, 0.0021, 0.0152,
        0.0175, 0.0105, 0.1533, 0.0099, 0.1294, 0.0641, 0.0112],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,389][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.7219e-06, 1.5013e-02, 1.1321e-03, 4.5703e-03, 4.8572e-03, 1.5212e-02,
        5.4702e-04, 5.3262e-04, 7.4135e-03, 4.8336e-02, 3.9845e-02, 8.1700e-02,
        5.9309e-01, 9.1958e-02, 1.3759e-02, 8.2020e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,390][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.8345e-04, 1.3187e-01, 3.3292e-02, 8.4901e-03, 8.2540e-03, 6.0245e-03,
        1.2030e-02, 2.2949e-02, 1.2206e-02, 3.6736e-02, 6.9474e-02, 7.9198e-02,
        4.5288e-01, 2.4227e-02, 7.5602e-02, 2.6584e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,392][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0130, 0.2947, 0.2000, 0.0219, 0.0071, 0.0786, 0.0611, 0.0197, 0.0215,
        0.0618, 0.0718, 0.0172, 0.0547, 0.0052, 0.0273, 0.0446],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,394][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1438, 0.1061, 0.1026, 0.0306, 0.0661, 0.0582, 0.0360, 0.0366, 0.0331,
        0.0450, 0.0439, 0.0680, 0.0482, 0.0779, 0.0542, 0.0496],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,396][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1042, 0.1343, 0.1172, 0.0350, 0.0514, 0.0314, 0.0623, 0.0605, 0.0422,
        0.0603, 0.0518, 0.0513, 0.0386, 0.0565, 0.0464, 0.0566],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,398][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0010, 0.0022, 0.0039, 0.0016, 0.1019, 0.0395, 0.0137, 0.0018, 0.0189,
        0.0041, 0.0057, 0.0625, 0.0130, 0.3375, 0.3623, 0.0302],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,400][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0303, 0.0226, 0.0053, 0.0074, 0.0356, 0.0817, 0.0036, 0.0097, 0.0042,
        0.0278, 0.0206, 0.0369, 0.0964, 0.3655, 0.1593, 0.0929],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,401][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.3639e-01, 7.1765e-03, 5.0000e-01, 1.3264e-06, 2.0760e-04, 3.1275e-04,
        3.6597e-04, 7.7343e-07, 1.5751e-05, 2.2477e-06, 3.5876e-05, 1.2061e-02,
        3.5628e-04, 2.6204e-03, 4.0410e-02, 4.2491e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,403][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0644, 0.1863, 0.0551, 0.0008, 0.0085, 0.0096, 0.0016, 0.0108, 0.0117,
        0.0271, 0.0085, 0.0886, 0.1336, 0.0364, 0.0977, 0.1518, 0.1076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,404][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0365, 0.1855, 0.0102, 0.0062, 0.0043, 0.0478, 0.0031, 0.0092, 0.0065,
        0.0212, 0.0702, 0.0166, 0.4931, 0.0114, 0.0354, 0.0259, 0.0167],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,405][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([1.0023e-01, 1.8418e-02, 1.7462e-01, 3.8338e-04, 4.6414e-02, 1.4557e-03,
        2.8238e-02, 3.1139e-03, 7.6681e-03, 9.0978e-03, 2.5912e-03, 4.6736e-02,
        9.5045e-02, 4.2435e-01, 9.5660e-03, 8.3893e-03, 2.3694e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,406][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0248, 0.4737, 0.1942, 0.0008, 0.0398, 0.0044, 0.0119, 0.0006, 0.0014,
        0.0092, 0.0040, 0.0433, 0.0222, 0.1064, 0.0235, 0.0082, 0.0316],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,406][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([3.3628e-05, 9.3381e-03, 5.0372e-04, 8.8582e-04, 3.2477e-03, 8.6502e-03,
        2.0008e-04, 1.7188e-04, 4.2015e-03, 2.4788e-02, 2.9293e-02, 1.1225e-01,
        5.5430e-01, 1.4722e-01, 1.6269e-02, 6.1277e-02, 2.7366e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,407][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0009, 0.1040, 0.0169, 0.0034, 0.0043, 0.0067, 0.0187, 0.0254, 0.0140,
        0.0232, 0.0625, 0.0778, 0.3320, 0.0198, 0.1910, 0.0297, 0.0697],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,409][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.2622, 0.2966, 0.1301, 0.0031, 0.0015, 0.0340, 0.0336, 0.0063, 0.0086,
        0.0250, 0.0327, 0.0146, 0.0357, 0.0027, 0.0640, 0.0292, 0.0201],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,412][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.2406, 0.1113, 0.0915, 0.0246, 0.0610, 0.0492, 0.0283, 0.0277, 0.0252,
        0.0352, 0.0357, 0.0594, 0.0402, 0.0629, 0.0428, 0.0359, 0.0285],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,413][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0139, 0.1065, 0.0999, 0.0351, 0.0313, 0.0455, 0.0807, 0.1100, 0.0476,
        0.0637, 0.0563, 0.0511, 0.0427, 0.0426, 0.0490, 0.0643, 0.0600],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,415][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0284, 0.0014, 0.0052, 0.0008, 0.0880, 0.0216, 0.0109, 0.0016, 0.0163,
        0.0015, 0.0031, 0.0455, 0.0077, 0.4549, 0.1676, 0.0111, 0.1343],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,417][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.1617, 0.0135, 0.0089, 0.0087, 0.0544, 0.1582, 0.0018, 0.0038, 0.0022,
        0.0048, 0.0121, 0.0193, 0.1291, 0.2931, 0.0814, 0.0316, 0.0154],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,418][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([9.9688e-01, 6.4529e-05, 2.6337e-03, 4.8097e-09, 6.1148e-07, 2.5092e-06,
        3.4534e-06, 3.8875e-09, 6.0582e-08, 6.4265e-09, 1.2440e-07, 4.0759e-05,
        1.5729e-06, 3.2868e-05, 3.1784e-04, 2.2397e-07, 1.8344e-05],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,420][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0124, 0.1078, 0.0323, 0.0009, 0.0082, 0.0069, 0.0029, 0.0281, 0.0215,
        0.0255, 0.0166, 0.0980, 0.0895, 0.0305, 0.1062, 0.1323, 0.1701, 0.1103],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,421][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0100, 0.2477, 0.0150, 0.0204, 0.0085, 0.0659, 0.0093, 0.0260, 0.0183,
        0.0202, 0.1116, 0.0125, 0.2919, 0.0092, 0.0220, 0.0203, 0.0148, 0.0764],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,422][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.7224e-03, 2.0767e-03, 2.0678e-01, 4.1894e-04, 9.5770e-02, 3.9376e-04,
        5.6861e-03, 1.0694e-03, 2.8352e-03, 4.9225e-03, 8.3132e-04, 3.6081e-02,
        3.6473e-02, 5.9572e-01, 1.3600e-03, 4.1462e-03, 2.0461e-03, 6.6665e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,423][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0022, 0.1833, 0.2350, 0.0082, 0.1238, 0.0146, 0.0075, 0.0015, 0.0108,
        0.0171, 0.0151, 0.0709, 0.0136, 0.1898, 0.0307, 0.0161, 0.0457, 0.0140],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,424][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.3533e-05, 9.3412e-03, 5.4841e-04, 2.3350e-03, 2.8530e-03, 1.2219e-02,
        2.7896e-04, 3.0832e-04, 6.2914e-03, 3.1869e-02, 3.4325e-02, 7.6893e-02,
        5.3657e-01, 1.0852e-01, 1.1439e-02, 8.1181e-02, 2.5168e-02, 5.9838e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,425][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0004, 0.1189, 0.0329, 0.0067, 0.0053, 0.0054, 0.0231, 0.0267, 0.0201,
        0.0255, 0.0619, 0.0651, 0.3193, 0.0150, 0.1063, 0.0205, 0.0467, 0.1002],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,427][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0478, 0.3165, 0.1671, 0.0113, 0.0029, 0.0494, 0.0563, 0.0173, 0.0181,
        0.0424, 0.0617, 0.0092, 0.0478, 0.0034, 0.0463, 0.0437, 0.0212, 0.0376],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,429][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1991, 0.1015, 0.0924, 0.0252, 0.0590, 0.0453, 0.0277, 0.0283, 0.0262,
        0.0328, 0.0359, 0.0659, 0.0345, 0.0658, 0.0376, 0.0325, 0.0292, 0.0610],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,430][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0284, 0.1121, 0.0939, 0.0331, 0.0308, 0.0356, 0.0700, 0.0903, 0.0438,
        0.0627, 0.0542, 0.0461, 0.0404, 0.0434, 0.0455, 0.0623, 0.0568, 0.0506],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,433][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0126, 0.0011, 0.0024, 0.0006, 0.0641, 0.0201, 0.0105, 0.0014, 0.0176,
        0.0021, 0.0032, 0.0510, 0.0083, 0.3905, 0.1836, 0.0125, 0.2088, 0.0095],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,435][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0660, 0.0115, 0.0089, 0.0128, 0.0394, 0.0964, 0.0034, 0.0077, 0.0085,
        0.0259, 0.0356, 0.0418, 0.1316, 0.2529, 0.0960, 0.0729, 0.0201, 0.0686],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,436][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.8642e-01, 1.1883e-03, 9.7539e-02, 1.1770e-06, 5.3661e-05, 1.4854e-04,
        2.3970e-04, 7.8906e-07, 1.0887e-05, 1.7164e-06, 1.4339e-05, 1.7636e-03,
        1.4221e-04, 6.4523e-04, 9.4725e-03, 2.1337e-05, 2.2122e-03, 1.2662e-04],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,438][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ computer] are: tensor([0.0262, 0.2491, 0.1174, 0.0010, 0.0118, 0.0148, 0.0017, 0.0141, 0.0115,
        0.0231, 0.0074, 0.0519, 0.0850, 0.0300, 0.0643, 0.1252, 0.0582, 0.0880,
        0.0194], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,439][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ computer] are: tensor([0.0055, 0.0975, 0.0079, 0.0101, 0.0149, 0.1106, 0.0083, 0.0178, 0.0114,
        0.0206, 0.0814, 0.0409, 0.3430, 0.0265, 0.0451, 0.0165, 0.0260, 0.0990,
        0.0169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,439][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ computer] are: tensor([0.0471, 0.0353, 0.0665, 0.0009, 0.0516, 0.0144, 0.0653, 0.0038, 0.0090,
        0.0180, 0.0053, 0.0586, 0.2021, 0.3130, 0.0188, 0.0133, 0.0215, 0.0055,
        0.0500], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,440][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ computer] are: tensor([0.0267, 0.6693, 0.0250, 0.0024, 0.0287, 0.0052, 0.0033, 0.0008, 0.0008,
        0.0123, 0.0068, 0.0064, 0.0190, 0.0807, 0.0112, 0.0136, 0.0181, 0.0574,
        0.0121], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,441][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ computer] are: tensor([1.4590e-05, 2.3042e-03, 2.3910e-04, 3.1080e-04, 2.3704e-03, 5.1680e-03,
        3.3223e-04, 1.5896e-04, 4.7316e-03, 1.2154e-02, 2.0314e-02, 1.7914e-01,
        2.4932e-01, 1.5488e-01, 2.7929e-02, 3.0475e-02, 6.4990e-02, 6.6188e-02,
        1.7898e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,443][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ computer] are: tensor([6.1411e-05, 3.0400e-02, 4.2037e-03, 4.0352e-03, 1.0378e-02, 1.1188e-02,
        2.0688e-02, 8.2280e-03, 8.6979e-03, 1.3543e-02, 2.9672e-02, 1.4447e-01,
        2.3309e-01, 3.5081e-02, 1.7030e-01, 1.6565e-02, 1.1916e-01, 6.2240e-02,
        7.7995e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,445][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ computer] are: tensor([0.0201, 0.2123, 0.0350, 0.0028, 0.0025, 0.0503, 0.0508, 0.0080, 0.0140,
        0.0252, 0.0440, 0.0370, 0.0444, 0.0061, 0.1944, 0.0277, 0.0697, 0.0497,
        0.1061], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,446][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ computer] are: tensor([0.3366, 0.0723, 0.0620, 0.0134, 0.0484, 0.0273, 0.0221, 0.0174, 0.0163,
        0.0216, 0.0229, 0.0626, 0.0239, 0.0688, 0.0278, 0.0221, 0.0234, 0.0486,
        0.0624], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,448][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ computer] are: tensor([0.0045, 0.0926, 0.0677, 0.0307, 0.0167, 0.0400, 0.0862, 0.1352, 0.0467,
        0.0681, 0.0586, 0.0422, 0.0378, 0.0318, 0.0504, 0.0679, 0.0574, 0.0460,
        0.0194], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,450][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ computer] are: tensor([4.7926e-02, 7.6525e-04, 2.8315e-03, 3.5896e-04, 4.7664e-02, 1.0393e-02,
        1.2283e-02, 1.9176e-03, 1.6637e-02, 1.3130e-03, 1.7725e-03, 4.0271e-02,
        3.9501e-03, 5.3369e-01, 1.1281e-01, 6.7898e-03, 1.0023e-01, 3.7083e-03,
        5.4686e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,452][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ computer] are: tensor([0.3046, 0.0110, 0.0096, 0.0115, 0.0461, 0.0804, 0.0030, 0.0036, 0.0047,
        0.0052, 0.0146, 0.0237, 0.0607, 0.1944, 0.0401, 0.0204, 0.0133, 0.0579,
        0.0954], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,453][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ computer] are: tensor([9.9921e-01, 3.8575e-06, 5.7513e-04, 8.2212e-10, 1.0625e-07, 8.8941e-07,
        1.0713e-06, 5.5795e-10, 1.3438e-08, 1.3560e-09, 1.8574e-08, 6.9918e-06,
        3.2080e-07, 6.1463e-06, 3.1845e-05, 2.7405e-08, 3.2635e-06, 1.0511e-06,
        1.5536e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,455][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0128, 0.0486, 0.0181, 0.0009, 0.0067, 0.0067, 0.0021, 0.0275, 0.0223,
        0.0232, 0.0114, 0.0648, 0.0904, 0.0336, 0.0710, 0.1001, 0.0966, 0.0826,
        0.0176, 0.2630], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,456][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0116, 0.2187, 0.0136, 0.0345, 0.0089, 0.0544, 0.0055, 0.0251, 0.0194,
        0.0251, 0.0968, 0.0125, 0.3321, 0.0088, 0.0180, 0.0255, 0.0117, 0.0489,
        0.0078, 0.0213], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,457][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0099, 0.0132, 0.1736, 0.0028, 0.0789, 0.0032, 0.0299, 0.0039, 0.0221,
        0.0160, 0.0045, 0.0658, 0.1068, 0.3592, 0.0104, 0.0111, 0.0143, 0.0041,
        0.0564, 0.0138], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,458][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0008, 0.0715, 0.2634, 0.0071, 0.1026, 0.0130, 0.0291, 0.0026, 0.0220,
        0.0149, 0.0118, 0.1507, 0.0071, 0.0925, 0.0745, 0.0087, 0.0455, 0.0226,
        0.0497, 0.0098], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,458][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.8353e-06, 1.0575e-02, 6.5944e-04, 3.8448e-03, 2.9214e-03, 1.1130e-02,
        4.4392e-04, 4.6960e-04, 6.6277e-03, 4.0267e-02, 3.7995e-02, 6.5533e-02,
        4.9581e-01, 5.8426e-02, 1.0622e-02, 6.8933e-02, 2.4883e-02, 4.8841e-02,
        3.7056e-02, 7.4952e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,460][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.7223e-04, 1.0697e-01, 1.7441e-02, 6.6288e-03, 4.7800e-03, 4.0902e-03,
        6.9215e-03, 2.0178e-02, 8.0132e-03, 3.2140e-02, 5.5270e-02, 7.2399e-02,
        4.2454e-01, 1.8345e-02, 6.0906e-02, 2.3355e-02, 3.3095e-02, 6.5343e-02,
        1.2842e-02, 2.6573e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,462][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0224, 0.2194, 0.1296, 0.0193, 0.0045, 0.0639, 0.0492, 0.0188, 0.0269,
        0.0579, 0.0917, 0.0191, 0.0621, 0.0044, 0.0261, 0.0445, 0.0177, 0.0414,
        0.0177, 0.0636], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,464][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0952, 0.0891, 0.0784, 0.0263, 0.0562, 0.0493, 0.0294, 0.0335, 0.0295,
        0.0389, 0.0392, 0.0566, 0.0408, 0.0623, 0.0412, 0.0391, 0.0284, 0.0630,
        0.0546, 0.0491], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,466][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0495, 0.1060, 0.0898, 0.0316, 0.0340, 0.0295, 0.0607, 0.0766, 0.0375,
        0.0568, 0.0483, 0.0388, 0.0345, 0.0378, 0.0361, 0.0512, 0.0424, 0.0458,
        0.0280, 0.0651], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,468][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0003, 0.0022, 0.0039, 0.0018, 0.0984, 0.0389, 0.0126, 0.0018, 0.0161,
        0.0036, 0.0054, 0.0456, 0.0094, 0.2042, 0.1823, 0.0213, 0.2189, 0.0152,
        0.0815, 0.0367], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,470][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0564, 0.0155, 0.0045, 0.0091, 0.0281, 0.0445, 0.0034, 0.0115, 0.0037,
        0.0200, 0.0175, 0.0241, 0.0716, 0.1999, 0.0673, 0.0558, 0.0160, 0.0549,
        0.0478, 0.2482], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,471][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.9198e-01, 2.2996e-03, 1.7612e-01, 5.6003e-07, 3.0779e-05, 1.0251e-04,
        1.6319e-04, 4.8917e-07, 7.0792e-06, 5.9822e-07, 1.8552e-05, 2.7104e-03,
        1.3656e-04, 2.8933e-04, 6.3856e-03, 9.6597e-06, 1.0924e-03, 1.9260e-04,
        1.8392e-02, 6.9088e-05], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,587][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:49,588][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,589][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,590][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,591][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,592][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,592][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,594][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,595][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,596][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,598][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,599][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,601][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:49,603][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0139, 0.9861], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,604][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,605][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([3.5610e-04, 9.9964e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,606][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0031, 0.9969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,606][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([2.9964e-04, 9.9970e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,607][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([5.9799e-04, 9.9940e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,608][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,609][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0042, 0.9958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,611][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0946, 0.9054], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,612][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([6.4366e-04, 9.9936e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,613][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1452, 0.8548], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,615][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([7.9581e-04, 9.9920e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:49,617][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Katie] are: tensor([0.0029, 0.6298, 0.3672], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,619][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Katie] are: tensor([0.0017, 0.8692, 0.1292], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,620][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Katie] are: tensor([7.9271e-04, 9.5676e-01, 4.2443e-02], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,621][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Katie] are: tensor([0.0018, 0.9770, 0.0213], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,622][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Katie] are: tensor([0.0010, 0.5777, 0.4212], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,623][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Katie] are: tensor([1.6078e-04, 7.1515e-01, 2.8469e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,623][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Katie] are: tensor([0.0016, 0.5977, 0.4007], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,624][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Katie] are: tensor([0.0008, 0.6016, 0.3977], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,625][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Katie] are: tensor([8.9307e-05, 7.4831e-01, 2.5160e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,625][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Katie] are: tensor([5.3657e-04, 7.7765e-01, 2.2181e-01], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,627][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Katie] are: tensor([0.6883, 0.2603, 0.0514], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,629][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Katie] are: tensor([0.0094, 0.5889, 0.4018], device='cuda:0') for source tokens [Then, Katie]
[2024-07-24 10:18:49,631][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0028, 0.6670, 0.2904, 0.0399], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,632][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0299, 0.8253, 0.1027, 0.0420], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,634][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0036, 0.8368, 0.0501, 0.1095], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,636][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.1626e-04, 9.1509e-01, 7.6013e-02, 8.6756e-03], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,637][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.0741e-04, 6.3928e-01, 2.2301e-01, 1.3710e-01], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,638][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0010, 0.7869, 0.1779, 0.0341], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,639][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0090, 0.6058, 0.3709, 0.0144], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,640][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0173, 0.6363, 0.2920, 0.0545], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,641][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0145, 0.1551, 0.1273, 0.7032], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,641][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0144, 0.8249, 0.0938, 0.0670], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,642][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.8876, 0.0510, 0.0174, 0.0439], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,643][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0009, 0.5782, 0.2483, 0.1726], device='cuda:0') for source tokens [Then, Katie and]
[2024-07-24 10:18:49,645][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0352, 0.6476, 0.1467, 0.0235, 0.1469], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,647][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0016, 0.8377, 0.0683, 0.0598, 0.0326], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,648][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([8.3811e-04, 8.8779e-01, 1.0299e-02, 8.3098e-02, 1.7979e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,649][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([5.7664e-04, 9.4896e-01, 1.5026e-02, 2.1803e-03, 3.3260e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,651][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([0.0008, 0.5952, 0.1258, 0.1067, 0.1715], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,652][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([5.3507e-04, 5.8265e-01, 3.3472e-01, 4.1409e-02, 4.0693e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,654][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0158, 0.5409, 0.4145, 0.0227, 0.0062], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,656][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0017, 0.6619, 0.2455, 0.0673, 0.0236], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,656][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([2.1856e-04, 3.9113e-01, 5.7483e-02, 3.8466e-01, 1.6651e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,657][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0118, 0.7416, 0.1298, 0.1117, 0.0050], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,658][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.7994, 0.1180, 0.0225, 0.0409, 0.0191], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,658][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0094, 0.5506, 0.2601, 0.0618, 0.1181], device='cuda:0') for source tokens [Then, Katie and Patrick]
[2024-07-24 10:18:49,659][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0151, 0.6160, 0.2249, 0.0117, 0.0860, 0.0464], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,661][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0524, 0.6072, 0.0602, 0.0340, 0.0233, 0.2227], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,663][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0213, 0.8794, 0.0188, 0.0380, 0.0076, 0.0348], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,665][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0037, 0.7814, 0.0136, 0.0051, 0.0716, 0.1246], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,666][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0007, 0.3866, 0.0750, 0.0647, 0.1799, 0.2931], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,668][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0022, 0.6910, 0.1986, 0.0399, 0.0237, 0.0445], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,670][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0629, 0.5850, 0.2972, 0.0105, 0.0032, 0.0413], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,672][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0279, 0.6020, 0.2504, 0.0308, 0.0148, 0.0741], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,673][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([6.0200e-05, 6.5254e-02, 2.1517e-02, 3.6056e-01, 4.2366e-02, 5.1024e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,674][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0464, 0.7658, 0.0781, 0.0349, 0.0026, 0.0722], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,674][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.7703, 0.0258, 0.0033, 0.0099, 0.0037, 0.1869], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,675][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0181, 0.2019, 0.0782, 0.0398, 0.0533, 0.6086], device='cuda:0') for source tokens [Then, Katie and Patrick were]
[2024-07-24 10:18:49,676][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0122, 0.7230, 0.1491, 0.0089, 0.0501, 0.0434, 0.0133],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,677][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0071, 0.7219, 0.0272, 0.0277, 0.0160, 0.1694, 0.0308],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,679][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0079, 0.8337, 0.0068, 0.0448, 0.0052, 0.0735, 0.0280],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,680][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([8.1045e-04, 9.2930e-01, 1.3624e-03, 1.2247e-03, 1.1024e-02, 4.6502e-02,
        9.7800e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,682][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0010, 0.4122, 0.0453, 0.0440, 0.1555, 0.3212, 0.0209],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,683][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([4.1871e-04, 6.6894e-01, 7.5555e-02, 3.7828e-02, 2.7561e-02, 9.3632e-02,
        9.6068e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,684][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0179, 0.6251, 0.1735, 0.0130, 0.0051, 0.0977, 0.0677],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,686][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0266, 0.3986, 0.1654, 0.0368, 0.0116, 0.1260, 0.2350],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,688][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([1.8940e-05, 7.9602e-02, 5.2827e-03, 2.2308e-01, 1.6732e-02, 6.1296e-01,
        6.2324e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,689][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0026, 0.6266, 0.0338, 0.0498, 0.0042, 0.1956, 0.0874],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,690][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.5257, 0.1126, 0.0032, 0.0158, 0.0065, 0.3022, 0.0340],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,691][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0194, 0.4019, 0.0154, 0.0188, 0.0098, 0.4172, 0.1175],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking]
[2024-07-24 10:18:49,692][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0059, 0.4093, 0.2447, 0.0142, 0.0990, 0.0466, 0.0224, 0.1579],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,693][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0069, 0.4862, 0.0607, 0.0401, 0.0471, 0.2394, 0.0411, 0.0785],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,693][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0076, 0.6595, 0.0106, 0.0607, 0.0129, 0.0993, 0.0620, 0.0874],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,694][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([7.1952e-05, 5.4781e-01, 9.0221e-03, 7.2991e-03, 1.0972e-01, 1.9580e-01,
        1.2996e-01, 3.1344e-04], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,696][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0008, 0.3778, 0.0297, 0.0875, 0.1820, 0.2900, 0.0176, 0.0145],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,698][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([1.1406e-04, 4.5251e-01, 1.3628e-01, 3.6321e-02, 4.6445e-02, 5.7216e-02,
        1.4156e-01, 1.2956e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,699][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0056, 0.5914, 0.1481, 0.0267, 0.0076, 0.1118, 0.0697, 0.0391],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,701][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0025, 0.2696, 0.1915, 0.0486, 0.0203, 0.1366, 0.1814, 0.1495],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,702][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([2.8655e-06, 6.7348e-02, 1.4054e-02, 2.6893e-01, 2.2599e-02, 5.0397e-01,
        1.1009e-01, 1.3007e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,705][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0012, 0.4077, 0.0974, 0.0675, 0.0068, 0.1628, 0.2055, 0.0511],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,706][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0375, 0.0854, 0.0138, 0.0309, 0.0342, 0.4944, 0.1842, 0.1197],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,707][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0014, 0.3230, 0.0531, 0.0397, 0.0240, 0.2210, 0.2791, 0.0587],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about]
[2024-07-24 10:18:49,708][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0093, 0.5178, 0.0767, 0.0099, 0.0474, 0.0362, 0.0317, 0.1158, 0.1550],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,709][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0058, 0.6462, 0.0240, 0.0417, 0.0307, 0.1458, 0.0265, 0.0368, 0.0425],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,710][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0020, 0.6795, 0.0058, 0.0715, 0.0174, 0.0755, 0.0446, 0.0418, 0.0619],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,711][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([1.6183e-04, 8.7201e-01, 4.8103e-03, 3.5097e-03, 3.9286e-02, 5.8716e-02,
        1.8551e-02, 1.5174e-04, 2.8000e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,712][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([1.2047e-04, 2.9304e-01, 2.8520e-02, 5.5288e-02, 2.1709e-01, 2.3864e-01,
        1.1022e-02, 8.7379e-03, 1.4755e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,714][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0010, 0.5135, 0.0995, 0.0399, 0.0386, 0.0475, 0.0831, 0.1039, 0.0730],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,715][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0057, 0.5484, 0.1778, 0.0209, 0.0093, 0.0852, 0.0952, 0.0258, 0.0317],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,717][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0024, 0.3088, 0.0871, 0.0396, 0.0163, 0.0942, 0.0929, 0.0773, 0.2814],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,718][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0020, 0.1233, 0.0137, 0.1759, 0.0281, 0.3503, 0.0843, 0.1147, 0.1076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,720][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0158, 0.4100, 0.0404, 0.0331, 0.0071, 0.1162, 0.1161, 0.0590, 0.2023],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,722][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.2207, 0.1511, 0.0062, 0.0215, 0.0137, 0.4136, 0.0836, 0.0295, 0.0602],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,724][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0013, 0.2470, 0.0207, 0.0501, 0.0299, 0.4000, 0.1492, 0.0699, 0.0318],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going]
[2024-07-24 10:18:49,725][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0156, 0.2478, 0.1190, 0.0111, 0.0837, 0.0361, 0.0175, 0.1360, 0.1771,
        0.1563], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,726][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0025, 0.5912, 0.0449, 0.0827, 0.0262, 0.1325, 0.0115, 0.0448, 0.0289,
        0.0349], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,726][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0012, 0.5141, 0.0106, 0.0941, 0.0234, 0.0783, 0.0310, 0.0610, 0.0679,
        0.1185], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,727][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.3397e-04, 6.8506e-01, 1.0054e-02, 8.7040e-03, 7.9028e-02, 1.3974e-01,
        2.4270e-02, 4.0169e-04, 1.7881e-02, 3.4226e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,728][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.9125e-05, 1.9805e-01, 2.2248e-02, 6.6510e-02, 7.4730e-02, 1.2414e-01,
        5.4282e-03, 5.1442e-03, 6.5776e-02, 4.3794e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,729][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([3.1263e-04, 4.9224e-01, 1.4343e-01, 3.4539e-02, 3.3020e-02, 2.4575e-02,
        4.2516e-02, 8.2770e-02, 4.1702e-02, 1.0490e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,731][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0030, 0.4326, 0.2777, 0.0377, 0.0100, 0.0747, 0.0658, 0.0174, 0.0206,
        0.0606], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,732][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0020, 0.1315, 0.0686, 0.0301, 0.0090, 0.0402, 0.0408, 0.0445, 0.1251,
        0.5082], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,734][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0165, 0.0279, 0.0167, 0.0931, 0.0158, 0.2386, 0.0411, 0.1084, 0.0616,
        0.3803], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,736][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0098, 0.4883, 0.0988, 0.0480, 0.0039, 0.0628, 0.0859, 0.0412, 0.1376,
        0.0236], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,738][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2625, 0.0819, 0.0169, 0.0223, 0.0225, 0.3428, 0.0768, 0.0284, 0.0291,
        0.1169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,740][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0025, 0.4457, 0.0370, 0.0347, 0.0177, 0.1728, 0.0675, 0.0417, 0.0413,
        0.1391], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to]
[2024-07-24 10:18:49,741][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0147, 0.2986, 0.0886, 0.0060, 0.0374, 0.0284, 0.0123, 0.1275, 0.1481,
        0.1421, 0.0963], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,742][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0065, 0.4678, 0.0245, 0.0356, 0.0150, 0.1387, 0.0161, 0.0391, 0.0343,
        0.0355, 0.1868], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,743][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0018, 0.4833, 0.0065, 0.0524, 0.0125, 0.0558, 0.0206, 0.0393, 0.0412,
        0.1077, 0.1790], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,744][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([4.0781e-04, 7.4706e-01, 1.0436e-02, 3.6281e-03, 6.1059e-02, 1.1722e-01,
        2.5467e-02, 1.3357e-04, 8.1741e-03, 1.7452e-02, 8.9606e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,744][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([5.7290e-05, 1.2940e-01, 7.8032e-03, 3.4004e-02, 3.6164e-02, 1.1749e-01,
        3.4070e-03, 3.4946e-03, 5.3188e-02, 3.2878e-01, 2.8621e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,745][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0004, 0.3363, 0.0696, 0.0229, 0.0136, 0.0255, 0.0637, 0.0791, 0.0553,
        0.0997, 0.2338], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,747][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0083, 0.4840, 0.2190, 0.0172, 0.0037, 0.0600, 0.0638, 0.0119, 0.0135,
        0.0521, 0.0664], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,749][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0009, 0.1016, 0.0299, 0.0158, 0.0032, 0.0350, 0.0372, 0.0239, 0.0877,
        0.2979, 0.3670], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,751][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0049, 0.0177, 0.0073, 0.0603, 0.0047, 0.2221, 0.0336, 0.0506, 0.0488,
        0.2213, 0.3288], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,752][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0162, 0.4110, 0.0334, 0.0309, 0.0011, 0.0574, 0.0757, 0.0534, 0.1540,
        0.0242, 0.1426], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,755][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1982, 0.0388, 0.0067, 0.0097, 0.0095, 0.2394, 0.0584, 0.0155, 0.0219,
        0.0661, 0.3357], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,757][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0008, 0.2250, 0.0197, 0.0249, 0.0162, 0.2022, 0.0848, 0.0358, 0.0253,
        0.1122, 0.2531], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the]
[2024-07-24 10:18:49,758][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ school] are: tensor([0.1130, 0.2404, 0.1675, 0.0029, 0.0235, 0.0342, 0.0052, 0.0771, 0.0447,
        0.0841, 0.0403, 0.1671], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,759][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ school] are: tensor([0.0255, 0.4880, 0.0359, 0.0263, 0.0152, 0.1372, 0.0090, 0.0242, 0.0144,
        0.0424, 0.1476, 0.0342], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,760][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ school] are: tensor([0.0114, 0.5038, 0.0016, 0.0221, 0.0047, 0.0517, 0.0099, 0.0317, 0.0379,
        0.1012, 0.1963, 0.0276], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,761][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ school] are: tensor([1.0773e-02, 8.6697e-01, 1.6141e-03, 2.7549e-04, 4.2639e-03, 3.0242e-02,
        8.1174e-04, 1.0530e-05, 3.2238e-04, 2.7369e-03, 8.1981e-04, 8.1157e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,762][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ school] are: tensor([2.6131e-04, 8.3295e-02, 6.2711e-03, 8.6639e-03, 2.5422e-02, 4.3434e-02,
        1.1359e-03, 1.0803e-03, 1.8742e-02, 1.1927e-01, 1.3812e-01, 5.5431e-01],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,762][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ school] are: tensor([0.0015, 0.3780, 0.0733, 0.0086, 0.0147, 0.0157, 0.0398, 0.0452, 0.0193,
        0.0367, 0.0795, 0.2879], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,765][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ school] are: tensor([0.0345, 0.6714, 0.1517, 0.0082, 0.0022, 0.0359, 0.0242, 0.0057, 0.0077,
        0.0223, 0.0262, 0.0101], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,767][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ school] are: tensor([0.0031, 0.2643, 0.0580, 0.0202, 0.0056, 0.0376, 0.0351, 0.0186, 0.0699,
        0.2604, 0.1927, 0.0344], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,768][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ school] are: tensor([0.0024, 0.0963, 0.0093, 0.0362, 0.0033, 0.1800, 0.0120, 0.0187, 0.0292,
        0.2541, 0.2156, 0.1430], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,770][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ school] are: tensor([0.0259, 0.4661, 0.0288, 0.0269, 0.0014, 0.0578, 0.0933, 0.0194, 0.1238,
        0.0241, 0.0850, 0.0475], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,772][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ school] are: tensor([0.8166, 0.0382, 0.0020, 0.0014, 0.0012, 0.0483, 0.0016, 0.0023, 0.0029,
        0.0221, 0.0544, 0.0089], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,774][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ school] are: tensor([0.1120, 0.5151, 0.0182, 0.0073, 0.0028, 0.0848, 0.0207, 0.0187, 0.0062,
        0.0574, 0.0967, 0.0600], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school]
[2024-07-24 10:18:49,775][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0606, 0.2106, 0.1185, 0.0034, 0.0151, 0.0250, 0.0067, 0.0877, 0.0540,
        0.0865, 0.0472, 0.0906, 0.1941], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,776][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0186, 0.3811, 0.0233, 0.0253, 0.0047, 0.0675, 0.0074, 0.0242, 0.0101,
        0.0215, 0.0929, 0.0086, 0.3147], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,777][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0041, 0.3086, 0.0019, 0.0109, 0.0017, 0.0151, 0.0067, 0.0164, 0.0131,
        0.0276, 0.0551, 0.0137, 0.5251], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,778][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.0197e-02, 7.0555e-01, 2.8932e-03, 1.8764e-03, 8.9116e-03, 6.6796e-02,
        4.6058e-03, 1.2893e-04, 3.2088e-03, 1.1484e-02, 5.3133e-03, 9.1462e-02,
        8.7574e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,779][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([7.9482e-05, 2.5914e-02, 2.0645e-03, 5.1529e-03, 5.7369e-03, 1.9615e-02,
        6.0113e-04, 5.8463e-04, 7.6249e-03, 4.8143e-02, 3.7151e-02, 9.8508e-02,
        7.4882e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,780][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0015, 0.2458, 0.1021, 0.0086, 0.0076, 0.0073, 0.0331, 0.0285, 0.0172,
        0.0242, 0.0451, 0.0794, 0.3997], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,782][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0232, 0.5192, 0.3169, 0.0085, 0.0019, 0.0232, 0.0278, 0.0062, 0.0056,
        0.0223, 0.0179, 0.0047, 0.0227], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,784][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0047, 0.1856, 0.0378, 0.0130, 0.0029, 0.0184, 0.0198, 0.0276, 0.0325,
        0.1713, 0.1547, 0.0136, 0.3181], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,785][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0075, 0.0183, 0.0055, 0.0360, 0.0020, 0.1116, 0.0102, 0.0338, 0.0243,
        0.1519, 0.1582, 0.0454, 0.3951], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,787][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.1197e-02, 5.4203e-01, 3.4922e-02, 2.2398e-02, 4.7693e-04, 3.1577e-02,
        6.4151e-02, 3.6021e-02, 5.6526e-02, 1.7739e-02, 5.8078e-02, 8.4926e-03,
        8.6391e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,789][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7874, 0.0182, 0.0031, 0.0027, 0.0009, 0.0458, 0.0036, 0.0035, 0.0026,
        0.0094, 0.0341, 0.0026, 0.0861], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,790][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0307, 0.2827, 0.0206, 0.0103, 0.0027, 0.0376, 0.0131, 0.0137, 0.0050,
        0.0292, 0.0687, 0.0451, 0.4406], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school.]
[2024-07-24 10:18:49,792][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Patrick] are: tensor([0.0463, 0.1635, 0.0356, 0.0012, 0.0098, 0.0146, 0.0037, 0.0294, 0.0168,
        0.0534, 0.0210, 0.1848, 0.3487, 0.0711], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,793][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Patrick] are: tensor([0.0024, 0.2497, 0.0085, 0.0127, 0.0097, 0.1232, 0.0062, 0.0124, 0.0089,
        0.0215, 0.0795, 0.0260, 0.4251, 0.0142], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,794][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Patrick] are: tensor([9.8575e-04, 1.4981e-01, 4.2279e-04, 3.3573e-03, 1.4701e-03, 1.0905e-02,
        4.0068e-03, 6.2429e-03, 8.2989e-03, 1.6616e-02, 3.8964e-02, 1.0383e-02,
        7.2435e-01, 2.4183e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,795][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Patrick] are: tensor([6.3215e-03, 7.2991e-01, 1.8832e-03, 2.1205e-04, 2.8288e-03, 1.7093e-02,
        1.2424e-03, 2.6413e-06, 3.3883e-04, 1.2640e-03, 4.8394e-04, 1.1708e-01,
        5.5547e-02, 6.5786e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,796][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Patrick] are: tensor([5.1612e-05, 7.3739e-03, 3.2269e-04, 7.1399e-04, 2.0847e-03, 8.3856e-03,
        3.6593e-04, 2.2986e-04, 4.4650e-03, 2.5415e-02, 3.2210e-02, 1.5666e-01,
        6.3976e-01, 1.2197e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,797][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Patrick] are: tensor([8.4276e-05, 4.0634e-02, 2.3748e-02, 3.6289e-03, 8.1075e-03, 8.1542e-03,
        1.9943e-02, 1.5098e-02, 1.3375e-02, 1.3050e-02, 4.4740e-02, 1.6575e-01,
        6.1233e-01, 3.1354e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,798][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Patrick] are: tensor([0.0807, 0.4701, 0.1149, 0.0098, 0.0037, 0.0644, 0.0405, 0.0074, 0.0130,
        0.0396, 0.0414, 0.0203, 0.0885, 0.0057], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,800][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Patrick] are: tensor([0.0004, 0.0876, 0.0112, 0.0077, 0.0028, 0.0180, 0.0135, 0.0116, 0.0465,
        0.1654, 0.1536, 0.0272, 0.4438, 0.0109], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,801][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Patrick] are: tensor([1.8881e-06, 6.9275e-02, 2.1576e-03, 1.5871e-02, 2.8553e-03, 4.6074e-02,
        6.3399e-03, 3.3646e-03, 2.2839e-02, 1.1139e-01, 1.3051e-01, 7.5037e-02,
        4.8783e-01, 2.6453e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,803][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Patrick] are: tensor([0.0073, 0.1621, 0.0176, 0.0178, 0.0020, 0.0763, 0.1364, 0.0291, 0.1348,
        0.0139, 0.0966, 0.0794, 0.2086, 0.0181], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,804][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Patrick] are: tensor([0.2842, 0.0785, 0.0089, 0.0029, 0.0043, 0.1306, 0.0120, 0.0036, 0.0094,
        0.0137, 0.0769, 0.0285, 0.3168, 0.0297], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,807][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Patrick] are: tensor([0.0250, 0.0952, 0.0106, 0.0010, 0.0013, 0.0287, 0.0144, 0.0038, 0.0056,
        0.0121, 0.0291, 0.1086, 0.6067, 0.0579], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick]
[2024-07-24 10:18:49,808][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0526, 0.2388, 0.1105, 0.0019, 0.0157, 0.0174, 0.0030, 0.0175, 0.0166,
        0.0359, 0.0136, 0.0711, 0.1885, 0.0489, 0.1682], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,810][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0082, 0.1567, 0.0102, 0.0065, 0.0088, 0.0653, 0.0082, 0.0124, 0.0128,
        0.0236, 0.0727, 0.0340, 0.5134, 0.0257, 0.0416], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,811][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0496, 0.1566, 0.0006, 0.0027, 0.0007, 0.0152, 0.0059, 0.0075, 0.0136,
        0.0202, 0.0594, 0.0230, 0.5558, 0.0174, 0.0718], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,812][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([1.2289e-02, 5.0157e-01, 3.1574e-04, 6.2521e-05, 3.8872e-04, 6.2723e-03,
        5.9311e-04, 1.6929e-06, 1.3290e-04, 6.5649e-04, 2.9606e-04, 5.0437e-02,
        4.1011e-02, 1.6526e-02, 3.6945e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,813][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([6.3618e-05, 4.8129e-03, 2.9810e-04, 6.8637e-04, 2.6684e-03, 1.0190e-02,
        3.9653e-04, 2.2337e-04, 5.5595e-03, 2.6564e-02, 3.2381e-02, 1.4025e-01,
        5.6460e-01, 1.7581e-01, 3.5494e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,813][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([3.3046e-04, 8.4513e-02, 1.0527e-02, 3.5681e-03, 3.8415e-03, 1.0047e-02,
        2.3598e-02, 2.2113e-02, 1.7948e-02, 3.4972e-02, 7.7573e-02, 9.0928e-02,
        3.9782e-01, 2.1763e-02, 2.0046e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,815][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0731, 0.3214, 0.0639, 0.0034, 0.0025, 0.0593, 0.0523, 0.0109, 0.0188,
        0.0427, 0.0523, 0.0308, 0.0778, 0.0066, 0.1843], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,817][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0039, 0.0325, 0.0058, 0.0031, 0.0007, 0.0129, 0.0138, 0.0088, 0.0381,
        0.1466, 0.1488, 0.0135, 0.3634, 0.0055, 0.2026], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,818][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([3.4010e-05, 2.5369e-02, 2.5816e-03, 8.7065e-03, 1.1956e-03, 5.6487e-02,
        4.4603e-03, 1.2990e-03, 1.4207e-02, 5.4187e-02, 7.8939e-02, 5.3770e-02,
        2.6799e-01, 1.4894e-02, 4.1588e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,820][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0165, 0.1463, 0.0131, 0.0070, 0.0011, 0.0702, 0.1148, 0.0147, 0.1016,
        0.0131, 0.0481, 0.0562, 0.0928, 0.0105, 0.2940], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,821][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([7.3292e-01, 4.7060e-02, 1.5049e-03, 5.2701e-04, 1.0935e-03, 3.1938e-02,
        2.3865e-03, 9.5014e-04, 1.6039e-03, 5.8449e-03, 1.9507e-02, 6.1984e-03,
        1.0596e-01, 8.2819e-03, 3.4217e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,823][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([1.5928e-01, 1.2005e-01, 5.7262e-03, 7.4231e-04, 4.0501e-04, 2.5178e-02,
        8.1562e-03, 3.3707e-03, 2.1928e-03, 9.4520e-03, 2.3543e-02, 6.5700e-02,
        4.2986e-01, 2.0129e-02, 1.2621e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted]
[2024-07-24 10:18:49,825][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0137, 0.0860, 0.0340, 0.0021, 0.0141, 0.0112, 0.0040, 0.0420, 0.0376,
        0.0424, 0.0229, 0.1183, 0.1878, 0.0584, 0.1421, 0.1834],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,827][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0044, 0.2907, 0.0196, 0.0391, 0.0124, 0.0717, 0.0070, 0.0294, 0.0180,
        0.0276, 0.0949, 0.0104, 0.3191, 0.0095, 0.0191, 0.0271],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,828][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0020, 0.1327, 0.0012, 0.0119, 0.0036, 0.0178, 0.0064, 0.0148, 0.0169,
        0.0262, 0.0569, 0.0131, 0.5975, 0.0465, 0.0328, 0.0198],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,828][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.5725e-04, 3.3862e-01, 2.7124e-03, 1.5174e-03, 9.2754e-03, 3.4532e-02,
        3.3564e-03, 6.3327e-05, 2.2482e-03, 5.5286e-03, 2.8922e-03, 8.8267e-02,
        4.3649e-02, 5.5990e-02, 4.0363e-01, 6.8645e-03], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,829][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7219e-06, 1.5013e-02, 1.1321e-03, 4.5703e-03, 4.8572e-03, 1.5212e-02,
        5.4702e-04, 5.3262e-04, 7.4135e-03, 4.8336e-02, 3.9845e-02, 8.1700e-02,
        5.9309e-01, 9.1958e-02, 1.3759e-02, 8.2020e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,830][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.8345e-04, 1.3187e-01, 3.3292e-02, 8.4901e-03, 8.2540e-03, 6.0245e-03,
        1.2030e-02, 2.2949e-02, 1.2206e-02, 3.6736e-02, 6.9474e-02, 7.9198e-02,
        4.5288e-01, 2.4227e-02, 7.5602e-02, 2.6584e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,831][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0130, 0.2947, 0.2000, 0.0219, 0.0071, 0.0786, 0.0611, 0.0197, 0.0215,
        0.0618, 0.0718, 0.0172, 0.0547, 0.0052, 0.0273, 0.0446],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,833][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0009, 0.0292, 0.0085, 0.0078, 0.0017, 0.0143, 0.0119, 0.0159, 0.0437,
        0.1869, 0.1509, 0.0117, 0.2549, 0.0051, 0.0948, 0.1618],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,835][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0099, 0.0087, 0.0040, 0.0166, 0.0022, 0.0541, 0.0052, 0.0184, 0.0108,
        0.0750, 0.1020, 0.0558, 0.2286, 0.0303, 0.1997, 0.1788],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,837][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0180, 0.3540, 0.0439, 0.0300, 0.0013, 0.0525, 0.0778, 0.0398, 0.1155,
        0.0294, 0.0820, 0.0324, 0.0752, 0.0027, 0.0330, 0.0124],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,839][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3329, 0.0372, 0.0066, 0.0045, 0.0059, 0.0875, 0.0170, 0.0126, 0.0069,
        0.0258, 0.0898, 0.0244, 0.1339, 0.0373, 0.1294, 0.0483],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,840][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0041, 0.1788, 0.0121, 0.0053, 0.0023, 0.0381, 0.0121, 0.0081, 0.0070,
        0.0227, 0.0954, 0.0580, 0.3828, 0.0195, 0.1055, 0.0482],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to]
[2024-07-24 10:18:49,840][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0644, 0.1863, 0.0551, 0.0008, 0.0085, 0.0096, 0.0016, 0.0108, 0.0117,
        0.0271, 0.0085, 0.0886, 0.1336, 0.0364, 0.0977, 0.1518, 0.1076],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,842][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0365, 0.1855, 0.0102, 0.0062, 0.0043, 0.0478, 0.0031, 0.0092, 0.0065,
        0.0212, 0.0702, 0.0166, 0.4931, 0.0114, 0.0354, 0.0259, 0.0167],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,843][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([2.9608e-02, 1.2665e-01, 3.9515e-04, 3.9683e-03, 1.2329e-03, 9.2054e-03,
        2.3041e-03, 5.3733e-03, 8.9015e-03, 1.4067e-02, 4.5940e-02, 1.6710e-02,
        6.5095e-01, 2.1637e-02, 3.8442e-02, 2.0263e-02, 4.3532e-03],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,845][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([7.2970e-03, 7.1770e-01, 4.6496e-04, 1.2653e-04, 6.9804e-04, 8.8369e-03,
        5.3013e-04, 2.3008e-06, 1.2441e-04, 6.9389e-04, 2.5389e-04, 2.2049e-02,
        2.6455e-02, 1.3245e-02, 1.8237e-01, 2.2736e-03, 1.6875e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,846][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([3.3628e-05, 9.3381e-03, 5.0372e-04, 8.8582e-04, 3.2477e-03, 8.6502e-03,
        2.0008e-04, 1.7188e-04, 4.2015e-03, 2.4788e-02, 2.9293e-02, 1.1225e-01,
        5.5430e-01, 1.4722e-01, 1.6269e-02, 6.1277e-02, 2.7366e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,847][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0009, 0.1040, 0.0169, 0.0034, 0.0043, 0.0067, 0.0187, 0.0254, 0.0140,
        0.0232, 0.0625, 0.0778, 0.3320, 0.0198, 0.1910, 0.0297, 0.0697],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,848][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.2622, 0.2966, 0.1301, 0.0031, 0.0015, 0.0340, 0.0336, 0.0063, 0.0086,
        0.0250, 0.0327, 0.0146, 0.0357, 0.0027, 0.0640, 0.0292, 0.0201],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,849][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0025, 0.0606, 0.0070, 0.0053, 0.0010, 0.0160, 0.0125, 0.0062, 0.0274,
        0.0910, 0.0981, 0.0123, 0.3077, 0.0045, 0.1736, 0.1460, 0.0285],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,849][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0025, 0.0163, 0.0012, 0.0067, 0.0005, 0.0452, 0.0016, 0.0031, 0.0048,
        0.0368, 0.0605, 0.0564, 0.3196, 0.0113, 0.1676, 0.1441, 0.1219],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,850][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0650, 0.2409, 0.0136, 0.0125, 0.0005, 0.0356, 0.1057, 0.0265, 0.0724,
        0.0144, 0.0734, 0.0341, 0.0955, 0.0029, 0.1837, 0.0125, 0.0107],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,853][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.6194, 0.0688, 0.0017, 0.0007, 0.0012, 0.0232, 0.0015, 0.0008, 0.0020,
        0.0068, 0.0357, 0.0064, 0.1445, 0.0122, 0.0445, 0.0190, 0.0117],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,855][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1039, 0.1998, 0.0031, 0.0012, 0.0005, 0.0222, 0.0068, 0.0039, 0.0026,
        0.0148, 0.0416, 0.0293, 0.3111, 0.0174, 0.1290, 0.0694, 0.0435],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give]
[2024-07-24 10:18:49,856][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0124, 0.1078, 0.0323, 0.0009, 0.0082, 0.0069, 0.0029, 0.0281, 0.0215,
        0.0255, 0.0166, 0.0980, 0.0895, 0.0305, 0.1062, 0.1323, 0.1701, 0.1103],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,858][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0100, 0.2477, 0.0150, 0.0204, 0.0085, 0.0659, 0.0093, 0.0260, 0.0183,
        0.0202, 0.1116, 0.0125, 0.2919, 0.0092, 0.0220, 0.0203, 0.0148, 0.0764],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,860][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0029, 0.1307, 0.0010, 0.0070, 0.0023, 0.0096, 0.0044, 0.0116, 0.0122,
        0.0219, 0.0493, 0.0163, 0.4999, 0.0443, 0.0621, 0.0246, 0.0095, 0.0904],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,861][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1851e-03, 2.8525e-01, 1.3118e-03, 5.8000e-04, 5.6429e-03, 2.9824e-02,
        3.0639e-03, 2.6772e-05, 1.2652e-03, 2.9497e-03, 1.5793e-03, 5.9415e-02,
        3.6966e-02, 5.5868e-02, 4.1970e-01, 6.2547e-03, 7.6737e-02, 1.2387e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,863][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.3533e-05, 9.3412e-03, 5.4841e-04, 2.3350e-03, 2.8530e-03, 1.2219e-02,
        2.7896e-04, 3.0832e-04, 6.2914e-03, 3.1869e-02, 3.4325e-02, 7.6893e-02,
        5.3657e-01, 1.0852e-01, 1.1439e-02, 8.1181e-02, 2.5168e-02, 5.9838e-02],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,864][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0004, 0.1189, 0.0329, 0.0067, 0.0053, 0.0054, 0.0231, 0.0267, 0.0201,
        0.0255, 0.0619, 0.0651, 0.3193, 0.0150, 0.1063, 0.0205, 0.0467, 0.1002],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,865][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0478, 0.3165, 0.1671, 0.0113, 0.0029, 0.0494, 0.0563, 0.0173, 0.0181,
        0.0424, 0.0617, 0.0092, 0.0478, 0.0034, 0.0463, 0.0437, 0.0212, 0.0376],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,866][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0017, 0.0516, 0.0116, 0.0077, 0.0016, 0.0157, 0.0130, 0.0166, 0.0401,
        0.0981, 0.1427, 0.0117, 0.1355, 0.0059, 0.1125, 0.1321, 0.0277, 0.1740],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,867][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0028, 0.0125, 0.0019, 0.0166, 0.0008, 0.0418, 0.0031, 0.0099, 0.0091,
        0.0635, 0.0819, 0.0138, 0.2413, 0.0085, 0.0831, 0.1972, 0.0634, 0.1486],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,868][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0536, 0.3321, 0.0251, 0.0142, 0.0007, 0.0335, 0.0659, 0.0348, 0.0924,
        0.0106, 0.0797, 0.0309, 0.0563, 0.0036, 0.0946, 0.0056, 0.0077, 0.0586],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,870][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1942, 0.0346, 0.0019, 0.0033, 0.0019, 0.0682, 0.0094, 0.0061, 0.0078,
        0.0228, 0.1274, 0.0081, 0.1438, 0.0140, 0.0872, 0.0468, 0.0132, 0.2093],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,872][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0018, 0.0549, 0.0035, 0.0037, 0.0013, 0.0406, 0.0121, 0.0090, 0.0053,
        0.0211, 0.0686, 0.0273, 0.3050, 0.0209, 0.1276, 0.0481, 0.0655, 0.1835],
       device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a]
[2024-07-24 10:18:49,874][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ computer] are: tensor([0.0262, 0.2491, 0.1174, 0.0010, 0.0118, 0.0148, 0.0017, 0.0141, 0.0115,
        0.0231, 0.0074, 0.0519, 0.0850, 0.0300, 0.0643, 0.1252, 0.0582, 0.0880,
        0.0194], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,876][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ computer] are: tensor([0.0055, 0.0975, 0.0079, 0.0101, 0.0149, 0.1106, 0.0083, 0.0178, 0.0114,
        0.0206, 0.0814, 0.0409, 0.3430, 0.0265, 0.0451, 0.0165, 0.0260, 0.0990,
        0.0169], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,878][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ computer] are: tensor([0.0059, 0.0888, 0.0007, 0.0035, 0.0020, 0.0212, 0.0093, 0.0058, 0.0158,
        0.0143, 0.0586, 0.0313, 0.3852, 0.0176, 0.1234, 0.0172, 0.0170, 0.1069,
        0.0756], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,879][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ computer] are: tensor([7.1730e-03, 3.4968e-01, 4.4321e-04, 7.6822e-05, 8.9698e-04, 7.2061e-03,
        3.9247e-04, 1.1356e-06, 7.4087e-05, 3.6554e-04, 1.5568e-04, 1.3317e-02,
        1.1017e-02, 1.0901e-02, 7.1604e-02, 1.0709e-03, 1.3084e-02, 4.1302e-03,
        5.0841e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,880][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ computer] are: tensor([1.4590e-05, 2.3042e-03, 2.3910e-04, 3.1080e-04, 2.3704e-03, 5.1680e-03,
        3.3223e-04, 1.5896e-04, 4.7316e-03, 1.2154e-02, 2.0314e-02, 1.7914e-01,
        2.4932e-01, 1.5488e-01, 2.7929e-02, 3.0475e-02, 6.4990e-02, 6.6188e-02,
        1.7898e-01], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,881][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ computer] are: tensor([6.1411e-05, 3.0400e-02, 4.2037e-03, 4.0352e-03, 1.0378e-02, 1.1188e-02,
        2.0688e-02, 8.2280e-03, 8.6979e-03, 1.3543e-02, 2.9672e-02, 1.4447e-01,
        2.3309e-01, 3.5081e-02, 1.7030e-01, 1.6565e-02, 1.1916e-01, 6.2240e-02,
        7.7995e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,882][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ computer] are: tensor([0.0201, 0.2123, 0.0350, 0.0028, 0.0025, 0.0503, 0.0508, 0.0080, 0.0140,
        0.0252, 0.0440, 0.0370, 0.0444, 0.0061, 0.1944, 0.0277, 0.0697, 0.0497,
        0.1061], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,883][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ computer] are: tensor([0.0004, 0.0081, 0.0040, 0.0019, 0.0015, 0.0107, 0.0142, 0.0037, 0.0258,
        0.0535, 0.0615, 0.0279, 0.1683, 0.0110, 0.1768, 0.0875, 0.0496, 0.0980,
        0.1957], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,884][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ computer] are: tensor([5.0275e-06, 1.7687e-02, 2.3519e-03, 8.7282e-03, 1.2296e-03, 2.8846e-02,
        4.9130e-03, 1.6956e-03, 1.6283e-02, 4.1545e-02, 6.8634e-02, 2.0141e-02,
        1.0906e-01, 6.2647e-03, 2.5965e-01, 9.1673e-02, 9.7495e-02, 1.7690e-01,
        4.6898e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,886][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ computer] are: tensor([0.0012, 0.0232, 0.0013, 0.0023, 0.0006, 0.0226, 0.0465, 0.0071, 0.0380,
        0.0061, 0.0285, 0.0891, 0.0666, 0.0090, 0.2681, 0.0060, 0.0298, 0.0474,
        0.3067], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,888][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ computer] are: tensor([0.2331, 0.0468, 0.0045, 0.0014, 0.0069, 0.0789, 0.0027, 0.0016, 0.0054,
        0.0080, 0.0567, 0.0078, 0.1218, 0.0357, 0.0557, 0.0178, 0.0114, 0.1848,
        0.1188], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,890][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ computer] are: tensor([0.0261, 0.0708, 0.0026, 0.0008, 0.0004, 0.0237, 0.0079, 0.0020, 0.0024,
        0.0137, 0.0324, 0.0220, 0.2021, 0.0144, 0.0743, 0.0347, 0.0343, 0.2379,
        0.1975], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer]
[2024-07-24 10:18:49,892][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0128, 0.0486, 0.0181, 0.0009, 0.0067, 0.0067, 0.0021, 0.0275, 0.0223,
        0.0232, 0.0114, 0.0648, 0.0904, 0.0336, 0.0710, 0.1001, 0.0966, 0.0826,
        0.0176, 0.2630], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,894][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0116, 0.2187, 0.0136, 0.0345, 0.0089, 0.0544, 0.0055, 0.0251, 0.0194,
        0.0251, 0.0968, 0.0125, 0.3321, 0.0088, 0.0180, 0.0255, 0.0117, 0.0489,
        0.0078, 0.0213], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,896][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0015, 0.0612, 0.0006, 0.0066, 0.0034, 0.0131, 0.0036, 0.0113, 0.0142,
        0.0176, 0.0510, 0.0131, 0.5691, 0.0539, 0.0268, 0.0149, 0.0059, 0.0928,
        0.0231, 0.0162], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,897][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2105e-03, 3.4194e-01, 1.7409e-03, 1.2151e-03, 5.9932e-03, 2.7642e-02,
        3.1665e-03, 7.8003e-05, 1.8624e-03, 4.8430e-03, 2.6600e-03, 6.0085e-02,
        3.0262e-02, 2.8787e-02, 2.1675e-01, 5.4257e-03, 3.9402e-02, 7.6008e-03,
        2.0895e-01, 1.0387e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,898][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.8353e-06, 1.0575e-02, 6.5944e-04, 3.8448e-03, 2.9214e-03, 1.1130e-02,
        4.4392e-04, 4.6960e-04, 6.6277e-03, 4.0267e-02, 3.7995e-02, 6.5533e-02,
        4.9581e-01, 5.8426e-02, 1.0622e-02, 6.8933e-02, 2.4883e-02, 4.8841e-02,
        3.7056e-02, 7.4952e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,899][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.7223e-04, 1.0697e-01, 1.7441e-02, 6.6288e-03, 4.7800e-03, 4.0902e-03,
        6.9215e-03, 2.0178e-02, 8.0132e-03, 3.2140e-02, 5.5270e-02, 7.2399e-02,
        4.2454e-01, 1.8345e-02, 6.0906e-02, 2.3355e-02, 3.3095e-02, 6.5343e-02,
        1.2842e-02, 2.6573e-02], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,900][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0224, 0.2194, 0.1296, 0.0193, 0.0045, 0.0639, 0.0492, 0.0188, 0.0269,
        0.0579, 0.0917, 0.0191, 0.0621, 0.0044, 0.0261, 0.0445, 0.0177, 0.0414,
        0.0177, 0.0636], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,901][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0010, 0.0144, 0.0031, 0.0039, 0.0007, 0.0058, 0.0066, 0.0073, 0.0336,
        0.1212, 0.0995, 0.0086, 0.2093, 0.0029, 0.0568, 0.1107, 0.0099, 0.0710,
        0.0321, 0.2012], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,902][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0274, 0.0043, 0.0016, 0.0073, 0.0007, 0.0303, 0.0026, 0.0137, 0.0058,
        0.0468, 0.0541, 0.0224, 0.1562, 0.0114, 0.0677, 0.1169, 0.0533, 0.0902,
        0.0621, 0.2252], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,904][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0261, 0.2749, 0.0277, 0.0220, 0.0007, 0.0349, 0.0541, 0.0340, 0.1313,
        0.0236, 0.0862, 0.0522, 0.0745, 0.0021, 0.0254, 0.0087, 0.0041, 0.0530,
        0.0439, 0.0206], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,906][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3361, 0.0289, 0.0053, 0.0024, 0.0024, 0.0591, 0.0149, 0.0073, 0.0049,
        0.0160, 0.0669, 0.0202, 0.0690, 0.0191, 0.1024, 0.0250, 0.0133, 0.0924,
        0.0735, 0.0411], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,908][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0032, 0.1181, 0.0051, 0.0036, 0.0009, 0.0267, 0.0112, 0.0067, 0.0061,
        0.0160, 0.0902, 0.0345, 0.2454, 0.0081, 0.0643, 0.0298, 0.0311, 0.1385,
        0.1051, 0.0552], device='cuda:0') for source tokens [Then, Katie and Patrick were thinking about going to the school. Patrick wanted to give a computer to]
[2024-07-24 10:18:49,912][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:49,914][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7326],
        [ 234],
        [ 452],
        [   5],
        [  21],
        [  16],
        [  23],
        [  11],
        [  37],
        [   4],
        [   4],
        [  22],
        [   1],
        [  21],
        [  10],
        [   1],
        [   4],
        [   1],
        [  12],
        [   1]], device='cuda:0')
[2024-07-24 10:18:49,916][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[7636],
        [ 193],
        [1316],
        [  25],
        [  66],
        [  39],
        [  47],
        [  29],
        [  47],
        [  10],
        [   9],
        [  37],
        [   5],
        [  17],
        [   8],
        [   3],
        [   5],
        [   2],
        [  11],
        [   4]], device='cuda:0')
[2024-07-24 10:18:49,917][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15226],
        [40945],
        [32318],
        [34935],
        [35360],
        [33973],
        [36656],
        [28509],
        [33211],
        [29608],
        [30828],
        [31406],
        [30917],
        [31878],
        [28205],
        [27871],
        [30656],
        [28376],
        [29287],
        [28480]], device='cuda:0')
[2024-07-24 10:18:49,919][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2099],
        [28984],
        [44555],
        [42685],
        [41058],
        [44450],
        [40896],
        [46621],
        [42398],
        [43093],
        [45772],
        [45636],
        [45237],
        [46410],
        [47185],
        [46210],
        [45987],
        [46398],
        [47221],
        [46099]], device='cuda:0')
[2024-07-24 10:18:49,921][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 2586],
        [29687],
        [   22],
        [   10],
        [   32],
        [  454],
        [  223],
        [  107],
        [  471],
        [  374],
        [  482],
        [ 1937],
        [  275],
        [19495],
        [26524],
        [ 9960],
        [13395],
        [14872],
        [30990],
        [16149]], device='cuda:0')
[2024-07-24 10:18:49,923][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[41456],
        [26965],
        [  549],
        [  151],
        [ 1945],
        [  605],
        [ 5514],
        [ 2326],
        [ 1647],
        [  508],
        [ 1034],
        [ 4615],
        [ 1921],
        [21595],
        [12041],
        [ 2807],
        [ 7645],
        [ 5648],
        [23858],
        [ 4839]], device='cuda:0')
[2024-07-24 10:18:49,925][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[23922],
        [15967],
        [ 1234],
        [ 4316],
        [ 4369],
        [ 3587],
        [ 4677],
        [ 4594],
        [ 4580],
        [ 4115],
        [ 5861],
        [ 2894],
        [10836],
        [ 8415],
        [ 7828],
        [ 8466],
        [ 7820],
        [ 7765],
        [ 6001],
        [ 7950]], device='cuda:0')
[2024-07-24 10:18:49,927][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45826],
        [24297],
        [15673],
        [18748],
        [14120],
        [18118],
        [19930],
        [20766],
        [21141],
        [20811],
        [19145],
        [23646],
        [25902],
        [31924],
        [28765],
        [29580],
        [29754],
        [28710],
        [30774],
        [31080]], device='cuda:0')
[2024-07-24 10:18:49,930][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24420],
        [45652],
        [49204],
        [49111],
        [49282],
        [48912],
        [47969],
        [47665],
        [47868],
        [48697],
        [48336],
        [47805],
        [48954],
        [47555],
        [46589],
        [48156],
        [47893],
        [47886],
        [44537],
        [47210]], device='cuda:0')
[2024-07-24 10:18:49,932][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46876],
        [27749],
        [11430],
        [12773],
        [ 7263],
        [12069],
        [ 6745],
        [ 2890],
        [ 3281],
        [ 3092],
        [ 2866],
        [ 5779],
        [ 3132],
        [ 2882],
        [ 3948],
        [ 2836],
        [ 3473],
        [ 3185],
        [ 4999],
        [ 2617]], device='cuda:0')
[2024-07-24 10:18:49,934][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17478],
        [15377],
        [15861],
        [15590],
        [11450],
        [16199],
        [12219],
        [15545],
        [ 6509],
        [ 6492],
        [ 2182],
        [ 3956],
        [ 2707],
        [ 3320],
        [ 3191],
        [ 4667],
        [ 3387],
        [ 2489],
        [ 3566],
        [ 2197]], device='cuda:0')
[2024-07-24 10:18:49,935][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24544],
        [25158],
        [23669],
        [24272],
        [29223],
        [30206],
        [30166],
        [29111],
        [28251],
        [29198],
        [28222],
        [27176],
        [28051],
        [29194],
        [28462],
        [26915],
        [27095],
        [25702],
        [27987],
        [25447]], device='cuda:0')
[2024-07-24 10:18:49,937][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[29455],
        [14569],
        [  315],
        [ 7626],
        [ 1312],
        [ 3879],
        [ 2723],
        [ 2604],
        [ 2294],
        [ 2496],
        [ 2268],
        [ 3158],
        [ 2664],
        [  874],
        [ 1443],
        [ 1601],
        [ 1287],
        [ 1963],
        [ 2581],
        [ 3977]], device='cuda:0')
[2024-07-24 10:18:49,939][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[11844],
        [27968],
        [49529],
        [49773],
        [49826],
        [48984],
        [32947],
        [49618],
        [49713],
        [49810],
        [49810],
        [14473],
        [48925],
        [32652],
        [15211],
        [49808],
        [13404],
        [47837],
        [12169],
        [49234]], device='cuda:0')
[2024-07-24 10:18:49,941][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16736],
        [11685],
        [13353],
        [12595],
        [12205],
        [15513],
        [13733],
        [12065],
        [15644],
        [14521],
        [13231],
        [14023],
        [12945],
        [10959],
        [13633],
        [16008],
        [12975],
        [15690],
        [14282],
        [15400]], device='cuda:0')
[2024-07-24 10:18:49,943][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17028],
        [12923],
        [10540],
        [11111],
        [11419],
        [11078],
        [11755],
        [11509],
        [13336],
        [13741],
        [14165],
        [13145],
        [14175],
        [15415],
        [14045],
        [15760],
        [14750],
        [15449],
        [13919],
        [16504]], device='cuda:0')
[2024-07-24 10:18:49,945][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[22839],
        [24662],
        [23510],
        [24045],
        [24333],
        [26074],
        [26342],
        [27937],
        [26903],
        [27700],
        [29745],
        [29965],
        [29800],
        [30563],
        [31104],
        [30496],
        [30940],
        [30428],
        [31616],
        [31054]], device='cuda:0')
[2024-07-24 10:18:49,947][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[31832],
        [27264],
        [27715],
        [28482],
        [28058],
        [28714],
        [30064],
        [31960],
        [32100],
        [32994],
        [32912],
        [32923],
        [31978],
        [31875],
        [31496],
        [31537],
        [31583],
        [30558],
        [30726],
        [31034]], device='cuda:0')
[2024-07-24 10:18:49,950][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21352],
        [12945],
        [12859],
        [12715],
        [13123],
        [13639],
        [13063],
        [15082],
        [13355],
        [14134],
        [13779],
        [14700],
        [17448],
        [18376],
        [23833],
        [26626],
        [18450],
        [27620],
        [25373],
        [26016]], device='cuda:0')
[2024-07-24 10:18:49,952][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17218],
        [22681],
        [19961],
        [20637],
        [20357],
        [18279],
        [18361],
        [18227],
        [15193],
        [14920],
        [14115],
        [ 9427],
        [11899],
        [10608],
        [ 9988],
        [11763],
        [10595],
        [11571],
        [ 9083],
        [12259]], device='cuda:0')
[2024-07-24 10:18:49,953][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15567],
        [16070],
        [16010],
        [15818],
        [15986],
        [16166],
        [17880],
        [18763],
        [18062],
        [16772],
        [17738],
        [12576],
        [14195],
        [12284],
        [18551],
        [14978],
        [19841],
        [17481],
        [20365],
        [15558]], device='cuda:0')
[2024-07-24 10:18:49,955][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 8088],
        [26768],
        [29244],
        [29430],
        [29851],
        [29456],
        [30686],
        [31110],
        [31419],
        [32017],
        [31201],
        [29350],
        [30431],
        [30039],
        [29820],
        [31405],
        [29473],
        [30549],
        [30057],
        [30117]], device='cuda:0')
[2024-07-24 10:18:49,957][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29751],
        [20168],
        [18352],
        [18597],
        [18601],
        [18079],
        [14897],
        [15270],
        [12938],
        [13898],
        [16568],
        [15032],
        [15620],
        [14936],
        [14375],
        [15299],
        [14535],
        [16004],
        [12884],
        [15635]], device='cuda:0')
[2024-07-24 10:18:49,959][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19794],
        [14538],
        [14685],
        [15245],
        [15137],
        [15909],
        [16004],
        [15852],
        [15580],
        [15657],
        [15407],
        [15293],
        [15196],
        [15053],
        [14336],
        [14848],
        [14786],
        [15004],
        [14578],
        [14958]], device='cuda:0')
[2024-07-24 10:18:49,961][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20251],
        [15897],
        [20067],
        [16763],
        [16740],
        [17287],
        [16725],
        [17287],
        [16496],
        [17180],
        [16186],
        [17222],
        [15928],
        [16618],
        [19124],
        [16790],
        [18394],
        [17221],
        [16979],
        [17041]], device='cuda:0')
[2024-07-24 10:18:49,963][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15669],
        [31162],
        [26897],
        [20095],
        [22850],
        [19248],
        [25202],
        [25801],
        [26935],
        [25880],
        [25482],
        [20610],
        [19747],
        [27296],
        [19798],
        [22571],
        [21882],
        [24720],
        [23072],
        [21658]], device='cuda:0')
[2024-07-24 10:18:49,965][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13892],
        [18904],
        [20672],
        [19730],
        [20328],
        [17583],
        [18148],
        [19149],
        [18169],
        [19356],
        [20309],
        [20073],
        [20393],
        [18875],
        [19486],
        [20418],
        [20084],
        [19951],
        [19604],
        [20662]], device='cuda:0')
[2024-07-24 10:18:49,967][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28940],
        [27923],
        [27853],
        [29600],
        [28410],
        [29493],
        [28579],
        [26057],
        [27793],
        [26651],
        [25808],
        [29167],
        [28042],
        [26723],
        [25346],
        [23479],
        [25699],
        [22060],
        [24063],
        [23360]], device='cuda:0')
[2024-07-24 10:18:49,969][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32449],
        [35176],
        [33818],
        [35116],
        [35078],
        [33090],
        [34032],
        [36031],
        [33297],
        [33545],
        [34956],
        [34198],
        [35070],
        [35517],
        [35167],
        [32567],
        [36346],
        [33361],
        [34074],
        [32884]], device='cuda:0')
[2024-07-24 10:18:49,971][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805],
        [10805]], device='cuda:0')
