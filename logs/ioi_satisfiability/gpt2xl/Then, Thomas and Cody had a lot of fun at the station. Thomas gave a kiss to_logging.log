[2024-07-24 10:18:50,672][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Cody
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:18:50,673][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,674][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:18:50,675][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit17', 'circuit27']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,676][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,677][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit15', 'circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit26']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit9']
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:18:50,678][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit3', 'circuit4', 'circuit28']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit28']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,679][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit24']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:18:50,680][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,681][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit23']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:18:50,682][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:18:50,683][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit16']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:18:50,684][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit9']
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,685][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,686][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:18:50,687][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit4', 'circuit6', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:18:50,688][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit13']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit26']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,689][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,690][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit13']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit14', 'circuit27']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit27']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,691][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit12']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit22', 'circuit26']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit9']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,692][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit10', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,693][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,694][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit22', 'circuit26']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,695][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:18:50,696][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit20']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,697][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,698][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,699][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,700][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:18:50,701][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,702][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,703][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit15', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit11', 'circuit25']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,704][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit21']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,705][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:18:50,706][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit25']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit21']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,707][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,708][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit27']
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,709][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,710][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,711][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2']
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,712][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit27']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,713][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:18:50,714][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:18:50,715][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit8', 'circuit11']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit27']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:18:50,716][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit8', 'circuit13', 'circuit14']
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,717][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,718][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22']
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,719][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit11', 'circuit12']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit26']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit13']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit10', 'circuit13']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit9', 'circuit13']
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,720][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit13']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit12', 'circuit27']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,721][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,722][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,723][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,724][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,725][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,726][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,727][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,728][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,729][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,730][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit3', 'circuit7']
[2024-07-24 10:18:50,731][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit13', 'circuit16']
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,732][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,733][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17']
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:18:50,734][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit7', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:50,735][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,736][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,737][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,738][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,739][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,740][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:18:50,741][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,742][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,743][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,744][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit7', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:18:50,745][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,746][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,747][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:18:50,748][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,749][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,750][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:18:50,751][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:18:50,752][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit21', 'circuit25']
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,753][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,754][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,755][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,756][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,757][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,758][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,759][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,760][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,761][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:18:50,762][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22', 'circuit25']
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,763][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:18:50,764][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,765][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,766][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,767][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,768][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,769][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,770][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,771][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,772][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,773][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,774][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,775][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,776][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,777][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,778][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,779][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,780][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit12', 'circuit14', 'circuit15', 'circuit20', 'circuit24']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,781][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1']
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:18:50,782][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,783][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,784][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit24']
[2024-07-24 10:18:50,785][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit11', 'circuit13', 'circuit16', 'circuit18', 'circuit22']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,786][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit20']
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit15', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:18:50,787][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:18:50,788][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit24']
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,789][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit8', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,790][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,791][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,792][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,793][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,794][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:18:50,795][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,796][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,797][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,798][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:18:50,799][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,800][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,801][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:50,802][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:18:52,239][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:52,241][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,241][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,242][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,243][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,243][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,244][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,245][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,246][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,247][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,247][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,248][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,249][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,250][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,250][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,252][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,254][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,255][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,257][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,258][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,258][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,260][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,262][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,263][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,264][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,265][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.4984, 0.2809, 0.2207], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,266][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([5.2024e-04, 3.4148e-04, 9.9914e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,267][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.6193, 0.2928, 0.0879], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,267][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([1.5025e-02, 6.9133e-04, 9.8428e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,268][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.1449, 0.0273, 0.8278], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,269][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([3.8860e-02, 2.6837e-05, 9.6111e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,271][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.5044, 0.1736, 0.3220], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,272][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.4944, 0.3359, 0.1697], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,274][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.4818, 0.2892, 0.2290], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,276][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.6084, 0.3210, 0.0706], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,278][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.4442, 0.2427, 0.3131], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,279][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.5164, 0.3243, 0.1593], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,281][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6995, 0.0792, 0.1595, 0.0618], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,283][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3027e-03, 3.9250e-02, 4.0529e-04, 9.5804e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,285][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2393, 0.1791, 0.0303, 0.5512], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,286][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1154, 0.3945, 0.0074, 0.4826], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,287][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3121, 0.1414, 0.2905, 0.2560], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,288][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1231, 0.1971, 0.0067, 0.6732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,288][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6957, 0.0333, 0.2458, 0.0252], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,289][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2546, 0.1936, 0.2602, 0.2915], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,290][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0673, 0.4711, 0.0199, 0.4418], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,291][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4266, 0.2382, 0.1138, 0.2213], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,293][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4109, 0.3061, 0.0811, 0.2019], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,295][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4552, 0.1988, 0.0862, 0.2598], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,296][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.2226, 0.2106, 0.2786, 0.1762, 0.1120], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,297][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([4.1488e-05, 1.1145e-05, 3.8129e-04, 2.3384e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,299][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.3398, 0.2562, 0.0634, 0.1021, 0.2385], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,301][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([2.0640e-03, 2.3342e-05, 3.5369e-03, 1.0093e-04, 9.9427e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,302][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.0227, 0.0051, 0.0676, 0.0040, 0.9006], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,303][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([7.2305e-03, 3.1187e-07, 1.3803e-05, 6.7753e-08, 9.9276e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,304][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.2036, 0.3113, 0.1515, 0.1529, 0.1807], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,305][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.2007, 0.2100, 0.1218, 0.3678, 0.0997], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,306][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.2920, 0.1862, 0.2728, 0.1251, 0.1239], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,306][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.3732, 0.2431, 0.1794, 0.1928, 0.0114], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,307][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.2734, 0.2074, 0.1152, 0.1453, 0.2587], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,308][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.2689, 0.2243, 0.0750, 0.3006, 0.1312], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,310][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4179, 0.0367, 0.1146, 0.0366, 0.0723, 0.3219], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,311][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2221e-04, 1.6756e-03, 2.7827e-04, 2.8621e-03, 3.9104e-05, 9.9482e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,313][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4965, 0.1266, 0.0383, 0.1498, 0.0404, 0.1484], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,314][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9407e-03, 5.4301e-03, 8.6579e-04, 1.1491e-02, 1.2590e-03, 9.7601e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,316][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2291, 0.0651, 0.0656, 0.1179, 0.0359, 0.4864], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,318][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9810e-02, 1.8577e-03, 5.2894e-04, 1.2915e-03, 1.2827e-04, 9.5638e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,319][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3616, 0.0270, 0.2979, 0.0253, 0.2518, 0.0363], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,321][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1362, 0.1061, 0.0805, 0.2463, 0.1246, 0.3063], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,322][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0962, 0.2703, 0.0203, 0.3551, 0.0382, 0.2197], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,323][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3145, 0.1896, 0.0932, 0.1954, 0.0753, 0.1320], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,323][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2575, 0.1986, 0.0590, 0.1454, 0.0239, 0.3157], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,324][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4373, 0.1461, 0.0592, 0.1821, 0.0833, 0.0921], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,325][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5270, 0.0607, 0.1023, 0.0459, 0.1478, 0.0756, 0.0407],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,326][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5617e-04, 4.3027e-03, 9.5226e-04, 4.3007e-03, 3.3981e-04, 4.6860e-04,
        9.8878e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,328][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3025, 0.1876, 0.0489, 0.2213, 0.0677, 0.1253, 0.0468],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,329][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0293, 0.0180, 0.0054, 0.0331, 0.0190, 0.1788, 0.7165],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,331][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1477, 0.0325, 0.0498, 0.0458, 0.0391, 0.4618, 0.2234],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,333][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0554, 0.1285, 0.0137, 0.0961, 0.0016, 0.0444, 0.6603],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,335][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3817, 0.0127, 0.2520, 0.0108, 0.2743, 0.0561, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,336][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1029, 0.0618, 0.0442, 0.1382, 0.1021, 0.2318, 0.3191],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,338][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0241, 0.1313, 0.0080, 0.1950, 0.0064, 0.1425, 0.4926],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,339][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2672, 0.1711, 0.0849, 0.1736, 0.0586, 0.1077, 0.1369],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,340][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2286, 0.1949, 0.0726, 0.1653, 0.0254, 0.0846, 0.2285],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,340][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3417, 0.1370, 0.0856, 0.1471, 0.0870, 0.0883, 0.1133],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,341][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3708, 0.0820, 0.1072, 0.0866, 0.0841, 0.0773, 0.0917, 0.1001],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,342][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6438e-04, 1.0272e-03, 2.3119e-04, 1.2075e-03, 2.7504e-03, 1.3658e-03,
        5.0268e-04, 9.9265e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,343][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2772, 0.1072, 0.0428, 0.1916, 0.1294, 0.1424, 0.0739, 0.0354],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,345][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0769e-03, 1.2859e-04, 2.6873e-05, 2.5214e-04, 5.8465e-04, 2.0038e-03,
        1.6737e-03, 9.9425e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,347][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0466, 0.0144, 0.0032, 0.0160, 0.0206, 0.0615, 0.0724, 0.7653],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,348][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2508e-03, 1.1952e-04, 6.8451e-05, 1.7785e-05, 2.9281e-04, 9.6438e-06,
        5.2859e-06, 9.9624e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,349][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.3063, 0.0662, 0.1068, 0.0386, 0.1621, 0.0438, 0.0572, 0.2192],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,351][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0875, 0.0471, 0.0431, 0.0928, 0.1003, 0.1506, 0.2783, 0.2003],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,353][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1264, 0.1535, 0.0237, 0.1419, 0.0388, 0.1158, 0.3438, 0.0561],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,355][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2406, 0.1526, 0.0713, 0.1477, 0.0998, 0.0992, 0.1272, 0.0616],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,356][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2098, 0.1507, 0.0380, 0.1246, 0.0496, 0.0840, 0.0839, 0.2594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,357][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4653, 0.0891, 0.0636, 0.0923, 0.0733, 0.0630, 0.0464, 0.1069],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,357][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3620, 0.0569, 0.0994, 0.0410, 0.1433, 0.0747, 0.0497, 0.1412, 0.0317],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,358][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9874e-04, 1.5861e-02, 5.7776e-05, 2.1565e-02, 1.3822e-05, 6.7604e-04,
        3.8738e-04, 9.5703e-05, 9.6044e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,359][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3022, 0.1432, 0.0483, 0.1331, 0.0501, 0.0770, 0.0610, 0.0848, 0.1002],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,360][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0051, 0.0030, 0.0013, 0.0068, 0.0270, 0.0444, 0.0596, 0.3647, 0.4882],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,362][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1595, 0.0218, 0.0457, 0.0259, 0.0339, 0.1148, 0.0743, 0.3443, 0.1798],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,364][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0225, 0.0908, 0.0068, 0.1066, 0.0008, 0.0653, 0.2345, 0.0072, 0.4655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,365][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2319, 0.0198, 0.1628, 0.0174, 0.2611, 0.0452, 0.0182, 0.2312, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,367][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0544, 0.0263, 0.0273, 0.0551, 0.0484, 0.1089, 0.1842, 0.2735, 0.2219],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,369][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0229, 0.1177, 0.0101, 0.1840, 0.0091, 0.1239, 0.3541, 0.0216, 0.1567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,371][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2066, 0.1349, 0.0718, 0.1381, 0.0447, 0.0866, 0.1127, 0.0806, 0.1241],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,373][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1710, 0.1585, 0.0445, 0.1499, 0.0214, 0.0774, 0.0921, 0.0598, 0.2254],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,373][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2630, 0.1144, 0.0784, 0.1348, 0.0946, 0.0786, 0.0849, 0.1009, 0.0504],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,374][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.2534, 0.1022, 0.1244, 0.0938, 0.0503, 0.0357, 0.0896, 0.0995, 0.0552,
        0.0958], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,375][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4094e-04, 4.5741e-05, 5.3802e-05, 3.7528e-05, 9.1370e-04, 2.0432e-05,
        1.1351e-03, 8.8515e-04, 1.7986e-05, 9.9675e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,376][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1998, 0.0693, 0.0666, 0.1107, 0.0839, 0.1006, 0.0923, 0.0744, 0.1021,
        0.1002], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,376][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4560e-04, 8.2933e-06, 1.3955e-05, 8.7074e-06, 4.7770e-04, 2.8318e-04,
        2.2884e-04, 1.8475e-03, 2.9436e-04, 9.9639e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,377][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([1.2322e-02, 2.0733e-03, 4.9860e-04, 2.4430e-03, 4.3665e-03, 1.0323e-02,
        1.0829e-02, 1.3873e-02, 9.5487e-03, 9.3372e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,379][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2282e-03, 2.8176e-05, 1.0355e-05, 3.7843e-06, 1.2672e-04, 4.2782e-07,
        1.7978e-06, 1.4491e-04, 2.7546e-07, 9.9546e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,381][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1668, 0.0354, 0.1050, 0.0276, 0.3518, 0.0232, 0.0251, 0.1100, 0.0300,
        0.1251], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,383][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0943, 0.0235, 0.0034, 0.0506, 0.0274, 0.0700, 0.1397, 0.1967, 0.2643,
        0.1301], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,384][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1330, 0.1229, 0.0309, 0.1824, 0.0118, 0.1076, 0.2012, 0.0660, 0.1060,
        0.0382], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,386][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1991, 0.1216, 0.0694, 0.1162, 0.0572, 0.0874, 0.1002, 0.0811, 0.1073,
        0.0605], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,388][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1344, 0.1047, 0.0333, 0.1017, 0.0500, 0.0576, 0.0845, 0.0882, 0.0731,
        0.2725], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,390][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.3162, 0.1574, 0.0593, 0.1174, 0.0427, 0.0716, 0.0661, 0.0466, 0.0551,
        0.0677], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,391][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2498, 0.0353, 0.0718, 0.0326, 0.1226, 0.0459, 0.0511, 0.1350, 0.0318,
        0.1999, 0.0241], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,392][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4903e-04, 1.5253e-03, 3.8247e-04, 3.7661e-03, 5.4628e-05, 1.5078e-04,
        1.4846e-03, 3.0389e-05, 4.3040e-03, 3.3107e-05, 9.8752e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,392][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1999, 0.1032, 0.0244, 0.1220, 0.0480, 0.0807, 0.0452, 0.0638, 0.1181,
        0.0805, 0.1143], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,393][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0223e-03, 3.5273e-04, 5.2364e-05, 6.9237e-04, 2.6455e-04, 4.8611e-03,
        7.4762e-03, 3.9665e-03, 3.0001e-02, 1.3051e-01, 8.2080e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,394][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0619, 0.0063, 0.0092, 0.0095, 0.0092, 0.0582, 0.0342, 0.0468, 0.0707,
        0.3783, 0.3156], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,396][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0545, 0.0231, 0.0047, 0.0096, 0.0011, 0.0363, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,398][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1697, 0.0129, 0.1708, 0.0127, 0.1981, 0.0415, 0.0163, 0.1802, 0.0125,
        0.1652, 0.0202], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,400][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0365, 0.0124, 0.0085, 0.0280, 0.0220, 0.0467, 0.0819, 0.1097, 0.1263,
        0.1928, 0.3350], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,401][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0240, 0.1163, 0.0084, 0.2109, 0.0069, 0.1121, 0.1975, 0.0245, 0.1666,
        0.0261, 0.1068], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,404][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1514, 0.1056, 0.0548, 0.1144, 0.0454, 0.0791, 0.0914, 0.0704, 0.1102,
        0.0735, 0.1039], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,406][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1438, 0.1112, 0.0492, 0.1145, 0.0289, 0.0835, 0.0965, 0.0347, 0.0924,
        0.0304, 0.2149], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,407][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2604, 0.0892, 0.0492, 0.0926, 0.0660, 0.0552, 0.0482, 0.0872, 0.0485,
        0.0845, 0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,408][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4054, 0.0344, 0.0646, 0.0222, 0.1130, 0.0449, 0.0197, 0.0874, 0.0197,
        0.1435, 0.0211, 0.0240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,409][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9752e-03, 1.8211e-02, 4.4758e-04, 3.9243e-02, 6.1857e-05, 2.7152e-04,
        3.3100e-02, 8.6441e-05, 6.8755e-02, 7.4393e-05, 4.1117e-02, 7.9566e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,410][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1839, 0.0900, 0.0271, 0.1004, 0.0337, 0.0934, 0.0292, 0.0691, 0.1120,
        0.0622, 0.1694, 0.0296], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,411][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0776e-02, 1.6539e-03, 4.2536e-04, 1.8835e-03, 9.5281e-04, 7.3266e-03,
        1.8903e-02, 1.2121e-02, 6.1572e-02, 5.5885e-02, 1.8266e-01, 6.4584e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,411][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1117, 0.0124, 0.0166, 0.0164, 0.0133, 0.0781, 0.0335, 0.0503, 0.0983,
        0.1416, 0.2321, 0.1957], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,413][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0656, 0.1028, 0.0191, 0.0841, 0.0070, 0.0629, 0.2062, 0.0501, 0.0540,
        0.0112, 0.0576, 0.2794], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,415][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1964, 0.0033, 0.1512, 0.0031, 0.2385, 0.0189, 0.0036, 0.1656, 0.0027,
        0.2074, 0.0071, 0.0022], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,417][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0383, 0.0090, 0.0062, 0.0178, 0.0171, 0.0231, 0.0368, 0.0578, 0.0950,
        0.0976, 0.2951, 0.3064], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,419][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0084, 0.0713, 0.0051, 0.1146, 0.0047, 0.0747, 0.2405, 0.0078, 0.0764,
        0.0135, 0.0510, 0.3319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,421][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1691, 0.0955, 0.0522, 0.0991, 0.0435, 0.0694, 0.0792, 0.0647, 0.0920,
        0.0499, 0.0933, 0.0919], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,423][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1728, 0.1058, 0.0718, 0.1055, 0.0257, 0.0539, 0.1106, 0.0411, 0.0634,
        0.0298, 0.0728, 0.1468], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,424][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1996, 0.0803, 0.0563, 0.0842, 0.0780, 0.0521, 0.0871, 0.0767, 0.0319,
        0.0797, 0.0794, 0.0947], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,425][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1472, 0.0787, 0.1039, 0.0825, 0.1104, 0.0462, 0.0755, 0.0246, 0.0705,
        0.0540, 0.0592, 0.0742, 0.0732], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,426][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ station] are: tensor([4.4804e-04, 9.2915e-04, 8.5055e-04, 2.4526e-03, 3.6072e-05, 5.2416e-04,
        6.6010e-05, 4.9759e-05, 1.3508e-03, 1.6325e-04, 3.2751e-03, 2.8654e-04,
        9.8957e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,427][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1343, 0.0583, 0.0952, 0.0561, 0.0483, 0.0569, 0.0611, 0.0635, 0.0695,
        0.0529, 0.0770, 0.0545, 0.1723], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,428][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ station] are: tensor([4.9432e-03, 1.1594e-05, 5.7583e-05, 1.7215e-05, 1.5093e-05, 2.1473e-04,
        4.1502e-05, 5.1115e-04, 3.6278e-04, 5.5407e-03, 1.1772e-03, 7.4247e-04,
        9.8636e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,429][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ station] are: tensor([2.3831e-02, 1.7535e-03, 5.8024e-03, 2.1580e-03, 3.6640e-04, 3.0496e-03,
        3.7120e-03, 9.0333e-03, 6.0967e-03, 6.0604e-02, 2.5155e-02, 1.7571e-02,
        8.4087e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,430][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ station] are: tensor([3.8948e-02, 3.2989e-05, 3.1992e-04, 1.0390e-05, 4.4542e-06, 1.6301e-05,
        3.1188e-06, 1.8543e-05, 5.1626e-06, 6.1131e-06, 1.5124e-05, 1.9200e-06,
        9.6062e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,431][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1744, 0.0452, 0.1577, 0.0247, 0.0843, 0.0164, 0.0304, 0.0337, 0.0150,
        0.1762, 0.0122, 0.0230, 0.2069], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,433][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0141, 0.0123, 0.0008, 0.0131, 0.0015, 0.0293, 0.0292, 0.0265, 0.0562,
        0.3221, 0.1531, 0.2388, 0.1031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,435][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0980, 0.1001, 0.0737, 0.0969, 0.0251, 0.0330, 0.0655, 0.0351, 0.0965,
        0.1016, 0.0747, 0.0690, 0.1310], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,437][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1484, 0.0959, 0.0794, 0.0869, 0.0551, 0.0574, 0.0787, 0.0596, 0.0756,
        0.0896, 0.0738, 0.0868, 0.0126], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,439][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0893, 0.0752, 0.0528, 0.0901, 0.0336, 0.0537, 0.0651, 0.0264, 0.0696,
        0.0263, 0.0857, 0.0666, 0.2655], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,441][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1763, 0.0828, 0.0535, 0.0704, 0.0530, 0.0598, 0.0473, 0.0531, 0.0658,
        0.0789, 0.0781, 0.0334, 0.1476], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,442][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4187, 0.0131, 0.0594, 0.0109, 0.1107, 0.0456, 0.0205, 0.0739, 0.0084,
        0.1019, 0.0159, 0.0348, 0.0767, 0.0095], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,443][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9674e-03, 2.9778e-02, 1.1500e-04, 5.5128e-03, 3.0904e-04, 1.1796e-04,
        2.6026e-04, 2.2075e-04, 2.5136e-03, 7.6672e-05, 1.1375e-03, 2.5240e-04,
        1.1771e-04, 9.5662e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,444][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3407, 0.0435, 0.0325, 0.0372, 0.0368, 0.1907, 0.0172, 0.0460, 0.0820,
        0.0363, 0.0507, 0.0212, 0.0212, 0.0441], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,445][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.1897e-02, 1.4145e-03, 2.5606e-04, 1.3705e-03, 5.7079e-04, 4.2735e-03,
        4.6068e-03, 1.8719e-02, 1.7924e-02, 1.9041e-02, 6.1596e-02, 1.6731e-01,
        2.3530e-01, 4.5572e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,446][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0306, 0.0103, 0.0052, 0.0197, 0.0064, 0.0213, 0.0182, 0.0451, 0.0602,
        0.0682, 0.1393, 0.1192, 0.1239, 0.3323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,447][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1024, 0.1628, 0.0369, 0.1043, 0.0085, 0.0722, 0.0784, 0.0328, 0.0515,
        0.0108, 0.0544, 0.0631, 0.0122, 0.2096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,449][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2509, 0.0064, 0.1043, 0.0048, 0.1860, 0.0132, 0.0064, 0.0975, 0.0039,
        0.2059, 0.0084, 0.0042, 0.1051, 0.0031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,451][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0192, 0.0046, 0.0038, 0.0086, 0.0073, 0.0129, 0.0196, 0.0321, 0.0334,
        0.0709, 0.0996, 0.1540, 0.1060, 0.4279], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,452][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0143, 0.1268, 0.0064, 0.1011, 0.0046, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0064, 0.3847], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,454][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1445, 0.0807, 0.0529, 0.0839, 0.0485, 0.0640, 0.0646, 0.0609, 0.0676,
        0.0604, 0.0708, 0.0729, 0.0395, 0.0889], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,456][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1080, 0.0911, 0.0386, 0.0981, 0.0426, 0.0742, 0.0608, 0.0638, 0.0761,
        0.0535, 0.0752, 0.0610, 0.0287, 0.1283], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,458][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2160, 0.0753, 0.0504, 0.0715, 0.0597, 0.0504, 0.0437, 0.0697, 0.0356,
        0.0635, 0.0753, 0.0338, 0.0614, 0.0936], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,460][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.1752, 0.0799, 0.0865, 0.0553, 0.1532, 0.0106, 0.0339, 0.0114, 0.0396,
        0.0229, 0.0330, 0.0508, 0.0940, 0.0592, 0.0944], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,461][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([1.9742e-04, 4.8450e-05, 5.2161e-01, 9.6644e-05, 1.6458e-04, 2.5903e-05,
        4.0502e-05, 1.2722e-05, 2.6139e-05, 1.3570e-05, 1.2209e-04, 3.5066e-05,
        1.6157e-04, 9.4305e-06, 4.7744e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,462][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.2201, 0.1005, 0.0648, 0.0384, 0.0182, 0.0569, 0.0725, 0.0190, 0.0642,
        0.0217, 0.0543, 0.0728, 0.0751, 0.0715, 0.0499], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,462][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([4.4437e-04, 9.2955e-07, 8.7433e-04, 1.6603e-06, 3.2523e-05, 5.9363e-06,
        7.8811e-06, 8.7410e-06, 3.4894e-05, 2.9277e-05, 9.6440e-05, 1.4378e-04,
        4.0096e-04, 2.1287e-04, 9.9771e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,463][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0102, 0.0015, 0.0297, 0.0015, 0.0117, 0.0020, 0.0011, 0.0012, 0.0038,
        0.0019, 0.0101, 0.0045, 0.0031, 0.0117, 0.9061], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,464][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([4.9491e-03, 2.1651e-06, 7.0066e-01, 1.5632e-07, 1.3840e-05, 6.5416e-07,
        2.9530e-07, 9.0520e-07, 1.5832e-07, 2.3245e-07, 3.0346e-07, 1.1095e-07,
        1.0921e-06, 3.5826e-08, 2.9437e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,466][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.1452, 0.0577, 0.1802, 0.0378, 0.1564, 0.0124, 0.0195, 0.0158, 0.0256,
        0.0219, 0.0111, 0.0323, 0.0826, 0.0264, 0.1749], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,468][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0320, 0.0059, 0.0043, 0.0152, 0.0534, 0.0150, 0.0251, 0.0260, 0.0374,
        0.0061, 0.0944, 0.1208, 0.0466, 0.3521, 0.1658], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,470][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.1155, 0.0731, 0.0946, 0.0633, 0.1224, 0.0224, 0.0479, 0.0237, 0.0582,
        0.0372, 0.0426, 0.0790, 0.0596, 0.0580, 0.1025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,472][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.1421, 0.0857, 0.0224, 0.0763, 0.0794, 0.0513, 0.0610, 0.0466, 0.0664,
        0.0591, 0.0661, 0.0821, 0.0539, 0.0852, 0.0223], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,474][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0863, 0.0635, 0.2221, 0.0605, 0.0400, 0.0289, 0.0451, 0.0146, 0.0409,
        0.0141, 0.0453, 0.0589, 0.0228, 0.0434, 0.2136], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,476][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.1107, 0.0619, 0.0486, 0.0566, 0.0607, 0.0759, 0.0535, 0.0750, 0.0274,
        0.0969, 0.0602, 0.0408, 0.0710, 0.0949, 0.0659], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,477][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2313, 0.0228, 0.0215, 0.0274, 0.0463, 0.1134, 0.0217, 0.0552, 0.0267,
        0.0442, 0.0218, 0.0202, 0.0557, 0.0182, 0.0243, 0.2496],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,478][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7512e-04, 5.8238e-04, 3.0369e-04, 1.2664e-03, 3.4777e-04, 6.5390e-03,
        1.4122e-04, 3.2847e-04, 7.6588e-04, 1.2333e-04, 3.5798e-04, 1.7579e-04,
        1.1229e-04, 5.0884e-05, 1.6638e-04, 9.8836e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,479][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1848, 0.0463, 0.0174, 0.0558, 0.0240, 0.0831, 0.0480, 0.0625, 0.0797,
        0.0700, 0.0786, 0.0590, 0.0145, 0.0784, 0.0150, 0.0828],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,480][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5930e-04, 4.6038e-06, 5.9219e-07, 3.9996e-06, 3.4648e-06, 4.5601e-05,
        1.1807e-05, 3.8660e-05, 4.7182e-05, 2.9246e-04, 1.4123e-04, 2.0665e-04,
        4.7210e-04, 6.5253e-04, 4.6365e-04, 9.9676e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,481][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0885, 0.0069, 0.0026, 0.0069, 0.0038, 0.0114, 0.0080, 0.0108, 0.0202,
        0.0242, 0.0420, 0.0228, 0.0234, 0.0457, 0.0315, 0.6514],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,482][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9498e-02, 2.1591e-05, 1.0687e-04, 2.1852e-05, 1.0031e-03, 1.8021e-03,
        1.2755e-05, 7.0345e-06, 5.9578e-06, 5.3208e-05, 1.5019e-05, 7.0729e-06,
        1.0871e-06, 1.0696e-06, 1.7298e-05, 9.5743e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,484][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1061, 0.0133, 0.1046, 0.0130, 0.1020, 0.0158, 0.0190, 0.0855, 0.0098,
        0.1639, 0.0114, 0.0147, 0.1286, 0.0136, 0.1661, 0.0326],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,485][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0183, 0.0041, 0.0038, 0.0060, 0.0035, 0.0060, 0.0116, 0.0135, 0.0149,
        0.0235, 0.0546, 0.0751, 0.0353, 0.3007, 0.2102, 0.2188],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,487][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0748, 0.0739, 0.0179, 0.0935, 0.0112, 0.0405, 0.1065, 0.0366, 0.0824,
        0.0663, 0.0768, 0.1291, 0.0279, 0.1002, 0.0259, 0.0365],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,489][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1140, 0.0625, 0.0421, 0.0663, 0.0402, 0.0618, 0.0554, 0.0554, 0.0612,
        0.0753, 0.0554, 0.0597, 0.0504, 0.0899, 0.0496, 0.0609],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,491][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0807, 0.0569, 0.0331, 0.0642, 0.0311, 0.1069, 0.0523, 0.0312, 0.0551,
        0.0345, 0.0569, 0.0502, 0.0239, 0.0676, 0.0325, 0.2228],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,493][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2222, 0.0784, 0.0364, 0.0937, 0.0470, 0.0412, 0.0376, 0.0474, 0.0397,
        0.0459, 0.0696, 0.0338, 0.0370, 0.0845, 0.0303, 0.0554],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,495][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2679, 0.0211, 0.0384, 0.0164, 0.0788, 0.0341, 0.0147, 0.0652, 0.0139,
        0.1127, 0.0137, 0.0259, 0.0622, 0.0193, 0.0537, 0.1394, 0.0225],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,496][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3928e-04, 1.1435e-03, 2.7662e-04, 1.2520e-03, 1.3300e-04, 1.3495e-04,
        4.3327e-01, 1.8445e-04, 1.1689e-03, 9.9723e-04, 3.4121e-03, 1.4675e-02,
        2.1876e-05, 2.8411e-04, 1.4097e-04, 1.1750e-04, 5.4234e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,497][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1038, 0.0531, 0.0192, 0.0809, 0.0288, 0.0486, 0.0165, 0.0615, 0.0815,
        0.0459, 0.1237, 0.0192, 0.0140, 0.1721, 0.0207, 0.0920, 0.0186],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,497][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.5990e-03, 2.7349e-04, 3.2196e-05, 1.7509e-04, 9.5005e-05, 3.7659e-04,
        1.3114e-03, 5.5523e-04, 1.7491e-03, 1.7575e-03, 4.7775e-03, 1.9528e-02,
        8.0118e-03, 2.8985e-02, 1.2204e-02, 1.3241e-01, 7.8416e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,498][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0233, 0.0028, 0.0025, 0.0030, 0.0015, 0.0195, 0.0077, 0.0072, 0.0117,
        0.0270, 0.0255, 0.0195, 0.0163, 0.0226, 0.0443, 0.5663, 0.1992],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,500][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0165, 0.0527, 0.0072, 0.0462, 0.0009, 0.0247, 0.4145, 0.0038, 0.0248,
        0.0043, 0.0314, 0.1009, 0.0009, 0.0131, 0.0016, 0.0038, 0.2527],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,503][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1209, 0.0028, 0.0845, 0.0027, 0.1116, 0.0177, 0.0031, 0.1155, 0.0030,
        0.1463, 0.0061, 0.0024, 0.1266, 0.0026, 0.1695, 0.0802, 0.0046],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,504][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0144, 0.0026, 0.0015, 0.0041, 0.0025, 0.0037, 0.0042, 0.0076, 0.0099,
        0.0124, 0.0312, 0.0366, 0.0289, 0.2079, 0.0777, 0.2855, 0.2691],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,506][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0339, 0.0023, 0.0595, 0.0023, 0.0462, 0.1369, 0.0065, 0.0438,
        0.0112, 0.0356, 0.1959, 0.0101, 0.1002, 0.0047, 0.0235, 0.2806],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,508][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1081, 0.0662, 0.0385, 0.0728, 0.0327, 0.0489, 0.0569, 0.0480, 0.0672,
        0.0423, 0.0665, 0.0684, 0.0366, 0.0718, 0.0412, 0.0615, 0.0724],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,510][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0757, 0.0588, 0.0319, 0.0694, 0.0177, 0.0461, 0.1287, 0.0346, 0.0551,
        0.0395, 0.0710, 0.0831, 0.0249, 0.0561, 0.0293, 0.0367, 0.1414],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,512][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1763, 0.0661, 0.0488, 0.0632, 0.0441, 0.0429, 0.0485, 0.0560, 0.0277,
        0.0543, 0.0551, 0.0358, 0.0507, 0.0713, 0.0448, 0.0670, 0.0475],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,513][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.1572, 0.0666, 0.0510, 0.0496, 0.0509, 0.0327, 0.0255, 0.0460, 0.0473,
        0.0460, 0.0383, 0.0339, 0.0332, 0.0432, 0.0464, 0.0582, 0.0290, 0.1450],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,514][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([3.2830e-05, 2.9171e-05, 2.3102e-05, 2.9540e-05, 1.8070e-04, 2.1182e-05,
        3.0257e-06, 2.2951e-06, 4.6391e-06, 1.5822e-05, 4.5806e-06, 8.7060e-07,
        2.0966e-05, 5.1429e-06, 6.6147e-06, 2.0087e-05, 1.5464e-06, 9.9960e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,515][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.1253, 0.0323, 0.0398, 0.0464, 0.0587, 0.0398, 0.0604, 0.0496, 0.0425,
        0.0859, 0.0366, 0.0696, 0.1440, 0.0385, 0.0334, 0.0275, 0.0631, 0.0066],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,515][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([3.4760e-04, 1.6658e-07, 6.5448e-08, 1.2658e-07, 1.0072e-06, 6.6575e-07,
        4.4349e-07, 7.9646e-06, 1.3555e-06, 1.2353e-04, 4.1648e-06, 3.2219e-06,
        1.0228e-04, 3.1504e-05, 2.1507e-05, 2.1461e-03, 1.6712e-04, 9.9704e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,516][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([1.5116e-02, 3.0588e-04, 3.0929e-04, 1.8164e-04, 2.6389e-04, 9.2443e-05,
        2.0387e-04, 3.9107e-04, 4.3238e-04, 2.2370e-03, 6.3771e-04, 4.7657e-04,
        8.2955e-04, 8.3532e-04, 1.6791e-03, 3.5497e-03, 2.1195e-03, 9.7034e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,518][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([1.0007e-03, 3.1637e-08, 3.5375e-07, 1.9503e-08, 1.7703e-06, 1.6769e-08,
        5.3500e-09, 3.6733e-07, 1.2438e-09, 1.5213e-06, 2.5256e-09, 9.7123e-10,
        1.5274e-07, 1.9327e-09, 4.5056e-08, 1.9689e-07, 1.6331e-09, 9.9899e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,520][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0592, 0.0543, 0.0925, 0.0410, 0.0777, 0.0068, 0.0369, 0.0292, 0.0334,
        0.0786, 0.0148, 0.0410, 0.0709, 0.0486, 0.0839, 0.0090, 0.0401, 0.1821],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,522][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0344, 0.0047, 0.0010, 0.0091, 0.0047, 0.0093, 0.0118, 0.0068, 0.0176,
        0.0088, 0.0357, 0.0491, 0.0324, 0.1537, 0.0134, 0.2239, 0.2807, 0.1030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,523][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.2190, 0.0687, 0.0396, 0.0641, 0.0219, 0.0433, 0.0519, 0.0398, 0.0465,
        0.0537, 0.0484, 0.0564, 0.0114, 0.0491, 0.0358, 0.0619, 0.0589, 0.0296],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,525][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.1104, 0.0713, 0.0357, 0.0642, 0.0401, 0.0475, 0.0483, 0.0406, 0.0541,
        0.0874, 0.0463, 0.0504, 0.0447, 0.0752, 0.0342, 0.0728, 0.0555, 0.0213],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,527][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0870, 0.0577, 0.0240, 0.0566, 0.0344, 0.0566, 0.0485, 0.0278, 0.0454,
        0.0417, 0.0413, 0.0363, 0.0193, 0.0524, 0.0178, 0.0438, 0.0437, 0.2657],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,529][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.1020, 0.0659, 0.0467, 0.0525, 0.0610, 0.0431, 0.0283, 0.0412, 0.0388,
        0.0713, 0.0876, 0.0298, 0.0406, 0.0705, 0.0515, 0.0926, 0.0321, 0.0442],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,530][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1889, 0.0166, 0.0288, 0.0139, 0.0686, 0.0461, 0.0147, 0.0474, 0.0153,
        0.0524, 0.0141, 0.0221, 0.0458, 0.0152, 0.0438, 0.1235, 0.0239, 0.2057,
        0.0133], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,531][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0639e-03, 8.9844e-03, 5.5146e-05, 2.6122e-02, 1.3645e-05, 2.3094e-04,
        1.0626e-03, 3.7214e-05, 2.5759e-02, 1.8240e-04, 1.4920e-02, 1.4073e-03,
        1.6431e-04, 6.9817e-03, 2.6990e-05, 6.6509e-04, 9.9160e-04, 6.9636e-05,
        9.0826e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,532][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1059, 0.0432, 0.0115, 0.0629, 0.0185, 0.0387, 0.0160, 0.0462, 0.0679,
        0.0358, 0.0926, 0.0190, 0.0116, 0.1904, 0.0110, 0.0544, 0.0178, 0.0292,
        0.1273], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,533][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.0776e-03, 5.6831e-05, 2.2723e-06, 2.7251e-05, 1.7499e-06, 6.5029e-05,
        9.0665e-05, 2.7042e-05, 3.5322e-04, 2.3718e-04, 5.3658e-04, 2.1802e-03,
        4.6671e-04, 3.9490e-03, 4.9157e-04, 2.2561e-01, 6.4118e-02, 1.1967e-01,
        5.8104e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,534][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.9389e-02, 1.0373e-03, 3.1120e-04, 1.5395e-03, 1.3489e-04, 1.0372e-02,
        2.7898e-03, 4.3490e-03, 3.8010e-03, 2.4853e-02, 9.7356e-03, 7.2571e-03,
        1.6063e-02, 1.1857e-02, 4.3653e-03, 3.4853e-01, 7.8222e-02, 1.9675e-01,
        2.5865e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,535][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.9793e-02, 4.3631e-02, 2.3839e-03, 5.8751e-02, 6.9002e-04, 2.5048e-02,
        1.8585e-01, 7.4859e-03, 3.9515e-02, 9.6129e-03, 1.6771e-02, 1.3577e-01,
        1.3742e-03, 1.6484e-02, 4.9762e-04, 4.8845e-03, 1.1490e-01, 2.4933e-04,
        3.0631e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,537][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0872, 0.0039, 0.0272, 0.0034, 0.0379, 0.0117, 0.0031, 0.0374, 0.0047,
        0.1066, 0.0170, 0.0027, 0.0741, 0.0047, 0.0540, 0.0566, 0.0052, 0.1556,
        0.3071], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,539][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0144, 0.0021, 0.0018, 0.0028, 0.0016, 0.0026, 0.0030, 0.0042, 0.0037,
        0.0110, 0.0110, 0.0181, 0.0123, 0.0904, 0.0597, 0.1196, 0.1574, 0.2108,
        0.2733], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,541][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0053, 0.0386, 0.0024, 0.0692, 0.0014, 0.0313, 0.0847, 0.0056, 0.0493,
        0.0058, 0.0336, 0.1513, 0.0086, 0.1168, 0.0043, 0.0174, 0.1668, 0.0166,
        0.1909], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,543][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0915, 0.0545, 0.0313, 0.0616, 0.0297, 0.0419, 0.0522, 0.0415, 0.0557,
        0.0442, 0.0558, 0.0599, 0.0314, 0.0628, 0.0338, 0.0550, 0.0670, 0.0466,
        0.0838], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,545][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0718, 0.0549, 0.0241, 0.0706, 0.0199, 0.0553, 0.0636, 0.0348, 0.0629,
        0.0402, 0.0635, 0.0635, 0.0252, 0.0679, 0.0236, 0.0555, 0.0707, 0.0332,
        0.0989], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,547][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1576, 0.0607, 0.0440, 0.0614, 0.0440, 0.0452, 0.0397, 0.0483, 0.0286,
        0.0473, 0.0572, 0.0284, 0.0454, 0.0610, 0.0381, 0.0631, 0.0370, 0.0358,
        0.0572], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,559][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:52,561][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,562][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,562][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,563][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,564][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,564][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,566][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,567][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,568][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,569][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,570][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,571][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,571][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,572][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,573][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,574][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,575][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,577][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,579][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,580][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,582][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,584][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,586][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,586][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,587][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.4984, 0.2809, 0.2207], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,588][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([5.2024e-04, 3.4148e-04, 9.9914e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,588][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.6193, 0.2928, 0.0879], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,589][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([1.5025e-02, 6.9133e-04, 9.8428e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,590][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.1449, 0.0273, 0.8278], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,591][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([3.8860e-02, 2.6837e-05, 9.6111e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,592][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.5044, 0.1736, 0.3220], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,594][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.4944, 0.3359, 0.1697], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,596][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.4818, 0.2892, 0.2290], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,597][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.6084, 0.3210, 0.0706], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,599][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.4442, 0.2427, 0.3131], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,601][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.5164, 0.3243, 0.1593], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,603][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6995, 0.0792, 0.1595, 0.0618], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,603][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3027e-03, 3.9250e-02, 4.0529e-04, 9.5804e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,604][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2393, 0.1791, 0.0303, 0.5512], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,605][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1154, 0.3945, 0.0074, 0.4826], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,606][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3121, 0.1414, 0.2905, 0.2560], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,606][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1231, 0.1971, 0.0067, 0.6732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,607][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6957, 0.0333, 0.2458, 0.0252], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,609][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2546, 0.1936, 0.2602, 0.2915], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,611][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0673, 0.4711, 0.0199, 0.4418], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,612][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4266, 0.2382, 0.1138, 0.2213], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,614][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4109, 0.3061, 0.0811, 0.2019], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,616][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4552, 0.1988, 0.0862, 0.2598], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,618][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.2226, 0.2106, 0.2786, 0.1762, 0.1120], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,619][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([4.1488e-05, 1.1145e-05, 3.8129e-04, 2.3384e-05, 9.9954e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,621][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.3398, 0.2562, 0.0634, 0.1021, 0.2385], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,621][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([2.0640e-03, 2.3342e-05, 3.5369e-03, 1.0093e-04, 9.9427e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,622][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.0227, 0.0051, 0.0676, 0.0040, 0.9006], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,623][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([7.2305e-03, 3.1187e-07, 1.3803e-05, 6.7753e-08, 9.9276e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,624][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.2036, 0.3113, 0.1515, 0.1529, 0.1807], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,624][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.2007, 0.2100, 0.1218, 0.3678, 0.0997], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,626][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.2920, 0.1862, 0.2728, 0.1251, 0.1239], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,628][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.3732, 0.2431, 0.1794, 0.1928, 0.0114], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,630][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.2734, 0.2074, 0.1152, 0.1453, 0.2587], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,631][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.2689, 0.2243, 0.0750, 0.3006, 0.1312], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:52,633][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4179, 0.0367, 0.1146, 0.0366, 0.0723, 0.3219], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,635][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2221e-04, 1.6756e-03, 2.7827e-04, 2.8621e-03, 3.9104e-05, 9.9482e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,636][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4965, 0.1266, 0.0383, 0.1498, 0.0404, 0.1484], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,637][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9407e-03, 5.4301e-03, 8.6579e-04, 1.1491e-02, 1.2590e-03, 9.7601e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,638][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2291, 0.0651, 0.0656, 0.1179, 0.0359, 0.4864], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,639][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9810e-02, 1.8577e-03, 5.2894e-04, 1.2915e-03, 1.2827e-04, 9.5638e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,640][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3616, 0.0270, 0.2979, 0.0253, 0.2518, 0.0363], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,640][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1362, 0.1061, 0.0805, 0.2463, 0.1246, 0.3063], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,641][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0962, 0.2703, 0.0203, 0.3551, 0.0382, 0.2197], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,642][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3145, 0.1896, 0.0932, 0.1954, 0.0753, 0.1320], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,644][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2575, 0.1986, 0.0590, 0.1454, 0.0239, 0.3157], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,646][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4373, 0.1461, 0.0592, 0.1821, 0.0833, 0.0921], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:52,648][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5270, 0.0607, 0.1023, 0.0459, 0.1478, 0.0756, 0.0407],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,649][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5617e-04, 4.3027e-03, 9.5226e-04, 4.3007e-03, 3.3981e-04, 4.6860e-04,
        9.8878e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,651][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3025, 0.1876, 0.0489, 0.2213, 0.0677, 0.1253, 0.0468],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,652][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0293, 0.0180, 0.0054, 0.0331, 0.0190, 0.1788, 0.7165],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,654][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1477, 0.0325, 0.0498, 0.0458, 0.0391, 0.4618, 0.2234],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,655][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0554, 0.1285, 0.0137, 0.0961, 0.0016, 0.0444, 0.6603],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,656][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3817, 0.0127, 0.2520, 0.0108, 0.2743, 0.0561, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,657][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1029, 0.0618, 0.0442, 0.1382, 0.1021, 0.2318, 0.3191],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,658][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0241, 0.1313, 0.0080, 0.1950, 0.0064, 0.1425, 0.4926],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,658][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2672, 0.1711, 0.0849, 0.1736, 0.0586, 0.1077, 0.1369],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,659][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2286, 0.1949, 0.0726, 0.1653, 0.0254, 0.0846, 0.2285],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,661][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3417, 0.1370, 0.0856, 0.1471, 0.0870, 0.0883, 0.1133],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:52,663][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3708, 0.0820, 0.1072, 0.0866, 0.0841, 0.0773, 0.0917, 0.1001],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,664][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6438e-04, 1.0272e-03, 2.3119e-04, 1.2075e-03, 2.7504e-03, 1.3658e-03,
        5.0268e-04, 9.9265e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,666][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2772, 0.1072, 0.0428, 0.1916, 0.1294, 0.1424, 0.0739, 0.0354],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,667][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0769e-03, 1.2859e-04, 2.6873e-05, 2.5214e-04, 5.8465e-04, 2.0038e-03,
        1.6737e-03, 9.9425e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,670][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0466, 0.0144, 0.0032, 0.0160, 0.0206, 0.0615, 0.0724, 0.7653],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,671][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2508e-03, 1.1952e-04, 6.8451e-05, 1.7785e-05, 2.9281e-04, 9.6438e-06,
        5.2859e-06, 9.9624e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,672][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.3063, 0.0662, 0.1068, 0.0386, 0.1621, 0.0438, 0.0572, 0.2192],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,673][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0875, 0.0471, 0.0431, 0.0928, 0.1003, 0.1506, 0.2783, 0.2003],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,674][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1264, 0.1535, 0.0237, 0.1419, 0.0388, 0.1158, 0.3438, 0.0561],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,675][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2406, 0.1526, 0.0713, 0.1477, 0.0998, 0.0992, 0.1272, 0.0616],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,675][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2098, 0.1507, 0.0380, 0.1246, 0.0496, 0.0840, 0.0839, 0.2594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,676][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4653, 0.0891, 0.0636, 0.0923, 0.0733, 0.0630, 0.0464, 0.1069],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:52,678][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3620, 0.0569, 0.0994, 0.0410, 0.1433, 0.0747, 0.0497, 0.1412, 0.0317],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,680][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9874e-04, 1.5861e-02, 5.7776e-05, 2.1565e-02, 1.3822e-05, 6.7604e-04,
        3.8738e-04, 9.5703e-05, 9.6044e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,681][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3022, 0.1432, 0.0483, 0.1331, 0.0501, 0.0770, 0.0610, 0.0848, 0.1002],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,683][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0051, 0.0030, 0.0013, 0.0068, 0.0270, 0.0444, 0.0596, 0.3647, 0.4882],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,685][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1595, 0.0218, 0.0457, 0.0259, 0.0339, 0.1148, 0.0743, 0.3443, 0.1798],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,687][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0225, 0.0908, 0.0068, 0.1066, 0.0008, 0.0653, 0.2345, 0.0072, 0.4655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,689][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2319, 0.0198, 0.1628, 0.0174, 0.2611, 0.0452, 0.0182, 0.2312, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,690][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0544, 0.0263, 0.0273, 0.0551, 0.0484, 0.1089, 0.1842, 0.2735, 0.2219],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,690][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0229, 0.1177, 0.0101, 0.1840, 0.0091, 0.1239, 0.3541, 0.0216, 0.1567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,691][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2066, 0.1349, 0.0718, 0.1381, 0.0447, 0.0866, 0.1127, 0.0806, 0.1241],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,692][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1710, 0.1585, 0.0445, 0.1499, 0.0214, 0.0774, 0.0921, 0.0598, 0.2254],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,693][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2630, 0.1144, 0.0784, 0.1348, 0.0946, 0.0786, 0.0849, 0.1009, 0.0504],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:52,694][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2534, 0.1022, 0.1244, 0.0938, 0.0503, 0.0357, 0.0896, 0.0995, 0.0552,
        0.0958], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,695][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4094e-04, 4.5741e-05, 5.3802e-05, 3.7528e-05, 9.1370e-04, 2.0432e-05,
        1.1351e-03, 8.8515e-04, 1.7986e-05, 9.9675e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,697][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1998, 0.0693, 0.0666, 0.1107, 0.0839, 0.1006, 0.0923, 0.0744, 0.1021,
        0.1002], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,699][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4560e-04, 8.2933e-06, 1.3955e-05, 8.7074e-06, 4.7770e-04, 2.8318e-04,
        2.2884e-04, 1.8475e-03, 2.9436e-04, 9.9639e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,700][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([1.2322e-02, 2.0733e-03, 4.9860e-04, 2.4430e-03, 4.3665e-03, 1.0323e-02,
        1.0829e-02, 1.3873e-02, 9.5487e-03, 9.3372e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,701][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2282e-03, 2.8176e-05, 1.0355e-05, 3.7843e-06, 1.2672e-04, 4.2782e-07,
        1.7978e-06, 1.4491e-04, 2.7546e-07, 9.9546e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,703][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1668, 0.0354, 0.1050, 0.0276, 0.3518, 0.0232, 0.0251, 0.1100, 0.0300,
        0.1251], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,705][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0943, 0.0235, 0.0034, 0.0506, 0.0274, 0.0700, 0.1397, 0.1967, 0.2643,
        0.1301], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,706][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1330, 0.1229, 0.0309, 0.1824, 0.0118, 0.1076, 0.2012, 0.0660, 0.1060,
        0.0382], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,707][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1991, 0.1216, 0.0694, 0.1162, 0.0572, 0.0874, 0.1002, 0.0811, 0.1073,
        0.0605], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,708][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1344, 0.1047, 0.0333, 0.1017, 0.0500, 0.0576, 0.0845, 0.0882, 0.0731,
        0.2725], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,709][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.3162, 0.1574, 0.0593, 0.1174, 0.0427, 0.0716, 0.0661, 0.0466, 0.0551,
        0.0677], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:52,710][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2498, 0.0353, 0.0718, 0.0326, 0.1226, 0.0459, 0.0511, 0.1350, 0.0318,
        0.1999, 0.0241], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,710][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4903e-04, 1.5253e-03, 3.8247e-04, 3.7661e-03, 5.4628e-05, 1.5078e-04,
        1.4846e-03, 3.0389e-05, 4.3040e-03, 3.3107e-05, 9.8752e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,712][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1999, 0.1032, 0.0244, 0.1220, 0.0480, 0.0807, 0.0452, 0.0638, 0.1181,
        0.0805, 0.1143], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,714][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0223e-03, 3.5273e-04, 5.2364e-05, 6.9237e-04, 2.6455e-04, 4.8611e-03,
        7.4762e-03, 3.9665e-03, 3.0001e-02, 1.3051e-01, 8.2080e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,716][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0619, 0.0063, 0.0092, 0.0095, 0.0092, 0.0582, 0.0342, 0.0468, 0.0707,
        0.3783, 0.3156], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,717][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0545, 0.0231, 0.0047, 0.0096, 0.0011, 0.0363, 0.0160, 0.0012, 0.0039,
        0.0009, 0.8486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,719][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1697, 0.0129, 0.1708, 0.0127, 0.1981, 0.0415, 0.0163, 0.1802, 0.0125,
        0.1652, 0.0202], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,721][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0365, 0.0124, 0.0085, 0.0280, 0.0220, 0.0467, 0.0819, 0.1097, 0.1263,
        0.1928, 0.3350], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,723][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0240, 0.1163, 0.0084, 0.2109, 0.0069, 0.1121, 0.1975, 0.0245, 0.1666,
        0.0261, 0.1068], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,724][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1514, 0.1056, 0.0548, 0.1144, 0.0454, 0.0791, 0.0914, 0.0704, 0.1102,
        0.0735, 0.1039], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,725][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1438, 0.1112, 0.0492, 0.1145, 0.0289, 0.0835, 0.0965, 0.0347, 0.0924,
        0.0304, 0.2149], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,726][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2604, 0.0892, 0.0492, 0.0926, 0.0660, 0.0552, 0.0482, 0.0872, 0.0485,
        0.0845, 0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:52,727][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4054, 0.0344, 0.0646, 0.0222, 0.1130, 0.0449, 0.0197, 0.0874, 0.0197,
        0.1435, 0.0211, 0.0240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,728][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9752e-03, 1.8211e-02, 4.4758e-04, 3.9243e-02, 6.1857e-05, 2.7152e-04,
        3.3100e-02, 8.6441e-05, 6.8755e-02, 7.4393e-05, 4.1117e-02, 7.9566e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,729][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1839, 0.0900, 0.0271, 0.1004, 0.0337, 0.0934, 0.0292, 0.0691, 0.1120,
        0.0622, 0.1694, 0.0296], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,730][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0776e-02, 1.6539e-03, 4.2536e-04, 1.8835e-03, 9.5281e-04, 7.3266e-03,
        1.8903e-02, 1.2121e-02, 6.1572e-02, 5.5885e-02, 1.8266e-01, 6.4584e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,732][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1117, 0.0124, 0.0166, 0.0164, 0.0133, 0.0781, 0.0335, 0.0503, 0.0983,
        0.1416, 0.2321, 0.1957], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,734][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0656, 0.1028, 0.0191, 0.0841, 0.0070, 0.0629, 0.2062, 0.0501, 0.0540,
        0.0112, 0.0576, 0.2794], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,736][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1964, 0.0033, 0.1512, 0.0031, 0.2385, 0.0189, 0.0036, 0.1656, 0.0027,
        0.2074, 0.0071, 0.0022], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,738][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0383, 0.0090, 0.0062, 0.0178, 0.0171, 0.0231, 0.0368, 0.0578, 0.0950,
        0.0976, 0.2951, 0.3064], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,740][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0084, 0.0713, 0.0051, 0.1146, 0.0047, 0.0747, 0.2405, 0.0078, 0.0764,
        0.0135, 0.0510, 0.3319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,741][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1691, 0.0955, 0.0522, 0.0991, 0.0435, 0.0694, 0.0792, 0.0647, 0.0920,
        0.0499, 0.0933, 0.0919], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,742][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1728, 0.1058, 0.0718, 0.1055, 0.0257, 0.0539, 0.1106, 0.0411, 0.0634,
        0.0298, 0.0728, 0.1468], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,743][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1996, 0.0803, 0.0563, 0.0842, 0.0780, 0.0521, 0.0871, 0.0767, 0.0319,
        0.0797, 0.0794, 0.0947], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:52,744][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1472, 0.0787, 0.1039, 0.0825, 0.1104, 0.0462, 0.0755, 0.0246, 0.0705,
        0.0540, 0.0592, 0.0742, 0.0732], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,745][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([4.4804e-04, 9.2915e-04, 8.5055e-04, 2.4526e-03, 3.6072e-05, 5.2416e-04,
        6.6010e-05, 4.9759e-05, 1.3508e-03, 1.6325e-04, 3.2751e-03, 2.8654e-04,
        9.8957e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,746][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1343, 0.0583, 0.0952, 0.0561, 0.0483, 0.0569, 0.0611, 0.0635, 0.0695,
        0.0529, 0.0770, 0.0545, 0.1723], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,747][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([4.9432e-03, 1.1594e-05, 5.7583e-05, 1.7215e-05, 1.5093e-05, 2.1473e-04,
        4.1502e-05, 5.1115e-04, 3.6278e-04, 5.5407e-03, 1.1772e-03, 7.4247e-04,
        9.8636e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,749][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.3831e-02, 1.7535e-03, 5.8024e-03, 2.1580e-03, 3.6640e-04, 3.0496e-03,
        3.7120e-03, 9.0333e-03, 6.0967e-03, 6.0604e-02, 2.5155e-02, 1.7571e-02,
        8.4087e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,750][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([3.8948e-02, 3.2989e-05, 3.1992e-04, 1.0390e-05, 4.4542e-06, 1.6301e-05,
        3.1188e-06, 1.8543e-05, 5.1626e-06, 6.1131e-06, 1.5124e-05, 1.9200e-06,
        9.6062e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,752][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.1744, 0.0452, 0.1577, 0.0247, 0.0843, 0.0164, 0.0304, 0.0337, 0.0150,
        0.1762, 0.0122, 0.0230, 0.2069], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,754][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0141, 0.0123, 0.0008, 0.0131, 0.0015, 0.0293, 0.0292, 0.0265, 0.0562,
        0.3221, 0.1531, 0.2388, 0.1031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,756][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0980, 0.1001, 0.0737, 0.0969, 0.0251, 0.0330, 0.0655, 0.0351, 0.0965,
        0.1016, 0.0747, 0.0690, 0.1310], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,758][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1484, 0.0959, 0.0794, 0.0869, 0.0551, 0.0574, 0.0787, 0.0596, 0.0756,
        0.0896, 0.0738, 0.0868, 0.0126], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,759][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0893, 0.0752, 0.0528, 0.0901, 0.0336, 0.0537, 0.0651, 0.0264, 0.0696,
        0.0263, 0.0857, 0.0666, 0.2655], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,760][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1763, 0.0828, 0.0535, 0.0704, 0.0530, 0.0598, 0.0473, 0.0531, 0.0658,
        0.0789, 0.0781, 0.0334, 0.1476], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:52,760][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4187, 0.0131, 0.0594, 0.0109, 0.1107, 0.0456, 0.0205, 0.0739, 0.0084,
        0.1019, 0.0159, 0.0348, 0.0767, 0.0095], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,761][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9674e-03, 2.9778e-02, 1.1500e-04, 5.5128e-03, 3.0904e-04, 1.1796e-04,
        2.6026e-04, 2.2075e-04, 2.5136e-03, 7.6672e-05, 1.1375e-03, 2.5240e-04,
        1.1771e-04, 9.5662e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,762][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3407, 0.0435, 0.0325, 0.0372, 0.0368, 0.1907, 0.0172, 0.0460, 0.0820,
        0.0363, 0.0507, 0.0212, 0.0212, 0.0441], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,763][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.1897e-02, 1.4145e-03, 2.5606e-04, 1.3705e-03, 5.7079e-04, 4.2735e-03,
        4.6068e-03, 1.8719e-02, 1.7924e-02, 1.9041e-02, 6.1596e-02, 1.6731e-01,
        2.3530e-01, 4.5572e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,765][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0306, 0.0103, 0.0052, 0.0197, 0.0064, 0.0213, 0.0182, 0.0451, 0.0602,
        0.0682, 0.1393, 0.1192, 0.1239, 0.3323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,767][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1024, 0.1628, 0.0369, 0.1043, 0.0085, 0.0722, 0.0784, 0.0328, 0.0515,
        0.0108, 0.0544, 0.0631, 0.0122, 0.2096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,768][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2509, 0.0064, 0.1043, 0.0048, 0.1860, 0.0132, 0.0064, 0.0975, 0.0039,
        0.2059, 0.0084, 0.0042, 0.1051, 0.0031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,771][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0192, 0.0046, 0.0038, 0.0086, 0.0073, 0.0129, 0.0196, 0.0321, 0.0334,
        0.0709, 0.0996, 0.1540, 0.1060, 0.4279], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,773][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0143, 0.1268, 0.0064, 0.1011, 0.0046, 0.0225, 0.0845, 0.0064, 0.0606,
        0.0048, 0.0400, 0.1367, 0.0064, 0.3847], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,774][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1445, 0.0807, 0.0529, 0.0839, 0.0485, 0.0640, 0.0646, 0.0609, 0.0676,
        0.0604, 0.0708, 0.0729, 0.0395, 0.0889], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,776][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1080, 0.0911, 0.0386, 0.0981, 0.0426, 0.0742, 0.0608, 0.0638, 0.0761,
        0.0535, 0.0752, 0.0610, 0.0287, 0.1283], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,777][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2160, 0.0753, 0.0504, 0.0715, 0.0597, 0.0504, 0.0437, 0.0697, 0.0356,
        0.0635, 0.0753, 0.0338, 0.0614, 0.0936], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:52,778][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.1752, 0.0799, 0.0865, 0.0553, 0.1532, 0.0106, 0.0339, 0.0114, 0.0396,
        0.0229, 0.0330, 0.0508, 0.0940, 0.0592, 0.0944], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,779][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([1.9742e-04, 4.8450e-05, 5.2161e-01, 9.6644e-05, 1.6458e-04, 2.5903e-05,
        4.0502e-05, 1.2722e-05, 2.6139e-05, 1.3570e-05, 1.2209e-04, 3.5066e-05,
        1.6157e-04, 9.4305e-06, 4.7744e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,779][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.2201, 0.1005, 0.0648, 0.0384, 0.0182, 0.0569, 0.0725, 0.0190, 0.0642,
        0.0217, 0.0543, 0.0728, 0.0751, 0.0715, 0.0499], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,781][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([4.4437e-04, 9.2955e-07, 8.7433e-04, 1.6603e-06, 3.2523e-05, 5.9363e-06,
        7.8811e-06, 8.7410e-06, 3.4894e-05, 2.9277e-05, 9.6440e-05, 1.4378e-04,
        4.0096e-04, 2.1287e-04, 9.9771e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,783][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0102, 0.0015, 0.0297, 0.0015, 0.0117, 0.0020, 0.0011, 0.0012, 0.0038,
        0.0019, 0.0101, 0.0045, 0.0031, 0.0117, 0.9061], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,784][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([4.9491e-03, 2.1651e-06, 7.0066e-01, 1.5632e-07, 1.3840e-05, 6.5416e-07,
        2.9530e-07, 9.0520e-07, 1.5832e-07, 2.3245e-07, 3.0346e-07, 1.1095e-07,
        1.0921e-06, 3.5826e-08, 2.9437e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,786][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.1452, 0.0577, 0.1802, 0.0378, 0.1564, 0.0124, 0.0195, 0.0158, 0.0256,
        0.0219, 0.0111, 0.0323, 0.0826, 0.0264, 0.1749], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,788][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0320, 0.0059, 0.0043, 0.0152, 0.0534, 0.0150, 0.0251, 0.0260, 0.0374,
        0.0061, 0.0944, 0.1208, 0.0466, 0.3521, 0.1658], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,790][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.1155, 0.0731, 0.0946, 0.0633, 0.1224, 0.0224, 0.0479, 0.0237, 0.0582,
        0.0372, 0.0426, 0.0790, 0.0596, 0.0580, 0.1025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,792][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.1421, 0.0857, 0.0224, 0.0763, 0.0794, 0.0513, 0.0610, 0.0466, 0.0664,
        0.0591, 0.0661, 0.0821, 0.0539, 0.0852, 0.0223], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,794][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0863, 0.0635, 0.2221, 0.0605, 0.0400, 0.0289, 0.0451, 0.0146, 0.0409,
        0.0141, 0.0453, 0.0589, 0.0228, 0.0434, 0.2136], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,796][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.1107, 0.0619, 0.0486, 0.0566, 0.0607, 0.0759, 0.0535, 0.0750, 0.0274,
        0.0969, 0.0602, 0.0408, 0.0710, 0.0949, 0.0659], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:52,797][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2313, 0.0228, 0.0215, 0.0274, 0.0463, 0.1134, 0.0217, 0.0552, 0.0267,
        0.0442, 0.0218, 0.0202, 0.0557, 0.0182, 0.0243, 0.2496],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,798][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7512e-04, 5.8238e-04, 3.0369e-04, 1.2664e-03, 3.4777e-04, 6.5390e-03,
        1.4122e-04, 3.2847e-04, 7.6588e-04, 1.2333e-04, 3.5798e-04, 1.7579e-04,
        1.1229e-04, 5.0884e-05, 1.6638e-04, 9.8836e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,799][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1848, 0.0463, 0.0174, 0.0558, 0.0240, 0.0831, 0.0480, 0.0625, 0.0797,
        0.0700, 0.0786, 0.0590, 0.0145, 0.0784, 0.0150, 0.0828],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,800][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5930e-04, 4.6038e-06, 5.9219e-07, 3.9996e-06, 3.4648e-06, 4.5601e-05,
        1.1807e-05, 3.8660e-05, 4.7182e-05, 2.9246e-04, 1.4123e-04, 2.0665e-04,
        4.7210e-04, 6.5253e-04, 4.6365e-04, 9.9676e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,801][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0885, 0.0069, 0.0026, 0.0069, 0.0038, 0.0114, 0.0080, 0.0108, 0.0202,
        0.0242, 0.0420, 0.0228, 0.0234, 0.0457, 0.0315, 0.6514],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,802][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9498e-02, 2.1591e-05, 1.0687e-04, 2.1852e-05, 1.0031e-03, 1.8021e-03,
        1.2755e-05, 7.0345e-06, 5.9578e-06, 5.3208e-05, 1.5019e-05, 7.0729e-06,
        1.0871e-06, 1.0696e-06, 1.7298e-05, 9.5743e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,804][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1061, 0.0133, 0.1046, 0.0130, 0.1020, 0.0158, 0.0190, 0.0855, 0.0098,
        0.1639, 0.0114, 0.0147, 0.1286, 0.0136, 0.1661, 0.0326],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,806][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0183, 0.0041, 0.0038, 0.0060, 0.0035, 0.0060, 0.0116, 0.0135, 0.0149,
        0.0235, 0.0546, 0.0751, 0.0353, 0.3007, 0.2102, 0.2188],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,808][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0748, 0.0739, 0.0179, 0.0935, 0.0112, 0.0405, 0.1065, 0.0366, 0.0824,
        0.0663, 0.0768, 0.1291, 0.0279, 0.1002, 0.0259, 0.0365],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,810][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1140, 0.0625, 0.0421, 0.0663, 0.0402, 0.0618, 0.0554, 0.0554, 0.0612,
        0.0753, 0.0554, 0.0597, 0.0504, 0.0899, 0.0496, 0.0609],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,812][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0807, 0.0569, 0.0331, 0.0642, 0.0311, 0.1069, 0.0523, 0.0312, 0.0551,
        0.0345, 0.0569, 0.0502, 0.0239, 0.0676, 0.0325, 0.2228],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,814][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2222, 0.0784, 0.0364, 0.0937, 0.0470, 0.0412, 0.0376, 0.0474, 0.0397,
        0.0459, 0.0696, 0.0338, 0.0370, 0.0845, 0.0303, 0.0554],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:52,815][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2679, 0.0211, 0.0384, 0.0164, 0.0788, 0.0341, 0.0147, 0.0652, 0.0139,
        0.1127, 0.0137, 0.0259, 0.0622, 0.0193, 0.0537, 0.1394, 0.0225],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,816][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3928e-04, 1.1435e-03, 2.7662e-04, 1.2520e-03, 1.3300e-04, 1.3495e-04,
        4.3327e-01, 1.8445e-04, 1.1689e-03, 9.9723e-04, 3.4121e-03, 1.4675e-02,
        2.1876e-05, 2.8411e-04, 1.4097e-04, 1.1750e-04, 5.4234e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,817][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1038, 0.0531, 0.0192, 0.0809, 0.0288, 0.0486, 0.0165, 0.0615, 0.0815,
        0.0459, 0.1237, 0.0192, 0.0140, 0.1721, 0.0207, 0.0920, 0.0186],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,818][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.5990e-03, 2.7349e-04, 3.2196e-05, 1.7509e-04, 9.5005e-05, 3.7659e-04,
        1.3114e-03, 5.5523e-04, 1.7491e-03, 1.7575e-03, 4.7775e-03, 1.9528e-02,
        8.0118e-03, 2.8985e-02, 1.2204e-02, 1.3241e-01, 7.8416e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,819][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0233, 0.0028, 0.0025, 0.0030, 0.0015, 0.0195, 0.0077, 0.0072, 0.0117,
        0.0270, 0.0255, 0.0195, 0.0163, 0.0226, 0.0443, 0.5663, 0.1992],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,821][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0165, 0.0527, 0.0072, 0.0462, 0.0009, 0.0247, 0.4145, 0.0038, 0.0248,
        0.0043, 0.0314, 0.1009, 0.0009, 0.0131, 0.0016, 0.0038, 0.2527],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,823][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1209, 0.0028, 0.0845, 0.0027, 0.1116, 0.0177, 0.0031, 0.1155, 0.0030,
        0.1463, 0.0061, 0.0024, 0.1266, 0.0026, 0.1695, 0.0802, 0.0046],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,825][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0144, 0.0026, 0.0015, 0.0041, 0.0025, 0.0037, 0.0042, 0.0076, 0.0099,
        0.0124, 0.0312, 0.0366, 0.0289, 0.2079, 0.0777, 0.2855, 0.2691],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,826][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0339, 0.0023, 0.0595, 0.0023, 0.0462, 0.1369, 0.0065, 0.0438,
        0.0112, 0.0356, 0.1959, 0.0101, 0.1002, 0.0047, 0.0235, 0.2806],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,829][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1081, 0.0662, 0.0385, 0.0728, 0.0327, 0.0489, 0.0569, 0.0480, 0.0672,
        0.0423, 0.0665, 0.0684, 0.0366, 0.0718, 0.0412, 0.0615, 0.0724],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,831][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0757, 0.0588, 0.0319, 0.0694, 0.0177, 0.0461, 0.1287, 0.0346, 0.0551,
        0.0395, 0.0710, 0.0831, 0.0249, 0.0561, 0.0293, 0.0367, 0.1414],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,833][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1763, 0.0661, 0.0488, 0.0632, 0.0441, 0.0429, 0.0485, 0.0560, 0.0277,
        0.0543, 0.0551, 0.0358, 0.0507, 0.0713, 0.0448, 0.0670, 0.0475],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:52,833][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.1572, 0.0666, 0.0510, 0.0496, 0.0509, 0.0327, 0.0255, 0.0460, 0.0473,
        0.0460, 0.0383, 0.0339, 0.0332, 0.0432, 0.0464, 0.0582, 0.0290, 0.1450],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,834][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([3.2830e-05, 2.9171e-05, 2.3102e-05, 2.9540e-05, 1.8070e-04, 2.1182e-05,
        3.0257e-06, 2.2951e-06, 4.6391e-06, 1.5822e-05, 4.5806e-06, 8.7060e-07,
        2.0966e-05, 5.1429e-06, 6.6147e-06, 2.0087e-05, 1.5464e-06, 9.9960e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,835][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.1253, 0.0323, 0.0398, 0.0464, 0.0587, 0.0398, 0.0604, 0.0496, 0.0425,
        0.0859, 0.0366, 0.0696, 0.1440, 0.0385, 0.0334, 0.0275, 0.0631, 0.0066],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,836][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([3.4760e-04, 1.6658e-07, 6.5448e-08, 1.2658e-07, 1.0072e-06, 6.6575e-07,
        4.4349e-07, 7.9646e-06, 1.3555e-06, 1.2353e-04, 4.1648e-06, 3.2219e-06,
        1.0228e-04, 3.1504e-05, 2.1507e-05, 2.1461e-03, 1.6712e-04, 9.9704e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,837][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([1.5116e-02, 3.0588e-04, 3.0929e-04, 1.8164e-04, 2.6389e-04, 9.2443e-05,
        2.0387e-04, 3.9107e-04, 4.3238e-04, 2.2370e-03, 6.3771e-04, 4.7657e-04,
        8.2955e-04, 8.3532e-04, 1.6791e-03, 3.5497e-03, 2.1195e-03, 9.7034e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,839][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([1.0007e-03, 3.1637e-08, 3.5375e-07, 1.9503e-08, 1.7703e-06, 1.6769e-08,
        5.3500e-09, 3.6733e-07, 1.2438e-09, 1.5213e-06, 2.5256e-09, 9.7123e-10,
        1.5274e-07, 1.9327e-09, 4.5056e-08, 1.9689e-07, 1.6331e-09, 9.9899e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,841][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0592, 0.0543, 0.0925, 0.0410, 0.0777, 0.0068, 0.0369, 0.0292, 0.0334,
        0.0786, 0.0148, 0.0410, 0.0709, 0.0486, 0.0839, 0.0090, 0.0401, 0.1821],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,842][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0344, 0.0047, 0.0010, 0.0091, 0.0047, 0.0093, 0.0118, 0.0068, 0.0176,
        0.0088, 0.0357, 0.0491, 0.0324, 0.1537, 0.0134, 0.2239, 0.2807, 0.1030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,844][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.2190, 0.0687, 0.0396, 0.0641, 0.0219, 0.0433, 0.0519, 0.0398, 0.0465,
        0.0537, 0.0484, 0.0564, 0.0114, 0.0491, 0.0358, 0.0619, 0.0589, 0.0296],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,846][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.1104, 0.0713, 0.0357, 0.0642, 0.0401, 0.0475, 0.0483, 0.0406, 0.0541,
        0.0874, 0.0463, 0.0504, 0.0447, 0.0752, 0.0342, 0.0728, 0.0555, 0.0213],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,848][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0870, 0.0577, 0.0240, 0.0566, 0.0344, 0.0566, 0.0485, 0.0278, 0.0454,
        0.0417, 0.0413, 0.0363, 0.0193, 0.0524, 0.0178, 0.0438, 0.0437, 0.2657],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,850][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.1020, 0.0659, 0.0467, 0.0525, 0.0610, 0.0431, 0.0283, 0.0412, 0.0388,
        0.0713, 0.0876, 0.0298, 0.0406, 0.0705, 0.0515, 0.0926, 0.0321, 0.0442],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:52,851][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1889, 0.0166, 0.0288, 0.0139, 0.0686, 0.0461, 0.0147, 0.0474, 0.0153,
        0.0524, 0.0141, 0.0221, 0.0458, 0.0152, 0.0438, 0.1235, 0.0239, 0.2057,
        0.0133], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,852][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0639e-03, 8.9844e-03, 5.5146e-05, 2.6122e-02, 1.3645e-05, 2.3094e-04,
        1.0626e-03, 3.7214e-05, 2.5759e-02, 1.8240e-04, 1.4920e-02, 1.4073e-03,
        1.6431e-04, 6.9817e-03, 2.6990e-05, 6.6509e-04, 9.9160e-04, 6.9636e-05,
        9.0826e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,853][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1059, 0.0432, 0.0115, 0.0629, 0.0185, 0.0387, 0.0160, 0.0462, 0.0679,
        0.0358, 0.0926, 0.0190, 0.0116, 0.1904, 0.0110, 0.0544, 0.0178, 0.0292,
        0.1273], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,853][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.0776e-03, 5.6831e-05, 2.2723e-06, 2.7251e-05, 1.7499e-06, 6.5029e-05,
        9.0665e-05, 2.7042e-05, 3.5322e-04, 2.3718e-04, 5.3658e-04, 2.1802e-03,
        4.6671e-04, 3.9490e-03, 4.9157e-04, 2.2561e-01, 6.4118e-02, 1.1967e-01,
        5.8104e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,855][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.9389e-02, 1.0373e-03, 3.1120e-04, 1.5395e-03, 1.3489e-04, 1.0372e-02,
        2.7898e-03, 4.3490e-03, 3.8010e-03, 2.4853e-02, 9.7356e-03, 7.2571e-03,
        1.6063e-02, 1.1857e-02, 4.3653e-03, 3.4853e-01, 7.8222e-02, 1.9675e-01,
        2.5865e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,856][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.9793e-02, 4.3631e-02, 2.3839e-03, 5.8751e-02, 6.9002e-04, 2.5048e-02,
        1.8585e-01, 7.4859e-03, 3.9515e-02, 9.6129e-03, 1.6771e-02, 1.3577e-01,
        1.3742e-03, 1.6484e-02, 4.9762e-04, 4.8845e-03, 1.1490e-01, 2.4933e-04,
        3.0631e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,858][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0872, 0.0039, 0.0272, 0.0034, 0.0379, 0.0117, 0.0031, 0.0374, 0.0047,
        0.1066, 0.0170, 0.0027, 0.0741, 0.0047, 0.0540, 0.0566, 0.0052, 0.1556,
        0.3071], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,860][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0144, 0.0021, 0.0018, 0.0028, 0.0016, 0.0026, 0.0030, 0.0042, 0.0037,
        0.0110, 0.0110, 0.0181, 0.0123, 0.0904, 0.0597, 0.1196, 0.1574, 0.2108,
        0.2733], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,862][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0053, 0.0386, 0.0024, 0.0692, 0.0014, 0.0313, 0.0847, 0.0056, 0.0493,
        0.0058, 0.0336, 0.1513, 0.0086, 0.1168, 0.0043, 0.0174, 0.1668, 0.0166,
        0.1909], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,864][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0915, 0.0545, 0.0313, 0.0616, 0.0297, 0.0419, 0.0522, 0.0415, 0.0557,
        0.0442, 0.0558, 0.0599, 0.0314, 0.0628, 0.0338, 0.0550, 0.0670, 0.0466,
        0.0838], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,866][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0718, 0.0549, 0.0241, 0.0706, 0.0199, 0.0553, 0.0636, 0.0348, 0.0629,
        0.0402, 0.0635, 0.0635, 0.0252, 0.0679, 0.0236, 0.0555, 0.0707, 0.0332,
        0.0989], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,867][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1576, 0.0607, 0.0440, 0.0614, 0.0440, 0.0452, 0.0397, 0.0483, 0.0286,
        0.0473, 0.0572, 0.0284, 0.0454, 0.0610, 0.0381, 0.0631, 0.0370, 0.0358,
        0.0572], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:52,871][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:52,873][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[25466],
        [12225],
        [ 4053],
        [ 8444],
        [    1],
        [11759],
        [21802],
        [19347],
        [ 9620],
        [13709],
        [18448],
        [17429],
        [27121],
        [ 5896],
        [ 3188],
        [ 5705],
        [23266],
        [24911],
        [ 9596]], device='cuda:0')
[2024-07-24 10:18:52,875][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[41859],
        [45560],
        [ 9796],
        [42524],
        [    1],
        [45634],
        [35679],
        [43909],
        [41908],
        [29365],
        [35170],
        [29793],
        [46171],
        [38777],
        [ 2813],
        [25277],
        [25358],
        [28490],
        [34533]], device='cuda:0')
[2024-07-24 10:18:52,877][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13278],
        [12574],
        [ 7430],
        [ 9203],
        [ 4369],
        [ 1874],
        [ 2259],
        [ 3394],
        [ 2380],
        [ 4052],
        [ 2264],
        [ 2598],
        [ 2804],
        [ 2626],
        [ 2581],
        [ 2549],
        [ 2113],
        [ 3564],
        [ 2582]], device='cuda:0')
[2024-07-24 10:18:52,879][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[41182],
        [14752],
        [15111],
        [22098],
        [  213],
        [29964],
        [44251],
        [13988],
        [29524],
        [30823],
        [41130],
        [42686],
        [29522],
        [11617],
        [13099],
        [ 8190],
        [43151],
        [ 5868],
        [30356]], device='cuda:0')
[2024-07-24 10:18:52,881][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13554],
        [13100],
        [12753],
        [ 7356],
        [ 8129],
        [12286],
        [10760],
        [10739],
        [12474],
        [14159],
        [15628],
        [16460],
        [12838],
        [17245],
        [14782],
        [16053],
        [17473],
        [13136],
        [20246]], device='cuda:0')
[2024-07-24 10:18:52,883][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40079],
        [40076],
        [40844],
        [23981],
        [  169],
        [14651],
        [19698],
        [16191],
        [23372],
        [ 2343],
        [32118],
        [31009],
        [42759],
        [37593],
        [41593],
        [23119],
        [29397],
        [10739],
        [26669]], device='cuda:0')
[2024-07-24 10:18:52,885][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30136],
        [29816],
        [ 1068],
        [10266],
        [ 9288],
        [18894],
        [14862],
        [10109],
        [11091],
        [20142],
        [17341],
        [16038],
        [29366],
        [ 5314],
        [  688],
        [30648],
        [24350],
        [46811],
        [37728]], device='cuda:0')
[2024-07-24 10:18:52,887][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29147],
        [23918],
        [29011],
        [31066],
        [  159],
        [31623],
        [32269],
        [26555],
        [31628],
        [16099],
        [36695],
        [31470],
        [42833],
        [34226],
        [30974],
        [35806],
        [33547],
        [26320],
        [34323]], device='cuda:0')
[2024-07-24 10:18:52,888][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44905],
        [44818],
        [21207],
        [31234],
        [ 6628],
        [ 1254],
        [ 1049],
        [13826],
        [ 4248],
        [  197],
        [ 3113],
        [ 2100],
        [ 5253],
        [ 3306],
        [ 1584],
        [ 3615],
        [ 5867],
        [ 4375],
        [ 6575]], device='cuda:0')
[2024-07-24 10:18:52,890][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 6493],
        [ 6682],
        [ 9265],
        [25913],
        [30268],
        [35803],
        [31815],
        [32329],
        [34095],
        [31970],
        [27650],
        [25444],
        [28863],
        [24166],
        [26618],
        [23086],
        [23677],
        [26937],
        [42174]], device='cuda:0')
[2024-07-24 10:18:52,892][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7327],
        [20920],
        [ 7258],
        [23663],
        [ 4426],
        [20451],
        [24448],
        [17743],
        [22133],
        [15934],
        [19392],
        [18837],
        [ 9970],
        [16643],
        [ 4401],
        [12198],
        [19597],
        [ 9156],
        [18623]], device='cuda:0')
[2024-07-24 10:18:52,894][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18985],
        [26954],
        [25353],
        [29949],
        [26394],
        [30442],
        [31910],
        [28974],
        [34383],
        [29776],
        [33186],
        [34387],
        [28842],
        [31365],
        [29471],
        [28041],
        [33165],
        [26563],
        [31422]], device='cuda:0')
[2024-07-24 10:18:52,896][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3198],
        [ 1027],
        [ 4562],
        [ 1555],
        [ 7582],
        [ 1522],
        [ 7311],
        [ 4990],
        [ 2988],
        [11096],
        [ 3869],
        [ 9059],
        [10751],
        [ 4427],
        [25820],
        [ 3536],
        [15443],
        [13917],
        [ 7169]], device='cuda:0')
[2024-07-24 10:18:52,899][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47915],
        [40400],
        [31559],
        [26404],
        [15455],
        [26380],
        [21148],
        [37276],
        [18811],
        [20297],
        [19988],
        [19294],
        [20312],
        [22135],
        [15961],
        [18302],
        [17234],
        [10690],
        [14314]], device='cuda:0')
[2024-07-24 10:18:52,901][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[40645],
        [12021],
        [ 5302],
        [19918],
        [    1],
        [22685],
        [43706],
        [34959],
        [15698],
        [21614],
        [19306],
        [37123],
        [36986],
        [14302],
        [ 5052],
        [31589],
        [43602],
        [39675],
        [19670]], device='cuda:0')
[2024-07-24 10:18:52,903][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26446],
        [27327],
        [36039],
        [33237],
        [37804],
        [29538],
        [35555],
        [34531],
        [35335],
        [34973],
        [33854],
        [34261],
        [34422],
        [32947],
        [36132],
        [29203],
        [32116],
        [30088],
        [27669]], device='cuda:0')
[2024-07-24 10:18:52,904][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10888],
        [16203],
        [24071],
        [10321],
        [16382],
        [16993],
        [ 8224],
        [15048],
        [ 9192],
        [17845],
        [ 4864],
        [11073],
        [14403],
        [21293],
        [22649],
        [26690],
        [ 8718],
        [21305],
        [ 6768]], device='cuda:0')
[2024-07-24 10:18:52,906][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[41123],
        [27670],
        [31634],
        [40107],
        [27997],
        [36804],
        [35654],
        [37248],
        [38405],
        [40474],
        [39002],
        [38705],
        [40334],
        [37723],
        [36298],
        [37611],
        [33872],
        [39763],
        [28054]], device='cuda:0')
[2024-07-24 10:18:52,907][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31111],
        [30434],
        [ 7164],
        [21560],
        [32394],
        [14773],
        [15647],
        [21930],
        [12987],
        [28959],
        [19781],
        [15562],
        [ 4532],
        [11758],
        [ 6950],
        [16680],
        [20256],
        [23470],
        [21451]], device='cuda:0')
[2024-07-24 10:18:52,909][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[32961],
        [33042],
        [37110],
        [30320],
        [14032],
        [28704],
        [31303],
        [44014],
        [35469],
        [35497],
        [34887],
        [35122],
        [37039],
        [35407],
        [35609],
        [24381],
        [28979],
        [24935],
        [35911]], device='cuda:0')
[2024-07-24 10:18:52,911][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23217],
        [13489],
        [ 8363],
        [13666],
        [25178],
        [ 9500],
        [ 7047],
        [ 7298],
        [11572],
        [14137],
        [ 8941],
        [ 7480],
        [ 6036],
        [11041],
        [ 8809],
        [ 8782],
        [ 6276],
        [29286],
        [ 8918]], device='cuda:0')
[2024-07-24 10:18:52,913][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[49288],
        [49279],
        [43528],
        [46145],
        [16347],
        [ 7470],
        [ 6942],
        [23583],
        [ 4274],
        [ 1782],
        [ 7924],
        [ 5893],
        [11681],
        [ 6902],
        [ 8322],
        [ 9661],
        [10539],
        [19165],
        [34923]], device='cuda:0')
[2024-07-24 10:18:52,915][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12371],
        [13962],
        [24024],
        [24135],
        [20615],
        [18136],
        [13597],
        [ 9230],
        [11002],
        [14484],
        [17480],
        [15678],
        [25236],
        [11680],
        [ 9353],
        [11400],
        [ 9774],
        [10408],
        [10636]], device='cuda:0')
[2024-07-24 10:18:52,918][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12730],
        [16855],
        [16928],
        [21209],
        [16934],
        [15392],
        [21125],
        [18464],
        [18883],
        [16315],
        [16306],
        [18781],
        [16773],
        [20713],
        [19770],
        [15674],
        [21404],
        [14962],
        [22318]], device='cuda:0')
[2024-07-24 10:18:52,920][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[35371],
        [33456],
        [33434],
        [30947],
        [31017],
        [31625],
        [31617],
        [31452],
        [29879],
        [29723],
        [29231],
        [30087],
        [29817],
        [28114],
        [28043],
        [28143],
        [29217],
        [27568],
        [26507]], device='cuda:0')
[2024-07-24 10:18:52,922][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44419],
        [46829],
        [43635],
        [45565],
        [43086],
        [40890],
        [39838],
        [43186],
        [41573],
        [40112],
        [40549],
        [39969],
        [42452],
        [41705],
        [39976],
        [38658],
        [36828],
        [37728],
        [38730]], device='cuda:0')
[2024-07-24 10:18:52,923][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14800],
        [12738],
        [15233],
        [15185],
        [24293],
        [14681],
        [20476],
        [ 6306],
        [17662],
        [18538],
        [16558],
        [18357],
        [12683],
        [13283],
        [14462],
        [15668],
        [14366],
        [14543],
        [11926]], device='cuda:0')
[2024-07-24 10:18:52,925][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7600],
        [ 7960],
        [11897],
        [10504],
        [15419],
        [25242],
        [24366],
        [16784],
        [24513],
        [20987],
        [23550],
        [22531],
        [18051],
        [22149],
        [21349],
        [25164],
        [25976],
        [20500],
        [23305]], device='cuda:0')
[2024-07-24 10:18:52,926][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9921],
        [35860],
        [43392],
        [27847],
        [50256],
        [25766],
        [ 6007],
        [14736],
        [32786],
        [27304],
        [30144],
        [11505],
        [13659],
        [33690],
        [43914],
        [17869],
        [ 6045],
        [10579],
        [28679]], device='cuda:0')
[2024-07-24 10:18:52,928][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620],
        [14620]], device='cuda:0')
[2024-07-24 10:18:52,949][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:52,951][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,953][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,955][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,957][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,958][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,959][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,959][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,960][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,961][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,962][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,964][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,965][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:52,967][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2570, 0.7430], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,969][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3114, 0.6886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,971][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6362, 0.3638], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,972][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1068, 0.8932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,974][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2873, 0.7127], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,974][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2666, 0.7334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,975][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7609, 0.2391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,976][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3770, 0.6230], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,976][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([9.9956e-01, 4.4095e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,977][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5655, 0.4345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,978][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,980][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8031, 0.1969], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:52,982][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0076, 0.2178, 0.7746], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,983][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.4262, 0.5555, 0.0183], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,984][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.4493, 0.2899, 0.2609], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,986][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.2896, 0.4519, 0.2585], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,988][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.1448, 0.4345, 0.4207], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,990][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.1468, 0.5516, 0.3016], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,991][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.6888, 0.2666, 0.0446], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,992][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.1526, 0.4201, 0.4273], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,992][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.9689, 0.0013, 0.0298], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,993][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.3995, 0.3861, 0.2145], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,994][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0034, 0.5395, 0.4572], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,995][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0459, 0.0707, 0.8833], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:52,996][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0129, 0.1429, 0.6951, 0.1491], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,997][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7485, 0.2442, 0.0051, 0.0021], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:52,999][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3430, 0.2061, 0.2115, 0.2394], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,001][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2530, 0.2818, 0.2091, 0.2560], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,002][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1143, 0.2867, 0.3387, 0.2604], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,004][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1516, 0.7354, 0.1028, 0.0103], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,006][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3846, 0.1324, 0.0295, 0.4535], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,008][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1515, 0.2861, 0.3418, 0.2206], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,008][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([9.8997e-01, 7.6139e-04, 4.6374e-03, 4.6337e-03], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,009][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3547, 0.2777, 0.1531, 0.2146], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,010][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0048, 0.3049, 0.3470, 0.3432], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,011][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4337, 0.1202, 0.0349, 0.4112], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,011][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.0035, 0.1102, 0.3703, 0.1772, 0.3388], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,012][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.5528, 0.4316, 0.0094, 0.0048, 0.0015], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,014][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.2789, 0.1768, 0.1547, 0.1930, 0.1965], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,016][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.2644, 0.2191, 0.1497, 0.2279, 0.1389], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,018][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.0801, 0.2431, 0.2244, 0.2062, 0.2461], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,019][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.1071, 0.7400, 0.1411, 0.0014, 0.0104], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,021][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.3777, 0.1460, 0.0214, 0.4076, 0.0472], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,023][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.0789, 0.2260, 0.2499, 0.1574, 0.2877], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,025][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.7842, 0.0008, 0.0184, 0.0037, 0.1929], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,026][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.2152, 0.2374, 0.1375, 0.2683, 0.1417], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,026][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.0029, 0.2361, 0.2374, 0.2618, 0.2619], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,027][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0402, 0.0570, 0.0092, 0.0194, 0.8743], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,028][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0234, 0.0806, 0.2364, 0.1359, 0.1145, 0.4093], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,029][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5643, 0.3925, 0.0075, 0.0041, 0.0015, 0.0301], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,029][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2196, 0.1459, 0.1442, 0.1587, 0.1810, 0.1507], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,031][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2249, 0.1852, 0.1375, 0.1535, 0.1250, 0.1739], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,033][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0686, 0.1827, 0.1997, 0.1556, 0.2194, 0.1739], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,035][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0311, 0.6437, 0.0702, 0.0274, 0.0118, 0.2158], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,036][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3308, 0.1115, 0.0267, 0.3992, 0.0642, 0.0675], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,038][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0720, 0.1386, 0.1846, 0.1267, 0.3183, 0.1599], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,040][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.7781, 0.0043, 0.0301, 0.0109, 0.1713, 0.0052], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,042][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2642, 0.2069, 0.1154, 0.1689, 0.0988, 0.1456], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,043][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0030, 0.1457, 0.1800, 0.1824, 0.2312, 0.2577], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,044][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0346, 0.0548, 0.0042, 0.0311, 0.0038, 0.8716], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,044][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0036, 0.0346, 0.0683, 0.0545, 0.1067, 0.5527, 0.1796],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,045][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.7485, 0.2222, 0.0045, 0.0019, 0.0008, 0.0207, 0.0013],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,046][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1983, 0.1235, 0.1212, 0.1397, 0.1593, 0.1248, 0.1332],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,047][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2297, 0.1483, 0.1136, 0.1309, 0.1051, 0.1451, 0.1274],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,049][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0626, 0.1555, 0.1662, 0.1383, 0.1903, 0.1483, 0.1388],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,051][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1107, 0.7520, 0.0715, 0.0029, 0.0041, 0.0555, 0.0033],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,052][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2723, 0.0876, 0.0202, 0.3164, 0.0434, 0.0607, 0.1995],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,054][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0672, 0.1022, 0.1567, 0.0930, 0.2649, 0.1301, 0.1860],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,055][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([9.7104e-01, 6.5603e-04, 5.0823e-03, 3.4439e-03, 1.9128e-02, 5.2774e-04,
        1.1776e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,057][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2344, 0.1818, 0.1012, 0.1406, 0.0831, 0.1211, 0.1379],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,059][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0040, 0.1082, 0.1438, 0.1451, 0.1977, 0.2030, 0.1982],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,060][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1116, 0.0370, 0.0043, 0.0224, 0.0064, 0.0047, 0.8136],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,061][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0011, 0.0115, 0.0665, 0.0208, 0.0700, 0.0866, 0.5225, 0.2210],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,062][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.3235, 0.5280, 0.0163, 0.0077, 0.0024, 0.0584, 0.0052, 0.0586],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,062][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1895, 0.1118, 0.1039, 0.1216, 0.1345, 0.1089, 0.1114, 0.1186],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,063][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2132, 0.1246, 0.0935, 0.1243, 0.0936, 0.1298, 0.1110, 0.1101],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,064][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0498, 0.1406, 0.1407, 0.1219, 0.1566, 0.1275, 0.1140, 0.1490],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,066][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0732, 0.3965, 0.0893, 0.0311, 0.0187, 0.1417, 0.0376, 0.2118],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,068][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.2264, 0.0808, 0.0166, 0.3081, 0.0435, 0.0514, 0.1818, 0.0915],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,070][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0444, 0.0762, 0.0896, 0.0625, 0.2264, 0.1072, 0.1491, 0.2445],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,071][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([6.2194e-02, 5.7601e-04, 3.4838e-03, 2.3207e-03, 2.7065e-02, 4.6618e-04,
        2.0220e-04, 9.0369e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,073][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1725, 0.1577, 0.0917, 0.1400, 0.0826, 0.1154, 0.1263, 0.1140],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,074][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0030, 0.0945, 0.1268, 0.1235, 0.1787, 0.1763, 0.1651, 0.1321],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,076][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.0240e-02, 3.2241e-02, 1.1144e-03, 1.0541e-02, 4.0475e-04, 1.8181e-03,
        9.2051e-04, 9.4272e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,077][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([5.6406e-04, 7.2519e-03, 4.9127e-02, 1.5855e-02, 3.6313e-02, 5.3192e-02,
        2.4091e-01, 5.8886e-01, 7.9306e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,077][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.7266, 0.2194, 0.0049, 0.0020, 0.0008, 0.0195, 0.0014, 0.0247, 0.0008],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,078][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1566, 0.0971, 0.0989, 0.1088, 0.1296, 0.1025, 0.1030, 0.1079, 0.0957],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,079][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.2148, 0.1057, 0.0900, 0.1033, 0.0898, 0.1223, 0.0966, 0.0972, 0.0803],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,080][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0471, 0.1180, 0.1396, 0.1048, 0.1556, 0.1135, 0.1033, 0.1211, 0.0969],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,081][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1045, 0.7530, 0.0428, 0.0017, 0.0016, 0.0334, 0.0019, 0.0598, 0.0014],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,082][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2147, 0.0688, 0.0137, 0.2574, 0.0322, 0.0470, 0.1567, 0.0737, 0.1357],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,084][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0480, 0.0855, 0.1032, 0.0807, 0.1749, 0.0768, 0.1529, 0.1403, 0.1378],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,085][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([1.0426e-01, 1.3288e-04, 1.2528e-03, 5.3915e-04, 6.5986e-03, 1.7920e-04,
        2.5874e-05, 4.8017e-01, 4.0684e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,086][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1883, 0.1347, 0.0739, 0.0957, 0.0577, 0.0832, 0.0937, 0.0856, 0.1871],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,088][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0058, 0.0710, 0.1033, 0.1042, 0.1561, 0.1569, 0.1367, 0.1103, 0.1559],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,090][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1367, 0.0744, 0.0081, 0.0668, 0.0050, 0.0077, 0.0274, 0.0110, 0.6628],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,091][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([2.6964e-04, 7.5231e-03, 2.9672e-02, 1.6892e-02, 3.9082e-02, 1.6961e-01,
        2.1931e-01, 4.2215e-01, 1.7691e-02, 7.7796e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,092][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([6.3017e-01, 2.9733e-01, 6.2623e-03, 2.4836e-03, 8.5443e-04, 2.5873e-02,
        1.7689e-03, 3.3779e-02, 1.0069e-03, 4.7804e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,094][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1498, 0.0939, 0.0857, 0.1019, 0.1084, 0.0903, 0.0918, 0.0931, 0.0875,
        0.0977], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,095][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.2057, 0.1052, 0.0797, 0.1070, 0.0747, 0.1052, 0.0895, 0.0907, 0.0715,
        0.0709], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,096][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0404, 0.1177, 0.1074, 0.1000, 0.1166, 0.1063, 0.0927, 0.1116, 0.0906,
        0.1168], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,097][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0692, 0.8121, 0.0288, 0.0016, 0.0022, 0.0224, 0.0020, 0.0558, 0.0012,
        0.0046], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,097][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.2288, 0.0722, 0.0159, 0.2330, 0.0461, 0.0392, 0.1374, 0.0809, 0.1237,
        0.0228], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,098][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0339, 0.0713, 0.0911, 0.0547, 0.1548, 0.1041, 0.1074, 0.2105, 0.0922,
        0.0800], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,099][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([1.8476e-02, 2.3863e-05, 1.1724e-03, 1.5590e-04, 9.4711e-03, 4.4097e-05,
        6.8624e-06, 4.7601e-01, 2.8498e-01, 2.0966e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,101][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1172, 0.1141, 0.0672, 0.1122, 0.0644, 0.0878, 0.0947, 0.0874, 0.1706,
        0.0844], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,103][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0038, 0.0642, 0.0884, 0.0888, 0.1313, 0.1248, 0.1156, 0.0956, 0.1228,
        0.1647], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,104][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0552, 0.0754, 0.0068, 0.0525, 0.0058, 0.0079, 0.0151, 0.0182, 0.1103,
        0.6528], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,106][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0023, 0.0238, 0.0410, 0.0373, 0.0639, 0.1400, 0.1426, 0.4038, 0.0375,
        0.0855, 0.0222], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,107][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([8.3264e-01, 1.2977e-01, 2.7580e-03, 1.0633e-03, 5.0089e-04, 1.3882e-02,
        7.8489e-04, 1.7833e-02, 4.5638e-04, 2.5639e-04, 5.4678e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,109][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1339, 0.0803, 0.0810, 0.0900, 0.1061, 0.0825, 0.0851, 0.0897, 0.0771,
        0.0932, 0.0808], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,111][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.2117, 0.0861, 0.0729, 0.0879, 0.0709, 0.0981, 0.0775, 0.0778, 0.0625,
        0.0688, 0.0857], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,112][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0373, 0.0950, 0.1053, 0.0846, 0.1191, 0.0903, 0.0826, 0.1028, 0.0768,
        0.1143, 0.0918], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,113][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0846, 0.7381, 0.0380, 0.0021, 0.0023, 0.0588, 0.0024, 0.0660, 0.0013,
        0.0050, 0.0014], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,113][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2118, 0.0673, 0.0134, 0.2121, 0.0312, 0.0399, 0.1288, 0.0705, 0.1246,
        0.0217, 0.0788], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,114][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0338, 0.0632, 0.0827, 0.0514, 0.1620, 0.0808, 0.1103, 0.1555, 0.0926,
        0.1101, 0.0575], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,115][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([3.7083e-02, 2.8461e-05, 6.3164e-04, 9.7226e-05, 3.3013e-03, 4.5756e-05,
        9.9425e-06, 2.5887e-01, 9.3733e-02, 1.1320e-01, 4.9300e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,117][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1500, 0.1099, 0.0591, 0.0816, 0.0472, 0.0690, 0.0768, 0.0693, 0.1517,
        0.0641, 0.1214], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,118][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0052, 0.0480, 0.0735, 0.0730, 0.1083, 0.1072, 0.0953, 0.0794, 0.1054,
        0.1339, 0.1709], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,120][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0320, 0.0513, 0.0048, 0.0242, 0.0012, 0.0098, 0.0038, 0.0040, 0.0458,
        0.0028, 0.8203], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,122][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0024, 0.0190, 0.0370, 0.0332, 0.0759, 0.1658, 0.1720, 0.2532, 0.0404,
        0.0709, 0.0582, 0.0721], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,123][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([8.2261e-01, 1.3860e-01, 2.7573e-03, 1.2898e-03, 5.6689e-04, 1.4328e-02,
        9.2275e-04, 1.7863e-02, 5.7730e-04, 2.9453e-04, 7.7173e-05, 1.1223e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,125][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1168, 0.0741, 0.0758, 0.0831, 0.0991, 0.0767, 0.0802, 0.0854, 0.0720,
        0.0889, 0.0729, 0.0749], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,127][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2263, 0.0779, 0.0662, 0.0767, 0.0638, 0.0852, 0.0731, 0.0733, 0.0545,
        0.0599, 0.0717, 0.0714], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,129][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0347, 0.0858, 0.0957, 0.0748, 0.1093, 0.0827, 0.0753, 0.0976, 0.0692,
        0.1088, 0.0809, 0.0853], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,129][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.1614e-01, 7.2641e-01, 4.2031e-02, 1.2514e-03, 1.8059e-03, 4.4307e-02,
        1.4207e-03, 6.0062e-02, 7.7730e-04, 4.6018e-03, 7.0337e-04, 4.8815e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,130][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1473, 0.0465, 0.0113, 0.1799, 0.0263, 0.0357, 0.1191, 0.0606, 0.1094,
        0.0178, 0.0746, 0.1716], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,131][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0303, 0.0483, 0.0690, 0.0430, 0.1490, 0.0674, 0.1029, 0.1469, 0.0817,
        0.1064, 0.0542, 0.1011], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,132][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([4.0573e-02, 2.8405e-05, 3.1776e-04, 1.5181e-04, 1.2742e-03, 2.8144e-05,
        6.8204e-06, 1.7039e-01, 9.6175e-02, 7.4127e-02, 6.1693e-01, 5.4659e-06],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,133][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1298, 0.0996, 0.0542, 0.0764, 0.0432, 0.0652, 0.0725, 0.0649, 0.1409,
        0.0598, 0.1127, 0.0807], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,135][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0059, 0.0364, 0.0593, 0.0606, 0.0928, 0.0899, 0.0853, 0.0635, 0.0872,
        0.1161, 0.1424, 0.1605], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,137][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1399, 0.0545, 0.0174, 0.0482, 0.0128, 0.0083, 0.0251, 0.0066, 0.1874,
        0.0136, 0.0177, 0.4683], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,139][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0003, 0.0108, 0.0436, 0.0188, 0.0678, 0.1301, 0.1896, 0.2347, 0.0272,
        0.1184, 0.0521, 0.0868, 0.0198], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,140][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ station] are: tensor([6.2396e-01, 3.0211e-01, 6.0084e-03, 3.2037e-03, 9.9401e-04, 2.7987e-02,
        2.2867e-03, 3.0635e-02, 1.2596e-03, 5.8161e-04, 2.1679e-04, 2.7577e-04,
        4.8852e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,142][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1193, 0.0737, 0.0682, 0.0800, 0.0869, 0.0717, 0.0725, 0.0714, 0.0669,
        0.0762, 0.0673, 0.0664, 0.0796], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,144][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1967, 0.0701, 0.0657, 0.0774, 0.0636, 0.0830, 0.0685, 0.0711, 0.0557,
        0.0605, 0.0751, 0.0629, 0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,145][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0286, 0.0863, 0.0815, 0.0725, 0.0928, 0.0769, 0.0682, 0.0836, 0.0650,
        0.0905, 0.0742, 0.0779, 0.1020], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,147][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ station] are: tensor([9.2064e-02, 7.6109e-01, 2.8618e-02, 1.0115e-03, 1.2457e-03, 2.2688e-02,
        8.5173e-04, 8.5105e-02, 9.7183e-04, 2.2877e-03, 6.8004e-04, 3.4157e-04,
        3.0492e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,147][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2039, 0.0683, 0.0124, 0.1838, 0.0307, 0.0293, 0.0946, 0.0585, 0.0906,
        0.0179, 0.0591, 0.1243, 0.0266], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,148][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0197, 0.0472, 0.0609, 0.0349, 0.1622, 0.0986, 0.0784, 0.1562, 0.0672,
        0.1184, 0.0475, 0.0768, 0.0319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,149][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ station] are: tensor([1.4311e-02, 1.3839e-05, 4.0132e-04, 6.4692e-05, 2.2143e-03, 3.3832e-05,
        3.0649e-06, 3.0356e-01, 9.6706e-02, 7.5055e-02, 5.0045e-01, 2.7592e-06,
        7.1932e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,150][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0874, 0.0885, 0.0520, 0.0854, 0.0486, 0.0671, 0.0706, 0.0666, 0.1293,
        0.0637, 0.0953, 0.0718, 0.0739], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,151][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0029, 0.0385, 0.0526, 0.0590, 0.0774, 0.0793, 0.0725, 0.0589, 0.0800,
        0.1019, 0.1295, 0.1283, 0.1192], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,152][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ station] are: tensor([1.4632e-02, 1.4636e-02, 3.3233e-03, 1.7580e-02, 4.6187e-04, 4.7370e-03,
        2.2244e-03, 1.7186e-03, 1.8775e-02, 4.4831e-03, 3.5484e-02, 3.6090e-03,
        8.7834e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,155][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0029, 0.0212, 0.0792, 0.0337, 0.0779, 0.0883, 0.1428, 0.2069, 0.0313,
        0.0922, 0.0399, 0.0719, 0.0339, 0.0777], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,156][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([8.0510e-01, 1.5444e-01, 2.9674e-03, 1.4299e-03, 5.8893e-04, 1.4655e-02,
        9.9693e-04, 1.8224e-02, 6.0441e-04, 3.0841e-04, 8.4622e-05, 1.2232e-04,
        3.0693e-04, 1.7155e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,157][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1000, 0.0623, 0.0650, 0.0706, 0.0861, 0.0660, 0.0685, 0.0719, 0.0617,
        0.0754, 0.0615, 0.0627, 0.0790, 0.0695], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,160][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.2383, 0.0738, 0.0652, 0.0629, 0.0545, 0.0690, 0.0555, 0.0583, 0.0430,
        0.0497, 0.0567, 0.0469, 0.0473, 0.0789], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,162][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0285, 0.0693, 0.0839, 0.0620, 0.0936, 0.0684, 0.0617, 0.0795, 0.0574,
        0.0909, 0.0671, 0.0695, 0.1007, 0.0675], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,163][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.1303e-01, 7.2668e-01, 3.6939e-02, 1.3311e-03, 9.5526e-04, 4.5416e-02,
        1.2062e-03, 6.6886e-02, 8.4811e-04, 2.9781e-03, 7.5996e-04, 4.8703e-04,
        1.8978e-03, 5.9169e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,164][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1214, 0.0382, 0.0089, 0.1566, 0.0225, 0.0310, 0.1032, 0.0519, 0.0952,
        0.0155, 0.0690, 0.1561, 0.0234, 0.1071], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,165][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0297, 0.0485, 0.0714, 0.0495, 0.1398, 0.0472, 0.1005, 0.0912, 0.0828,
        0.0779, 0.0521, 0.0954, 0.0498, 0.0642], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,165][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([4.4951e-02, 3.4307e-05, 5.5898e-04, 6.6458e-05, 3.0275e-03, 6.4164e-05,
        7.1709e-06, 4.0672e-01, 4.5929e-02, 2.5748e-01, 2.1822e-01, 2.6497e-06,
        2.2850e-02, 9.1127e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,166][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1118, 0.0895, 0.0478, 0.0659, 0.0381, 0.0550, 0.0594, 0.0566, 0.1222,
        0.0538, 0.0986, 0.0665, 0.0566, 0.0781], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,167][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0066, 0.0283, 0.0435, 0.0453, 0.0677, 0.0657, 0.0577, 0.0455, 0.0646,
        0.0819, 0.1011, 0.1054, 0.1044, 0.1824], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,169][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.1858, 0.1008, 0.0525, 0.0918, 0.0379, 0.0333, 0.0406, 0.0358, 0.1206,
        0.0518, 0.0268, 0.0429, 0.0271, 0.1524], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,171][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0004, 0.0133, 0.0514, 0.0223, 0.1033, 0.0971, 0.1455, 0.1266, 0.0356,
        0.0559, 0.0318, 0.0954, 0.0281, 0.1299, 0.0634], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,173][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([6.4206e-01, 2.7077e-01, 7.0843e-03, 4.3799e-03, 1.6011e-03, 3.1365e-02,
        3.2503e-03, 3.3629e-02, 1.9082e-03, 9.5796e-04, 3.5730e-04, 4.9799e-04,
        8.6846e-04, 7.2694e-04, 5.4171e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,174][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0958, 0.0638, 0.0578, 0.0692, 0.0755, 0.0637, 0.0628, 0.0649, 0.0583,
        0.0686, 0.0587, 0.0576, 0.0737, 0.0653, 0.0643], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,176][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.2433, 0.0527, 0.0439, 0.0611, 0.0427, 0.0745, 0.0517, 0.0559, 0.0424,
        0.0435, 0.0585, 0.0492, 0.0379, 0.0999, 0.0427], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,178][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0236, 0.0724, 0.0702, 0.0616, 0.0804, 0.0675, 0.0576, 0.0692, 0.0544,
        0.0751, 0.0630, 0.0649, 0.0895, 0.0661, 0.0847], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,179][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([1.0119e-01, 7.5552e-01, 4.5134e-02, 1.2151e-03, 2.5922e-03, 2.3686e-02,
        1.3210e-03, 6.0532e-02, 7.9467e-04, 3.7785e-03, 5.2262e-04, 3.3662e-04,
        1.9271e-03, 3.4000e-04, 1.1027e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,181][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.1834, 0.0704, 0.0122, 0.1759, 0.0239, 0.0295, 0.0941, 0.0542, 0.0858,
        0.0151, 0.0473, 0.1033, 0.0180, 0.0737, 0.0134], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,182][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0181, 0.0454, 0.0483, 0.0341, 0.1361, 0.0653, 0.0687, 0.1386, 0.0643,
        0.1010, 0.0415, 0.0767, 0.0386, 0.0638, 0.0597], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,183][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([7.7737e-03, 1.7140e-05, 2.9073e-04, 8.2618e-05, 2.5719e-03, 2.1013e-05,
        2.7809e-06, 2.4341e-01, 1.2998e-01, 1.1164e-01, 4.9192e-01, 2.7505e-06,
        1.1563e-02, 1.4370e-04, 5.7725e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,183][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0678, 0.0731, 0.0432, 0.0784, 0.0424, 0.0612, 0.0639, 0.0567, 0.1088,
        0.0531, 0.0773, 0.0621, 0.0646, 0.0857, 0.0618], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,184][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0071, 0.0218, 0.0332, 0.0413, 0.0535, 0.0604, 0.0527, 0.0371, 0.0557,
        0.0678, 0.0908, 0.0927, 0.0850, 0.1593, 0.1419], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,186][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0033, 0.0209, 0.3108, 0.0041, 0.0033, 0.0008, 0.0006, 0.0012, 0.0057,
        0.0014, 0.0018, 0.0008, 0.0009, 0.0772, 0.5672], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,188][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0013, 0.0142, 0.0361, 0.0195, 0.0325, 0.0905, 0.1113, 0.1802, 0.0225,
        0.0696, 0.0416, 0.0655, 0.0299, 0.0962, 0.0483, 0.1408],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,190][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([7.9266e-01, 1.6017e-01, 3.6541e-03, 1.6183e-03, 7.7207e-04, 1.4100e-02,
        1.2824e-03, 2.3363e-02, 7.4652e-04, 4.0346e-04, 1.1414e-04, 1.7189e-04,
        4.0108e-04, 2.4388e-04, 2.0823e-04, 8.6170e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,191][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0902, 0.0585, 0.0563, 0.0632, 0.0709, 0.0574, 0.0570, 0.0606, 0.0539,
        0.0624, 0.0543, 0.0527, 0.0687, 0.0600, 0.0621, 0.0718],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,193][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.2125, 0.0655, 0.0515, 0.0575, 0.0475, 0.0659, 0.0486, 0.0506, 0.0400,
        0.0440, 0.0545, 0.0430, 0.0397, 0.0868, 0.0406, 0.0518],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,195][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0225, 0.0647, 0.0658, 0.0543, 0.0729, 0.0578, 0.0516, 0.0634, 0.0503,
        0.0711, 0.0596, 0.0595, 0.0822, 0.0599, 0.0785, 0.0860],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,197][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([8.9473e-02, 8.4383e-01, 1.5706e-02, 6.0851e-04, 4.0512e-04, 1.3813e-02,
        4.2372e-04, 3.1585e-02, 4.6056e-04, 1.4212e-03, 2.9597e-04, 1.7824e-04,
        8.2790e-04, 2.1232e-04, 5.0690e-04, 2.4808e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,198][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1641, 0.0509, 0.0119, 0.1658, 0.0291, 0.0274, 0.0917, 0.0526, 0.0821,
        0.0150, 0.0529, 0.1191, 0.0237, 0.0849, 0.0163, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,199][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0231, 0.0462, 0.0559, 0.0355, 0.1077, 0.0593, 0.0602, 0.1237, 0.0678,
        0.1057, 0.0457, 0.0678, 0.0423, 0.0559, 0.0687, 0.0346],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,200][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.1695e-02, 1.9604e-05, 2.1807e-04, 1.1804e-04, 1.2005e-03, 3.4726e-05,
        5.1804e-06, 1.6143e-01, 6.7965e-02, 5.2804e-02, 6.8699e-01, 5.6250e-06,
        6.5331e-03, 1.1323e-04, 4.3733e-04, 4.2961e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,201][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0826, 0.0728, 0.0411, 0.0614, 0.0359, 0.0512, 0.0559, 0.0507, 0.1075,
        0.0483, 0.0827, 0.0610, 0.0536, 0.0751, 0.0530, 0.0672],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,202][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0030, 0.0209, 0.0330, 0.0349, 0.0506, 0.0505, 0.0431, 0.0323, 0.0481,
        0.0600, 0.0784, 0.0786, 0.0758, 0.1361, 0.1324, 0.1223],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,204][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0213, 0.0479, 0.0033, 0.0194, 0.0032, 0.0127, 0.0015, 0.0123, 0.0297,
        0.0048, 0.0033, 0.0015, 0.0034, 0.0872, 0.0009, 0.7475],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,206][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0012, 0.0110, 0.0206, 0.0175, 0.0304, 0.1790, 0.0538, 0.2059, 0.0248,
        0.0412, 0.0258, 0.0649, 0.0135, 0.0607, 0.0289, 0.1564, 0.0644],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,207][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.4672e-01, 1.1798e-01, 2.4975e-03, 1.0716e-03, 5.0454e-04, 1.1795e-02,
        7.7710e-04, 1.7066e-02, 4.9787e-04, 2.5791e-04, 6.5583e-05, 1.0095e-04,
        2.7131e-04, 1.4789e-04, 1.3103e-04, 6.7319e-05, 4.0217e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,209][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0814, 0.0524, 0.0522, 0.0585, 0.0685, 0.0530, 0.0561, 0.0597, 0.0511,
        0.0621, 0.0509, 0.0514, 0.0639, 0.0569, 0.0589, 0.0658, 0.0569],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,211][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2404, 0.0624, 0.0477, 0.0507, 0.0417, 0.0584, 0.0510, 0.0489, 0.0350,
        0.0378, 0.0465, 0.0418, 0.0349, 0.0738, 0.0377, 0.0482, 0.0431],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,213][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0229, 0.0577, 0.0607, 0.0509, 0.0697, 0.0544, 0.0509, 0.0632, 0.0471,
        0.0704, 0.0538, 0.0568, 0.0805, 0.0551, 0.0728, 0.0782, 0.0549],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,214][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.2965e-01, 7.6786e-01, 2.8396e-02, 9.3770e-04, 7.3618e-04, 2.5400e-02,
        6.3995e-04, 4.0513e-02, 4.3581e-04, 2.2051e-03, 3.8208e-04, 2.3471e-04,
        9.5582e-04, 2.9093e-04, 9.1229e-04, 3.3147e-04, 1.1554e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,216][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1388, 0.0430, 0.0100, 0.1465, 0.0211, 0.0273, 0.0895, 0.0495, 0.0836,
        0.0142, 0.0561, 0.1254, 0.0205, 0.0886, 0.0134, 0.0114, 0.0612],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,217][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0268, 0.0383, 0.0529, 0.0345, 0.1030, 0.0467, 0.0754, 0.1162, 0.0630,
        0.0766, 0.0397, 0.0733, 0.0330, 0.0559, 0.0631, 0.0333, 0.0684],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,217][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([5.9751e-02, 4.6554e-05, 3.9252e-04, 2.0775e-04, 1.7883e-03, 4.0800e-05,
        7.6608e-06, 1.8537e-01, 9.9215e-02, 6.8532e-02, 5.7406e-01, 8.6109e-06,
        9.0837e-03, 1.4025e-04, 6.6440e-04, 6.8685e-04, 7.4164e-06],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,218][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0878, 0.0706, 0.0390, 0.0548, 0.0318, 0.0469, 0.0512, 0.0458, 0.0991,
        0.0424, 0.0793, 0.0570, 0.0459, 0.0671, 0.0479, 0.0620, 0.0712],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,219][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0049, 0.0163, 0.0278, 0.0290, 0.0446, 0.0440, 0.0427, 0.0296, 0.0413,
        0.0529, 0.0676, 0.0725, 0.0648, 0.1205, 0.1162, 0.1169, 0.1082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,221][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0455, 0.0284, 0.0034, 0.0099, 0.0040, 0.0022, 0.3036, 0.0032, 0.0371,
        0.0053, 0.0067, 0.0050, 0.0009, 0.0726, 0.0027, 0.0027, 0.4668],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,223][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([1.7683e-04, 4.3549e-03, 1.3144e-02, 6.4593e-03, 3.0203e-02, 9.0627e-02,
        9.0757e-02, 5.8031e-02, 7.7348e-03, 4.7282e-02, 1.6496e-02, 2.8386e-02,
        7.6137e-03, 5.9159e-02, 1.8757e-02, 3.3761e-01, 1.3142e-01, 5.1791e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,224][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([7.5558e-01, 1.8524e-01, 4.5214e-03, 2.3665e-03, 8.6702e-04, 2.0660e-02,
        1.8178e-03, 2.5565e-02, 1.0136e-03, 4.8853e-04, 1.7037e-04, 2.5214e-04,
        4.9028e-04, 3.6851e-04, 3.0528e-04, 1.4356e-04, 1.0698e-04, 3.8281e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,226][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0857, 0.0520, 0.0494, 0.0562, 0.0628, 0.0502, 0.0512, 0.0533, 0.0475,
        0.0550, 0.0471, 0.0480, 0.0592, 0.0537, 0.0546, 0.0622, 0.0514, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,228][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.2373, 0.0585, 0.0481, 0.0487, 0.0402, 0.0534, 0.0428, 0.0481, 0.0331,
        0.0370, 0.0449, 0.0376, 0.0328, 0.0765, 0.0410, 0.0468, 0.0383, 0.0351],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,230][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0189, 0.0578, 0.0568, 0.0478, 0.0625, 0.0518, 0.0453, 0.0544, 0.0432,
        0.0609, 0.0502, 0.0515, 0.0700, 0.0511, 0.0678, 0.0730, 0.0485, 0.0889],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,231][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([1.7654e-01, 7.2455e-01, 2.1803e-02, 6.2608e-04, 4.5940e-04, 1.1236e-02,
        3.3771e-04, 5.9105e-02, 5.9176e-04, 1.4165e-03, 3.1750e-04, 1.8878e-04,
        9.2514e-04, 2.0592e-04, 5.6063e-04, 4.3793e-04, 9.6539e-05, 5.9901e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,233][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.1756, 0.0633, 0.0117, 0.1411, 0.0263, 0.0259, 0.0784, 0.0531, 0.0771,
        0.0180, 0.0462, 0.0911, 0.0218, 0.0695, 0.0131, 0.0110, 0.0434, 0.0334],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,234][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0176, 0.0362, 0.0517, 0.0293, 0.1006, 0.0540, 0.0652, 0.1407, 0.0566,
        0.0904, 0.0364, 0.0629, 0.0361, 0.0449, 0.0582, 0.0344, 0.0594, 0.0255],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,235][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([1.0839e-02, 1.0724e-05, 2.1742e-04, 8.4165e-05, 1.8474e-03, 8.1110e-06,
        1.5665e-06, 2.4812e-01, 6.6803e-02, 6.3103e-02, 5.0642e-01, 1.8268e-06,
        9.2674e-03, 9.4554e-05, 4.5193e-04, 3.6288e-04, 1.4761e-06, 9.2370e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,236][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0541, 0.0605, 0.0369, 0.0667, 0.0376, 0.0513, 0.0538, 0.0476, 0.0899,
        0.0451, 0.0634, 0.0519, 0.0554, 0.0724, 0.0531, 0.0632, 0.0601, 0.0371],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,236][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0028, 0.0185, 0.0261, 0.0278, 0.0372, 0.0392, 0.0339, 0.0277, 0.0380,
        0.0492, 0.0616, 0.0602, 0.0621, 0.1051, 0.1082, 0.0997, 0.0861, 0.1164],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,239][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0595, 0.0604, 0.0030, 0.0518, 0.0052, 0.0130, 0.0144, 0.0027, 0.0655,
        0.0141, 0.0176, 0.0125, 0.0109, 0.1835, 0.0014, 0.0167, 0.0166, 0.4511],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,241][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0008, 0.0068, 0.0168, 0.0092, 0.0155, 0.1315, 0.0598, 0.1286, 0.0200,
        0.0529, 0.0233, 0.0320, 0.0112, 0.0418, 0.0239, 0.2685, 0.0732, 0.0796,
        0.0046], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,242][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([8.7171e-01, 9.7208e-02, 2.0938e-03, 8.6485e-04, 4.2390e-04, 1.0041e-02,
        6.7765e-04, 1.5653e-02, 4.0774e-04, 2.1836e-04, 5.3603e-05, 8.3693e-05,
        2.2080e-04, 1.2287e-04, 1.0953e-04, 5.3283e-05, 3.3326e-05, 1.4693e-05,
        1.1599e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,244][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0712, 0.0463, 0.0470, 0.0505, 0.0613, 0.0484, 0.0495, 0.0524, 0.0453,
        0.0538, 0.0457, 0.0459, 0.0568, 0.0506, 0.0529, 0.0620, 0.0505, 0.0593,
        0.0507], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,246][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2664, 0.0548, 0.0428, 0.0431, 0.0371, 0.0529, 0.0406, 0.0409, 0.0311,
        0.0330, 0.0414, 0.0341, 0.0299, 0.0661, 0.0347, 0.0428, 0.0354, 0.0352,
        0.0376], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,248][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0202, 0.0491, 0.0537, 0.0433, 0.0622, 0.0480, 0.0446, 0.0535, 0.0406,
        0.0585, 0.0472, 0.0496, 0.0677, 0.0472, 0.0641, 0.0715, 0.0485, 0.0828,
        0.0477], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,249][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.1349e-01, 7.8748e-01, 1.8681e-02, 1.0573e-03, 6.4413e-04, 3.0133e-02,
        7.1132e-04, 4.1298e-02, 6.3243e-04, 1.7704e-03, 4.9778e-04, 3.1533e-04,
        1.0383e-03, 3.6136e-04, 6.9808e-04, 4.7558e-04, 1.4381e-04, 3.3492e-04,
        2.3568e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,250][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1311, 0.0531, 0.0123, 0.1075, 0.0208, 0.0235, 0.0698, 0.0484, 0.0690,
        0.0162, 0.0424, 0.0862, 0.0169, 0.0613, 0.0105, 0.0103, 0.0419, 0.0238,
        0.1549], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,251][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0210, 0.0372, 0.0457, 0.0319, 0.0997, 0.0453, 0.0640, 0.0936, 0.0598,
        0.0674, 0.0339, 0.0589, 0.0341, 0.0508, 0.0562, 0.0337, 0.0575, 0.0623,
        0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,252][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.2492e-02, 1.2790e-05, 3.2076e-04, 3.8561e-05, 2.0554e-03, 3.0027e-05,
        4.0177e-06, 1.7586e-01, 5.8474e-02, 9.6576e-02, 5.3176e-01, 2.7571e-06,
        9.0744e-03, 5.6532e-05, 6.3116e-04, 3.8632e-04, 4.4261e-06, 9.9004e-02,
        3.2123e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,253][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0794, 0.0638, 0.0355, 0.0492, 0.0290, 0.0414, 0.0449, 0.0423, 0.0881,
        0.0397, 0.0707, 0.0496, 0.0426, 0.0583, 0.0426, 0.0540, 0.0605, 0.0386,
        0.0697], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,254][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0063, 0.0115, 0.0209, 0.0209, 0.0343, 0.0331, 0.0292, 0.0203, 0.0317,
        0.0389, 0.0518, 0.0535, 0.0501, 0.0937, 0.0958, 0.0941, 0.0798, 0.1058,
        0.1284], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,256][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1640, 0.0794, 0.0047, 0.0592, 0.0010, 0.0059, 0.0095, 0.0034, 0.0956,
        0.0064, 0.0153, 0.0035, 0.0040, 0.1266, 0.0014, 0.0035, 0.0071, 0.0022,
        0.4072], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,274][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:53,276][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,277][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,279][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,280][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,282][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,283][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,284][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,285][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,286][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,286][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,287][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,288][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,289][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1194, 0.8806], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,290][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8924, 0.1076], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,292][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9977, 0.0023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,294][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3691, 0.6309], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,296][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2865, 0.7135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,298][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4038, 0.5962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,299][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9309, 0.0691], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,301][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,303][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8930, 0.1070], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,305][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5143, 0.4857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,306][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.0875e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,308][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7836, 0.2164], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,309][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0663, 0.6441, 0.2896], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,309][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.1438, 0.2766, 0.5796], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,310][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.8802, 0.0290, 0.0908], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,311][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.2806, 0.4090, 0.3103], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,312][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0972, 0.4847, 0.4180], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,312][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.3914, 0.5898, 0.0188], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,314][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.3326, 0.0814, 0.5859], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,316][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.6159, 0.1085, 0.2756], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,318][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.7502, 0.1920, 0.0578], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,319][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.7248, 0.2096, 0.0656], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,321][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([1.7101e-04, 7.8162e-01, 2.1821e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,323][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0469, 0.0507, 0.9025], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,325][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0293, 0.2624, 0.1328, 0.5756], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,326][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0244, 0.0445, 0.9253, 0.0058], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,327][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5008, 0.0178, 0.0699, 0.4115], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,328][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1922, 0.2506, 0.2306, 0.3266], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,328][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0814, 0.2549, 0.4265, 0.2372], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,329][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1606, 0.2556, 0.0192, 0.5646], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,330][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3564, 0.1586, 0.2640, 0.2210], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,331][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2557, 0.0293, 0.3983, 0.3167], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,333][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7063, 0.0864, 0.0418, 0.1655], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,335][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2452, 0.6031, 0.0159, 0.1357], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,336][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.0352e-04, 5.2559e-01, 2.1215e-01, 2.6195e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,337][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4551, 0.1138, 0.0425, 0.3885], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,339][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.0250, 0.2285, 0.0985, 0.5427, 0.1054], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,341][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0742, 0.0678, 0.4178, 0.1646, 0.2757], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,341][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.3914, 0.0244, 0.0569, 0.3534, 0.1739], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,342][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.1799, 0.2482, 0.1848, 0.3240, 0.0631], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,344][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.0501, 0.2530, 0.2174, 0.1886, 0.2910], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,346][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.1563, 0.2478, 0.0084, 0.5711, 0.0165], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,347][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.3726, 0.0605, 0.1668, 0.0946, 0.3055], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,348][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.1649, 0.0900, 0.3791, 0.3490, 0.0170], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,349][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.6190, 0.1522, 0.0460, 0.1508, 0.0321], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,349][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.6968, 0.0843, 0.0555, 0.0392, 0.1242], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,350][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([2.6580e-04, 4.2803e-01, 1.8247e-01, 2.3593e-01, 1.5330e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,351][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.0227, 0.0192, 0.0047, 0.0067, 0.9466], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,353][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0150, 0.1222, 0.0613, 0.2804, 0.0750, 0.4461], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,355][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0380, 0.0761, 0.1318, 0.1397, 0.5770, 0.0374], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,356][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2756, 0.0175, 0.0593, 0.2221, 0.1812, 0.2443], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,358][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1297, 0.1931, 0.1742, 0.2319, 0.0713, 0.1998], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,360][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0433, 0.1777, 0.2222, 0.1195, 0.2797, 0.1575], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,362][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1150, 0.1626, 0.0117, 0.3532, 0.0225, 0.3351], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,364][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2792, 0.0787, 0.0732, 0.1984, 0.2662, 0.1043], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,365][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1351, 0.0379, 0.2858, 0.2135, 0.1741, 0.1536], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,366][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5542, 0.1178, 0.0500, 0.1315, 0.0479, 0.0986], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,367][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.4855, 0.2048, 0.0260, 0.0671, 0.1577, 0.0589], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,367][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([2.7618e-04, 3.0433e-01, 1.5590e-01, 1.8381e-01, 1.5864e-01, 1.9704e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,368][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0350, 0.0271, 0.0028, 0.0246, 0.0053, 0.9053], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,369][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0127, 0.0979, 0.0486, 0.2053, 0.0595, 0.3353, 0.2407],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,371][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0491, 0.0450, 0.2644, 0.0525, 0.3910, 0.1811, 0.0168],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,373][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2177, 0.0148, 0.0425, 0.1640, 0.1306, 0.1598, 0.2706],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,375][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1096, 0.1449, 0.1410, 0.1773, 0.0551, 0.1490, 0.2230],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,376][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0463, 0.1469, 0.1804, 0.1188, 0.2634, 0.1337, 0.1106],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,378][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0873, 0.1131, 0.0088, 0.2419, 0.0168, 0.2198, 0.3123],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,380][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1219, 0.0999, 0.3282, 0.1668, 0.2007, 0.0397, 0.0428],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,382][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0953, 0.0455, 0.1575, 0.1565, 0.1772, 0.1254, 0.2425],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,383][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5120, 0.0821, 0.0372, 0.1209, 0.0451, 0.0719, 0.1308],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,384][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3022, 0.3047, 0.0207, 0.0826, 0.1485, 0.0711, 0.0703],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,385][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0004, 0.2483, 0.1364, 0.1559, 0.1483, 0.1661, 0.1446],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,385][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0830, 0.0186, 0.0026, 0.0190, 0.0051, 0.0048, 0.8670],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,386][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0065, 0.0713, 0.0345, 0.1846, 0.0428, 0.3280, 0.2359, 0.0965],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,387][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0445, 0.0737, 0.3021, 0.0837, 0.1977, 0.2195, 0.0452, 0.0337],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,389][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1870, 0.0143, 0.0362, 0.1452, 0.1152, 0.1401, 0.2360, 0.1260],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,391][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1052, 0.1414, 0.1175, 0.1691, 0.0484, 0.1314, 0.1774, 0.1097],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,393][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0355, 0.1406, 0.1685, 0.1062, 0.2227, 0.1118, 0.0731, 0.1416],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,394][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0729, 0.0992, 0.0056, 0.2080, 0.0112, 0.1831, 0.2717, 0.1483],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,396][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.3462, 0.0602, 0.0217, 0.2129, 0.0834, 0.1031, 0.1113, 0.0610],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,398][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1745, 0.0519, 0.0962, 0.1740, 0.0699, 0.1617, 0.2254, 0.0462],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,400][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.4050, 0.0785, 0.0340, 0.1303, 0.0408, 0.1019, 0.1491, 0.0602],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,401][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.4531, 0.1255, 0.0511, 0.0522, 0.1853, 0.0702, 0.0505, 0.0121],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,402][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0003, 0.2365, 0.1255, 0.1409, 0.1379, 0.1471, 0.1207, 0.0911],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,403][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.4980e-02, 2.5586e-02, 1.2608e-03, 1.2111e-02, 6.8320e-04, 2.8862e-03,
        2.2699e-03, 9.4022e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,403][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0096, 0.0684, 0.0364, 0.1475, 0.0448, 0.2483, 0.1842, 0.0904, 0.1704],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,404][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([5.1039e-03, 5.5985e-03, 4.8299e-01, 9.6212e-03, 2.9644e-01, 3.7451e-02,
        6.5900e-02, 9.6790e-02, 1.0461e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,405][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1371, 0.0117, 0.0322, 0.1101, 0.0972, 0.1152, 0.1718, 0.0803, 0.2444],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,407][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0747, 0.1009, 0.0945, 0.1192, 0.0409, 0.1023, 0.1294, 0.0868, 0.2512],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,409][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0304, 0.1180, 0.1966, 0.0929, 0.2584, 0.1003, 0.0794, 0.0761, 0.0479],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,411][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0518, 0.0642, 0.0057, 0.1386, 0.0108, 0.1320, 0.1843, 0.1026, 0.3101],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,412][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0849, 0.1200, 0.1459, 0.1706, 0.1613, 0.0388, 0.0573, 0.1052, 0.1160],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,415][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1241, 0.0710, 0.0756, 0.1387, 0.1202, 0.0617, 0.1870, 0.0560, 0.1656],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,416][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.4330, 0.0563, 0.0265, 0.1073, 0.0379, 0.0522, 0.1187, 0.0610, 0.1070],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,418][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2999, 0.2231, 0.0199, 0.0689, 0.1410, 0.0598, 0.0601, 0.0071, 0.1201],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,419][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0006, 0.1732, 0.1140, 0.1251, 0.1365, 0.1519, 0.1104, 0.0898, 0.0984],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,420][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1024, 0.0447, 0.0072, 0.0540, 0.0051, 0.0078, 0.0431, 0.0107, 0.7250],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,421][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0032, 0.0477, 0.0204, 0.1409, 0.0253, 0.2934, 0.1877, 0.0722, 0.1693,
        0.0400], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,421][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0502, 0.0781, 0.1771, 0.1302, 0.1117, 0.0839, 0.0237, 0.2964, 0.0440,
        0.0047], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,422][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1062, 0.0105, 0.0278, 0.1062, 0.0816, 0.0988, 0.1471, 0.0752, 0.2448,
        0.1017], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,424][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0694, 0.1006, 0.0888, 0.1249, 0.0323, 0.1012, 0.1292, 0.0766, 0.2325,
        0.0445], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,425][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0308, 0.1454, 0.1283, 0.1036, 0.1570, 0.1136, 0.0673, 0.1073, 0.0468,
        0.0999], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,427][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0442, 0.0609, 0.0025, 0.1309, 0.0050, 0.1237, 0.1886, 0.0914, 0.3214,
        0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,429][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.2038, 0.0378, 0.0747, 0.1040, 0.0661, 0.1457, 0.0650, 0.1953, 0.0499,
        0.0578], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,430][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0867, 0.0518, 0.0992, 0.1240, 0.0526, 0.1774, 0.1566, 0.1345, 0.1110,
        0.0065], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,432][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.3010, 0.0830, 0.0518, 0.1045, 0.0473, 0.0889, 0.1222, 0.0690, 0.0949,
        0.0374], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,434][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.5577, 0.0857, 0.0445, 0.0195, 0.1280, 0.0467, 0.0299, 0.0098, 0.0580,
        0.0202], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,436][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0004, 0.1667, 0.1032, 0.1167, 0.1222, 0.1233, 0.0992, 0.0804, 0.0771,
        0.1107], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,437][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0275, 0.0169, 0.0021, 0.0187, 0.0037, 0.0040, 0.0091, 0.0076, 0.0542,
        0.8560], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,438][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0070, 0.0601, 0.0297, 0.1328, 0.0356, 0.2234, 0.1635, 0.0743, 0.1555,
        0.0479, 0.0700], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,438][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0235, 0.0317, 0.2428, 0.0546, 0.2083, 0.1483, 0.1111, 0.1082, 0.0108,
        0.0564, 0.0041], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,439][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0895, 0.0087, 0.0241, 0.0707, 0.0702, 0.0764, 0.1107, 0.0576, 0.1524,
        0.0733, 0.2665], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,440][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0699, 0.0893, 0.0789, 0.1076, 0.0333, 0.0852, 0.1139, 0.0732, 0.2015,
        0.0458, 0.1016], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,441][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0283, 0.1010, 0.1303, 0.0799, 0.1827, 0.0854, 0.0654, 0.1015, 0.0372,
        0.1085, 0.0798], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,443][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0402, 0.0540, 0.0040, 0.1180, 0.0075, 0.1103, 0.1621, 0.0841, 0.2727,
        0.0389, 0.1083], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,445][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0595, 0.0392, 0.0685, 0.1030, 0.2197, 0.0538, 0.0288, 0.0160, 0.1444,
        0.2393, 0.0277], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,446][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0656, 0.0240, 0.1005, 0.1190, 0.1283, 0.1797, 0.1136, 0.0543, 0.0964,
        0.0504, 0.0683], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,448][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.3872, 0.0623, 0.0313, 0.0772, 0.0362, 0.0556, 0.1009, 0.0558, 0.0767,
        0.0349, 0.0818], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,450][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2194, 0.2431, 0.0173, 0.0515, 0.1191, 0.0702, 0.0718, 0.0069, 0.1382,
        0.0189, 0.0436], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,452][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0007, 0.1301, 0.0927, 0.1016, 0.1070, 0.1166, 0.0892, 0.0766, 0.0731,
        0.0979, 0.1145], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,454][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0212, 0.0229, 0.0030, 0.0171, 0.0010, 0.0100, 0.0051, 0.0034, 0.0438,
        0.0020, 0.8705], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,455][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0059, 0.0554, 0.0259, 0.1251, 0.0313, 0.2095, 0.1479, 0.0690, 0.1431,
        0.0441, 0.0629, 0.0800], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,456][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0240, 0.0174, 0.0626, 0.0553, 0.0623, 0.2082, 0.0501, 0.2310, 0.0455,
        0.0379, 0.2023, 0.0034], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,456][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0691, 0.0078, 0.0214, 0.0564, 0.0591, 0.0611, 0.0922, 0.0524, 0.1166,
        0.0663, 0.1971, 0.2005], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,457][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0605, 0.0716, 0.0717, 0.0943, 0.0291, 0.0752, 0.1106, 0.0708, 0.1708,
        0.0419, 0.0823, 0.1211], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,458][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0280, 0.0856, 0.1224, 0.0624, 0.1683, 0.0811, 0.0596, 0.1131, 0.0315,
        0.1286, 0.0624, 0.0570], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,460][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0370, 0.0486, 0.0036, 0.1053, 0.0070, 0.0937, 0.1392, 0.0760, 0.2300,
        0.0350, 0.0899, 0.1347], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,462][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0451, 0.0244, 0.4184, 0.0932, 0.1077, 0.0278, 0.0188, 0.0311, 0.0776,
        0.0542, 0.0818, 0.0200], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,464][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0370, 0.0156, 0.0522, 0.0816, 0.0910, 0.0915, 0.1532, 0.0341, 0.0846,
        0.0509, 0.0692, 0.2389], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,466][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3313, 0.0555, 0.0271, 0.0766, 0.0294, 0.0452, 0.0923, 0.0566, 0.0722,
        0.0330, 0.0736, 0.1072], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,468][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2252, 0.1828, 0.0199, 0.0529, 0.1142, 0.0733, 0.0667, 0.0086, 0.1275,
        0.0203, 0.0485, 0.0602], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,470][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0008, 0.1071, 0.0819, 0.0907, 0.1000, 0.1057, 0.0880, 0.0652, 0.0640,
        0.0945, 0.1016, 0.1006], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,471][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0823, 0.0165, 0.0092, 0.0272, 0.0097, 0.0068, 0.0263, 0.0040, 0.1473,
        0.0112, 0.0188, 0.6406], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,473][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0037, 0.0436, 0.0195, 0.1194, 0.0240, 0.2333, 0.1543, 0.0588, 0.1360,
        0.0357, 0.0566, 0.0763, 0.0389], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,474][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0280, 0.0184, 0.2052, 0.0586, 0.1734, 0.0970, 0.1004, 0.1638, 0.0051,
        0.0365, 0.0918, 0.0187, 0.0031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,474][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0617, 0.0073, 0.0190, 0.0622, 0.0548, 0.0605, 0.0888, 0.0397, 0.1321,
        0.0553, 0.1933, 0.1695, 0.0557], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,475][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0575, 0.0808, 0.0624, 0.1011, 0.0239, 0.0789, 0.0975, 0.0592, 0.1863,
        0.0357, 0.0895, 0.1003, 0.0269], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,476][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0195, 0.1091, 0.0962, 0.0743, 0.1484, 0.0771, 0.0472, 0.0761, 0.0302,
        0.0912, 0.0552, 0.0426, 0.1329], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,478][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0313, 0.0470, 0.0020, 0.1034, 0.0040, 0.0898, 0.1441, 0.0721, 0.2460,
        0.0247, 0.0877, 0.1271, 0.0208], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,479][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0252, 0.0514, 0.1691, 0.1128, 0.0753, 0.0511, 0.0210, 0.0125, 0.0636,
        0.0390, 0.1088, 0.0157, 0.2545], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,481][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0492, 0.0123, 0.0959, 0.1265, 0.0907, 0.1428, 0.1104, 0.0343, 0.0586,
        0.0333, 0.0925, 0.1410, 0.0126], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,483][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2462, 0.0743, 0.0364, 0.0682, 0.0243, 0.1043, 0.0885, 0.0599, 0.0703,
        0.0249, 0.0691, 0.1135, 0.0200], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,484][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.3030, 0.0553, 0.0742, 0.0212, 0.1574, 0.0718, 0.0458, 0.0203, 0.0622,
        0.0362, 0.0387, 0.0565, 0.0574], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,487][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0003, 0.1164, 0.0743, 0.0946, 0.0853, 0.0961, 0.0755, 0.0634, 0.0622,
        0.0861, 0.0962, 0.0796, 0.0700], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,488][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([6.3887e-03, 4.7152e-03, 1.1626e-03, 8.1541e-03, 1.6657e-04, 2.1041e-03,
        1.2116e-03, 7.8440e-04, 1.1385e-02, 1.5605e-03, 2.2472e-02, 3.0754e-03,
        9.3682e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,490][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0051, 0.0465, 0.0232, 0.1065, 0.0277, 0.1832, 0.1307, 0.0609, 0.1235,
        0.0399, 0.0576, 0.0726, 0.0453, 0.0772], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,491][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0707, 0.0185, 0.2373, 0.0212, 0.1314, 0.0582, 0.0451, 0.1426, 0.0060,
        0.0897, 0.0927, 0.0174, 0.0655, 0.0037], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,492][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0488, 0.0051, 0.0170, 0.0359, 0.0483, 0.0479, 0.0610, 0.0390, 0.0807,
        0.0519, 0.1295, 0.1282, 0.0619, 0.2448], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,493][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0483, 0.0586, 0.0610, 0.0812, 0.0225, 0.0584, 0.0850, 0.0518, 0.1493,
        0.0334, 0.0686, 0.0826, 0.0304, 0.1688], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,493][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0227, 0.0636, 0.1244, 0.0524, 0.1515, 0.0670, 0.0464, 0.0809, 0.0291,
        0.1053, 0.0513, 0.0430, 0.1282, 0.0342], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,494][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0286, 0.0381, 0.0032, 0.0853, 0.0062, 0.0819, 0.1208, 0.0658, 0.1971,
        0.0295, 0.0770, 0.1161, 0.0241, 0.1263], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,496][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0442, 0.0169, 0.1721, 0.0602, 0.1608, 0.0224, 0.0110, 0.0194, 0.1132,
        0.0418, 0.0630, 0.0201, 0.1790, 0.0758], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,498][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0307, 0.0086, 0.1034, 0.0812, 0.0817, 0.0491, 0.0600, 0.0564, 0.0884,
        0.0746, 0.0434, 0.0919, 0.1583, 0.0723], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,500][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2749, 0.0806, 0.0360, 0.0676, 0.0267, 0.0510, 0.0677, 0.0728, 0.0487,
        0.0337, 0.0415, 0.0610, 0.0251, 0.1127], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,502][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2732, 0.1376, 0.0197, 0.0451, 0.1344, 0.0480, 0.0417, 0.0055, 0.0772,
        0.0152, 0.0322, 0.0398, 0.0322, 0.0982], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,504][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0010, 0.0914, 0.0674, 0.0773, 0.0816, 0.0880, 0.0660, 0.0534, 0.0547,
        0.0754, 0.0821, 0.0717, 0.0676, 0.1224], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,506][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.1715, 0.0710, 0.0467, 0.0697, 0.0458, 0.0360, 0.0529, 0.0282, 0.1152,
        0.0581, 0.0354, 0.0706, 0.0322, 0.1666], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,508][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0045, 0.0453, 0.0181, 0.1079, 0.0208, 0.2064, 0.1352, 0.0575, 0.1299,
        0.0327, 0.0511, 0.0670, 0.0360, 0.0765, 0.0111], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,509][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0162, 0.0206, 0.0367, 0.0495, 0.1319, 0.0347, 0.0340, 0.2357, 0.0821,
        0.0476, 0.1851, 0.0294, 0.0204, 0.0492, 0.0271], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,510][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0377, 0.0076, 0.0155, 0.0394, 0.0389, 0.0473, 0.0562, 0.0335, 0.0759,
        0.0446, 0.1252, 0.1096, 0.0518, 0.1863, 0.1304], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,511][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0465, 0.0586, 0.0491, 0.0777, 0.0191, 0.0623, 0.0755, 0.0486, 0.1419,
        0.0300, 0.0643, 0.0765, 0.0251, 0.1667, 0.0580], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,511][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0176, 0.1016, 0.0828, 0.0696, 0.1250, 0.0798, 0.0454, 0.0654, 0.0282,
        0.0725, 0.0532, 0.0380, 0.1224, 0.0352, 0.0633], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,512][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0300, 0.0454, 0.0015, 0.1020, 0.0031, 0.0819, 0.1296, 0.0581, 0.2183,
        0.0182, 0.0744, 0.1048, 0.0156, 0.1142, 0.0028], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,514][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0157, 0.0206, 0.1438, 0.0374, 0.0266, 0.0639, 0.0145, 0.0232, 0.0602,
        0.0143, 0.0706, 0.0204, 0.0657, 0.1854, 0.2377], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,516][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0090, 0.0182, 0.0266, 0.0594, 0.0572, 0.1230, 0.0796, 0.0716, 0.0514,
        0.0580, 0.0285, 0.1926, 0.0692, 0.1453, 0.0104], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,518][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.1962, 0.0842, 0.0172, 0.0401, 0.0168, 0.0749, 0.1048, 0.0389, 0.0501,
        0.0193, 0.0500, 0.0872, 0.0158, 0.1696, 0.0350], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,520][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.2015, 0.0449, 0.0424, 0.0225, 0.0807, 0.0751, 0.0495, 0.0190, 0.0797,
        0.0322, 0.0493, 0.0589, 0.0456, 0.0869, 0.1119], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,522][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0010, 0.0823, 0.0569, 0.0821, 0.0692, 0.0921, 0.0669, 0.0477, 0.0491,
        0.0677, 0.0779, 0.0685, 0.0600, 0.1136, 0.0651], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,523][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([7.8463e-04, 2.0684e-03, 1.2661e-01, 1.0428e-03, 1.8618e-03, 2.3244e-04,
        1.8277e-04, 3.2063e-04, 1.9839e-03, 4.2814e-04, 6.5807e-04, 4.4899e-04,
        3.7438e-04, 2.4982e-02, 8.3802e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,525][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0039, 0.0394, 0.0188, 0.1008, 0.0227, 0.1790, 0.1296, 0.0564, 0.1207,
        0.0355, 0.0545, 0.0697, 0.0413, 0.0750, 0.0138, 0.0390],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,527][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0110, 0.0083, 0.1167, 0.0253, 0.2589, 0.0355, 0.0312, 0.2808, 0.0026,
        0.0229, 0.0207, 0.0418, 0.0305, 0.0135, 0.0914, 0.0090],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,528][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0384, 0.0064, 0.0162, 0.0315, 0.0379, 0.0354, 0.0436, 0.0280, 0.0629,
        0.0374, 0.0996, 0.0840, 0.0478, 0.1667, 0.1434, 0.1209],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,529][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0439, 0.0546, 0.0447, 0.0732, 0.0195, 0.0588, 0.0739, 0.0443, 0.1453,
        0.0280, 0.0693, 0.0743, 0.0248, 0.1596, 0.0544, 0.0312],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,530][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0148, 0.0819, 0.0905, 0.0531, 0.1141, 0.0543, 0.0367, 0.0509, 0.0244,
        0.0701, 0.0544, 0.0358, 0.1207, 0.0316, 0.0738, 0.0931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,531][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0272, 0.0389, 0.0024, 0.0867, 0.0046, 0.0798, 0.1148, 0.0593, 0.1905,
        0.0243, 0.0728, 0.1028, 0.0197, 0.1117, 0.0042, 0.0603],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,533][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0572, 0.0210, 0.0390, 0.0937, 0.1348, 0.0394, 0.0254, 0.0305, 0.0898,
        0.0460, 0.0714, 0.0312, 0.0594, 0.0851, 0.0874, 0.0887],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,535][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0211, 0.0263, 0.0524, 0.0779, 0.0540, 0.0475, 0.0731, 0.0420, 0.0758,
        0.0840, 0.0509, 0.1118, 0.0737, 0.1776, 0.0253, 0.0068],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,536][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2645, 0.0505, 0.0215, 0.0606, 0.0171, 0.0523, 0.0658, 0.0362, 0.0401,
        0.0193, 0.0465, 0.0833, 0.0152, 0.1215, 0.0407, 0.0649],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,538][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1998, 0.0403, 0.0390, 0.0198, 0.0718, 0.0852, 0.0472, 0.0166, 0.0642,
        0.0254, 0.0353, 0.0562, 0.0413, 0.0761, 0.1073, 0.0747],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,540][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0004, 0.0845, 0.0597, 0.0702, 0.0709, 0.0790, 0.0549, 0.0423, 0.0463,
        0.0613, 0.0718, 0.0597, 0.0545, 0.1011, 0.0613, 0.0822],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,542][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0131, 0.0101, 0.0011, 0.0067, 0.0024, 0.0072, 0.0011, 0.0034, 0.0158,
        0.0033, 0.0019, 0.0021, 0.0020, 0.0519, 0.0010, 0.8772],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,544][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0054, 0.0454, 0.0216, 0.0966, 0.0254, 0.1611, 0.1133, 0.0563, 0.1106,
        0.0357, 0.0513, 0.0641, 0.0404, 0.0697, 0.0145, 0.0390, 0.0497],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,545][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0165, 0.0143, 0.0785, 0.0185, 0.1288, 0.0641, 0.0054, 0.1217, 0.0396,
        0.0236, 0.1506, 0.0614, 0.0389, 0.0344, 0.0719, 0.1284, 0.0035],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,546][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0310, 0.0059, 0.0140, 0.0236, 0.0333, 0.0305, 0.0419, 0.0262, 0.0470,
        0.0341, 0.0797, 0.0762, 0.0432, 0.1315, 0.1199, 0.1078, 0.1541],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,547][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0381, 0.0471, 0.0480, 0.0603, 0.0184, 0.0503, 0.0765, 0.0466, 0.1179,
        0.0258, 0.0569, 0.0777, 0.0232, 0.1455, 0.0587, 0.0280, 0.0810],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,548][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0188, 0.0630, 0.0727, 0.0492, 0.1046, 0.0539, 0.0455, 0.0693, 0.0246,
        0.0848, 0.0459, 0.0407, 0.1209, 0.0294, 0.0611, 0.0763, 0.0394],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,549][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0274, 0.0339, 0.0026, 0.0744, 0.0050, 0.0673, 0.0996, 0.0541, 0.1659,
        0.0247, 0.0656, 0.0970, 0.0202, 0.1036, 0.0045, 0.0528, 0.1014],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,551][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0319, 0.0426, 0.1476, 0.0722, 0.1054, 0.0130, 0.0115, 0.0557, 0.0916,
        0.0627, 0.0512, 0.0234, 0.0573, 0.0602, 0.1098, 0.0486, 0.0154],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,553][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0196, 0.0296, 0.0535, 0.0566, 0.0652, 0.0441, 0.0768, 0.0505, 0.0745,
        0.0328, 0.0418, 0.1203, 0.0496, 0.1734, 0.0154, 0.0229, 0.0733],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,555][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2366, 0.0403, 0.0181, 0.0544, 0.0244, 0.0329, 0.0663, 0.0347, 0.0443,
        0.0222, 0.0474, 0.0718, 0.0170, 0.1218, 0.0344, 0.0505, 0.0830],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,556][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1365, 0.0934, 0.0184, 0.0343, 0.0733, 0.0784, 0.0616, 0.0098, 0.1073,
        0.0181, 0.0394, 0.0591, 0.0260, 0.1297, 0.0340, 0.0342, 0.0466],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,559][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0009, 0.0663, 0.0528, 0.0596, 0.0647, 0.0723, 0.0611, 0.0429, 0.0409,
        0.0570, 0.0649, 0.0593, 0.0502, 0.0938, 0.0604, 0.0851, 0.0679],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,560][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.0636e-02, 6.2713e-03, 1.1711e-03, 5.3101e-03, 2.1518e-03, 1.6359e-03,
        2.2048e-01, 1.6722e-03, 2.7673e-02, 3.2911e-03, 5.6850e-03, 7.6215e-03,
        5.6115e-04, 5.1411e-02, 4.3381e-03, 2.2880e-03, 6.3780e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,562][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0024, 0.0363, 0.0143, 0.1006, 0.0167, 0.2015, 0.1305, 0.0490, 0.1186,
        0.0273, 0.0435, 0.0607, 0.0322, 0.0692, 0.0091, 0.0319, 0.0468, 0.0092],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,563][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0273, 0.0224, 0.2586, 0.0665, 0.0890, 0.1087, 0.0607, 0.0600, 0.0050,
        0.0254, 0.0167, 0.0273, 0.0090, 0.0100, 0.1018, 0.0725, 0.0303, 0.0089],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,564][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.0281, 0.0046, 0.0111, 0.0221, 0.0251, 0.0248, 0.0326, 0.0222, 0.0465,
        0.0282, 0.0712, 0.0681, 0.0364, 0.1266, 0.1199, 0.1045, 0.1357, 0.0924],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,565][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0395, 0.0527, 0.0456, 0.0648, 0.0174, 0.0527, 0.0675, 0.0425, 0.1232,
        0.0251, 0.0586, 0.0672, 0.0229, 0.1455, 0.0525, 0.0260, 0.0703, 0.0260],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,566][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0145, 0.0797, 0.0797, 0.0544, 0.0984, 0.0537, 0.0332, 0.0452, 0.0233,
        0.0643, 0.0430, 0.0283, 0.1006, 0.0285, 0.0609, 0.0681, 0.0266, 0.0977],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,567][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.0254, 0.0390, 0.0012, 0.0826, 0.0024, 0.0721, 0.1127, 0.0498, 0.1934,
        0.0148, 0.0648, 0.0905, 0.0124, 0.0935, 0.0021, 0.0475, 0.0910, 0.0049],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,569][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0408, 0.0474, 0.0547, 0.0477, 0.1472, 0.0329, 0.0214, 0.0308, 0.0458,
        0.2867, 0.0138, 0.0325, 0.0310, 0.0287, 0.0470, 0.0128, 0.0183, 0.0607],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,571][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0130, 0.0068, 0.1132, 0.0259, 0.0495, 0.0432, 0.0787, 0.0977, 0.0439,
        0.0703, 0.0445, 0.0629, 0.0813, 0.0758, 0.0641, 0.0220, 0.1070, 0.0002],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,573][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.2086, 0.0293, 0.0148, 0.0463, 0.0129, 0.0619, 0.0522, 0.0454, 0.0436,
        0.0167, 0.0465, 0.0668, 0.0172, 0.1506, 0.0391, 0.0707, 0.0652, 0.0124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,575][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.2797, 0.0398, 0.0422, 0.0160, 0.0757, 0.0528, 0.0352, 0.0185, 0.0451,
        0.0244, 0.0203, 0.0399, 0.0309, 0.0465, 0.0964, 0.0547, 0.0467, 0.0353],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,577][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0007, 0.0753, 0.0530, 0.0601, 0.0564, 0.0662, 0.0474, 0.0415, 0.0397,
        0.0569, 0.0600, 0.0493, 0.0515, 0.0833, 0.0606, 0.0742, 0.0524, 0.0715],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,579][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0346, 0.0180, 0.0014, 0.0256, 0.0030, 0.0080, 0.0073, 0.0014, 0.0324,
        0.0076, 0.0109, 0.0100, 0.0081, 0.1126, 0.0012, 0.0093, 0.0116, 0.6971],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,581][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0039, 0.0404, 0.0184, 0.0955, 0.0213, 0.1644, 0.1162, 0.0518, 0.1087,
        0.0316, 0.0464, 0.0612, 0.0363, 0.0676, 0.0125, 0.0353, 0.0477, 0.0123,
        0.0285], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,582][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0174, 0.0076, 0.1318, 0.0318, 0.0952, 0.0975, 0.0514, 0.1831, 0.0024,
        0.0184, 0.0340, 0.0269, 0.0276, 0.0027, 0.1078, 0.0384, 0.0408, 0.0851,
        0.0003], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,583][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0201, 0.0046, 0.0119, 0.0153, 0.0274, 0.0229, 0.0261, 0.0177, 0.0338,
        0.0248, 0.0560, 0.0528, 0.0340, 0.0946, 0.1047, 0.0991, 0.1044, 0.0869,
        0.1632], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,584][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0358, 0.0419, 0.0420, 0.0539, 0.0171, 0.0486, 0.0622, 0.0394, 0.1133,
        0.0244, 0.0557, 0.0635, 0.0216, 0.1314, 0.0511, 0.0271, 0.0662, 0.0279,
        0.0770], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,585][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0186, 0.0499, 0.0656, 0.0388, 0.1062, 0.0486, 0.0401, 0.0564, 0.0224,
        0.0561, 0.0419, 0.0357, 0.0962, 0.0245, 0.0559, 0.0823, 0.0357, 0.0955,
        0.0295], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,587][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0259, 0.0361, 0.0022, 0.0716, 0.0042, 0.0626, 0.0927, 0.0544, 0.1560,
        0.0215, 0.0579, 0.0861, 0.0179, 0.0896, 0.0037, 0.0470, 0.0871, 0.0081,
        0.0756], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,589][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0442, 0.0180, 0.0696, 0.0735, 0.0317, 0.0129, 0.0234, 0.0297, 0.0719,
        0.0291, 0.0587, 0.0214, 0.0995, 0.0564, 0.0594, 0.1635, 0.0349, 0.0622,
        0.0399], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,591][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0222, 0.0328, 0.0353, 0.0592, 0.0557, 0.0317, 0.0879, 0.0199, 0.0828,
        0.0192, 0.0461, 0.0980, 0.0558, 0.1381, 0.0075, 0.0227, 0.0743, 0.0474,
        0.0635], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,592][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2180, 0.0320, 0.0181, 0.0418, 0.0244, 0.0355, 0.0609, 0.0303, 0.0368,
        0.0200, 0.0440, 0.0607, 0.0170, 0.1147, 0.0370, 0.0512, 0.0792, 0.0198,
        0.0586], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,594][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1348, 0.0871, 0.0168, 0.0295, 0.0680, 0.0745, 0.0626, 0.0093, 0.0995,
        0.0171, 0.0351, 0.0588, 0.0234, 0.1120, 0.0319, 0.0323, 0.0458, 0.0192,
        0.0423], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,596][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0013, 0.0530, 0.0478, 0.0497, 0.0577, 0.0636, 0.0457, 0.0332, 0.0358,
        0.0474, 0.0562, 0.0482, 0.0449, 0.0789, 0.0591, 0.0768, 0.0539, 0.0710,
        0.0758], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,598][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1290, 0.0305, 0.0024, 0.0365, 0.0007, 0.0058, 0.0128, 0.0023, 0.0881,
        0.0066, 0.0168, 0.0088, 0.0040, 0.1262, 0.0038, 0.0048, 0.0192, 0.0021,
        0.4995], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,602][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:53,603][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[30651],
        [30925],
        [19925],
        [34977],
        [    1],
        [27693],
        [38041],
        [37431],
        [37204],
        [43352],
        [33926],
        [33731],
        [37504],
        [22103],
        [17535],
        [22218],
        [37492],
        [32940],
        [21281]], device='cuda:0')
[2024-07-24 10:18:53,605][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[23489],
        [ 9428],
        [ 8122],
        [ 8222],
        [    1],
        [15365],
        [24008],
        [26667],
        [10580],
        [28477],
        [18756],
        [19778],
        [23992],
        [ 6976],
        [10774],
        [ 8916],
        [24044],
        [34771],
        [ 5200]], device='cuda:0')
[2024-07-24 10:18:53,607][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15603],
        [22635],
        [23863],
        [24387],
        [20709],
        [23461],
        [25362],
        [35333],
        [40839],
        [39044],
        [37907],
        [33244],
        [33476],
        [31797],
        [28008],
        [26344],
        [26958],
        [18390],
        [21669]], device='cuda:0')
[2024-07-24 10:18:53,610][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[46987],
        [46376],
        [46566],
        [46984],
        [46747],
        [46712],
        [46953],
        [46351],
        [47001],
        [46891],
        [47030],
        [47038],
        [46877],
        [47040],
        [46885],
        [47048],
        [47041],
        [47023],
        [47034]], device='cuda:0')
[2024-07-24 10:18:53,611][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[36060],
        [38407],
        [39855],
        [40533],
        [40474],
        [40420],
        [40789],
        [40450],
        [40195],
        [40359],
        [40273],
        [40364],
        [40368],
        [40361],
        [40476],
        [40095],
        [40266],
        [40260],
        [40286]], device='cuda:0')
[2024-07-24 10:18:53,614][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25539],
        [24224],
        [21140],
        [24390],
        [24441],
        [25516],
        [26309],
        [25988],
        [26622],
        [26921],
        [27270],
        [27937],
        [28121],
        [28515],
        [29236],
        [29162],
        [29627],
        [30016],
        [30561]], device='cuda:0')
[2024-07-24 10:18:53,616][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19354],
        [19540],
        [19403],
        [19346],
        [19206],
        [19859],
        [19921],
        [20888],
        [20430],
        [20156],
        [20174],
        [20190],
        [19867],
        [19789],
        [19832],
        [19892],
        [19924],
        [20195],
        [20185]], device='cuda:0')
[2024-07-24 10:18:53,618][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42889],
        [34338],
        [37127],
        [34256],
        [34440],
        [32187],
        [33503],
        [35311],
        [33678],
        [33025],
        [33495],
        [33896],
        [33648],
        [33840],
        [33729],
        [32813],
        [33591],
        [34315],
        [33258]], device='cuda:0')
[2024-07-24 10:18:53,620][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10588],
        [ 9690],
        [ 9450],
        [10611],
        [ 9706],
        [ 8508],
        [ 6658],
        [ 6280],
        [ 5470],
        [ 5309],
        [ 5030],
        [ 4542],
        [ 4897],
        [ 4544],
        [ 4993],
        [ 4775],
        [ 4588],
        [ 4654],
        [ 4344]], device='cuda:0')
[2024-07-24 10:18:53,621][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35726],
        [38681],
        [27093],
        [33702],
        [13138],
        [ 9176],
        [10512],
        [10438],
        [16480],
        [13289],
        [13653],
        [14860],
        [12982],
        [16891],
        [14416],
        [16091],
        [17266],
        [16222],
        [18474]], device='cuda:0')
[2024-07-24 10:18:53,623][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15953],
        [15954],
        [15735],
        [16010],
        [ 5151],
        [ 6012],
        [14800],
        [23415],
        [28995],
        [27729],
        [22271],
        [21676],
        [22816],
        [23300],
        [22988],
        [21311],
        [21714],
        [20521],
        [19753]], device='cuda:0')
[2024-07-24 10:18:53,625][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[26629],
        [29191],
        [30231],
        [31074],
        [32821],
        [33195],
        [33696],
        [34439],
        [34499],
        [35218],
        [35101],
        [35371],
        [35814],
        [35655],
        [36138],
        [36097],
        [36008],
        [36288],
        [35977]], device='cuda:0')
[2024-07-24 10:18:53,627][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17045],
        [15242],
        [17032],
        [11143],
        [ 9048],
        [ 9239],
        [ 8504],
        [ 7553],
        [ 6597],
        [ 6507],
        [ 5467],
        [ 5390],
        [ 5628],
        [ 5566],
        [ 5605],
        [ 5976],
        [ 5908],
        [ 5744],
        [ 5866]], device='cuda:0')
[2024-07-24 10:18:53,629][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26367],
        [23523],
        [19422],
        [16618],
        [38114],
        [ 3904],
        [21323],
        [29680],
        [14631],
        [15592],
        [27808],
        [27209],
        [14855],
        [14198],
        [16402],
        [ 5204],
        [19600],
        [ 8049],
        [11523]], device='cuda:0')
[2024-07-24 10:18:53,631][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21925],
        [20280],
        [26587],
        [16149],
        [ 8727],
        [36123],
        [33591],
        [29532],
        [33993],
        [28386],
        [37076],
        [28680],
        [45370],
        [24547],
        [38223],
        [25082],
        [35091],
        [31103],
        [30430]], device='cuda:0')
[2024-07-24 10:18:53,633][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20921],
        [32014],
        [31529],
        [36179],
        [36207],
        [41627],
        [41009],
        [41421],
        [41064],
        [41744],
        [41162],
        [41170],
        [41493],
        [41242],
        [41342],
        [41317],
        [40965],
        [41347],
        [41054]], device='cuda:0')
[2024-07-24 10:18:53,635][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 1066],
        [ 1224],
        [ 9302],
        [16044],
        [10442],
        [11438],
        [11365],
        [ 9819],
        [11154],
        [ 7569],
        [ 8847],
        [13411],
        [ 9741],
        [10282],
        [ 8802],
        [ 8302],
        [11636],
        [10250],
        [ 9980]], device='cuda:0')
[2024-07-24 10:18:53,637][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 6587],
        [ 6532],
        [ 5762],
        [ 4654],
        [ 4764],
        [ 4731],
        [ 5589],
        [ 7096],
        [ 7415],
        [ 8915],
        [10939],
        [10866],
        [10102],
        [12582],
        [13944],
        [16293],
        [18549],
        [20788],
        [22631]], device='cuda:0')
[2024-07-24 10:18:53,639][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[26897],
        [23652],
        [23185],
        [25233],
        [24331],
        [22304],
        [22189],
        [22972],
        [25482],
        [24892],
        [25095],
        [24497],
        [24978],
        [25030],
        [24932],
        [24881],
        [24308],
        [24199],
        [24141]], device='cuda:0')
[2024-07-24 10:18:53,640][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20025],
        [17869],
        [22179],
        [24327],
        [25298],
        [26241],
        [27000],
        [24187],
        [26005],
        [23527],
        [23080],
        [23202],
        [23867],
        [23209],
        [23203],
        [22583],
        [23065],
        [22100],
        [22591]], device='cuda:0')
[2024-07-24 10:18:53,642][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36192],
        [34988],
        [34955],
        [35555],
        [35598],
        [36173],
        [36059],
        [36165],
        [35556],
        [35447],
        [35462],
        [35289],
        [35276],
        [35022],
        [35066],
        [35025],
        [34919],
        [34953],
        [34660]], device='cuda:0')
[2024-07-24 10:18:53,644][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18572],
        [15085],
        [ 9740],
        [ 7967],
        [ 1923],
        [ 1888],
        [ 3864],
        [ 5719],
        [ 5174],
        [10115],
        [ 4075],
        [ 7001],
        [25604],
        [19943],
        [ 8663],
        [ 6957],
        [ 7275],
        [14641],
        [11343]], device='cuda:0')
[2024-07-24 10:18:53,646][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1258],
        [ 1244],
        [18418],
        [21402],
        [19007],
        [39647],
        [41877],
        [38984],
        [24854],
        [36886],
        [39857],
        [37820],
        [40636],
        [43651],
        [39819],
        [39123],
        [39410],
        [47332],
        [33681]], device='cuda:0')
[2024-07-24 10:18:53,648][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[7341],
        [6276],
        [3491],
        [6078],
        [3336],
        [1898],
        [1834],
        [1671],
        [1833],
        [1905],
        [2031],
        [1907],
        [1878],
        [1820],
        [1941],
        [1785],
        [1929],
        [1995],
        [2223]], device='cuda:0')
[2024-07-24 10:18:53,650][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16022],
        [32759],
        [22747],
        [38314],
        [20977],
        [31930],
        [36957],
        [27907],
        [35609],
        [22957],
        [34797],
        [31700],
        [20413],
        [32417],
        [19334],
        [18098],
        [26806],
        [17311],
        [26098]], device='cuda:0')
[2024-07-24 10:18:53,652][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18986],
        [ 7384],
        [ 6567],
        [ 6983],
        [ 8466],
        [ 9691],
        [11291],
        [11969],
        [13142],
        [13968],
        [14340],
        [15941],
        [16004],
        [16728],
        [16841],
        [16871],
        [17359],
        [17210],
        [17576]], device='cuda:0')
[2024-07-24 10:18:53,655][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[31354],
        [31730],
        [19597],
        [33422],
        [19167],
        [35263],
        [24119],
        [13017],
        [26531],
        [ 7129],
        [ 6168],
        [22989],
        [ 6790],
        [27831],
        [16305],
        [33773],
        [22126],
        [36892],
        [24424]], device='cuda:0')
[2024-07-24 10:18:53,657][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[47106],
        [49162],
        [46597],
        [45474],
        [47355],
        [44150],
        [42221],
        [43722],
        [45266],
        [43354],
        [45251],
        [37590],
        [37416],
        [33894],
        [37252],
        [36387],
        [34190],
        [29751],
        [35414]], device='cuda:0')
[2024-07-24 10:18:53,658][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18708],
        [20614],
        [18357],
        [22248],
        [40421],
        [12681],
        [13014],
        [16021],
        [ 7824],
        [17789],
        [ 5974],
        [13150],
        [ 3491],
        [ 8544],
        [ 5716],
        [15017],
        [10499],
        [ 3190],
        [10016]], device='cuda:0')
[2024-07-24 10:18:53,660][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044],
        [27044]], device='cuda:0')
[2024-07-24 10:18:53,688][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:53,690][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,691][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,691][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,692][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,693][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,695][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,696][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,697][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,699][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,701][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,702][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,703][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:53,704][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4128, 0.5872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,705][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5056, 0.4944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,706][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,706][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7016, 0.2984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,707][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9391, 0.0609], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,708][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6496, 0.3504], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,709][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6705, 0.3295], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,711][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2868, 0.7132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,713][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9158, 0.0842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,715][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1920, 0.8080], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,717][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6095, 0.3905], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,718][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7293, 0.2707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:53,720][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.2447, 0.4351, 0.3202], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,721][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.7435, 0.1896, 0.0668], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,722][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([4.3904e-06, 2.4270e-01, 7.5730e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,723][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.3151, 0.2875, 0.3975], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,723][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.8461, 0.0744, 0.0796], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,724][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.1915, 0.7825, 0.0261], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,725][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.4415, 0.3799, 0.1786], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,726][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.1069, 0.4426, 0.4504], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,728][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.9345, 0.0450, 0.0204], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,730][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.1362, 0.7403, 0.1235], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,731][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.4096, 0.2875, 0.3029], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,733][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.4134, 0.1759, 0.4106], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:53,735][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1692, 0.2938, 0.2971, 0.2399], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,736][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6145, 0.2201, 0.0655, 0.0999], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,738][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.7789e-07, 1.1107e-02, 2.3762e-01, 7.5127e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,739][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1965, 0.1688, 0.3654, 0.2693], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,739][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7600, 0.0628, 0.0807, 0.0965], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,740][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4707, 0.3848, 0.0610, 0.0835], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,741][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2675, 0.2525, 0.3251, 0.1549], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,742][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0949, 0.3074, 0.4291, 0.1686], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,742][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9141, 0.0485, 0.0243, 0.0130], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,744][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0430, 0.2554, 0.3451, 0.3566], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,746][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2996, 0.2030, 0.2088, 0.2886], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,748][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2435, 0.1521, 0.3723, 0.2320], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:53,749][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.1175, 0.1886, 0.3128, 0.2255, 0.1555], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,751][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.6288, 0.1919, 0.0513, 0.0784, 0.0496], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,753][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([2.4338e-07, 7.5778e-04, 1.4974e-02, 2.6739e-01, 7.1687e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,754][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.0733, 0.0834, 0.4870, 0.3176, 0.0387], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,756][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.6691, 0.0623, 0.0694, 0.1080, 0.0911], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,757][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.1128, 0.4493, 0.0808, 0.3301, 0.0270], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,758][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.2265, 0.2259, 0.1484, 0.1799, 0.2193], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,758][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.0457, 0.3277, 0.2748, 0.1832, 0.1687], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,759][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.9071, 0.0401, 0.0184, 0.0093, 0.0251], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,760][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.0255, 0.1659, 0.1516, 0.6033, 0.0537], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,762][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.1685, 0.1302, 0.1263, 0.2309, 0.3440], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,763][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.2542, 0.0901, 0.2146, 0.1355, 0.3057], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:53,765][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0895, 0.1762, 0.1916, 0.1659, 0.3094, 0.0674], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,767][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.6608, 0.1231, 0.0373, 0.0751, 0.0468, 0.0569], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,768][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([7.0324e-09, 7.9113e-05, 1.9957e-03, 4.2342e-02, 8.6986e-01, 8.5723e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,770][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2548, 0.1051, 0.1618, 0.3434, 0.1168, 0.0181], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,772][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.6532, 0.0502, 0.0653, 0.0846, 0.0865, 0.0602], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,774][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2139, 0.3213, 0.0523, 0.2149, 0.1587, 0.0387], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,774][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2059, 0.2011, 0.2195, 0.0823, 0.2167, 0.0745], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,775][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0511, 0.2784, 0.2012, 0.1144, 0.1520, 0.2029], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,776][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8030, 0.0553, 0.0298, 0.0170, 0.0398, 0.0551], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,776][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0352, 0.1661, 0.1674, 0.4562, 0.1033, 0.0719], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,777][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1680, 0.0872, 0.0985, 0.1531, 0.2826, 0.2105], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,779][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1556, 0.1023, 0.2119, 0.1214, 0.3168, 0.0920], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:53,781][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0821, 0.1445, 0.1698, 0.1871, 0.2261, 0.0845, 0.1060],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,783][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.7648, 0.0861, 0.0204, 0.0404, 0.0219, 0.0222, 0.0442],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,784][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.0538e-09, 2.4974e-05, 5.0870e-04, 2.2403e-02, 1.7041e-01, 5.9195e-01,
        2.1471e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,786][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0998, 0.0836, 0.2103, 0.3692, 0.1569, 0.0393, 0.0410],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,788][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6207, 0.0431, 0.0574, 0.0705, 0.0750, 0.0480, 0.0853],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,790][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1806, 0.2670, 0.0966, 0.1400, 0.1567, 0.1340, 0.0251],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,791][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2375, 0.1992, 0.1062, 0.1074, 0.1421, 0.1070, 0.1007],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,792][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0397, 0.1863, 0.1708, 0.0967, 0.1246, 0.1527, 0.2292],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,793][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8213, 0.0398, 0.0200, 0.0124, 0.0279, 0.0442, 0.0343],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,793][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0309, 0.1483, 0.1409, 0.3311, 0.0986, 0.1467, 0.1035],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,794][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1650, 0.0726, 0.0777, 0.1173, 0.1999, 0.1403, 0.2272],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,795][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1346, 0.0705, 0.1687, 0.1420, 0.2332, 0.1686, 0.0823],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:53,797][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0706, 0.1209, 0.1211, 0.1504, 0.1818, 0.0751, 0.0866, 0.1935],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,799][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.6953, 0.0791, 0.0145, 0.0231, 0.0142, 0.0110, 0.0367, 0.1260],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,800][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([9.1319e-09, 1.6411e-05, 4.6543e-04, 6.0054e-03, 1.1879e-01, 7.6646e-02,
        6.5661e-01, 1.4147e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,802][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0382, 0.0480, 0.2213, 0.3210, 0.0790, 0.1055, 0.1787, 0.0083],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,804][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.5091, 0.0410, 0.0486, 0.0670, 0.0650, 0.0484, 0.0819, 0.1388],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,806][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0625, 0.2955, 0.0756, 0.2126, 0.1793, 0.1006, 0.0633, 0.0107],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,807][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1732, 0.0914, 0.1680, 0.1073, 0.1412, 0.1104, 0.1429, 0.0655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,809][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0221, 0.1791, 0.1227, 0.0900, 0.0866, 0.1366, 0.1942, 0.1687],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,809][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.6896, 0.0396, 0.0199, 0.0127, 0.0277, 0.0416, 0.0324, 0.1365],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,810][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0169, 0.1182, 0.0808, 0.3458, 0.0615, 0.1714, 0.1790, 0.0265],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,811][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1597, 0.0485, 0.0346, 0.0701, 0.0897, 0.0744, 0.1306, 0.3923],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,812][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.1294, 0.0596, 0.1633, 0.0749, 0.2470, 0.0930, 0.0615, 0.1713],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:53,813][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0679, 0.1117, 0.1066, 0.1021, 0.1770, 0.0507, 0.0785, 0.1935, 0.1120],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,815][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.4358, 0.0925, 0.0167, 0.0480, 0.0179, 0.0263, 0.0537, 0.1452, 0.1639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,816][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([3.5653e-09, 3.1511e-07, 1.7683e-05, 2.5937e-04, 1.4886e-02, 6.1041e-03,
        4.8636e-02, 4.1274e-01, 5.1735e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,818][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0634, 0.0627, 0.1150, 0.2705, 0.0924, 0.0721, 0.2284, 0.0331, 0.0624],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,819][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.5174, 0.0324, 0.0424, 0.0518, 0.0564, 0.0353, 0.0634, 0.1151, 0.0859],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,821][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1865, 0.1812, 0.0463, 0.1401, 0.1432, 0.0990, 0.1063, 0.0460, 0.0513],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,823][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1108, 0.1078, 0.1095, 0.1218, 0.1114, 0.0953, 0.1948, 0.0911, 0.0575],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,825][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0242, 0.1343, 0.1070, 0.0754, 0.0882, 0.1366, 0.2013, 0.1599, 0.0731],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,826][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.6708, 0.0309, 0.0157, 0.0105, 0.0225, 0.0367, 0.0285, 0.1149, 0.0696],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,827][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0115, 0.0801, 0.0992, 0.2365, 0.0677, 0.1157, 0.1700, 0.0648, 0.1546],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,827][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0750, 0.0498, 0.0425, 0.0656, 0.1038, 0.0741, 0.1019, 0.2346, 0.2526],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,828][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1050, 0.0581, 0.0974, 0.1296, 0.1219, 0.1120, 0.0750, 0.1182, 0.1828],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:53,829][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0538, 0.1001, 0.1036, 0.1009, 0.1137, 0.0585, 0.0624, 0.1503, 0.1400,
        0.1166], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,830][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.7252, 0.0440, 0.0060, 0.0093, 0.0042, 0.0028, 0.0110, 0.0499, 0.0454,
        0.1023], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,832][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([6.8601e-11, 1.7260e-08, 3.6097e-07, 6.8301e-06, 3.6158e-04, 1.0308e-03,
        3.4859e-03, 5.1915e-03, 3.9070e-01, 5.9922e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,834][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0628, 0.0495, 0.1160, 0.2125, 0.0583, 0.0408, 0.1948, 0.1032, 0.1459,
        0.0162], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,835][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.2836, 0.0337, 0.0347, 0.0559, 0.0473, 0.0425, 0.0717, 0.1222, 0.0879,
        0.2205], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,837][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1006, 0.2315, 0.1097, 0.1102, 0.1152, 0.0430, 0.0785, 0.0681, 0.1120,
        0.0312], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,839][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1118, 0.1688, 0.0823, 0.0750, 0.1332, 0.0719, 0.1272, 0.1152, 0.0486,
        0.0659], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,841][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0218, 0.1472, 0.0821, 0.0756, 0.0665, 0.1161, 0.1376, 0.1168, 0.0615,
        0.1748], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,843][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.4849, 0.0275, 0.0133, 0.0091, 0.0189, 0.0292, 0.0231, 0.1012, 0.0578,
        0.2350], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,845][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0178, 0.0854, 0.1236, 0.1978, 0.0514, 0.0876, 0.1155, 0.0579, 0.2490,
        0.0139], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,847][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0652, 0.0275, 0.0221, 0.0399, 0.0608, 0.0436, 0.0661, 0.1881, 0.1856,
        0.3010], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,849][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.1033, 0.0528, 0.1031, 0.0816, 0.1821, 0.0793, 0.0528, 0.1424, 0.0922,
        0.1104], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:53,850][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0440, 0.0877, 0.0931, 0.0838, 0.1305, 0.0475, 0.0630, 0.1293, 0.1014,
        0.1113, 0.1083], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,850][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.6433, 0.0476, 0.0072, 0.0138, 0.0057, 0.0042, 0.0128, 0.0464, 0.0504,
        0.0880, 0.0804], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,851][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([8.3739e-11, 2.0765e-09, 4.2339e-08, 1.0800e-06, 2.3487e-05, 2.6915e-05,
        2.2604e-04, 1.3566e-04, 3.3684e-02, 3.9617e-01, 5.6974e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,852][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0678, 0.0386, 0.0932, 0.1950, 0.1138, 0.0557, 0.1328, 0.0425, 0.1958,
        0.0330, 0.0317], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,853][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.3458, 0.0275, 0.0331, 0.0417, 0.0427, 0.0294, 0.0504, 0.0923, 0.0672,
        0.1776, 0.0923], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,855][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1595, 0.1635, 0.0359, 0.0938, 0.0920, 0.0821, 0.1070, 0.0965, 0.0982,
        0.0582, 0.0132], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,857][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2966, 0.1125, 0.0978, 0.0625, 0.0775, 0.0925, 0.0716, 0.1158, 0.0163,
        0.0203, 0.0365], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,858][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0176, 0.0864, 0.0725, 0.0508, 0.0659, 0.0971, 0.1368, 0.1437, 0.0481,
        0.2209, 0.0602], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,860][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.4036, 0.0251, 0.0136, 0.0093, 0.0184, 0.0289, 0.0232, 0.0856, 0.0528,
        0.1900, 0.1495], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,862][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0111, 0.0694, 0.0528, 0.1906, 0.0523, 0.0901, 0.1541, 0.0637, 0.1710,
        0.0733, 0.0716], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,864][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0220, 0.0208, 0.0200, 0.0309, 0.0521, 0.0343, 0.0469, 0.1072, 0.1065,
        0.1930, 0.3663], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,866][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0849, 0.0355, 0.0783, 0.0740, 0.1076, 0.0553, 0.0537, 0.1342, 0.1096,
        0.0896, 0.1773], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:53,866][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0382, 0.0682, 0.0728, 0.0778, 0.1135, 0.0406, 0.0499, 0.1283, 0.1015,
        0.1098, 0.1439, 0.0557], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,867][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.4804, 0.0229, 0.0025, 0.0037, 0.0016, 0.0008, 0.0043, 0.0236, 0.0217,
        0.0700, 0.0635, 0.3050], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,868][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([2.1191e-12, 6.2961e-11, 1.9341e-09, 4.6919e-08, 9.5528e-07, 1.2016e-06,
        2.7713e-06, 9.7427e-06, 2.2073e-03, 2.6336e-02, 9.0956e-01, 6.1885e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,869][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0679, 0.0428, 0.0878, 0.2052, 0.0634, 0.0322, 0.1220, 0.0442, 0.1133,
        0.0500, 0.1234, 0.0478], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,870][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3224, 0.0231, 0.0278, 0.0367, 0.0371, 0.0241, 0.0423, 0.0829, 0.0577,
        0.1649, 0.0799, 0.1011], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,872][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2092, 0.1652, 0.0251, 0.0887, 0.0657, 0.1000, 0.0608, 0.0924, 0.0625,
        0.0730, 0.0307, 0.0266], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,874][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2000, 0.1312, 0.0557, 0.0744, 0.0952, 0.1110, 0.0564, 0.1137, 0.0433,
        0.0325, 0.0617, 0.0248], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,876][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0173, 0.0789, 0.0755, 0.0514, 0.0514, 0.0807, 0.1198, 0.1116, 0.0502,
        0.1957, 0.0630, 0.1046], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,877][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4704, 0.0174, 0.0082, 0.0056, 0.0112, 0.0207, 0.0152, 0.0702, 0.0393,
        0.1617, 0.1267, 0.0534], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,879][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0207, 0.0776, 0.0560, 0.1391, 0.0563, 0.0848, 0.0554, 0.0588, 0.1650,
        0.0510, 0.1535, 0.0819], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,881][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0102, 0.0154, 0.0169, 0.0238, 0.0397, 0.0253, 0.0341, 0.0674, 0.0680,
        0.1249, 0.2418, 0.3324], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,883][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0805, 0.0414, 0.0457, 0.0821, 0.0554, 0.0828, 0.0421, 0.0803, 0.1327,
        0.0600, 0.2580, 0.0389], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:53,884][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0348, 0.0670, 0.0634, 0.0639, 0.1156, 0.0359, 0.0430, 0.1057, 0.0868,
        0.1153, 0.1254, 0.0573, 0.0860], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,884][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.3190, 0.0360, 0.0045, 0.0081, 0.0033, 0.0023, 0.0081, 0.0313, 0.0280,
        0.0744, 0.0691, 0.2544, 0.1614], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,885][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ station] are: tensor([1.3504e-12, 3.8399e-11, 5.4208e-10, 1.8532e-08, 4.3968e-07, 3.7065e-07,
        2.0646e-06, 7.0707e-06, 3.3732e-04, 3.5753e-02, 2.8513e-01, 1.7872e-01,
        5.0005e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,886][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0276, 0.0302, 0.1323, 0.1254, 0.0977, 0.0335, 0.1121, 0.0381, 0.1281,
        0.0934, 0.0663, 0.1057, 0.0098], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,887][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.2104, 0.0218, 0.0242, 0.0363, 0.0312, 0.0256, 0.0449, 0.0769, 0.0529,
        0.1456, 0.0736, 0.0983, 0.1583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,889][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0483, 0.1286, 0.0334, 0.0988, 0.0537, 0.0913, 0.1239, 0.0661, 0.0832,
        0.0987, 0.0524, 0.1189, 0.0027], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,891][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1252, 0.0983, 0.0856, 0.0529, 0.1310, 0.0830, 0.0952, 0.1508, 0.0276,
        0.0475, 0.0432, 0.0446, 0.0153], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,893][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0132, 0.1105, 0.0722, 0.0528, 0.0512, 0.0908, 0.0966, 0.0904, 0.0342,
        0.1457, 0.0460, 0.0846, 0.1117], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,894][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.3042, 0.0179, 0.0086, 0.0056, 0.0109, 0.0175, 0.0132, 0.0601, 0.0338,
        0.1298, 0.0987, 0.0476, 0.2520], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,896][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0093, 0.0456, 0.0681, 0.1135, 0.0503, 0.0692, 0.1272, 0.0418, 0.1050,
        0.0473, 0.1160, 0.1919, 0.0148], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,898][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0133, 0.0083, 0.0082, 0.0135, 0.0207, 0.0139, 0.0219, 0.0471, 0.0475,
        0.0902, 0.1804, 0.2548, 0.2802], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,900][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0693, 0.0277, 0.1002, 0.0480, 0.1469, 0.0514, 0.0366, 0.1384, 0.0572,
        0.1275, 0.0816, 0.0507, 0.0646], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:53,901][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0342, 0.0549, 0.0620, 0.0580, 0.0951, 0.0333, 0.0522, 0.1026, 0.0761,
        0.0946, 0.1114, 0.0586, 0.0843, 0.0828], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,902][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1894, 0.0400, 0.0053, 0.0105, 0.0039, 0.0039, 0.0105, 0.0366, 0.0350,
        0.0757, 0.0739, 0.2233, 0.1534, 0.1385], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,903][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([2.3565e-12, 1.3553e-11, 1.4432e-09, 9.0701e-09, 3.5351e-07, 2.5285e-07,
        2.6878e-06, 3.6895e-06, 8.7273e-05, 5.8608e-03, 1.4720e-02, 4.6068e-02,
        5.9646e-01, 3.3680e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,903][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0528, 0.0388, 0.0816, 0.1764, 0.0466, 0.0677, 0.0853, 0.0256, 0.1202,
        0.0344, 0.0805, 0.0813, 0.0426, 0.0662], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,904][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2440, 0.0179, 0.0221, 0.0276, 0.0282, 0.0187, 0.0324, 0.0645, 0.0430,
        0.1259, 0.0606, 0.0778, 0.1357, 0.1016], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,906][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.2366, 0.1060, 0.0135, 0.0579, 0.0556, 0.0709, 0.0657, 0.0772, 0.0797,
        0.0368, 0.0464, 0.0646, 0.0298, 0.0592], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,908][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0534, 0.0631, 0.0884, 0.0773, 0.1138, 0.0447, 0.1374, 0.0572, 0.0572,
        0.0376, 0.0643, 0.0611, 0.0204, 0.1240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,910][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0129, 0.0840, 0.0880, 0.0500, 0.0511, 0.0706, 0.1081, 0.0852, 0.0348,
        0.1764, 0.0434, 0.0675, 0.0971, 0.0306], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,912][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3524, 0.0153, 0.0079, 0.0053, 0.0100, 0.0174, 0.0126, 0.0526, 0.0300,
        0.1125, 0.0898, 0.0393, 0.2068, 0.0481], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,914][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0152, 0.0463, 0.0441, 0.1225, 0.0356, 0.0562, 0.0694, 0.0473, 0.1285,
        0.0251, 0.1155, 0.1339, 0.0449, 0.1155], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,916][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0253, 0.0072, 0.0072, 0.0098, 0.0162, 0.0113, 0.0164, 0.0396, 0.0383,
        0.0681, 0.1357, 0.1951, 0.2240, 0.2058], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,918][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0851, 0.0250, 0.0501, 0.0693, 0.0429, 0.0470, 0.0515, 0.0554, 0.1940,
        0.0550, 0.2028, 0.0501, 0.0421, 0.0297], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:53,919][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0292, 0.0526, 0.0367, 0.0542, 0.1056, 0.0306, 0.0472, 0.0979, 0.0723,
        0.0755, 0.1120, 0.0605, 0.0705, 0.0970, 0.0581], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,919][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.1169, 0.0321, 0.0035, 0.0064, 0.0021, 0.0018, 0.0055, 0.0226, 0.0210,
        0.0660, 0.0662, 0.2056, 0.1237, 0.1091, 0.2174], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,920][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([9.5740e-14, 1.5221e-12, 9.0329e-12, 1.8693e-10, 8.7165e-09, 2.8500e-09,
        3.2730e-08, 4.7566e-08, 2.9522e-06, 5.7285e-05, 3.8528e-04, 1.1198e-03,
        8.2297e-03, 2.2175e-02, 9.6803e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,921][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0324, 0.0226, 0.0362, 0.0927, 0.0553, 0.0338, 0.1376, 0.0295, 0.1152,
        0.0407, 0.0903, 0.1302, 0.0446, 0.0767, 0.0623], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,922][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2060, 0.0171, 0.0181, 0.0277, 0.0237, 0.0202, 0.0344, 0.0612, 0.0429,
        0.1145, 0.0553, 0.0758, 0.1246, 0.1065, 0.0720], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,924][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0324, 0.1211, 0.0064, 0.0755, 0.0500, 0.0855, 0.0837, 0.0799, 0.0811,
        0.0975, 0.0337, 0.0796, 0.0166, 0.1521, 0.0048], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,926][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.2244, 0.2021, 0.0456, 0.0753, 0.0686, 0.0791, 0.0469, 0.0278, 0.0387,
        0.0179, 0.0686, 0.0244, 0.0057, 0.0542, 0.0207], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,928][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0120, 0.1049, 0.0567, 0.0525, 0.0413, 0.0863, 0.1014, 0.0797, 0.0371,
        0.1294, 0.0421, 0.0752, 0.0951, 0.0385, 0.0481], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,929][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.2715, 0.0115, 0.0054, 0.0035, 0.0068, 0.0118, 0.0079, 0.0414, 0.0212,
        0.0846, 0.0623, 0.0255, 0.1656, 0.0346, 0.2463], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,931][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0062, 0.0391, 0.0066, 0.1097, 0.0289, 0.0709, 0.0853, 0.0371, 0.1138,
        0.0374, 0.0896, 0.1216, 0.0437, 0.1957, 0.0144], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,933][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0061, 0.0077, 0.0074, 0.0113, 0.0161, 0.0115, 0.0155, 0.0231, 0.0298,
        0.0456, 0.1028, 0.1415, 0.1486, 0.1476, 0.2854], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,935][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0969, 0.0368, 0.0619, 0.0768, 0.0690, 0.0609, 0.0446, 0.0876, 0.0561,
        0.0879, 0.0813, 0.0494, 0.0906, 0.0319, 0.0683], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:53,935][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0288, 0.0559, 0.0536, 0.0552, 0.0657, 0.0323, 0.0400, 0.0869, 0.0732,
        0.0877, 0.0990, 0.0513, 0.0752, 0.0882, 0.0784, 0.0286],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,936][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0681, 0.0405, 0.0059, 0.0117, 0.0037, 0.0042, 0.0091, 0.0298, 0.0266,
        0.0652, 0.0634, 0.1672, 0.0938, 0.1071, 0.1340, 0.1698],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,937][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([2.8699e-14, 2.1630e-13, 4.0091e-12, 6.6090e-11, 5.4909e-10, 4.8484e-10,
        3.5960e-09, 4.9611e-09, 3.3983e-07, 8.0498e-06, 5.3310e-05, 1.5029e-04,
        9.7187e-04, 1.1042e-02, 7.4176e-01, 2.4602e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,938][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0276, 0.0142, 0.0812, 0.0693, 0.0228, 0.0118, 0.0522, 0.0444, 0.1132,
        0.0464, 0.0573, 0.0818, 0.0475, 0.1288, 0.1973, 0.0043],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,939][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1738, 0.0156, 0.0197, 0.0251, 0.0247, 0.0187, 0.0317, 0.0563, 0.0407,
        0.1161, 0.0555, 0.0736, 0.1170, 0.0970, 0.0771, 0.0574],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,941][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0474, 0.1217, 0.0388, 0.0773, 0.0330, 0.0229, 0.0765, 0.0363, 0.0629,
        0.0579, 0.0411, 0.1505, 0.0307, 0.1671, 0.0323, 0.0038],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,943][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.2131, 0.1197, 0.0978, 0.0507, 0.0846, 0.0670, 0.0550, 0.0753, 0.0144,
        0.0264, 0.0348, 0.0309, 0.0197, 0.0394, 0.0473, 0.0240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,945][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0099, 0.0845, 0.0533, 0.0411, 0.0407, 0.0693, 0.1013, 0.0683, 0.0320,
        0.1298, 0.0441, 0.0932, 0.1044, 0.0350, 0.0510, 0.0420],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,947][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.2188, 0.0123, 0.0068, 0.0043, 0.0079, 0.0131, 0.0097, 0.0367, 0.0221,
        0.0741, 0.0582, 0.0285, 0.1305, 0.0341, 0.1862, 0.1567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,949][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0039, 0.0254, 0.0387, 0.0763, 0.0205, 0.0284, 0.0740, 0.0166, 0.0942,
        0.0111, 0.1479, 0.1214, 0.0270, 0.1987, 0.1077, 0.0082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,951][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0027, 0.0061, 0.0047, 0.0090, 0.0117, 0.0080, 0.0120, 0.0148, 0.0259,
        0.0336, 0.0892, 0.1072, 0.0931, 0.1284, 0.1907, 0.2629],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,952][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0527, 0.0341, 0.0538, 0.0416, 0.0971, 0.0338, 0.0424, 0.0865, 0.0559,
        0.0874, 0.1010, 0.0740, 0.0788, 0.0292, 0.0718, 0.0600],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:53,953][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0248, 0.0433, 0.0510, 0.0567, 0.0701, 0.0253, 0.0324, 0.0949, 0.0745,
        0.0749, 0.0977, 0.0456, 0.0725, 0.0836, 0.0809, 0.0341, 0.0377],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,954][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0633, 0.0190, 0.0028, 0.0040, 0.0016, 0.0012, 0.0033, 0.0142, 0.0118,
        0.0402, 0.0384, 0.1202, 0.0731, 0.0640, 0.1467, 0.1161, 0.2801],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,955][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.0394e-14, 3.5608e-14, 5.5151e-13, 1.1840e-11, 9.3055e-11, 1.9331e-10,
        6.8321e-11, 1.8988e-09, 1.9995e-07, 2.8677e-06, 5.0573e-05, 2.7189e-05,
        3.2083e-04, 5.0146e-04, 5.9671e-02, 4.8544e-01, 4.5398e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,956][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0296, 0.0217, 0.0598, 0.1194, 0.0493, 0.0122, 0.0149, 0.0192, 0.0872,
        0.0460, 0.0680, 0.0860, 0.0572, 0.1142, 0.1534, 0.0273, 0.0345],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,958][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2062, 0.0146, 0.0185, 0.0226, 0.0239, 0.0159, 0.0258, 0.0537, 0.0351,
        0.1089, 0.0484, 0.0626, 0.1100, 0.0851, 0.0666, 0.0491, 0.0531],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,960][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1269, 0.1350, 0.0527, 0.0540, 0.0787, 0.0713, 0.0124, 0.0322, 0.0538,
        0.0379, 0.0204, 0.0657, 0.0332, 0.1504, 0.0423, 0.0233, 0.0098],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,962][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1840, 0.1455, 0.0456, 0.0614, 0.0689, 0.0675, 0.0509, 0.0880, 0.0239,
        0.0256, 0.0477, 0.0299, 0.0156, 0.0428, 0.0211, 0.0465, 0.0352],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,964][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0108, 0.0681, 0.0593, 0.0330, 0.0412, 0.0535, 0.0783, 0.0787, 0.0290,
        0.1455, 0.0361, 0.0693, 0.0932, 0.0275, 0.0525, 0.0374, 0.0868],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,966][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2992, 0.0115, 0.0060, 0.0038, 0.0066, 0.0122, 0.0082, 0.0334, 0.0190,
        0.0636, 0.0510, 0.0212, 0.1084, 0.0263, 0.1486, 0.1305, 0.0504],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,968][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0092, 0.0403, 0.0324, 0.0885, 0.0238, 0.0423, 0.0297, 0.0333, 0.0947,
        0.0222, 0.0921, 0.0672, 0.0516, 0.1736, 0.0810, 0.0440, 0.0742],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,969][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0036, 0.0051, 0.0046, 0.0067, 0.0099, 0.0064, 0.0093, 0.0149, 0.0197,
        0.0297, 0.0613, 0.0815, 0.0779, 0.0724, 0.1395, 0.1929, 0.2648],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,970][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0482, 0.0236, 0.0460, 0.0397, 0.0666, 0.0478, 0.0267, 0.1117, 0.0732,
        0.0651, 0.1420, 0.0380, 0.0493, 0.0247, 0.0681, 0.0973, 0.0320],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:53,971][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0252, 0.0426, 0.0404, 0.0435, 0.0749, 0.0253, 0.0305, 0.0696, 0.0604,
        0.0864, 0.0762, 0.0435, 0.0750, 0.0771, 0.0659, 0.0382, 0.0373, 0.0881],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,972][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0414, 0.0223, 0.0030, 0.0046, 0.0016, 0.0015, 0.0037, 0.0128, 0.0107,
        0.0343, 0.0337, 0.0804, 0.0473, 0.0528, 0.0729, 0.0851, 0.1632, 0.3285],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,973][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([1.6520e-15, 1.2339e-14, 9.6507e-14, 3.0391e-12, 4.4164e-11, 3.2248e-11,
        1.5836e-10, 3.8163e-10, 1.4525e-08, 3.1239e-07, 2.6817e-06, 6.4511e-06,
        1.7285e-05, 2.4788e-04, 7.9644e-03, 1.1716e-01, 6.8238e-01, 1.9222e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,975][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0151, 0.0153, 0.0513, 0.0499, 0.0181, 0.0324, 0.0850, 0.0136, 0.0862,
        0.0430, 0.0592, 0.0994, 0.0327, 0.0458, 0.0966, 0.0333, 0.1941, 0.0292],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,976][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.1303, 0.0164, 0.0167, 0.0251, 0.0208, 0.0189, 0.0306, 0.0528, 0.0374,
        0.0987, 0.0487, 0.0662, 0.1043, 0.0916, 0.0607, 0.0474, 0.0608, 0.0726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,978][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.0671, 0.0918, 0.0509, 0.0462, 0.0261, 0.0258, 0.0730, 0.0477, 0.0769,
        0.0311, 0.0222, 0.1146, 0.0175, 0.1574, 0.0499, 0.0167, 0.0821, 0.0030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,980][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0942, 0.0724, 0.0634, 0.0730, 0.0598, 0.0774, 0.1229, 0.0444, 0.0219,
        0.0226, 0.0429, 0.0645, 0.0119, 0.0367, 0.0398, 0.0272, 0.1023, 0.0228],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,982][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0084, 0.0837, 0.0576, 0.0404, 0.0350, 0.0659, 0.0783, 0.0678, 0.0245,
        0.0964, 0.0327, 0.0545, 0.0826, 0.0274, 0.0407, 0.0318, 0.0785, 0.0938],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,984][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.2137, 0.0123, 0.0066, 0.0040, 0.0069, 0.0108, 0.0073, 0.0291, 0.0167,
        0.0519, 0.0405, 0.0181, 0.0872, 0.0231, 0.1242, 0.1040, 0.0447, 0.1988],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,986][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0092, 0.0282, 0.0308, 0.0610, 0.0244, 0.0401, 0.0570, 0.0292, 0.0773,
        0.0341, 0.0587, 0.0857, 0.0391, 0.1109, 0.0738, 0.0560, 0.1643, 0.0203],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,987][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0030, 0.0032, 0.0023, 0.0048, 0.0058, 0.0040, 0.0066, 0.0099, 0.0151,
        0.0204, 0.0449, 0.0555, 0.0513, 0.0842, 0.0969, 0.1331, 0.2289, 0.2302],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,988][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0431, 0.0215, 0.0630, 0.0298, 0.0990, 0.0457, 0.0355, 0.0932, 0.0379,
        0.1139, 0.0526, 0.0480, 0.0667, 0.0221, 0.0779, 0.0665, 0.0378, 0.0459],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:53,989][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0246, 0.0400, 0.0373, 0.0448, 0.0635, 0.0241, 0.0311, 0.0755, 0.0544,
        0.0658, 0.0825, 0.0341, 0.0611, 0.0643, 0.0575, 0.0303, 0.0371, 0.1127,
        0.0592], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,990][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0277, 0.0131, 0.0020, 0.0027, 0.0010, 0.0008, 0.0021, 0.0078, 0.0070,
        0.0238, 0.0230, 0.0614, 0.0356, 0.0354, 0.0649, 0.0560, 0.1196, 0.2537,
        0.2623], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,991][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.2748e-15, 3.8448e-16, 4.2376e-15, 6.5380e-14, 9.2885e-13, 2.4449e-12,
        6.3430e-12, 1.7729e-11, 6.0205e-10, 7.2173e-08, 7.6970e-08, 2.9394e-07,
        1.8936e-06, 2.7239e-06, 3.2026e-04, 5.0161e-03, 3.9402e-02, 1.6077e-01,
        7.9449e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,993][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0181, 0.0125, 0.0291, 0.0770, 0.0168, 0.0128, 0.0695, 0.0223, 0.0980,
        0.0167, 0.0407, 0.0675, 0.0275, 0.0917, 0.0663, 0.0381, 0.1587, 0.1024,
        0.0342], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,995][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1574, 0.0155, 0.0188, 0.0224, 0.0214, 0.0157, 0.0252, 0.0479, 0.0318,
        0.0950, 0.0444, 0.0580, 0.0957, 0.0782, 0.0601, 0.0427, 0.0493, 0.0663,
        0.0543], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,997][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1405, 0.0909, 0.0326, 0.0490, 0.0778, 0.0581, 0.0409, 0.0676, 0.0730,
        0.0312, 0.0261, 0.0703, 0.0260, 0.0627, 0.0303, 0.0450, 0.0436, 0.0229,
        0.0114], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:53,999][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1903, 0.0910, 0.0382, 0.0774, 0.0391, 0.0552, 0.0936, 0.0464, 0.0246,
        0.0195, 0.0537, 0.0502, 0.0051, 0.0451, 0.0241, 0.0332, 0.0827, 0.0137,
        0.0167], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,001][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0090, 0.0468, 0.0443, 0.0256, 0.0327, 0.0562, 0.0651, 0.0643, 0.0219,
        0.1105, 0.0309, 0.0541, 0.0809, 0.0227, 0.0426, 0.0357, 0.0733, 0.1141,
        0.0694], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,003][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2566, 0.0116, 0.0063, 0.0041, 0.0065, 0.0121, 0.0081, 0.0289, 0.0172,
        0.0491, 0.0411, 0.0179, 0.0756, 0.0211, 0.0955, 0.0928, 0.0413, 0.1702,
        0.0439], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,004][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0049, 0.0252, 0.0236, 0.0577, 0.0199, 0.0279, 0.0602, 0.0239, 0.0584,
        0.0171, 0.0389, 0.0961, 0.0272, 0.1007, 0.0579, 0.0297, 0.1593, 0.0589,
        0.1124], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,005][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0020, 0.0022, 0.0017, 0.0031, 0.0042, 0.0029, 0.0040, 0.0055, 0.0095,
        0.0124, 0.0287, 0.0398, 0.0343, 0.0466, 0.0605, 0.0958, 0.1312, 0.1451,
        0.3707], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,006][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0507, 0.0258, 0.0382, 0.0392, 0.0446, 0.0479, 0.0305, 0.0761, 0.0991,
        0.0437, 0.1550, 0.0449, 0.0240, 0.0260, 0.0574, 0.0664, 0.0380, 0.0339,
        0.0585], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,043][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:54,045][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,046][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,047][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,048][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,050][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,052][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,053][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,054][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,055][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,056][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,056][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,057][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,058][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4080, 0.5920], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,058][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2042, 0.7958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,060][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0751, 0.9249], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,061][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0953, 0.9047], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,063][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6209, 0.3791], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,065][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2371, 0.7629], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,066][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5963, 0.4037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,068][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2259, 0.7741], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,070][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4698, 0.5302], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,071][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0066, 0.9934], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,072][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2373, 0.7627], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,073][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3542, 0.6458], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,074][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.2327, 0.4067, 0.3607], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,074][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.1847, 0.3455, 0.4698], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,075][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([7.1616e-04, 9.6702e-02, 9.0258e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,076][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0884, 0.1692, 0.7425], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,078][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2785, 0.5908, 0.1306], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,080][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.1256, 0.4150, 0.4595], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,082][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.3777, 0.2794, 0.3429], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,083][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.1668, 0.5915, 0.2417], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,085][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.2694, 0.5422, 0.1884], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,087][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0042, 0.9649, 0.0309], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,088][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0813, 0.3326, 0.5862], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,089][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.2978, 0.5425, 0.1597], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,090][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1565, 0.2715, 0.3343, 0.2376], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,091][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1060, 0.3549, 0.4063, 0.1328], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,091][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([7.5945e-05, 4.2991e-03, 8.3782e-01, 1.5780e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,092][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0245, 0.0637, 0.6641, 0.2477], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,093][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0950, 0.5136, 0.2379, 0.1534], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,095][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0851, 0.2355, 0.4140, 0.2655], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,097][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3305, 0.2198, 0.2712, 0.1786], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,098][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1099, 0.3596, 0.1477, 0.3829], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,100][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1680, 0.3267, 0.2268, 0.2784], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,102][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0043, 0.9317, 0.0398, 0.0243], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,104][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0727, 0.2353, 0.4473, 0.2447], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,105][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1425, 0.2856, 0.0632, 0.5086], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,107][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.1142, 0.1735, 0.3323, 0.2206, 0.1593], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,107][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.1533, 0.3036, 0.3106, 0.1114, 0.1211], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,108][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([1.3091e-05, 1.8135e-05, 4.6059e-03, 6.4915e-03, 9.8887e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,109][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0107, 0.0540, 0.4375, 0.4426, 0.0551], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,109][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.0750, 0.2911, 0.2047, 0.3532, 0.0761], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,110][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.0095, 0.0623, 0.1355, 0.1069, 0.6859], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,112][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.2328, 0.1787, 0.2243, 0.1597, 0.2045], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,114][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.1063, 0.3135, 0.1572, 0.3266, 0.0963], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,116][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.1485, 0.2517, 0.1465, 0.3343, 0.1189], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,117][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.0177, 0.7026, 0.0346, 0.0299, 0.2152], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,119][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.0373, 0.1587, 0.2773, 0.1518, 0.3748], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,121][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.2223, 0.2587, 0.0918, 0.3591, 0.0681], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,123][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0819, 0.1589, 0.2158, 0.1609, 0.3163, 0.0663], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,124][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1552, 0.2068, 0.3014, 0.1009, 0.1177, 0.1180], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,125][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.3822e-07, 1.0737e-06, 2.1963e-04, 3.5131e-04, 9.9572e-01, 3.7115e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,125][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0057, 0.0368, 0.4042, 0.2843, 0.0183, 0.2508], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,126][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1820, 0.1937, 0.1064, 0.3978, 0.0330, 0.0872], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,127][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0102, 0.0303, 0.0777, 0.0408, 0.8002, 0.0407], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,128][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2462, 0.1549, 0.1881, 0.1213, 0.1610, 0.1284], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,130][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0915, 0.2313, 0.1100, 0.2556, 0.0719, 0.2398], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,131][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0843, 0.2254, 0.1146, 0.1704, 0.1811, 0.2242], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,133][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0064, 0.5058, 0.0218, 0.0218, 0.1127, 0.3315], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,135][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0357, 0.1269, 0.2334, 0.1185, 0.3198, 0.1658], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,137][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1588, 0.2762, 0.0775, 0.3367, 0.0634, 0.0874], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,138][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0759, 0.1307, 0.1898, 0.1830, 0.2334, 0.0816, 0.1055],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,140][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1120, 0.2511, 0.2794, 0.0992, 0.0883, 0.0990, 0.0710],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,141][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.4704e-06, 1.3657e-06, 2.8323e-04, 1.0701e-03, 5.6476e-01, 3.9173e-01,
        4.2153e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,142][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0030, 0.0225, 0.3384, 0.2379, 0.0112, 0.3378, 0.0491],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,143][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1494, 0.1839, 0.0925, 0.3073, 0.0221, 0.1675, 0.0773],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,144][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0085, 0.0268, 0.0747, 0.0363, 0.7668, 0.0470, 0.0399],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,144][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2200, 0.1384, 0.1698, 0.1075, 0.1434, 0.1152, 0.1056],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,145][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1076, 0.1362, 0.0754, 0.1619, 0.0606, 0.1631, 0.2953],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,147][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0545, 0.1132, 0.0961, 0.1518, 0.1426, 0.3874, 0.0545],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,149][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0075, 0.4507, 0.0121, 0.0139, 0.0907, 0.2945, 0.1305],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,151][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0331, 0.1059, 0.1969, 0.1092, 0.2782, 0.1469, 0.1299],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,152][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1285, 0.2018, 0.0465, 0.4098, 0.0412, 0.0953, 0.0769],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,154][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0672, 0.1108, 0.1314, 0.1500, 0.1832, 0.0759, 0.0873, 0.1943],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,156][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.1156, 0.2324, 0.2238, 0.0832, 0.0619, 0.0684, 0.0850, 0.1297],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,157][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([2.7426e-06, 8.5234e-07, 5.0586e-04, 2.5564e-04, 6.5025e-01, 4.0634e-02,
        2.8376e-01, 2.4599e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,158][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0009, 0.0085, 0.1992, 0.1981, 0.0047, 0.4803, 0.0954, 0.0128],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,159][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0668, 0.1410, 0.0652, 0.1799, 0.0305, 0.1383, 0.2057, 0.1726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,160][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0106, 0.0365, 0.0603, 0.0524, 0.4584, 0.1184, 0.0930, 0.1705],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,161][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1789, 0.1272, 0.1539, 0.1024, 0.1325, 0.1091, 0.0985, 0.0975],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,162][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0987, 0.1139, 0.0752, 0.1389, 0.0629, 0.1323, 0.1904, 0.1878],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,163][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0419, 0.1195, 0.0657, 0.1173, 0.0876, 0.4273, 0.0620, 0.0787],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,165][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0224, 0.2064, 0.0089, 0.0099, 0.0794, 0.1776, 0.0871, 0.4084],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,166][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0207, 0.0851, 0.1515, 0.0829, 0.2115, 0.1188, 0.0986, 0.2310],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,168][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1547, 0.2016, 0.0603, 0.2886, 0.0625, 0.0858, 0.0719, 0.0747],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,169][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0631, 0.1024, 0.1185, 0.1011, 0.1801, 0.0502, 0.0781, 0.1951, 0.1114],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,171][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0872, 0.2814, 0.2417, 0.0773, 0.0552, 0.0822, 0.0610, 0.0731, 0.0409],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,172][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.2490e-06, 2.1716e-08, 2.3906e-05, 1.8496e-05, 1.7319e-01, 7.3253e-03,
        4.6703e-02, 6.6003e-01, 1.1270e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,174][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0008, 0.0113, 0.3986, 0.4232, 0.0020, 0.1212, 0.0341, 0.0031, 0.0057],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,176][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0076, 0.0283, 0.0657, 0.0432, 0.0217, 0.0115, 0.0303, 0.7823, 0.0094],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,177][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0074, 0.0275, 0.0640, 0.0419, 0.4986, 0.0452, 0.0413, 0.1238, 0.1503],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,177][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1793, 0.1135, 0.1391, 0.0878, 0.1180, 0.0931, 0.0867, 0.0821, 0.1003],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,178][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0823, 0.0953, 0.0563, 0.1094, 0.0474, 0.1091, 0.1779, 0.1652, 0.1571],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,179][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0324, 0.0735, 0.0957, 0.1039, 0.1670, 0.3205, 0.0589, 0.0917, 0.0564],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,180][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0141, 0.3129, 0.0066, 0.0056, 0.0618, 0.1413, 0.0584, 0.3674, 0.0319],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,182][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0235, 0.0774, 0.1416, 0.0781, 0.2007, 0.1069, 0.0939, 0.1845, 0.0933],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,184][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1229, 0.1581, 0.0388, 0.3070, 0.0354, 0.0760, 0.0619, 0.0466, 0.1532],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,185][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0519, 0.0922, 0.1122, 0.1005, 0.1162, 0.0589, 0.0632, 0.1519, 0.1395,
        0.1136], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,186][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1082, 0.1845, 0.1336, 0.0390, 0.0229, 0.0224, 0.0457, 0.0759, 0.0606,
        0.3072], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,188][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([1.8732e-08, 3.7831e-10, 2.0127e-07, 1.8587e-07, 3.3623e-03, 1.0429e-03,
        2.4086e-03, 3.3621e-03, 1.9303e-01, 7.9679e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,190][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0010, 0.0167, 0.2533, 0.4151, 0.0029, 0.2347, 0.0570, 0.0038, 0.0124,
        0.0031], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,192][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0184, 0.0676, 0.0206, 0.0549, 0.0304, 0.2863, 0.0848, 0.3867, 0.0366,
        0.0138], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,193][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0041, 0.0151, 0.0459, 0.0240, 0.4103, 0.0240, 0.0260, 0.1380, 0.1493,
        0.1634], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,194][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1294, 0.1021, 0.1183, 0.0874, 0.1063, 0.0963, 0.0833, 0.0855, 0.0974,
        0.0941], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,195][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0811, 0.1049, 0.0665, 0.1135, 0.0550, 0.1040, 0.1389, 0.1201, 0.1182,
        0.0976], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,195][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0311, 0.0580, 0.0320, 0.0664, 0.0560, 0.4200, 0.0503, 0.1245, 0.1174,
        0.0442], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,196][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0186, 0.1803, 0.0054, 0.0059, 0.0658, 0.1349, 0.0575, 0.3691, 0.0386,
        0.1240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,198][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0175, 0.0660, 0.1185, 0.0624, 0.1696, 0.0931, 0.0743, 0.1836, 0.0725,
        0.1425], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,199][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1422, 0.1665, 0.0566, 0.2357, 0.0513, 0.0708, 0.0568, 0.0604, 0.1181,
        0.0418], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,201][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0412, 0.0802, 0.1059, 0.0822, 0.1368, 0.0466, 0.0622, 0.1319, 0.1002,
        0.1083, 0.1044], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,203][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1489, 0.1838, 0.1266, 0.0364, 0.0216, 0.0204, 0.0326, 0.0503, 0.0355,
        0.1663, 0.1776], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,204][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([5.1132e-08, 8.9619e-11, 3.2985e-08, 4.4498e-08, 1.3006e-04, 1.8266e-05,
        1.5001e-04, 4.8682e-05, 1.1076e-02, 6.6387e-01, 3.2471e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,206][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0008, 0.0084, 0.2013, 0.2149, 0.0044, 0.4438, 0.0948, 0.0109, 0.0117,
        0.0065, 0.0025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,208][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0388, 0.1610, 0.0536, 0.1901, 0.0262, 0.0415, 0.1028, 0.2197, 0.1016,
        0.0348, 0.0300], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,210][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0028, 0.0113, 0.0364, 0.0193, 0.3168, 0.0225, 0.0233, 0.1024, 0.1225,
        0.1764, 0.1661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,211][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1483, 0.0972, 0.1179, 0.0744, 0.0997, 0.0792, 0.0726, 0.0710, 0.0837,
        0.0773, 0.0787], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,211][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0807, 0.0770, 0.0512, 0.0890, 0.0471, 0.0902, 0.1319, 0.1209, 0.1198,
        0.1022, 0.0898], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,212][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0224, 0.0480, 0.0327, 0.0602, 0.1015, 0.3138, 0.0762, 0.1274, 0.1034,
        0.0509, 0.0635], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,213][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0186, 0.1484, 0.0062, 0.0074, 0.0492, 0.1084, 0.0604, 0.2800, 0.0383,
        0.1120, 0.1711], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,214][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0182, 0.0576, 0.1092, 0.0589, 0.1591, 0.0847, 0.0726, 0.1603, 0.0696,
        0.1288, 0.0811], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,216][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1183, 0.1177, 0.0423, 0.2324, 0.0344, 0.0570, 0.0546, 0.0460, 0.1292,
        0.0347, 0.1334], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,218][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0358, 0.0628, 0.0831, 0.0776, 0.1187, 0.0400, 0.0504, 0.1298, 0.1013,
        0.1069, 0.1389, 0.0547], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,220][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0322, 0.0527, 0.0369, 0.0110, 0.0061, 0.0053, 0.0110, 0.0261, 0.0173,
        0.1267, 0.1499, 0.5247], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,221][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([7.5596e-10, 8.9090e-13, 6.6805e-10, 6.9926e-10, 2.4080e-06, 3.7170e-07,
        5.1713e-07, 1.8248e-06, 3.6579e-04, 2.3761e-02, 9.5604e-01, 1.9828e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,223][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0023, 0.0167, 0.3110, 0.3134, 0.0091, 0.2628, 0.0492, 0.0097, 0.0116,
        0.0055, 0.0031, 0.0057], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,225][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0888, 0.1272, 0.0736, 0.1718, 0.0312, 0.0633, 0.0947, 0.1231, 0.0516,
        0.0452, 0.0655, 0.0642], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,226][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0016, 0.0090, 0.0370, 0.0196, 0.2912, 0.0177, 0.0184, 0.1186, 0.1116,
        0.1374, 0.1556, 0.0824], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,228][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1286, 0.0872, 0.1076, 0.0696, 0.0926, 0.0738, 0.0683, 0.0669, 0.0804,
        0.0739, 0.0755, 0.0756], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,228][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0772, 0.0722, 0.0479, 0.0834, 0.0447, 0.0810, 0.1205, 0.1097, 0.1069,
        0.0914, 0.0780, 0.0871], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,229][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0216, 0.0525, 0.0345, 0.0823, 0.0535, 0.2006, 0.0450, 0.0924, 0.1117,
        0.0821, 0.1988, 0.0251], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,230][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0210, 0.1716, 0.0041, 0.0049, 0.0410, 0.0931, 0.0433, 0.2713, 0.0288,
        0.0874, 0.1707, 0.0628], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,231][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0169, 0.0563, 0.1012, 0.0577, 0.1423, 0.0800, 0.0686, 0.1443, 0.0660,
        0.1179, 0.0746, 0.0743], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,232][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1155, 0.1211, 0.0281, 0.2470, 0.0200, 0.0546, 0.0407, 0.0294, 0.1206,
        0.0246, 0.1275, 0.0710], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,234][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0331, 0.0613, 0.0697, 0.0631, 0.1153, 0.0363, 0.0433, 0.1072, 0.0869,
        0.1123, 0.1231, 0.0559, 0.0925], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,236][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0452, 0.0760, 0.0520, 0.0169, 0.0099, 0.0092, 0.0152, 0.0289, 0.0236,
        0.1233, 0.1270, 0.3390, 0.1337], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,237][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([1.5844e-09, 1.3606e-12, 3.4939e-10, 5.7504e-10, 2.2695e-06, 2.7025e-07,
        1.1932e-06, 3.4840e-06, 8.6036e-05, 8.3323e-02, 4.1154e-01, 2.5016e-01,
        2.5488e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,238][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0012, 0.0156, 0.2417, 0.5471, 0.0023, 0.1201, 0.0463, 0.0024, 0.0136,
        0.0022, 0.0008, 0.0053, 0.0012], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,241][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0213, 0.0999, 0.0148, 0.1089, 0.0384, 0.1907, 0.0943, 0.0846, 0.1113,
        0.0234, 0.0533, 0.1448, 0.0143], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,243][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0024, 0.0069, 0.0137, 0.0093, 0.0920, 0.0134, 0.0109, 0.0541, 0.0747,
        0.1026, 0.1394, 0.1271, 0.3536], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,244][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.1082, 0.0804, 0.0967, 0.0674, 0.0854, 0.0716, 0.0638, 0.0654, 0.0743,
        0.0737, 0.0701, 0.0725, 0.0706], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,245][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0693, 0.0884, 0.0646, 0.0965, 0.0537, 0.0861, 0.1058, 0.0854, 0.0880,
        0.0729, 0.0660, 0.0692, 0.0541], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,246][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0201, 0.0448, 0.0223, 0.0537, 0.0308, 0.1485, 0.0443, 0.1156, 0.1428,
        0.0612, 0.2079, 0.0433, 0.0646], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,247][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0324, 0.1018, 0.0028, 0.0033, 0.0366, 0.0649, 0.0315, 0.2282, 0.0246,
        0.0830, 0.1464, 0.0486, 0.1958], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,248][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0112, 0.0479, 0.0877, 0.0451, 0.1230, 0.0685, 0.0540, 0.1397, 0.0514,
        0.1118, 0.0599, 0.0592, 0.1404], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,248][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1401, 0.1223, 0.0562, 0.1676, 0.0420, 0.0466, 0.0394, 0.0440, 0.0760,
        0.0366, 0.0750, 0.0689, 0.0852], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,251][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0320, 0.0505, 0.0692, 0.0585, 0.0975, 0.0329, 0.0521, 0.1036, 0.0762,
        0.0923, 0.1088, 0.0573, 0.0906, 0.0787], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,253][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0409, 0.0821, 0.0870, 0.0384, 0.0339, 0.0315, 0.0297, 0.0422, 0.0249,
        0.0900, 0.1132, 0.2047, 0.0972, 0.0844], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,254][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.1873e-09, 4.6280e-13, 1.1769e-09, 3.0876e-10, 1.6921e-06, 2.1288e-07,
        1.7952e-06, 1.6040e-06, 1.5513e-05, 8.3434e-03, 9.0542e-03, 4.8321e-02,
        3.5333e-01, 5.8094e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,255][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0011, 0.0089, 0.3197, 0.4181, 0.0032, 0.1645, 0.0591, 0.0042, 0.0098,
        0.0022, 0.0009, 0.0055, 0.0014, 0.0012], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,258][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0265, 0.0645, 0.0874, 0.0802, 0.0317, 0.0516, 0.1373, 0.1648, 0.0539,
        0.0276, 0.0450, 0.1432, 0.0590, 0.0272], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,260][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0014, 0.0058, 0.0227, 0.0116, 0.1389, 0.0114, 0.0114, 0.0616, 0.0658,
        0.0650, 0.0928, 0.0615, 0.4004, 0.0497], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,261][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1095, 0.0763, 0.0929, 0.0618, 0.0801, 0.0664, 0.0608, 0.0588, 0.0712,
        0.0644, 0.0670, 0.0667, 0.0614, 0.0626], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,262][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0677, 0.0672, 0.0418, 0.0750, 0.0353, 0.0693, 0.1083, 0.1004, 0.0934,
        0.0787, 0.0670, 0.0762, 0.0566, 0.0632], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,263][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0270, 0.0420, 0.0512, 0.0507, 0.0798, 0.1417, 0.0531, 0.0912, 0.0798,
        0.0731, 0.1595, 0.0458, 0.0790, 0.0261], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,264][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0258, 0.1298, 0.0035, 0.0039, 0.0292, 0.0611, 0.0355, 0.2125, 0.0241,
        0.0662, 0.1303, 0.0537, 0.1767, 0.0477], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,265][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0138, 0.0452, 0.0864, 0.0462, 0.1221, 0.0645, 0.0574, 0.1151, 0.0545,
        0.0946, 0.0598, 0.0617, 0.1285, 0.0500], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,266][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0917, 0.0817, 0.0262, 0.1870, 0.0153, 0.0385, 0.0379, 0.0193, 0.0920,
        0.0197, 0.0910, 0.0675, 0.0688, 0.1634], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,268][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0269, 0.0477, 0.0405, 0.0539, 0.1068, 0.0317, 0.0473, 0.1001, 0.0724,
        0.0750, 0.1091, 0.0584, 0.0761, 0.0908, 0.0635], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,270][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0283, 0.0532, 0.0582, 0.0253, 0.0211, 0.0167, 0.0183, 0.0447, 0.0244,
        0.1125, 0.0892, 0.1684, 0.1304, 0.0523, 0.1571], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,271][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([4.8745e-11, 1.7858e-14, 1.4504e-12, 1.2638e-12, 1.6087e-08, 3.9498e-10,
        5.5408e-09, 4.4013e-09, 1.7857e-07, 1.7137e-05, 7.0031e-05, 3.7259e-04,
        1.2094e-03, 1.3946e-02, 9.8438e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,273][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0014, 0.0107, 0.2390, 0.4246, 0.0069, 0.2139, 0.0626, 0.0064, 0.0150,
        0.0046, 0.0022, 0.0072, 0.0023, 0.0025, 0.0005], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,275][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0344, 0.0775, 0.0124, 0.0850, 0.0314, 0.0525, 0.1271, 0.0426, 0.0675,
        0.0285, 0.0489, 0.1496, 0.1747, 0.0582, 0.0097], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,277][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0038, 0.0064, 0.0055, 0.0062, 0.0303, 0.0054, 0.0052, 0.0180, 0.0209,
        0.0426, 0.0692, 0.0855, 0.3163, 0.1251, 0.2596], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,278][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0864, 0.0669, 0.0831, 0.0579, 0.0743, 0.0613, 0.0555, 0.0579, 0.0646,
        0.0651, 0.0598, 0.0627, 0.0644, 0.0625, 0.0775], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,279][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0733, 0.0770, 0.0630, 0.0854, 0.0534, 0.0768, 0.0885, 0.0765, 0.0737,
        0.0646, 0.0595, 0.0588, 0.0515, 0.0526, 0.0454], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,280][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0238, 0.0469, 0.0188, 0.0537, 0.0404, 0.1499, 0.0607, 0.0776, 0.1228,
        0.0610, 0.1705, 0.0431, 0.0787, 0.0318, 0.0203], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,281][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0681, 0.0717, 0.0009, 0.0015, 0.0197, 0.0339, 0.0170, 0.1862, 0.0157,
        0.0493, 0.1036, 0.0294, 0.1630, 0.0225, 0.2175], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,282][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0098, 0.0423, 0.0751, 0.0417, 0.1025, 0.0588, 0.0467, 0.1125, 0.0457,
        0.0908, 0.0543, 0.0515, 0.1238, 0.0449, 0.0999], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,283][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.1143, 0.0974, 0.0365, 0.1635, 0.0171, 0.0392, 0.0335, 0.0298, 0.0635,
        0.0235, 0.0638, 0.0555, 0.0728, 0.1367, 0.0529], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,285][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0262, 0.0505, 0.0582, 0.0535, 0.0673, 0.0319, 0.0400, 0.0878, 0.0729,
        0.0851, 0.0966, 0.0501, 0.0805, 0.0843, 0.0857, 0.0292],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,287][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0326, 0.0769, 0.0593, 0.0216, 0.0166, 0.0126, 0.0147, 0.0257, 0.0156,
        0.0704, 0.1028, 0.1867, 0.0676, 0.0875, 0.1345, 0.0751],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,288][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.2267e-11, 1.1339e-15, 5.0067e-13, 2.3779e-13, 7.4547e-10, 2.7182e-11,
        2.4834e-10, 1.4625e-10, 6.7955e-09, 1.7435e-06, 4.4893e-06, 2.1485e-05,
        7.5355e-05, 6.2380e-03, 8.6120e-01, 1.3246e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,289][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([6.5892e-04, 7.6819e-03, 2.5086e-01, 4.5298e-01, 1.7389e-03, 1.8094e-01,
        7.8604e-02, 2.7414e-03, 1.2220e-02, 2.0321e-03, 6.0563e-04, 5.8165e-03,
        1.1085e-03, 1.3508e-03, 2.1417e-04, 4.4516e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,292][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0385, 0.1007, 0.0206, 0.1341, 0.0104, 0.0550, 0.0730, 0.0373, 0.0974,
        0.0334, 0.0619, 0.1219, 0.0387, 0.1567, 0.0173, 0.0029],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,293][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0015, 0.0030, 0.0066, 0.0038, 0.0381, 0.0027, 0.0035, 0.0164, 0.0162,
        0.0259, 0.0278, 0.0281, 0.1633, 0.0398, 0.4359, 0.1874],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,295][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0943, 0.0666, 0.0798, 0.0543, 0.0693, 0.0584, 0.0523, 0.0510, 0.0610,
        0.0574, 0.0582, 0.0585, 0.0546, 0.0562, 0.0689, 0.0592],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,296][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0643, 0.0742, 0.0549, 0.0797, 0.0476, 0.0726, 0.0868, 0.0736, 0.0752,
        0.0644, 0.0587, 0.0602, 0.0495, 0.0537, 0.0418, 0.0428],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,297][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0274, 0.0589, 0.0468, 0.0546, 0.0428, 0.0973, 0.0472, 0.1100, 0.1003,
        0.0553, 0.0985, 0.0556, 0.0690, 0.0435, 0.0537, 0.0392],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,298][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0566, 0.0532, 0.0011, 0.0014, 0.0118, 0.0202, 0.0119, 0.0972, 0.0103,
        0.0294, 0.0560, 0.0179, 0.0759, 0.0136, 0.1095, 0.4342],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,299][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0097, 0.0380, 0.0696, 0.0372, 0.0972, 0.0528, 0.0441, 0.1013, 0.0430,
        0.0864, 0.0492, 0.0473, 0.1080, 0.0397, 0.0913, 0.0852],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,300][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1002, 0.1018, 0.0374, 0.1214, 0.0250, 0.0291, 0.0352, 0.0285, 0.0577,
        0.0244, 0.0695, 0.0635, 0.0653, 0.1175, 0.0575, 0.0662],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,302][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0228, 0.0398, 0.0571, 0.0562, 0.0734, 0.0248, 0.0327, 0.0944, 0.0736,
        0.0719, 0.0945, 0.0439, 0.0771, 0.0781, 0.0895, 0.0337, 0.0364],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,304][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0148, 0.0358, 0.0302, 0.0130, 0.0082, 0.0061, 0.0084, 0.0198, 0.0124,
        0.0719, 0.0832, 0.1960, 0.0839, 0.0549, 0.1330, 0.0685, 0.1598],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,305][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.7092e-12, 3.7480e-16, 1.0393e-13, 8.7726e-14, 1.1467e-10, 3.0413e-11,
        3.8693e-12, 1.6370e-10, 1.1515e-08, 9.5242e-07, 1.6365e-05, 5.5910e-06,
        3.7674e-05, 2.2721e-04, 5.1691e-02, 7.9972e-01, 1.4830e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,307][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0012, 0.0092, 0.2671, 0.3476, 0.0043, 0.2706, 0.0614, 0.0068, 0.0122,
        0.0043, 0.0017, 0.0062, 0.0022, 0.0020, 0.0004, 0.0011, 0.0016],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,309][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0776, 0.0926, 0.0342, 0.1628, 0.0090, 0.0799, 0.0391, 0.1468, 0.0410,
        0.0207, 0.0385, 0.0895, 0.0320, 0.0740, 0.0249, 0.0111, 0.0263],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,311][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0006, 0.0017, 0.0048, 0.0022, 0.0316, 0.0018, 0.0016, 0.0130, 0.0132,
        0.0212, 0.0188, 0.0166, 0.1288, 0.0230, 0.3703, 0.1642, 0.1865],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,313][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0917, 0.0635, 0.0774, 0.0509, 0.0665, 0.0535, 0.0497, 0.0482, 0.0582,
        0.0524, 0.0551, 0.0548, 0.0513, 0.0517, 0.0654, 0.0547, 0.0550],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,314][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0720, 0.0585, 0.0436, 0.0652, 0.0410, 0.0626, 0.0815, 0.0783, 0.0721,
        0.0658, 0.0569, 0.0580, 0.0510, 0.0489, 0.0462, 0.0428, 0.0556],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,315][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0174, 0.0333, 0.0268, 0.0450, 0.0391, 0.1159, 0.0151, 0.0448, 0.0745,
        0.0590, 0.1196, 0.0275, 0.1082, 0.0253, 0.0293, 0.2058, 0.0134],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,316][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.0428e-02, 2.3298e-02, 4.6858e-04, 6.0852e-04, 4.3212e-03, 7.4826e-03,
        4.4134e-03, 3.8294e-02, 4.2992e-03, 9.7679e-03, 1.9792e-02, 6.3550e-03,
        2.6508e-02, 5.1673e-03, 3.8102e-02, 1.8502e-01, 5.8567e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,316][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0108, 0.0360, 0.0656, 0.0367, 0.0934, 0.0497, 0.0435, 0.0977, 0.0430,
        0.0760, 0.0489, 0.0472, 0.1010, 0.0397, 0.0861, 0.0779, 0.0469],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,318][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1006, 0.0824, 0.0270, 0.1303, 0.0150, 0.0279, 0.0236, 0.0230, 0.0609,
        0.0158, 0.0692, 0.0429, 0.0476, 0.1047, 0.0426, 0.0798, 0.1069],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,320][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0238, 0.0386, 0.0437, 0.0427, 0.0758, 0.0256, 0.0307, 0.0704, 0.0602,
        0.0839, 0.0751, 0.0420, 0.0807, 0.0719, 0.0714, 0.0387, 0.0360, 0.0888],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,321][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0208, 0.0525, 0.0387, 0.0139, 0.0093, 0.0083, 0.0111, 0.0192, 0.0144,
        0.0746, 0.0850, 0.1977, 0.0688, 0.0542, 0.1063, 0.0678, 0.1194, 0.0379],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,323][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([3.4471e-13, 2.7590e-17, 4.2005e-15, 4.9224e-15, 2.5504e-11, 1.1985e-12,
        6.5035e-12, 1.1633e-11, 2.9590e-10, 3.7990e-08, 1.9813e-07, 6.5621e-07,
        8.6371e-07, 7.7460e-05, 4.9172e-03, 1.1247e-01, 3.3709e-01, 5.4545e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,324][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0041, 0.0248, 0.2355, 0.4365, 0.0082, 0.1666, 0.0625, 0.0065, 0.0230,
        0.0057, 0.0025, 0.0098, 0.0033, 0.0038, 0.0010, 0.0015, 0.0025, 0.0021],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,326][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0263, 0.0936, 0.0117, 0.0744, 0.0239, 0.1233, 0.0575, 0.0430, 0.0834,
        0.0283, 0.0291, 0.1032, 0.0384, 0.0995, 0.0086, 0.0302, 0.0419, 0.0838],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,328][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([1.1530e-04, 4.2514e-04, 5.8071e-04, 4.3978e-04, 2.2552e-03, 3.9541e-04,
        3.0081e-04, 2.0959e-03, 2.3791e-03, 3.7267e-03, 5.5483e-03, 5.5873e-03,
        3.3641e-02, 9.5934e-03, 5.7519e-02, 6.2484e-02, 7.0945e-02, 7.4197e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,330][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0684, 0.0556, 0.0665, 0.0489, 0.0594, 0.0523, 0.0462, 0.0487, 0.0546,
        0.0548, 0.0505, 0.0529, 0.0530, 0.0536, 0.0633, 0.0566, 0.0532, 0.0615],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,331][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0626, 0.0668, 0.0536, 0.0727, 0.0461, 0.0692, 0.0785, 0.0668, 0.0657,
        0.0565, 0.0520, 0.0513, 0.0446, 0.0475, 0.0383, 0.0407, 0.0479, 0.0391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,331][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.0158, 0.0359, 0.0215, 0.0408, 0.0277, 0.1111, 0.0232, 0.0728, 0.0960,
        0.0490, 0.0914, 0.0396, 0.0778, 0.0250, 0.0251, 0.1577, 0.0229, 0.0665],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,332][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([1.3652e-02, 2.7130e-03, 7.5044e-05, 1.3001e-04, 7.8308e-04, 1.3626e-03,
        9.7222e-04, 7.6172e-03, 1.0573e-03, 1.8745e-03, 3.5209e-03, 1.2907e-03,
        5.4939e-03, 8.8795e-04, 6.2694e-03, 3.2897e-02, 9.0066e-02, 8.2934e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,333][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0070, 0.0303, 0.0570, 0.0287, 0.0807, 0.0425, 0.0333, 0.0865, 0.0328,
        0.0711, 0.0383, 0.0365, 0.0940, 0.0313, 0.0768, 0.0678, 0.0360, 0.1492],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,335][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0980, 0.0722, 0.0342, 0.0896, 0.0219, 0.0270, 0.0211, 0.0204, 0.0380,
        0.0197, 0.0419, 0.0365, 0.0571, 0.0925, 0.0504, 0.0705, 0.1070, 0.1021],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,337][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0229, 0.0372, 0.0419, 0.0447, 0.0665, 0.0235, 0.0313, 0.0759, 0.0545,
        0.0631, 0.0801, 0.0334, 0.0654, 0.0609, 0.0644, 0.0300, 0.0358, 0.1131,
        0.0555], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,339][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0114, 0.0302, 0.0159, 0.0058, 0.0027, 0.0025, 0.0050, 0.0089, 0.0068,
        0.0349, 0.0593, 0.2153, 0.0405, 0.0855, 0.1377, 0.0652, 0.1602, 0.0261,
        0.0861], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,340][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.5875e-12, 1.3194e-18, 3.1095e-16, 1.4173e-16, 5.2176e-13, 1.7228e-13,
        4.0623e-13, 7.7330e-13, 1.0236e-11, 1.9832e-08, 5.4591e-09, 3.2851e-08,
        1.0322e-07, 5.8039e-07, 1.5481e-04, 5.9747e-03, 2.2634e-02, 7.6423e-01,
        2.0700e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,342][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.9179e-04, 5.2253e-03, 2.5376e-01, 4.2829e-01, 1.2166e-03, 2.0605e-01,
        8.1792e-02, 2.7298e-03, 9.7080e-03, 1.6827e-03, 5.2581e-04, 4.7465e-03,
        9.2303e-04, 9.5181e-04, 1.4148e-04, 3.3552e-04, 7.6456e-04, 6.1234e-04,
        1.4534e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,344][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0281, 0.0533, 0.0149, 0.0959, 0.0067, 0.1145, 0.0623, 0.0319, 0.1105,
        0.0234, 0.0540, 0.0775, 0.0518, 0.0810, 0.0155, 0.0536, 0.0454, 0.0474,
        0.0323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,345][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.2729e-05, 4.6029e-05, 7.1112e-05, 6.6492e-05, 3.7748e-04, 8.7095e-05,
        6.4595e-05, 4.4185e-04, 5.5586e-04, 5.8614e-04, 1.0286e-03, 8.3135e-04,
        8.6789e-03, 2.4201e-03, 2.4862e-02, 2.7163e-02, 3.3087e-02, 8.9699e-01,
        2.6319e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,348][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0798, 0.0567, 0.0686, 0.0456, 0.0593, 0.0499, 0.0449, 0.0438, 0.0523,
        0.0481, 0.0495, 0.0496, 0.0462, 0.0472, 0.0588, 0.0506, 0.0500, 0.0565,
        0.0425], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,350][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0688, 0.0574, 0.0432, 0.0614, 0.0407, 0.0602, 0.0747, 0.0693, 0.0640,
        0.0579, 0.0502, 0.0499, 0.0448, 0.0430, 0.0412, 0.0390, 0.0476, 0.0402,
        0.0466], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,351][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0106, 0.0278, 0.0262, 0.0356, 0.0246, 0.1233, 0.0244, 0.0418, 0.0520,
        0.0338, 0.0673, 0.0242, 0.0664, 0.0221, 0.0322, 0.2500, 0.0233, 0.1028,
        0.0117], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,353][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.0090e-03, 2.2180e-03, 4.7486e-05, 7.3229e-05, 3.2525e-04, 6.0200e-04,
        4.6512e-04, 3.0953e-03, 4.4214e-04, 7.1552e-04, 1.5275e-03, 5.9705e-04,
        1.8819e-03, 4.9982e-04, 2.5968e-03, 1.4360e-02, 5.8007e-02, 5.7834e-01,
        3.2820e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,353][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0086, 0.0302, 0.0523, 0.0311, 0.0784, 0.0426, 0.0364, 0.0751, 0.0360,
        0.0632, 0.0398, 0.0398, 0.0854, 0.0335, 0.0702, 0.0658, 0.0397, 0.1368,
        0.0350], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,354][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0617, 0.0482, 0.0143, 0.0709, 0.0078, 0.0156, 0.0126, 0.0097, 0.0346,
        0.0081, 0.0402, 0.0252, 0.0210, 0.0630, 0.0229, 0.0418, 0.0667, 0.0492,
        0.3867], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,358][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:54,360][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21468],
        [ 9438],
        [ 7358],
        [16405],
        [   20],
        [ 9708],
        [21539],
        [17156],
        [16883],
        [17821],
        [12365],
        [17443],
        [21801],
        [10632],
        [ 8511],
        [13074],
        [23514],
        [20532],
        [13027]], device='cuda:0')
[2024-07-24 10:18:54,362][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[32813],
        [34672],
        [22567],
        [36023],
        [    2],
        [29219],
        [39400],
        [38618],
        [38567],
        [44266],
        [35318],
        [35337],
        [39352],
        [23902],
        [19665],
        [24634],
        [39382],
        [34530],
        [21223]], device='cuda:0')
[2024-07-24 10:18:54,364][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[14533],
        [13255],
        [15856],
        [16259],
        [17906],
        [17717],
        [18056],
        [15825],
        [15593],
        [14224],
        [13806],
        [14073],
        [14053],
        [13730],
        [14120],
        [14272],
        [14714],
        [14849],
        [14619]], device='cuda:0')
[2024-07-24 10:18:54,366][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13510],
        [15444],
        [13427],
        [13182],
        [12303],
        [12682],
        [13491],
        [13565],
        [14693],
        [14211],
        [16011],
        [24217],
        [27061],
        [26942],
        [27888],
        [25905],
        [28748],
        [26098],
        [24847]], device='cuda:0')
[2024-07-24 10:18:54,368][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[45728],
        [48447],
        [38086],
        [31779],
        [19119],
        [17392],
        [24669],
        [28711],
        [28034],
        [27830],
        [40452],
        [42128],
        [45790],
        [45221],
        [23146],
        [36014],
        [48381],
        [29433],
        [46344]], device='cuda:0')
[2024-07-24 10:18:54,370][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16797],
        [17398],
        [20256],
        [19598],
        [21544],
        [21590],
        [22643],
        [16439],
        [18449],
        [21765],
        [28900],
        [24484],
        [28270],
        [25456],
        [26357],
        [29138],
        [28552],
        [21854],
        [23973]], device='cuda:0')
[2024-07-24 10:18:54,372][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37951],
        [38122],
        [37907],
        [37513],
        [36107],
        [35592],
        [35307],
        [33790],
        [33890],
        [30808],
        [31527],
        [31337],
        [29909],
        [30002],
        [29529],
        [28991],
        [29291],
        [28067],
        [28116]], device='cuda:0')
[2024-07-24 10:18:54,373][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24991],
        [22825],
        [19906],
        [21700],
        [18687],
        [18857],
        [22055],
        [19609],
        [20631],
        [18758],
        [19532],
        [20114],
        [18750],
        [19725],
        [17237],
        [17020],
        [19491],
        [18687],
        [20420]], device='cuda:0')
[2024-07-24 10:18:54,375][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[37596],
        [35704],
        [24708],
        [13507],
        [21922],
        [22142],
        [22721],
        [20936],
        [21913],
        [26026],
        [29976],
        [30949],
        [28076],
        [22501],
        [27675],
        [25411],
        [27849],
        [19252],
        [23332]], device='cuda:0')
[2024-07-24 10:18:54,377][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[11946],
        [15574],
        [18831],
        [18088],
        [23313],
        [21616],
        [22547],
        [21980],
        [23268],
        [23637],
        [25281],
        [25079],
        [22508],
        [23824],
        [23030],
        [22463],
        [22841],
        [21371],
        [20401]], device='cuda:0')
[2024-07-24 10:18:54,379][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21027],
        [20513],
        [20679],
        [20641],
        [20731],
        [20768],
        [20995],
        [21183],
        [21307],
        [21267],
        [22067],
        [21893],
        [23062],
        [22885],
        [22232],
        [22931],
        [22858],
        [23962],
        [24074]], device='cuda:0')
[2024-07-24 10:18:54,381][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[8367],
        [3387],
        [3716],
        [5566],
        [5145],
        [5511],
        [5495],
        [4931],
        [4628],
        [4372],
        [4225],
        [4862],
        [6300],
        [5316],
        [5139],
        [6127],
        [5217],
        [5671],
        [6105]], device='cuda:0')
[2024-07-24 10:18:54,384][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3463],
        [4140],
        [2812],
        [3930],
        [2966],
        [3439],
        [4512],
        [2954],
        [3611],
        [3161],
        [4273],
        [5490],
        [4269],
        [4602],
        [3146],
        [4062],
        [5094],
        [4656],
        [5988]], device='cuda:0')
[2024-07-24 10:18:54,386][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10347],
        [10580],
        [17353],
        [32683],
        [23532],
        [23974],
        [25911],
        [16448],
        [16546],
        [10499],
        [10003],
        [12218],
        [10460],
        [12721],
        [16108],
        [13337],
        [11225],
        [10448],
        [11353]], device='cuda:0')
[2024-07-24 10:18:54,388][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18409],
        [ 4337],
        [ 7618],
        [17214],
        [23384],
        [ 9932],
        [ 6808],
        [21611],
        [14206],
        [ 2165],
        [ 7066],
        [ 6977],
        [ 9453],
        [17250],
        [10374],
        [ 7436],
        [11115],
        [11309],
        [21357]], device='cuda:0')
[2024-07-24 10:18:54,389][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13335],
        [12159],
        [14951],
        [14689],
        [14866],
        [15052],
        [14472],
        [14728],
        [14145],
        [14800],
        [14207],
        [13344],
        [13261],
        [12445],
        [12276],
        [12747],
        [12433],
        [12174],
        [11899]], device='cuda:0')
[2024-07-24 10:18:54,391][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 6525],
        [ 8802],
        [14649],
        [19093],
        [20229],
        [24770],
        [24466],
        [23286],
        [22709],
        [18642],
        [18867],
        [16351],
        [18740],
        [21386],
        [21781],
        [21438],
        [21510],
        [21073],
        [20937]], device='cuda:0')
[2024-07-24 10:18:54,393][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 3092],
        [ 3735],
        [ 6416],
        [ 3775],
        [13232],
        [13280],
        [ 7786],
        [10342],
        [ 1689],
        [10495],
        [12743],
        [17435],
        [15800],
        [13484],
        [15520],
        [11793],
        [22607],
        [12144],
        [ 4992]], device='cuda:0')
[2024-07-24 10:18:54,395][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[26389],
        [27760],
        [27818],
        [30500],
        [33140],
        [31250],
        [31047],
        [31753],
        [34019],
        [35401],
        [32001],
        [32485],
        [38370],
        [34557],
        [35499],
        [36136],
        [33630],
        [35914],
        [35533]], device='cuda:0')
[2024-07-24 10:18:54,397][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24475],
        [18849],
        [22499],
        [27286],
        [28979],
        [24183],
        [26346],
        [32307],
        [30729],
        [35754],
        [30737],
        [30493],
        [32189],
        [34777],
        [29841],
        [25244],
        [29555],
        [29980],
        [28274]], device='cuda:0')
[2024-07-24 10:18:54,399][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[25707],
        [32153],
        [38760],
        [39856],
        [40825],
        [39931],
        [40155],
        [41579],
        [40403],
        [37775],
        [35554],
        [34782],
        [35647],
        [38117],
        [36429],
        [35773],
        [34232],
        [32542],
        [31747]], device='cuda:0')
[2024-07-24 10:18:54,401][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33759],
        [37709],
        [39660],
        [40712],
        [41371],
        [41785],
        [42291],
        [42874],
        [43273],
        [43440],
        [43539],
        [43631],
        [43625],
        [43687],
        [43836],
        [43747],
        [43829],
        [43747],
        [43730]], device='cuda:0')
[2024-07-24 10:18:54,403][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10374],
        [ 7413],
        [ 8170],
        [ 8302],
        [ 9104],
        [ 8572],
        [ 8832],
        [ 8855],
        [ 8921],
        [ 8849],
        [ 8994],
        [ 8839],
        [ 8860],
        [ 9076],
        [ 9230],
        [ 9339],
        [ 9715],
        [ 9661],
        [ 9923]], device='cuda:0')
[2024-07-24 10:18:54,405][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21623],
        [24179],
        [23697],
        [23483],
        [23294],
        [23072],
        [23709],
        [24395],
        [23941],
        [25788],
        [26528],
        [28846],
        [28768],
        [27002],
        [27865],
        [25944],
        [25622],
        [25843],
        [25037]], device='cuda:0')
[2024-07-24 10:18:54,407][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8526],
        [15781],
        [15427],
        [15124],
        [11930],
        [11212],
        [10976],
        [11015],
        [11698],
        [11006],
        [11618],
        [12243],
        [12394],
        [13020],
        [15028],
        [19539],
        [19700],
        [38259],
        [39518]], device='cuda:0')
[2024-07-24 10:18:54,408][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30041],
        [27116],
        [27397],
        [28932],
        [28700],
        [28530],
        [28622],
        [26974],
        [28425],
        [28060],
        [28594],
        [28684],
        [27881],
        [28500],
        [28423],
        [28060],
        [28184],
        [27442],
        [28114]], device='cuda:0')
[2024-07-24 10:18:54,410][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[11487],
        [ 7144],
        [ 7258],
        [ 4851],
        [ 5409],
        [ 5171],
        [ 5326],
        [ 5690],
        [ 5457],
        [ 5897],
        [ 6279],
        [ 6826],
        [ 7720],
        [ 7135],
        [ 7423],
        [ 7834],
        [ 8171],
        [ 9026],
        [ 8780]], device='cuda:0')
[2024-07-24 10:18:54,412][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[41192],
        [38665],
        [33100],
        [32717],
        [29890],
        [29739],
        [30291],
        [28141],
        [31356],
        [28339],
        [28175],
        [27426],
        [25536],
        [25980],
        [25638],
        [26266],
        [24024],
        [22943],
        [27258]], device='cuda:0')
[2024-07-24 10:18:54,414][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[45760],
        [44014],
        [37669],
        [30493],
        [28906],
        [30235],
        [35954],
        [21066],
        [30073],
        [46678],
        [38198],
        [39805],
        [34775],
        [28070],
        [30133],
        [33181],
        [29176],
        [25939],
        [14958]], device='cuda:0')
[2024-07-24 10:18:54,416][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377],
        [33377]], device='cuda:0')
[2024-07-24 10:18:54,454][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:54,456][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,457][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,459][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,460][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,461][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,461][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,462][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,463][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,463][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,464][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,466][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,468][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,469][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8931, 0.1069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,471][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9430, 0.0570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,473][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0032, 0.9968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,475][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([5.2395e-04, 9.9948e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,476][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3612, 0.6388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,478][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7392, 0.2608], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,478][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1688, 0.8312], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,479][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,480][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3887, 0.6113], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,481][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7302, 0.2698], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,481][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5122, 0.4878], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,482][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4042, 0.5958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,484][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.9721, 0.0018, 0.0261], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,486][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.8537, 0.0572, 0.0891], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,487][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([1.3523e-04, 1.4890e-01, 8.5096e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,488][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([9.8277e-07, 8.7366e-03, 9.9126e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,490][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2600, 0.4203, 0.3197], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,491][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.6259, 0.1996, 0.1745], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,493][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0807, 0.4275, 0.4918], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,494][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([1.4012e-04, 1.4774e-01, 8.5212e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,496][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.2279, 0.3746, 0.3975], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,497][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.2114, 0.6415, 0.1471], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,498][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.3836, 0.1434, 0.4730], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,498][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.2378, 0.3663, 0.3960], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,499][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9031, 0.0423, 0.0081, 0.0466], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,500][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.7378, 0.0504, 0.1990, 0.0128], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,501][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.6118e-04, 8.2820e-02, 3.7847e-01, 5.3855e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,502][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.3283e-06, 9.8863e-03, 9.3978e-01, 5.0336e-02], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,504][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1553, 0.2751, 0.2450, 0.3246], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,506][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4910, 0.1714, 0.1515, 0.1862], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,507][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0442, 0.2394, 0.3037, 0.4127], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,509][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.8458e-04, 8.4515e-02, 6.5486e-01, 2.6044e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,511][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1685, 0.2744, 0.2927, 0.2644], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,512][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2549, 0.5662, 0.0479, 0.1309], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,514][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5061, 0.2875, 0.0715, 0.1349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,515][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1859, 0.2739, 0.2970, 0.2432], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,516][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.8863, 0.0085, 0.0022, 0.0050, 0.0980], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,516][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.6492, 0.0434, 0.0769, 0.1694, 0.0611], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,517][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([6.9398e-06, 6.9143e-03, 2.8809e-02, 9.2679e-02, 8.7159e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,518][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([2.1078e-06, 1.0174e-02, 3.9672e-01, 5.8793e-02, 5.3431e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,518][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.1331, 0.2237, 0.2474, 0.2730, 0.1227], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,520][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.4369, 0.1455, 0.1273, 0.1623, 0.1280], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,522][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0395, 0.1886, 0.2101, 0.3009, 0.2610], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,524][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([1.9276e-05, 2.2119e-02, 7.6059e-02, 7.1923e-02, 8.2988e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,525][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.1308, 0.2160, 0.2293, 0.2075, 0.2164], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,527][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.3547, 0.1701, 0.0719, 0.2171, 0.1862], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,529][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.3431, 0.0999, 0.2025, 0.0860, 0.2685], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,531][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.1318, 0.2150, 0.2327, 0.1892, 0.2314], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,532][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.6331, 0.0557, 0.0041, 0.0612, 0.0022, 0.2438], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,533][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.7547, 0.0134, 0.0335, 0.1424, 0.0415, 0.0145], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,534][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([3.2814e-06, 4.3179e-03, 2.5455e-02, 3.9060e-02, 8.9852e-01, 3.2641e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,535][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([1.8447e-06, 3.9581e-03, 1.7446e-01, 1.2594e-02, 4.2972e-01, 3.7927e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,535][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1021, 0.1666, 0.1724, 0.1955, 0.1567, 0.2066], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,536][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4059, 0.1265, 0.1088, 0.1387, 0.1085, 0.1115], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,537][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0161, 0.1007, 0.1431, 0.1823, 0.1925, 0.3654], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,539][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([3.4558e-06, 5.8915e-03, 6.8415e-02, 2.1689e-02, 8.8971e-01, 1.4288e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,541][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1095, 0.1790, 0.1882, 0.1718, 0.1798, 0.1717], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,542][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1274, 0.6632, 0.0092, 0.0472, 0.0879, 0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,544][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3208, 0.2270, 0.0696, 0.2179, 0.1249, 0.0398], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,546][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1091, 0.1776, 0.1923, 0.1582, 0.1900, 0.1728], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,548][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8229, 0.0261, 0.0083, 0.0283, 0.0020, 0.0126, 0.0998],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,550][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4119, 0.0274, 0.0921, 0.0725, 0.3097, 0.0462, 0.0401],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,551][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.3757e-07, 1.5350e-03, 1.6863e-02, 1.9198e-02, 9.2911e-01, 3.0519e-02,
        2.7770e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,552][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.9577e-07, 1.5721e-03, 2.0051e-01, 7.6595e-03, 3.8575e-01, 3.7918e-01,
        2.5334e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,552][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0809, 0.1345, 0.1357, 0.1688, 0.1282, 0.1963, 0.1556],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,553][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3675, 0.1119, 0.0962, 0.1225, 0.0960, 0.0983, 0.1076],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,554][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0112, 0.0725, 0.1106, 0.1370, 0.1577, 0.2868, 0.2240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,555][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([4.7743e-07, 1.9384e-03, 4.0469e-02, 1.0821e-02, 9.3446e-01, 1.0437e-02,
        1.8728e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,557][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0961, 0.1541, 0.1619, 0.1484, 0.1566, 0.1475, 0.1353],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,559][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0822, 0.1661, 0.0387, 0.1091, 0.0908, 0.4213, 0.0918],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,560][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3323, 0.1199, 0.1048, 0.0854, 0.1716, 0.0616, 0.1245],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,562][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0965, 0.1531, 0.1654, 0.1358, 0.1647, 0.1497, 0.1347],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,564][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.6121, 0.0292, 0.0029, 0.0205, 0.0047, 0.0117, 0.0194, 0.2995],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,566][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.5185, 0.0336, 0.1260, 0.0565, 0.1404, 0.0426, 0.0623, 0.0201],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,567][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([8.3980e-06, 4.9057e-03, 2.2062e-02, 5.7746e-02, 7.6751e-01, 6.6318e-02,
        9.3221e-03, 7.2132e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,568][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([2.5402e-06, 2.1584e-03, 1.3031e-01, 1.7195e-02, 3.1846e-01, 2.9871e-01,
        4.2324e-02, 1.9084e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,569][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0717, 0.1265, 0.1117, 0.1542, 0.1191, 0.1692, 0.1402, 0.1074],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,570][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.3587, 0.1005, 0.0857, 0.1117, 0.0858, 0.0871, 0.0964, 0.0741],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,571][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0157, 0.0613, 0.0709, 0.1042, 0.0988, 0.1949, 0.1638, 0.2905],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,571][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([1.5533e-05, 7.8269e-03, 4.8037e-02, 3.1511e-02, 8.1647e-01, 2.4477e-02,
        4.4504e-03, 6.7209e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,572][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0835, 0.1331, 0.1399, 0.1285, 0.1365, 0.1281, 0.1176, 0.1327],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,574][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0910, 0.1000, 0.0303, 0.0658, 0.0614, 0.1226, 0.0502, 0.4786],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,575][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.3452, 0.1185, 0.1092, 0.0367, 0.2078, 0.0723, 0.0104, 0.0999],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,577][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0840, 0.1346, 0.1453, 0.1185, 0.1466, 0.1315, 0.1185, 0.1211],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,579][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.8572, 0.0287, 0.0052, 0.0339, 0.0044, 0.0070, 0.0129, 0.0109, 0.0399],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,580][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.3436, 0.0135, 0.0555, 0.0397, 0.3358, 0.0480, 0.0769, 0.0806, 0.0064],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,582][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([2.9104e-06, 3.2714e-03, 2.4739e-02, 3.1181e-02, 8.4413e-01, 3.7296e-02,
        5.1182e-03, 4.1827e-02, 1.2433e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,583][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([6.8299e-07, 2.3525e-03, 1.7563e-01, 9.1921e-03, 2.7866e-01, 2.7879e-01,
        3.5071e-02, 1.9668e-01, 2.3617e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,585][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0651, 0.1166, 0.0962, 0.1403, 0.0995, 0.1582, 0.1266, 0.0923, 0.1053],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,587][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.2796, 0.0947, 0.0831, 0.1032, 0.0828, 0.0847, 0.0918, 0.0734, 0.1068],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,588][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0083, 0.0482, 0.0664, 0.0851, 0.0887, 0.1583, 0.1299, 0.2399, 0.1754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,588][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([3.8238e-06, 5.7047e-03, 5.5233e-02, 2.2613e-02, 8.1656e-01, 1.9183e-02,
        4.6016e-03, 5.6608e-02, 1.9488e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,589][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0747, 0.1193, 0.1247, 0.1148, 0.1202, 0.1155, 0.1058, 0.1195, 0.1056],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,590][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1137, 0.0886, 0.0201, 0.0542, 0.0377, 0.0687, 0.0433, 0.1087, 0.4650],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,591][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1801, 0.2257, 0.0710, 0.1219, 0.1590, 0.0304, 0.0503, 0.0202, 0.1414],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,593][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0731, 0.1193, 0.1306, 0.1062, 0.1320, 0.1185, 0.1075, 0.1111, 0.1017],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,594][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([9.6768e-01, 6.0035e-03, 3.5855e-04, 4.0610e-03, 8.2760e-04, 7.7064e-04,
        3.0225e-03, 2.8132e-03, 3.9794e-03, 1.0479e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,596][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.4244, 0.0340, 0.0667, 0.0707, 0.1096, 0.0512, 0.0545, 0.1444, 0.0241,
        0.0204], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,597][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([1.1271e-05, 5.7411e-03, 3.4664e-02, 5.7724e-02, 7.3259e-01, 5.4709e-02,
        9.3851e-03, 5.5411e-02, 1.9858e-02, 2.9911e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,599][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([6.7800e-06, 4.1210e-03, 9.0497e-02, 2.0599e-02, 1.4664e-01, 3.6280e-01,
        5.6582e-02, 1.9588e-01, 4.2504e-02, 8.0372e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,601][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0600, 0.1021, 0.1012, 0.1291, 0.0924, 0.1543, 0.1172, 0.0899, 0.0932,
        0.0605], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,602][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.2990, 0.0861, 0.0733, 0.0956, 0.0740, 0.0739, 0.0817, 0.0625, 0.0976,
        0.0564], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,604][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0109, 0.0432, 0.0475, 0.0733, 0.0592, 0.1457, 0.1228, 0.2027, 0.1628,
        0.1319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,605][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([2.1690e-05, 1.2113e-02, 7.2435e-02, 4.4138e-02, 7.1670e-01, 2.7467e-02,
        7.0553e-03, 6.2886e-02, 2.6242e-02, 3.0939e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,606][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0681, 0.1081, 0.1142, 0.1045, 0.1108, 0.1036, 0.0949, 0.1074, 0.0957,
        0.0927], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,607][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0066, 0.0191, 0.0011, 0.0058, 0.0017, 0.0459, 0.0120, 0.1010, 0.7714,
        0.0356], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,607][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1604, 0.0806, 0.0889, 0.1451, 0.1986, 0.0620, 0.0424, 0.0266, 0.0353,
        0.1600], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,608][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0641, 0.1095, 0.1183, 0.0956, 0.1200, 0.1063, 0.0971, 0.0995, 0.0924,
        0.0972], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,609][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([8.3663e-01, 2.1621e-02, 1.7332e-03, 1.4229e-02, 2.5613e-04, 2.7041e-03,
        2.6659e-03, 2.1858e-03, 1.3773e-02, 1.9427e-04, 1.0400e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,611][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.4339, 0.0184, 0.0507, 0.0386, 0.1371, 0.0673, 0.0656, 0.0723, 0.0081,
        0.1023, 0.0056], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,612][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([1.2327e-06, 3.1161e-03, 2.3266e-02, 3.1288e-02, 8.3078e-01, 3.6953e-02,
        4.5999e-03, 3.1772e-02, 1.2201e-02, 2.0523e-02, 5.4980e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,614][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.1956e-06, 3.4836e-03, 1.6601e-01, 8.8768e-03, 2.4033e-01, 2.8227e-01,
        4.3746e-02, 1.4920e-01, 3.0223e-02, 7.1343e-02, 4.5188e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,615][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0554, 0.0944, 0.0940, 0.1181, 0.0921, 0.1323, 0.1076, 0.0837, 0.0898,
        0.0639, 0.0686], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,618][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.2663, 0.0815, 0.0697, 0.0898, 0.0699, 0.0709, 0.0778, 0.0605, 0.0925,
        0.0553, 0.0659], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,620][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0059, 0.0341, 0.0497, 0.0615, 0.0667, 0.1198, 0.0967, 0.1808, 0.1297,
        0.1536, 0.1015], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,621][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([1.5784e-06, 4.1340e-03, 5.9177e-02, 1.9502e-02, 7.9836e-01, 1.5999e-02,
        3.8854e-03, 4.9913e-02, 1.4522e-02, 2.8274e-02, 6.2318e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,622][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0631, 0.0996, 0.1047, 0.0961, 0.1013, 0.0957, 0.0878, 0.0990, 0.0880,
        0.0862, 0.0786], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,623][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0251, 0.0412, 0.0078, 0.0173, 0.0176, 0.0402, 0.0559, 0.0556, 0.4935,
        0.2250, 0.0207], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,624][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1604, 0.1962, 0.0503, 0.1225, 0.1334, 0.0290, 0.0383, 0.0227, 0.0532,
        0.0360, 0.1580], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,625][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0642, 0.1003, 0.1083, 0.0869, 0.1105, 0.0980, 0.0886, 0.0915, 0.0849,
        0.0901, 0.0768], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,626][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8295, 0.0176, 0.0143, 0.0227, 0.0018, 0.0055, 0.0115, 0.0118, 0.0191,
        0.0009, 0.0096, 0.0558], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,627][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2923, 0.0134, 0.0534, 0.0425, 0.2469, 0.0409, 0.0189, 0.1120, 0.0048,
        0.0855, 0.0114, 0.0780], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,628][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.4877e-07, 1.1509e-03, 2.2944e-02, 1.5160e-02, 8.8696e-01, 2.2428e-02,
        2.3946e-03, 2.8351e-02, 5.7773e-03, 1.0592e-02, 3.0347e-03, 1.2051e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,629][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.7555e-07, 1.6924e-03, 2.5179e-01, 5.9203e-03, 2.5467e-01, 2.6038e-01,
        2.6014e-02, 1.2521e-01, 1.2753e-02, 4.7321e-02, 2.5210e-03, 1.1722e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,631][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0501, 0.0875, 0.0853, 0.1117, 0.0827, 0.1192, 0.1040, 0.0739, 0.0853,
        0.0555, 0.0621, 0.0826], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,633][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2571, 0.0748, 0.0645, 0.0832, 0.0645, 0.0659, 0.0723, 0.0563, 0.0861,
        0.0507, 0.0611, 0.0634], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,634][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0042, 0.0281, 0.0430, 0.0542, 0.0583, 0.1115, 0.0874, 0.1709, 0.1182,
        0.1471, 0.0951, 0.0819], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,636][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.8484e-07, 1.9940e-03, 5.2593e-02, 1.0150e-02, 8.6014e-01, 9.0198e-03,
        1.9285e-03, 3.5704e-02, 6.8730e-03, 1.6930e-02, 3.0375e-03, 1.6301e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,638][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0574, 0.0916, 0.0969, 0.0883, 0.0940, 0.0870, 0.0804, 0.0908, 0.0808,
        0.0795, 0.0734, 0.0798], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,639][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0202, 0.0479, 0.0169, 0.0159, 0.0268, 0.0500, 0.0257, 0.0940, 0.3547,
        0.2058, 0.1021, 0.0399], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,641][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2267, 0.0858, 0.0614, 0.0446, 0.1623, 0.0587, 0.0608, 0.0795, 0.0144,
        0.0612, 0.0254, 0.1191], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,641][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0562, 0.0937, 0.1019, 0.0813, 0.1022, 0.0910, 0.0825, 0.0844, 0.0794,
        0.0840, 0.0718, 0.0715], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,642][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ station] are: tensor([8.8459e-01, 7.7158e-03, 2.6864e-03, 6.0998e-03, 4.1242e-04, 8.2380e-04,
        2.0066e-03, 1.8202e-03, 1.0229e-02, 2.5680e-04, 5.0071e-03, 4.7818e-03,
        7.3572e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,643][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.2295, 0.0111, 0.0283, 0.0537, 0.1384, 0.0563, 0.0540, 0.0421, 0.0222,
        0.0663, 0.0478, 0.2361, 0.0142], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,644][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ station] are: tensor([4.9070e-06, 4.4216e-03, 4.0214e-02, 5.8579e-02, 7.4059e-01, 4.9368e-02,
        7.9253e-03, 4.5440e-02, 1.2765e-02, 1.8784e-02, 7.2811e-03, 2.8187e-03,
        1.1804e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,645][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.4613e-06, 2.9989e-03, 1.2310e-01, 1.4720e-02, 1.2303e-01, 2.9887e-01,
        5.4027e-02, 2.4155e-01, 2.9147e-02, 7.9371e-02, 5.1054e-03, 1.7033e-02,
        1.1043e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,647][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0463, 0.0787, 0.0836, 0.0986, 0.0869, 0.1258, 0.0937, 0.0823, 0.0713,
        0.0579, 0.0564, 0.0717, 0.0468], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,649][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.2375, 0.0726, 0.0618, 0.0799, 0.0623, 0.0625, 0.0689, 0.0536, 0.0812,
        0.0486, 0.0582, 0.0607, 0.0521], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,650][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0069, 0.0298, 0.0341, 0.0527, 0.0442, 0.1125, 0.0897, 0.1647, 0.1178,
        0.1112, 0.0911, 0.0685, 0.0768], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,652][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ station] are: tensor([6.8201e-06, 9.9652e-03, 7.5945e-02, 3.2680e-02, 7.4010e-01, 2.0436e-02,
        5.0781e-03, 5.9644e-02, 1.7078e-02, 2.4752e-02, 7.3594e-03, 3.9570e-03,
        3.0028e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,654][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0517, 0.0845, 0.0904, 0.0815, 0.0878, 0.0809, 0.0743, 0.0845, 0.0751,
        0.0740, 0.0685, 0.0747, 0.0721], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,656][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0089, 0.0202, 0.0069, 0.0116, 0.0111, 0.0360, 0.0309, 0.0934, 0.4143,
        0.1637, 0.1430, 0.0468, 0.0131], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,657][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1393, 0.0717, 0.0444, 0.0626, 0.2103, 0.0206, 0.0290, 0.0469, 0.0228,
        0.0961, 0.0956, 0.0307, 0.1299], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,659][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0511, 0.0860, 0.0940, 0.0750, 0.0953, 0.0845, 0.0766, 0.0795, 0.0743,
        0.0785, 0.0673, 0.0676, 0.0705], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,660][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5568, 0.0491, 0.0127, 0.0527, 0.0076, 0.0204, 0.0255, 0.0202, 0.0418,
        0.0040, 0.0324, 0.0567, 0.0324, 0.0875], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,660][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1441, 0.0049, 0.0664, 0.0207, 0.1274, 0.0342, 0.0518, 0.0564, 0.0169,
        0.1019, 0.0287, 0.2613, 0.0753, 0.0100], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,661][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([5.7381e-07, 1.3678e-03, 1.7323e-02, 1.7767e-02, 8.5931e-01, 2.7493e-02,
        2.7478e-03, 3.7572e-02, 8.6553e-03, 1.3375e-02, 4.2243e-03, 1.3969e-03,
        5.9523e-03, 2.8157e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,662][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([4.8487e-07, 1.3453e-03, 1.1747e-01, 1.0161e-02, 2.0564e-01, 2.7286e-01,
        4.0401e-02, 1.8048e-01, 2.9829e-02, 8.2086e-02, 5.0562e-03, 2.0478e-02,
        8.4477e-03, 2.5740e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,664][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0411, 0.0748, 0.0684, 0.0975, 0.0735, 0.1097, 0.0900, 0.0637, 0.0734,
        0.0494, 0.0539, 0.0700, 0.0541, 0.0803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,665][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.2194, 0.0665, 0.0577, 0.0734, 0.0575, 0.0591, 0.0648, 0.0510, 0.0762,
        0.0463, 0.0554, 0.0572, 0.0478, 0.0676], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,667][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0044, 0.0248, 0.0338, 0.0456, 0.0469, 0.0903, 0.0723, 0.1378, 0.1024,
        0.1110, 0.0799, 0.0675, 0.0850, 0.0984], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,668][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([1.1056e-06, 3.1498e-03, 3.6106e-02, 1.6012e-02, 8.2331e-01, 1.3012e-02,
        2.9314e-03, 5.2638e-02, 1.4001e-02, 2.1672e-02, 5.1238e-03, 2.5560e-03,
        4.1129e-03, 5.3765e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,670][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0494, 0.0795, 0.0842, 0.0768, 0.0818, 0.0762, 0.0704, 0.0792, 0.0702,
        0.0685, 0.0634, 0.0699, 0.0675, 0.0629], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,672][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0134, 0.0149, 0.0059, 0.0082, 0.0087, 0.0210, 0.0072, 0.1164, 0.2846,
        0.1962, 0.0473, 0.0804, 0.0193, 0.1767], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,674][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.3211, 0.1764, 0.0437, 0.0663, 0.0778, 0.0223, 0.0274, 0.0154, 0.0201,
        0.0166, 0.0347, 0.0444, 0.0226, 0.1113], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,676][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0486, 0.0797, 0.0873, 0.0711, 0.0880, 0.0788, 0.0710, 0.0737, 0.0694,
        0.0729, 0.0630, 0.0622, 0.0649, 0.0692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:54,677][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([9.3647e-01, 1.5538e-03, 2.8377e-02, 7.4412e-04, 2.9730e-04, 6.2270e-04,
        4.9529e-04, 1.5901e-04, 6.9072e-04, 3.8765e-05, 1.4559e-04, 1.0625e-03,
        6.7079e-04, 2.2180e-03, 2.6453e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,678][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.1579, 0.0062, 0.0144, 0.0254, 0.1334, 0.0452, 0.0410, 0.0299, 0.0138,
        0.1922, 0.0664, 0.1465, 0.0354, 0.0504, 0.0420], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,679][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([7.1087e-06, 6.3896e-03, 3.2694e-02, 7.3372e-02, 6.8615e-01, 5.5352e-02,
        8.0627e-03, 5.6536e-02, 1.4505e-02, 2.2215e-02, 7.6508e-03, 2.3877e-03,
        1.1687e-02, 1.7492e-02, 5.4970e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,679][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([4.3625e-07, 1.4797e-03, 8.9020e-02, 1.7777e-02, 1.1617e-01, 3.1464e-01,
        5.4903e-02, 2.3070e-01, 2.1431e-02, 5.8912e-02, 3.7779e-03, 1.1742e-02,
        7.4150e-03, 5.7451e-02, 1.4573e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,680][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0424, 0.0745, 0.0592, 0.0890, 0.0797, 0.0970, 0.0837, 0.0651, 0.0672,
        0.0507, 0.0501, 0.0659, 0.0500, 0.0784, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,682][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.2061, 0.0626, 0.0545, 0.0702, 0.0543, 0.0560, 0.0619, 0.0486, 0.0722,
        0.0436, 0.0526, 0.0547, 0.0459, 0.0660, 0.0506], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,684][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0047, 0.0237, 0.0274, 0.0427, 0.0356, 0.0960, 0.0796, 0.1434, 0.1054,
        0.0969, 0.0770, 0.0610, 0.0684, 0.1027, 0.0354], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,686][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([1.0012e-05, 1.2348e-02, 6.2457e-02, 3.4891e-02, 7.0686e-01, 2.5928e-02,
        4.5824e-03, 7.3979e-02, 1.5727e-02, 2.6561e-02, 6.1628e-03, 2.6159e-03,
        4.5576e-03, 1.6725e-02, 6.5993e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,687][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0467, 0.0748, 0.0783, 0.0717, 0.0764, 0.0710, 0.0654, 0.0736, 0.0657,
        0.0647, 0.0594, 0.0648, 0.0632, 0.0588, 0.0653], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,690][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0213, 0.0329, 0.0081, 0.0157, 0.0570, 0.0131, 0.0306, 0.0450, 0.3244,
        0.0991, 0.0151, 0.0333, 0.0111, 0.2171, 0.0762], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,692][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0758, 0.0236, 0.0728, 0.0359, 0.2330, 0.0967, 0.0631, 0.0277, 0.0125,
        0.0754, 0.0105, 0.1032, 0.0552, 0.0379, 0.0768], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,693][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0483, 0.0758, 0.0820, 0.0665, 0.0817, 0.0739, 0.0670, 0.0688, 0.0646,
        0.0676, 0.0587, 0.0583, 0.0609, 0.0647, 0.0612], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:54,695][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.7566e-01, 1.1675e-02, 9.8940e-04, 1.5395e-02, 1.9636e-03, 5.8237e-03,
        9.4490e-03, 3.3562e-03, 9.3861e-03, 1.0863e-03, 5.1673e-03, 4.4702e-03,
        2.7498e-03, 1.6364e-02, 7.3814e-04, 3.5728e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,696][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.2407, 0.0102, 0.0311, 0.0443, 0.0387, 0.0225, 0.0359, 0.0423, 0.0125,
        0.0764, 0.0228, 0.2579, 0.0088, 0.0426, 0.1040, 0.0096],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,696][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.0566e-06, 2.5679e-03, 3.4963e-02, 2.9059e-02, 8.0944e-01, 2.4392e-02,
        4.8212e-03, 3.3731e-02, 7.6794e-03, 1.4702e-02, 4.8495e-03, 2.5921e-03,
        1.1609e-02, 9.1964e-03, 8.5510e-03, 1.8452e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,697][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.4393e-07, 2.3663e-03, 1.7758e-01, 1.2227e-02, 1.4523e-01, 2.4695e-01,
        4.6555e-02, 1.4483e-01, 2.3652e-02, 4.9046e-02, 3.2048e-03, 1.9341e-02,
        1.4012e-02, 6.2746e-02, 3.5440e-02, 1.6814e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,698][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0387, 0.0666, 0.0688, 0.0845, 0.0601, 0.0928, 0.0786, 0.0607, 0.0628,
        0.0464, 0.0474, 0.0647, 0.0490, 0.0692, 0.0590, 0.0507],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,700][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1950, 0.0597, 0.0519, 0.0667, 0.0518, 0.0533, 0.0587, 0.0460, 0.0689,
        0.0415, 0.0496, 0.0520, 0.0437, 0.0628, 0.0485, 0.0499],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,702][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0039, 0.0212, 0.0292, 0.0384, 0.0373, 0.0785, 0.0654, 0.1264, 0.0862,
        0.0958, 0.0657, 0.0552, 0.0757, 0.0913, 0.0404, 0.0893],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,704][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.2771e-06, 5.2849e-03, 9.7327e-02, 1.8049e-02, 7.5739e-01, 1.0834e-02,
        4.0199e-03, 3.8502e-02, 9.2661e-03, 1.7699e-02, 4.1670e-03, 3.0274e-03,
        7.4202e-03, 9.3732e-03, 1.5473e-02, 2.1652e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,705][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0440, 0.0698, 0.0731, 0.0671, 0.0711, 0.0668, 0.0616, 0.0693, 0.0618,
        0.0611, 0.0554, 0.0610, 0.0586, 0.0549, 0.0610, 0.0636],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,708][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1186, 0.1057, 0.0037, 0.0098, 0.0147, 0.0377, 0.0179, 0.0247, 0.1502,
        0.0736, 0.0422, 0.0391, 0.0086, 0.2621, 0.0447, 0.0468],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,710][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0761, 0.0999, 0.0626, 0.0656, 0.0596, 0.0684, 0.0581, 0.0574, 0.0354,
        0.0909, 0.0579, 0.0570, 0.0442, 0.0619, 0.0773, 0.0276],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,711][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0438, 0.0724, 0.0775, 0.0633, 0.0761, 0.0694, 0.0631, 0.0645, 0.0612,
        0.0633, 0.0549, 0.0546, 0.0572, 0.0609, 0.0578, 0.0600],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:54,713][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7086, 0.0161, 0.0067, 0.0200, 0.0012, 0.0070, 0.0748, 0.0080, 0.0180,
        0.0015, 0.0160, 0.0207, 0.0120, 0.0265, 0.0055, 0.0034, 0.0539],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,714][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1889, 0.0102, 0.0339, 0.0289, 0.1257, 0.0186, 0.0154, 0.0485, 0.0048,
        0.0977, 0.0092, 0.0984, 0.0431, 0.0418, 0.1130, 0.0904, 0.0315],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,714][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.6991e-08, 4.0876e-04, 1.4657e-02, 8.0689e-03, 9.2304e-01, 1.2755e-02,
        1.1296e-03, 2.1568e-02, 2.8002e-03, 5.1484e-03, 1.3569e-03, 5.5638e-04,
        3.1711e-03, 2.0368e-03, 2.5612e-03, 6.4848e-04, 9.1755e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,715][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.8580e-08, 1.2976e-03, 1.8116e-01, 7.4167e-03, 1.8320e-01, 3.0150e-01,
        2.9478e-02, 1.6325e-01, 1.3304e-02, 3.1803e-02, 1.8017e-03, 8.9132e-03,
        7.9651e-03, 3.1517e-02, 1.7896e-02, 1.6236e-02, 3.2606e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,716][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0343, 0.0590, 0.0610, 0.0775, 0.0584, 0.0867, 0.0735, 0.0566, 0.0585,
        0.0421, 0.0459, 0.0601, 0.0498, 0.0674, 0.0551, 0.0522, 0.0619],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,718][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1890, 0.0565, 0.0492, 0.0630, 0.0490, 0.0506, 0.0555, 0.0437, 0.0655,
        0.0393, 0.0470, 0.0487, 0.0406, 0.0581, 0.0449, 0.0466, 0.0529],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,721][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0026, 0.0177, 0.0281, 0.0348, 0.0387, 0.0699, 0.0552, 0.1174, 0.0776,
        0.0995, 0.0595, 0.0518, 0.0801, 0.0824, 0.0409, 0.0881, 0.0558],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,722][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.3374e-08, 6.4593e-04, 3.8713e-02, 5.1991e-03, 9.0551e-01, 4.8237e-03,
        1.0532e-03, 2.2635e-02, 3.3830e-03, 6.7934e-03, 1.1830e-03, 6.3384e-04,
        2.1178e-03, 2.1433e-03, 4.4203e-03, 6.3105e-04, 1.1701e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,724][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0425, 0.0659, 0.0690, 0.0635, 0.0673, 0.0624, 0.0576, 0.0649, 0.0580,
        0.0567, 0.0520, 0.0571, 0.0555, 0.0524, 0.0578, 0.0607, 0.0569],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,726][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0081, 0.0068, 0.0015, 0.0024, 0.0025, 0.0119, 0.0027, 0.0214, 0.0669,
        0.0386, 0.0151, 0.0075, 0.0124, 0.0575, 0.0216, 0.6626, 0.0606],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,728][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1752, 0.0686, 0.0432, 0.0455, 0.0905, 0.0408, 0.0552, 0.1059, 0.0130,
        0.0577, 0.0252, 0.0668, 0.0332, 0.0485, 0.0577, 0.0158, 0.0571],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,730][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0408, 0.0668, 0.0725, 0.0590, 0.0722, 0.0659, 0.0591, 0.0616, 0.0583,
        0.0611, 0.0528, 0.0523, 0.0550, 0.0583, 0.0548, 0.0571, 0.0526],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:54,731][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.8000, 0.0092, 0.0030, 0.0087, 0.0021, 0.0046, 0.0080, 0.0025, 0.0050,
        0.0018, 0.0046, 0.0043, 0.0037, 0.0080, 0.0019, 0.0015, 0.0042, 0.1268],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,732][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.2457, 0.0109, 0.0419, 0.0249, 0.0714, 0.0185, 0.0111, 0.0126, 0.0182,
        0.0336, 0.0177, 0.0800, 0.0572, 0.0539, 0.1113, 0.0336, 0.0202, 0.1372],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,733][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([2.6793e-06, 3.3513e-03, 2.7135e-02, 6.0070e-02, 7.1952e-01, 4.5495e-02,
        7.2489e-03, 4.9509e-02, 1.4670e-02, 2.0131e-02, 8.1075e-03, 2.8117e-03,
        9.6503e-03, 1.4524e-02, 5.2858e-03, 2.2267e-03, 4.5710e-04, 9.7987e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,733][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([2.2039e-06, 3.4722e-03, 6.2357e-02, 1.4130e-02, 1.1031e-01, 2.7657e-01,
        4.5820e-02, 1.7802e-01, 3.0909e-02, 7.5229e-02, 5.8819e-03, 2.6868e-02,
        1.1863e-02, 5.9308e-02, 1.7819e-02, 3.0252e-02, 1.0061e-02, 4.1132e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,734][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0330, 0.0579, 0.0632, 0.0758, 0.0589, 0.0864, 0.0690, 0.0571, 0.0563,
        0.0445, 0.0408, 0.0539, 0.0389, 0.0631, 0.0525, 0.0493, 0.0559, 0.0437],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,737][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.1790, 0.0543, 0.0469, 0.0601, 0.0466, 0.0479, 0.0531, 0.0415, 0.0622,
        0.0373, 0.0449, 0.0467, 0.0394, 0.0562, 0.0437, 0.0450, 0.0511, 0.0440],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,739][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0050, 0.0219, 0.0215, 0.0354, 0.0264, 0.0782, 0.0664, 0.1179, 0.0895,
        0.0688, 0.0642, 0.0502, 0.0462, 0.0866, 0.0253, 0.0775, 0.0614, 0.0576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,740][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([3.2958e-06, 4.7354e-03, 5.7052e-02, 2.2652e-02, 7.8104e-01, 1.4232e-02,
        2.7954e-03, 4.9744e-02, 1.2043e-02, 2.0200e-02, 4.3847e-03, 2.0583e-03,
        2.7281e-03, 9.1308e-03, 6.2853e-03, 1.8344e-03, 3.1081e-04, 8.7675e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,742][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0390, 0.0621, 0.0648, 0.0595, 0.0632, 0.0590, 0.0545, 0.0612, 0.0549,
        0.0539, 0.0492, 0.0542, 0.0524, 0.0493, 0.0547, 0.0574, 0.0542, 0.0566],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,744][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0284, 0.0086, 0.0018, 0.0032, 0.0025, 0.0205, 0.0054, 0.0328, 0.0777,
        0.0350, 0.0251, 0.0119, 0.0087, 0.1485, 0.0319, 0.3916, 0.1191, 0.0472],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,746][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.1112, 0.0445, 0.0836, 0.0436, 0.0911, 0.0716, 0.0437, 0.0173, 0.0212,
        0.0268, 0.0421, 0.0317, 0.0247, 0.0418, 0.0872, 0.0675, 0.0363, 0.1141],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,748][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0407, 0.0627, 0.0673, 0.0553, 0.0673, 0.0616, 0.0559, 0.0580, 0.0547,
        0.0572, 0.0498, 0.0496, 0.0517, 0.0547, 0.0516, 0.0534, 0.0493, 0.0593],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:54,749][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.7673, 0.0201, 0.0063, 0.0183, 0.0012, 0.0065, 0.0101, 0.0041, 0.0186,
        0.0013, 0.0164, 0.0137, 0.0131, 0.0303, 0.0061, 0.0065, 0.0080, 0.0148,
        0.0372], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,750][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1220, 0.0029, 0.0165, 0.0129, 0.0927, 0.0441, 0.0164, 0.0929, 0.0032,
        0.0379, 0.0052, 0.0821, 0.0072, 0.0103, 0.0562, 0.0899, 0.0334, 0.2716,
        0.0025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,751][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.8872e-08, 6.7615e-04, 1.3072e-02, 1.2576e-02, 9.0919e-01, 1.1839e-02,
        9.5741e-04, 2.4615e-02, 4.0342e-03, 7.4398e-03, 1.5030e-03, 5.1798e-04,
        2.4879e-03, 1.8571e-03, 2.4574e-03, 7.5917e-04, 5.0722e-05, 3.8701e-03,
        2.0935e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,752][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.7012e-07, 1.8247e-03, 1.2255e-01, 9.9331e-03, 1.3547e-01, 3.4763e-01,
        4.7062e-02, 1.3192e-01, 2.2361e-02, 3.8458e-02, 2.5760e-03, 1.7308e-02,
        8.1627e-03, 3.6579e-02, 1.3465e-02, 1.9869e-02, 5.8711e-03, 3.6869e-02,
        2.0948e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,753][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0310, 0.0541, 0.0512, 0.0708, 0.0516, 0.0836, 0.0662, 0.0517, 0.0527,
        0.0389, 0.0407, 0.0533, 0.0415, 0.0600, 0.0453, 0.0474, 0.0539, 0.0488,
        0.0575], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,755][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1564, 0.0516, 0.0456, 0.0566, 0.0451, 0.0467, 0.0509, 0.0410, 0.0587,
        0.0373, 0.0439, 0.0451, 0.0379, 0.0524, 0.0411, 0.0430, 0.0482, 0.0422,
        0.0564], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,757][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0029, 0.0170, 0.0229, 0.0311, 0.0309, 0.0655, 0.0525, 0.1019, 0.0737,
        0.0754, 0.0561, 0.0480, 0.0577, 0.0728, 0.0302, 0.0774, 0.0535, 0.0675,
        0.0629], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,758][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([3.2334e-08, 5.7689e-04, 2.5514e-02, 5.2846e-03, 8.9954e-01, 4.6764e-03,
        7.5922e-04, 2.6873e-02, 4.4501e-03, 1.1628e-02, 1.3513e-03, 5.8920e-04,
        2.1902e-03, 1.7949e-03, 4.1428e-03, 6.9674e-04, 5.3419e-05, 9.0485e-03,
        8.2626e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,760][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0386, 0.0592, 0.0614, 0.0569, 0.0602, 0.0563, 0.0522, 0.0579, 0.0520,
        0.0504, 0.0463, 0.0518, 0.0495, 0.0472, 0.0515, 0.0545, 0.0515, 0.0541,
        0.0484], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,762][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0132, 0.0115, 0.0016, 0.0034, 0.0036, 0.0096, 0.0057, 0.0264, 0.0679,
        0.0288, 0.0027, 0.0083, 0.0073, 0.1046, 0.0256, 0.3854, 0.1132, 0.1252,
        0.0562], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,764][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0740, 0.0960, 0.0330, 0.0625, 0.0702, 0.0803, 0.0247, 0.0138, 0.0255,
        0.0139, 0.1447, 0.0431, 0.0307, 0.0629, 0.0413, 0.0354, 0.0226, 0.0883,
        0.0371], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,766][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0398, 0.0587, 0.0635, 0.0524, 0.0633, 0.0585, 0.0531, 0.0548, 0.0522,
        0.0547, 0.0474, 0.0473, 0.0491, 0.0521, 0.0490, 0.0510, 0.0470, 0.0562,
        0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:54,808][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:54,809][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,811][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,812][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,814][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,815][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,817][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,818][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,819][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,819][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,820][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,821][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,821][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:54,822][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9928, 0.0072], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,823][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1003, 0.8997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,825][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.4143e-05, 9.9994e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,826][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.7540e-05, 9.9997e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,828][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0957, 0.9043], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,829][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3072, 0.6928], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,831][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8970, 0.1030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,833][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2430, 0.7570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,833][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3261, 0.6739], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,834][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4330, 0.5670], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,835][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7321, 0.2679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,836][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1475, 0.8525], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:54,838][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.9978, 0.0011, 0.0011], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,839][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0068, 0.0186, 0.9747], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,840][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0009, 0.4204, 0.5787], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,841][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([2.5429e-04, 7.9434e-01, 2.0541e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,841][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2232, 0.7338, 0.0430], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,842][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.1465, 0.4091, 0.4444], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,843][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.6286, 0.2851, 0.0863], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,844][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.1549, 0.7091, 0.1360], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,846][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.2027, 0.5107, 0.2866], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,847][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.1835, 0.5942, 0.2223], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,849][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.5784, 0.3139, 0.1078], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,850][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.2153, 0.4381, 0.3466], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:54,852][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9780, 0.0065, 0.0011, 0.0144], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,854][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0027, 0.0162, 0.9187, 0.0624], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,855][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.2383e-05, 2.0208e-01, 7.6785e-01, 3.0060e-02], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,856][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([8.9465e-06, 3.7149e-01, 3.7569e-01, 2.5281e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,857][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0438, 0.4261, 0.0388, 0.4913], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,858][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0801, 0.2076, 0.3616, 0.3507], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,859][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6091, 0.1008, 0.0498, 0.2403], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,860][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0649, 0.3546, 0.4260, 0.1545], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,860][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1503, 0.3441, 0.2525, 0.2531], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,861][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1768, 0.5699, 0.0962, 0.1571], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,863][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4218, 0.2474, 0.0680, 0.2629], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,865][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0306, 0.4213, 0.4352, 0.1130], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:54,866][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([9.9452e-01, 2.1041e-03, 2.7971e-04, 2.4917e-03, 6.0198e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,867][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([3.9056e-04, 9.4914e-04, 7.3825e-02, 4.3784e-03, 9.2046e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,869][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.0025, 0.2489, 0.4216, 0.0844, 0.2426], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,871][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0007, 0.0827, 0.2099, 0.0844, 0.6222], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,873][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([1.0329e-02, 1.6552e-02, 9.2691e-01, 4.6180e-02, 3.1355e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,874][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.0719, 0.2136, 0.2298, 0.2704, 0.2143], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,876][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.2972, 0.1456, 0.0473, 0.4689, 0.0409], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,878][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.0671, 0.2725, 0.2388, 0.1568, 0.2648], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,880][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.1044, 0.2884, 0.2056, 0.2513, 0.1503], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,881][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.2649, 0.1971, 0.1021, 0.2120, 0.2238], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,881][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.3745, 0.2124, 0.0620, 0.2577, 0.0935], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,882][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.2277, 0.1343, 0.1947, 0.0605, 0.3828], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:54,883][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.7207e-01, 4.3584e-03, 4.3173e-04, 8.6846e-03, 1.0754e-04, 1.4351e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,884][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.1302e-04, 6.5484e-04, 5.1408e-02, 4.3482e-03, 9.1790e-01, 2.5576e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,884][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([5.5353e-05, 8.5807e-02, 2.3454e-01, 1.8970e-02, 1.1625e-01, 5.4438e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,885][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([1.6121e-05, 2.5895e-02, 1.3193e-02, 3.0488e-02, 4.7942e-01, 4.5098e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,887][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0548, 0.0209, 0.7023, 0.0252, 0.1874, 0.0094], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,889][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0385, 0.1064, 0.1782, 0.1974, 0.2295, 0.2500], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,890][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1535, 0.0310, 0.0181, 0.0881, 0.0179, 0.6914], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,892][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0410, 0.2436, 0.1477, 0.1407, 0.3234, 0.1036], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,894][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1002, 0.2427, 0.1762, 0.2013, 0.1327, 0.1468], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,895][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1318, 0.5112, 0.0232, 0.0686, 0.1263, 0.1390], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,897][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3313, 0.1351, 0.0343, 0.1692, 0.0534, 0.2767], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,898][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0467, 0.2478, 0.1148, 0.0583, 0.2991, 0.2333], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:54,899][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.6785e-01, 3.2833e-03, 7.6908e-04, 6.3489e-03, 1.1912e-04, 2.3841e-03,
        1.9242e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,900][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.9729e-04, 7.4927e-04, 6.0874e-02, 3.8631e-03, 8.8575e-01, 2.7781e-02,
        2.0784e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,901][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([5.8105e-06, 3.2143e-02, 1.1084e-01, 1.1195e-02, 5.4654e-02, 7.5683e-01,
        3.4329e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,901][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.3974e-06, 7.9077e-03, 5.7199e-03, 7.2479e-03, 1.1505e-01, 8.0635e-01,
        5.7719e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,902][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0540, 0.0382, 0.1055, 0.0944, 0.0414, 0.3377, 0.3288],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,904][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0365, 0.0908, 0.1576, 0.1388, 0.2083, 0.1988, 0.1692],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,906][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1166, 0.0267, 0.0164, 0.0683, 0.0184, 0.5844, 0.1691],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,908][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0240, 0.1958, 0.1140, 0.1017, 0.2935, 0.1830, 0.0880],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,910][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0839, 0.2029, 0.1504, 0.1740, 0.1432, 0.1530, 0.0925],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,912][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0699, 0.1318, 0.0473, 0.0891, 0.0989, 0.4242, 0.1388],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,913][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1573, 0.1265, 0.0358, 0.1593, 0.0611, 0.2049, 0.2551],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,915][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0172, 0.1081, 0.1262, 0.0328, 0.3351, 0.1945, 0.1860],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:54,917][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([9.6984e-01, 3.3879e-03, 4.2977e-04, 7.0877e-03, 1.5088e-04, 2.7162e-03,
        8.9038e-03, 7.4853e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,917][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([5.0052e-04, 1.0027e-03, 4.4957e-02, 4.0373e-03, 7.0219e-01, 2.1613e-02,
        2.1293e-02, 2.0441e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,918][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([9.3402e-06, 3.3196e-03, 2.1573e-02, 1.9371e-03, 4.6225e-02, 1.6419e-01,
        1.1444e-02, 7.5130e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,919][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([9.3850e-06, 7.9558e-03, 4.8579e-03, 8.8515e-03, 5.0161e-02, 1.8649e-01,
        5.9656e-02, 6.8202e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,919][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0263, 0.0142, 0.1470, 0.0401, 0.6769, 0.0345, 0.0403, 0.0207],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,920][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0244, 0.0676, 0.1078, 0.1504, 0.1108, 0.1923, 0.1803, 0.1665],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,922][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1391, 0.0257, 0.0119, 0.0580, 0.0111, 0.4399, 0.2195, 0.0948],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,924][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0297, 0.1640, 0.1019, 0.1191, 0.1683, 0.2231, 0.0777, 0.1161],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,926][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0753, 0.1855, 0.1229, 0.1621, 0.1195, 0.1429, 0.0844, 0.1073],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,928][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0668, 0.0969, 0.0397, 0.0665, 0.0733, 0.1685, 0.0851, 0.4031],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,930][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2101, 0.1340, 0.0311, 0.1260, 0.0482, 0.1567, 0.1928, 0.1012],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,932][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0042, 0.0060, 0.0074, 0.0036, 0.0593, 0.0106, 0.0271, 0.8818],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:54,933][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([9.6485e-01, 5.2664e-03, 8.7502e-04, 8.9313e-03, 2.4115e-04, 2.8029e-03,
        8.5704e-03, 1.4467e-03, 7.0180e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,934][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([2.7588e-04, 8.9623e-04, 4.8645e-02, 2.8037e-03, 7.1805e-01, 1.9379e-02,
        1.4764e-02, 1.6138e-01, 3.3804e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,935][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([7.2957e-07, 1.5181e-02, 3.6567e-02, 5.5068e-03, 1.2854e-02, 5.5766e-01,
        8.2735e-02, 5.6784e-02, 2.3271e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,936][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.0123e-06, 1.3634e-03, 9.2532e-04, 1.2648e-03, 1.0483e-02, 6.8483e-02,
        1.2603e-02, 7.8541e-01, 1.1947e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,936][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0245, 0.0614, 0.0111, 0.1532, 0.2780, 0.1352, 0.0771, 0.0946, 0.1648],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,937][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0199, 0.0534, 0.1290, 0.1037, 0.1875, 0.1354, 0.1414, 0.1585, 0.0712],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,938][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1745, 0.0154, 0.0097, 0.0371, 0.0098, 0.2774, 0.1135, 0.0816, 0.2811],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,939][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0143, 0.1099, 0.1039, 0.0469, 0.1978, 0.1305, 0.0828, 0.1810, 0.1328],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,941][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0673, 0.1691, 0.1274, 0.1327, 0.1073, 0.1251, 0.0805, 0.0823, 0.1082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,943][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0628, 0.0646, 0.0237, 0.0422, 0.0407, 0.0928, 0.0654, 0.1027, 0.5051],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,944][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1417, 0.0783, 0.0236, 0.0881, 0.0387, 0.1410, 0.1434, 0.0882, 0.2570],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,946][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0021, 0.0236, 0.0339, 0.0086, 0.0859, 0.0464, 0.1145, 0.5649, 0.1203],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:54,947][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([9.8662e-01, 2.2840e-03, 1.7952e-04, 3.4996e-03, 4.9059e-05, 9.2380e-04,
        3.7049e-03, 5.8924e-04, 1.9091e-03, 2.3910e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,949][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([3.8952e-04, 1.0529e-03, 5.3971e-02, 3.2439e-03, 6.8408e-01, 1.5466e-02,
        1.4907e-02, 1.3168e-01, 3.1279e-02, 6.3929e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,950][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([2.4418e-07, 2.4702e-03, 4.8870e-03, 7.1285e-04, 2.4100e-03, 1.1367e-01,
        1.3366e-02, 3.9771e-02, 8.0499e-01, 1.7723e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,951][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([2.7729e-06, 2.3899e-03, 5.1790e-04, 1.7855e-03, 8.1294e-03, 1.9234e-01,
        9.5457e-03, 1.6627e-01, 5.5835e-01, 6.0671e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,953][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0036, 0.0060, 0.2979, 0.0241, 0.4203, 0.0196, 0.0110, 0.0076, 0.1405,
        0.0692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,953][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0267, 0.0761, 0.0963, 0.1250, 0.0980, 0.1756, 0.1307, 0.1318, 0.0714,
        0.0684], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,954][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0255, 0.0109, 0.0039, 0.0296, 0.0037, 0.2941, 0.1707, 0.0541, 0.3932,
        0.0142], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,955][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0187, 0.1036, 0.0548, 0.0711, 0.1012, 0.1280, 0.0778, 0.1236, 0.2580,
        0.0632], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,956][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0580, 0.1437, 0.1065, 0.1246, 0.1001, 0.1065, 0.0666, 0.1063, 0.1344,
        0.0534], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,957][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0072, 0.0211, 0.0025, 0.0080, 0.0037, 0.0632, 0.0227, 0.0991, 0.7040,
        0.0687], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,959][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1328, 0.1011, 0.0233, 0.0852, 0.0352, 0.1125, 0.1317, 0.0760, 0.2216,
        0.0805], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,961][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0024, 0.0069, 0.0087, 0.0030, 0.0518, 0.0151, 0.0795, 0.3760, 0.2487,
        0.2079], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:54,962][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.4250e-01, 6.0898e-03, 6.8970e-04, 9.9767e-03, 6.5007e-05, 2.6897e-03,
        6.4264e-03, 1.2206e-03, 7.3927e-03, 2.0302e-04, 2.2747e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,963][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([2.9995e-04, 9.2168e-04, 5.1814e-02, 2.9449e-03, 6.0941e-01, 1.9816e-02,
        1.4849e-02, 1.6374e-01, 3.4599e-02, 8.1890e-02, 1.9706e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,964][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.1499e-07, 2.0212e-02, 4.8889e-02, 2.8354e-03, 1.3658e-02, 6.5137e-01,
        9.1697e-02, 1.2739e-02, 1.4029e-01, 1.7411e-02, 8.9641e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,966][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0104e-06, 3.7051e-03, 2.7501e-03, 2.1495e-03, 2.4811e-02, 1.2668e-01,
        2.8129e-02, 6.1847e-02, 6.4260e-01, 1.0217e-01, 5.1541e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,968][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0296, 0.0226, 0.0694, 0.0859, 0.1317, 0.0639, 0.0409, 0.1484, 0.1161,
        0.0830, 0.2086], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,969][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0263, 0.0495, 0.1079, 0.0922, 0.1203, 0.1382, 0.1239, 0.1257, 0.0652,
        0.0978, 0.0529], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,971][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0755, 0.0122, 0.0076, 0.0299, 0.0087, 0.2968, 0.1024, 0.0633, 0.2311,
        0.0322, 0.1403], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,972][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0103, 0.0623, 0.0552, 0.0360, 0.0995, 0.1161, 0.0861, 0.1976, 0.1469,
        0.1650, 0.0248], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,972][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0487, 0.1347, 0.0993, 0.1080, 0.0844, 0.1045, 0.0662, 0.0828, 0.1039,
        0.0617, 0.1059], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,973][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0177, 0.0348, 0.0105, 0.0170, 0.0211, 0.0525, 0.0647, 0.0555, 0.4532,
        0.2462, 0.0269], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,974][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0993, 0.0751, 0.0166, 0.0640, 0.0277, 0.0981, 0.0990, 0.0652, 0.1757,
        0.0691, 0.2102], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,975][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([2.4713e-04, 3.9009e-02, 3.0301e-02, 1.2620e-02, 5.8291e-02, 7.8772e-02,
        1.3649e-01, 2.2651e-01, 1.5178e-01, 2.5916e-01, 6.8118e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:54,977][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([9.4947e-01, 3.7969e-03, 1.4730e-03, 7.9410e-03, 1.5166e-04, 2.2648e-03,
        8.3901e-03, 1.8101e-03, 4.9642e-03, 2.6939e-04, 3.4497e-03, 1.6023e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,978][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.0196e-04, 7.1244e-04, 5.9081e-02, 2.7984e-03, 6.2052e-01, 2.0312e-02,
        1.3277e-02, 1.5581e-01, 2.9486e-02, 6.9955e-02, 1.8496e-02, 9.3493e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,980][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.3836e-07, 2.4963e-02, 5.4883e-02, 3.9048e-03, 1.1090e-02, 7.0369e-01,
        1.0408e-01, 4.3688e-03, 8.4186e-02, 5.5094e-03, 2.6575e-03, 6.6130e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,981][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([5.5433e-07, 4.2776e-03, 1.0111e-02, 2.0597e-03, 7.8089e-02, 2.9635e-01,
        3.6862e-02, 1.4422e-01, 1.0778e-01, 1.5147e-01, 1.7027e-02, 1.5175e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,982][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0187, 0.0279, 0.0880, 0.0944, 0.1199, 0.0267, 0.1027, 0.0526, 0.0897,
        0.0571, 0.1083, 0.2138], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,984][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0204, 0.0503, 0.0967, 0.0890, 0.1210, 0.1144, 0.1066, 0.1185, 0.0655,
        0.0691, 0.0502, 0.0983], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,986][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0256, 0.0091, 0.0060, 0.0255, 0.0070, 0.2979, 0.1001, 0.0585, 0.2268,
        0.0336, 0.1704, 0.0395], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,988][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0078, 0.0668, 0.0582, 0.0356, 0.1246, 0.0819, 0.0577, 0.1947, 0.1293,
        0.1253, 0.0385, 0.0795], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,989][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0470, 0.1209, 0.0916, 0.1024, 0.0843, 0.0949, 0.0600, 0.0845, 0.0993,
        0.0591, 0.1105, 0.0453], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,990][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0191, 0.0338, 0.0180, 0.0153, 0.0294, 0.0604, 0.0343, 0.0791, 0.3157,
        0.2209, 0.0829, 0.0911], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,991][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0676, 0.0494, 0.0123, 0.0456, 0.0222, 0.0786, 0.0857, 0.0557, 0.1490,
        0.0670, 0.1842, 0.1827], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,991][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0006, 0.0574, 0.0927, 0.0127, 0.1228, 0.1176, 0.2410, 0.0875, 0.0605,
        0.1822, 0.0094, 0.0157], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:54,992][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.8802e-01, 1.2903e-03, 2.0159e-04, 2.3404e-03, 1.1543e-05, 3.1119e-04,
        1.5720e-03, 2.5446e-04, 1.8039e-03, 2.4137e-05, 1.3432e-03, 2.6662e-03,
        1.6104e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,993][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([3.0997e-04, 6.8765e-04, 4.3469e-02, 1.9332e-03, 5.5245e-01, 1.2161e-02,
        1.0494e-02, 1.0510e-01, 2.1579e-02, 4.5925e-02, 1.4052e-02, 7.4235e-03,
        1.8441e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,995][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([2.1260e-07, 6.1643e-03, 4.2075e-02, 1.2033e-03, 1.6186e-02, 5.7912e-01,
        8.8879e-02, 1.0116e-02, 2.3367e-01, 1.5966e-02, 3.6492e-03, 2.5985e-03,
        3.7001e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,996][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([5.5428e-06, 1.8814e-03, 2.7446e-03, 1.5334e-03, 3.5615e-02, 8.6275e-02,
        2.9056e-02, 1.0382e-01, 3.3492e-01, 1.7022e-01, 8.2036e-03, 1.9714e-01,
        2.8591e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:54,998][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0021, 0.0015, 0.1100, 0.0088, 0.4821, 0.0238, 0.0073, 0.0323, 0.0411,
        0.1668, 0.0561, 0.0090, 0.0591], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,000][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0200, 0.0538, 0.0644, 0.0867, 0.0687, 0.1764, 0.1008, 0.1053, 0.0530,
        0.0602, 0.0494, 0.1052, 0.0563], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,002][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0155, 0.0086, 0.0033, 0.0229, 0.0034, 0.2553, 0.1224, 0.0439, 0.2698,
        0.0148, 0.1895, 0.0439, 0.0068], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,003][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0083, 0.0606, 0.0395, 0.0403, 0.0705, 0.0714, 0.0626, 0.1990, 0.1526,
        0.0698, 0.0704, 0.1218, 0.0333], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,005][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0382, 0.1053, 0.0824, 0.0978, 0.0756, 0.0847, 0.0567, 0.0869, 0.1031,
        0.0561, 0.1154, 0.0432, 0.0545], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,007][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0096, 0.0176, 0.0093, 0.0120, 0.0148, 0.0464, 0.0383, 0.0776, 0.3508,
        0.1831, 0.1016, 0.0971, 0.0418], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,007][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0555, 0.0610, 0.0151, 0.0508, 0.0234, 0.0815, 0.0914, 0.0542, 0.1425,
        0.0561, 0.1824, 0.1390, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,008][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0004, 0.0221, 0.0310, 0.0054, 0.0586, 0.0576, 0.1497, 0.2494, 0.1217,
        0.2499, 0.0157, 0.0278, 0.0108], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,009][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([8.7957e-01, 9.9266e-03, 2.0427e-03, 1.7582e-02, 4.9521e-04, 6.1210e-03,
        1.6489e-02, 2.9681e-03, 8.7060e-03, 6.6896e-04, 7.5335e-03, 2.0052e-02,
        7.9559e-04, 2.7049e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,010][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.5775e-04, 5.7559e-04, 3.8347e-02, 2.5439e-03, 4.7264e-01, 1.4909e-02,
        1.1895e-02, 1.3912e-01, 3.0392e-02, 6.6531e-02, 1.7582e-02, 8.7496e-03,
        1.8408e-01, 1.2371e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,011][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([5.8786e-08, 2.8595e-03, 6.3016e-03, 4.4344e-04, 3.6427e-03, 3.7344e-02,
        4.9842e-03, 1.5373e-01, 5.2446e-01, 1.9133e-01, 5.7032e-03, 3.3796e-03,
        1.6072e-03, 6.4215e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,012][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.4652e-07, 1.9065e-04, 8.6604e-05, 1.7993e-04, 1.3425e-03, 1.1669e-02,
        3.5903e-03, 4.2815e-02, 1.0069e-01, 7.5715e-02, 1.2245e-03, 1.7112e-01,
        1.6723e-02, 5.7466e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,014][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0046, 0.0141, 0.0006, 0.0998, 0.0394, 0.0749, 0.0225, 0.0101, 0.0440,
        0.0177, 0.0848, 0.0329, 0.3178, 0.2369], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,016][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0161, 0.0384, 0.0712, 0.0738, 0.1079, 0.1127, 0.1150, 0.1015, 0.0508,
        0.0712, 0.0389, 0.0963, 0.0637, 0.0425], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,018][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0512, 0.0080, 0.0049, 0.0218, 0.0047, 0.1890, 0.0735, 0.0442, 0.2247,
        0.0188, 0.1520, 0.0390, 0.0094, 0.1587], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,020][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0078, 0.0481, 0.0616, 0.0270, 0.0778, 0.0639, 0.0579, 0.1513, 0.0889,
        0.1202, 0.0376, 0.1346, 0.0933, 0.0300], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,022][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0412, 0.1053, 0.0785, 0.0851, 0.0722, 0.0768, 0.0598, 0.0691, 0.0791,
        0.0463, 0.0927, 0.0444, 0.0664, 0.0830], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,024][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0066, 0.0151, 0.0065, 0.0084, 0.0090, 0.0269, 0.0118, 0.0810, 0.2633,
        0.1869, 0.0409, 0.1374, 0.0527, 0.1533], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,024][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0880, 0.0477, 0.0127, 0.0475, 0.0218, 0.0621, 0.0644, 0.0441, 0.1256,
        0.0458, 0.1181, 0.1209, 0.0425, 0.1589], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,025][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([4.2713e-05, 1.5069e-03, 3.9318e-03, 9.1302e-04, 1.0837e-02, 4.0124e-03,
        7.9009e-03, 2.7583e-01, 9.0299e-02, 5.4052e-01, 5.2151e-03, 1.1886e-02,
        1.8848e-02, 2.8263e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,026][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([9.8997e-01, 8.8281e-04, 8.3324e-04, 9.2700e-04, 1.8240e-05, 4.2123e-04,
        8.5661e-04, 9.5394e-05, 9.6997e-04, 2.1726e-05, 3.7948e-04, 1.5668e-03,
        2.4175e-05, 2.6328e-03, 3.9982e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,027][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([2.5361e-04, 6.1519e-04, 3.6427e-02, 2.3400e-03, 4.1454e-01, 1.6250e-02,
        1.2674e-02, 1.2171e-01, 2.5474e-02, 5.4247e-02, 1.6309e-02, 7.7266e-03,
        2.0587e-01, 1.9849e-02, 6.5714e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,028][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([1.3799e-06, 1.7300e-02, 2.8998e-02, 3.5038e-03, 1.6402e-02, 6.4492e-01,
        6.8336e-02, 1.5620e-02, 1.5689e-01, 1.8992e-02, 2.1339e-03, 1.9762e-03,
        3.7100e-04, 1.7588e-02, 6.9630e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,030][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([3.8774e-06, 1.6300e-03, 4.4501e-04, 3.5630e-04, 2.4991e-02, 2.5846e-02,
        6.6426e-03, 4.6506e-02, 3.9813e-02, 2.7160e-02, 8.6304e-04, 2.3798e-02,
        1.4630e-02, 6.5256e-01, 1.3475e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,032][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0009, 0.0037, 0.0005, 0.0040, 0.4764, 0.0005, 0.0034, 0.0139, 0.0106,
        0.1560, 0.0053, 0.0047, 0.2945, 0.0234, 0.0022], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,033][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0177, 0.0454, 0.0514, 0.0672, 0.0543, 0.1591, 0.0952, 0.1180, 0.0507,
        0.0562, 0.0458, 0.0924, 0.0520, 0.0513, 0.0435], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,035][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0067, 0.0047, 0.0016, 0.0154, 0.0017, 0.2004, 0.1059, 0.0247, 0.2431,
        0.0091, 0.1683, 0.0406, 0.0050, 0.1702, 0.0028], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,037][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0089, 0.0466, 0.0108, 0.0335, 0.0886, 0.1042, 0.0617, 0.1594, 0.1173,
        0.0812, 0.0553, 0.1115, 0.0702, 0.0417, 0.0091], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,039][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0346, 0.0979, 0.0557, 0.0839, 0.0617, 0.0703, 0.0491, 0.0697, 0.0910,
        0.0458, 0.1029, 0.0402, 0.0583, 0.0897, 0.0494], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,041][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0192, 0.0250, 0.0094, 0.0134, 0.0449, 0.0199, 0.0347, 0.0406, 0.2644,
        0.1106, 0.0172, 0.0671, 0.0329, 0.1726, 0.1283], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,042][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0568, 0.0371, 0.0100, 0.0414, 0.0155, 0.0810, 0.0762, 0.0370, 0.1400,
        0.0433, 0.1464, 0.1133, 0.0333, 0.1382, 0.0306], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,043][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0013, 0.0264, 0.0438, 0.0076, 0.0901, 0.1068, 0.1578, 0.1429, 0.0955,
        0.1805, 0.0100, 0.0301, 0.0445, 0.0412, 0.0215], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,044][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.7039e-01, 2.7173e-03, 2.1708e-04, 4.9176e-03, 9.1011e-05, 1.7226e-03,
        4.7724e-03, 6.2205e-04, 2.7165e-03, 1.2689e-04, 1.6878e-03, 2.9755e-03,
        7.9984e-05, 6.0671e-03, 1.3040e-04, 7.6499e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,045][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([8.3479e-05, 3.6440e-04, 3.5090e-02, 1.4877e-03, 4.7806e-01, 1.0936e-02,
        8.2674e-03, 1.1508e-01, 1.7419e-02, 4.0460e-02, 1.0167e-02, 4.9905e-03,
        1.6751e-01, 1.1014e-02, 7.2751e-02, 2.6315e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,046][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.5598e-06, 2.8811e-02, 7.0029e-02, 3.8086e-03, 1.9808e-02, 4.6868e-01,
        1.8016e-01, 1.3751e-02, 1.3725e-01, 1.7621e-02, 3.5712e-03, 3.2818e-03,
        3.4713e-04, 1.9203e-02, 1.3190e-02, 2.0483e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,047][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.9930e-06, 1.5782e-04, 5.5687e-05, 5.9236e-05, 9.0207e-04, 1.1231e-03,
        4.9502e-04, 9.8487e-04, 1.2260e-02, 4.0225e-03, 1.4944e-04, 7.2328e-03,
        1.4191e-03, 6.4385e-02, 3.9820e-02, 8.6693e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,049][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0073, 0.0075, 0.0419, 0.0084, 0.0108, 0.0104, 0.0114, 0.0397, 0.0130,
        0.1691, 0.0215, 0.0371, 0.4508, 0.0306, 0.1374, 0.0029],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,050][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0143, 0.0430, 0.0591, 0.0768, 0.0713, 0.1051, 0.0782, 0.0726, 0.0514,
        0.0474, 0.0460, 0.0869, 0.0613, 0.0539, 0.0452, 0.0873],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,052][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0356, 0.0076, 0.0041, 0.0187, 0.0044, 0.1523, 0.0777, 0.0419, 0.1720,
        0.0160, 0.1145, 0.0250, 0.0086, 0.1667, 0.0063, 0.1485],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,054][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0078, 0.0527, 0.0384, 0.0303, 0.0512, 0.0379, 0.0751, 0.1541, 0.1211,
        0.0936, 0.0496, 0.1287, 0.0643, 0.0407, 0.0320, 0.0224],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,056][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0363, 0.0890, 0.0642, 0.0777, 0.0543, 0.0702, 0.0425, 0.0661, 0.0809,
        0.0467, 0.0861, 0.0363, 0.0662, 0.0833, 0.0584, 0.0419],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,058][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0790, 0.0543, 0.0051, 0.0096, 0.0155, 0.0436, 0.0233, 0.0251, 0.1472,
        0.0856, 0.0384, 0.0749, 0.0259, 0.1932, 0.0820, 0.0972],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,059][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0767, 0.0395, 0.0087, 0.0346, 0.0128, 0.0593, 0.0707, 0.0379, 0.1090,
        0.0364, 0.1309, 0.0922, 0.0288, 0.1303, 0.0245, 0.1075],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,060][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0013, 0.0685, 0.0341, 0.0150, 0.0423, 0.0670, 0.1596, 0.1788, 0.1302,
        0.1553, 0.0109, 0.0175, 0.0161, 0.0540, 0.0117, 0.0378],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,061][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.3372e-01, 2.9778e-03, 7.9393e-04, 6.2309e-03, 9.3684e-05, 2.0729e-03,
        1.8806e-02, 1.1403e-03, 4.3741e-03, 2.3560e-04, 3.4194e-03, 7.7773e-03,
        1.9751e-04, 9.6120e-03, 4.3756e-04, 2.4858e-04, 7.8634e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,062][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.2386e-04, 4.0060e-04, 3.2989e-02, 1.5628e-03, 4.5356e-01, 1.1929e-02,
        8.0836e-03, 1.1956e-01, 1.9534e-02, 4.6917e-02, 9.9856e-03, 5.0500e-03,
        1.7176e-01, 1.0468e-02, 6.8988e-02, 2.9543e-02, 9.5527e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,063][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.1102e-07, 2.1548e-02, 5.2636e-02, 3.5205e-03, 1.5152e-02, 6.3910e-01,
        3.5149e-02, 1.6026e-02, 1.3403e-01, 1.3347e-02, 2.1259e-03, 8.0571e-04,
        3.9701e-04, 1.6199e-02, 7.2157e-03, 3.5558e-02, 7.1933e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,064][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.0576e-08, 6.7394e-06, 2.3852e-06, 2.0668e-06, 5.6493e-05, 3.9709e-04,
        2.5273e-05, 1.3778e-03, 3.4500e-04, 4.4524e-04, 1.7753e-05, 2.7213e-04,
        2.8283e-04, 5.7889e-03, 2.3212e-03, 9.6374e-01, 2.4914e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,066][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0151, 0.0105, 0.0182, 0.0195, 0.0109, 0.0696, 0.0709, 0.0871, 0.0363,
        0.0151, 0.1371, 0.0965, 0.1459, 0.0736, 0.0387, 0.0277, 0.1271],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,068][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0161, 0.0374, 0.0633, 0.0591, 0.0859, 0.0820, 0.0722, 0.0916, 0.0445,
        0.0513, 0.0384, 0.0810, 0.0483, 0.0491, 0.0541, 0.0746, 0.0510],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,070][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0266, 0.0076, 0.0052, 0.0189, 0.0068, 0.1508, 0.0398, 0.0420, 0.1381,
        0.0238, 0.0815, 0.0181, 0.0125, 0.1389, 0.0075, 0.1780, 0.1041],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,071][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0063, 0.0530, 0.0317, 0.0302, 0.0821, 0.0561, 0.0245, 0.1098, 0.1155,
        0.0907, 0.0429, 0.1045, 0.0919, 0.0615, 0.0332, 0.0518, 0.0143],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,074][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0332, 0.0829, 0.0637, 0.0742, 0.0610, 0.0650, 0.0389, 0.0655, 0.0768,
        0.0460, 0.0820, 0.0342, 0.0569, 0.0804, 0.0609, 0.0478, 0.0306],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,075][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0072, 0.0054, 0.0019, 0.0025, 0.0032, 0.0146, 0.0045, 0.0181, 0.0640,
        0.0430, 0.0138, 0.0183, 0.0293, 0.0503, 0.0400, 0.5726, 0.1114],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,077][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0265, 0.0371, 0.0090, 0.0329, 0.0164, 0.0429, 0.0501, 0.0373, 0.0843,
        0.0444, 0.1078, 0.1122, 0.0366, 0.1224, 0.0325, 0.0990, 0.1088],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,078][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0004, 0.0328, 0.0388, 0.0076, 0.0507, 0.0611, 0.0525, 0.2248, 0.0853,
        0.2723, 0.0056, 0.0110, 0.0143, 0.0352, 0.0130, 0.0621, 0.0326],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,079][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([9.8966e-01, 1.1345e-03, 1.2729e-04, 1.6374e-03, 1.8912e-05, 4.7245e-04,
        1.3787e-03, 1.6057e-04, 7.6905e-04, 4.0324e-05, 6.0095e-04, 1.1927e-03,
        2.5760e-05, 2.1058e-03, 6.5594e-05, 3.4431e-05, 4.1453e-04, 1.6292e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,080][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([2.0560e-04, 2.7964e-04, 1.6383e-02, 8.9719e-04, 2.0076e-01, 5.0019e-03,
        5.4541e-03, 5.8055e-02, 1.3321e-02, 3.0098e-02, 9.2174e-03, 4.2894e-03,
        1.1180e-01, 9.5460e-03, 3.6910e-02, 1.8771e-02, 9.0067e-03, 4.7001e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,081][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([1.5275e-06, 8.8752e-03, 1.7706e-02, 2.2034e-03, 1.1194e-02, 3.9668e-01,
        6.1870e-02, 3.3972e-02, 3.1091e-01, 2.1521e-02, 2.2012e-03, 1.2183e-03,
        2.2762e-04, 5.3717e-02, 5.5062e-03, 3.8752e-02, 2.3332e-02, 1.0110e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,082][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([1.0737e-06, 1.0270e-05, 1.0088e-06, 3.1746e-06, 2.5517e-05, 3.0754e-04,
        6.1010e-05, 9.7435e-04, 1.1238e-03, 4.1768e-04, 1.4806e-05, 3.5142e-04,
        1.5948e-04, 1.2015e-02, 6.4278e-04, 7.2696e-01, 3.7583e-02, 2.1935e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,084][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([2.1507e-04, 2.7018e-03, 5.3945e-02, 3.7928e-03, 9.5313e-02, 2.2497e-03,
        1.3166e-03, 1.3348e-03, 2.9299e-02, 4.1273e-01, 8.2877e-03, 2.1735e-03,
        1.2879e-01, 1.6824e-02, 2.1035e-01, 5.9245e-03, 2.3079e-03, 2.2439e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,086][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.0122, 0.0353, 0.0536, 0.0691, 0.0544, 0.1006, 0.0659, 0.0613, 0.0411,
        0.0451, 0.0326, 0.0808, 0.0520, 0.0453, 0.0437, 0.0994, 0.0471, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,087][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0076, 0.0038, 0.0013, 0.0112, 0.0012, 0.1301, 0.0815, 0.0226, 0.1630,
        0.0058, 0.0897, 0.0211, 0.0027, 0.1386, 0.0021, 0.1255, 0.1844, 0.0076],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,089][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0036, 0.0428, 0.0209, 0.0311, 0.0371, 0.0874, 0.0422, 0.1291, 0.1559,
        0.0667, 0.0589, 0.1065, 0.0697, 0.0417, 0.0192, 0.0489, 0.0214, 0.0169],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,091][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.0278, 0.0843, 0.0608, 0.0714, 0.0565, 0.0681, 0.0377, 0.0618, 0.0778,
        0.0428, 0.0804, 0.0306, 0.0524, 0.0809, 0.0542, 0.0492, 0.0277, 0.0356],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,093][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0192, 0.0061, 0.0020, 0.0029, 0.0029, 0.0203, 0.0069, 0.0240, 0.0677,
        0.0373, 0.0191, 0.0232, 0.0196, 0.0988, 0.0486, 0.3620, 0.1680, 0.0712],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,095][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0268, 0.0380, 0.0074, 0.0326, 0.0116, 0.0528, 0.0636, 0.0293, 0.0984,
        0.0295, 0.1260, 0.0944, 0.0226, 0.1254, 0.0207, 0.0929, 0.1099, 0.0181],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,096][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0009, 0.0157, 0.0118, 0.0047, 0.0432, 0.0328, 0.0796, 0.2314, 0.1305,
        0.2246, 0.0054, 0.0097, 0.0065, 0.0489, 0.0066, 0.0398, 0.0564, 0.0515],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,097][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.4133e-01, 3.8870e-03, 8.2077e-04, 6.8221e-03, 7.4135e-05, 2.0984e-03,
        5.8854e-03, 7.7235e-04, 5.1338e-03, 1.8994e-04, 4.2629e-03, 7.7343e-03,
        3.0442e-04, 1.2859e-02, 5.0024e-04, 3.2955e-04, 2.5350e-03, 2.2028e-04,
        4.2365e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,098][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.8985e-05, 2.0203e-04, 1.1505e-02, 6.0297e-04, 2.5150e-01, 4.5771e-03,
        3.9228e-03, 6.8177e-02, 1.0655e-02, 2.4882e-02, 5.1188e-03, 2.7073e-03,
        8.9587e-02, 5.2935e-03, 2.5492e-02, 1.3325e-02, 4.7217e-03, 4.5866e-01,
        1.9006e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,099][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.8787e-07, 1.2386e-02, 4.2983e-02, 1.9492e-03, 1.3684e-02, 4.3549e-01,
        7.3484e-02, 7.3818e-02, 1.7735e-01, 3.2828e-02, 1.5700e-03, 8.0811e-04,
        3.2986e-04, 3.2559e-02, 8.2100e-03, 3.9781e-02, 1.6264e-02, 2.4480e-02,
        1.2032e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,100][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.4951e-08, 9.5424e-07, 1.9286e-07, 5.8850e-07, 3.6320e-06, 1.1105e-04,
        2.2981e-05, 2.8455e-04, 3.2178e-04, 3.7178e-04, 2.2232e-06, 1.2036e-04,
        9.5971e-05, 3.1110e-03, 2.8657e-04, 2.5022e-01, 2.2661e-02, 7.1722e-01,
        5.1635e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,102][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0047, 0.0096, 0.0015, 0.0187, 0.0201, 0.1307, 0.0148, 0.0095, 0.0344,
        0.0224, 0.1308, 0.0280, 0.1201, 0.1405, 0.0051, 0.0529, 0.0307, 0.1126,
        0.1130], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,104][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0136, 0.0314, 0.0529, 0.0520, 0.0725, 0.0854, 0.0734, 0.0811, 0.0388,
        0.0508, 0.0286, 0.0720, 0.0385, 0.0396, 0.0444, 0.0867, 0.0488, 0.0700,
        0.0195], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,105][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0532, 0.0076, 0.0040, 0.0162, 0.0046, 0.1241, 0.0460, 0.0379, 0.1115,
        0.0163, 0.0707, 0.0164, 0.0079, 0.1162, 0.0051, 0.1174, 0.1070, 0.0233,
        0.1144], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,108][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0044, 0.0394, 0.0358, 0.0201, 0.0712, 0.0460, 0.0493, 0.1315, 0.0817,
        0.0895, 0.0223, 0.1213, 0.0886, 0.0312, 0.0315, 0.0451, 0.0293, 0.0565,
        0.0052], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,110][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0284, 0.0783, 0.0594, 0.0677, 0.0558, 0.0649, 0.0396, 0.0543, 0.0661,
        0.0402, 0.0654, 0.0338, 0.0540, 0.0688, 0.0550, 0.0448, 0.0307, 0.0469,
        0.0462], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,112][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0078, 0.0074, 0.0018, 0.0028, 0.0035, 0.0109, 0.0067, 0.0179, 0.0562,
        0.0289, 0.0033, 0.0174, 0.0169, 0.0663, 0.0388, 0.3279, 0.1552, 0.1399,
        0.0903], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,113][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0292, 0.0375, 0.0069, 0.0285, 0.0121, 0.0440, 0.0465, 0.0291, 0.0788,
        0.0304, 0.1034, 0.0930, 0.0260, 0.1086, 0.0210, 0.0939, 0.0926, 0.0192,
        0.0995], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,114][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.7722e-04, 1.4623e-02, 1.0381e-02, 3.8909e-03, 2.4743e-02, 2.6351e-02,
        4.8118e-02, 3.0936e-01, 6.5190e-02, 2.7905e-01, 2.7809e-03, 4.6104e-03,
        5.8063e-03, 3.3918e-02, 3.9166e-03, 2.7195e-02, 2.5663e-02, 1.0289e-01,
        1.1346e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,118][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:55,120][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21206],
        [ 2393],
        [ 5816],
        [12380],
        [  441],
        [ 7398],
        [16479],
        [ 7904],
        [ 5230],
        [ 8046],
        [ 4242],
        [ 7459],
        [ 4195],
        [ 5796],
        [ 6894],
        [ 7482],
        [17102],
        [12097],
        [ 6206]], device='cuda:0')
[2024-07-24 10:18:55,122][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[20288],
        [ 6501],
        [ 8487],
        [14409],
        [  641],
        [ 9900],
        [17143],
        [15994],
        [15597],
        [17456],
        [ 8180],
        [11690],
        [18492],
        [10867],
        [11457],
        [14667],
        [18318],
        [25997],
        [11371]], device='cuda:0')
[2024-07-24 10:18:55,124][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[31398],
        [32646],
        [32070],
        [32072],
        [33961],
        [39053],
        [35224],
        [39876],
        [32714],
        [32210],
        [33364],
        [34213],
        [33441],
        [36036],
        [32951],
        [34003],
        [36525],
        [36833],
        [34628]], device='cuda:0')
[2024-07-24 10:18:55,126][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23740],
        [23897],
        [28924],
        [34608],
        [28564],
        [25639],
        [40924],
        [37486],
        [40725],
        [32533],
        [32960],
        [37094],
        [33234],
        [37225],
        [33846],
        [33856],
        [41465],
        [42002],
        [42156]], device='cuda:0')
[2024-07-24 10:18:55,128][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11705],
        [ 7189],
        [13372],
        [12081],
        [17898],
        [17701],
        [17937],
        [14684],
        [16082],
        [13821],
        [15663],
        [16853],
        [14326],
        [16110],
        [13340],
        [15728],
        [17560],
        [13794],
        [17247]], device='cuda:0')
[2024-07-24 10:18:55,130][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11440],
        [ 8058],
        [ 8963],
        [ 8943],
        [ 7070],
        [12333],
        [12690],
        [12806],
        [12666],
        [15350],
        [12694],
        [11929],
        [14443],
        [13231],
        [15083],
        [13002],
        [13542],
        [13869],
        [14488]], device='cuda:0')
[2024-07-24 10:18:55,133][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[40649],
        [37869],
        [39357],
        [39185],
        [39775],
        [40971],
        [40888],
        [40452],
        [40293],
        [39888],
        [39973],
        [39821],
        [39849],
        [39444],
        [39446],
        [39232],
        [39177],
        [38998],
        [39128]], device='cuda:0')
[2024-07-24 10:18:55,134][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38270],
        [38446],
        [37759],
        [38295],
        [37966],
        [37647],
        [37395],
        [37127],
        [36826],
        [36539],
        [36352],
        [36336],
        [36318],
        [36388],
        [36425],
        [36298],
        [36260],
        [36207],
        [36245]], device='cuda:0')
[2024-07-24 10:18:55,136][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25641],
        [14493],
        [11533],
        [10611],
        [ 9942],
        [ 6771],
        [ 5989],
        [ 5278],
        [ 4822],
        [ 4359],
        [ 4234],
        [ 4153],
        [ 4247],
        [ 4301],
        [ 4272],
        [ 4211],
        [ 4189],
        [ 4174],
        [ 4269]], device='cuda:0')
[2024-07-24 10:18:55,137][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28432],
        [34646],
        [28839],
        [29092],
        [29512],
        [29198],
        [29238],
        [28291],
        [28271],
        [27587],
        [27970],
        [28517],
        [27760],
        [28085],
        [27492],
        [28142],
        [28870],
        [28010],
        [28711]], device='cuda:0')
[2024-07-24 10:18:55,139][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[43745],
        [41602],
        [40764],
        [40475],
        [40241],
        [39881],
        [39827],
        [39901],
        [39910],
        [39892],
        [39836],
        [39726],
        [39622],
        [39560],
        [39465],
        [39300],
        [39313],
        [39375],
        [39435]], device='cuda:0')
[2024-07-24 10:18:55,141][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 7114],
        [18163],
        [33291],
        [33900],
        [31151],
        [37698],
        [39843],
        [29658],
        [33136],
        [33430],
        [30135],
        [34403],
        [36196],
        [25900],
        [26962],
        [28456],
        [39589],
        [35343],
        [35040]], device='cuda:0')
[2024-07-24 10:18:55,143][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31199],
        [24850],
        [33295],
        [28721],
        [42823],
        [34546],
        [36751],
        [37327],
        [35348],
        [38570],
        [32296],
        [34472],
        [38364],
        [31242],
        [37344],
        [28572],
        [30653],
        [26073],
        [22952]], device='cuda:0')
[2024-07-24 10:18:55,145][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25659],
        [22215],
        [20798],
        [19648],
        [20737],
        [20244],
        [20034],
        [20000],
        [19735],
        [20652],
        [20888],
        [20636],
        [20798],
        [20181],
        [19901],
        [19456],
        [19092],
        [19046],
        [18769]], device='cuda:0')
[2024-07-24 10:18:55,148][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25421],
        [25074],
        [27478],
        [27574],
        [38605],
        [14943],
        [19883],
        [17530],
        [ 7749],
        [20314],
        [19152],
        [12660],
        [ 7270],
        [13044],
        [28578],
        [ 8969],
        [14370],
        [11943],
        [17119]], device='cuda:0')
[2024-07-24 10:18:55,150][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29168],
        [29206],
        [29183],
        [29322],
        [29212],
        [29406],
        [29538],
        [29534],
        [29431],
        [29285],
        [29875],
        [29618],
        [29287],
        [30001],
        [29251],
        [29407],
        [29796],
        [29265],
        [29603]], device='cuda:0')
[2024-07-24 10:18:55,152][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13359],
        [10680],
        [13380],
        [12792],
        [14924],
        [14973],
        [14935],
        [16334],
        [16328],
        [16383],
        [16842],
        [16741],
        [17226],
        [17635],
        [17372],
        [17188],
        [17339],
        [15417],
        [15303]], device='cuda:0')
[2024-07-24 10:18:55,153][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37215],
        [31078],
        [34590],
        [34604],
        [38316],
        [27151],
        [20996],
        [36125],
        [33016],
        [44957],
        [26641],
        [23217],
        [31908],
        [45997],
        [27755],
        [30677],
        [26142],
        [39000],
        [34319]], device='cuda:0')
[2024-07-24 10:18:55,155][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18558],
        [14526],
        [16980],
        [16296],
        [15130],
        [21552],
        [27616],
        [21184],
        [19807],
        [18548],
        [16542],
        [21777],
        [19293],
        [18359],
        [16860],
        [33820],
        [33881],
        [35678],
        [36965]], device='cuda:0')
[2024-07-24 10:18:55,157][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[33928],
        [24676],
        [26546],
        [ 8641],
        [ 4941],
        [ 3780],
        [32642],
        [ 2751],
        [14000],
        [ 4594],
        [22055],
        [14287],
        [ 5038],
        [15624],
        [ 5274],
        [12416],
        [23107],
        [ 8604],
        [24705]], device='cuda:0')
[2024-07-24 10:18:55,159][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[26359],
        [33078],
        [34597],
        [37118],
        [34024],
        [30077],
        [28709],
        [29406],
        [29396],
        [30251],
        [30483],
        [30268],
        [29300],
        [29759],
        [30242],
        [30977],
        [30765],
        [29840],
        [29448]], device='cuda:0')
[2024-07-24 10:18:55,161][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[41277],
        [38285],
        [19430],
        [19181],
        [10746],
        [15169],
        [15250],
        [13981],
        [17377],
        [18745],
        [17711],
        [17686],
        [18616],
        [17246],
        [18057],
        [16639],
        [16469],
        [17860],
        [16014]], device='cuda:0')
[2024-07-24 10:18:55,163][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22660],
        [23684],
        [24253],
        [25569],
        [25612],
        [25117],
        [24760],
        [24875],
        [26270],
        [26668],
        [27433],
        [27137],
        [27082],
        [27081],
        [26795],
        [27158],
        [27097],
        [27037],
        [27180]], device='cuda:0')
[2024-07-24 10:18:55,165][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15882],
        [20240],
        [18429],
        [19579],
        [19416],
        [19500],
        [19563],
        [19808],
        [20820],
        [21154],
        [22389],
        [22671],
        [22800],
        [22624],
        [22789],
        [21896],
        [21652],
        [21920],
        [21747]], device='cuda:0')
[2024-07-24 10:18:55,167][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[15603],
        [12293],
        [14864],
        [14805],
        [13816],
        [16209],
        [28465],
        [ 9216],
        [12937],
        [12561],
        [13675],
        [13357],
        [12884],
        [10947],
        [13350],
        [14595],
        [18021],
        [14333],
        [14282]], device='cuda:0')
[2024-07-24 10:18:55,169][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[27821],
        [39822],
        [40195],
        [39664],
        [39635],
        [37616],
        [38060],
        [37756],
        [36972],
        [37065],
        [36437],
        [36771],
        [37145],
        [37023],
        [36888],
        [36444],
        [36807],
        [36695],
        [36618]], device='cuda:0')
[2024-07-24 10:18:55,171][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9227],
        [7281],
        [6790],
        [7476],
        [7299],
        [5048],
        [2874],
        [6570],
        [3555],
        [2543],
        [1957],
        [1929],
        [1968],
        [3618],
        [2193],
        [2488],
        [2074],
        [2165],
        [2136]], device='cuda:0')
[2024-07-24 10:18:55,173][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21680],
        [22494],
        [23714],
        [24139],
        [27244],
        [28768],
        [23973],
        [29686],
        [27082],
        [28798],
        [28366],
        [29115],
        [31722],
        [25129],
        [32970],
        [29219],
        [27234],
        [27865],
        [25627]], device='cuda:0')
[2024-07-24 10:18:55,174][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[42210],
        [38450],
        [32049],
        [36179],
        [22560],
        [38172],
        [35918],
        [28940],
        [40934],
        [27303],
        [34060],
        [39638],
        [26921],
        [35364],
        [19442],
        [30074],
        [30000],
        [27011],
        [28907]], device='cuda:0')
[2024-07-24 10:18:55,176][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607],
        [40607]], device='cuda:0')
[2024-07-24 10:18:55,219][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:55,220][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,221][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,221][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,222][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,223][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,223][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,224][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,225][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,225][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,226][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,226][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,227][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,228][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6150, 0.3850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,228][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0989, 0.9011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,229][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7132, 0.2868], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,230][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1213, 0.8787], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,231][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8642, 0.1358], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,233][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8695, 0.1305], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,235][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7700, 0.2300], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,236][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6206, 0.3794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,238][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5186, 0.4814], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,240][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3352, 0.6648], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,242][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2811, 0.7189], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,243][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0256, 0.9744], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,244][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.1493, 0.5440, 0.3067], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,245][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0146, 0.2079, 0.7775], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,245][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.4510, 0.3327, 0.2162], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,246][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0728, 0.4926, 0.4346], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,247][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.9623, 0.0361, 0.0015], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,248][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.2928, 0.0730, 0.6342], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,250][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.2720, 0.7157, 0.0122], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,251][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.4572, 0.2742, 0.2686], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,253][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.3566, 0.2932, 0.3502], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,254][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.2107, 0.4373, 0.3521], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,256][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.2324, 0.5556, 0.2120], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,258][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([1.5177e-05, 9.9995e-01, 3.3393e-05], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,259][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1615, 0.4874, 0.2066, 0.1445], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,261][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0111, 0.1087, 0.7416, 0.1386], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,262][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4268, 0.3210, 0.1958, 0.0564], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,262][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0451, 0.3611, 0.3187, 0.2751], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,263][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8189, 0.0618, 0.0073, 0.1121], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,264][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1756, 0.0740, 0.6721, 0.0783], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,264][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3349, 0.3475, 0.2897, 0.0280], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,266][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3615, 0.2165, 0.2108, 0.2112], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,267][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2528, 0.2219, 0.2539, 0.2714], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,269][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1547, 0.3239, 0.2536, 0.2677], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,271][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1678, 0.3575, 0.1978, 0.2769], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,272][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.1678e-02, 5.4980e-01, 4.0713e-05, 4.3848e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,274][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.1795, 0.1897, 0.1161, 0.0741, 0.4406], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,276][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0111, 0.1152, 0.4773, 0.1706, 0.2258], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,278][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.1980, 0.1424, 0.5456, 0.0628, 0.0511], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,279][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.0520, 0.2948, 0.2466, 0.2083, 0.1982], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,280][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.7879, 0.0687, 0.0094, 0.0977, 0.0363], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,280][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.1093, 0.0352, 0.3848, 0.2704, 0.2003], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,281][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.1682, 0.5518, 0.1768, 0.0905, 0.0126], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,282][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.2931, 0.1748, 0.1700, 0.1717, 0.1904], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,283][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.2015, 0.1723, 0.2069, 0.2093, 0.2101], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,285][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.1092, 0.2531, 0.2011, 0.2113, 0.2252], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,286][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.1004, 0.2224, 0.0764, 0.1502, 0.4506], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,288][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([2.4277e-08, 9.5908e-01, 8.8018e-05, 3.8689e-02, 2.1466e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,289][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1426, 0.1770, 0.0953, 0.0637, 0.3887, 0.1327], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,290][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0053, 0.0644, 0.4240, 0.1132, 0.1537, 0.2393], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,292][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3050, 0.3083, 0.1357, 0.1612, 0.0333, 0.0565], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,294][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0284, 0.2226, 0.2084, 0.1770, 0.1806, 0.1830], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,296][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8628, 0.0440, 0.0029, 0.0606, 0.0166, 0.0131], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,297][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0171, 0.0048, 0.1608, 0.1047, 0.7056, 0.0071], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,298][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2138, 0.3587, 0.1666, 0.1136, 0.1394, 0.0079], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,299][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2554, 0.1496, 0.1449, 0.1453, 0.1593, 0.1454], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,299][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1648, 0.1420, 0.1646, 0.1704, 0.1660, 0.1922], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,300][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0916, 0.2011, 0.1513, 0.1699, 0.1748, 0.2114], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,301][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1286, 0.2095, 0.0899, 0.1130, 0.2935, 0.1655], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,302][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.1347e-08, 8.7587e-02, 8.1482e-04, 4.0724e-01, 4.9939e-01, 4.9753e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,304][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0276, 0.1348, 0.0652, 0.0532, 0.2124, 0.3540, 0.1526],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,305][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0026, 0.0514, 0.3365, 0.0759, 0.1456, 0.2170, 0.1710],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,307][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3382, 0.2358, 0.1268, 0.0647, 0.0515, 0.1059, 0.0772],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,308][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0257, 0.1908, 0.1853, 0.1482, 0.1546, 0.1522, 0.1433],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,311][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8642, 0.0374, 0.0022, 0.0544, 0.0141, 0.0113, 0.0164],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,313][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0106, 0.0047, 0.2145, 0.0320, 0.7288, 0.0051, 0.0044],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,314][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1974, 0.3676, 0.1745, 0.1153, 0.0822, 0.0465, 0.0165],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,315][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2287, 0.1300, 0.1257, 0.1260, 0.1384, 0.1265, 0.1247],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,316][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1457, 0.1226, 0.1382, 0.1450, 0.1407, 0.1597, 0.1481],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,317][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0768, 0.1689, 0.1335, 0.1412, 0.1552, 0.1821, 0.1423],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,317][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0784, 0.1598, 0.0772, 0.1017, 0.2509, 0.1288, 0.2032],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,318][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.4027e-11, 2.0424e-01, 2.1973e-04, 4.8106e-01, 3.0989e-01, 4.4611e-03,
        1.3041e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,319][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0465, 0.0387, 0.0188, 0.0216, 0.1040, 0.1231, 0.0557, 0.5916],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,321][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0051, 0.0526, 0.2122, 0.0769, 0.1232, 0.1664, 0.1947, 0.1689],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,323][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.3358, 0.1239, 0.0986, 0.0649, 0.0395, 0.0484, 0.0671, 0.2217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,325][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0219, 0.1800, 0.1655, 0.1234, 0.1231, 0.1183, 0.1059, 0.1619],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,326][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.7749, 0.0641, 0.0046, 0.0755, 0.0222, 0.0172, 0.0227, 0.0187],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,328][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0347, 0.0096, 0.3688, 0.1530, 0.3033, 0.0120, 0.0515, 0.0671],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,330][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1356, 0.3292, 0.1605, 0.0851, 0.0830, 0.0728, 0.0887, 0.0451],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,332][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1932, 0.1141, 0.1120, 0.1101, 0.1229, 0.1107, 0.1093, 0.1277],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,333][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1260, 0.1045, 0.1187, 0.1226, 0.1206, 0.1354, 0.1261, 0.1461],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,334][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0648, 0.1502, 0.1113, 0.1261, 0.1328, 0.1570, 0.1355, 0.1224],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,334][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0834, 0.1152, 0.0385, 0.0922, 0.1466, 0.0973, 0.1817, 0.2450],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,335][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([4.4096e-11, 8.3700e-03, 3.2981e-05, 7.9712e-01, 1.9248e-01, 1.1526e-03,
        2.9626e-05, 8.1161e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,336][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0928, 0.0758, 0.0345, 0.0226, 0.1205, 0.1314, 0.1085, 0.1283, 0.2855],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,337][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0022, 0.0305, 0.2329, 0.0441, 0.0917, 0.1244, 0.1320, 0.2392, 0.1030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,339][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2736, 0.2249, 0.1573, 0.0513, 0.0205, 0.0415, 0.0325, 0.1116, 0.0868],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,341][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0217, 0.1396, 0.1314, 0.1086, 0.1090, 0.1135, 0.1079, 0.1542, 0.1142],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,343][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.5871, 0.0582, 0.0095, 0.0982, 0.0360, 0.0315, 0.0363, 0.0275, 0.1156],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,344][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0156, 0.0041, 0.1822, 0.0663, 0.5618, 0.0045, 0.0406, 0.1205, 0.0043],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,346][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1964, 0.1873, 0.0472, 0.1085, 0.1351, 0.0684, 0.1619, 0.0682, 0.0269],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,348][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1739, 0.1007, 0.0983, 0.0979, 0.1086, 0.0992, 0.0978, 0.1130, 0.1105],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,349][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1075, 0.0917, 0.1041, 0.1100, 0.1057, 0.1201, 0.1117, 0.1302, 0.1190],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,351][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0595, 0.1346, 0.1019, 0.1099, 0.1186, 0.1438, 0.1182, 0.1099, 0.1037],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,352][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0662, 0.1285, 0.0778, 0.0903, 0.1600, 0.0940, 0.1224, 0.1651, 0.0957],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,352][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.0670e-07, 6.4913e-04, 2.2716e-06, 4.8278e-03, 9.4749e-01, 9.8738e-04,
        1.7568e-04, 2.4439e-04, 4.5625e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,353][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0449, 0.0215, 0.0126, 0.0095, 0.0430, 0.0736, 0.0457, 0.0962, 0.3873,
        0.2656], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,354][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0025, 0.0267, 0.1415, 0.0405, 0.0704, 0.0897, 0.0986, 0.1607, 0.1371,
        0.2321], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,355][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2400, 0.1198, 0.0668, 0.0631, 0.1048, 0.0970, 0.0676, 0.0775, 0.0633,
        0.1001], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,357][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0137, 0.1202, 0.1216, 0.0971, 0.1020, 0.0996, 0.0924, 0.1345, 0.1001,
        0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,359][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.5899, 0.0654, 0.0070, 0.0813, 0.0277, 0.0212, 0.0257, 0.0233, 0.1072,
        0.0514], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,361][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0183, 0.0018, 0.2741, 0.0479, 0.4567, 0.0120, 0.0120, 0.0701, 0.0862,
        0.0210], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,362][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1860, 0.1237, 0.3392, 0.0662, 0.0238, 0.0374, 0.0260, 0.0411, 0.1506,
        0.0059], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,364][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.1575, 0.0911, 0.0885, 0.0872, 0.0979, 0.0889, 0.0868, 0.1008, 0.0978,
        0.1035], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,366][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1023, 0.0827, 0.0909, 0.0960, 0.0925, 0.1039, 0.0985, 0.1146, 0.1073,
        0.1114], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,368][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0563, 0.1211, 0.0885, 0.0998, 0.1104, 0.1311, 0.1144, 0.1033, 0.0961,
        0.0790], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,369][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0349, 0.1100, 0.0480, 0.1031, 0.1577, 0.0840, 0.1192, 0.1390, 0.1058,
        0.0983], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,369][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([1.1128e-11, 9.2314e-03, 4.0365e-05, 9.9375e-02, 2.8624e-01, 1.1675e-03,
        5.7127e-05, 2.9471e-04, 5.9036e-01, 1.3236e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,370][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0111, 0.0610, 0.0189, 0.0100, 0.0450, 0.0735, 0.0622, 0.0643, 0.2085,
        0.4349, 0.0106], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,371][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0022, 0.0210, 0.1224, 0.0304, 0.0495, 0.0863, 0.0903, 0.1328, 0.0847,
        0.2924, 0.0880], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,372][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1115, 0.1436, 0.1238, 0.0630, 0.0308, 0.0798, 0.0267, 0.0891, 0.1343,
        0.0852, 0.1123], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,373][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0124, 0.1020, 0.1022, 0.0848, 0.0950, 0.0912, 0.0868, 0.1326, 0.0928,
        0.1142, 0.0860], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,375][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.5394, 0.0540, 0.0073, 0.0770, 0.0297, 0.0222, 0.0276, 0.0223, 0.0958,
        0.0445, 0.0802], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,377][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0337, 0.0108, 0.0786, 0.1903, 0.2318, 0.0084, 0.0552, 0.1407, 0.0499,
        0.1963, 0.0044], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,378][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2622, 0.0332, 0.0997, 0.0297, 0.1548, 0.0560, 0.0819, 0.0528, 0.0456,
        0.1803, 0.0039], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,380][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1383, 0.0815, 0.0797, 0.0796, 0.0884, 0.0809, 0.0801, 0.0924, 0.0899,
        0.0950, 0.0943], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,382][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0844, 0.0713, 0.0830, 0.0858, 0.0837, 0.0951, 0.0889, 0.1033, 0.0945,
        0.0994, 0.1105], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,384][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0558, 0.1153, 0.0891, 0.0915, 0.0977, 0.1260, 0.1043, 0.0846, 0.0926,
        0.0684, 0.0747], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,386][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0575, 0.1341, 0.0695, 0.0747, 0.1202, 0.0579, 0.1088, 0.1262, 0.0851,
        0.0771, 0.0890], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,387][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([4.5889e-11, 1.6147e-04, 1.7064e-06, 4.9525e-04, 1.6985e-02, 8.8372e-05,
        2.4149e-05, 1.8148e-05, 2.1167e-02, 3.5340e-04, 9.6071e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,387][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0152, 0.0781, 0.0260, 0.0127, 0.0773, 0.1230, 0.0525, 0.0441, 0.1976,
        0.2615, 0.0375, 0.0744], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,388][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0014, 0.0200, 0.1035, 0.0273, 0.0528, 0.0811, 0.0680, 0.1102, 0.0787,
        0.3023, 0.1037, 0.0511], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,389][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3230, 0.1097, 0.1193, 0.0288, 0.0154, 0.0330, 0.0302, 0.1077, 0.0461,
        0.0719, 0.0919, 0.0229], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,390][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0094, 0.0969, 0.0997, 0.0771, 0.0856, 0.0838, 0.0791, 0.1247, 0.0798,
        0.1050, 0.0777, 0.0813], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,392][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7716, 0.0218, 0.0018, 0.0311, 0.0098, 0.0067, 0.0087, 0.0079, 0.0486,
        0.0167, 0.0391, 0.0362], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,394][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0215, 0.0039, 0.1745, 0.0588, 0.4884, 0.0023, 0.0087, 0.0501, 0.0111,
        0.1295, 0.0168, 0.0344], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,396][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1984, 0.0970, 0.1658, 0.0494, 0.0795, 0.0324, 0.0814, 0.1046, 0.0406,
        0.1113, 0.0220, 0.0175], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,397][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1355, 0.0754, 0.0727, 0.0718, 0.0797, 0.0731, 0.0720, 0.0844, 0.0812,
        0.0865, 0.0848, 0.0828], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,399][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0806, 0.0659, 0.0746, 0.0790, 0.0755, 0.0862, 0.0804, 0.0942, 0.0859,
        0.0895, 0.1007, 0.0875], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,401][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0446, 0.1010, 0.0844, 0.0856, 0.0927, 0.1109, 0.0900, 0.0837, 0.0852,
        0.0656, 0.0735, 0.0827], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,403][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0605, 0.0877, 0.0331, 0.0678, 0.1097, 0.1024, 0.1186, 0.1404, 0.0697,
        0.0667, 0.0693, 0.0742], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,404][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.1690e-10, 4.1405e-01, 7.2097e-04, 4.0762e-03, 4.4338e-01, 3.4326e-04,
        3.8513e-06, 3.0938e-07, 1.9612e-03, 5.7135e-05, 3.0502e-02, 1.0490e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,405][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0225, 0.0262, 0.0132, 0.0070, 0.0540, 0.0428, 0.0416, 0.0526, 0.2240,
        0.2230, 0.0282, 0.0831, 0.1819], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,406][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0023, 0.0164, 0.0814, 0.0281, 0.0516, 0.0710, 0.0816, 0.1104, 0.0917,
        0.2129, 0.1133, 0.0654, 0.0738], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,407][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0840, 0.1393, 0.1858, 0.0699, 0.0268, 0.0515, 0.0625, 0.0486, 0.0818,
        0.0825, 0.0662, 0.0593, 0.0419], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,408][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0111, 0.0934, 0.0910, 0.0723, 0.0783, 0.0761, 0.0706, 0.1082, 0.0737,
        0.0931, 0.0720, 0.0768, 0.0834], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,409][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.6176, 0.0405, 0.0029, 0.0482, 0.0138, 0.0101, 0.0138, 0.0136, 0.0661,
        0.0270, 0.0618, 0.0545, 0.0300], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,411][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0333, 0.0050, 0.1913, 0.0918, 0.2020, 0.0076, 0.0395, 0.0225, 0.1386,
        0.0368, 0.1015, 0.1053, 0.0247], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,413][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0796, 0.0709, 0.2551, 0.0467, 0.1320, 0.0284, 0.0726, 0.0298, 0.1028,
        0.0821, 0.0300, 0.0597, 0.0105], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,415][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1224, 0.0704, 0.0678, 0.0670, 0.0743, 0.0680, 0.0666, 0.0773, 0.0750,
        0.0794, 0.0778, 0.0757, 0.0783], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,417][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0738, 0.0586, 0.0666, 0.0699, 0.0681, 0.0783, 0.0733, 0.0868, 0.0789,
        0.0836, 0.0936, 0.0807, 0.0878], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,419][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0432, 0.0920, 0.0745, 0.0752, 0.0854, 0.1072, 0.0884, 0.0819, 0.0780,
        0.0619, 0.0682, 0.0820, 0.0622], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,421][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0410, 0.0815, 0.0356, 0.0649, 0.1153, 0.0784, 0.0879, 0.0879, 0.0627,
        0.0606, 0.0469, 0.0578, 0.1795], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,422][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ station] are: tensor([9.6781e-11, 7.9919e-01, 7.6680e-04, 6.2681e-02, 1.3321e-01, 2.2269e-04,
        7.7745e-07, 3.7120e-06, 1.0006e-03, 1.0036e-06, 4.0829e-05, 1.1774e-04,
        2.7705e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,424][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0109, 0.0048, 0.0017, 0.0021, 0.0064, 0.0119, 0.0088, 0.0420, 0.1556,
        0.2471, 0.0172, 0.0942, 0.2203, 0.1772], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,426][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0015, 0.0139, 0.0955, 0.0195, 0.0407, 0.0629, 0.0774, 0.1016, 0.0657,
        0.2334, 0.1034, 0.0564, 0.0819, 0.0462], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,428][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1061, 0.1185, 0.1583, 0.0238, 0.0223, 0.0607, 0.0373, 0.0682, 0.0239,
        0.0536, 0.1396, 0.0107, 0.0884, 0.0884], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,429][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0056, 0.0911, 0.0918, 0.0639, 0.0694, 0.0677, 0.0636, 0.1115, 0.0669,
        0.0897, 0.0619, 0.0720, 0.0794, 0.0655], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,430][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.5023, 0.0287, 0.0032, 0.0504, 0.0149, 0.0125, 0.0150, 0.0116, 0.0637,
        0.0233, 0.0527, 0.0567, 0.0301, 0.1348], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,431][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0084, 0.0021, 0.1100, 0.0314, 0.4103, 0.0020, 0.0264, 0.0396, 0.0207,
        0.0707, 0.0181, 0.1103, 0.1479, 0.0019], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,432][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0787, 0.1236, 0.0443, 0.0332, 0.0567, 0.0589, 0.0750, 0.0393, 0.0704,
        0.0813, 0.0300, 0.1038, 0.1846, 0.0201], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,433][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1211, 0.0673, 0.0640, 0.0625, 0.0689, 0.0638, 0.0623, 0.0713, 0.0694,
        0.0730, 0.0710, 0.0693, 0.0712, 0.0649], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,435][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0643, 0.0543, 0.0634, 0.0666, 0.0650, 0.0743, 0.0684, 0.0815, 0.0719,
        0.0760, 0.0851, 0.0736, 0.0811, 0.0744], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,436][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0410, 0.0895, 0.0684, 0.0732, 0.0778, 0.0970, 0.0816, 0.0746, 0.0713,
        0.0568, 0.0615, 0.0767, 0.0583, 0.0722], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,438][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0384, 0.0783, 0.0537, 0.0562, 0.1064, 0.0528, 0.0852, 0.0863, 0.0664,
        0.0615, 0.0607, 0.0571, 0.1074, 0.0894], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,439][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([3.1342e-21, 3.6412e-09, 6.8230e-11, 4.4224e-07, 2.0585e-07, 6.0442e-09,
        1.5510e-09, 9.1608e-08, 2.1228e-04, 2.0848e-04, 1.3300e-02, 1.3699e-03,
        9.8491e-01, 3.8587e-09], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,441][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0282, 0.0167, 0.0065, 0.0036, 0.0370, 0.0293, 0.0382, 0.0448, 0.1121,
        0.2148, 0.0125, 0.0401, 0.1557, 0.1521, 0.1085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,443][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0013, 0.0141, 0.0497, 0.0218, 0.0410, 0.0592, 0.0749, 0.0955, 0.0688,
        0.2114, 0.1000, 0.0541, 0.0719, 0.0531, 0.0833], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,445][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0714, 0.0684, 0.0487, 0.0463, 0.0721, 0.0533, 0.0739, 0.0731, 0.0503,
        0.1183, 0.0653, 0.0394, 0.0812, 0.0909, 0.0476], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,446][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0074, 0.0841, 0.0824, 0.0606, 0.0643, 0.0643, 0.0595, 0.0997, 0.0613,
        0.0854, 0.0605, 0.0660, 0.0728, 0.0625, 0.0690], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,447][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.4869, 0.0275, 0.0025, 0.0370, 0.0109, 0.0095, 0.0110, 0.0135, 0.0534,
        0.0215, 0.0536, 0.0445, 0.0247, 0.1233, 0.0802], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,448][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0369, 0.0040, 0.0347, 0.0279, 0.1034, 0.0160, 0.0381, 0.0554, 0.0885,
        0.0999, 0.2095, 0.0996, 0.0454, 0.0186, 0.1223], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,449][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.1202, 0.1715, 0.0050, 0.0805, 0.0382, 0.0658, 0.0348, 0.0323, 0.0417,
        0.0740, 0.0521, 0.0567, 0.1273, 0.0926, 0.0073], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,450][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.1113, 0.0620, 0.0604, 0.0588, 0.0655, 0.0599, 0.0582, 0.0679, 0.0655,
        0.0695, 0.0677, 0.0658, 0.0684, 0.0617, 0.0575], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,452][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0695, 0.0518, 0.0588, 0.0606, 0.0603, 0.0676, 0.0628, 0.0741, 0.0683,
        0.0709, 0.0795, 0.0687, 0.0745, 0.0699, 0.0630], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,454][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0392, 0.0827, 0.0666, 0.0702, 0.0746, 0.0951, 0.0744, 0.0680, 0.0698,
        0.0524, 0.0587, 0.0695, 0.0556, 0.0707, 0.0526], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,456][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0412, 0.0800, 0.0337, 0.0595, 0.1165, 0.0879, 0.0477, 0.0822, 0.0580,
        0.0613, 0.0418, 0.0442, 0.1178, 0.1003, 0.0279], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,457][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([1.4220e-13, 3.5416e-02, 6.7443e-05, 2.6523e-03, 8.6075e-02, 2.3892e-04,
        1.0379e-05, 2.6815e-03, 7.5391e-03, 1.5111e-03, 2.9929e-03, 1.7132e-04,
        8.5993e-01, 3.1219e-05, 6.8814e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,459][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1248, 0.0313, 0.0089, 0.0063, 0.0303, 0.0234, 0.0262, 0.0144, 0.0610,
        0.0474, 0.0075, 0.0508, 0.0808, 0.0638, 0.0774, 0.3458],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,461][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0015, 0.0115, 0.0659, 0.0188, 0.0285, 0.0423, 0.0479, 0.0783, 0.0567,
        0.1851, 0.0834, 0.0418, 0.0649, 0.0533, 0.1221, 0.0980],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,463][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1067, 0.1097, 0.0373, 0.0308, 0.0709, 0.0138, 0.0329, 0.0365, 0.0753,
        0.1185, 0.0451, 0.0492, 0.0594, 0.1676, 0.0391, 0.0071],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,465][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0070, 0.0753, 0.0761, 0.0586, 0.0633, 0.0617, 0.0593, 0.0896, 0.0597,
        0.0764, 0.0581, 0.0605, 0.0663, 0.0571, 0.0622, 0.0686],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,465][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3084, 0.0293, 0.0047, 0.0457, 0.0173, 0.0152, 0.0164, 0.0164, 0.0538,
        0.0270, 0.0506, 0.0520, 0.0290, 0.1276, 0.0848, 0.1219],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,466][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0203, 0.0039, 0.0631, 0.0429, 0.1468, 0.0040, 0.0266, 0.0301, 0.0819,
        0.0682, 0.0257, 0.1385, 0.0260, 0.0148, 0.2950, 0.0122],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,467][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1602, 0.0594, 0.1048, 0.0315, 0.0727, 0.0260, 0.0316, 0.0449, 0.0603,
        0.1196, 0.0214, 0.0245, 0.0325, 0.0305, 0.1776, 0.0026],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,468][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1004, 0.0576, 0.0563, 0.0557, 0.0610, 0.0560, 0.0549, 0.0640, 0.0619,
        0.0652, 0.0639, 0.0627, 0.0647, 0.0590, 0.0547, 0.0620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,470][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0561, 0.0467, 0.0553, 0.0571, 0.0551, 0.0652, 0.0595, 0.0705, 0.0624,
        0.0666, 0.0746, 0.0646, 0.0707, 0.0637, 0.0593, 0.0726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,472][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0356, 0.0796, 0.0594, 0.0685, 0.0677, 0.0867, 0.0699, 0.0689, 0.0654,
        0.0542, 0.0575, 0.0686, 0.0503, 0.0690, 0.0490, 0.0497],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,474][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0617, 0.0764, 0.0290, 0.0568, 0.0934, 0.0767, 0.0809, 0.1221, 0.0478,
        0.0396, 0.0430, 0.0515, 0.0879, 0.0687, 0.0169, 0.0476],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,475][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.2941e-12, 2.3074e-01, 1.7804e-03, 1.2281e-02, 5.2150e-02, 1.9186e-03,
        1.7504e-04, 2.7980e-04, 5.1137e-03, 1.4138e-03, 5.9313e-03, 3.5643e-04,
        4.8671e-01, 1.9047e-05, 1.2171e-02, 1.8896e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,478][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0052, 0.0077, 0.0021, 0.0011, 0.0058, 0.0110, 0.0044, 0.0070, 0.0256,
        0.0380, 0.0028, 0.0094, 0.0694, 0.0358, 0.0417, 0.6576, 0.0754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,479][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0006, 0.0113, 0.0661, 0.0168, 0.0293, 0.0428, 0.0355, 0.0669, 0.0507,
        0.1793, 0.0678, 0.0308, 0.0680, 0.0394, 0.1079, 0.1256, 0.0611],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,481][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1260, 0.0814, 0.0540, 0.0250, 0.0196, 0.0374, 0.0277, 0.0730, 0.0512,
        0.0493, 0.0504, 0.0254, 0.0490, 0.2226, 0.0668, 0.0147, 0.0265],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,483][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0060, 0.0708, 0.0743, 0.0536, 0.0583, 0.0570, 0.0535, 0.0876, 0.0538,
        0.0719, 0.0521, 0.0540, 0.0614, 0.0532, 0.0578, 0.0620, 0.0726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,483][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5792, 0.0147, 0.0013, 0.0228, 0.0076, 0.0056, 0.0074, 0.0068, 0.0337,
        0.0122, 0.0309, 0.0264, 0.0145, 0.0717, 0.0445, 0.0655, 0.0550],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,484][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0058, 0.0015, 0.0644, 0.0106, 0.2601, 0.0013, 0.0012, 0.0120, 0.0114,
        0.0322, 0.0063, 0.0448, 0.2011, 0.0106, 0.3103, 0.0232, 0.0032],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,485][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1165, 0.1359, 0.0918, 0.0578, 0.0419, 0.0193, 0.0080, 0.0691, 0.0474,
        0.0508, 0.0334, 0.0551, 0.0619, 0.0395, 0.1466, 0.0129, 0.0121],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,486][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0999, 0.0560, 0.0537, 0.0523, 0.0572, 0.0531, 0.0520, 0.0599, 0.0577,
        0.0611, 0.0592, 0.0581, 0.0598, 0.0547, 0.0504, 0.0571, 0.0579],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,488][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0546, 0.0456, 0.0527, 0.0546, 0.0533, 0.0606, 0.0560, 0.0655, 0.0584,
        0.0618, 0.0684, 0.0597, 0.0657, 0.0600, 0.0557, 0.0660, 0.0613],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,490][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0332, 0.0734, 0.0595, 0.0618, 0.0693, 0.0817, 0.0628, 0.0613, 0.0621,
        0.0488, 0.0544, 0.0611, 0.0496, 0.0629, 0.0505, 0.0507, 0.0567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,492][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0362, 0.0681, 0.0360, 0.0445, 0.1056, 0.0543, 0.0779, 0.0946, 0.0498,
        0.0497, 0.0557, 0.0499, 0.0834, 0.0695, 0.0265, 0.0366, 0.0618],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,494][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.6227e-16, 1.9917e-04, 4.7794e-07, 5.8219e-06, 5.3423e-04, 1.3964e-06,
        5.2375e-08, 1.6671e-08, 1.6856e-05, 5.0273e-06, 3.6011e-04, 1.8003e-04,
        6.8247e-01, 5.0279e-09, 1.3937e-03, 3.0248e-01, 1.2353e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,496][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0111, 0.0030, 0.0007, 0.0007, 0.0021, 0.0060, 0.0045, 0.0106, 0.0201,
        0.0397, 0.0014, 0.0061, 0.0239, 0.0361, 0.0184, 0.2913, 0.0818, 0.4426],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,498][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0015, 0.0121, 0.0527, 0.0206, 0.0303, 0.0544, 0.0511, 0.0536, 0.0617,
        0.1134, 0.0832, 0.0436, 0.0574, 0.0476, 0.0827, 0.1098, 0.0770, 0.0471],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,499][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0822, 0.0686, 0.0524, 0.0185, 0.0542, 0.0255, 0.0085, 0.0169, 0.0180,
        0.1294, 0.0485, 0.0035, 0.2364, 0.0415, 0.0553, 0.0305, 0.0078, 0.1024],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,501][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0088, 0.0673, 0.0673, 0.0502, 0.0541, 0.0539, 0.0497, 0.0785, 0.0518,
        0.0664, 0.0499, 0.0515, 0.0579, 0.0521, 0.0525, 0.0573, 0.0630, 0.0679],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,502][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.3663, 0.0271, 0.0028, 0.0335, 0.0116, 0.0086, 0.0101, 0.0104, 0.0456,
        0.0183, 0.0393, 0.0379, 0.0185, 0.0971, 0.0598, 0.0850, 0.0673, 0.0608],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,502][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.0232, 0.0041, 0.0691, 0.0682, 0.0631, 0.0181, 0.0065, 0.0067, 0.0476,
        0.0080, 0.1618, 0.0450, 0.0269, 0.0190, 0.3304, 0.0642, 0.0171, 0.0209],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,503][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0466, 0.1790, 0.0899, 0.0384, 0.0302, 0.0304, 0.0462, 0.0287, 0.0592,
        0.0241, 0.0704, 0.0532, 0.0325, 0.0533, 0.1118, 0.0145, 0.0891, 0.0025],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,505][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0926, 0.0529, 0.0508, 0.0497, 0.0543, 0.0500, 0.0490, 0.0562, 0.0541,
        0.0572, 0.0553, 0.0541, 0.0559, 0.0513, 0.0471, 0.0536, 0.0539, 0.0620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,507][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0491, 0.0428, 0.0491, 0.0517, 0.0497, 0.0579, 0.0527, 0.0618, 0.0555,
        0.0579, 0.0644, 0.0552, 0.0614, 0.0566, 0.0524, 0.0629, 0.0581, 0.0608],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,509][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0296, 0.0715, 0.0527, 0.0590, 0.0661, 0.0773, 0.0638, 0.0614, 0.0554,
        0.0474, 0.0474, 0.0600, 0.0484, 0.0606, 0.0435, 0.0492, 0.0580, 0.0487],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,510][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0311, 0.0650, 0.0392, 0.0564, 0.0913, 0.0623, 0.0908, 0.0549, 0.0532,
        0.0614, 0.0440, 0.0501, 0.0442, 0.0639, 0.0301, 0.0294, 0.0697, 0.0630],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,512][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([6.2512e-14, 6.5619e-01, 9.5537e-04, 3.1060e-02, 3.7843e-02, 1.3303e-03,
        7.5705e-05, 8.2626e-04, 9.9747e-03, 1.0021e-03, 2.4062e-03, 4.9647e-05,
        1.8928e-01, 4.3222e-05, 1.4360e-03, 3.8744e-02, 3.1803e-03, 2.5595e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,514][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0058, 0.0032, 0.0009, 0.0007, 0.0028, 0.0053, 0.0044, 0.0063, 0.0156,
        0.0341, 0.0008, 0.0063, 0.0275, 0.0327, 0.0153, 0.3020, 0.0603, 0.4636,
        0.0124], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,516][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0008, 0.0095, 0.0585, 0.0139, 0.0264, 0.0343, 0.0465, 0.0640, 0.0415,
        0.1692, 0.0624, 0.0353, 0.0601, 0.0372, 0.0977, 0.0814, 0.0770, 0.0517,
        0.0326], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,518][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1388, 0.0742, 0.1004, 0.0225, 0.0106, 0.0167, 0.0182, 0.0441, 0.0483,
        0.0563, 0.0889, 0.0085, 0.0435, 0.0804, 0.1245, 0.0171, 0.0193, 0.0379,
        0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,519][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0081, 0.0606, 0.0627, 0.0453, 0.0491, 0.0493, 0.0470, 0.0762, 0.0472,
        0.0628, 0.0459, 0.0487, 0.0547, 0.0506, 0.0518, 0.0546, 0.0630, 0.0673,
        0.0552], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,520][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2857, 0.0162, 0.0038, 0.0294, 0.0136, 0.0101, 0.0119, 0.0118, 0.0356,
        0.0180, 0.0360, 0.0372, 0.0228, 0.0725, 0.0653, 0.0712, 0.0707, 0.0576,
        0.1305], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,520][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.3226e-03, 7.5723e-04, 4.3490e-02, 1.8815e-02, 2.5219e-01, 6.0179e-04,
        9.8338e-03, 2.3770e-02, 8.8341e-03, 1.0249e-01, 3.8288e-03, 7.4390e-02,
        4.8170e-02, 4.5139e-03, 1.8891e-01, 1.3646e-02, 2.9911e-02, 1.7337e-01,
        1.4780e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,521][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1418, 0.0645, 0.0857, 0.0456, 0.0442, 0.0451, 0.0271, 0.0255, 0.0709,
        0.0601, 0.0766, 0.0592, 0.0495, 0.0139, 0.1064, 0.0129, 0.0455, 0.0143,
        0.0111], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,523][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0872, 0.0498, 0.0475, 0.0465, 0.0505, 0.0471, 0.0463, 0.0528, 0.0512,
        0.0535, 0.0516, 0.0507, 0.0523, 0.0480, 0.0441, 0.0503, 0.0507, 0.0582,
        0.0618], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,525][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0427, 0.0397, 0.0478, 0.0495, 0.0488, 0.0558, 0.0511, 0.0592, 0.0518,
        0.0548, 0.0602, 0.0525, 0.0587, 0.0534, 0.0515, 0.0602, 0.0547, 0.0564,
        0.0510], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,527][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0297, 0.0651, 0.0527, 0.0555, 0.0612, 0.0706, 0.0605, 0.0541, 0.0556,
        0.0427, 0.0470, 0.0559, 0.0452, 0.0571, 0.0440, 0.0446, 0.0552, 0.0460,
        0.0573], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,528][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0386, 0.0579, 0.0409, 0.0498, 0.0660, 0.0477, 0.0726, 0.0758, 0.0460,
        0.0461, 0.0489, 0.0509, 0.0679, 0.0629, 0.0334, 0.0305, 0.0596, 0.0437,
        0.0607], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,530][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.0631e-18, 1.8283e-06, 5.2984e-08, 1.0736e-07, 2.0452e-05, 9.7165e-08,
        1.3011e-08, 1.5517e-08, 6.2741e-06, 7.3862e-06, 3.7589e-04, 2.1785e-05,
        5.2485e-01, 1.6760e-08, 5.3052e-03, 2.4095e-01, 1.1371e-02, 2.1708e-01,
        4.9889e-06], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,572][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:55,573][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,573][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,574][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,574][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,574][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,575][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,575][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,575][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,575][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,576][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,577][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,578][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,578][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6150, 0.3850], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,578][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6166, 0.3834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,579][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7915, 0.2085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,579][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1447, 0.8553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,579][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9685, 0.0315], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,580][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8219, 0.1781], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,580][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5151, 0.4849], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,580][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0866, 0.9134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,581][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8421, 0.1579], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,581][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6812, 0.3188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,581][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7103, 0.2897], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,582][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9969e-01, 3.0918e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,582][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.1493, 0.5440, 0.3067], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,582][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.3215, 0.2210, 0.4574], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,583][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.7255, 0.2251, 0.0494], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,583][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0776, 0.4022, 0.5201], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,583][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.9334, 0.0273, 0.0392], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,584][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.6568, 0.1880, 0.1552], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,584][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.3482, 0.3320, 0.3198], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,584][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.2631, 0.1826, 0.5543], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,585][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.7628, 0.1466, 0.0906], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,585][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.4570, 0.2575, 0.2855], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,585][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.4577, 0.2502, 0.2921], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,586][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0343, 0.9623, 0.0034], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,586][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1615, 0.4874, 0.2066, 0.1445], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,586][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2468, 0.1524, 0.4428, 0.1579], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,587][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5957, 0.2236, 0.0399, 0.1409], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,587][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0458, 0.2798, 0.4177, 0.2566], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,587][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8277, 0.0417, 0.0513, 0.0794], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,588][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4370, 0.2411, 0.2316, 0.0903], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,588][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2667, 0.2542, 0.2480, 0.2310], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,588][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0088, 0.0916, 0.0182, 0.8813], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,589][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6348, 0.1230, 0.0897, 0.1525], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,589][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3633, 0.2276, 0.2173, 0.1918], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,589][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3823, 0.1857, 0.2284, 0.2036], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,590][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.0534e-04, 1.9805e-01, 8.0171e-01, 3.7015e-05], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,590][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.1795, 0.1897, 0.1161, 0.0741, 0.4406], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,590][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.2071, 0.1378, 0.3055, 0.1522, 0.1973], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,591][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.6372, 0.1342, 0.0651, 0.0937, 0.0698], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,591][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0333, 0.1981, 0.2777, 0.2078, 0.2832], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,592][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.8975, 0.0192, 0.0325, 0.0339, 0.0170], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,592][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.3705, 0.0546, 0.0450, 0.0343, 0.4956], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,592][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.2108, 0.2014, 0.1948, 0.1820, 0.2110], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,593][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.0188, 0.0240, 0.1707, 0.3240, 0.4625], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,593][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.5534, 0.0798, 0.1441, 0.1079, 0.1148], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,594][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.2006, 0.1520, 0.1704, 0.1500, 0.3270], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,596][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.2966, 0.1542, 0.1840, 0.1610, 0.2042], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,597][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([4.5318e-01, 4.4074e-01, 1.5621e-02, 2.5177e-04, 9.0206e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,598][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1426, 0.1770, 0.0953, 0.0637, 0.3887, 0.1327], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,598][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1708, 0.1005, 0.2810, 0.1253, 0.1694, 0.1529], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,598][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4914, 0.1719, 0.0284, 0.1344, 0.0631, 0.1108], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,599][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0344, 0.1685, 0.2476, 0.1640, 0.2496, 0.1360], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,599][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.7331, 0.0413, 0.0486, 0.0598, 0.0281, 0.0891], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,599][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2660, 0.0863, 0.0889, 0.0504, 0.4210, 0.0873], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,600][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1775, 0.1693, 0.1639, 0.1535, 0.1773, 0.1586], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,600][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0082, 0.1481, 0.0267, 0.4701, 0.0577, 0.2892], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,601][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3830, 0.0817, 0.1082, 0.0990, 0.1631, 0.1649], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,601][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0878, 0.1173, 0.0790, 0.1007, 0.1871, 0.4282], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,601][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2524, 0.1363, 0.1567, 0.1353, 0.1711, 0.1482], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,602][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([6.4233e-06, 8.3462e-05, 6.2750e-03, 3.9401e-07, 9.9330e-01, 3.3145e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,604][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0276, 0.1348, 0.0652, 0.0532, 0.2124, 0.3540, 0.1526],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,605][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1334, 0.0841, 0.2364, 0.0987, 0.1543, 0.1511, 0.1419],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,607][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4877, 0.1463, 0.0300, 0.0978, 0.0649, 0.1002, 0.0731],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,608][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0262, 0.1486, 0.2093, 0.1459, 0.2141, 0.1313, 0.1246],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,610][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7667, 0.0339, 0.0331, 0.0457, 0.0177, 0.0723, 0.0307],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,612][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2290, 0.0687, 0.0916, 0.0491, 0.4342, 0.0696, 0.0578],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,613][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1545, 0.1459, 0.1413, 0.1328, 0.1525, 0.1367, 0.1364],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,615][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0072, 0.0248, 0.0212, 0.1381, 0.0434, 0.0295, 0.7358],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,615][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3281, 0.0679, 0.0787, 0.0848, 0.1213, 0.1896, 0.1294],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,616][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0969, 0.0817, 0.0816, 0.0677, 0.2000, 0.3644, 0.1078],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,616][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2315, 0.1169, 0.1356, 0.1187, 0.1397, 0.1243, 0.1334],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,616][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.4716e-06, 7.1676e-04, 9.1398e-03, 3.9034e-06, 9.7164e-01, 1.8485e-02,
        9.6426e-06], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,617][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0465, 0.0387, 0.0188, 0.0216, 0.1040, 0.1231, 0.0557, 0.5916],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,617][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.1280, 0.0693, 0.1618, 0.0853, 0.1139, 0.1001, 0.1387, 0.2030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,618][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.5601, 0.0673, 0.0203, 0.0632, 0.0512, 0.0616, 0.0470, 0.1293],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,618][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0278, 0.1386, 0.1818, 0.1346, 0.1852, 0.1200, 0.1173, 0.0947],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,618][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.7022, 0.0391, 0.0342, 0.0456, 0.0178, 0.0690, 0.0215, 0.0707],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,619][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2153, 0.0240, 0.0498, 0.0270, 0.1860, 0.0343, 0.0415, 0.4223],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,620][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1340, 0.1281, 0.1227, 0.1159, 0.1327, 0.1190, 0.1190, 0.1286],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,621][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0037, 0.0164, 0.0146, 0.0728, 0.0503, 0.0815, 0.5118, 0.2489],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,623][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.3344, 0.0522, 0.0619, 0.0658, 0.1094, 0.1248, 0.0990, 0.1524],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,624][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0686, 0.0701, 0.0558, 0.0672, 0.1394, 0.2856, 0.1474, 0.1658],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,626][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2220, 0.0958, 0.1170, 0.1101, 0.1341, 0.1060, 0.1160, 0.0991],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,627][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.2082e-03, 4.1947e-04, 1.2644e-03, 1.4369e-06, 3.5651e-01, 3.1261e-03,
        3.5307e-04, 6.3711e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,629][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0928, 0.0758, 0.0345, 0.0226, 0.1205, 0.1314, 0.1085, 0.1283, 0.2855],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,630][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.1038, 0.0566, 0.1662, 0.0641, 0.1034, 0.0898, 0.1085, 0.2196, 0.0879],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,632][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3693, 0.1137, 0.0225, 0.0818, 0.0396, 0.0745, 0.0628, 0.1658, 0.0700],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,633][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0162, 0.1148, 0.1706, 0.1105, 0.1808, 0.1026, 0.1047, 0.0962, 0.1035],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,633][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.6763, 0.0311, 0.0346, 0.0368, 0.0163, 0.0553, 0.0223, 0.0645, 0.0627],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,634][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.4170, 0.0326, 0.0302, 0.0291, 0.1441, 0.0239, 0.0387, 0.2294, 0.0549],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,634][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1187, 0.1115, 0.1096, 0.1028, 0.1180, 0.1062, 0.1059, 0.1144, 0.1127],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,634][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0088, 0.0128, 0.0086, 0.0387, 0.0449, 0.0135, 0.2815, 0.0954, 0.4958],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,635][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.2864, 0.0527, 0.0608, 0.0604, 0.1092, 0.1162, 0.0978, 0.1376, 0.0791],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,635][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0676, 0.0628, 0.0561, 0.0478, 0.1473, 0.2729, 0.1029, 0.1610, 0.0814],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,636][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.2189, 0.0892, 0.1110, 0.0999, 0.1116, 0.0902, 0.1155, 0.0778, 0.0858],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,636][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([6.7693e-06, 6.3274e-06, 8.2379e-05, 6.9113e-08, 1.8668e-02, 1.6590e-04,
        8.5768e-07, 9.8106e-01, 1.2350e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,636][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0449, 0.0215, 0.0126, 0.0095, 0.0430, 0.0736, 0.0457, 0.0962, 0.3873,
        0.2656], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,637][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0976, 0.0479, 0.1080, 0.0515, 0.0720, 0.0675, 0.0960, 0.2041, 0.1024,
        0.1528], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,639][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.4396, 0.0741, 0.0177, 0.0541, 0.0615, 0.0689, 0.0474, 0.1137, 0.0462,
        0.0769], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,640][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0173, 0.1024, 0.1484, 0.1057, 0.1608, 0.0914, 0.1042, 0.0821, 0.1015,
        0.0862], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,642][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.6549, 0.0212, 0.0215, 0.0226, 0.0105, 0.0359, 0.0146, 0.0408, 0.0497,
        0.1282], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,643][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.2637, 0.0234, 0.0272, 0.0195, 0.1665, 0.0235, 0.0279, 0.1784, 0.1120,
        0.1580], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,645][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1101, 0.1021, 0.0980, 0.0925, 0.1054, 0.0947, 0.0949, 0.1028, 0.1028,
        0.0967], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,647][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0025, 0.0047, 0.0028, 0.0283, 0.0221, 0.0178, 0.1158, 0.1273, 0.6336,
        0.0450], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,649][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.3425, 0.0498, 0.0351, 0.0541, 0.0625, 0.1026, 0.0810, 0.1464, 0.0692,
        0.0568], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,650][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0673, 0.0578, 0.0477, 0.0496, 0.1206, 0.2205, 0.1331, 0.1345, 0.0815,
        0.0873], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,651][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.2369, 0.0770, 0.0874, 0.0823, 0.0929, 0.0757, 0.0926, 0.0760, 0.0881,
        0.0912], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,651][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.9227e-03, 2.4837e-04, 3.7648e-04, 7.3653e-07, 3.4500e-02, 2.8885e-03,
        3.1461e-05, 9.3421e-01, 2.0926e-03, 2.3728e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,651][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0111, 0.0610, 0.0189, 0.0100, 0.0450, 0.0735, 0.0622, 0.0643, 0.2085,
        0.4349, 0.0106], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,652][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0652, 0.0391, 0.1019, 0.0444, 0.0682, 0.0663, 0.0832, 0.1592, 0.0774,
        0.2036, 0.0915], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,652][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3605, 0.0954, 0.0190, 0.0651, 0.0443, 0.0659, 0.0412, 0.1363, 0.0530,
        0.0617, 0.0576], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,653][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0200, 0.0903, 0.1357, 0.0886, 0.1413, 0.0834, 0.0858, 0.0817, 0.0899,
        0.1100, 0.0731], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,653][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.6619, 0.0186, 0.0208, 0.0196, 0.0080, 0.0341, 0.0122, 0.0431, 0.0372,
        0.1097, 0.0349], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,653][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0966, 0.0451, 0.0330, 0.0277, 0.1890, 0.0397, 0.0493, 0.1926, 0.0943,
        0.1696, 0.0631], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,654][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1009, 0.0938, 0.0898, 0.0848, 0.0963, 0.0866, 0.0872, 0.0940, 0.0944,
        0.0891, 0.0832], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,654][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0039, 0.0041, 0.0080, 0.0535, 0.0272, 0.0154, 0.3372, 0.0416, 0.2500,
        0.0342, 0.2249], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,656][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2236, 0.0528, 0.0486, 0.0609, 0.0682, 0.1216, 0.0980, 0.1316, 0.0832,
        0.0688, 0.0428], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,658][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0924, 0.0449, 0.0454, 0.0284, 0.1013, 0.2763, 0.1031, 0.0968, 0.0805,
        0.0732, 0.0578], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,659][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.2054, 0.0670, 0.0805, 0.0746, 0.0870, 0.0698, 0.0886, 0.0727, 0.0797,
        0.0805, 0.0944], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,660][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([7.2672e-08, 7.3225e-05, 1.2726e-04, 3.4055e-08, 1.9529e-02, 1.5396e-04,
        5.6427e-07, 6.6492e-01, 2.6643e-05, 3.1517e-01, 5.0285e-09],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,662][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0152, 0.0781, 0.0260, 0.0127, 0.0773, 0.1230, 0.0525, 0.0441, 0.1976,
        0.2615, 0.0375, 0.0744], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,664][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0671, 0.0396, 0.1006, 0.0428, 0.0716, 0.0682, 0.0668, 0.1331, 0.0740,
        0.1844, 0.0939, 0.0579], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,665][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3718, 0.0781, 0.0181, 0.0528, 0.0342, 0.0551, 0.0423, 0.1289, 0.0451,
        0.0542, 0.0532, 0.0663], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,667][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0123, 0.0871, 0.1224, 0.0856, 0.1322, 0.0815, 0.0801, 0.0746, 0.0864,
        0.0953, 0.0727, 0.0699], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,668][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.6887, 0.0149, 0.0186, 0.0170, 0.0070, 0.0282, 0.0117, 0.0429, 0.0354,
        0.0953, 0.0249, 0.0153], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,668][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.2108, 0.0335, 0.0404, 0.0206, 0.2268, 0.0350, 0.0342, 0.0903, 0.0550,
        0.1481, 0.0721, 0.0331], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,669][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0923, 0.0851, 0.0829, 0.0776, 0.0893, 0.0800, 0.0801, 0.0869, 0.0868,
        0.0831, 0.0775, 0.0783], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,669][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0014, 0.0013, 0.0055, 0.0025, 0.0087, 0.0032, 0.0863, 0.0371, 0.0297,
        0.0070, 0.0218, 0.7953], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,670][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2052, 0.0471, 0.0468, 0.0580, 0.0771, 0.1166, 0.0800, 0.1251, 0.0747,
        0.0764, 0.0406, 0.0523], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,670][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0487, 0.0455, 0.0630, 0.0381, 0.1107, 0.1881, 0.0688, 0.1083, 0.0974,
        0.0705, 0.0870, 0.0739], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,670][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2176, 0.0655, 0.0763, 0.0683, 0.0759, 0.0633, 0.0794, 0.0587, 0.0664,
        0.0678, 0.0800, 0.0809], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,671][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.6233e-07, 1.1245e-03, 2.2637e-04, 1.2405e-06, 1.7038e-02, 3.3559e-03,
        3.0506e-06, 8.0204e-01, 1.7481e-03, 1.7446e-01, 1.1798e-06, 2.3905e-06],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,671][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0225, 0.0262, 0.0132, 0.0070, 0.0540, 0.0428, 0.0416, 0.0526, 0.2240,
        0.2230, 0.0282, 0.0831, 0.1819], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,672][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0631, 0.0343, 0.0814, 0.0398, 0.0573, 0.0568, 0.0749, 0.1404, 0.0759,
        0.1375, 0.1006, 0.0661, 0.0718], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,674][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.3308, 0.0732, 0.0247, 0.0555, 0.0348, 0.0493, 0.0371, 0.0971, 0.0449,
        0.0611, 0.0591, 0.0771, 0.0554], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,676][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0137, 0.0791, 0.1160, 0.0780, 0.1200, 0.0712, 0.0814, 0.0686, 0.0764,
        0.0732, 0.0714, 0.0730, 0.0780], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,677][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.6960, 0.0118, 0.0111, 0.0132, 0.0052, 0.0233, 0.0108, 0.0289, 0.0370,
        0.0885, 0.0262, 0.0164, 0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,679][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.1613, 0.0259, 0.0346, 0.0151, 0.1546, 0.0338, 0.0472, 0.1105, 0.0799,
        0.1135, 0.0640, 0.0547, 0.1047], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,680][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0851, 0.0791, 0.0764, 0.0717, 0.0823, 0.0736, 0.0739, 0.0803, 0.0803,
        0.0762, 0.0711, 0.0722, 0.0779], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,682][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0008, 0.0043, 0.0019, 0.0111, 0.0126, 0.0050, 0.0559, 0.0244, 0.2373,
        0.0114, 0.0709, 0.4990, 0.0655], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,684][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.3231, 0.0347, 0.0325, 0.0482, 0.0575, 0.1029, 0.0759, 0.1062, 0.0570,
        0.0561, 0.0368, 0.0428, 0.0261], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,685][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0487, 0.0307, 0.0419, 0.0249, 0.0845, 0.1925, 0.0841, 0.1177, 0.0712,
        0.0720, 0.0769, 0.0867, 0.0681], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,686][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.2068, 0.0546, 0.0638, 0.0585, 0.0673, 0.0560, 0.0669, 0.0550, 0.0608,
        0.0677, 0.0758, 0.0746, 0.0923], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,686][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([6.1841e-06, 2.3700e-05, 3.0857e-05, 6.3849e-08, 8.2786e-03, 3.3030e-04,
        1.2114e-05, 4.2198e-01, 1.7213e-04, 5.6911e-01, 3.1224e-08, 1.5367e-05,
        4.0074e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,687][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0109, 0.0048, 0.0017, 0.0021, 0.0064, 0.0119, 0.0088, 0.0420, 0.1556,
        0.2471, 0.0172, 0.0942, 0.2203, 0.1772], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,687][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0517, 0.0311, 0.0910, 0.0336, 0.0553, 0.0561, 0.0719, 0.1310, 0.0581,
        0.1619, 0.0843, 0.0613, 0.0833, 0.0294], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,687][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2429, 0.0659, 0.0157, 0.0492, 0.0327, 0.0666, 0.0459, 0.1354, 0.0414,
        0.0460, 0.0582, 0.0596, 0.0590, 0.0816], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,688][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0097, 0.0725, 0.1071, 0.0702, 0.1174, 0.0673, 0.0716, 0.0636, 0.0718,
        0.0790, 0.0580, 0.0649, 0.0802, 0.0665], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,688][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.4667, 0.0265, 0.0336, 0.0303, 0.0141, 0.0383, 0.0181, 0.0514, 0.0518,
        0.1267, 0.0372, 0.0243, 0.0474, 0.0337], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,689][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1006, 0.0126, 0.0190, 0.0151, 0.0950, 0.0252, 0.0204, 0.1454, 0.0777,
        0.1445, 0.0644, 0.0500, 0.1379, 0.0922], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,690][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0781, 0.0731, 0.0712, 0.0669, 0.0765, 0.0687, 0.0686, 0.0742, 0.0741,
        0.0708, 0.0662, 0.0674, 0.0726, 0.0715], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,692][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0013, 0.0019, 0.0031, 0.0236, 0.0197, 0.0022, 0.0728, 0.0382, 0.1685,
        0.0154, 0.0409, 0.4915, 0.0267, 0.0942], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,693][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2432, 0.0361, 0.0434, 0.0545, 0.0696, 0.0872, 0.0725, 0.1009, 0.0640,
        0.0574, 0.0337, 0.0522, 0.0366, 0.0487], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,695][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0599, 0.0389, 0.0338, 0.0278, 0.0738, 0.1715, 0.0787, 0.1026, 0.0642,
        0.0610, 0.0605, 0.0934, 0.0690, 0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,696][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1689, 0.0515, 0.0631, 0.0579, 0.0689, 0.0536, 0.0651, 0.0538, 0.0583,
        0.0638, 0.0724, 0.0730, 0.0756, 0.0740], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,697][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([5.3928e-06, 4.8377e-07, 8.1132e-06, 1.4343e-08, 4.6363e-03, 1.2364e-04,
        8.6367e-07, 5.7318e-01, 6.6389e-05, 4.0932e-01, 8.5048e-08, 4.9728e-06,
        4.5936e-03, 8.0628e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,699][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0282, 0.0167, 0.0065, 0.0036, 0.0370, 0.0293, 0.0382, 0.0448, 0.1121,
        0.2148, 0.0125, 0.0401, 0.1557, 0.1521, 0.1085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,701][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0527, 0.0299, 0.0645, 0.0342, 0.0507, 0.0511, 0.0660, 0.1298, 0.0602,
        0.1425, 0.0830, 0.0579, 0.0703, 0.0304, 0.0767], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,702][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.2434, 0.0631, 0.0137, 0.0510, 0.0568, 0.0508, 0.0438, 0.0887, 0.0435,
        0.0637, 0.0548, 0.0600, 0.0657, 0.0792, 0.0218], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,703][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0124, 0.0644, 0.0866, 0.0642, 0.0940, 0.0597, 0.0680, 0.0599, 0.0728,
        0.0708, 0.0641, 0.0594, 0.0730, 0.0660, 0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,703][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.6679, 0.0137, 0.0181, 0.0144, 0.0074, 0.0225, 0.0106, 0.0287, 0.0329,
        0.0605, 0.0231, 0.0153, 0.0271, 0.0211, 0.0367], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,704][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.1939, 0.0128, 0.0085, 0.0057, 0.0986, 0.0253, 0.0307, 0.1053, 0.0574,
        0.1196, 0.0541, 0.0311, 0.0821, 0.1043, 0.0707], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,704][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0711, 0.0681, 0.0659, 0.0616, 0.0715, 0.0639, 0.0639, 0.0690, 0.0687,
        0.0658, 0.0615, 0.0628, 0.0678, 0.0668, 0.0717], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,705][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0060, 0.0012, 0.0081, 0.0051, 0.0866, 0.0058, 0.0585, 0.0554, 0.1247,
        0.0292, 0.0659, 0.3756, 0.0788, 0.0428, 0.0563], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,705][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.2304, 0.0364, 0.0276, 0.0405, 0.0578, 0.1085, 0.0899, 0.0903, 0.0620,
        0.0527, 0.0359, 0.0574, 0.0362, 0.0485, 0.0260], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,706][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0511, 0.0294, 0.0322, 0.0287, 0.0640, 0.1799, 0.0599, 0.0771, 0.0821,
        0.0597, 0.0703, 0.0698, 0.0792, 0.0807, 0.0357], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,706][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.1513, 0.0525, 0.0613, 0.0556, 0.0646, 0.0557, 0.0613, 0.0507, 0.0538,
        0.0614, 0.0645, 0.0658, 0.0762, 0.0665, 0.0588], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,707][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([5.4236e-04, 5.6358e-05, 4.6181e-07, 3.3725e-08, 3.3624e-04, 1.2006e-04,
        9.1239e-07, 7.7397e-01, 2.2019e-04, 7.5048e-02, 4.0275e-08, 2.3293e-06,
        2.7963e-04, 1.4784e-01, 1.5740e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,709][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1248, 0.0313, 0.0089, 0.0063, 0.0303, 0.0234, 0.0262, 0.0144, 0.0610,
        0.0474, 0.0075, 0.0508, 0.0808, 0.0638, 0.0774, 0.3458],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,710][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0554, 0.0276, 0.0716, 0.0337, 0.0438, 0.0445, 0.0566, 0.1113, 0.0597,
        0.1202, 0.0802, 0.0550, 0.0637, 0.0313, 0.0884, 0.0568],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,712][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2450, 0.0690, 0.0107, 0.0439, 0.0449, 0.0376, 0.0330, 0.0845, 0.0419,
        0.0687, 0.0443, 0.0723, 0.0577, 0.0859, 0.0192, 0.0414],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,713][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0109, 0.0661, 0.0977, 0.0613, 0.1007, 0.0560, 0.0584, 0.0554, 0.0610,
        0.0587, 0.0549, 0.0544, 0.0654, 0.0626, 0.0901, 0.0465],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,715][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.6358, 0.0144, 0.0162, 0.0137, 0.0057, 0.0283, 0.0105, 0.0314, 0.0278,
        0.0698, 0.0200, 0.0134, 0.0306, 0.0193, 0.0312, 0.0321],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,717][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.2752, 0.0205, 0.0149, 0.0071, 0.0879, 0.0125, 0.0201, 0.0542, 0.0365,
        0.0666, 0.0288, 0.0277, 0.0594, 0.0560, 0.0807, 0.1517],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,719][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0663, 0.0632, 0.0613, 0.0574, 0.0663, 0.0594, 0.0597, 0.0646, 0.0645,
        0.0617, 0.0576, 0.0588, 0.0635, 0.0625, 0.0675, 0.0655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,720][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0006, 0.0052, 0.0009, 0.0250, 0.0032, 0.0083, 0.0547, 0.0134, 0.2604,
        0.0094, 0.0359, 0.2655, 0.0301, 0.1387, 0.0067, 0.1418],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,720][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2207, 0.0286, 0.0345, 0.0360, 0.0514, 0.0802, 0.0764, 0.1123, 0.0569,
        0.0656, 0.0407, 0.0429, 0.0321, 0.0350, 0.0331, 0.0536],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,721][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0254, 0.0403, 0.0225, 0.0370, 0.0486, 0.1418, 0.0605, 0.0963, 0.0787,
        0.0734, 0.0751, 0.0904, 0.0495, 0.1040, 0.0250, 0.0316],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,721][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1268, 0.0487, 0.0575, 0.0516, 0.0615, 0.0523, 0.0556, 0.0496, 0.0509,
        0.0583, 0.0613, 0.0595, 0.0761, 0.0637, 0.0568, 0.0698],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,722][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([4.0917e-05, 5.8222e-06, 5.2363e-05, 4.4735e-08, 1.1456e-02, 2.2107e-04,
        7.4446e-07, 4.0820e-01, 3.5645e-05, 1.0328e-01, 3.2222e-08, 1.4980e-06,
        3.6974e-03, 4.6446e-02, 4.1862e-01, 7.9430e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:55,722][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0052, 0.0077, 0.0021, 0.0011, 0.0058, 0.0110, 0.0044, 0.0070, 0.0256,
        0.0380, 0.0028, 0.0094, 0.0694, 0.0358, 0.0417, 0.6576, 0.0754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,723][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0438, 0.0268, 0.0668, 0.0320, 0.0447, 0.0461, 0.0451, 0.0930, 0.0541,
        0.1235, 0.0686, 0.0443, 0.0699, 0.0297, 0.0850, 0.0736, 0.0528],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,723][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2590, 0.0631, 0.0113, 0.0410, 0.0307, 0.0417, 0.0307, 0.1034, 0.0358,
        0.0460, 0.0408, 0.0516, 0.0532, 0.0818, 0.0205, 0.0526, 0.0368],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,723][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0091, 0.0616, 0.0865, 0.0603, 0.0879, 0.0557, 0.0517, 0.0507, 0.0591,
        0.0638, 0.0540, 0.0495, 0.0664, 0.0595, 0.0820, 0.0487, 0.0534],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,725][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6372, 0.0135, 0.0136, 0.0142, 0.0061, 0.0284, 0.0128, 0.0304, 0.0274,
        0.0712, 0.0184, 0.0127, 0.0263, 0.0188, 0.0280, 0.0245, 0.0166],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,727][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1549, 0.0182, 0.0210, 0.0093, 0.1072, 0.0145, 0.0131, 0.0581, 0.0331,
        0.0626, 0.0273, 0.0268, 0.0675, 0.0564, 0.0876, 0.1863, 0.0561],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,729][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0625, 0.0592, 0.0577, 0.0541, 0.0624, 0.0559, 0.0561, 0.0607, 0.0603,
        0.0583, 0.0543, 0.0555, 0.0601, 0.0587, 0.0637, 0.0619, 0.0585],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,730][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0005, 0.0015, 0.0010, 0.0083, 0.0023, 0.0018, 0.0356, 0.0136, 0.0507,
        0.0034, 0.0234, 0.5138, 0.0230, 0.0338, 0.0071, 0.0392, 0.2410],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,732][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1573, 0.0352, 0.0387, 0.0421, 0.0581, 0.0947, 0.0635, 0.1117, 0.0554,
        0.0610, 0.0335, 0.0451, 0.0364, 0.0375, 0.0337, 0.0496, 0.0466],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,734][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0341, 0.0358, 0.0357, 0.0291, 0.0854, 0.1578, 0.0438, 0.0767, 0.0715,
        0.0495, 0.0681, 0.0586, 0.0568, 0.0753, 0.0392, 0.0497, 0.0328],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,736][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1109, 0.0460, 0.0563, 0.0505, 0.0590, 0.0483, 0.0550, 0.0456, 0.0468,
        0.0534, 0.0580, 0.0587, 0.0675, 0.0583, 0.0533, 0.0618, 0.0706],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,736][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.7101e-07, 9.4124e-06, 2.5212e-05, 3.1854e-08, 6.2316e-03, 1.8879e-04,
        4.6831e-08, 4.2182e-01, 5.5181e-05, 4.2388e-02, 1.9747e-08, 1.3549e-07,
        5.4634e-03, 1.6442e-01, 2.2127e-01, 1.3803e-01, 1.0796e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:55,737][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0111, 0.0030, 0.0007, 0.0007, 0.0021, 0.0060, 0.0045, 0.0106, 0.0201,
        0.0397, 0.0014, 0.0061, 0.0239, 0.0361, 0.0184, 0.2913, 0.0818, 0.4426],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,738][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0503, 0.0277, 0.0553, 0.0326, 0.0389, 0.0441, 0.0499, 0.0818, 0.0568,
        0.0852, 0.0671, 0.0452, 0.0591, 0.0301, 0.0688, 0.0653, 0.0597, 0.0821],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,738][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.3039, 0.0521, 0.0113, 0.0383, 0.0374, 0.0395, 0.0170, 0.0477, 0.0232,
        0.0550, 0.0445, 0.0331, 0.0644, 0.0635, 0.0200, 0.0509, 0.0192, 0.0791],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,738][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0069, 0.0563, 0.0778, 0.0556, 0.0808, 0.0519, 0.0549, 0.0449, 0.0553,
        0.0515, 0.0481, 0.0484, 0.0595, 0.0542, 0.0711, 0.0452, 0.0560, 0.0817],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,739][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.6902, 0.0103, 0.0106, 0.0108, 0.0049, 0.0202, 0.0073, 0.0206, 0.0237,
        0.0634, 0.0143, 0.0086, 0.0184, 0.0183, 0.0281, 0.0243, 0.0101, 0.0158],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,739][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.0836, 0.0097, 0.0097, 0.0067, 0.0486, 0.0171, 0.0159, 0.0665, 0.0382,
        0.0598, 0.0203, 0.0190, 0.0482, 0.0624, 0.0638, 0.1628, 0.0726, 0.1951],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,740][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0569, 0.0556, 0.0543, 0.0508, 0.0587, 0.0525, 0.0527, 0.0570, 0.0565,
        0.0547, 0.0512, 0.0524, 0.0568, 0.0553, 0.0601, 0.0580, 0.0549, 0.0617],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,740][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0012, 0.0024, 0.0014, 0.0105, 0.0078, 0.0054, 0.0112, 0.0069, 0.2316,
        0.0129, 0.0666, 0.1561, 0.0298, 0.0553, 0.0102, 0.1295, 0.0726, 0.1885],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,741][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.2463, 0.0239, 0.0307, 0.0280, 0.0616, 0.0783, 0.0555, 0.0819, 0.0451,
        0.0548, 0.0288, 0.0349, 0.0323, 0.0369, 0.0320, 0.0502, 0.0430, 0.0360],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,743][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0241, 0.0333, 0.0223, 0.0272, 0.0733, 0.1523, 0.0620, 0.0858, 0.0492,
        0.0625, 0.0427, 0.0655, 0.0669, 0.0753, 0.0247, 0.0558, 0.0444, 0.0329],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,745][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0768, 0.0434, 0.0489, 0.0457, 0.0565, 0.0488, 0.0493, 0.0466, 0.0476,
        0.0565, 0.0579, 0.0548, 0.0709, 0.0555, 0.0537, 0.0604, 0.0590, 0.0676],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,746][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([1.0848e-04, 3.4802e-06, 7.1356e-06, 1.2948e-08, 2.3991e-03, 8.9542e-05,
        8.8865e-07, 2.5181e-01, 2.6940e-05, 4.5076e-02, 4.8067e-09, 1.1448e-06,
        2.8193e-04, 7.9099e-02, 6.4052e-02, 1.2505e-02, 1.6010e-03, 5.4294e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:55,747][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0058, 0.0032, 0.0009, 0.0007, 0.0028, 0.0053, 0.0044, 0.0063, 0.0156,
        0.0341, 0.0008, 0.0063, 0.0275, 0.0327, 0.0153, 0.3020, 0.0603, 0.4636,
        0.0124], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,749][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0413, 0.0242, 0.0615, 0.0267, 0.0414, 0.0348, 0.0483, 0.0834, 0.0441,
        0.1115, 0.0605, 0.0435, 0.0618, 0.0269, 0.0767, 0.0495, 0.0552, 0.0748,
        0.0340], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,751][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2685, 0.0564, 0.0105, 0.0368, 0.0245, 0.0321, 0.0260, 0.0847, 0.0332,
        0.0386, 0.0343, 0.0409, 0.0406, 0.0674, 0.0185, 0.0475, 0.0303, 0.0688,
        0.0402], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,753][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0081, 0.0522, 0.0730, 0.0495, 0.0761, 0.0475, 0.0495, 0.0426, 0.0525,
        0.0564, 0.0439, 0.0461, 0.0579, 0.0492, 0.0693, 0.0428, 0.0520, 0.0775,
        0.0539], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,754][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.6636, 0.0106, 0.0133, 0.0117, 0.0051, 0.0218, 0.0082, 0.0249, 0.0238,
        0.0691, 0.0170, 0.0095, 0.0234, 0.0160, 0.0233, 0.0235, 0.0102, 0.0113,
        0.0137], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,755][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0971, 0.0112, 0.0088, 0.0068, 0.0656, 0.0127, 0.0142, 0.0717, 0.0296,
        0.0598, 0.0210, 0.0181, 0.0475, 0.0521, 0.0505, 0.1159, 0.0534, 0.2320,
        0.0319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,755][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0539, 0.0525, 0.0514, 0.0481, 0.0553, 0.0497, 0.0497, 0.0539, 0.0535,
        0.0519, 0.0486, 0.0496, 0.0537, 0.0522, 0.0568, 0.0549, 0.0518, 0.0584,
        0.0540], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,755][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0006, 0.0019, 0.0007, 0.0125, 0.0036, 0.0021, 0.0345, 0.0062, 0.0963,
        0.0123, 0.0470, 0.3483, 0.0087, 0.0339, 0.0041, 0.0390, 0.1625, 0.0287,
        0.1571], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,756][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1992, 0.0318, 0.0314, 0.0420, 0.0540, 0.0756, 0.0573, 0.0917, 0.0551,
        0.0501, 0.0295, 0.0398, 0.0321, 0.0397, 0.0295, 0.0401, 0.0415, 0.0353,
        0.0243], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,756][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0392, 0.0264, 0.0288, 0.0226, 0.0650, 0.1194, 0.0651, 0.0692, 0.0647,
        0.0452, 0.0514, 0.0642, 0.0642, 0.0659, 0.0316, 0.0430, 0.0485, 0.0356,
        0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,757][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0814, 0.0404, 0.0477, 0.0449, 0.0521, 0.0461, 0.0491, 0.0413, 0.0418,
        0.0490, 0.0523, 0.0504, 0.0592, 0.0517, 0.0479, 0.0558, 0.0589, 0.0657,
        0.0643], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,757][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.3104e-09, 4.2312e-09, 1.9550e-07, 7.2356e-12, 2.8254e-04, 2.0833e-07,
        3.1005e-10, 8.9467e-03, 8.5084e-09, 2.0772e-03, 2.4361e-12, 2.5729e-10,
        1.0358e-04, 1.0610e-04, 1.2601e-03, 2.8080e-04, 6.4547e-07, 9.8694e-01,
        3.3426e-07], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:55,759][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:55,761][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[19712],
        [ 4979],
        [ 7528],
        [15027],
        [ 3815],
        [11143],
        [18758],
        [ 8689],
        [ 6336],
        [12864],
        [ 3736],
        [ 6571],
        [ 2599],
        [ 7027],
        [ 6879],
        [13287],
        [16069],
        [11342],
        [ 8124]], device='cuda:0')
[2024-07-24 10:18:55,762][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21434],
        [ 3295],
        [ 6280],
        [18252],
        [ 3231],
        [11106],
        [17838],
        [ 7244],
        [ 5368],
        [10732],
        [ 4859],
        [ 5814],
        [ 1649],
        [ 6316],
        [ 6492],
        [10683],
        [17138],
        [16341],
        [ 8055]], device='cuda:0')
[2024-07-24 10:18:55,764][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11457],
        [ 4867],
        [ 5257],
        [ 7005],
        [22989],
        [22734],
        [18643],
        [15852],
        [15929],
        [10504],
        [ 7398],
        [ 8845],
        [ 9078],
        [ 7168],
        [ 7073],
        [11167],
        [14823],
        [ 8797],
        [ 9154]], device='cuda:0')
[2024-07-24 10:18:55,766][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[21149],
        [15300],
        [18473],
        [18102],
        [17233],
        [16272],
        [17015],
        [18426],
        [19221],
        [20624],
        [21535],
        [21955],
        [20879],
        [21499],
        [21943],
        [21257],
        [20886],
        [20295],
        [21162]], device='cuda:0')
[2024-07-24 10:18:55,768][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18103],
        [17869],
        [12090],
        [13670],
        [ 7448],
        [15265],
        [12206],
        [16870],
        [15165],
        [12123],
        [14293],
        [14225],
        [12211],
        [12338],
        [12364],
        [15013],
        [16847],
        [ 5724],
        [11411]], device='cuda:0')
[2024-07-24 10:18:55,769][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6085],
        [ 7409],
        [ 9036],
        [ 9459],
        [11016],
        [11689],
        [10898],
        [11130],
        [10358],
        [12020],
        [12263],
        [12145],
        [12932],
        [13367],
        [14019],
        [14220],
        [14405],
        [14939],
        [15450]], device='cuda:0')
[2024-07-24 10:18:55,771][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 2305],
        [ 6897],
        [ 3328],
        [ 7324],
        [ 7853],
        [ 5664],
        [ 5496],
        [ 8388],
        [12003],
        [11665],
        [12071],
        [ 6732],
        [10147],
        [11080],
        [11136],
        [13894],
        [ 9940],
        [12562],
        [12550]], device='cuda:0')
[2024-07-24 10:18:55,773][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[  796],
        [  996],
        [ 4418],
        [ 4590],
        [ 9465],
        [35255],
        [36229],
        [12706],
        [27950],
        [22148],
        [13429],
        [28459],
        [ 3855],
        [21633],
        [ 2520],
        [ 3703],
        [16093],
        [ 2824],
        [12129]], device='cuda:0')
[2024-07-24 10:18:55,774][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35395],
        [33224],
        [30317],
        [37210],
        [33392],
        [33201],
        [33374],
        [32346],
        [29348],
        [39296],
        [35152],
        [36359],
        [37101],
        [36426],
        [36703],
        [41066],
        [40103],
        [37360],
        [39152]], device='cuda:0')
[2024-07-24 10:18:55,775][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[42101],
        [42145],
        [41989],
        [41962],
        [41593],
        [41673],
        [41709],
        [41704],
        [41734],
        [41681],
        [41461],
        [41491],
        [41255],
        [41031],
        [40828],
        [40650],
        [40539],
        [40377],
        [40351]], device='cuda:0')
[2024-07-24 10:18:55,776][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11159],
        [13747],
        [15234],
        [16906],
        [18032],
        [17889],
        [17471],
        [17032],
        [17735],
        [18017],
        [18218],
        [18174],
        [18175],
        [18522],
        [18221],
        [17768],
        [17331],
        [17037],
        [16854]], device='cuda:0')
[2024-07-24 10:18:55,777][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12122],
        [11452],
        [12482],
        [11931],
        [11526],
        [10978],
        [10984],
        [11261],
        [11453],
        [11163],
        [11116],
        [10991],
        [10560],
        [10609],
        [10786],
        [10646],
        [10668],
        [10757],
        [10979]], device='cuda:0')
[2024-07-24 10:18:55,779][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16311],
        [24807],
        [29109],
        [28530],
        [44152],
        [39604],
        [37189],
        [27814],
        [31886],
        [30661],
        [30298],
        [28169],
        [32097],
        [29517],
        [30054],
        [28355],
        [29870],
        [29069],
        [28867]], device='cuda:0')
[2024-07-24 10:18:55,781][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23363],
        [27436],
        [27445],
        [25406],
        [27306],
        [28184],
        [26578],
        [24326],
        [33460],
        [23334],
        [15520],
        [28350],
        [27834],
        [10306],
        [12148],
        [15985],
        [10803],
        [23857],
        [11161]], device='cuda:0')
[2024-07-24 10:18:55,782][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7107],
        [23622],
        [19972],
        [15569],
        [14691],
        [15706],
        [18175],
        [34399],
        [13988],
        [26608],
        [20724],
        [14840],
        [25980],
        [30428],
        [33415],
        [29861],
        [16293],
        [26804],
        [31020]], device='cuda:0')
[2024-07-24 10:18:55,784][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15851],
        [ 9963],
        [10974],
        [ 9995],
        [11701],
        [10377],
        [ 8426],
        [ 5739],
        [ 9202],
        [ 9701],
        [ 8984],
        [ 9139],
        [11691],
        [12523],
        [12619],
        [16217],
        [16902],
        [21028],
        [21336]], device='cuda:0')
[2024-07-24 10:18:55,786][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[47579],
        [47862],
        [48716],
        [48619],
        [48609],
        [48693],
        [48399],
        [47225],
        [46957],
        [46288],
        [46002],
        [46146],
        [45636],
        [45553],
        [45718],
        [45970],
        [45935],
        [46077],
        [45978]], device='cuda:0')
[2024-07-24 10:18:55,787][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[6945],
        [5228],
        [4798],
        [4681],
        [5216],
        [4062],
        [3945],
        [6369],
        [5720],
        [5560],
        [5241],
        [5173],
        [4645],
        [4171],
        [3885],
        [3778],
        [3848],
        [4119],
        [4330]], device='cuda:0')
[2024-07-24 10:18:55,789][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10280],
        [ 6314],
        [ 6591],
        [ 6563],
        [ 6282],
        [ 6356],
        [ 6628],
        [ 6764],
        [ 6744],
        [ 6544],
        [ 6227],
        [ 6399],
        [ 6296],
        [ 6167],
        [ 6102],
        [ 6118],
        [ 6194],
        [ 6296],
        [ 6283]], device='cuda:0')
[2024-07-24 10:18:55,791][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[14843],
        [ 9473],
        [ 5671],
        [ 3765],
        [ 4610],
        [ 3122],
        [ 3361],
        [ 2955],
        [ 3007],
        [ 2461],
        [ 2271],
        [ 2343],
        [ 2203],
        [ 2685],
        [ 2364],
        [ 2391],
        [ 2479],
        [ 2441],
        [ 2420]], device='cuda:0')
[2024-07-24 10:18:55,792][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9810],
        [10675],
        [11026],
        [11808],
        [10375],
        [10136],
        [ 9771],
        [ 8443],
        [ 8043],
        [ 7889],
        [ 8611],
        [ 8418],
        [ 8880],
        [ 9004],
        [ 8605],
        [ 8878],
        [ 8835],
        [ 8241],
        [ 8127]], device='cuda:0')
[2024-07-24 10:18:55,793][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21089],
        [24921],
        [24512],
        [24727],
        [24323],
        [24439],
        [24692],
        [24627],
        [24526],
        [24751],
        [25040],
        [25348],
        [25612],
        [25722],
        [25439],
        [25551],
        [25479],
        [25370],
        [25327]], device='cuda:0')
[2024-07-24 10:18:55,794][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35351],
        [18577],
        [27928],
        [24033],
        [28938],
        [17109],
        [34864],
        [27859],
        [32039],
        [29845],
        [32361],
        [36812],
        [35378],
        [35535],
        [34777],
        [33235],
        [36448],
        [30631],
        [35466]], device='cuda:0')
[2024-07-24 10:18:55,795][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[1647],
        [1958],
        [2262],
        [2921],
        [3140],
        [2465],
        [2581],
        [2608],
        [2789],
        [2722],
        [2964],
        [2933],
        [2742],
        [3009],
        [2954],
        [3081],
        [3150],
        [3053],
        [3158]], device='cuda:0')
[2024-07-24 10:18:55,797][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27487],
        [26753],
        [19041],
        [17245],
        [16114],
        [12756],
        [12870],
        [12547],
        [13399],
        [13652],
        [13913],
        [14592],
        [14220],
        [14642],
        [14613],
        [15008],
        [14619],
        [14310],
        [14414]], device='cuda:0')
[2024-07-24 10:18:55,799][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8515],
        [ 7993],
        [10778],
        [12651],
        [14521],
        [14701],
        [17013],
        [17262],
        [18322],
        [18058],
        [20207],
        [21269],
        [22618],
        [22911],
        [23713],
        [24142],
        [25477],
        [26941],
        [27696]], device='cuda:0')
[2024-07-24 10:18:55,800][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[40874],
        [40874],
        [40597],
        [29414],
        [39653],
        [10865],
        [11400],
        [20935],
        [24672],
        [24509],
        [23231],
        [24035],
        [21800],
        [23119],
        [29202],
        [26872],
        [30749],
        [22591],
        [14391]], device='cuda:0')
[2024-07-24 10:18:55,802][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43260],
        [44626],
        [43728],
        [43524],
        [42919],
        [45321],
        [45126],
        [45450],
        [45034],
        [45240],
        [45415],
        [45125],
        [45163],
        [45005],
        [44814],
        [44360],
        [44009],
        [43817],
        [44203]], device='cuda:0')
[2024-07-24 10:18:55,804][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[43764],
        [37443],
        [37717],
        [44431],
        [45035],
        [47573],
        [46819],
        [44860],
        [46236],
        [43622],
        [40821],
        [44522],
        [40738],
        [37533],
        [37479],
        [40767],
        [44006],
        [40280],
        [36638]], device='cuda:0')
[2024-07-24 10:18:55,806][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142],
        [8142]], device='cuda:0')
[2024-07-24 10:18:55,845][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:55,845][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,846][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,846][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,846][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,847][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,847][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,847][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,849][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,849][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,849][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,850][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,850][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:55,851][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3536, 0.6464], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,853][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3533, 0.6467], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,854][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1124, 0.8876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,856][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.7187, 0.2813], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,857][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6311, 0.3689], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,859][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1546, 0.8454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,861][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4757, 0.5243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,862][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9959, 0.0041], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,863][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0721, 0.9279], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,863][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3289, 0.6711], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,863][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8871, 0.1129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,864][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4133, 0.5867], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:55,864][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.2989, 0.3255, 0.3756], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,864][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([6.4638e-04, 9.8639e-01, 1.2965e-02], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,865][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0653, 0.4671, 0.4676], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,865][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.5650, 0.2305, 0.2045], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,865][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2145, 0.4255, 0.3600], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,866][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0135, 0.4136, 0.5729], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,866][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.2410, 0.4424, 0.3166], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,867][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.8298, 0.0683, 0.1019], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,868][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0255, 0.4318, 0.5427], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,870][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.1396, 0.5680, 0.2924], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,871][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.4347, 0.0882, 0.4771], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,873][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.3552, 0.3537, 0.2910], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:55,874][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2292, 0.2598, 0.2807, 0.2302], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,876][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0040, 0.1608, 0.8006, 0.0346], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,877][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0354, 0.3069, 0.3645, 0.2932], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,879][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5034, 0.1672, 0.1861, 0.1433], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,880][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2028, 0.2855, 0.3607, 0.1510], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,880][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0142, 0.1524, 0.6963, 0.1371], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,880][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1921, 0.2441, 0.3392, 0.2246], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,881][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.7540e-01, 9.4074e-03, 1.4528e-02, 6.6935e-04], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,881][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0166, 0.2638, 0.4598, 0.2597], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,881][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1510, 0.4140, 0.1837, 0.2513], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,882][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5435, 0.0661, 0.2770, 0.1134], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,882][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1303, 0.0982, 0.0388, 0.7327], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:55,882][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.1809, 0.1652, 0.1759, 0.1627, 0.3153], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,883][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0007, 0.6533, 0.0325, 0.3016, 0.0119], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,883][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.0287, 0.2400, 0.2515, 0.2508, 0.2289], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,884][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.3859, 0.1414, 0.1380, 0.1273, 0.2074], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,885][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.2396, 0.1762, 0.1566, 0.1096, 0.3180], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,887][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.0083, 0.1589, 0.4885, 0.1582, 0.1861], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,888][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0928, 0.2643, 0.1815, 0.3143, 0.1471], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,890][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.7886, 0.0400, 0.0798, 0.0052, 0.0864], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,891][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.0117, 0.2077, 0.2738, 0.2281, 0.2787], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,893][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.0613, 0.3928, 0.2110, 0.2329, 0.1020], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,895][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.2524, 0.0286, 0.3316, 0.0519, 0.3355], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,896][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.2372, 0.2644, 0.1579, 0.1129, 0.2277], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:55,897][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1432, 0.1651, 0.1517, 0.1148, 0.2698, 0.1554], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,898][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0120, 0.1779, 0.0422, 0.1414, 0.6106, 0.0158], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,898][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0230, 0.1858, 0.2033, 0.1841, 0.1923, 0.2115], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,898][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2337, 0.1257, 0.1458, 0.1127, 0.2573, 0.1248], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,899][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0854, 0.1151, 0.1725, 0.0675, 0.4178, 0.1417], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,899][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0223, 0.1605, 0.2407, 0.1620, 0.2919, 0.1226], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,899][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1326, 0.1650, 0.1898, 0.1752, 0.2293, 0.1080], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,900][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.8787, 0.0380, 0.0444, 0.0063, 0.0177, 0.0149], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,900][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0110, 0.1695, 0.2343, 0.1704, 0.2581, 0.1567], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,900][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1231, 0.3187, 0.1750, 0.1683, 0.0696, 0.1452], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,901][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3089, 0.0530, 0.3482, 0.0836, 0.0912, 0.1150], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,902][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0581, 0.0531, 0.0065, 0.0986, 0.0101, 0.7736], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:55,903][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1410, 0.1380, 0.1213, 0.1120, 0.2213, 0.1390, 0.1275],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,905][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0014, 0.1358, 0.0513, 0.0841, 0.6447, 0.0786, 0.0041],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,907][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0159, 0.1478, 0.1730, 0.1529, 0.1732, 0.1819, 0.1553],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,908][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2558, 0.0935, 0.1287, 0.0976, 0.2215, 0.1236, 0.0793],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,910][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0260, 0.0802, 0.1658, 0.0625, 0.4159, 0.1768, 0.0729],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,911][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0116, 0.1286, 0.2597, 0.1263, 0.2934, 0.1120, 0.0686],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,913][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0906, 0.1482, 0.1672, 0.1726, 0.2450, 0.1082, 0.0682],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,914][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.7550e-01, 8.1471e-03, 5.0441e-03, 6.0238e-04, 1.8259e-03, 7.0897e-03,
        1.7902e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,915][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0084, 0.1393, 0.2146, 0.1463, 0.2189, 0.1595, 0.1130],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,915][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1138, 0.2403, 0.1546, 0.1559, 0.0634, 0.1526, 0.1194],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,915][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1305, 0.0505, 0.4554, 0.0564, 0.2175, 0.0536, 0.0362],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,916][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1090, 0.0660, 0.0914, 0.1451, 0.0690, 0.1584, 0.3610],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:55,916][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.1249, 0.1219, 0.0995, 0.0917, 0.2137, 0.1294, 0.1096, 0.1092],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,917][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0498, 0.5365, 0.0851, 0.0943, 0.1182, 0.0266, 0.0572, 0.0324],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,917][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0140, 0.1265, 0.1385, 0.1312, 0.1344, 0.1503, 0.1417, 0.1633],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,917][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2112, 0.0625, 0.0955, 0.0804, 0.1939, 0.1009, 0.0664, 0.1892],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,918][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0589, 0.0482, 0.0656, 0.0380, 0.2380, 0.1091, 0.0499, 0.3923],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,918][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0140, 0.0991, 0.2994, 0.1017, 0.2286, 0.1128, 0.0826, 0.0618],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,919][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0737, 0.1881, 0.1092, 0.2417, 0.1150, 0.1325, 0.1004, 0.0394],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,921][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.9438, 0.0093, 0.0104, 0.0016, 0.0035, 0.0175, 0.0091, 0.0048],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,922][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0061, 0.1224, 0.1723, 0.1319, 0.1858, 0.1372, 0.1074, 0.1369],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,924][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1300, 0.2246, 0.0949, 0.0965, 0.0338, 0.1147, 0.0931, 0.2124],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,925][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.3843, 0.0346, 0.0888, 0.0498, 0.2364, 0.0374, 0.0544, 0.1144],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,927][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0428, 0.1178, 0.0379, 0.1441, 0.0191, 0.2035, 0.1129, 0.3218],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:55,929][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1052, 0.1028, 0.0895, 0.0790, 0.1787, 0.0985, 0.0910, 0.0802, 0.1752],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,930][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([1.5853e-04, 7.5181e-03, 3.4843e-02, 1.9701e-03, 9.0035e-01, 1.6955e-02,
        5.0385e-03, 3.2371e-02, 7.9503e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,931][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0109, 0.1035, 0.1215, 0.1044, 0.1237, 0.1337, 0.1158, 0.1587, 0.1277],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,932][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1905, 0.0688, 0.1037, 0.0749, 0.1902, 0.1029, 0.0711, 0.0954, 0.1026],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,933][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1289, 0.0730, 0.0762, 0.0519, 0.1662, 0.1308, 0.0805, 0.0849, 0.2077],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,933][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0064, 0.0708, 0.2721, 0.0663, 0.2500, 0.1114, 0.0730, 0.1247, 0.0252],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,933][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0743, 0.1385, 0.1431, 0.1354, 0.1938, 0.0969, 0.0854, 0.0691, 0.0635],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,934][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([9.9153e-01, 5.2411e-04, 2.6908e-03, 4.7756e-05, 1.2866e-03, 1.3325e-03,
        3.2550e-04, 2.0533e-03, 2.0701e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,934][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0055, 0.0977, 0.1744, 0.0994, 0.1929, 0.1177, 0.0959, 0.1451, 0.0715],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,935][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0891, 0.1548, 0.0613, 0.0787, 0.0228, 0.0856, 0.0698, 0.2491, 0.1889],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,935][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4934, 0.0346, 0.2193, 0.0610, 0.0585, 0.0293, 0.0281, 0.0294, 0.0464],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,935][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0853, 0.0553, 0.0231, 0.2339, 0.0212, 0.1261, 0.0367, 0.0583, 0.3602],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:55,936][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0663, 0.0836, 0.0746, 0.0678, 0.1618, 0.0904, 0.0796, 0.0713, 0.1636,
        0.1411], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,937][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0004, 0.2695, 0.0544, 0.0725, 0.0629, 0.0321, 0.1587, 0.0446, 0.3019,
        0.0029], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,938][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0107, 0.0945, 0.1097, 0.0997, 0.1034, 0.1196, 0.1106, 0.1409, 0.1319,
        0.0791], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,940][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1503, 0.0533, 0.0875, 0.0671, 0.1537, 0.0890, 0.0654, 0.1010, 0.1313,
        0.1013], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,941][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1331, 0.0382, 0.0580, 0.0203, 0.1875, 0.0727, 0.0569, 0.0868, 0.1774,
        0.1692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,943][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0054, 0.0490, 0.2460, 0.0533, 0.2788, 0.0782, 0.0571, 0.0643, 0.0425,
        0.1255], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,945][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0459, 0.1505, 0.0998, 0.1783, 0.0855, 0.1170, 0.1016, 0.0434, 0.1416,
        0.0364], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,946][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([9.5556e-01, 2.6947e-03, 1.5171e-02, 6.1460e-04, 2.2816e-03, 2.3101e-03,
        1.4037e-02, 1.1014e-03, 1.4352e-03, 4.7916e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,947][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0053, 0.0913, 0.1422, 0.0961, 0.1529, 0.1118, 0.0901, 0.1165, 0.0803,
        0.1135], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,949][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0478, 0.1534, 0.0661, 0.0780, 0.0283, 0.0907, 0.0713, 0.2039, 0.1612,
        0.0993], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,950][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.5899, 0.0183, 0.0936, 0.0148, 0.1524, 0.0298, 0.0095, 0.0199, 0.0325,
        0.0392], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,950][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.1358, 0.0924, 0.0616, 0.1095, 0.0798, 0.0471, 0.0178, 0.0698, 0.1144,
        0.2720], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:55,951][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0513, 0.0624, 0.0656, 0.0576, 0.1342, 0.0815, 0.0719, 0.0639, 0.1341,
        0.1322, 0.1454], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,951][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([4.2019e-04, 2.3262e-03, 1.8325e-02, 1.0525e-03, 9.6407e-01, 1.9405e-03,
        5.0392e-03, 1.9968e-03, 2.1042e-03, 2.7041e-03, 2.1667e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,952][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0096, 0.0863, 0.0972, 0.0870, 0.0990, 0.1106, 0.1023, 0.1261, 0.1137,
        0.0871, 0.0812], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,952][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.1577, 0.0593, 0.0917, 0.0626, 0.1512, 0.0840, 0.0635, 0.0956, 0.0918,
        0.0810, 0.0616], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,952][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0315, 0.0648, 0.0958, 0.0335, 0.2562, 0.1075, 0.0677, 0.0508, 0.1194,
        0.1415, 0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,953][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0102, 0.0566, 0.2301, 0.0673, 0.1899, 0.0635, 0.0749, 0.0884, 0.0335,
        0.1713, 0.0142], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,953][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0628, 0.1021, 0.1408, 0.1101, 0.1626, 0.0737, 0.0720, 0.0516, 0.0468,
        0.1054, 0.0722], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,954][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.8921, 0.0084, 0.0366, 0.0009, 0.0062, 0.0122, 0.0085, 0.0140, 0.0013,
        0.0099, 0.0096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,954][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0048, 0.0746, 0.1303, 0.0816, 0.1496, 0.0961, 0.0820, 0.1219, 0.0650,
        0.1317, 0.0624], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,957][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0594, 0.1350, 0.0602, 0.0677, 0.0226, 0.0688, 0.0574, 0.2069, 0.1427,
        0.0935, 0.0858], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,958][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.3807, 0.0381, 0.2604, 0.0320, 0.0821, 0.0370, 0.0196, 0.0261, 0.0221,
        0.0434, 0.0586], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,959][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0550, 0.0457, 0.0446, 0.1289, 0.0243, 0.1090, 0.0707, 0.0221, 0.0998,
        0.0407, 0.3591], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:55,960][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0713, 0.0623, 0.0544, 0.0513, 0.1090, 0.0662, 0.0612, 0.0540, 0.1203,
        0.1076, 0.1333, 0.1091], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,962][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0050, 0.0576, 0.0548, 0.0401, 0.4500, 0.1547, 0.0123, 0.0550, 0.1126,
        0.0082, 0.0491, 0.0005], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,964][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0064, 0.0803, 0.0888, 0.0788, 0.0897, 0.0974, 0.0881, 0.1226, 0.1046,
        0.0846, 0.0803, 0.0784], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,965][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1616, 0.0597, 0.0952, 0.0621, 0.1520, 0.0837, 0.0586, 0.0933, 0.0775,
        0.0728, 0.0545, 0.0290], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,967][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0399, 0.1060, 0.1137, 0.0329, 0.2284, 0.1046, 0.0719, 0.0348, 0.0888,
        0.0928, 0.0333, 0.0530], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,969][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0075, 0.0656, 0.1779, 0.0713, 0.1396, 0.0837, 0.0582, 0.0823, 0.0524,
        0.1935, 0.0376, 0.0303], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,971][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0561, 0.0936, 0.1235, 0.0997, 0.1492, 0.0692, 0.0487, 0.0443, 0.0587,
        0.0879, 0.1344, 0.0345], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,971][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([9.7264e-01, 2.3865e-03, 6.4867e-03, 1.5848e-04, 9.2499e-04, 2.0246e-03,
        8.0429e-04, 8.3503e-04, 1.3245e-03, 4.6022e-03, 6.2694e-03, 1.5434e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,972][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0046, 0.0771, 0.1195, 0.0795, 0.1288, 0.0925, 0.0717, 0.1136, 0.0641,
        0.1216, 0.0715, 0.0556], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,973][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0371, 0.1172, 0.0587, 0.0704, 0.0256, 0.0774, 0.0626, 0.1981, 0.1360,
        0.0886, 0.0971, 0.0312], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,973][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2573, 0.0316, 0.3302, 0.0598, 0.1142, 0.0366, 0.0162, 0.0381, 0.0280,
        0.0193, 0.0378, 0.0308], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,974][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0665, 0.0574, 0.0411, 0.0827, 0.0271, 0.0875, 0.0891, 0.0403, 0.0555,
        0.0273, 0.0450, 0.3805], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:55,974][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0350, 0.0458, 0.0485, 0.0422, 0.1017, 0.0591, 0.0557, 0.0456, 0.1146,
        0.0921, 0.1222, 0.0969, 0.1406], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,975][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0007, 0.0387, 0.0119, 0.0403, 0.0174, 0.0155, 0.2680, 0.0717, 0.1885,
        0.0237, 0.1799, 0.1311, 0.0127], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,975][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0078, 0.0686, 0.0799, 0.0733, 0.0747, 0.0934, 0.0914, 0.1166, 0.0952,
        0.0696, 0.0683, 0.0833, 0.0779], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,975][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1908, 0.0503, 0.0728, 0.0498, 0.1241, 0.0665, 0.0519, 0.0866, 0.0800,
        0.0757, 0.0497, 0.0290, 0.0730], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,976][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0917, 0.0517, 0.0682, 0.0206, 0.1480, 0.0664, 0.0560, 0.0543, 0.1145,
        0.1014, 0.0310, 0.0622, 0.1340], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,977][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0043, 0.0595, 0.1748, 0.0579, 0.0880, 0.0602, 0.0634, 0.0675, 0.0349,
        0.1796, 0.0315, 0.0466, 0.1319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,978][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0466, 0.0877, 0.0784, 0.0993, 0.0678, 0.0637, 0.0694, 0.0299, 0.0876,
        0.0541, 0.1845, 0.0594, 0.0717], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,980][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ station] are: tensor([7.7427e-01, 1.0669e-02, 1.2352e-02, 6.8789e-04, 3.2086e-03, 3.4800e-03,
        1.3812e-02, 4.4369e-03, 8.6448e-03, 1.7917e-02, 1.2426e-01, 1.8243e-02,
        8.0177e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,981][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0035, 0.0682, 0.1006, 0.0764, 0.1056, 0.0836, 0.0720, 0.0975, 0.0611,
        0.1032, 0.0629, 0.0602, 0.1051], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,983][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0363, 0.1330, 0.0535, 0.0704, 0.0246, 0.0731, 0.0552, 0.1751, 0.1255,
        0.0936, 0.0986, 0.0311, 0.0299], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,985][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0714, 0.0069, 0.0138, 0.0084, 0.0033, 0.0171, 0.0071, 0.0061, 0.0016,
        0.0008, 0.0220, 0.0129, 0.8287], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,986][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0642, 0.0640, 0.0373, 0.0989, 0.0135, 0.3676, 0.0247, 0.0054, 0.0828,
        0.0319, 0.0719, 0.0686, 0.0691], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:55,988][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0328, 0.0480, 0.0445, 0.0434, 0.0863, 0.0545, 0.0505, 0.0454, 0.0934,
        0.0886, 0.1106, 0.0885, 0.1097, 0.1037], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,989][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.3461e-04, 2.1430e-03, 2.1223e-02, 8.1315e-04, 8.8246e-01, 1.0740e-02,
        3.0665e-03, 1.4755e-02, 5.0213e-03, 1.0164e-02, 1.2192e-03, 1.3173e-03,
        4.6561e-02, 3.8481e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,990][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0065, 0.0669, 0.0751, 0.0663, 0.0750, 0.0858, 0.0761, 0.1002, 0.0861,
        0.0666, 0.0661, 0.0739, 0.0803, 0.0751], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,990][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1628, 0.0337, 0.0584, 0.0410, 0.1120, 0.0524, 0.0395, 0.0869, 0.0807,
        0.0890, 0.0661, 0.0384, 0.0884, 0.0507], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,990][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0316, 0.0152, 0.0167, 0.0106, 0.0457, 0.0293, 0.0175, 0.0490, 0.1204,
        0.1872, 0.0433, 0.1145, 0.2275, 0.0913], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,991][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0055, 0.0376, 0.1706, 0.0435, 0.1422, 0.0678, 0.0402, 0.0692, 0.0245,
        0.1372, 0.0194, 0.0264, 0.2018, 0.0142], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,991][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0341, 0.0504, 0.0876, 0.0609, 0.1238, 0.0535, 0.0553, 0.0416, 0.0429,
        0.0867, 0.0837, 0.0488, 0.2152, 0.0153], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,992][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.6164, 0.0039, 0.0164, 0.0011, 0.0028, 0.0053, 0.0237, 0.0094, 0.0145,
        0.0274, 0.1466, 0.1171, 0.0069, 0.0086], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,992][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0042, 0.0594, 0.1057, 0.0635, 0.1156, 0.0745, 0.0626, 0.0907, 0.0513,
        0.1014, 0.0578, 0.0532, 0.1118, 0.0482], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,993][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0402, 0.0883, 0.0448, 0.0516, 0.0176, 0.0617, 0.0486, 0.1884, 0.1264,
        0.0863, 0.0859, 0.0289, 0.0357, 0.0955], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,993][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2654, 0.0351, 0.1662, 0.0235, 0.0535, 0.0509, 0.0269, 0.0264, 0.0395,
        0.0188, 0.0400, 0.0518, 0.1574, 0.0446], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,994][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0800, 0.0919, 0.0338, 0.2475, 0.0267, 0.0978, 0.0235, 0.0258, 0.1262,
        0.0378, 0.0441, 0.0383, 0.0316, 0.0950], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:55,996][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0413, 0.0341, 0.0395, 0.0380, 0.0870, 0.0568, 0.0454, 0.0440, 0.0874,
        0.0765, 0.0880, 0.0718, 0.1025, 0.0942, 0.0934], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,997][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([2.2201e-04, 1.1188e-01, 1.0380e-03, 1.3960e-02, 1.5399e-02, 6.1417e-02,
        3.9921e-02, 1.5789e-02, 1.5045e-01, 1.8165e-02, 1.2299e-01, 3.4608e-02,
        3.4088e-02, 3.7842e-01, 1.6529e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:55,998][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0076, 0.0646, 0.0631, 0.0647, 0.0616, 0.0779, 0.0724, 0.0928, 0.0848,
        0.0595, 0.0622, 0.0693, 0.0706, 0.0850, 0.0637], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,000][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.1757, 0.0445, 0.0611, 0.0441, 0.1044, 0.0563, 0.0484, 0.0805, 0.0672,
        0.0715, 0.0451, 0.0265, 0.0587, 0.0433, 0.0727], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,002][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0919, 0.0340, 0.0230, 0.0158, 0.0630, 0.0533, 0.0380, 0.0539, 0.0909,
        0.1381, 0.0198, 0.0362, 0.1877, 0.0625, 0.0919], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,004][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0010, 0.0305, 0.0360, 0.0290, 0.0665, 0.0580, 0.0465, 0.0499, 0.0192,
        0.1651, 0.0213, 0.0374, 0.3663, 0.0169, 0.0563], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,005][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0424, 0.0971, 0.0590, 0.1035, 0.0608, 0.0690, 0.0622, 0.0386, 0.0726,
        0.0434, 0.1305, 0.0547, 0.0948, 0.0341, 0.0373], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,006][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.3672, 0.0146, 0.0302, 0.0026, 0.0135, 0.0099, 0.0213, 0.0495, 0.0171,
        0.1414, 0.1067, 0.0304, 0.0140, 0.0220, 0.1597], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,007][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0032, 0.0622, 0.0764, 0.0674, 0.0850, 0.0742, 0.0621, 0.0867, 0.0540,
        0.0886, 0.0551, 0.0532, 0.0977, 0.0591, 0.0752], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,007][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0272, 0.0890, 0.0434, 0.0566, 0.0252, 0.0696, 0.0482, 0.1486, 0.1097,
        0.0906, 0.0907, 0.0267, 0.0328, 0.1079, 0.0336], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,008][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.1920, 0.0232, 0.1655, 0.0190, 0.0348, 0.0281, 0.0143, 0.0604, 0.0225,
        0.0152, 0.0180, 0.0149, 0.1202, 0.0312, 0.2406], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,008][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0836, 0.0570, 0.0538, 0.0514, 0.0441, 0.2666, 0.0335, 0.0192, 0.0717,
        0.0392, 0.0541, 0.0871, 0.0193, 0.0544, 0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,009][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0321, 0.0331, 0.0330, 0.0295, 0.0731, 0.0362, 0.0367, 0.0339, 0.0774,
        0.0688, 0.0882, 0.0733, 0.1018, 0.0966, 0.0846, 0.1016],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,009][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0115, 0.0424, 0.0083, 0.0385, 0.1652, 0.0030, 0.0167, 0.0250, 0.0314,
        0.0085, 0.0673, 0.0152, 0.0196, 0.5328, 0.0128, 0.0017],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,010][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0065, 0.0592, 0.0664, 0.0595, 0.0612, 0.0692, 0.0675, 0.0867, 0.0758,
        0.0570, 0.0608, 0.0643, 0.0691, 0.0707, 0.0662, 0.0599],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,010][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1439, 0.0441, 0.0705, 0.0434, 0.1119, 0.0552, 0.0411, 0.0695, 0.0537,
        0.0623, 0.0397, 0.0256, 0.0668, 0.0401, 0.0842, 0.0480],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,011][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1065, 0.0337, 0.0489, 0.0137, 0.1004, 0.0299, 0.0271, 0.0166, 0.0379,
        0.0387, 0.0133, 0.0361, 0.1137, 0.0282, 0.1969, 0.1583],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,013][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0033, 0.0455, 0.0839, 0.0338, 0.0709, 0.0422, 0.0299, 0.0570, 0.0142,
        0.1723, 0.0297, 0.0315, 0.2255, 0.0245, 0.0962, 0.0394],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,014][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0313, 0.0915, 0.0771, 0.0905, 0.0716, 0.0431, 0.0401, 0.0246, 0.0598,
        0.0420, 0.0934, 0.0403, 0.1520, 0.0337, 0.0643, 0.0446],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,016][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.3323, 0.0773, 0.0188, 0.0081, 0.0261, 0.0243, 0.0406, 0.0249, 0.0319,
        0.0441, 0.1091, 0.0229, 0.0036, 0.0662, 0.0274, 0.1424],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,017][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0037, 0.0578, 0.0880, 0.0600, 0.0904, 0.0628, 0.0534, 0.0753, 0.0456,
        0.0775, 0.0555, 0.0463, 0.0910, 0.0507, 0.0845, 0.0576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,019][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0339, 0.0931, 0.0428, 0.0582, 0.0206, 0.0583, 0.0446, 0.1381, 0.1133,
        0.0787, 0.0856, 0.0254, 0.0323, 0.0994, 0.0332, 0.0424],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,021][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1919, 0.0238, 0.1465, 0.0156, 0.0485, 0.0205, 0.0141, 0.0208, 0.0322,
        0.0096, 0.0250, 0.0278, 0.1396, 0.0386, 0.2164, 0.0290],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,022][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0304, 0.0488, 0.0083, 0.1161, 0.0038, 0.2265, 0.0545, 0.0064, 0.0339,
        0.0202, 0.0275, 0.0670, 0.0170, 0.0393, 0.0099, 0.2906],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,024][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0470, 0.0339, 0.0321, 0.0304, 0.0662, 0.0373, 0.0350, 0.0302, 0.0718,
        0.0658, 0.0836, 0.0690, 0.0830, 0.0853, 0.0727, 0.0964, 0.0601],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,024][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.9110e-03, 4.9816e-02, 2.4415e-02, 4.0105e-02, 4.9277e-01, 3.2666e-02,
        1.2930e-03, 2.1973e-02, 5.0322e-02, 8.7508e-03, 2.8319e-02, 1.5209e-03,
        4.0185e-02, 1.6562e-01, 2.9431e-02, 9.4694e-03, 4.3203e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,025][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0057, 0.0545, 0.0645, 0.0548, 0.0643, 0.0657, 0.0565, 0.0802, 0.0697,
        0.0579, 0.0558, 0.0563, 0.0681, 0.0655, 0.0664, 0.0592, 0.0550],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,025][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1316, 0.0398, 0.0657, 0.0403, 0.1084, 0.0534, 0.0365, 0.0808, 0.0548,
        0.0595, 0.0391, 0.0212, 0.0678, 0.0424, 0.0741, 0.0533, 0.0311],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,025][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0338, 0.0364, 0.0408, 0.0136, 0.0944, 0.0380, 0.0156, 0.0249, 0.0427,
        0.0607, 0.0122, 0.0277, 0.1103, 0.0289, 0.1385, 0.2264, 0.0552],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,026][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0050, 0.0492, 0.0951, 0.0492, 0.1106, 0.0365, 0.0243, 0.0470, 0.0229,
        0.1386, 0.0191, 0.0216, 0.1507, 0.0213, 0.0998, 0.0858, 0.0232],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,026][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0360, 0.0600, 0.0663, 0.0697, 0.0943, 0.0418, 0.0280, 0.0323, 0.0455,
        0.0684, 0.0798, 0.0255, 0.1732, 0.0298, 0.0597, 0.0588, 0.0310],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,027][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([6.8619e-01, 3.2098e-03, 2.2545e-03, 2.1963e-04, 6.0023e-04, 2.0561e-03,
        7.2258e-04, 1.3220e-03, 1.6155e-03, 1.8706e-03, 6.5625e-03, 2.0738e-03,
        1.1577e-03, 1.7070e-03, 9.3601e-03, 2.7856e-01, 5.1669e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,027][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0036, 0.0536, 0.0814, 0.0564, 0.0830, 0.0617, 0.0439, 0.0748, 0.0459,
        0.0784, 0.0516, 0.0427, 0.0854, 0.0486, 0.0802, 0.0655, 0.0433],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,029][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0357, 0.0728, 0.0464, 0.0504, 0.0222, 0.0611, 0.0459, 0.1559, 0.0911,
        0.0790, 0.0746, 0.0244, 0.0341, 0.0909, 0.0363, 0.0470, 0.0321],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,031][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0772, 0.0182, 0.1664, 0.0207, 0.0720, 0.0225, 0.0140, 0.0329, 0.0135,
        0.0253, 0.0280, 0.0203, 0.2174, 0.0212, 0.2092, 0.0206, 0.0205],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,032][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0527, 0.0224, 0.0381, 0.0490, 0.0273, 0.0600, 0.1316, 0.0162, 0.0272,
        0.0401, 0.0503, 0.0951, 0.0474, 0.0293, 0.0571, 0.0661, 0.1903],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,034][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0362, 0.0290, 0.0321, 0.0278, 0.0695, 0.0384, 0.0343, 0.0305, 0.0615,
        0.0567, 0.0704, 0.0582, 0.0802, 0.0746, 0.0736, 0.0836, 0.0563, 0.0870],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,036][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0003, 0.0161, 0.0027, 0.0117, 0.0347, 0.0073, 0.0718, 0.1671, 0.0979,
        0.0082, 0.0938, 0.0451, 0.0069, 0.2991, 0.0044, 0.0156, 0.1166, 0.0007],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,038][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0065, 0.0535, 0.0563, 0.0528, 0.0526, 0.0638, 0.0611, 0.0728, 0.0650,
        0.0474, 0.0514, 0.0547, 0.0597, 0.0609, 0.0549, 0.0547, 0.0605, 0.0714],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,039][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0887, 0.0379, 0.0520, 0.0385, 0.0831, 0.0477, 0.0391, 0.0730, 0.0618,
        0.0576, 0.0385, 0.0236, 0.0560, 0.0401, 0.0684, 0.0551, 0.0345, 0.1042],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,041][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0589, 0.0269, 0.0193, 0.0106, 0.0511, 0.0293, 0.0179, 0.0362, 0.0599,
        0.0639, 0.0089, 0.0199, 0.0588, 0.0510, 0.0817, 0.1494, 0.0560, 0.2002],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,041][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.0007, 0.0232, 0.1183, 0.0207, 0.1089, 0.0311, 0.0187, 0.0508, 0.0138,
        0.0984, 0.0159, 0.0145, 0.2283, 0.0161, 0.1134, 0.0529, 0.0201, 0.0542],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,042][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0278, 0.0744, 0.0554, 0.0785, 0.0567, 0.0471, 0.0418, 0.0294, 0.0603,
        0.0466, 0.0944, 0.0422, 0.0969, 0.0277, 0.0423, 0.0601, 0.0521, 0.0663],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,042][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.4604, 0.0205, 0.0206, 0.0033, 0.0072, 0.0185, 0.0140, 0.0079, 0.0126,
        0.0448, 0.0628, 0.0291, 0.0351, 0.0163, 0.0715, 0.1446, 0.0178, 0.0130],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,043][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0025, 0.0482, 0.0709, 0.0527, 0.0787, 0.0580, 0.0497, 0.0710, 0.0441,
        0.0672, 0.0466, 0.0408, 0.0778, 0.0465, 0.0705, 0.0558, 0.0492, 0.0699],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,043][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0330, 0.0835, 0.0454, 0.0566, 0.0187, 0.0563, 0.0428, 0.1226, 0.0981,
        0.0779, 0.0803, 0.0235, 0.0317, 0.0964, 0.0314, 0.0420, 0.0316, 0.0283],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,044][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.1396, 0.0194, 0.0255, 0.0326, 0.0124, 0.0161, 0.0056, 0.0015, 0.0098,
        0.0045, 0.0121, 0.0090, 0.0055, 0.0441, 0.0257, 0.0045, 0.0068, 0.6252],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,044][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0820, 0.0474, 0.0327, 0.0342, 0.0469, 0.0716, 0.0450, 0.0086, 0.0829,
        0.0298, 0.0658, 0.0642, 0.0122, 0.0384, 0.0381, 0.1745, 0.0516, 0.0741],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,045][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0483, 0.0273, 0.0276, 0.0248, 0.0547, 0.0319, 0.0308, 0.0262, 0.0577,
        0.0514, 0.0612, 0.0562, 0.0714, 0.0737, 0.0627, 0.0826, 0.0546, 0.0782,
        0.0788], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,046][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.4177e-03, 1.6299e-03, 1.2837e-02, 4.0973e-04, 9.3624e-01, 3.8218e-03,
        3.1241e-03, 6.6736e-03, 1.2960e-03, 4.3394e-03, 2.9620e-04, 1.5655e-03,
        6.7277e-03, 5.5139e-04, 1.2579e-02, 1.7144e-03, 2.0474e-03, 2.4643e-03,
        2.6857e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,047][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0055, 0.0475, 0.0555, 0.0463, 0.0557, 0.0566, 0.0547, 0.0659, 0.0592,
        0.0493, 0.0481, 0.0516, 0.0592, 0.0554, 0.0562, 0.0530, 0.0545, 0.0689,
        0.0570], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,049][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1008, 0.0335, 0.0523, 0.0331, 0.0851, 0.0479, 0.0348, 0.0780, 0.0497,
        0.0536, 0.0316, 0.0192, 0.0541, 0.0369, 0.0618, 0.0480, 0.0282, 0.0966,
        0.0549], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,050][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0293, 0.0176, 0.0177, 0.0078, 0.0514, 0.0270, 0.0175, 0.0256, 0.0350,
        0.0491, 0.0069, 0.0181, 0.0633, 0.0339, 0.0842, 0.1435, 0.0578, 0.2726,
        0.0416], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,052][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0040, 0.0288, 0.0867, 0.0313, 0.1134, 0.0456, 0.0351, 0.0474, 0.0149,
        0.1077, 0.0115, 0.0278, 0.1242, 0.0128, 0.0970, 0.0671, 0.0365, 0.0937,
        0.0146], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,053][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0339, 0.0496, 0.0625, 0.0493, 0.0871, 0.0407, 0.0376, 0.0314, 0.0313,
        0.0572, 0.0535, 0.0368, 0.1193, 0.0202, 0.0576, 0.0516, 0.0451, 0.0783,
        0.0569], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,055][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.5538, 0.0094, 0.0162, 0.0012, 0.0030, 0.0070, 0.0079, 0.0071, 0.0074,
        0.0106, 0.0375, 0.0194, 0.0120, 0.0093, 0.0570, 0.2261, 0.0071, 0.0055,
        0.0025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,057][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0029, 0.0429, 0.0704, 0.0462, 0.0818, 0.0538, 0.0447, 0.0672, 0.0379,
        0.0728, 0.0416, 0.0390, 0.0755, 0.0377, 0.0711, 0.0560, 0.0453, 0.0750,
        0.0382], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,058][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0432, 0.0767, 0.0392, 0.0500, 0.0162, 0.0504, 0.0401, 0.1361, 0.0967,
        0.0639, 0.0705, 0.0236, 0.0312, 0.0786, 0.0287, 0.0430, 0.0275, 0.0306,
        0.0538], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,059][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2641, 0.0210, 0.0830, 0.0182, 0.0353, 0.0205, 0.0112, 0.0304, 0.0159,
        0.0143, 0.0319, 0.0156, 0.2547, 0.0193, 0.1021, 0.0136, 0.0143, 0.0203,
        0.0141], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,059][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0411, 0.0383, 0.0094, 0.0978, 0.0081, 0.0500, 0.0284, 0.0155, 0.0301,
        0.0091, 0.0401, 0.0391, 0.0141, 0.0369, 0.0105, 0.0924, 0.0341, 0.0626,
        0.3424], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,100][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:56,101][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,103][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,104][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,105][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,106][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,108][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,109][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,110][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,111][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,112][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,112][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,112][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,113][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8148, 0.1852], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,113][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0054, 0.9946], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,113][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7676, 0.2324], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,114][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7556, 0.2444], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,114][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6311, 0.3689], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,114][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5740, 0.4260], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,115][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7560, 0.2440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,115][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5685, 0.4315], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,116][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7598, 0.2402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,117][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3166, 0.6834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,119][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9554, 0.0446], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,121][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4010, 0.5990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,122][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.8363, 0.0865, 0.0771], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,123][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0017, 0.4435, 0.5548], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,125][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.5631, 0.2142, 0.2227], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,126][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.6243, 0.1628, 0.2129], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,128][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2145, 0.4255, 0.3600], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,129][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.8748, 0.0799, 0.0454], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,129][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.4755, 0.4084, 0.1160], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,130][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.3273, 0.2251, 0.4476], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,130][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.7210, 0.1371, 0.1419], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,130][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.2237, 0.4634, 0.3130], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,131][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.9538, 0.0329, 0.0133], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,131][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.3449, 0.3639, 0.2912], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,131][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8120, 0.0593, 0.0914, 0.0374], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,132][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0010, 0.2728, 0.4766, 0.2496], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,132][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4419, 0.1870, 0.2100, 0.1611], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,132][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3110, 0.2001, 0.3968, 0.0921], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,133][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2028, 0.2855, 0.3607, 0.1510], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,134][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5782, 0.1946, 0.1469, 0.0803], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,136][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3605, 0.3716, 0.1947, 0.0732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,137][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4093, 0.2935, 0.2084, 0.0888], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,139][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.4574, 0.2012, 0.2712, 0.0702], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,140][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1478, 0.2715, 0.3008, 0.2798], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,142][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9263, 0.0350, 0.0154, 0.0233], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,143][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1219, 0.0971, 0.0383, 0.7427], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,145][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.8064, 0.0641, 0.0513, 0.0389, 0.0392], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,146][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0012, 0.2190, 0.2815, 0.2019, 0.2964], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,147][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.3862, 0.1320, 0.1360, 0.1087, 0.2370], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,147][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.4972, 0.0751, 0.1311, 0.0468, 0.2498], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,147][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.2396, 0.1762, 0.1566, 0.1096, 0.3180], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,148][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.8846, 0.0447, 0.0284, 0.0271, 0.0151], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,148][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.6320, 0.1585, 0.0583, 0.0360, 0.1152], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,149][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.2907, 0.0895, 0.1871, 0.0600, 0.3728], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,149][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.6736, 0.0822, 0.0846, 0.0444, 0.1153], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,149][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.0819, 0.2411, 0.2421, 0.2355, 0.1994], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,150][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.9459, 0.0198, 0.0101, 0.0153, 0.0090], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,150][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.2286, 0.2729, 0.1571, 0.1125, 0.2289], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,151][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6337, 0.1131, 0.1181, 0.0452, 0.0605, 0.0294], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,152][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0009, 0.1578, 0.2252, 0.1484, 0.2849, 0.1828], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,154][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3686, 0.1091, 0.1055, 0.0825, 0.2195, 0.1149], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,156][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1755, 0.0640, 0.1276, 0.0449, 0.4320, 0.1560], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,157][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0854, 0.1151, 0.1725, 0.0675, 0.4178, 0.1417], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,159][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2512, 0.1902, 0.1480, 0.2021, 0.1349, 0.0735], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,160][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1415, 0.1822, 0.1634, 0.0468, 0.3278, 0.1384], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,162][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1882, 0.2030, 0.0910, 0.0502, 0.3751, 0.0926], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,163][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3592, 0.1030, 0.1380, 0.0515, 0.2282, 0.1201], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,164][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0829, 0.1653, 0.1574, 0.1583, 0.2271, 0.2090], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,164][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8594, 0.0475, 0.0237, 0.0284, 0.0162, 0.0249], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,165][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0547, 0.0513, 0.0061, 0.0941, 0.0096, 0.7842], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,165][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6917, 0.0894, 0.0693, 0.0409, 0.0530, 0.0318, 0.0240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,166][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0004, 0.1318, 0.1923, 0.1173, 0.2372, 0.1638, 0.1572],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,166][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3599, 0.0949, 0.0841, 0.0736, 0.1911, 0.0944, 0.1019],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,166][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0918, 0.0484, 0.1507, 0.0444, 0.4009, 0.2138, 0.0500],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,167][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0260, 0.0802, 0.1658, 0.0625, 0.4159, 0.1768, 0.0729],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,167][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3554, 0.1860, 0.1250, 0.1122, 0.1001, 0.0688, 0.0525],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,167][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0828, 0.1689, 0.1276, 0.0572, 0.3054, 0.2156, 0.0425],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,168][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1110, 0.1863, 0.0935, 0.0450, 0.2887, 0.1696, 0.1058],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,169][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2325, 0.1203, 0.1341, 0.0559, 0.2198, 0.1639, 0.0735],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,171][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0635, 0.1382, 0.1327, 0.1355, 0.1767, 0.1737, 0.1797],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,172][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8232, 0.0471, 0.0239, 0.0279, 0.0193, 0.0267, 0.0319],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,174][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1063, 0.0658, 0.0920, 0.1430, 0.0695, 0.1613, 0.3621],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,175][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.6842, 0.0868, 0.0371, 0.0362, 0.0510, 0.0439, 0.0303, 0.0305],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,177][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0004, 0.1249, 0.1735, 0.1116, 0.2034, 0.1345, 0.1493, 0.1025],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,178][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.4525, 0.0753, 0.0598, 0.0479, 0.1099, 0.0679, 0.0751, 0.1116],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,180][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0583, 0.0118, 0.0413, 0.0142, 0.1535, 0.0598, 0.0135, 0.6477],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,182][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0589, 0.0482, 0.0656, 0.0380, 0.2380, 0.1091, 0.0499, 0.3923],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,182][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2516, 0.1390, 0.1279, 0.1277, 0.0963, 0.0697, 0.1015, 0.0862],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,182][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0782, 0.1008, 0.0332, 0.0203, 0.1403, 0.0780, 0.0265, 0.5227],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,183][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1766, 0.1107, 0.1279, 0.0356, 0.2516, 0.1064, 0.0578, 0.1333],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,183][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1975, 0.0685, 0.0748, 0.0530, 0.1505, 0.1245, 0.0908, 0.2404],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,183][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0459, 0.1105, 0.1054, 0.1059, 0.1479, 0.1635, 0.1555, 0.1654],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,184][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.6533, 0.0678, 0.0449, 0.0466, 0.0395, 0.0364, 0.0535, 0.0579],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,184][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0401, 0.1184, 0.0374, 0.1409, 0.0188, 0.2038, 0.1103, 0.3302],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,185][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.7349, 0.0580, 0.0480, 0.0289, 0.0381, 0.0197, 0.0199, 0.0164, 0.0361],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,185][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0003, 0.0933, 0.1561, 0.0879, 0.1988, 0.1321, 0.1396, 0.1060, 0.0858],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,186][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3920, 0.0725, 0.0621, 0.0554, 0.1128, 0.0638, 0.0706, 0.1002, 0.0707],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,188][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0967, 0.0216, 0.0607, 0.0197, 0.1555, 0.0712, 0.0207, 0.4409, 0.1129],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,189][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1289, 0.0730, 0.0762, 0.0519, 0.1662, 0.1308, 0.0805, 0.0849, 0.2077],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,191][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.5107, 0.0962, 0.0886, 0.0542, 0.0422, 0.0487, 0.0399, 0.0665, 0.0529],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,192][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1015, 0.0784, 0.0273, 0.0222, 0.0572, 0.0629, 0.0219, 0.5061, 0.1226],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,194][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1795, 0.1219, 0.0738, 0.0307, 0.2468, 0.0791, 0.0631, 0.0814, 0.1238],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,196][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.3751, 0.0512, 0.0641, 0.0284, 0.1090, 0.0783, 0.0574, 0.1097, 0.1269],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,197][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0373, 0.0923, 0.1009, 0.0958, 0.1452, 0.1345, 0.1343, 0.1614, 0.0982],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,199][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.7329, 0.0445, 0.0218, 0.0275, 0.0177, 0.0244, 0.0302, 0.0492, 0.0517],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,199][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0790, 0.0548, 0.0227, 0.2332, 0.0212, 0.1276, 0.0350, 0.0597, 0.3668],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,200][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.6457, 0.0789, 0.0520, 0.0352, 0.0458, 0.0179, 0.0203, 0.0115, 0.0597,
        0.0331], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,200][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0003, 0.0874, 0.1388, 0.0816, 0.1608, 0.1101, 0.1220, 0.0891, 0.0822,
        0.1278], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,200][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.4491, 0.0599, 0.0465, 0.0403, 0.0860, 0.0495, 0.0523, 0.0901, 0.0632,
        0.0631], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,201][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0969, 0.0103, 0.0333, 0.0094, 0.0942, 0.0508, 0.0168, 0.3043, 0.1454,
        0.2385], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,201][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1331, 0.0382, 0.0580, 0.0203, 0.1875, 0.0727, 0.0569, 0.0868, 0.1774,
        0.1692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,202][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.3724, 0.1120, 0.1027, 0.0667, 0.0397, 0.0499, 0.0401, 0.0430, 0.0768,
        0.0968], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,202][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0491, 0.0497, 0.0127, 0.0138, 0.0414, 0.0506, 0.0192, 0.3327, 0.2215,
        0.2094], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,202][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.1801, 0.1005, 0.0652, 0.0248, 0.1483, 0.0582, 0.0429, 0.0421, 0.1220,
        0.2159], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,203][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2929, 0.0440, 0.0619, 0.0217, 0.0695, 0.0565, 0.0416, 0.0855, 0.1744,
        0.1519], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,204][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0406, 0.0996, 0.0927, 0.0914, 0.1026, 0.1298, 0.1168, 0.1560, 0.0935,
        0.0770], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,206][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.7421, 0.0342, 0.0184, 0.0221, 0.0199, 0.0220, 0.0232, 0.0282, 0.0414,
        0.0487], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,207][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1291, 0.0929, 0.0609, 0.1086, 0.0795, 0.0465, 0.0169, 0.0706, 0.1126,
        0.2825], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,209][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.7865, 0.0332, 0.0342, 0.0173, 0.0254, 0.0147, 0.0122, 0.0094, 0.0244,
        0.0249, 0.0179], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,210][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0002, 0.0755, 0.1244, 0.0680, 0.1618, 0.0995, 0.1145, 0.0762, 0.0712,
        0.1284, 0.0803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,212][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2491, 0.0641, 0.0552, 0.0525, 0.1175, 0.0555, 0.0656, 0.1152, 0.0785,
        0.0817, 0.0652], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,214][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0514, 0.0204, 0.0604, 0.0138, 0.1438, 0.0696, 0.0239, 0.3237, 0.0786,
        0.1773, 0.0371], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,215][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0315, 0.0648, 0.0958, 0.0335, 0.2562, 0.1075, 0.0677, 0.0508, 0.1194,
        0.1415, 0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,216][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4910, 0.0778, 0.0670, 0.0406, 0.0329, 0.0277, 0.0186, 0.0605, 0.0440,
        0.1125, 0.0275], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,217][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0559, 0.0928, 0.0273, 0.0181, 0.0794, 0.0674, 0.0198, 0.2048, 0.1377,
        0.2824, 0.0144], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,217][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1359, 0.0929, 0.0926, 0.0273, 0.1960, 0.0683, 0.0755, 0.0369, 0.0740,
        0.1571, 0.0437], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,218][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2182, 0.0515, 0.0685, 0.0303, 0.0955, 0.0654, 0.0423, 0.1131, 0.1185,
        0.1685, 0.0282], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,218][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0374, 0.0780, 0.0842, 0.0787, 0.1146, 0.1071, 0.1149, 0.1300, 0.0830,
        0.0982, 0.0738], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,219][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.8511, 0.0170, 0.0089, 0.0102, 0.0073, 0.0108, 0.0124, 0.0190, 0.0251,
        0.0248, 0.0134], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,219][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0523, 0.0447, 0.0445, 0.1268, 0.0244, 0.1097, 0.0688, 0.0220, 0.0977,
        0.0418, 0.3672], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,219][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.7311, 0.0401, 0.0263, 0.0162, 0.0199, 0.0140, 0.0099, 0.0102, 0.0337,
        0.0262, 0.0390, 0.0334], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,220][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0003, 0.0762, 0.1144, 0.0669, 0.1348, 0.0975, 0.0936, 0.0733, 0.0681,
        0.1119, 0.0895, 0.0735], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,220][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.2410, 0.0541, 0.0459, 0.0445, 0.1052, 0.0490, 0.0595, 0.1149, 0.0769,
        0.0793, 0.0644, 0.0656], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,222][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0999, 0.0272, 0.0745, 0.0137, 0.1624, 0.0798, 0.0253, 0.2381, 0.0682,
        0.1358, 0.0389, 0.0361], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,224][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0399, 0.1060, 0.1137, 0.0329, 0.2284, 0.1046, 0.0719, 0.0348, 0.0888,
        0.0928, 0.0333, 0.0530], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,225][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.4022, 0.0715, 0.0484, 0.0379, 0.0301, 0.0262, 0.0209, 0.0456, 0.0578,
        0.1484, 0.0639, 0.0470], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,227][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0512, 0.1073, 0.0464, 0.0202, 0.1023, 0.0658, 0.0193, 0.1970, 0.1190,
        0.2155, 0.0250, 0.0310], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,227][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1026, 0.1588, 0.0756, 0.0230, 0.1659, 0.0693, 0.0568, 0.0420, 0.0730,
        0.1108, 0.0517, 0.0704], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,229][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1887, 0.0613, 0.0748, 0.0246, 0.1067, 0.0691, 0.0462, 0.0630, 0.1090,
        0.1514, 0.0595, 0.0457], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,231][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0335, 0.0755, 0.0704, 0.0773, 0.1060, 0.1001, 0.1066, 0.1170, 0.0766,
        0.0830, 0.0712, 0.0828], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,233][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8801, 0.0117, 0.0059, 0.0080, 0.0049, 0.0082, 0.0083, 0.0145, 0.0177,
        0.0154, 0.0099, 0.0155], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,234][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0628, 0.0562, 0.0406, 0.0802, 0.0270, 0.0881, 0.0873, 0.0410, 0.0536,
        0.0280, 0.0442, 0.3911], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,235][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.5010, 0.0590, 0.0491, 0.0269, 0.0285, 0.0152, 0.0264, 0.0094, 0.0721,
        0.0364, 0.0681, 0.0667, 0.0411], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,235][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0002, 0.0645, 0.0969, 0.0611, 0.1089, 0.0825, 0.0954, 0.0701, 0.0620,
        0.1085, 0.0819, 0.0744, 0.0936], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,235][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.3219, 0.0502, 0.0342, 0.0352, 0.0700, 0.0402, 0.0483, 0.0914, 0.0617,
        0.0674, 0.0491, 0.0500, 0.0803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,236][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1485, 0.0135, 0.0430, 0.0089, 0.1291, 0.0482, 0.0194, 0.2095, 0.0672,
        0.1571, 0.0221, 0.0280, 0.1054], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,236][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0917, 0.0517, 0.0682, 0.0206, 0.1480, 0.0664, 0.0560, 0.0543, 0.1145,
        0.1014, 0.0310, 0.0622, 0.1340], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,237][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.4144, 0.0429, 0.0438, 0.0391, 0.0307, 0.0246, 0.0277, 0.0399, 0.0642,
        0.0949, 0.0593, 0.0834, 0.0351], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,237][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0570, 0.0455, 0.0241, 0.0113, 0.0613, 0.0418, 0.0151, 0.1393, 0.0995,
        0.2530, 0.0174, 0.0374, 0.1973], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,238][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1654, 0.0657, 0.0435, 0.0202, 0.0920, 0.0550, 0.0513, 0.0346, 0.0867,
        0.1303, 0.0414, 0.0612, 0.1527], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,238][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2189, 0.0439, 0.0512, 0.0203, 0.0655, 0.0545, 0.0459, 0.0595, 0.1438,
        0.1439, 0.0396, 0.0636, 0.0493], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,240][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0419, 0.0728, 0.0629, 0.0659, 0.0931, 0.0916, 0.0936, 0.1110, 0.0653,
        0.0837, 0.0624, 0.0714, 0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,242][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.8935, 0.0076, 0.0038, 0.0063, 0.0032, 0.0056, 0.0074, 0.0142, 0.0143,
        0.0141, 0.0081, 0.0126, 0.0092], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,243][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0620, 0.0637, 0.0365, 0.0974, 0.0132, 0.3789, 0.0235, 0.0053, 0.0805,
        0.0325, 0.0719, 0.0668, 0.0679], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,245][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.5261, 0.0465, 0.0350, 0.0281, 0.0315, 0.0151, 0.0183, 0.0174, 0.0509,
        0.0319, 0.0623, 0.0658, 0.0327, 0.0385], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,247][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0001, 0.0571, 0.0992, 0.0521, 0.1270, 0.0818, 0.0853, 0.0621, 0.0555,
        0.1023, 0.0710, 0.0677, 0.0967, 0.0420], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,248][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.2072, 0.0507, 0.0411, 0.0381, 0.0875, 0.0486, 0.0521, 0.0923, 0.0662,
        0.0699, 0.0544, 0.0543, 0.0857, 0.0518], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,250][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0521, 0.0040, 0.0157, 0.0043, 0.0457, 0.0173, 0.0046, 0.2591, 0.0558,
        0.2044, 0.0298, 0.0313, 0.1471, 0.1289], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,251][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0316, 0.0152, 0.0167, 0.0106, 0.0457, 0.0293, 0.0175, 0.0490, 0.1204,
        0.1872, 0.0433, 0.1145, 0.2275, 0.0913], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,252][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1186, 0.0616, 0.0546, 0.0741, 0.0447, 0.0398, 0.0287, 0.0548, 0.0759,
        0.1139, 0.0758, 0.0770, 0.0819, 0.0986], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,252][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0471, 0.0217, 0.0096, 0.0072, 0.0298, 0.0238, 0.0077, 0.1186, 0.0707,
        0.2029, 0.0164, 0.0462, 0.2970, 0.1014], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,253][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1109, 0.0517, 0.0237, 0.0113, 0.0510, 0.0341, 0.0228, 0.0438, 0.0901,
        0.1459, 0.0574, 0.0840, 0.1647, 0.1085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,253][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1156, 0.0238, 0.0241, 0.0193, 0.0475, 0.0404, 0.0276, 0.0697, 0.1123,
        0.1784, 0.0606, 0.0743, 0.1076, 0.0987], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,253][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0277, 0.0600, 0.0662, 0.0614, 0.0937, 0.0878, 0.0857, 0.0974, 0.0635,
        0.0725, 0.0577, 0.0695, 0.0966, 0.0604], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,254][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7535, 0.0203, 0.0095, 0.0126, 0.0079, 0.0122, 0.0138, 0.0194, 0.0252,
        0.0223, 0.0130, 0.0217, 0.0143, 0.0544], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,254][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0754, 0.0927, 0.0339, 0.2506, 0.0270, 0.0998, 0.0227, 0.0263, 0.1263,
        0.0395, 0.0439, 0.0376, 0.0313, 0.0930], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,255][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.7309, 0.0166, 0.0173, 0.0129, 0.0160, 0.0119, 0.0084, 0.0076, 0.0261,
        0.0156, 0.0205, 0.0258, 0.0198, 0.0234, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,256][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0002, 0.0614, 0.0730, 0.0514, 0.0953, 0.0752, 0.0770, 0.0584, 0.0541,
        0.0978, 0.0717, 0.0647, 0.0869, 0.0468, 0.0861], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,257][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.2667, 0.0432, 0.0325, 0.0318, 0.0702, 0.0393, 0.0421, 0.0859, 0.0641,
        0.0646, 0.0457, 0.0489, 0.0820, 0.0443, 0.0389], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,259][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.1724, 0.0098, 0.0153, 0.0048, 0.0471, 0.0245, 0.0105, 0.2242, 0.0447,
        0.1264, 0.0170, 0.0127, 0.0705, 0.0980, 0.1221], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,261][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0919, 0.0340, 0.0230, 0.0158, 0.0630, 0.0533, 0.0380, 0.0539, 0.0909,
        0.1381, 0.0198, 0.0362, 0.1877, 0.0625, 0.0919], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,262][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.7657, 0.0152, 0.0082, 0.0215, 0.0080, 0.0210, 0.0069, 0.0096, 0.0127,
        0.0265, 0.0102, 0.0146, 0.0364, 0.0315, 0.0122], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,264][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.1944, 0.0507, 0.0119, 0.0064, 0.0457, 0.0222, 0.0086, 0.1119, 0.0567,
        0.1462, 0.0085, 0.0235, 0.1768, 0.0792, 0.0573], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,266][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.2443, 0.0452, 0.0419, 0.0190, 0.0951, 0.0374, 0.0328, 0.0234, 0.0485,
        0.0642, 0.0250, 0.0286, 0.1170, 0.0660, 0.1117], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,267][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.3515, 0.0211, 0.0163, 0.0123, 0.0314, 0.0723, 0.0262, 0.0496, 0.0749,
        0.0842, 0.0224, 0.0285, 0.0717, 0.0706, 0.0670], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,268][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0308, 0.0589, 0.0373, 0.0565, 0.0891, 0.0858, 0.0842, 0.1004, 0.0645,
        0.0744, 0.0584, 0.0684, 0.0910, 0.0650, 0.0353], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,269][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.8291, 0.0110, 0.0052, 0.0075, 0.0048, 0.0072, 0.0069, 0.0126, 0.0161,
        0.0106, 0.0086, 0.0134, 0.0102, 0.0374, 0.0195], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,269][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0790, 0.0573, 0.0533, 0.0509, 0.0444, 0.2731, 0.0324, 0.0191, 0.0711,
        0.0400, 0.0543, 0.0870, 0.0190, 0.0540, 0.0651], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,270][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.5933, 0.0226, 0.0252, 0.0163, 0.0176, 0.0080, 0.0136, 0.0083, 0.0296,
        0.0227, 0.0310, 0.0399, 0.0336, 0.0355, 0.0519, 0.0509],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,270][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0003, 0.0553, 0.0770, 0.0510, 0.1004, 0.0612, 0.0694, 0.0529, 0.0473,
        0.0814, 0.0647, 0.0599, 0.0772, 0.0436, 0.0862, 0.0723],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,271][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2285, 0.0401, 0.0326, 0.0294, 0.0665, 0.0344, 0.0456, 0.0757, 0.0545,
        0.0609, 0.0498, 0.0519, 0.0906, 0.0413, 0.0423, 0.0557],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,271][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1836, 0.0114, 0.0212, 0.0045, 0.0541, 0.0245, 0.0086, 0.1182, 0.0245,
        0.0742, 0.0118, 0.0228, 0.0765, 0.0547, 0.2011, 0.1084],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,272][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1065, 0.0337, 0.0489, 0.0137, 0.1004, 0.0299, 0.0271, 0.0166, 0.0379,
        0.0387, 0.0133, 0.0361, 0.1137, 0.0282, 0.1969, 0.1583],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,272][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.3594, 0.0305, 0.0268, 0.0203, 0.0264, 0.0143, 0.0151, 0.0192, 0.0353,
        0.0840, 0.0597, 0.0488, 0.0664, 0.0717, 0.0847, 0.0375],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,274][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0683, 0.0429, 0.0274, 0.0085, 0.0588, 0.0361, 0.0104, 0.0863, 0.0351,
        0.1038, 0.0079, 0.0257, 0.1984, 0.0444, 0.0867, 0.1591],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,276][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.2040, 0.0512, 0.0224, 0.0099, 0.0989, 0.0219, 0.0213, 0.0258, 0.0389,
        0.0959, 0.0239, 0.0325, 0.0836, 0.0334, 0.0880, 0.1483],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,277][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.2889, 0.0223, 0.0244, 0.0069, 0.0430, 0.0141, 0.0173, 0.0276, 0.0538,
        0.0775, 0.0339, 0.0378, 0.0852, 0.0486, 0.1630, 0.0558],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,279][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0335, 0.0579, 0.0519, 0.0501, 0.0821, 0.0720, 0.0750, 0.0827, 0.0591,
        0.0645, 0.0565, 0.0638, 0.0843, 0.0565, 0.0481, 0.0619],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,281][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.8327, 0.0090, 0.0044, 0.0052, 0.0032, 0.0049, 0.0056, 0.0093, 0.0130,
        0.0119, 0.0081, 0.0148, 0.0098, 0.0303, 0.0218, 0.0161],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,282][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0286, 0.0485, 0.0080, 0.1149, 0.0037, 0.2289, 0.0529, 0.0062, 0.0329,
        0.0204, 0.0270, 0.0661, 0.0167, 0.0380, 0.0096, 0.2975],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,284][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6592, 0.0222, 0.0179, 0.0124, 0.0144, 0.0083, 0.0057, 0.0067, 0.0207,
        0.0164, 0.0258, 0.0268, 0.0215, 0.0240, 0.0345, 0.0501, 0.0334],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,286][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0002, 0.0521, 0.0737, 0.0463, 0.0916, 0.0622, 0.0600, 0.0480, 0.0451,
        0.0765, 0.0591, 0.0528, 0.0712, 0.0385, 0.0826, 0.0743, 0.0659],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,286][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1720, 0.0407, 0.0334, 0.0316, 0.0712, 0.0362, 0.0413, 0.0798, 0.0591,
        0.0623, 0.0474, 0.0445, 0.0811, 0.0489, 0.0438, 0.0561, 0.0505],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,287][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0654, 0.0080, 0.0204, 0.0038, 0.0477, 0.0218, 0.0054, 0.1453, 0.0268,
        0.0762, 0.0125, 0.0125, 0.0804, 0.0685, 0.1878, 0.1888, 0.0289],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,287][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0338, 0.0364, 0.0408, 0.0136, 0.0944, 0.0380, 0.0156, 0.0249, 0.0427,
        0.0607, 0.0122, 0.0277, 0.1103, 0.0289, 0.1385, 0.2264, 0.0552],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,287][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3302, 0.0333, 0.0227, 0.0234, 0.0172, 0.0156, 0.0096, 0.0417, 0.0294,
        0.0934, 0.0370, 0.0366, 0.0491, 0.0772, 0.0586, 0.0847, 0.0403],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,288][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0264, 0.0279, 0.0138, 0.0063, 0.0355, 0.0235, 0.0046, 0.0965, 0.0448,
        0.1006, 0.0063, 0.0136, 0.2351, 0.0596, 0.0680, 0.2160, 0.0217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,288][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1012, 0.0636, 0.0225, 0.0082, 0.0585, 0.0343, 0.0184, 0.0196, 0.0351,
        0.0518, 0.0218, 0.0275, 0.0983, 0.0422, 0.0721, 0.2665, 0.0583],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,289][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1674, 0.0233, 0.0230, 0.0080, 0.0369, 0.0250, 0.0095, 0.0549, 0.0532,
        0.0859, 0.0255, 0.0319, 0.0650, 0.0642, 0.1396, 0.1380, 0.0487],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,289][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0243, 0.0519, 0.0498, 0.0513, 0.0675, 0.0666, 0.0697, 0.0768, 0.0539,
        0.0539, 0.0518, 0.0602, 0.0745, 0.0562, 0.0487, 0.0721, 0.0708],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,291][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8132, 0.0094, 0.0050, 0.0066, 0.0042, 0.0064, 0.0066, 0.0102, 0.0139,
        0.0126, 0.0082, 0.0134, 0.0096, 0.0292, 0.0172, 0.0145, 0.0199],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,293][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0504, 0.0218, 0.0380, 0.0476, 0.0273, 0.0605, 0.1313, 0.0162, 0.0262,
        0.0418, 0.0502, 0.0961, 0.0472, 0.0283, 0.0577, 0.0674, 0.1920],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,295][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.6153, 0.0228, 0.0185, 0.0113, 0.0190, 0.0105, 0.0123, 0.0084, 0.0206,
        0.0148, 0.0227, 0.0265, 0.0145, 0.0268, 0.0441, 0.0435, 0.0558, 0.0125],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,296][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0001, 0.0449, 0.0638, 0.0417, 0.0757, 0.0555, 0.0635, 0.0520, 0.0432,
        0.0724, 0.0554, 0.0522, 0.0657, 0.0366, 0.0740, 0.0695, 0.0700, 0.0634],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,298][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.2572, 0.0383, 0.0263, 0.0266, 0.0492, 0.0275, 0.0328, 0.0668, 0.0479,
        0.0486, 0.0374, 0.0343, 0.0600, 0.0401, 0.0327, 0.0427, 0.0424, 0.0892],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,300][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0529, 0.0058, 0.0105, 0.0031, 0.0295, 0.0135, 0.0048, 0.1262, 0.0278,
        0.0664, 0.0071, 0.0087, 0.0437, 0.0644, 0.1224, 0.1219, 0.0256, 0.2658],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,302][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0589, 0.0269, 0.0193, 0.0106, 0.0511, 0.0293, 0.0179, 0.0362, 0.0599,
        0.0639, 0.0089, 0.0199, 0.0588, 0.0510, 0.0817, 0.1494, 0.0560, 0.2002],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,303][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.4509, 0.0420, 0.0238, 0.0121, 0.0126, 0.0085, 0.0086, 0.0237, 0.0166,
        0.0644, 0.0318, 0.0346, 0.0269, 0.0510, 0.0756, 0.0533, 0.0346, 0.0290],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,303][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0553, 0.0225, 0.0049, 0.0047, 0.0167, 0.0238, 0.0080, 0.1033, 0.0455,
        0.1054, 0.0064, 0.0163, 0.1087, 0.0753, 0.0278, 0.1474, 0.0317, 0.1963],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,304][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.1168, 0.0433, 0.0134, 0.0085, 0.0391, 0.0226, 0.0178, 0.0173, 0.0390,
        0.0716, 0.0159, 0.0212, 0.0599, 0.0560, 0.0591, 0.1589, 0.0523, 0.1873],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,304][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.2269, 0.0181, 0.0202, 0.0063, 0.0253, 0.0174, 0.0159, 0.0479, 0.0476,
        0.0526, 0.0230, 0.0275, 0.0377, 0.0660, 0.1391, 0.0676, 0.0713, 0.0895],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,305][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0215, 0.0488, 0.0520, 0.0509, 0.0627, 0.0665, 0.0739, 0.0729, 0.0528,
        0.0507, 0.0466, 0.0619, 0.0717, 0.0526, 0.0480, 0.0630, 0.0695, 0.0340],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,305][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.7811, 0.0089, 0.0043, 0.0080, 0.0038, 0.0064, 0.0075, 0.0095, 0.0146,
        0.0145, 0.0088, 0.0166, 0.0075, 0.0318, 0.0159, 0.0173, 0.0234, 0.0201],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,306][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0779, 0.0477, 0.0325, 0.0339, 0.0479, 0.0722, 0.0437, 0.0085, 0.0818,
        0.0305, 0.0660, 0.0628, 0.0119, 0.0375, 0.0380, 0.1802, 0.0500, 0.0771],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,306][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.8303, 0.0077, 0.0077, 0.0043, 0.0075, 0.0038, 0.0039, 0.0037, 0.0076,
        0.0060, 0.0063, 0.0118, 0.0078, 0.0107, 0.0156, 0.0195, 0.0233, 0.0052,
        0.0173], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,307][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0001, 0.0395, 0.0642, 0.0357, 0.0838, 0.0544, 0.0606, 0.0430, 0.0376,
        0.0687, 0.0468, 0.0489, 0.0623, 0.0300, 0.0751, 0.0670, 0.0664, 0.0671,
        0.0488], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,309][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2189, 0.0407, 0.0310, 0.0289, 0.0548, 0.0302, 0.0331, 0.0650, 0.0434,
        0.0460, 0.0337, 0.0304, 0.0546, 0.0380, 0.0322, 0.0388, 0.0368, 0.0775,
        0.0661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,311][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0462, 0.0051, 0.0121, 0.0026, 0.0266, 0.0140, 0.0045, 0.1552, 0.0200,
        0.0600, 0.0065, 0.0060, 0.0467, 0.0604, 0.1053, 0.0962, 0.0191, 0.2663,
        0.0473], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,312][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0293, 0.0176, 0.0177, 0.0078, 0.0514, 0.0270, 0.0175, 0.0256, 0.0350,
        0.0491, 0.0069, 0.0181, 0.0633, 0.0339, 0.0842, 0.1435, 0.0578, 0.2726,
        0.0416], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,314][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5564, 0.0243, 0.0149, 0.0136, 0.0115, 0.0110, 0.0084, 0.0199, 0.0151,
        0.0383, 0.0189, 0.0293, 0.0261, 0.0430, 0.0335, 0.0338, 0.0343, 0.0349,
        0.0329], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,315][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0479, 0.0162, 0.0080, 0.0031, 0.0250, 0.0185, 0.0046, 0.1040, 0.0230,
        0.0917, 0.0035, 0.0083, 0.1165, 0.0425, 0.0333, 0.1273, 0.0162, 0.2840,
        0.0265], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,317][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0714, 0.0457, 0.0171, 0.0068, 0.0400, 0.0191, 0.0151, 0.0130, 0.0309,
        0.0496, 0.0131, 0.0185, 0.0666, 0.0493, 0.0590, 0.1567, 0.0414, 0.2232,
        0.0634], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,319][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2856, 0.0125, 0.0153, 0.0064, 0.0293, 0.0174, 0.0129, 0.0310, 0.0371,
        0.0561, 0.0152, 0.0236, 0.0377, 0.0540, 0.0830, 0.0791, 0.0617, 0.1034,
        0.0387], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,320][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0214, 0.0445, 0.0439, 0.0452, 0.0664, 0.0616, 0.0649, 0.0695, 0.0479,
        0.0484, 0.0455, 0.0535, 0.0652, 0.0477, 0.0432, 0.0639, 0.0635, 0.0568,
        0.0470], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,320][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8274, 0.0074, 0.0037, 0.0055, 0.0032, 0.0047, 0.0047, 0.0070, 0.0108,
        0.0102, 0.0066, 0.0115, 0.0066, 0.0214, 0.0122, 0.0117, 0.0148, 0.0090,
        0.0218], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,321][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0380, 0.0377, 0.0092, 0.0963, 0.0080, 0.0502, 0.0272, 0.0155, 0.0290,
        0.0093, 0.0398, 0.0386, 0.0138, 0.0353, 0.0104, 0.0945, 0.0329, 0.0663,
        0.3480], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,322][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:56,323][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[19701],
        [ 6174],
        [ 8209],
        [ 9745],
        [ 8634],
        [ 3040],
        [ 3948],
        [ 9573],
        [  568],
        [ 7041],
        [  311],
        [ 1826],
        [ 1313],
        [  696],
        [ 5355],
        [ 8013],
        [ 2604],
        [ 8418],
        [  639]], device='cuda:0')
[2024-07-24 10:18:56,325][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[19954],
        [ 7257],
        [12166],
        [22995],
        [17298],
        [13325],
        [21351],
        [11531],
        [10192],
        [16988],
        [ 7081],
        [ 8952],
        [ 2569],
        [12986],
        [12453],
        [19895],
        [19157],
        [19694],
        [14311]], device='cuda:0')
[2024-07-24 10:18:56,326][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6523],
        [ 5334],
        [14254],
        [12020],
        [20478],
        [17813],
        [16663],
        [16996],
        [15926],
        [15926],
        [15443],
        [14947],
        [15022],
        [14859],
        [16167],
        [15492],
        [15304],
        [15186],
        [14384]], device='cuda:0')
[2024-07-24 10:18:56,328][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[43411],
        [37365],
        [35342],
        [ 5503],
        [34768],
        [   72],
        [   29],
        [18902],
        [    1],
        [23434],
        [    1],
        [  611],
        [30469],
        [    1],
        [34265],
        [16675],
        [  287],
        [27661],
        [    1]], device='cuda:0')
[2024-07-24 10:18:56,330][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[36258],
        [39481],
        [38563],
        [37541],
        [38982],
        [38605],
        [38371],
        [39000],
        [38692],
        [38308],
        [38373],
        [38271],
        [38094],
        [37934],
        [37725],
        [37936],
        [37962],
        [38513],
        [38362]], device='cuda:0')
[2024-07-24 10:18:56,331][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5516],
        [10751],
        [20200],
        [19890],
        [22569],
        [22508],
        [20819],
        [16301],
        [15700],
        [13176],
        [13942],
        [14134],
        [12602],
        [11390],
        [12148],
        [12659],
        [12255],
        [12018],
        [11866]], device='cuda:0')
[2024-07-24 10:18:56,333][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24372],
        [29010],
        [39527],
        [39910],
        [44057],
        [44226],
        [43565],
        [41401],
        [34873],
        [33428],
        [37283],
        [36937],
        [31711],
        [22034],
        [26940],
        [31555],
        [28365],
        [22523],
        [21423]], device='cuda:0')
[2024-07-24 10:18:56,335][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48105],
        [13532],
        [ 9175],
        [ 8367],
        [ 7626],
        [ 7844],
        [ 7225],
        [ 7711],
        [ 7919],
        [ 7597],
        [ 8052],
        [ 7826],
        [ 7461],
        [ 7583],
        [ 7212],
        [ 7333],
        [ 7211],
        [ 7225],
        [ 7067]], device='cuda:0')
[2024-07-24 10:18:56,337][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31441],
        [35789],
        [30664],
        [30882],
        [29604],
        [25929],
        [25367],
        [29650],
        [23727],
        [24641],
        [21768],
        [21383],
        [20591],
        [15716],
        [20806],
        [18476],
        [16856],
        [18321],
        [16536]], device='cuda:0')
[2024-07-24 10:18:56,338][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 4465],
        [ 4570],
        [15449],
        [ 5311],
        [ 5313],
        [ 6935],
        [ 4609],
        [ 4551],
        [ 4429],
        [ 4754],
        [ 5439],
        [ 4680],
        [12934],
        [21918],
        [22918],
        [27798],
        [20003],
        [26352],
        [26156]], device='cuda:0')
[2024-07-24 10:18:56,340][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20717],
        [19886],
        [19286],
        [17999],
        [20092],
        [20033],
        [19607],
        [19203],
        [19193],
        [18925],
        [19018],
        [18701],
        [18859],
        [19168],
        [18809],
        [18544],
        [18326],
        [18144],
        [18031]], device='cuda:0')
[2024-07-24 10:18:56,341][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22220],
        [16993],
        [13626],
        [12596],
        [10592],
        [10682],
        [ 9862],
        [ 9588],
        [ 8487],
        [ 8039],
        [ 8040],
        [ 7583],
        [ 7640],
        [ 7351],
        [ 7125],
        [ 7177],
        [ 6846],
        [ 6959],
        [ 6830]], device='cuda:0')
[2024-07-24 10:18:56,342][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 4227],
        [ 1527],
        [ 1290],
        [  839],
        [25772],
        [ 2028],
        [ 9154],
        [13818],
        [ 1944],
        [11157],
        [ 2545],
        [ 3360],
        [  876],
        [  700],
        [  720],
        [  751],
        [  939],
        [ 6013],
        [  529]], device='cuda:0')
[2024-07-24 10:18:56,343][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24498],
        [30700],
        [18512],
        [41757],
        [  172],
        [37420],
        [17792],
        [41336],
        [36904],
        [ 7991],
        [30404],
        [30803],
        [34450],
        [31334],
        [22875],
        [39122],
        [24512],
        [25847],
        [29121]], device='cuda:0')
[2024-07-24 10:18:56,345][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[25369],
        [15975],
        [16035],
        [15979],
        [16996],
        [19786],
        [18994],
        [25461],
        [19511],
        [20688],
        [21859],
        [20660],
        [21456],
        [20617],
        [20738],
        [21035],
        [18904],
        [20930],
        [21117]], device='cuda:0')
[2024-07-24 10:18:56,346][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[36941],
        [27631],
        [28045],
        [26184],
        [25540],
        [18829],
        [19469],
        [18392],
        [20987],
        [16834],
        [23427],
        [19287],
        [12208],
        [12634],
        [21052],
        [14684],
        [15325],
        [14019],
        [25680]], device='cuda:0')
[2024-07-24 10:18:56,348][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12806],
        [34998],
        [37637],
        [36271],
        [37053],
        [35008],
        [34515],
        [34265],
        [33843],
        [33500],
        [33339],
        [33140],
        [33188],
        [33458],
        [33856],
        [33762],
        [33693],
        [33636],
        [33660]], device='cuda:0')
[2024-07-24 10:18:56,350][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15823],
        [18623],
        [20243],
        [20407],
        [21393],
        [22091],
        [22142],
        [24042],
        [24677],
        [25109],
        [26069],
        [26488],
        [27075],
        [27228],
        [27278],
        [27356],
        [27253],
        [27299],
        [27181]], device='cuda:0')
[2024-07-24 10:18:56,352][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3891],
        [ 8176],
        [ 8765],
        [14095],
        [22232],
        [33556],
        [34655],
        [42786],
        [43294],
        [43575],
        [43123],
        [41696],
        [41168],
        [40656],
        [39623],
        [34709],
        [35506],
        [32841],
        [33609]], device='cuda:0')
[2024-07-24 10:18:56,353][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3054],
        [ 2483],
        [ 8807],
        [ 8148],
        [ 4363],
        [ 4579],
        [ 5010],
        [ 1894],
        [ 3496],
        [ 4342],
        [ 5567],
        [ 5451],
        [ 7929],
        [12047],
        [11748],
        [11231],
        [10567],
        [10336],
        [12077]], device='cuda:0')
[2024-07-24 10:18:56,355][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10313],
        [28029],
        [14003],
        [27444],
        [13528],
        [35173],
        [32758],
        [34303],
        [28087],
        [30165],
        [25649],
        [26348],
        [25661],
        [30341],
        [14202],
        [25830],
        [25596],
        [23095],
        [19383]], device='cuda:0')
[2024-07-24 10:18:56,357][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[45852],
        [44842],
        [37270],
        [36425],
        [39480],
        [23284],
        [22269],
        [37095],
        [37697],
        [37820],
        [36676],
        [36165],
        [32263],
        [29570],
        [33718],
        [26799],
        [23865],
        [23515],
        [20638]], device='cuda:0')
[2024-07-24 10:18:56,358][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[25150],
        [23071],
        [17930],
        [19040],
        [27808],
        [29319],
        [28181],
        [32293],
        [31806],
        [39939],
        [37552],
        [35651],
        [39111],
        [38189],
        [31781],
        [33067],
        [28870],
        [22981],
        [22185]], device='cuda:0')
[2024-07-24 10:18:56,359][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30833],
        [41062],
        [38831],
        [34629],
        [37932],
        [28876],
        [26610],
        [21916],
        [29866],
        [27944],
        [25331],
        [26634],
        [28678],
        [27531],
        [32615],
        [32606],
        [31749],
        [32727],
        [35059]], device='cuda:0')
[2024-07-24 10:18:56,360][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39204],
        [43192],
        [43965],
        [43466],
        [42463],
        [41945],
        [41784],
        [41315],
        [41114],
        [41015],
        [40773],
        [40748],
        [40844],
        [40732],
        [40674],
        [40834],
        [40744],
        [40811],
        [40691]], device='cuda:0')
[2024-07-24 10:18:56,361][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[32393],
        [35261],
        [34897],
        [35208],
        [33990],
        [35766],
        [35518],
        [36340],
        [35958],
        [35431],
        [35052],
        [34813],
        [34355],
        [32513],
        [31932],
        [32196],
        [31741],
        [30772],
        [31767]], device='cuda:0')
[2024-07-24 10:18:56,363][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[25570],
        [ 8495],
        [ 7995],
        [16372],
        [45634],
        [31066],
        [37850],
        [25720],
        [27352],
        [28756],
        [29901],
        [36265],
        [26490],
        [25172],
        [33726],
        [23758],
        [31372],
        [29719],
        [30335]], device='cuda:0')
[2024-07-24 10:18:56,365][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24905],
        [20187],
        [23580],
        [20373],
        [15847],
        [17675],
        [18365],
        [17220],
        [15694],
        [13915],
        [14046],
        [14639],
        [16734],
        [16551],
        [16777],
        [18838],
        [19830],
        [23377],
        [21789]], device='cuda:0')
[2024-07-24 10:18:56,366][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[19529],
        [28057],
        [29453],
        [28042],
        [27285],
        [25736],
        [26128],
        [18352],
        [23397],
        [22674],
        [22611],
        [23396],
        [23480],
        [23290],
        [24117],
        [23713],
        [25484],
        [23296],
        [21735]], device='cuda:0')
[2024-07-24 10:18:56,368][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011],
        [29011]], device='cuda:0')
[2024-07-24 10:18:56,399][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:56,401][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,402][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,403][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,404][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,406][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,407][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,408][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,409][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,409][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,409][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,410][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,410][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,410][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4398, 0.5602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,411][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1027, 0.8973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,411][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6913, 0.3087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,411][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1682, 0.8318], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,412][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3059, 0.6941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,412][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4254, 0.5746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,412][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0878, 0.9122], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,413][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2576, 0.7424], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,415][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9669, 0.0331], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,416][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0329, 0.9671], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,418][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6549, 0.3451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,419][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1600, 0.8400], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,420][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.3446, 0.3979, 0.2576], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,421][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0901, 0.3886, 0.5213], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,423][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.7099, 0.1912, 0.0989], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,425][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0923, 0.4506, 0.4571], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,426][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2654, 0.3600, 0.3746], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,427][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.2274, 0.4627, 0.3099], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,427][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0368, 0.3999, 0.5633], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,427][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0548, 0.0243, 0.9209], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,428][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.8785, 0.0500, 0.0715], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,428][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.1484, 0.6274, 0.2241], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,428][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.3452, 0.3145, 0.3403], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,429][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0631, 0.4420, 0.4949], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,429][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2388, 0.3067, 0.2073, 0.2472], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,429][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0263, 0.2545, 0.3728, 0.3463], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,430][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5994, 0.1715, 0.0924, 0.1367], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,430][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0612, 0.3110, 0.3160, 0.3118], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,431][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1452, 0.2320, 0.2823, 0.3406], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,432][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2089, 0.3275, 0.2269, 0.2367], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,434][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0182, 0.3524, 0.2833, 0.3461], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,435][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0106, 0.0364, 0.8907, 0.0622], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,437][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7597, 0.0579, 0.1377, 0.0446], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,438][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0186, 0.5555, 0.3193, 0.1066], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,440][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2693, 0.2288, 0.2308, 0.2711], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,442][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0425, 0.3005, 0.3378, 0.3193], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,443][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.2037, 0.2072, 0.1403, 0.1749, 0.2739], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,444][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0474, 0.1855, 0.2735, 0.3051, 0.1885], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,444][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.4661, 0.1799, 0.1013, 0.1450, 0.1077], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,445][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.0482, 0.2357, 0.2377, 0.2348, 0.2435], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,445][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.0811, 0.1836, 0.1784, 0.1922, 0.3647], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,445][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.1392, 0.2618, 0.1857, 0.2176, 0.1957], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,446][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0242, 0.2234, 0.2001, 0.1835, 0.3689], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,446][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.1791, 0.0424, 0.3352, 0.0419, 0.4014], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,446][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.9264, 0.0095, 0.0160, 0.0071, 0.0410], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,447][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.2440, 0.4051, 0.1601, 0.1533, 0.0374], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,447][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.2260, 0.1819, 0.1947, 0.2145, 0.1830], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,447][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0402, 0.2152, 0.2427, 0.2325, 0.2694], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,448][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1626, 0.1884, 0.1265, 0.1508, 0.2584, 0.1134], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,450][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0176, 0.1582, 0.2055, 0.2321, 0.2004, 0.1863], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,452][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4450, 0.1587, 0.0848, 0.1228, 0.0903, 0.0984], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,453][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0360, 0.1903, 0.1929, 0.1882, 0.1985, 0.1941], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,455][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0522, 0.1443, 0.1515, 0.2264, 0.2321, 0.1935], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,456][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1442, 0.2146, 0.1420, 0.1740, 0.1657, 0.1595], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,458][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0132, 0.2379, 0.1965, 0.1698, 0.2373, 0.1454], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,460][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0093, 0.0179, 0.3435, 0.0315, 0.5323, 0.0655], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,461][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5428, 0.0477, 0.0941, 0.0318, 0.2115, 0.0721], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,461][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0361, 0.4752, 0.2131, 0.1663, 0.0552, 0.0541], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,462][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1703, 0.1702, 0.1587, 0.1797, 0.1498, 0.1714], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,462][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0285, 0.1793, 0.2009, 0.1874, 0.2313, 0.1727], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,463][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1501, 0.1666, 0.1102, 0.1315, 0.2242, 0.0989, 0.1186],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,463][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0213, 0.1291, 0.1887, 0.1817, 0.2072, 0.1477, 0.1245],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,463][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4458, 0.1403, 0.0693, 0.1097, 0.0834, 0.0912, 0.0603],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,464][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0300, 0.1594, 0.1620, 0.1576, 0.1683, 0.1638, 0.1588],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,464][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0392, 0.1160, 0.1263, 0.1849, 0.1812, 0.1874, 0.1649],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,464][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1035, 0.1892, 0.1310, 0.1456, 0.1498, 0.1383, 0.1426],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,465][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0099, 0.2018, 0.1596, 0.1340, 0.2088, 0.0975, 0.1884],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,466][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0050, 0.0127, 0.3568, 0.0332, 0.4670, 0.0561, 0.0691],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,467][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3891, 0.0550, 0.1043, 0.0441, 0.2443, 0.1195, 0.0437],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,469][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0341, 0.4907, 0.1246, 0.1865, 0.0318, 0.0606, 0.0717],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,471][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1282, 0.1443, 0.1334, 0.1519, 0.1258, 0.1426, 0.1739],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,472][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0222, 0.1489, 0.1694, 0.1572, 0.1998, 0.1486, 0.1539],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,474][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.1609, 0.1510, 0.0977, 0.1117, 0.1918, 0.0821, 0.0994, 0.1055],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,476][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0268, 0.0984, 0.1546, 0.1577, 0.1599, 0.1291, 0.1153, 0.1582],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,477][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.3054, 0.1414, 0.0927, 0.1324, 0.0872, 0.0984, 0.0813, 0.0612],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,479][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0253, 0.1396, 0.1427, 0.1385, 0.1471, 0.1449, 0.1394, 0.1225],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,481][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0313, 0.1007, 0.0983, 0.1689, 0.1406, 0.1434, 0.1470, 0.1697],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,482][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0972, 0.1783, 0.1085, 0.1337, 0.1279, 0.1302, 0.1271, 0.0970],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,484][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0077, 0.1691, 0.1282, 0.1380, 0.1869, 0.0837, 0.1231, 0.1633],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,484][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0652, 0.0108, 0.1878, 0.0162, 0.3720, 0.0373, 0.0381, 0.2726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,484][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.4571, 0.0098, 0.0173, 0.0130, 0.0836, 0.0347, 0.0223, 0.3623],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,485][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0250, 0.2606, 0.0835, 0.1836, 0.0257, 0.0857, 0.2682, 0.0677],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,485][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1289, 0.1181, 0.1148, 0.1279, 0.1075, 0.1229, 0.1498, 0.1300],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,486][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0186, 0.1333, 0.1508, 0.1363, 0.1779, 0.1270, 0.1305, 0.1256],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,486][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1291, 0.1305, 0.0874, 0.1044, 0.1761, 0.0783, 0.0960, 0.0975, 0.1008],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,486][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0195, 0.0886, 0.1348, 0.1269, 0.1555, 0.1186, 0.1045, 0.1606, 0.0910],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,487][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3663, 0.1236, 0.0655, 0.1037, 0.0786, 0.0835, 0.0531, 0.0504, 0.0752],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,487][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0232, 0.1247, 0.1272, 0.1247, 0.1322, 0.1308, 0.1262, 0.1082, 0.1028],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,488][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0217, 0.0914, 0.0982, 0.1591, 0.1270, 0.1212, 0.1305, 0.1256, 0.1253],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,490][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0903, 0.1526, 0.1049, 0.1196, 0.1170, 0.1142, 0.1182, 0.0853, 0.0979],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,491][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0055, 0.1705, 0.1392, 0.1184, 0.1646, 0.0586, 0.1187, 0.0716, 0.1528],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,493][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0195, 0.0278, 0.3581, 0.0342, 0.3632, 0.0538, 0.0458, 0.0653, 0.0323],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,494][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.7637, 0.0138, 0.0222, 0.0110, 0.0524, 0.0261, 0.0119, 0.0356, 0.0634],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,496][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0353, 0.4131, 0.2030, 0.0984, 0.0343, 0.0457, 0.0810, 0.0467, 0.0425],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,498][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1119, 0.0993, 0.0995, 0.1146, 0.0904, 0.1064, 0.1351, 0.1097, 0.1332],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,499][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0201, 0.1230, 0.1360, 0.1245, 0.1542, 0.1127, 0.1172, 0.0929, 0.1193],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,501][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1206, 0.1195, 0.0790, 0.0920, 0.1591, 0.0707, 0.0849, 0.0932, 0.0936,
        0.0876], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,501][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0247, 0.0848, 0.1209, 0.1205, 0.1226, 0.0868, 0.0945, 0.1309, 0.1091,
        0.1052], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,502][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2980, 0.1228, 0.0717, 0.1183, 0.0752, 0.0791, 0.0599, 0.0431, 0.0810,
        0.0511], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,502][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0212, 0.1130, 0.1161, 0.1131, 0.1210, 0.1204, 0.1161, 0.0998, 0.0947,
        0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,503][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0283, 0.0881, 0.0710, 0.1265, 0.1416, 0.0994, 0.1141, 0.1215, 0.1101,
        0.0995], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,503][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0727, 0.1414, 0.0946, 0.1092, 0.1036, 0.1027, 0.1099, 0.0828, 0.0968,
        0.0864], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,503][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0095, 0.1530, 0.1184, 0.0985, 0.1580, 0.0638, 0.0917, 0.0964, 0.1116,
        0.0991], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,504][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0710, 0.0133, 0.2188, 0.0137, 0.3058, 0.0326, 0.0298, 0.1121, 0.0340,
        0.1690], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,504][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.6441, 0.0068, 0.0098, 0.0057, 0.0331, 0.0200, 0.0087, 0.0309, 0.1359,
        0.1050], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,505][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0248, 0.3303, 0.1306, 0.1303, 0.0196, 0.0647, 0.1450, 0.0391, 0.0886,
        0.0269], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,505][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0981, 0.0885, 0.0884, 0.0973, 0.0797, 0.0901, 0.1115, 0.0979, 0.1173,
        0.1310], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,507][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0134, 0.1070, 0.1215, 0.1059, 0.1396, 0.0981, 0.1008, 0.0860, 0.1104,
        0.1172], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,508][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1017, 0.1037, 0.0708, 0.0838, 0.1407, 0.0651, 0.0795, 0.0863, 0.0857,
        0.0809, 0.1018], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,510][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0221, 0.0695, 0.1013, 0.1078, 0.1181, 0.0804, 0.0842, 0.1283, 0.0846,
        0.1077, 0.0958], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,511][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.2469, 0.1086, 0.0668, 0.1052, 0.0695, 0.0762, 0.0567, 0.0417, 0.0812,
        0.0494, 0.0978], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,513][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0192, 0.1043, 0.1066, 0.1040, 0.1113, 0.1103, 0.1066, 0.0916, 0.0867,
        0.0782, 0.0810], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,515][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0203, 0.0804, 0.0851, 0.1287, 0.1206, 0.0886, 0.1042, 0.1037, 0.1013,
        0.0865, 0.0807], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,516][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0785, 0.1209, 0.0865, 0.0975, 0.1009, 0.1019, 0.0976, 0.0758, 0.0794,
        0.0804, 0.0806], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,518][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0038, 0.2020, 0.1012, 0.1135, 0.1676, 0.0550, 0.0857, 0.0686, 0.0953,
        0.0470, 0.0604], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,519][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0094, 0.0175, 0.2870, 0.0270, 0.2303, 0.0405, 0.0587, 0.1145, 0.0312,
        0.1640, 0.0199], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,519][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.4026, 0.0352, 0.0539, 0.0231, 0.1080, 0.0578, 0.0307, 0.0454, 0.1111,
        0.0957, 0.0366], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,519][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0831, 0.2727, 0.2884, 0.0852, 0.0417, 0.0424, 0.0398, 0.0337, 0.0458,
        0.0414, 0.0258], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,520][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1063, 0.0759, 0.0806, 0.0859, 0.0739, 0.0774, 0.0971, 0.0816, 0.1043,
        0.1092, 0.1079], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,520][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0132, 0.0976, 0.1103, 0.0985, 0.1264, 0.0923, 0.0956, 0.0778, 0.0952,
        0.0982, 0.0949], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,521][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0891, 0.0941, 0.0632, 0.0744, 0.1280, 0.0578, 0.0710, 0.0815, 0.0791,
        0.0757, 0.0955, 0.0906], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,521][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0110, 0.0575, 0.0785, 0.0843, 0.1081, 0.0767, 0.0806, 0.1160, 0.0865,
        0.1025, 0.1165, 0.0819], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,522][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3075, 0.1080, 0.0556, 0.0887, 0.0624, 0.0673, 0.0445, 0.0365, 0.0581,
        0.0383, 0.0743, 0.0588], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,522][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0176, 0.0959, 0.0986, 0.0961, 0.1033, 0.1023, 0.0989, 0.0854, 0.0801,
        0.0724, 0.0751, 0.0742], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,522][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0185, 0.0686, 0.0721, 0.1145, 0.1044, 0.1117, 0.0978, 0.1085, 0.0945,
        0.0778, 0.0741, 0.0577], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,524][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0697, 0.1129, 0.0816, 0.0876, 0.0928, 0.0884, 0.0894, 0.0688, 0.0726,
        0.0730, 0.0779, 0.0852], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,526][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0057, 0.1410, 0.0928, 0.0951, 0.1475, 0.0670, 0.1077, 0.0686, 0.1004,
        0.0492, 0.0450, 0.0799], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,527][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0023, 0.0087, 0.2921, 0.0108, 0.2852, 0.0237, 0.0294, 0.1067, 0.0152,
        0.1809, 0.0105, 0.0345], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,529][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4746, 0.0581, 0.0627, 0.0213, 0.1158, 0.0532, 0.0268, 0.0158, 0.0626,
        0.0412, 0.0236, 0.0444], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,529][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0325, 0.3784, 0.1263, 0.0836, 0.0199, 0.0241, 0.0365, 0.0404, 0.0620,
        0.0588, 0.0803, 0.0573], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,531][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0887, 0.0680, 0.0719, 0.0772, 0.0676, 0.0684, 0.0842, 0.0715, 0.0894,
        0.0971, 0.0943, 0.1219], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,533][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0113, 0.0887, 0.1030, 0.0876, 0.1187, 0.0833, 0.0859, 0.0702, 0.0832,
        0.0894, 0.0849, 0.0938], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,535][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0962, 0.0901, 0.0593, 0.0694, 0.1153, 0.0526, 0.0634, 0.0716, 0.0704,
        0.0664, 0.0846, 0.0801, 0.0809], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,536][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0096, 0.0506, 0.0761, 0.0816, 0.0743, 0.0718, 0.0793, 0.0963, 0.0882,
        0.0928, 0.1292, 0.0929, 0.0571], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,537][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2886, 0.0977, 0.0523, 0.0861, 0.0594, 0.0611, 0.0432, 0.0323, 0.0558,
        0.0387, 0.0717, 0.0593, 0.0539], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,537][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0162, 0.0898, 0.0921, 0.0899, 0.0956, 0.0956, 0.0920, 0.0805, 0.0756,
        0.0678, 0.0702, 0.0693, 0.0656], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,538][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0415, 0.0609, 0.0603, 0.0890, 0.0842, 0.0850, 0.0955, 0.1108, 0.0773,
        0.0723, 0.0650, 0.0520, 0.1061], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,538][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0715, 0.1032, 0.0694, 0.0808, 0.0828, 0.0816, 0.0783, 0.0592, 0.0667,
        0.0669, 0.0679, 0.0751, 0.0965], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,538][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0064, 0.1099, 0.0763, 0.0861, 0.1222, 0.0527, 0.0814, 0.0757, 0.0969,
        0.0522, 0.0513, 0.0670, 0.1218], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,539][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0162, 0.0082, 0.1191, 0.0098, 0.1639, 0.0255, 0.0296, 0.1753, 0.0209,
        0.2050, 0.0147, 0.0334, 0.1784], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,539][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.6196, 0.0124, 0.0153, 0.0075, 0.0352, 0.0183, 0.0089, 0.0132, 0.0432,
        0.0371, 0.0101, 0.0294, 0.1498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,540][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0468, 0.1879, 0.1043, 0.1033, 0.0182, 0.0294, 0.1002, 0.0556, 0.1054,
        0.0399, 0.0774, 0.1056, 0.0259], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,540][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0732, 0.0621, 0.0631, 0.0684, 0.0586, 0.0638, 0.0779, 0.0673, 0.0805,
        0.0872, 0.0841, 0.1114, 0.1025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,542][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0122, 0.0814, 0.0916, 0.0799, 0.1037, 0.0747, 0.0776, 0.0641, 0.0788,
        0.0841, 0.0801, 0.0866, 0.0854], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,544][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0737, 0.0907, 0.0609, 0.0679, 0.1162, 0.0514, 0.0608, 0.0688, 0.0662,
        0.0628, 0.0782, 0.0745, 0.0764, 0.0516], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,546][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0042, 0.0458, 0.0743, 0.0653, 0.0839, 0.0775, 0.0703, 0.1142, 0.0677,
        0.0891, 0.1125, 0.0937, 0.0629, 0.0385], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,547][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.2688, 0.0918, 0.0505, 0.0837, 0.0559, 0.0587, 0.0394, 0.0329, 0.0543,
        0.0352, 0.0670, 0.0546, 0.0526, 0.0544], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,549][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0149, 0.0860, 0.0877, 0.0853, 0.0907, 0.0897, 0.0865, 0.0745, 0.0700,
        0.0631, 0.0656, 0.0648, 0.0610, 0.0602], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,551][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0151, 0.0579, 0.0631, 0.1031, 0.0890, 0.0716, 0.0940, 0.0753, 0.0869,
        0.0603, 0.0663, 0.0597, 0.0906, 0.0671], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,552][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0723, 0.0998, 0.0669, 0.0747, 0.0715, 0.0720, 0.0741, 0.0506, 0.0596,
        0.0578, 0.0628, 0.0702, 0.0915, 0.0762], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,553][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0032, 0.1286, 0.0843, 0.0915, 0.1402, 0.0478, 0.0704, 0.0591, 0.0878,
        0.0503, 0.0452, 0.0455, 0.0934, 0.0528], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,554][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0012, 0.0010, 0.0458, 0.0021, 0.0628, 0.0056, 0.0073, 0.1845, 0.0167,
        0.3574, 0.0103, 0.0480, 0.2338, 0.0234], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,554][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.2414, 0.0043, 0.0053, 0.0039, 0.0171, 0.0095, 0.0046, 0.0249, 0.0891,
        0.0996, 0.0329, 0.0693, 0.3327, 0.0653], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,555][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0045, 0.2986, 0.1396, 0.0999, 0.0239, 0.0217, 0.0722, 0.0380, 0.0611,
        0.0311, 0.0508, 0.0746, 0.0354, 0.0486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,555][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0548, 0.0573, 0.0566, 0.0637, 0.0516, 0.0570, 0.0718, 0.0627, 0.0751,
        0.0815, 0.0801, 0.1045, 0.0932, 0.0901], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,556][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0077, 0.0677, 0.0794, 0.0705, 0.0953, 0.0659, 0.0686, 0.0646, 0.0781,
        0.0878, 0.0788, 0.0881, 0.0874, 0.0600], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,556][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0854, 0.0815, 0.0526, 0.0607, 0.1052, 0.0457, 0.0555, 0.0628, 0.0606,
        0.0578, 0.0724, 0.0701, 0.0718, 0.0496, 0.0682], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,557][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0132, 0.0471, 0.0665, 0.0782, 0.0853, 0.0656, 0.0675, 0.0779, 0.0685,
        0.0676, 0.1205, 0.0766, 0.0616, 0.0418, 0.0621], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,557][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.3113, 0.0891, 0.0467, 0.0784, 0.0472, 0.0484, 0.0366, 0.0252, 0.0474,
        0.0320, 0.0612, 0.0489, 0.0435, 0.0488, 0.0351], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,558][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0149, 0.0798, 0.0813, 0.0795, 0.0845, 0.0840, 0.0812, 0.0704, 0.0663,
        0.0597, 0.0620, 0.0611, 0.0579, 0.0573, 0.0601], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,560][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0366, 0.0670, 0.0602, 0.0727, 0.0857, 0.0759, 0.0727, 0.0853, 0.0749,
        0.0732, 0.0618, 0.0453, 0.0798, 0.0624, 0.0466], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,561][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0500, 0.0891, 0.0616, 0.0709, 0.0700, 0.0697, 0.0688, 0.0534, 0.0597,
        0.0610, 0.0598, 0.0667, 0.0859, 0.0743, 0.0591], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,563][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0057, 0.0948, 0.1070, 0.0694, 0.0999, 0.0532, 0.0656, 0.0552, 0.0791,
        0.0532, 0.0381, 0.0557, 0.0840, 0.0582, 0.0812], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,564][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0044, 0.0015, 0.0491, 0.0013, 0.0719, 0.0059, 0.0078, 0.2901, 0.0091,
        0.2610, 0.0036, 0.0112, 0.1653, 0.0075, 0.1103], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,566][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.7647, 0.0061, 0.0044, 0.0029, 0.0124, 0.0068, 0.0034, 0.0076, 0.0173,
        0.0117, 0.0028, 0.0081, 0.0740, 0.0176, 0.0603], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,568][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0599, 0.2215, 0.0845, 0.0770, 0.0262, 0.0261, 0.0278, 0.0145, 0.0539,
        0.0355, 0.0559, 0.0707, 0.0518, 0.0551, 0.1396], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,569][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0635, 0.0512, 0.0565, 0.0586, 0.0525, 0.0548, 0.0637, 0.0578, 0.0655,
        0.0720, 0.0686, 0.0900, 0.0846, 0.0787, 0.0820], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,571][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0077, 0.0679, 0.0798, 0.0675, 0.0923, 0.0644, 0.0666, 0.0610, 0.0693,
        0.0782, 0.0684, 0.0745, 0.0781, 0.0528, 0.0716], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,571][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0838, 0.0743, 0.0482, 0.0562, 0.0993, 0.0422, 0.0515, 0.0583, 0.0575,
        0.0540, 0.0695, 0.0655, 0.0679, 0.0463, 0.0655, 0.0601],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,572][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0067, 0.0402, 0.0575, 0.0654, 0.0679, 0.0468, 0.0603, 0.0869, 0.0618,
        0.0929, 0.1048, 0.0781, 0.0568, 0.0421, 0.0536, 0.0782],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,572][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2691, 0.0843, 0.0448, 0.0752, 0.0458, 0.0483, 0.0350, 0.0256, 0.0476,
        0.0319, 0.0606, 0.0509, 0.0468, 0.0516, 0.0370, 0.0454],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,572][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0147, 0.0735, 0.0759, 0.0741, 0.0795, 0.0775, 0.0752, 0.0653, 0.0623,
        0.0563, 0.0583, 0.0578, 0.0548, 0.0536, 0.0568, 0.0644],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,573][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0212, 0.0479, 0.0541, 0.0724, 0.0857, 0.0823, 0.0810, 0.0878, 0.0694,
        0.0601, 0.0535, 0.0461, 0.0799, 0.0560, 0.0406, 0.0622],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,573][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0431, 0.0791, 0.0573, 0.0660, 0.0633, 0.0631, 0.0650, 0.0547, 0.0573,
        0.0566, 0.0583, 0.0622, 0.0849, 0.0711, 0.0592, 0.0591],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,574][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0062, 0.1041, 0.0642, 0.0709, 0.0931, 0.0546, 0.0751, 0.0627, 0.0825,
        0.0511, 0.0393, 0.0538, 0.0800, 0.0471, 0.0439, 0.0712],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,574][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0077, 0.0049, 0.0714, 0.0051, 0.1108, 0.0162, 0.0248, 0.2270, 0.0166,
        0.1832, 0.0096, 0.0180, 0.1233, 0.0134, 0.1181, 0.0500],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,576][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4915, 0.0169, 0.0102, 0.0058, 0.0205, 0.0132, 0.0067, 0.0055, 0.0175,
        0.0118, 0.0072, 0.0184, 0.1200, 0.0112, 0.1109, 0.1327],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,578][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0500, 0.1881, 0.0576, 0.0558, 0.0184, 0.0247, 0.0479, 0.0267, 0.0384,
        0.0416, 0.0733, 0.0744, 0.0942, 0.0726, 0.0909, 0.0455],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,579][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0510, 0.0512, 0.0481, 0.0523, 0.0445, 0.0488, 0.0605, 0.0518, 0.0630,
        0.0686, 0.0687, 0.0891, 0.0774, 0.0760, 0.0737, 0.0752],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,581][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0105, 0.0656, 0.0759, 0.0662, 0.0863, 0.0621, 0.0651, 0.0550, 0.0636,
        0.0695, 0.0641, 0.0703, 0.0709, 0.0485, 0.0660, 0.0605],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,583][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0741, 0.0716, 0.0467, 0.0528, 0.0918, 0.0396, 0.0478, 0.0575, 0.0537,
        0.0523, 0.0637, 0.0599, 0.0636, 0.0448, 0.0612, 0.0559, 0.0628],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,585][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0069, 0.0378, 0.0582, 0.0573, 0.0696, 0.0456, 0.0415, 0.1064, 0.0641,
        0.0788, 0.0962, 0.0695, 0.0488, 0.0398, 0.0561, 0.0782, 0.0454],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,586][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2988, 0.0834, 0.0411, 0.0691, 0.0439, 0.0465, 0.0293, 0.0239, 0.0404,
        0.0271, 0.0552, 0.0429, 0.0397, 0.0427, 0.0298, 0.0401, 0.0462],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,588][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0123, 0.0696, 0.0711, 0.0696, 0.0742, 0.0733, 0.0707, 0.0615, 0.0580,
        0.0524, 0.0544, 0.0537, 0.0507, 0.0501, 0.0531, 0.0604, 0.0649],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,588][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0159, 0.0507, 0.0530, 0.0866, 0.0720, 0.0802, 0.0713, 0.0777, 0.0677,
        0.0537, 0.0533, 0.0432, 0.0676, 0.0550, 0.0423, 0.0605, 0.0494],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,589][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0463, 0.0771, 0.0564, 0.0600, 0.0640, 0.0596, 0.0607, 0.0476, 0.0504,
        0.0516, 0.0539, 0.0584, 0.0765, 0.0640, 0.0546, 0.0574, 0.0617],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,589][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0059, 0.0866, 0.0626, 0.0624, 0.0895, 0.0510, 0.0915, 0.0498, 0.0803,
        0.0392, 0.0390, 0.0573, 0.0705, 0.0493, 0.0486, 0.0474, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,590][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0009, 0.0008, 0.0336, 0.0013, 0.0463, 0.0057, 0.0071, 0.3244, 0.0069,
        0.2614, 0.0028, 0.0076, 0.1112, 0.0154, 0.1234, 0.0377, 0.0134],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,590][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3101, 0.0143, 0.0135, 0.0058, 0.0256, 0.0133, 0.0049, 0.0078, 0.0241,
        0.0168, 0.0073, 0.0143, 0.1472, 0.0190, 0.1395, 0.1943, 0.0421],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,591][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0328, 0.2133, 0.0569, 0.0687, 0.0120, 0.0176, 0.0216, 0.0523, 0.0420,
        0.0420, 0.0465, 0.0491, 0.0390, 0.0737, 0.0718, 0.0661, 0.0947],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,591][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0462, 0.0519, 0.0470, 0.0518, 0.0436, 0.0467, 0.0567, 0.0494, 0.0588,
        0.0636, 0.0639, 0.0805, 0.0706, 0.0670, 0.0669, 0.0676, 0.0677],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,592][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0082, 0.0584, 0.0681, 0.0589, 0.0794, 0.0567, 0.0589, 0.0549, 0.0599,
        0.0684, 0.0596, 0.0656, 0.0687, 0.0478, 0.0635, 0.0588, 0.0642],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,593][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0879, 0.0679, 0.0437, 0.0499, 0.0853, 0.0369, 0.0446, 0.0527, 0.0493,
        0.0468, 0.0568, 0.0536, 0.0565, 0.0405, 0.0530, 0.0497, 0.0559, 0.0692],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,595][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0120, 0.0360, 0.0478, 0.0624, 0.0483, 0.0515, 0.0520, 0.0711, 0.0550,
        0.0601, 0.0856, 0.0633, 0.0493, 0.0426, 0.0492, 0.0852, 0.0624, 0.0663],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,597][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.3131, 0.0816, 0.0429, 0.0717, 0.0410, 0.0419, 0.0292, 0.0193, 0.0386,
        0.0260, 0.0516, 0.0392, 0.0347, 0.0391, 0.0289, 0.0341, 0.0432, 0.0239],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,598][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0127, 0.0650, 0.0663, 0.0650, 0.0692, 0.0682, 0.0659, 0.0574, 0.0546,
        0.0496, 0.0513, 0.0506, 0.0480, 0.0476, 0.0501, 0.0568, 0.0612, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,600][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0149, 0.0487, 0.0469, 0.0776, 0.0830, 0.0730, 0.0696, 0.0673, 0.0601,
        0.0556, 0.0486, 0.0394, 0.0811, 0.0472, 0.0338, 0.0482, 0.0449, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,602][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.0372, 0.0758, 0.0518, 0.0592, 0.0584, 0.0566, 0.0595, 0.0443, 0.0519,
        0.0473, 0.0513, 0.0565, 0.0720, 0.0633, 0.0507, 0.0572, 0.0608, 0.0461],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,603][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0041, 0.0981, 0.0671, 0.0679, 0.0918, 0.0375, 0.0679, 0.0468, 0.0744,
        0.0442, 0.0318, 0.0485, 0.0832, 0.0409, 0.0474, 0.0518, 0.0571, 0.0395],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,605][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0129, 0.0006, 0.0083, 0.0008, 0.0163, 0.0042, 0.0052, 0.3738, 0.0079,
        0.1829, 0.0023, 0.0026, 0.0474, 0.0302, 0.0225, 0.0115, 0.0058, 0.2648],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,605][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.5774, 0.0050, 0.0037, 0.0036, 0.0101, 0.0079, 0.0041, 0.0108, 0.0217,
        0.0122, 0.0030, 0.0059, 0.0471, 0.0204, 0.0493, 0.0797, 0.0264, 0.1117],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,606][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0907, 0.1436, 0.0723, 0.0515, 0.0101, 0.0186, 0.0376, 0.0363, 0.0295,
        0.0305, 0.0410, 0.0495, 0.0242, 0.0645, 0.1037, 0.0573, 0.1042, 0.0350],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,606][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0354, 0.0488, 0.0437, 0.0494, 0.0411, 0.0463, 0.0541, 0.0505, 0.0564,
        0.0615, 0.0597, 0.0754, 0.0678, 0.0665, 0.0650, 0.0629, 0.0631, 0.0525],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,607][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0080, 0.0572, 0.0648, 0.0565, 0.0739, 0.0537, 0.0555, 0.0549, 0.0580,
        0.0667, 0.0557, 0.0590, 0.0622, 0.0478, 0.0577, 0.0526, 0.0582, 0.0576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,607][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0780, 0.0616, 0.0405, 0.0457, 0.0774, 0.0344, 0.0407, 0.0485, 0.0438,
        0.0422, 0.0501, 0.0476, 0.0506, 0.0382, 0.0485, 0.0443, 0.0509, 0.0633,
        0.0939], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,608][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0086, 0.0353, 0.0493, 0.0503, 0.0655, 0.0480, 0.0475, 0.0837, 0.0481,
        0.0667, 0.0625, 0.0548, 0.0480, 0.0342, 0.0464, 0.0637, 0.0497, 0.0649,
        0.0728], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,608][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2774, 0.0810, 0.0438, 0.0674, 0.0406, 0.0416, 0.0283, 0.0212, 0.0394,
        0.0258, 0.0497, 0.0388, 0.0349, 0.0383, 0.0286, 0.0346, 0.0418, 0.0254,
        0.0414], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,609][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0119, 0.0614, 0.0626, 0.0613, 0.0654, 0.0644, 0.0620, 0.0541, 0.0512,
        0.0466, 0.0480, 0.0474, 0.0449, 0.0445, 0.0468, 0.0532, 0.0571, 0.0564,
        0.0609], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,610][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0103, 0.0442, 0.0455, 0.0831, 0.0719, 0.0593, 0.0667, 0.0633, 0.0600,
        0.0476, 0.0450, 0.0442, 0.0636, 0.0456, 0.0360, 0.0488, 0.0477, 0.0632,
        0.0541], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,611][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0461, 0.0699, 0.0506, 0.0553, 0.0560, 0.0520, 0.0555, 0.0413, 0.0455,
        0.0461, 0.0478, 0.0527, 0.0699, 0.0584, 0.0492, 0.0544, 0.0577, 0.0445,
        0.0472], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,613][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0033, 0.0886, 0.0507, 0.0703, 0.1084, 0.0403, 0.0718, 0.0407, 0.0837,
        0.0359, 0.0361, 0.0458, 0.0740, 0.0445, 0.0363, 0.0398, 0.0537, 0.0335,
        0.0426], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,615][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0027, 0.0006, 0.0149, 0.0011, 0.0190, 0.0039, 0.0071, 0.3255, 0.0060,
        0.1836, 0.0018, 0.0034, 0.0440, 0.0273, 0.0499, 0.0136, 0.0101, 0.2718,
        0.0138], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,616][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3336, 0.0073, 0.0074, 0.0039, 0.0173, 0.0107, 0.0051, 0.0149, 0.0235,
        0.0172, 0.0042, 0.0069, 0.0877, 0.0211, 0.0735, 0.1000, 0.0292, 0.2089,
        0.0275], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,618][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0561, 0.1843, 0.0871, 0.0337, 0.0119, 0.0136, 0.0235, 0.0177, 0.0244,
        0.0187, 0.0369, 0.0478, 0.0184, 0.0612, 0.1124, 0.0523, 0.1175, 0.0381,
        0.0444], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,620][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0394, 0.0446, 0.0428, 0.0486, 0.0407, 0.0431, 0.0526, 0.0457, 0.0520,
        0.0551, 0.0553, 0.0692, 0.0623, 0.0596, 0.0600, 0.0582, 0.0619, 0.0518,
        0.0573], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,621][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0090, 0.0525, 0.0605, 0.0534, 0.0689, 0.0501, 0.0525, 0.0509, 0.0539,
        0.0612, 0.0526, 0.0568, 0.0590, 0.0460, 0.0560, 0.0508, 0.0569, 0.0559,
        0.0530], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,665][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:56,666][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,666][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,666][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,666][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,667][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,667][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,667][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,668][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,668][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,668][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,669][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,670][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,672][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0729, 0.9271], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,674][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0323, 0.9677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,675][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1975, 0.8025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,677][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2119, 0.7881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,678][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9966, 0.0034], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,680][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8586, 0.1414], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,681][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1424, 0.8576], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,682][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3935, 0.6065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,682][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9669, 0.0331], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,683][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0060, 0.9940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,683][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2598, 0.7402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,683][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6909, 0.3091], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,684][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0457, 0.3940, 0.5603], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,684][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0778, 0.1329, 0.7893], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,684][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.2700, 0.5401, 0.1899], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,685][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0634, 0.3379, 0.5986], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,685][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.9822, 0.0084, 0.0095], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,685][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.3312, 0.5276, 0.1412], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,686][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0710, 0.4141, 0.5150], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,687][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.2358, 0.3750, 0.3893], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,688][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.8785, 0.0500, 0.0715], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,690][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0459, 0.6995, 0.2546], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,691][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.1878, 0.5199, 0.2924], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,693][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.2034, 0.3299, 0.4668], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,694][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0158, 0.2870, 0.4643, 0.2330], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,696][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0030, 0.1170, 0.7207, 0.1593], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,698][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2121, 0.3000, 0.2468, 0.2412], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,699][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0223, 0.1562, 0.5596, 0.2619], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,700][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9832, 0.0049, 0.0071, 0.0048], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,700][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5159, 0.2571, 0.1137, 0.1133], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,700][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0514, 0.3079, 0.3346, 0.3061], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,701][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1532, 0.2765, 0.3011, 0.2692], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,701][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7597, 0.0579, 0.1377, 0.0446], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,701][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0038, 0.4700, 0.3308, 0.1955], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,702][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1215, 0.5742, 0.1243, 0.1800], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,702][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2186, 0.2402, 0.3950, 0.1462], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:56,702][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.0296, 0.1584, 0.2162, 0.1405, 0.4554], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,703][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.1070, 0.0265, 0.1487, 0.0376, 0.6802], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,703][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.2517, 0.2467, 0.1521, 0.1936, 0.1558], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,704][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0782, 0.1061, 0.1884, 0.1473, 0.4800], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,706][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.9792, 0.0031, 0.0058, 0.0038, 0.0082], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,707][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.2902, 0.2830, 0.1125, 0.2280, 0.0862], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,709][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.0398, 0.2213, 0.2533, 0.2151, 0.2705], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,710][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.1653, 0.2167, 0.2313, 0.2114, 0.1753], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,712][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.9264, 0.0095, 0.0160, 0.0071, 0.0410], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,714][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.0560, 0.4032, 0.1661, 0.3195, 0.0552], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,715][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.2085, 0.2200, 0.1570, 0.2025, 0.2120], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,717][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.2488, 0.1100, 0.1533, 0.0595, 0.4284], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:56,717][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0132, 0.1252, 0.1953, 0.1024, 0.4236, 0.1402], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,717][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0020, 0.0120, 0.0993, 0.0237, 0.7431, 0.1199], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,718][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0955, 0.2895, 0.1377, 0.2212, 0.1781, 0.0780], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,718][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0228, 0.0774, 0.1372, 0.0848, 0.4785, 0.1994], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,718][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9305, 0.0107, 0.0196, 0.0093, 0.0160, 0.0139], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,719][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4456, 0.1759, 0.0507, 0.1387, 0.0579, 0.1312], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,719][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0333, 0.1783, 0.2054, 0.1775, 0.2094, 0.1962], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,720][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0835, 0.1801, 0.1980, 0.1724, 0.1625, 0.2035], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,720][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.5428, 0.0477, 0.0941, 0.0318, 0.2115, 0.0721], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,720][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0028, 0.3759, 0.2510, 0.2204, 0.1038, 0.0461], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,721][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0811, 0.3009, 0.0995, 0.2477, 0.1519, 0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,723][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1197, 0.1021, 0.1671, 0.0433, 0.4689, 0.0989], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:56,724][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0137, 0.1128, 0.1683, 0.0879, 0.3349, 0.1182, 0.1642],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,725][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.2558e-04, 1.1029e-02, 9.5197e-02, 2.2311e-02, 6.6787e-01, 1.7678e-01,
        2.6192e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,727][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0848, 0.1379, 0.1154, 0.0963, 0.2967, 0.1050, 0.1639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,728][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0273, 0.0679, 0.1001, 0.0632, 0.3728, 0.1494, 0.2193],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,729][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9128, 0.0105, 0.0160, 0.0095, 0.0180, 0.0150, 0.0182],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,729][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2612, 0.2169, 0.0802, 0.1079, 0.0920, 0.1521, 0.0897],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,730][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0264, 0.1514, 0.1732, 0.1465, 0.1721, 0.1563, 0.1741],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,730][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0609, 0.1512, 0.1719, 0.1460, 0.1407, 0.1712, 0.1582],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,730][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3891, 0.0550, 0.1043, 0.0441, 0.2443, 0.1195, 0.0437],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,731][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0036, 0.3799, 0.1765, 0.2540, 0.0743, 0.0524, 0.0594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,731][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0757, 0.2139, 0.1073, 0.1429, 0.1809, 0.1748, 0.1045],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,732][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0431, 0.0755, 0.1244, 0.0467, 0.5002, 0.1548, 0.0552],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:56,734][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0348, 0.0990, 0.1421, 0.0563, 0.2054, 0.0623, 0.0702, 0.3297],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,736][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0061, 0.0035, 0.0243, 0.0046, 0.2763, 0.0276, 0.0054, 0.6521],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,737][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0894, 0.1108, 0.1064, 0.1340, 0.1582, 0.0569, 0.0804, 0.2639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,737][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0593, 0.0408, 0.0596, 0.0271, 0.1595, 0.0693, 0.1022, 0.4822],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,738][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.8459, 0.0165, 0.0221, 0.0133, 0.0323, 0.0182, 0.0283, 0.0233],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,738][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.3141, 0.1534, 0.0299, 0.0839, 0.0412, 0.1292, 0.0515, 0.1967],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,738][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0266, 0.1328, 0.1450, 0.1341, 0.1506, 0.1366, 0.1398, 0.1343],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,739][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0744, 0.1267, 0.1385, 0.1175, 0.1067, 0.1347, 0.1253, 0.1762],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,739][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.4571, 0.0098, 0.0173, 0.0130, 0.0836, 0.0347, 0.0223, 0.3623],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,740][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0039, 0.2309, 0.1313, 0.2538, 0.0605, 0.0755, 0.1936, 0.0504],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,740][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0551, 0.2127, 0.0573, 0.1541, 0.0663, 0.2029, 0.0692, 0.1823],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,740][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0692, 0.0220, 0.0387, 0.0182, 0.2072, 0.0911, 0.0290, 0.5247],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:56,741][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0094, 0.0678, 0.1008, 0.0579, 0.1761, 0.0706, 0.1091, 0.3330, 0.0753],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,742][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0020, 0.0071, 0.0477, 0.0097, 0.3105, 0.0488, 0.0118, 0.5200, 0.0424],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,744][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1059, 0.1323, 0.1040, 0.1121, 0.1483, 0.0621, 0.1310, 0.0896, 0.1147],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,745][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0182, 0.0281, 0.0622, 0.0296, 0.1358, 0.0831, 0.1125, 0.4500, 0.0806],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,747][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.9126, 0.0059, 0.0095, 0.0071, 0.0126, 0.0094, 0.0135, 0.0167, 0.0127],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,748][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2242, 0.1310, 0.0461, 0.0979, 0.0520, 0.1203, 0.0590, 0.1657, 0.1037],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,750][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0201, 0.1147, 0.1307, 0.1173, 0.1353, 0.1169, 0.1261, 0.0966, 0.1424],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,752][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0462, 0.1073, 0.1267, 0.1073, 0.1020, 0.1218, 0.1135, 0.1647, 0.1107],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,753][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.7637, 0.0138, 0.0222, 0.0110, 0.0524, 0.0261, 0.0119, 0.0356, 0.0634],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,754][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0055, 0.2955, 0.2345, 0.1548, 0.0728, 0.0479, 0.0741, 0.0459, 0.0689],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,755][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0642, 0.1196, 0.0833, 0.1020, 0.1167, 0.0819, 0.0940, 0.2049, 0.1335],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,755][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1670, 0.0437, 0.0881, 0.0305, 0.2892, 0.0775, 0.0344, 0.0828, 0.1868],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:56,755][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0163, 0.0607, 0.0842, 0.0410, 0.1526, 0.0515, 0.0701, 0.3262, 0.0671,
        0.1303], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,756][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0062, 0.0079, 0.0435, 0.0148, 0.2808, 0.0569, 0.0117, 0.4850, 0.0628,
        0.0304], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,756][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1187, 0.1031, 0.0925, 0.1012, 0.1132, 0.0735, 0.0526, 0.0757, 0.1299,
        0.1396], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,757][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0480, 0.0228, 0.0209, 0.0154, 0.0723, 0.0423, 0.0732, 0.3363, 0.0749,
        0.2938], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,757][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.8578, 0.0091, 0.0144, 0.0108, 0.0243, 0.0111, 0.0181, 0.0223, 0.0209,
        0.0112], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,757][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.1312, 0.1437, 0.0394, 0.0933, 0.0345, 0.0913, 0.0723, 0.2090, 0.1478,
        0.0376], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,758][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0213, 0.1043, 0.1214, 0.1004, 0.1181, 0.1082, 0.1068, 0.0993, 0.1155,
        0.1048], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,758][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0608, 0.0975, 0.1078, 0.0924, 0.0796, 0.1066, 0.1023, 0.1406, 0.0983,
        0.1141], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,760][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6441, 0.0068, 0.0098, 0.0057, 0.0331, 0.0200, 0.0087, 0.0309, 0.1359,
        0.1050], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,762][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0036, 0.2552, 0.1430, 0.1796, 0.0352, 0.0624, 0.1173, 0.0335, 0.1354,
        0.0347], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,763][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0577, 0.1666, 0.0403, 0.1280, 0.0431, 0.0891, 0.0466, 0.1092, 0.2056,
        0.1137], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,765][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0779, 0.0182, 0.0360, 0.0096, 0.1338, 0.0410, 0.0160, 0.0716, 0.2250,
        0.3710], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:56,767][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0063, 0.0431, 0.0553, 0.0394, 0.1366, 0.0540, 0.0833, 0.3045, 0.0727,
        0.1341, 0.0707], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,768][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0018, 0.0087, 0.0445, 0.0178, 0.2283, 0.1140, 0.0233, 0.4516, 0.0679,
        0.0318, 0.0103], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,770][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0913, 0.0938, 0.0563, 0.1009, 0.1026, 0.0848, 0.0965, 0.0301, 0.0715,
        0.1289, 0.1433], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,771][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0190, 0.0242, 0.0258, 0.0198, 0.0772, 0.0504, 0.0823, 0.2675, 0.0747,
        0.2578, 0.1013], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,772][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.9333, 0.0034, 0.0063, 0.0044, 0.0121, 0.0058, 0.0062, 0.0102, 0.0087,
        0.0064, 0.0032], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,772][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.1064, 0.1072, 0.0368, 0.0861, 0.0561, 0.1572, 0.0538, 0.2170, 0.0851,
        0.0497, 0.0445], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,773][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0147, 0.0980, 0.1021, 0.0979, 0.1127, 0.0973, 0.1004, 0.0854, 0.1094,
        0.0806, 0.1015], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,773][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0376, 0.0866, 0.0959, 0.0838, 0.0818, 0.0955, 0.0897, 0.1374, 0.0911,
        0.1186, 0.0820], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,773][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4026, 0.0352, 0.0539, 0.0231, 0.1080, 0.0578, 0.0307, 0.0454, 0.1111,
        0.0957, 0.0366], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,774][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0160, 0.1917, 0.2376, 0.1309, 0.0648, 0.0622, 0.0491, 0.0458, 0.0829,
        0.0638, 0.0551], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,774][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0493, 0.0868, 0.0647, 0.0903, 0.0886, 0.0801, 0.0799, 0.1234, 0.1137,
        0.1475, 0.0757], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,775][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0545, 0.0467, 0.0948, 0.0210, 0.2748, 0.0746, 0.0389, 0.0456, 0.0950,
        0.2002, 0.0538], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:56,775][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0035, 0.0272, 0.0418, 0.0245, 0.0989, 0.0385, 0.0644, 0.4249, 0.0537,
        0.1384, 0.0482, 0.0360], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,776][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0005, 0.0082, 0.0702, 0.0151, 0.2797, 0.1056, 0.0212, 0.4211, 0.0477,
        0.0200, 0.0078, 0.0028], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,777][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0805, 0.0621, 0.0774, 0.0537, 0.1061, 0.0448, 0.0879, 0.0584, 0.0361,
        0.1381, 0.0936, 0.1613], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,779][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0175, 0.0133, 0.0119, 0.0073, 0.0522, 0.0258, 0.0395, 0.3675, 0.0404,
        0.2887, 0.0753, 0.0606], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,780][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.9525, 0.0023, 0.0035, 0.0027, 0.0045, 0.0043, 0.0042, 0.0071, 0.0055,
        0.0045, 0.0024, 0.0063], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,782][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1347, 0.1170, 0.0462, 0.0695, 0.0545, 0.1158, 0.0595, 0.1914, 0.0712,
        0.0406, 0.0637, 0.0360], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,783][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0147, 0.0877, 0.0961, 0.0869, 0.0994, 0.0920, 0.0952, 0.0769, 0.1009,
        0.0762, 0.0825, 0.0916], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,784][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0290, 0.0774, 0.0875, 0.0753, 0.0735, 0.0896, 0.0838, 0.1312, 0.0846,
        0.1128, 0.0777, 0.0775], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,786][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.4746, 0.0581, 0.0627, 0.0213, 0.1158, 0.0532, 0.0268, 0.0158, 0.0626,
        0.0412, 0.0236, 0.0444], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,788][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0047, 0.2536, 0.1401, 0.1136, 0.0402, 0.0276, 0.0341, 0.0373, 0.0879,
        0.0681, 0.1158, 0.0770], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,789][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0591, 0.0771, 0.0446, 0.0611, 0.0871, 0.0788, 0.0469, 0.1150, 0.1399,
        0.1230, 0.0846, 0.0828], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,790][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0661, 0.0644, 0.1019, 0.0217, 0.2958, 0.0720, 0.0291, 0.0245, 0.0697,
        0.1313, 0.0537, 0.0699], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:56,790][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0085, 0.0391, 0.0534, 0.0302, 0.1009, 0.0401, 0.0608, 0.3277, 0.0569,
        0.1259, 0.0502, 0.0382, 0.0680], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,791][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0061, 0.0106, 0.0565, 0.0173, 0.2749, 0.0798, 0.0119, 0.4550, 0.0491,
        0.0201, 0.0067, 0.0023, 0.0097], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,791][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0509, 0.0513, 0.0343, 0.0627, 0.0599, 0.0338, 0.0221, 0.0522, 0.0852,
        0.1763, 0.1002, 0.0563, 0.2148], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,791][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0293, 0.0157, 0.0127, 0.0091, 0.0438, 0.0278, 0.0445, 0.2815, 0.0435,
        0.2031, 0.0681, 0.0569, 0.1640], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,792][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.9605, 0.0015, 0.0023, 0.0017, 0.0042, 0.0028, 0.0034, 0.0063, 0.0052,
        0.0038, 0.0016, 0.0042, 0.0027], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,792][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.2188, 0.1116, 0.0271, 0.0609, 0.0320, 0.1172, 0.0440, 0.1843, 0.0708,
        0.0385, 0.0431, 0.0221, 0.0299], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,793][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0167, 0.0802, 0.0877, 0.0799, 0.0894, 0.0836, 0.0826, 0.0737, 0.0903,
        0.0703, 0.0798, 0.0790, 0.0868], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,793][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0525, 0.0707, 0.0787, 0.0705, 0.0578, 0.0847, 0.0822, 0.1122, 0.0805,
        0.0905, 0.0756, 0.0756, 0.0684], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,795][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.6196, 0.0124, 0.0153, 0.0075, 0.0352, 0.0183, 0.0089, 0.0132, 0.0432,
        0.0371, 0.0101, 0.0294, 0.1498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,797][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0034, 0.1419, 0.1182, 0.1329, 0.0330, 0.0250, 0.0701, 0.0365, 0.1429,
        0.0399, 0.1117, 0.1152, 0.0291], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,798][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0303, 0.0985, 0.0360, 0.0787, 0.0365, 0.0768, 0.0479, 0.0775, 0.1649,
        0.0525, 0.0647, 0.1206, 0.1152], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,799][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1204, 0.0318, 0.0442, 0.0122, 0.1276, 0.0427, 0.0211, 0.0317, 0.0867,
        0.1468, 0.0459, 0.0646, 0.2244], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:56,800][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0081, 0.0510, 0.0919, 0.0296, 0.1114, 0.0384, 0.0452, 0.3367, 0.0368,
        0.1011, 0.0322, 0.0177, 0.0449, 0.0548], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,802][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0049, 0.0040, 0.0297, 0.0071, 0.2195, 0.0356, 0.0081, 0.5104, 0.0655,
        0.0396, 0.0128, 0.0051, 0.0131, 0.0447], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,804][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0291, 0.0568, 0.0286, 0.0440, 0.0397, 0.0323, 0.0399, 0.0332, 0.0234,
        0.2236, 0.0773, 0.0454, 0.2079, 0.1189], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,806][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0208, 0.0212, 0.0242, 0.0088, 0.0588, 0.0280, 0.0299, 0.2905, 0.0234,
        0.2052, 0.0556, 0.0274, 0.1276, 0.0785], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,807][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.9171, 0.0032, 0.0059, 0.0040, 0.0097, 0.0067, 0.0061, 0.0106, 0.0071,
        0.0054, 0.0029, 0.0072, 0.0040, 0.0101], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,807][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.2811, 0.0785, 0.0258, 0.0537, 0.0262, 0.0907, 0.0491, 0.0831, 0.0568,
        0.0280, 0.0396, 0.0266, 0.0440, 0.1170], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,808][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0115, 0.0755, 0.0816, 0.0749, 0.0918, 0.0757, 0.0775, 0.0653, 0.0867,
        0.0654, 0.0751, 0.0697, 0.0737, 0.0756], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,808][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0297, 0.0710, 0.0813, 0.0668, 0.0624, 0.0760, 0.0711, 0.1095, 0.0707,
        0.0895, 0.0653, 0.0647, 0.0672, 0.0748], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,808][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.2414, 0.0043, 0.0053, 0.0039, 0.0171, 0.0095, 0.0046, 0.0249, 0.0891,
        0.0996, 0.0329, 0.0693, 0.3327, 0.0653], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,809][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0007, 0.1922, 0.1386, 0.1203, 0.0425, 0.0236, 0.0567, 0.0311, 0.0883,
        0.0415, 0.0808, 0.0946, 0.0452, 0.0439], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,809][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0314, 0.0600, 0.0444, 0.0608, 0.0658, 0.0450, 0.0561, 0.1032, 0.1157,
        0.1073, 0.0715, 0.1079, 0.0758, 0.0551], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,810][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0587, 0.0056, 0.0128, 0.0049, 0.0520, 0.0157, 0.0054, 0.0383, 0.0876,
        0.2101, 0.0598, 0.0846, 0.2620, 0.1026], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:56,810][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0099, 0.0316, 0.0455, 0.0244, 0.0793, 0.0361, 0.0495, 0.2731, 0.0446,
        0.1055, 0.0381, 0.0291, 0.0580, 0.0804, 0.0951], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,811][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0108, 0.0052, 0.0289, 0.0086, 0.2078, 0.0713, 0.0105, 0.4840, 0.0348,
        0.0193, 0.0074, 0.0023, 0.0096, 0.0390, 0.0604], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,813][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0482, 0.0571, 0.0188, 0.0589, 0.0478, 0.0344, 0.0249, 0.0245, 0.1156,
        0.0500, 0.1556, 0.0546, 0.0927, 0.1596, 0.0572], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,815][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0417, 0.0164, 0.0087, 0.0064, 0.0349, 0.0215, 0.0280, 0.2418, 0.0272,
        0.1612, 0.0448, 0.0278, 0.1355, 0.0771, 0.1271], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,816][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([9.7636e-01, 9.6229e-04, 1.5221e-03, 1.3846e-03, 1.6871e-03, 1.5526e-03,
        2.4550e-03, 2.2614e-03, 2.5698e-03, 1.3246e-03, 7.2828e-04, 2.0422e-03,
        8.6803e-04, 2.0191e-03, 2.2659e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,817][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0669, 0.0899, 0.0291, 0.0696, 0.0365, 0.0947, 0.0492, 0.1484, 0.0834,
        0.0444, 0.0445, 0.0313, 0.0440, 0.1478, 0.0203], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,819][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0126, 0.0649, 0.0827, 0.0667, 0.0776, 0.0750, 0.0727, 0.0601, 0.0780,
        0.0634, 0.0629, 0.0671, 0.0679, 0.0697, 0.0786], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,821][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0418, 0.0627, 0.0661, 0.0603, 0.0498, 0.0732, 0.0725, 0.1007, 0.0713,
        0.0797, 0.0647, 0.0656, 0.0615, 0.0738, 0.0563], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,822][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.7647, 0.0061, 0.0044, 0.0029, 0.0124, 0.0068, 0.0034, 0.0076, 0.0173,
        0.0117, 0.0028, 0.0081, 0.0740, 0.0176, 0.0603], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,824][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0082, 0.1551, 0.0562, 0.1196, 0.0268, 0.0385, 0.0380, 0.0212, 0.0837,
        0.0408, 0.0878, 0.0982, 0.0613, 0.0748, 0.0897], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,824][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0426, 0.0669, 0.0500, 0.0602, 0.0524, 0.0573, 0.0343, 0.0594, 0.0961,
        0.0756, 0.0631, 0.0676, 0.1135, 0.0858, 0.0751], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,825][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0779, 0.0231, 0.0223, 0.0077, 0.0697, 0.0252, 0.0103, 0.0243, 0.0563,
        0.0898, 0.0230, 0.0280, 0.1349, 0.0732, 0.3342], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:56,825][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0090, 0.0267, 0.0367, 0.0235, 0.0777, 0.0321, 0.0478, 0.2343, 0.0450,
        0.0919, 0.0398, 0.0295, 0.0589, 0.0706, 0.0978, 0.0787],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,826][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0064, 0.0095, 0.0356, 0.0151, 0.1734, 0.0697, 0.0136, 0.4413, 0.0388,
        0.0196, 0.0069, 0.0032, 0.0096, 0.0379, 0.0662, 0.0530],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,826][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0606, 0.0331, 0.0265, 0.0277, 0.0391, 0.0204, 0.0277, 0.0296, 0.0267,
        0.1208, 0.0698, 0.0551, 0.2263, 0.1125, 0.0854, 0.0388],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,826][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0353, 0.0109, 0.0098, 0.0071, 0.0377, 0.0196, 0.0313, 0.1809, 0.0308,
        0.1542, 0.0456, 0.0368, 0.1115, 0.0662, 0.1216, 0.1007],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,827][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.9687, 0.0011, 0.0015, 0.0012, 0.0021, 0.0014, 0.0021, 0.0031, 0.0028,
        0.0018, 0.0012, 0.0030, 0.0016, 0.0027, 0.0033, 0.0023],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,827][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.1265, 0.1071, 0.0343, 0.0709, 0.0231, 0.0566, 0.0419, 0.1626, 0.0700,
        0.0307, 0.0479, 0.0243, 0.0339, 0.1274, 0.0249, 0.0177],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,828][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0124, 0.0644, 0.0705, 0.0643, 0.0725, 0.0685, 0.0690, 0.0575, 0.0751,
        0.0596, 0.0627, 0.0654, 0.0638, 0.0637, 0.0617, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,830][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0369, 0.0585, 0.0611, 0.0569, 0.0514, 0.0659, 0.0644, 0.0898, 0.0650,
        0.0747, 0.0601, 0.0594, 0.0610, 0.0686, 0.0581, 0.0683],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,832][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.4915, 0.0169, 0.0102, 0.0058, 0.0205, 0.0132, 0.0067, 0.0055, 0.0175,
        0.0118, 0.0072, 0.0184, 0.1200, 0.0112, 0.1109, 0.1327],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,833][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0032, 0.1361, 0.0685, 0.0735, 0.0333, 0.0214, 0.0355, 0.0174, 0.0592,
        0.0425, 0.1121, 0.0914, 0.0943, 0.0573, 0.1174, 0.0370],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,835][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0503, 0.0624, 0.0424, 0.0682, 0.0415, 0.0316, 0.0459, 0.0627, 0.1134,
        0.0949, 0.0540, 0.0934, 0.0682, 0.0590, 0.0486, 0.0634],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,836][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.1113, 0.0166, 0.0213, 0.0062, 0.0599, 0.0155, 0.0088, 0.0068, 0.0215,
        0.0303, 0.0121, 0.0269, 0.0929, 0.0190, 0.2647, 0.2861],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:56,838][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0079, 0.0242, 0.0379, 0.0174, 0.0623, 0.0256, 0.0330, 0.3011, 0.0324,
        0.0875, 0.0248, 0.0148, 0.0414, 0.0663, 0.0755, 0.0577, 0.0901],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,839][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.4301e-04, 3.6499e-03, 3.1286e-02, 7.8269e-03, 1.2738e-01, 4.9483e-02,
        7.6472e-03, 6.2101e-01, 2.7632e-02, 1.7207e-02, 3.5534e-03, 1.4697e-03,
        6.8810e-03, 1.9514e-02, 4.5080e-02, 2.6634e-02, 3.2985e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,841][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0353, 0.0279, 0.0278, 0.0192, 0.0594, 0.0175, 0.0372, 0.0296, 0.0140,
        0.0856, 0.0474, 0.0906, 0.1839, 0.0809, 0.0970, 0.0505, 0.0962],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,841][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0403, 0.0118, 0.0066, 0.0032, 0.0231, 0.0097, 0.0116, 0.1993, 0.0147,
        0.1207, 0.0252, 0.0127, 0.0760, 0.0585, 0.0929, 0.0893, 0.2043],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,842][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9645, 0.0010, 0.0016, 0.0013, 0.0021, 0.0018, 0.0020, 0.0037, 0.0029,
        0.0019, 0.0011, 0.0028, 0.0014, 0.0034, 0.0031, 0.0025, 0.0029],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,842][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0923, 0.1018, 0.0427, 0.0506, 0.0455, 0.0684, 0.0430, 0.1299, 0.0530,
        0.0363, 0.0541, 0.0300, 0.0466, 0.1244, 0.0306, 0.0224, 0.0285],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,843][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0109, 0.0598, 0.0670, 0.0581, 0.0677, 0.0625, 0.0688, 0.0534, 0.0698,
        0.0520, 0.0581, 0.0625, 0.0585, 0.0608, 0.0604, 0.0589, 0.0707],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,843][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0266, 0.0548, 0.0596, 0.0529, 0.0504, 0.0612, 0.0572, 0.0878, 0.0588,
        0.0753, 0.0537, 0.0524, 0.0589, 0.0635, 0.0561, 0.0651, 0.0658],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,844][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3101, 0.0143, 0.0135, 0.0058, 0.0256, 0.0133, 0.0049, 0.0078, 0.0241,
        0.0168, 0.0073, 0.0143, 0.1472, 0.0190, 0.1395, 0.1943, 0.0421],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,844][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0027, 0.1552, 0.0693, 0.0928, 0.0246, 0.0188, 0.0200, 0.0376, 0.0660,
        0.0484, 0.0748, 0.0675, 0.0489, 0.0598, 0.0974, 0.0550, 0.0611],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,845][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0326, 0.0598, 0.0348, 0.0412, 0.0502, 0.0464, 0.0299, 0.0778, 0.0877,
        0.0854, 0.0539, 0.0684, 0.0914, 0.0581, 0.0466, 0.0912, 0.0449],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,846][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0338, 0.0146, 0.0168, 0.0053, 0.0537, 0.0164, 0.0062, 0.0096, 0.0218,
        0.0396, 0.0125, 0.0176, 0.1006, 0.0232, 0.2031, 0.3828, 0.0423],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:56,847][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0148, 0.0245, 0.0355, 0.0154, 0.0526, 0.0203, 0.0275, 0.2700, 0.0278,
        0.0744, 0.0206, 0.0108, 0.0319, 0.0588, 0.0588, 0.0457, 0.0704, 0.1402],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,849][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0412, 0.0067, 0.0286, 0.0101, 0.1578, 0.0499, 0.0080, 0.3870, 0.0418,
        0.0193, 0.0073, 0.0026, 0.0086, 0.0359, 0.0584, 0.0397, 0.0060, 0.0911],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,851][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.0557, 0.0369, 0.0277, 0.0496, 0.0207, 0.0274, 0.0270, 0.0360, 0.0819,
        0.0393, 0.0712, 0.0842, 0.1808, 0.0563, 0.0702, 0.0511, 0.0519, 0.0319],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,852][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0683, 0.0065, 0.0042, 0.0025, 0.0139, 0.0079, 0.0107, 0.1336, 0.0126,
        0.0745, 0.0181, 0.0086, 0.0439, 0.0414, 0.0539, 0.0502, 0.1193, 0.3298],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,854][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.9387, 0.0017, 0.0023, 0.0025, 0.0048, 0.0022, 0.0028, 0.0052, 0.0039,
        0.0029, 0.0018, 0.0038, 0.0023, 0.0051, 0.0049, 0.0039, 0.0046, 0.0065],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,856][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.0543, 0.1078, 0.0241, 0.0594, 0.0223, 0.0711, 0.0467, 0.1576, 0.0912,
        0.0248, 0.0412, 0.0215, 0.0288, 0.1589, 0.0151, 0.0262, 0.0266, 0.0224],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,857][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0111, 0.0578, 0.0652, 0.0586, 0.0664, 0.0605, 0.0611, 0.0500, 0.0628,
        0.0507, 0.0540, 0.0547, 0.0581, 0.0545, 0.0580, 0.0573, 0.0607, 0.0584],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,858][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0570, 0.0539, 0.0546, 0.0514, 0.0427, 0.0573, 0.0565, 0.0701, 0.0553,
        0.0576, 0.0529, 0.0520, 0.0462, 0.0581, 0.0454, 0.0564, 0.0630, 0.0697],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,859][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.5774, 0.0050, 0.0037, 0.0036, 0.0101, 0.0079, 0.0041, 0.0108, 0.0217,
        0.0122, 0.0030, 0.0059, 0.0471, 0.0204, 0.0493, 0.0797, 0.0264, 0.1117],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,859][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0058, 0.1229, 0.0967, 0.0809, 0.0213, 0.0191, 0.0337, 0.0270, 0.0519,
        0.0347, 0.0693, 0.0671, 0.0311, 0.0529, 0.1416, 0.0489, 0.0671, 0.0279],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,860][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0426, 0.0794, 0.0274, 0.0642, 0.0481, 0.0700, 0.0278, 0.0618, 0.1047,
        0.0477, 0.0439, 0.0604, 0.0655, 0.0768, 0.0359, 0.0639, 0.0449, 0.0350],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,860][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0401, 0.0089, 0.0085, 0.0033, 0.0283, 0.0138, 0.0049, 0.0144, 0.0217,
        0.0413, 0.0068, 0.0094, 0.0571, 0.0311, 0.1410, 0.2334, 0.0287, 0.3072],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:56,861][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0130, 0.0214, 0.0326, 0.0142, 0.0441, 0.0179, 0.0244, 0.2516, 0.0226,
        0.0638, 0.0146, 0.0080, 0.0268, 0.0557, 0.0485, 0.0322, 0.0567, 0.1276,
        0.1244], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,861][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0014, 0.0037, 0.0320, 0.0093, 0.1852, 0.0612, 0.0104, 0.4285, 0.0393,
        0.0217, 0.0051, 0.0018, 0.0066, 0.0279, 0.0504, 0.0285, 0.0051, 0.0706,
        0.0113], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,862][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0386, 0.0209, 0.0285, 0.0253, 0.0257, 0.0136, 0.0281, 0.0270, 0.0317,
        0.0685, 0.0773, 0.0410, 0.0849, 0.0710, 0.1000, 0.0486, 0.0701, 0.0757,
        0.1235], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,862][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0389, 0.0050, 0.0041, 0.0017, 0.0101, 0.0053, 0.0062, 0.1095, 0.0068,
        0.0549, 0.0101, 0.0044, 0.0314, 0.0343, 0.0414, 0.0366, 0.0898, 0.3266,
        0.1826], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,863][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7926e-01, 5.5714e-04, 9.5726e-04, 8.3911e-04, 1.2474e-03, 9.4169e-04,
        9.4271e-04, 1.9506e-03, 1.3215e-03, 8.7309e-04, 4.3996e-04, 1.2679e-03,
        6.1472e-04, 1.6429e-03, 1.5250e-03, 1.0403e-03, 1.2452e-03, 1.9987e-03,
        1.3305e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,865][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1482, 0.0855, 0.0299, 0.0513, 0.0262, 0.0608, 0.0479, 0.1356, 0.0495,
        0.0311, 0.0393, 0.0233, 0.0397, 0.1009, 0.0209, 0.0264, 0.0334, 0.0237,
        0.0264], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,866][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0111, 0.0553, 0.0589, 0.0553, 0.0639, 0.0553, 0.0561, 0.0441, 0.0611,
        0.0454, 0.0537, 0.0507, 0.0530, 0.0532, 0.0524, 0.0518, 0.0564, 0.0527,
        0.0697], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,868][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0375, 0.0494, 0.0528, 0.0479, 0.0442, 0.0532, 0.0506, 0.0674, 0.0504,
        0.0579, 0.0475, 0.0462, 0.0470, 0.0530, 0.0463, 0.0534, 0.0561, 0.0723,
        0.0669], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,869][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3336, 0.0073, 0.0074, 0.0039, 0.0173, 0.0107, 0.0051, 0.0149, 0.0235,
        0.0172, 0.0042, 0.0069, 0.0877, 0.0211, 0.0735, 0.1000, 0.0292, 0.2089,
        0.0275], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,871][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0060, 0.1344, 0.0932, 0.0571, 0.0236, 0.0174, 0.0253, 0.0190, 0.0426,
        0.0239, 0.0612, 0.0688, 0.0262, 0.0584, 0.1228, 0.0463, 0.0772, 0.0287,
        0.0679], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,873][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0334, 0.0500, 0.0381, 0.0392, 0.0424, 0.0399, 0.0315, 0.0976, 0.0617,
        0.0795, 0.0454, 0.0587, 0.0709, 0.0391, 0.0491, 0.0785, 0.0455, 0.0312,
        0.0682], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,874][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0315, 0.0077, 0.0120, 0.0035, 0.0397, 0.0115, 0.0052, 0.0131, 0.0167,
        0.0391, 0.0064, 0.0086, 0.0634, 0.0230, 0.1283, 0.1817, 0.0234, 0.3489,
        0.0363], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:56,876][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:56,877][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17726],
        [ 8386],
        [13538],
        [13507],
        [22036],
        [ 9367],
        [ 7837],
        [ 8967],
        [ 2772],
        [13383],
        [ 2217],
        [ 3821],
        [ 2442],
        [ 2551],
        [11165],
        [10551],
        [ 2918],
        [ 8288],
        [ 1294]], device='cuda:0')
[2024-07-24 10:18:56,878][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[18920],
        [ 5049],
        [ 9973],
        [ 9965],
        [24165],
        [ 5391],
        [ 5713],
        [10016],
        [ 1332],
        [ 8710],
        [  896],
        [ 2829],
        [ 1463],
        [ 1433],
        [ 9862],
        [10811],
        [ 2983],
        [ 9724],
        [ 1020]], device='cuda:0')
[2024-07-24 10:18:56,880][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40265],
        [42311],
        [42224],
        [42193],
        [42127],
        [42099],
        [41976],
        [41524],
        [41732],
        [41887],
        [41975],
        [42155],
        [42140],
        [42335],
        [42513],
        [42531],
        [42578],
        [42587],
        [42646]], device='cuda:0')
[2024-07-24 10:18:56,881][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19728],
        [ 9256],
        [21634],
        [18334],
        [23589],
        [20111],
        [21917],
        [16766],
        [18121],
        [18607],
        [16894],
        [17107],
        [16328],
        [16102],
        [18314],
        [18363],
        [18535],
        [18446],
        [19248]], device='cuda:0')
[2024-07-24 10:18:56,883][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6720],
        [ 6927],
        [ 7900],
        [ 9194],
        [10456],
        [10712],
        [10856],
        [13120],
        [12541],
        [13789],
        [14855],
        [13988],
        [14944],
        [15579],
        [15083],
        [15961],
        [15387],
        [15228],
        [16082]], device='cuda:0')
[2024-07-24 10:18:56,884][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[3341],
        [3729],
        [3925],
        [3898],
        [4147],
        [4510],
        [4630],
        [4409],
        [4321],
        [4160],
        [4137],
        [4110],
        [4126],
        [4085],
        [4060],
        [4027],
        [4020],
        [4022],
        [4046]], device='cuda:0')
[2024-07-24 10:18:56,886][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13442],
        [18522],
        [17616],
        [19925],
        [ 2295],
        [ 4933],
        [ 6006],
        [ 7713],
        [ 8682],
        [ 5810],
        [ 6432],
        [ 7171],
        [ 9196],
        [ 9025],
        [ 8552],
        [ 8338],
        [ 8909],
        [ 8473],
        [ 9385]], device='cuda:0')
[2024-07-24 10:18:56,888][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[32372],
        [32965],
        [33103],
        [33426],
        [34676],
        [35238],
        [35874],
        [35796],
        [35337],
        [35273],
        [34941],
        [34880],
        [34548],
        [34202],
        [33989],
        [33422],
        [33571],
        [33458],
        [33564]], device='cuda:0')
[2024-07-24 10:18:56,889][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[37680],
        [13425],
        [21652],
        [17885],
        [31593],
        [25654],
        [27966],
        [24814],
        [24668],
        [24641],
        [23474],
        [23557],
        [20235],
        [20887],
        [19621],
        [17832],
        [18259],
        [18099],
        [18168]], device='cuda:0')
[2024-07-24 10:18:56,891][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23708],
        [41554],
        [29290],
        [30814],
        [38273],
        [39337],
        [39229],
        [40508],
        [38948],
        [41090],
        [40537],
        [40570],
        [42633],
        [43545],
        [42911],
        [42826],
        [43100],
        [44568],
        [44559]], device='cuda:0')
[2024-07-24 10:18:56,893][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7013],
        [ 7268],
        [ 8177],
        [ 9235],
        [ 7528],
        [11729],
        [12553],
        [ 6156],
        [ 7240],
        [ 6448],
        [ 9191],
        [ 9835],
        [ 5839],
        [ 6379],
        [ 5281],
        [ 8096],
        [ 9588],
        [ 8210],
        [10272]], device='cuda:0')
[2024-07-24 10:18:56,895][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[38978],
        [42738],
        [46790],
        [47581],
        [47416],
        [47556],
        [45542],
        [42291],
        [46199],
        [43770],
        [47542],
        [44466],
        [43018],
        [44618],
        [46115],
        [44307],
        [43297],
        [44153],
        [44815]], device='cuda:0')
[2024-07-24 10:18:56,896][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24018],
        [39233],
        [39432],
        [39142],
        [38384],
        [37452],
        [36160],
        [35474],
        [34446],
        [32481],
        [32212],
        [31059],
        [29676],
        [28723],
        [28566],
        [27596],
        [26593],
        [25991],
        [25523]], device='cuda:0')
[2024-07-24 10:18:56,897][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35813],
        [21521],
        [23134],
        [26661],
        [26156],
        [27017],
        [27310],
        [26707],
        [26304],
        [25487],
        [25288],
        [24581],
        [24090],
        [23380],
        [22959],
        [22832],
        [22408],
        [22316],
        [21987]], device='cuda:0')
[2024-07-24 10:18:56,898][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[27601],
        [42981],
        [43889],
        [41689],
        [34180],
        [37855],
        [27941],
        [17756],
        [26656],
        [29831],
        [25722],
        [22353],
        [25584],
        [27925],
        [26013],
        [18742],
        [12762],
        [17277],
        [15343]], device='cuda:0')
[2024-07-24 10:18:56,899][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[40733],
        [39009],
        [34110],
        [34404],
        [29722],
        [28191],
        [28260],
        [33536],
        [33134],
        [32604],
        [32079],
        [33483],
        [33025],
        [33326],
        [33691],
        [33862],
        [34500],
        [35322],
        [34554]], device='cuda:0')
[2024-07-24 10:18:56,901][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[46980],
        [26497],
        [28835],
        [26268],
        [18445],
        [16567],
        [15842],
        [24952],
        [23015],
        [22256],
        [20856],
        [20997],
        [21827],
        [23042],
        [22393],
        [21439],
        [24061],
        [21398],
        [21288]], device='cuda:0')
[2024-07-24 10:18:56,902][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22891],
        [36938],
        [27147],
        [29170],
        [24858],
        [29601],
        [26172],
        [29581],
        [33822],
        [32659],
        [39023],
        [33628],
        [34024],
        [31910],
        [40593],
        [29525],
        [30309],
        [36639],
        [36090]], device='cuda:0')
[2024-07-24 10:18:56,904][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20915],
        [27441],
        [18324],
        [20198],
        [18430],
        [17584],
        [16408],
        [24540],
        [24045],
        [23555],
        [20834],
        [22021],
        [23450],
        [23813],
        [25262],
        [24122],
        [24060],
        [25704],
        [27746]], device='cuda:0')
[2024-07-24 10:18:56,906][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[41913],
        [41872],
        [41517],
        [41516],
        [40724],
        [38310],
        [37936],
        [36850],
        [40036],
        [37538],
        [39613],
        [40651],
        [40982],
        [39360],
        [41382],
        [41184],
        [41129],
        [40148],
        [41525]], device='cuda:0')
[2024-07-24 10:18:56,908][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[14369],
        [28627],
        [39195],
        [37795],
        [38479],
        [37049],
        [36824],
        [36572],
        [36731],
        [37177],
        [36692],
        [36489],
        [36331],
        [35933],
        [36796],
        [36887],
        [36108],
        [36765],
        [35257]], device='cuda:0')
[2024-07-24 10:18:56,909][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[44869],
        [44330],
        [43014],
        [44467],
        [43908],
        [45041],
        [45154],
        [45554],
        [45281],
        [45346],
        [45577],
        [45420],
        [45623],
        [45487],
        [45159],
        [45197],
        [45191],
        [45245],
        [45371]], device='cuda:0')
[2024-07-24 10:18:56,911][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[44034],
        [43197],
        [39482],
        [38828],
        [37901],
        [35721],
        [35253],
        [35508],
        [35289],
        [36071],
        [35855],
        [36156],
        [36340],
        [36351],
        [36249],
        [36067],
        [36243],
        [36503],
        [36519]], device='cuda:0')
[2024-07-24 10:18:56,913][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22605],
        [24000],
        [28893],
        [35287],
        [26380],
        [42154],
        [44986],
        [47078],
        [37262],
        [42491],
        [46483],
        [45441],
        [42418],
        [46556],
        [39273],
        [46536],
        [47710],
        [46138],
        [48031]], device='cuda:0')
[2024-07-24 10:18:56,914][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[43021],
        [35733],
        [35358],
        [35253],
        [34209],
        [33481],
        [32716],
        [29142],
        [31333],
        [29928],
        [30123],
        [30174],
        [29273],
        [29771],
        [30650],
        [30869],
        [30087],
        [30426],
        [29763]], device='cuda:0')
[2024-07-24 10:18:56,915][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[39194],
        [48666],
        [48613],
        [48694],
        [48633],
        [48317],
        [48213],
        [49024],
        [49482],
        [49450],
        [49547],
        [49448],
        [49372],
        [49509],
        [49435],
        [49311],
        [49301],
        [49358],
        [49431]], device='cuda:0')
[2024-07-24 10:18:56,916][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[16517],
        [ 5206],
        [ 4712],
        [ 4555],
        [11928],
        [13718],
        [16316],
        [18692],
        [13888],
        [13644],
        [13716],
        [12957],
        [16967],
        [19772],
        [13132],
        [10899],
        [12692],
        [15710],
        [16842]], device='cuda:0')
[2024-07-24 10:18:56,917][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[6656],
        [4972],
        [5967],
        [4908],
        [7059],
        [6070],
        [5890],
        [4388],
        [5285],
        [5867],
        [4577],
        [5019],
        [4688],
        [4176],
        [4585],
        [4787],
        [4211],
        [4042],
        [3749]], device='cuda:0')
[2024-07-24 10:18:56,919][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[1391],
        [1291],
        [1178],
        [1616],
        [3234],
        [2951],
        [5872],
        [1640],
        [2075],
        [1481],
        [1855],
        [2783],
        [1988],
        [1918],
        [1860],
        [4035],
        [5439],
        [3107],
        [4277]], device='cuda:0')
[2024-07-24 10:18:56,921][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403],
        [19403]], device='cuda:0')
[2024-07-24 10:18:56,967][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:56,968][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,968][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,969][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,970][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,972][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,973][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,974][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,975][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,976][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,977][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,979][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,980][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:56,981][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8750, 0.1250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,982][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4529, 0.5471], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,982][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,982][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4661, 0.5339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,983][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8715, 0.1285], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,983][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,983][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0611, 0.9389], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,984][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1766, 0.8234], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,984][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7532, 0.2468], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,984][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9882, 0.0118], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,985][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.5646e-04, 9.9934e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,985][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1432, 0.8568], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:56,985][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0510, 0.0503, 0.8987], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,986][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0036, 0.9229, 0.0734], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,988][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0010, 0.8577, 0.1413], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,989][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.2931, 0.3473, 0.3596], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,991][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.8956, 0.0175, 0.0868], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,992][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.9422, 0.0252, 0.0326], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,994][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0279, 0.3634, 0.6087], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,996][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0178, 0.5994, 0.3827], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,997][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.4320, 0.1146, 0.4534], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:56,999][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.9857, 0.0061, 0.0082], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,001][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0014, 0.4724, 0.5262], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,002][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0810, 0.4559, 0.4631], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,004][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0386, 0.0061, 0.9516, 0.0037], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,005][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0234, 0.3020, 0.1013, 0.5732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,005][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0010, 0.6521, 0.1246, 0.2223], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,005][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2242, 0.2731, 0.2761, 0.2266], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,006][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7488, 0.0266, 0.1299, 0.0947], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,006][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9270, 0.0212, 0.0275, 0.0243], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,006][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0164, 0.2009, 0.4573, 0.3254], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,007][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0242, 0.3951, 0.2977, 0.2830], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,007][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2821, 0.1231, 0.5331, 0.0617], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,007][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9714, 0.0089, 0.0143, 0.0054], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,008][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.3757e-04, 3.7875e-01, 5.3714e-01, 8.3876e-02], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,008][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0480, 0.1929, 0.5579, 0.2012], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,008][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.0395, 0.0339, 0.5184, 0.3125, 0.0958], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,009][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0195, 0.3767, 0.0529, 0.2436, 0.3074], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,011][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.0023, 0.4852, 0.1099, 0.1667, 0.2358], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,013][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.1799, 0.2030, 0.2088, 0.1712, 0.2371], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,014][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.8352, 0.0054, 0.0279, 0.0204, 0.1112], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,015][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.9085, 0.0136, 0.0183, 0.0199, 0.0397], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,017][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0585, 0.2303, 0.3114, 0.2421, 0.1577], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,019][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.0753, 0.2124, 0.2732, 0.1573, 0.2817], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,020][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.4008, 0.0355, 0.1158, 0.0265, 0.4214], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,022][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.9792, 0.0043, 0.0059, 0.0023, 0.0083], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,022][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.0013, 0.1978, 0.3176, 0.0508, 0.4325], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,023][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0515, 0.1936, 0.1347, 0.3699, 0.2503], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,023][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0133, 0.0035, 0.3863, 0.0200, 0.5720, 0.0050], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,023][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0193, 0.4966, 0.0435, 0.2284, 0.1576, 0.0545], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,024][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0012, 0.4007, 0.0788, 0.1350, 0.1973, 0.1869], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,024][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1500, 0.1715, 0.1699, 0.1424, 0.1932, 0.1729], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,024][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4939, 0.0033, 0.0317, 0.0202, 0.1155, 0.3354], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,025][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.8210, 0.0186, 0.0412, 0.0246, 0.0557, 0.0389], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,025][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0134, 0.1424, 0.2765, 0.2217, 0.1234, 0.2227], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,025][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0152, 0.2322, 0.2087, 0.1229, 0.2021, 0.2189], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,026][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0548, 0.0473, 0.1869, 0.0218, 0.6244, 0.0648], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,028][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9522, 0.0078, 0.0114, 0.0040, 0.0166, 0.0080], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,029][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([2.1732e-04, 2.2527e-01, 1.7724e-01, 1.0214e-01, 4.0576e-01, 8.9362e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,030][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0186, 0.0983, 0.1529, 0.1198, 0.1967, 0.4137], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,032][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0091, 0.0064, 0.4590, 0.0339, 0.4697, 0.0167, 0.0054],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,033][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0098, 0.3257, 0.0288, 0.2042, 0.2208, 0.0676, 0.1432],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,035][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0005, 0.3481, 0.0644, 0.1214, 0.1819, 0.1700, 0.1137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,036][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1219, 0.1533, 0.1489, 0.1250, 0.1699, 0.1512, 0.1298],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,038][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6099, 0.0014, 0.0140, 0.0102, 0.0519, 0.2633, 0.0493],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,039][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7374, 0.0262, 0.0456, 0.0277, 0.0778, 0.0659, 0.0195],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,040][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0146, 0.1100, 0.2474, 0.1847, 0.1136, 0.1414, 0.1883],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,040][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0076, 0.2134, 0.1334, 0.0930, 0.1855, 0.2148, 0.1524],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,040][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0561, 0.0375, 0.1685, 0.0190, 0.5894, 0.0960, 0.0335],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,041][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.9640, 0.0058, 0.0082, 0.0027, 0.0114, 0.0056, 0.0023],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,041][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0004, 0.1312, 0.1079, 0.0494, 0.3723, 0.0916, 0.2472],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,042][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0258, 0.0833, 0.1269, 0.1091, 0.1798, 0.3147, 0.1604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,042][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0054, 0.0067, 0.3601, 0.0698, 0.4225, 0.0302, 0.0873, 0.0181],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,042][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0208, 0.2002, 0.0235, 0.0907, 0.1278, 0.0338, 0.0911, 0.4120],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,043][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0010, 0.3046, 0.0522, 0.0912, 0.1177, 0.1270, 0.1003, 0.2060],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,043][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1134, 0.1244, 0.1249, 0.1050, 0.1434, 0.1284, 0.1061, 0.1543],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,044][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([5.3847e-01, 4.0051e-04, 3.4664e-03, 1.5573e-03, 1.8124e-02, 4.6244e-02,
        9.5441e-03, 3.8220e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,045][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.4637, 0.0363, 0.0798, 0.0456, 0.1381, 0.1024, 0.0277, 0.1063],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,047][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0035, 0.0558, 0.0941, 0.1163, 0.0711, 0.1119, 0.1473, 0.3999],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,049][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0127, 0.1389, 0.1106, 0.0711, 0.1184, 0.1661, 0.1558, 0.2265],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,050][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0890, 0.0098, 0.0669, 0.0093, 0.3876, 0.0792, 0.0178, 0.3404],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,052][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.9666, 0.0053, 0.0068, 0.0021, 0.0073, 0.0038, 0.0014, 0.0067],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,053][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([7.6313e-05, 1.3768e-01, 1.1310e-01, 2.5280e-02, 2.8988e-01, 3.9401e-02,
        2.4824e-01, 1.4635e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,054][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0127, 0.0699, 0.1255, 0.0712, 0.1335, 0.2783, 0.1760, 0.1329],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,056][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0511, 0.0036, 0.2751, 0.0128, 0.5894, 0.0086, 0.0135, 0.0353, 0.0106],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,057][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0496, 0.0991, 0.0360, 0.1440, 0.0971, 0.0343, 0.0718, 0.3192, 0.1490],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,057][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0009, 0.2090, 0.0486, 0.0816, 0.1066, 0.1055, 0.0841, 0.1725, 0.1912],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,058][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0991, 0.1162, 0.1134, 0.0947, 0.1272, 0.1114, 0.0961, 0.1261, 0.1157],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,058][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([9.2631e-01, 1.1202e-04, 8.3865e-04, 7.1246e-04, 2.9874e-03, 1.1044e-02,
        2.6175e-03, 1.6020e-02, 3.9358e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,058][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.7073, 0.0176, 0.0346, 0.0218, 0.0729, 0.0476, 0.0180, 0.0446, 0.0356],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,059][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0068, 0.0519, 0.1000, 0.0723, 0.0532, 0.0623, 0.0805, 0.3799, 0.1931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,059][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0251, 0.1122, 0.0974, 0.0663, 0.0863, 0.1442, 0.1291, 0.2013, 0.1381],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,060][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.3528, 0.0231, 0.1056, 0.0156, 0.2516, 0.0647, 0.0279, 0.0584, 0.1003],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,060][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.9327, 0.0071, 0.0107, 0.0042, 0.0154, 0.0084, 0.0037, 0.0110, 0.0068],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,060][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([6.3441e-05, 9.9480e-02, 1.4438e-01, 2.4294e-02, 2.1166e-01, 2.1307e-02,
        1.4956e-01, 1.2390e-01, 2.2536e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,061][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0276, 0.0475, 0.0887, 0.0476, 0.0757, 0.2280, 0.1613, 0.0805, 0.2431],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,063][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0143, 0.0053, 0.1646, 0.0609, 0.0958, 0.0067, 0.0365, 0.0215, 0.5142,
        0.0802], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,065][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0234, 0.0891, 0.0258, 0.0503, 0.0801, 0.0238, 0.0434, 0.3502, 0.1180,
        0.1959], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,066][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0007, 0.1908, 0.0384, 0.0686, 0.0854, 0.1001, 0.0755, 0.1494, 0.1868,
        0.1044], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,067][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0982, 0.0984, 0.0979, 0.0809, 0.1097, 0.0966, 0.0820, 0.1135, 0.1034,
        0.1193], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,068][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.3474, 0.0005, 0.0027, 0.0022, 0.0138, 0.0654, 0.0144, 0.2442, 0.3008,
        0.0086], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,070][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.4578, 0.0250, 0.0472, 0.0286, 0.0997, 0.0744, 0.0242, 0.0674, 0.0665,
        0.1091], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,072][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0045, 0.0335, 0.0599, 0.0621, 0.0428, 0.0518, 0.0677, 0.2849, 0.1340,
        0.2588], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,073][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0050, 0.1054, 0.0846, 0.0511, 0.1014, 0.1148, 0.1013, 0.1720, 0.1535,
        0.1109], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,074][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2697, 0.0125, 0.0447, 0.0085, 0.1512, 0.0456, 0.0147, 0.0457, 0.1588,
        0.2486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,075][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.9422, 0.0054, 0.0077, 0.0028, 0.0112, 0.0065, 0.0025, 0.0084, 0.0052,
        0.0080], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,075][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([1.3715e-04, 1.0133e-01, 1.7905e-01, 2.3499e-02, 1.4906e-01, 1.7571e-02,
        1.6467e-01, 1.0112e-01, 2.2693e-01, 3.6624e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,076][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0068, 0.0390, 0.0710, 0.0413, 0.0790, 0.2041, 0.1219, 0.0633, 0.2002,
        0.1735], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,076][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0496, 0.0022, 0.2844, 0.0095, 0.3808, 0.0131, 0.0127, 0.0129, 0.0090,
        0.2209, 0.0049], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,076][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0755, 0.0596, 0.0166, 0.0532, 0.0615, 0.0196, 0.0467, 0.3231, 0.1115,
        0.1754, 0.0571], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,077][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0012, 0.1563, 0.0411, 0.0633, 0.0834, 0.0840, 0.0654, 0.1377, 0.1429,
        0.0851, 0.1396], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,077][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0812, 0.0923, 0.0888, 0.0742, 0.0995, 0.0885, 0.0774, 0.1037, 0.0929,
        0.1100, 0.0915], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,078][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([6.3663e-01, 5.9579e-04, 5.5027e-03, 3.7230e-03, 1.6705e-02, 6.2265e-02,
        1.4827e-02, 9.1303e-02, 1.1836e-01, 6.3395e-03, 4.3750e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,078][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.5627, 0.0195, 0.0360, 0.0219, 0.0702, 0.0586, 0.0192, 0.0559, 0.0505,
        0.0772, 0.0283], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,079][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0073, 0.0367, 0.0778, 0.0542, 0.0358, 0.0427, 0.0590, 0.2615, 0.1182,
        0.2295, 0.0772], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,080][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0158, 0.0895, 0.0700, 0.0472, 0.0884, 0.1121, 0.0876, 0.1611, 0.1205,
        0.1029, 0.1048], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,082][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2003, 0.0349, 0.0897, 0.0118, 0.2128, 0.0637, 0.0296, 0.0420, 0.0841,
        0.1787, 0.0524], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,084][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.9250, 0.0059, 0.0097, 0.0035, 0.0166, 0.0079, 0.0035, 0.0099, 0.0059,
        0.0091, 0.0028], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,085][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0003, 0.1005, 0.1289, 0.0269, 0.1995, 0.0206, 0.0937, 0.0846, 0.2300,
        0.0695, 0.0456], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,087][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0275, 0.0224, 0.0501, 0.0330, 0.0523, 0.2259, 0.0894, 0.0381, 0.1465,
        0.1014, 0.2134], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,089][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0497, 0.0064, 0.1631, 0.0111, 0.3340, 0.0114, 0.0039, 0.0121, 0.0366,
        0.2771, 0.0790, 0.0156], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,090][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0368, 0.0904, 0.0212, 0.0670, 0.0798, 0.0243, 0.0513, 0.2902, 0.1065,
        0.1359, 0.0653, 0.0313], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,092][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0003, 0.1405, 0.0313, 0.0553, 0.0811, 0.0763, 0.0541, 0.1284, 0.1317,
        0.0828, 0.1479, 0.0702], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,092][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0739, 0.0868, 0.0826, 0.0681, 0.0928, 0.0827, 0.0719, 0.0900, 0.0829,
        0.0954, 0.0841, 0.0887], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,093][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([7.3377e-01, 6.2589e-04, 4.7018e-03, 3.4707e-03, 1.1862e-02, 6.0291e-02,
        1.4920e-02, 5.1704e-02, 6.7242e-02, 3.9117e-03, 3.5131e-02, 1.2370e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,093][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7722, 0.0125, 0.0233, 0.0133, 0.0339, 0.0247, 0.0083, 0.0251, 0.0223,
        0.0372, 0.0151, 0.0120], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,093][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0066, 0.0345, 0.0712, 0.0516, 0.0330, 0.0325, 0.0491, 0.2036, 0.1077,
        0.1783, 0.0693, 0.1626], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,094][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0032, 0.0795, 0.0507, 0.0363, 0.0641, 0.0910, 0.0794, 0.1789, 0.1222,
        0.1106, 0.1239, 0.0602], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,094][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2488, 0.0393, 0.1002, 0.0129, 0.2721, 0.0576, 0.0211, 0.0189, 0.0485,
        0.0771, 0.0446, 0.0590], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,095][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.9245, 0.0058, 0.0084, 0.0035, 0.0154, 0.0083, 0.0039, 0.0095, 0.0061,
        0.0088, 0.0031, 0.0027], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,095][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0004, 0.0649, 0.0846, 0.0218, 0.1283, 0.0187, 0.0811, 0.1081, 0.2537,
        0.0902, 0.0763, 0.0719], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,096][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0253, 0.0210, 0.0315, 0.0308, 0.0406, 0.1209, 0.0479, 0.0404, 0.1224,
        0.0837, 0.1664, 0.2690], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,097][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0188, 0.0038, 0.1989, 0.0215, 0.0941, 0.0056, 0.0241, 0.0100, 0.0677,
        0.2113, 0.1428, 0.1069, 0.0946], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,099][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0405, 0.1337, 0.0155, 0.0693, 0.0625, 0.0201, 0.0476, 0.1629, 0.0919,
        0.1040, 0.0762, 0.0338, 0.1421], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,100][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0005, 0.1419, 0.0270, 0.0499, 0.0604, 0.0751, 0.0560, 0.1114, 0.1362,
        0.0818, 0.1310, 0.0705, 0.0584], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,102][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0778, 0.0779, 0.0748, 0.0609, 0.0822, 0.0733, 0.0617, 0.0824, 0.0743,
        0.0841, 0.0709, 0.0739, 0.1059], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,103][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.4471, 0.0009, 0.0040, 0.0032, 0.0129, 0.0664, 0.0182, 0.1831, 0.1697,
        0.0077, 0.0379, 0.0138, 0.0351], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,104][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.7937, 0.0072, 0.0145, 0.0094, 0.0315, 0.0194, 0.0092, 0.0194, 0.0195,
        0.0313, 0.0109, 0.0072, 0.0269], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,106][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0043, 0.0262, 0.0518, 0.0436, 0.0313, 0.0299, 0.0439, 0.1635, 0.0891,
        0.1541, 0.0699, 0.1310, 0.1613], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,108][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0029, 0.0696, 0.0610, 0.0389, 0.0664, 0.0841, 0.0841, 0.1293, 0.1146,
        0.0779, 0.1004, 0.0625, 0.1083], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,109][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2944, 0.0183, 0.0324, 0.0082, 0.1031, 0.0263, 0.0129, 0.0135, 0.0659,
        0.0598, 0.0302, 0.0476, 0.2873], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,110][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.9147, 0.0060, 0.0088, 0.0036, 0.0135, 0.0080, 0.0036, 0.0098, 0.0064,
        0.0092, 0.0030, 0.0027, 0.0108], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,110][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0005, 0.0289, 0.0748, 0.0158, 0.1404, 0.0143, 0.1725, 0.1303, 0.1987,
        0.0456, 0.0649, 0.0597, 0.0538], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,111][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0072, 0.0164, 0.0317, 0.0159, 0.0333, 0.0579, 0.0424, 0.0312, 0.0989,
        0.0977, 0.1903, 0.2294, 0.1478], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,111][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0086, 0.0004, 0.1225, 0.0013, 0.1194, 0.0036, 0.0062, 0.0117, 0.0116,
        0.2631, 0.0248, 0.0367, 0.3890, 0.0011], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,112][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0465, 0.0520, 0.0234, 0.0518, 0.0964, 0.0198, 0.0305, 0.2187, 0.0501,
        0.0739, 0.0397, 0.0167, 0.0884, 0.1922], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,112][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0002, 0.1243, 0.0223, 0.0449, 0.0612, 0.0667, 0.0495, 0.1179, 0.1276,
        0.0738, 0.1301, 0.0613, 0.0561, 0.0641], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,112][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0622, 0.0688, 0.0681, 0.0561, 0.0756, 0.0663, 0.0569, 0.0773, 0.0711,
        0.0824, 0.0700, 0.0721, 0.0998, 0.0734], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,113][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([7.1795e-01, 1.2717e-04, 9.9104e-04, 6.5625e-04, 3.6055e-03, 1.3903e-02,
        2.8943e-03, 4.4502e-02, 8.4742e-02, 2.6322e-03, 2.9462e-02, 1.4093e-02,
        9.8252e-03, 7.4619e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,113][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.5959, 0.0138, 0.0252, 0.0138, 0.0503, 0.0312, 0.0114, 0.0354, 0.0284,
        0.0583, 0.0200, 0.0169, 0.0555, 0.0439], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,115][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0033, 0.0227, 0.0483, 0.0325, 0.0189, 0.0232, 0.0313, 0.1425, 0.0685,
        0.1202, 0.0432, 0.1126, 0.1285, 0.2044], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,117][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0018, 0.0680, 0.0412, 0.0275, 0.0468, 0.0643, 0.0610, 0.1507, 0.0927,
        0.0700, 0.0821, 0.0449, 0.0886, 0.1604], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,119][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0838, 0.0054, 0.0199, 0.0031, 0.0797, 0.0161, 0.0053, 0.0335, 0.0603,
        0.1553, 0.0418, 0.0567, 0.3892, 0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,120][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.9403, 0.0051, 0.0073, 0.0023, 0.0090, 0.0043, 0.0018, 0.0065, 0.0037,
        0.0061, 0.0017, 0.0015, 0.0065, 0.0039], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,121][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.2076e-05, 5.8606e-02, 8.9174e-02, 1.4288e-02, 1.2298e-01, 1.3225e-02,
        8.5089e-02, 7.7204e-02, 1.9150e-01, 3.8523e-02, 5.4240e-02, 5.1355e-02,
        6.2560e-02, 1.4123e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,123][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0027, 0.0109, 0.0175, 0.0147, 0.0189, 0.0700, 0.0362, 0.0183, 0.0724,
        0.0527, 0.1739, 0.2902, 0.1471, 0.0746], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,125][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0133, 0.0027, 0.0314, 0.0119, 0.0614, 0.0052, 0.0070, 0.0031, 0.0220,
        0.0698, 0.0440, 0.0383, 0.1074, 0.0119, 0.5707], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,126][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0098, 0.1445, 0.0111, 0.0322, 0.0758, 0.0156, 0.0220, 0.1568, 0.0456,
        0.0826, 0.0592, 0.0132, 0.0849, 0.1739, 0.0728], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,127][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0002, 0.1288, 0.0221, 0.0448, 0.0600, 0.0669, 0.0465, 0.1060, 0.1208,
        0.0735, 0.1204, 0.0633, 0.0522, 0.0640, 0.0305], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,127][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0631, 0.0635, 0.0618, 0.0505, 0.0700, 0.0605, 0.0520, 0.0719, 0.0637,
        0.0735, 0.0615, 0.0633, 0.0910, 0.0680, 0.0858], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,128][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([6.5891e-01, 6.5614e-04, 3.0355e-03, 2.1116e-03, 1.0303e-02, 3.3643e-02,
        9.6437e-03, 8.1851e-02, 7.6820e-02, 3.9167e-03, 2.1970e-02, 9.3758e-03,
        1.7752e-02, 5.9012e-02, 1.1001e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,128][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.8923, 0.0035, 0.0054, 0.0037, 0.0139, 0.0094, 0.0030, 0.0091, 0.0087,
        0.0125, 0.0037, 0.0035, 0.0104, 0.0113, 0.0096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,128][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0117, 0.0341, 0.0602, 0.0362, 0.0271, 0.0232, 0.0303, 0.1066, 0.0635,
        0.0995, 0.0430, 0.0827, 0.1039, 0.1568, 0.1212], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,129][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0014, 0.0791, 0.0392, 0.0343, 0.0631, 0.0633, 0.0550, 0.1286, 0.1060,
        0.0588, 0.0772, 0.0347, 0.0907, 0.1252, 0.0433], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,129][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.3018, 0.0101, 0.0161, 0.0042, 0.0653, 0.0118, 0.0078, 0.0150, 0.0325,
        0.0342, 0.0120, 0.0232, 0.1351, 0.0296, 0.3013], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,130][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.9219, 0.0048, 0.0065, 0.0026, 0.0105, 0.0062, 0.0026, 0.0082, 0.0050,
        0.0074, 0.0022, 0.0018, 0.0083, 0.0050, 0.0070], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,130][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0003, 0.0526, 0.0314, 0.0086, 0.0553, 0.0223, 0.0862, 0.1644, 0.1587,
        0.0427, 0.0634, 0.0502, 0.1099, 0.0812, 0.0729], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,131][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0034, 0.0133, 0.0136, 0.0162, 0.0150, 0.0713, 0.0660, 0.0205, 0.0726,
        0.0563, 0.1507, 0.2223, 0.0969, 0.0642, 0.1177], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,132][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([5.4856e-03, 4.2024e-04, 3.5955e-02, 3.6306e-03, 2.2680e-02, 8.7735e-04,
        1.3243e-03, 1.4218e-03, 4.8348e-03, 2.2302e-02, 1.0906e-02, 1.1976e-02,
        8.5673e-02, 1.7825e-03, 7.8514e-01, 5.5913e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,134][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0335, 0.1013, 0.0137, 0.0353, 0.0380, 0.0087, 0.0213, 0.1679, 0.0561,
        0.0971, 0.0697, 0.0175, 0.0825, 0.1488, 0.0806, 0.0280],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,136][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0005, 0.1318, 0.0251, 0.0457, 0.0557, 0.0606, 0.0470, 0.0877, 0.1087,
        0.0651, 0.1089, 0.0588, 0.0544, 0.0621, 0.0307, 0.0573],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,137][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0599, 0.0595, 0.0568, 0.0466, 0.0639, 0.0558, 0.0489, 0.0625, 0.0579,
        0.0670, 0.0575, 0.0595, 0.0853, 0.0604, 0.0792, 0.0793],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,139][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([8.3116e-01, 1.8116e-04, 1.1108e-03, 8.2992e-04, 3.3287e-03, 1.1302e-02,
        3.0855e-03, 1.4301e-02, 2.1457e-02, 8.8672e-04, 6.6039e-03, 4.1531e-03,
        9.4820e-03, 1.5039e-02, 6.7194e-03, 7.0357e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,140][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.8366, 0.0045, 0.0083, 0.0053, 0.0135, 0.0073, 0.0035, 0.0109, 0.0107,
        0.0156, 0.0064, 0.0056, 0.0198, 0.0135, 0.0247, 0.0137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,142][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0055, 0.0344, 0.0489, 0.0366, 0.0190, 0.0225, 0.0299, 0.1385, 0.0575,
        0.1075, 0.0376, 0.0798, 0.0954, 0.1460, 0.0830, 0.0579],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,143][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0063, 0.0467, 0.0344, 0.0276, 0.0412, 0.0501, 0.0540, 0.0834, 0.0877,
        0.0588, 0.0809, 0.0550, 0.0943, 0.1479, 0.0562, 0.0754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,144][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1618, 0.0068, 0.0115, 0.0023, 0.0482, 0.0065, 0.0037, 0.0031, 0.0128,
        0.0132, 0.0074, 0.0133, 0.1034, 0.0074, 0.2745, 0.3240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,144][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.9111, 0.0048, 0.0070, 0.0028, 0.0118, 0.0059, 0.0028, 0.0068, 0.0049,
        0.0071, 0.0023, 0.0022, 0.0095, 0.0049, 0.0083, 0.0079],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,145][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0004, 0.0360, 0.0284, 0.0137, 0.0703, 0.0115, 0.0698, 0.0328, 0.1750,
        0.0650, 0.0850, 0.1003, 0.1154, 0.0877, 0.0877, 0.0210],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,145][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0045, 0.0114, 0.0202, 0.0125, 0.0163, 0.0435, 0.0259, 0.0182, 0.0467,
        0.0428, 0.1293, 0.1603, 0.1210, 0.0722, 0.0923, 0.1828],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,146][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([4.1674e-03, 8.8182e-04, 2.9870e-02, 2.7137e-03, 4.5320e-02, 1.3371e-03,
        4.2670e-04, 1.9205e-03, 3.9340e-03, 3.1079e-02, 8.0352e-03, 6.5492e-03,
        2.1520e-01, 2.1714e-03, 6.0649e-01, 3.6427e-02, 3.4683e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,146][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0243, 0.0535, 0.0067, 0.0289, 0.0262, 0.0091, 0.0206, 0.1455, 0.0581,
        0.0832, 0.0395, 0.0168, 0.0805, 0.1937, 0.1162, 0.0300, 0.0674],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,147][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.1174, 0.0216, 0.0429, 0.0575, 0.0593, 0.0409, 0.0961, 0.1118,
        0.0597, 0.1048, 0.0532, 0.0471, 0.0556, 0.0270, 0.0582, 0.0467],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,147][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0478, 0.0567, 0.0537, 0.0439, 0.0610, 0.0531, 0.0465, 0.0610, 0.0543,
        0.0641, 0.0548, 0.0570, 0.0819, 0.0581, 0.0737, 0.0747, 0.0577],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,148][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([8.1753e-01, 1.1036e-04, 9.2724e-04, 6.3965e-04, 2.6567e-03, 1.0196e-02,
        2.3420e-03, 1.3173e-02, 1.8684e-02, 8.1751e-04, 6.3543e-03, 2.9725e-03,
        6.6180e-03, 1.2646e-02, 4.4857e-03, 7.5886e-02, 2.3958e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,149][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.8148, 0.0048, 0.0096, 0.0050, 0.0160, 0.0096, 0.0037, 0.0116, 0.0097,
        0.0184, 0.0054, 0.0059, 0.0158, 0.0178, 0.0248, 0.0195, 0.0076],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,151][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0053, 0.0224, 0.0426, 0.0298, 0.0163, 0.0168, 0.0257, 0.1207, 0.0525,
        0.0959, 0.0325, 0.0813, 0.0858, 0.1361, 0.1048, 0.0649, 0.0666],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,153][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0065, 0.0595, 0.0324, 0.0252, 0.0436, 0.0525, 0.0354, 0.0965, 0.0761,
        0.0506, 0.0754, 0.0447, 0.0786, 0.1355, 0.0511, 0.0895, 0.0470],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,154][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0908, 0.0060, 0.0147, 0.0020, 0.0469, 0.0088, 0.0039, 0.0057, 0.0100,
        0.0172, 0.0056, 0.0095, 0.0968, 0.0087, 0.2073, 0.4369, 0.0294],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,156][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.9210, 0.0045, 0.0062, 0.0024, 0.0102, 0.0052, 0.0022, 0.0070, 0.0042,
        0.0062, 0.0019, 0.0017, 0.0077, 0.0041, 0.0065, 0.0067, 0.0024],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,158][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0003, 0.0197, 0.0131, 0.0062, 0.0322, 0.0088, 0.0323, 0.1619, 0.1136,
        0.0734, 0.0672, 0.0554, 0.0968, 0.1235, 0.0509, 0.0235, 0.1212],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,159][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0063, 0.0094, 0.0159, 0.0101, 0.0180, 0.0491, 0.0214, 0.0168, 0.0414,
        0.0331, 0.0676, 0.1257, 0.1021, 0.0561, 0.0961, 0.2247, 0.1061],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,161][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0175, 0.0017, 0.0232, 0.0122, 0.0463, 0.0041, 0.0046, 0.0027, 0.0166,
        0.0287, 0.0366, 0.0224, 0.0383, 0.0163, 0.4457, 0.0539, 0.0299, 0.1992],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,161][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0190, 0.0738, 0.0121, 0.0329, 0.0371, 0.0137, 0.0242, 0.1307, 0.0389,
        0.0726, 0.0474, 0.0184, 0.0839, 0.1314, 0.0747, 0.0261, 0.0680, 0.0950],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,162][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0003, 0.1312, 0.0225, 0.0465, 0.0537, 0.0643, 0.0439, 0.0859, 0.1083,
        0.0575, 0.0939, 0.0503, 0.0418, 0.0538, 0.0241, 0.0511, 0.0426, 0.0280],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,162][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0475, 0.0530, 0.0499, 0.0424, 0.0559, 0.0512, 0.0445, 0.0595, 0.0520,
        0.0598, 0.0500, 0.0515, 0.0725, 0.0564, 0.0662, 0.0677, 0.0531, 0.0668],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,163][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.4777, 0.0007, 0.0022, 0.0020, 0.0074, 0.0323, 0.0097, 0.1269, 0.0913,
        0.0032, 0.0142, 0.0055, 0.0109, 0.0681, 0.0076, 0.0811, 0.0417, 0.0174],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,163][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.7758, 0.0047, 0.0072, 0.0054, 0.0167, 0.0101, 0.0050, 0.0145, 0.0121,
        0.0186, 0.0053, 0.0056, 0.0182, 0.0173, 0.0191, 0.0185, 0.0088, 0.0371],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,164][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0040, 0.0182, 0.0353, 0.0265, 0.0184, 0.0164, 0.0244, 0.0822, 0.0514,
        0.0751, 0.0371, 0.0706, 0.0776, 0.1385, 0.0802, 0.0556, 0.0637, 0.1245],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,164][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0021, 0.0630, 0.0355, 0.0320, 0.0395, 0.0507, 0.0512, 0.0937, 0.0856,
        0.0451, 0.0641, 0.0299, 0.0612, 0.1343, 0.0341, 0.0623, 0.0507, 0.0650],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,165][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.1647, 0.0073, 0.0113, 0.0025, 0.0356, 0.0069, 0.0039, 0.0078, 0.0167,
        0.0174, 0.0044, 0.0074, 0.0508, 0.0191, 0.1587, 0.1569, 0.0217, 0.3069],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,165][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.9099, 0.0044, 0.0062, 0.0024, 0.0093, 0.0053, 0.0024, 0.0075, 0.0043,
        0.0065, 0.0019, 0.0017, 0.0073, 0.0048, 0.0065, 0.0064, 0.0026, 0.0107],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,167][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0004, 0.0309, 0.0438, 0.0087, 0.0426, 0.0083, 0.0486, 0.1188, 0.1001,
        0.0592, 0.0583, 0.0498, 0.0429, 0.1264, 0.1074, 0.0193, 0.1064, 0.0282],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,169][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0014, 0.0048, 0.0094, 0.0052, 0.0143, 0.0379, 0.0160, 0.0167, 0.0317,
        0.0278, 0.1225, 0.1333, 0.0881, 0.0492, 0.0664, 0.2120, 0.1354, 0.0279],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,170][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.0774e-03, 9.8227e-05, 1.6015e-02, 3.0442e-04, 4.3044e-02, 3.7264e-04,
        3.5833e-04, 8.3638e-04, 2.8684e-04, 1.8657e-02, 2.5944e-04, 2.0786e-03,
        5.2035e-02, 4.5534e-04, 4.2766e-01, 8.1730e-03, 3.1871e-03, 4.2261e-01,
        4.9367e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,172][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2243, 0.0089, 0.0107, 0.0308, 0.0198, 0.0093, 0.0228, 0.1009, 0.0315,
        0.0431, 0.0189, 0.0152, 0.0530, 0.0915, 0.1302, 0.0248, 0.0385, 0.0770,
        0.0489], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,173][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.1074, 0.0240, 0.0417, 0.0530, 0.0548, 0.0410, 0.0813, 0.0927,
        0.0533, 0.0857, 0.0500, 0.0409, 0.0494, 0.0281, 0.0515, 0.0449, 0.0308,
        0.0691], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,175][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0401, 0.0497, 0.0476, 0.0402, 0.0537, 0.0484, 0.0424, 0.0561, 0.0489,
        0.0575, 0.0484, 0.0501, 0.0710, 0.0536, 0.0645, 0.0650, 0.0510, 0.0626,
        0.0493], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,176][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([7.1377e-01, 2.6278e-04, 1.3227e-03, 9.4724e-04, 3.2149e-03, 1.3769e-02,
        3.5231e-03, 2.8262e-02, 3.3198e-02, 1.2601e-03, 7.1317e-03, 3.0621e-03,
        6.9221e-03, 2.9555e-02, 5.5497e-03, 7.1806e-02, 2.4967e-02, 1.3793e-02,
        3.7688e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,178][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.7973, 0.0043, 0.0098, 0.0050, 0.0191, 0.0107, 0.0043, 0.0113, 0.0101,
        0.0150, 0.0047, 0.0041, 0.0134, 0.0134, 0.0163, 0.0128, 0.0060, 0.0277,
        0.0147], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,178][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0024, 0.0148, 0.0290, 0.0213, 0.0117, 0.0122, 0.0190, 0.0799, 0.0381,
        0.0751, 0.0247, 0.0614, 0.0693, 0.1124, 0.0798, 0.0565, 0.0519, 0.1350,
        0.1055], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,179][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0117, 0.0529, 0.0380, 0.0279, 0.0348, 0.0448, 0.0444, 0.0761, 0.0778,
        0.0448, 0.0579, 0.0340, 0.0593, 0.1280, 0.0438, 0.0550, 0.0460, 0.0741,
        0.0490], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,179][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0741, 0.0055, 0.0140, 0.0019, 0.0488, 0.0081, 0.0042, 0.0089, 0.0101,
        0.0198, 0.0041, 0.0059, 0.0553, 0.0111, 0.1365, 0.2139, 0.0220, 0.3363,
        0.0193], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,180][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.8997, 0.0048, 0.0069, 0.0026, 0.0105, 0.0056, 0.0025, 0.0079, 0.0045,
        0.0067, 0.0020, 0.0018, 0.0078, 0.0047, 0.0068, 0.0066, 0.0026, 0.0115,
        0.0046], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,180][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0005, 0.0505, 0.0519, 0.0143, 0.0561, 0.0119, 0.0685, 0.0685, 0.1442,
        0.0404, 0.0464, 0.0583, 0.0393, 0.1115, 0.0725, 0.0149, 0.1030, 0.0178,
        0.0295], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,181][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0052, 0.0067, 0.0120, 0.0061, 0.0096, 0.0400, 0.0216, 0.0106, 0.0356,
        0.0236, 0.0511, 0.1001, 0.0551, 0.0534, 0.0802, 0.1741, 0.1121, 0.0147,
        0.1883], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,218][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:57,220][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,221][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,222][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,223][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,225][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,226][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,227][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,228][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,230][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,230][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,230][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,230][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,231][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5923, 0.4077], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,231][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0367, 0.9633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,231][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.2987e-04, 9.9987e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,232][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5300, 0.4700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,232][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6124, 0.3876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,232][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,233][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7996, 0.2004], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,233][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2177, 0.7823], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,233][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7532, 0.2468], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,234][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2784, 0.7216], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,236][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0042, 0.9958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,238][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0133, 0.9867], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,239][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.6284, 0.1714, 0.2002], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,240][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0365, 0.3479, 0.6155], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,242][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([6.1524e-04, 7.3251e-01, 2.6687e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,243][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.2139, 0.1749, 0.6112], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,245][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2315, 0.1793, 0.5892], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,246][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.9422, 0.0252, 0.0326], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,247][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.8003, 0.1032, 0.0965], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,247][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.1862, 0.5843, 0.2295], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,248][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.4320, 0.1146, 0.4534], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,248][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.1403, 0.3167, 0.5430], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,248][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0085, 0.4560, 0.5355], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,249][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0425, 0.7728, 0.1847], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,249][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4408, 0.1520, 0.3795, 0.0277], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,249][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0118, 0.1997, 0.4788, 0.3097], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,250][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.0684e-04, 5.2144e-01, 2.3261e-01, 2.4564e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,250][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1025, 0.0943, 0.6513, 0.1519], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,250][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1406, 0.2211, 0.4739, 0.1645], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,251][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9270, 0.0212, 0.0275, 0.0243], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,252][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6324, 0.1308, 0.1120, 0.1249], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,253][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1084, 0.4102, 0.2436, 0.2378], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,255][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2821, 0.1231, 0.5331, 0.0617], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,257][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0472, 0.2208, 0.6119, 0.1200], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,258][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0028, 0.3240, 0.5198, 0.1534], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,260][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0081, 0.7193, 0.1483, 0.1243], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,261][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.5231, 0.1297, 0.1790, 0.0482, 0.1201], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,263][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0263, 0.1560, 0.3051, 0.2518, 0.2607], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,264][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.0006, 0.4188, 0.1892, 0.2345, 0.1570], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,265][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0800, 0.0830, 0.2483, 0.3075, 0.2813], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,265][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.1835, 0.0567, 0.1501, 0.0710, 0.5386], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,265][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.9085, 0.0136, 0.0183, 0.0199, 0.0397], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,266][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.6530, 0.0712, 0.0869, 0.0893, 0.0995], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,266][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.1512, 0.2615, 0.1618, 0.1848, 0.2407], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,267][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.4008, 0.0355, 0.1158, 0.0265, 0.4214], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,267][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.0652, 0.0810, 0.1135, 0.0388, 0.7016], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,267][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.0084, 0.1765, 0.3203, 0.0889, 0.4058], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,268][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.0647, 0.3912, 0.1263, 0.1417, 0.2761], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,268][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3595, 0.1294, 0.1943, 0.0343, 0.2254, 0.0572], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,269][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0044, 0.1170, 0.2827, 0.1855, 0.2706, 0.1398], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,270][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([3.2685e-04, 4.0723e-01, 1.4726e-01, 1.8444e-01, 1.5238e-01, 1.0836e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,272][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0294, 0.0287, 0.3032, 0.1206, 0.3831, 0.1350], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,273][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0500, 0.0659, 0.1756, 0.0581, 0.5054, 0.1449], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,274][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8210, 0.0186, 0.0412, 0.0246, 0.0557, 0.0389], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,275][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5258, 0.0940, 0.0776, 0.0904, 0.1187, 0.0935], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,277][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1431, 0.2413, 0.1748, 0.1554, 0.1959, 0.0895], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,279][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0548, 0.0473, 0.1869, 0.0218, 0.6244, 0.0648], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,280][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0081, 0.0595, 0.1374, 0.0264, 0.6657, 0.1029], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,282][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0013, 0.1907, 0.2140, 0.1380, 0.3358, 0.1202], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,282][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0029, 0.4334, 0.0951, 0.1482, 0.1558, 0.1646], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,283][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2813, 0.1195, 0.1942, 0.0340, 0.2501, 0.0754, 0.0456],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,283][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0041, 0.1007, 0.2371, 0.1564, 0.2428, 0.1263, 0.1327],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,283][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.2575e-04, 2.7822e-01, 1.3306e-01, 1.4765e-01, 1.6755e-01, 1.1301e-01,
        1.6029e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,284][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0399, 0.0400, 0.2257, 0.1327, 0.3293, 0.1696, 0.0629],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,284][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0775, 0.0518, 0.1571, 0.0506, 0.4158, 0.1570, 0.0902],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,284][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7374, 0.0262, 0.0456, 0.0277, 0.0778, 0.0659, 0.0195],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,285][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4500, 0.0949, 0.0866, 0.0863, 0.1212, 0.0993, 0.0616],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,285][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1543, 0.1756, 0.1536, 0.1159, 0.2350, 0.1067, 0.0588],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,286][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0561, 0.0375, 0.1685, 0.0190, 0.5894, 0.0960, 0.0335],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,286][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0062, 0.0482, 0.1150, 0.0219, 0.6527, 0.1260, 0.0300],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,288][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0017, 0.1435, 0.1487, 0.0984, 0.3136, 0.1249, 0.1692],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,290][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0009, 0.4895, 0.0442, 0.1105, 0.1485, 0.1419, 0.0644],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,291][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.6779, 0.0461, 0.0472, 0.0117, 0.0527, 0.0213, 0.0231, 0.1200],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,293][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0026, 0.0950, 0.2135, 0.1477, 0.1953, 0.1035, 0.1380, 0.1044],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,294][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0004, 0.1750, 0.0607, 0.1256, 0.1050, 0.1570, 0.3105, 0.0658],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,296][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0311, 0.0259, 0.2384, 0.1346, 0.1829, 0.1970, 0.0864, 0.1038],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,298][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0606, 0.0175, 0.0728, 0.0272, 0.2879, 0.0997, 0.0524, 0.3818],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,299][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.4637, 0.0363, 0.0798, 0.0456, 0.1381, 0.1024, 0.0277, 0.1063],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,300][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.3124, 0.0750, 0.0834, 0.0768, 0.1237, 0.1148, 0.0688, 0.1451],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,300][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0565, 0.1910, 0.1079, 0.1074, 0.1726, 0.1094, 0.0774, 0.1778],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,300][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0890, 0.0098, 0.0669, 0.0093, 0.3876, 0.0792, 0.0178, 0.3404],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,301][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0122, 0.0193, 0.0409, 0.0150, 0.2640, 0.0831, 0.0196, 0.5458],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,301][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0007, 0.1244, 0.1248, 0.0644, 0.2396, 0.1016, 0.2382, 0.1063],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,302][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0007, 0.2598, 0.0599, 0.1608, 0.0938, 0.1286, 0.1777, 0.1187],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,302][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3700, 0.0481, 0.0950, 0.0118, 0.1705, 0.0391, 0.0392, 0.2011, 0.0251],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,302][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0020, 0.0830, 0.1987, 0.1325, 0.2203, 0.0824, 0.1214, 0.0837, 0.0760],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,303][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.1292e-04, 2.4555e-01, 9.9554e-02, 1.1233e-01, 8.5004e-02, 6.4762e-02,
        1.5484e-01, 7.6605e-02, 1.6124e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,303][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0495, 0.0224, 0.2061, 0.0770, 0.3226, 0.0851, 0.0837, 0.0472, 0.1063],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,305][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3110, 0.0253, 0.0614, 0.0360, 0.1397, 0.0805, 0.0554, 0.0559, 0.2348],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,306][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.7073, 0.0176, 0.0346, 0.0218, 0.0729, 0.0476, 0.0180, 0.0446, 0.0356],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,308][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.4412, 0.0609, 0.0655, 0.0606, 0.0891, 0.0690, 0.0414, 0.1118, 0.0603],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,309][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0587, 0.1405, 0.0931, 0.0928, 0.1785, 0.1061, 0.0554, 0.1782, 0.0967],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,311][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.3528, 0.0231, 0.1056, 0.0156, 0.2516, 0.0647, 0.0279, 0.0584, 0.1003],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,313][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0273, 0.0342, 0.0879, 0.0232, 0.3573, 0.0895, 0.0259, 0.1277, 0.2270],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,314][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0009, 0.1128, 0.2122, 0.0597, 0.2659, 0.0711, 0.1206, 0.0932, 0.0637],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,315][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([3.5472e-04, 2.6889e-01, 3.7528e-02, 3.7312e-02, 5.6891e-02, 5.1740e-02,
        6.5962e-02, 9.5001e-02, 3.8632e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,317][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.6425, 0.0335, 0.0538, 0.0135, 0.0430, 0.0172, 0.0253, 0.1115, 0.0320,
        0.0277], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,317][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0058, 0.0812, 0.1605, 0.1244, 0.1667, 0.0838, 0.1094, 0.0757, 0.0799,
        0.1126], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,317][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([6.9406e-05, 2.0000e-01, 6.8216e-02, 1.0910e-01, 6.2468e-02, 8.5803e-02,
        1.8747e-01, 4.1014e-02, 1.6811e-01, 7.7745e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,318][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0390, 0.0228, 0.1215, 0.0787, 0.1275, 0.1278, 0.0651, 0.0358, 0.2715,
        0.1103], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,318][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1140, 0.0100, 0.0261, 0.0181, 0.0972, 0.0514, 0.0287, 0.0604, 0.3231,
        0.2711], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,319][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.4578, 0.0250, 0.0472, 0.0286, 0.0997, 0.0744, 0.0242, 0.0674, 0.0665,
        0.1091], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,319][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.4090, 0.0435, 0.0569, 0.0554, 0.0870, 0.0681, 0.0403, 0.1181, 0.0615,
        0.0603], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,319][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0394, 0.1275, 0.1068, 0.0839, 0.1762, 0.0861, 0.0576, 0.1491, 0.0948,
        0.0785], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,320][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2697, 0.0125, 0.0447, 0.0085, 0.1512, 0.0456, 0.0147, 0.0457, 0.1588,
        0.2486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,320][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0219, 0.0160, 0.0308, 0.0091, 0.1897, 0.0655, 0.0149, 0.1047, 0.2491,
        0.2984], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,321][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0017, 0.0954, 0.1947, 0.0563, 0.1920, 0.0827, 0.1684, 0.0971, 0.0803,
        0.0313], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,322][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([3.9990e-04, 1.1981e-01, 2.2626e-02, 5.1304e-02, 4.5165e-02, 3.2452e-02,
        4.8409e-02, 4.3685e-02, 4.2222e-01, 2.1393e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,324][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1765, 0.0543, 0.1528, 0.0168, 0.1768, 0.0484, 0.0440, 0.2210, 0.0236,
        0.0741, 0.0117], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,325][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0026, 0.0713, 0.1530, 0.1188, 0.1610, 0.0799, 0.1042, 0.0696, 0.0745,
        0.1069, 0.0582], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,326][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.4682e-04, 1.4771e-01, 8.3860e-02, 1.0601e-01, 6.5352e-02, 6.9576e-02,
        1.2540e-01, 9.0609e-02, 1.6162e-01, 9.7965e-02, 5.1756e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,328][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0411, 0.0230, 0.1195, 0.0662, 0.1854, 0.0841, 0.0691, 0.0783, 0.1096,
        0.1348, 0.0889], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,329][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1187, 0.0243, 0.0651, 0.0274, 0.1536, 0.0784, 0.0535, 0.0449, 0.1531,
        0.1393, 0.1417], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,331][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.5627, 0.0195, 0.0360, 0.0219, 0.0702, 0.0586, 0.0192, 0.0559, 0.0505,
        0.0772, 0.0283], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,333][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4258, 0.0493, 0.0595, 0.0512, 0.0814, 0.0654, 0.0329, 0.0840, 0.0512,
        0.0547, 0.0446], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,334][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0975, 0.1015, 0.0712, 0.0838, 0.1768, 0.0855, 0.0411, 0.1316, 0.0850,
        0.0630, 0.0630], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,335][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2003, 0.0349, 0.0897, 0.0118, 0.2128, 0.0637, 0.0296, 0.0420, 0.0841,
        0.1787, 0.0524], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,335][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0080, 0.0274, 0.0853, 0.0132, 0.3872, 0.0689, 0.0215, 0.0663, 0.1094,
        0.1561, 0.0566], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,335][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0014, 0.1073, 0.1860, 0.0593, 0.2384, 0.0643, 0.0956, 0.0970, 0.0790,
        0.0384, 0.0333], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,336][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0004, 0.1336, 0.0188, 0.0335, 0.0314, 0.0357, 0.0296, 0.0388, 0.3203,
        0.1499, 0.2081], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,336][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0740, 0.0700, 0.1614, 0.0190, 0.1889, 0.0574, 0.0423, 0.2242, 0.0414,
        0.0726, 0.0320, 0.0169], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,337][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0031, 0.0707, 0.1460, 0.1067, 0.1682, 0.0674, 0.0898, 0.0677, 0.0627,
        0.1066, 0.0564, 0.0547], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,337][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.8487e-04, 1.9057e-01, 8.6814e-02, 1.0365e-01, 7.0279e-02, 5.8896e-02,
        8.7111e-02, 6.2499e-02, 1.3293e-01, 9.7901e-02, 6.7071e-02, 4.2086e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,337][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0521, 0.0195, 0.0621, 0.0682, 0.1208, 0.0920, 0.0305, 0.0311, 0.1381,
        0.1199, 0.1594, 0.1062], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,338][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2915, 0.0254, 0.0514, 0.0238, 0.0947, 0.0548, 0.0428, 0.0178, 0.0788,
        0.0541, 0.0955, 0.1695], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,339][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7722, 0.0125, 0.0233, 0.0133, 0.0339, 0.0247, 0.0083, 0.0251, 0.0223,
        0.0372, 0.0151, 0.0120], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,341][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5264, 0.0397, 0.0347, 0.0398, 0.0493, 0.0435, 0.0233, 0.0719, 0.0434,
        0.0532, 0.0396, 0.0351], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,342][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0843, 0.1221, 0.0824, 0.0740, 0.1127, 0.0682, 0.0443, 0.1229, 0.0902,
        0.0767, 0.0873, 0.0349], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,344][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.2488, 0.0393, 0.1002, 0.0129, 0.2721, 0.0576, 0.0211, 0.0189, 0.0485,
        0.0771, 0.0446, 0.0590], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,345][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0170, 0.0542, 0.0870, 0.0163, 0.3567, 0.0780, 0.0251, 0.0401, 0.0932,
        0.0957, 0.0588, 0.0777], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,347][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0017, 0.0962, 0.1501, 0.0559, 0.1888, 0.0589, 0.1063, 0.1138, 0.0919,
        0.0472, 0.0507, 0.0384], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,349][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0004, 0.1237, 0.0154, 0.0224, 0.0379, 0.0224, 0.0137, 0.0570, 0.2331,
        0.1558, 0.2599, 0.0583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,350][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.7161, 0.0273, 0.0530, 0.0054, 0.0373, 0.0123, 0.0185, 0.0684, 0.0112,
        0.0193, 0.0072, 0.0068, 0.0173], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,351][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0046, 0.0675, 0.1272, 0.0981, 0.1206, 0.0687, 0.0938, 0.0665, 0.0594,
        0.0878, 0.0525, 0.0606, 0.0928], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,352][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([1.2110e-04, 1.3012e-01, 4.4708e-02, 1.0333e-01, 5.3349e-02, 8.1238e-02,
        1.5820e-01, 4.4823e-02, 1.6328e-01, 6.0752e-02, 6.7893e-02, 5.7977e-02,
        3.4205e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,352][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0165, 0.0180, 0.0673, 0.0756, 0.0676, 0.0779, 0.0646, 0.0209, 0.1395,
        0.0235, 0.0870, 0.2197, 0.1221], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,353][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1521, 0.0100, 0.0190, 0.0114, 0.0490, 0.0276, 0.0189, 0.0141, 0.0936,
        0.0545, 0.0692, 0.1369, 0.3438], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,353][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.7937, 0.0072, 0.0145, 0.0094, 0.0315, 0.0194, 0.0092, 0.0194, 0.0195,
        0.0313, 0.0109, 0.0072, 0.0269], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,353][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.5756, 0.0265, 0.0312, 0.0344, 0.0416, 0.0378, 0.0195, 0.0590, 0.0352,
        0.0380, 0.0324, 0.0271, 0.0415], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,354][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0462, 0.0890, 0.0718, 0.0763, 0.1072, 0.0627, 0.0485, 0.1115, 0.0805,
        0.0558, 0.0859, 0.0432, 0.1214], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,354][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2944, 0.0183, 0.0324, 0.0082, 0.1031, 0.0263, 0.0129, 0.0135, 0.0659,
        0.0598, 0.0302, 0.0476, 0.2873], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,355][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0205, 0.0267, 0.0405, 0.0117, 0.1709, 0.0614, 0.0164, 0.0395, 0.1095,
        0.1187, 0.0440, 0.0692, 0.2711], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,355][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0025, 0.0587, 0.1265, 0.0547, 0.1774, 0.0609, 0.1567, 0.1071, 0.0957,
        0.0419, 0.0452, 0.0338, 0.0390], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,356][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([1.0274e-04, 9.3524e-02, 1.1149e-02, 4.8853e-02, 1.7724e-02, 1.6249e-02,
        4.2470e-02, 3.0109e-02, 3.3152e-01, 7.6657e-02, 2.0055e-01, 1.0029e-01,
        3.0803e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,358][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2181, 0.0387, 0.0951, 0.0080, 0.1114, 0.0379, 0.0372, 0.1794, 0.0268,
        0.0846, 0.0170, 0.0219, 0.0787, 0.0451], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,359][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0014, 0.0582, 0.1406, 0.0880, 0.1566, 0.0538, 0.0780, 0.0532, 0.0518,
        0.0870, 0.0482, 0.0491, 0.0951, 0.0391], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,360][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([5.8153e-05, 1.2463e-01, 6.1242e-02, 8.9114e-02, 6.3561e-02, 5.0295e-02,
        1.1016e-01, 4.9963e-02, 1.3507e-01, 7.7347e-02, 7.1092e-02, 7.3345e-02,
        4.5912e-02, 4.8208e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,362][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0131, 0.0058, 0.0836, 0.0128, 0.1122, 0.0388, 0.0243, 0.0385, 0.0451,
        0.0793, 0.1553, 0.1251, 0.2470, 0.0191], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,364][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0406, 0.0043, 0.0103, 0.0061, 0.0259, 0.0165, 0.0096, 0.0265, 0.0861,
        0.0973, 0.0855, 0.1875, 0.2913, 0.1125], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,365][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.5959, 0.0138, 0.0252, 0.0138, 0.0503, 0.0312, 0.0114, 0.0354, 0.0284,
        0.0583, 0.0200, 0.0169, 0.0555, 0.0439], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,367][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3095, 0.0476, 0.0490, 0.0466, 0.0676, 0.0532, 0.0292, 0.0784, 0.0418,
        0.0524, 0.0447, 0.0376, 0.0700, 0.0724], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,369][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0284, 0.0777, 0.0652, 0.0525, 0.1085, 0.0615, 0.0418, 0.1348, 0.0740,
        0.0591, 0.0784, 0.0380, 0.1080, 0.0721], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,369][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0838, 0.0054, 0.0199, 0.0031, 0.0797, 0.0161, 0.0053, 0.0335, 0.0603,
        0.1553, 0.0418, 0.0567, 0.3892, 0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,369][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0096, 0.0077, 0.0217, 0.0047, 0.1172, 0.0236, 0.0056, 0.0544, 0.0992,
        0.1626, 0.0583, 0.0714, 0.2535, 0.1105], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,370][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0004, 0.0794, 0.1402, 0.0416, 0.1970, 0.0586, 0.1019, 0.1025, 0.0716,
        0.0301, 0.0385, 0.0319, 0.0408, 0.0658], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,370][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0003, 0.1185, 0.0152, 0.0136, 0.0210, 0.0165, 0.0268, 0.0439, 0.1373,
        0.1064, 0.1463, 0.1061, 0.0704, 0.1776], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,371][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.4824, 0.0381, 0.0548, 0.0113, 0.0576, 0.0206, 0.0256, 0.1177, 0.0186,
        0.0334, 0.0123, 0.0105, 0.0310, 0.0431, 0.0429], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,371][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0072, 0.0591, 0.0974, 0.0855, 0.0833, 0.0683, 0.0777, 0.0471, 0.0626,
        0.0796, 0.0501, 0.0541, 0.0841, 0.0448, 0.0992], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,372][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([1.3031e-04, 1.2026e-01, 4.4386e-02, 8.1531e-02, 4.8386e-02, 7.2088e-02,
        9.7618e-02, 6.4074e-02, 1.4616e-01, 7.1497e-02, 5.9242e-02, 4.9671e-02,
        4.0471e-02, 6.1934e-02, 4.2549e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,372][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0430, 0.0136, 0.0481, 0.0357, 0.0571, 0.0502, 0.0250, 0.0138, 0.0795,
        0.0477, 0.0983, 0.0976, 0.0812, 0.0455, 0.2639], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,373][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.1864, 0.0076, 0.0189, 0.0084, 0.0525, 0.0155, 0.0113, 0.0093, 0.0508,
        0.0306, 0.0361, 0.0753, 0.1586, 0.0639, 0.2749], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,375][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.8923, 0.0035, 0.0054, 0.0037, 0.0139, 0.0094, 0.0030, 0.0091, 0.0087,
        0.0125, 0.0037, 0.0035, 0.0104, 0.0113, 0.0096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,376][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.7449, 0.0135, 0.0153, 0.0182, 0.0214, 0.0172, 0.0104, 0.0244, 0.0175,
        0.0189, 0.0149, 0.0131, 0.0210, 0.0257, 0.0236], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,378][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.1085, 0.0799, 0.0453, 0.0574, 0.0779, 0.0509, 0.0372, 0.1038, 0.0668,
        0.0402, 0.0647, 0.0276, 0.0946, 0.0628, 0.0825], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,379][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.3018, 0.0101, 0.0161, 0.0042, 0.0653, 0.0118, 0.0078, 0.0150, 0.0325,
        0.0342, 0.0120, 0.0232, 0.1351, 0.0296, 0.3013], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,381][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0327, 0.0136, 0.0191, 0.0051, 0.1089, 0.0392, 0.0090, 0.0374, 0.0703,
        0.0864, 0.0236, 0.0326, 0.1575, 0.0589, 0.3057], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,383][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0028, 0.0664, 0.0637, 0.0385, 0.1261, 0.0804, 0.1018, 0.1231, 0.0788,
        0.0370, 0.0431, 0.0354, 0.0633, 0.0696, 0.0699], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,385][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0018, 0.0632, 0.0080, 0.0104, 0.0191, 0.0337, 0.0295, 0.0251, 0.1635,
        0.0828, 0.1633, 0.0936, 0.0382, 0.1754, 0.0924], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,386][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2212, 0.0562, 0.1130, 0.0160, 0.0845, 0.0260, 0.0340, 0.1391, 0.0272,
        0.0450, 0.0166, 0.0155, 0.0490, 0.0534, 0.0879, 0.0155],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,386][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0018, 0.0546, 0.1025, 0.0828, 0.1044, 0.0552, 0.0714, 0.0588, 0.0486,
        0.0729, 0.0466, 0.0438, 0.0775, 0.0332, 0.1029, 0.0431],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,387][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([9.0924e-05, 1.9369e-01, 4.6989e-02, 8.4987e-02, 4.2911e-02, 4.1181e-02,
        9.2641e-02, 2.7509e-02, 1.1940e-01, 6.8214e-02, 6.2740e-02, 5.6914e-02,
        4.4296e-02, 5.7136e-02, 3.5118e-02, 2.6184e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,387][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0200, 0.0045, 0.0589, 0.0207, 0.0429, 0.0132, 0.0172, 0.0052, 0.0444,
        0.0420, 0.0545, 0.0774, 0.0855, 0.0141, 0.4481, 0.0515],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,388][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1022, 0.0066, 0.0106, 0.0053, 0.0259, 0.0136, 0.0093, 0.0036, 0.0255,
        0.0136, 0.0224, 0.0683, 0.1125, 0.0230, 0.1821, 0.3754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,388][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.8366, 0.0045, 0.0083, 0.0053, 0.0135, 0.0073, 0.0035, 0.0109, 0.0107,
        0.0156, 0.0064, 0.0056, 0.0198, 0.0135, 0.0247, 0.0137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,389][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.5769, 0.0225, 0.0217, 0.0253, 0.0313, 0.0259, 0.0141, 0.0313, 0.0280,
        0.0276, 0.0254, 0.0224, 0.0372, 0.0346, 0.0369, 0.0389],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,389][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1352, 0.0630, 0.0451, 0.0495, 0.0602, 0.0361, 0.0312, 0.0601, 0.0676,
        0.0452, 0.0586, 0.0366, 0.1009, 0.0564, 0.0798, 0.0744],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,389][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1618, 0.0068, 0.0115, 0.0023, 0.0482, 0.0065, 0.0037, 0.0031, 0.0128,
        0.0132, 0.0074, 0.0133, 0.1034, 0.0074, 0.2745, 0.3240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,390][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0160, 0.0176, 0.0315, 0.0053, 0.1194, 0.0190, 0.0072, 0.0097, 0.0310,
        0.0344, 0.0137, 0.0276, 0.1204, 0.0228, 0.3074, 0.2170],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,392][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0013, 0.0805, 0.0634, 0.0535, 0.1376, 0.0510, 0.1101, 0.0433, 0.0801,
        0.0539, 0.0552, 0.0545, 0.0675, 0.0645, 0.0598, 0.0238],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,394][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0006, 0.0413, 0.0067, 0.0156, 0.0105, 0.0112, 0.0148, 0.0189, 0.1582,
        0.0516, 0.1064, 0.0608, 0.0514, 0.2768, 0.0991, 0.0762],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,395][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1625, 0.0531, 0.1029, 0.0143, 0.1189, 0.0326, 0.0239, 0.1649, 0.0231,
        0.0439, 0.0161, 0.0110, 0.0565, 0.0566, 0.0817, 0.0229, 0.0149],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,396][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0017, 0.0500, 0.1053, 0.0741, 0.1204, 0.0485, 0.0594, 0.0460, 0.0429,
        0.0699, 0.0399, 0.0398, 0.0811, 0.0319, 0.1070, 0.0431, 0.0391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,398][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0002, 0.1374, 0.0524, 0.0795, 0.0548, 0.0441, 0.0552, 0.0639, 0.1286,
        0.0779, 0.0616, 0.0443, 0.0395, 0.0484, 0.0332, 0.0265, 0.0525],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,400][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0196, 0.0070, 0.0366, 0.0241, 0.0527, 0.0276, 0.0098, 0.0215, 0.0584,
        0.0589, 0.0800, 0.0612, 0.1366, 0.0247, 0.2628, 0.0768, 0.0418],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,402][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1220, 0.0058, 0.0145, 0.0054, 0.0326, 0.0139, 0.0090, 0.0055, 0.0233,
        0.0179, 0.0196, 0.0487, 0.1024, 0.0226, 0.1604, 0.3103, 0.0862],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,403][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8148, 0.0048, 0.0096, 0.0050, 0.0160, 0.0096, 0.0037, 0.0116, 0.0097,
        0.0184, 0.0054, 0.0059, 0.0158, 0.0178, 0.0248, 0.0195, 0.0076],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,403][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5908, 0.0195, 0.0194, 0.0213, 0.0275, 0.0238, 0.0127, 0.0341, 0.0230,
        0.0282, 0.0220, 0.0187, 0.0349, 0.0340, 0.0360, 0.0331, 0.0208],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,404][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1640, 0.0685, 0.0468, 0.0420, 0.0708, 0.0389, 0.0179, 0.0790, 0.0520,
        0.0403, 0.0510, 0.0289, 0.0858, 0.0538, 0.0623, 0.0753, 0.0226],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,404][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0908, 0.0060, 0.0147, 0.0020, 0.0469, 0.0088, 0.0039, 0.0057, 0.0100,
        0.0172, 0.0056, 0.0095, 0.0968, 0.0087, 0.2073, 0.4369, 0.0294],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,405][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0083, 0.0130, 0.0235, 0.0037, 0.1229, 0.0214, 0.0047, 0.0169, 0.0340,
        0.0436, 0.0158, 0.0217, 0.1106, 0.0243, 0.2545, 0.2413, 0.0399],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,405][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0019, 0.0635, 0.0565, 0.0409, 0.1079, 0.0437, 0.0656, 0.1558, 0.0710,
        0.0490, 0.0531, 0.0379, 0.0518, 0.0759, 0.0475, 0.0286, 0.0493],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,406][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.4173e-04, 7.3323e-02, 4.9410e-03, 1.1258e-02, 1.2382e-02, 1.2323e-02,
        5.8694e-03, 2.0998e-02, 1.3384e-01, 7.1356e-02, 1.1543e-01, 5.2711e-02,
        3.5488e-02, 2.4300e-01, 5.1614e-02, 1.0066e-01, 5.4663e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,406][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.2386, 0.0541, 0.0785, 0.0115, 0.0868, 0.0276, 0.0289, 0.1408, 0.0233,
        0.0329, 0.0142, 0.0116, 0.0408, 0.0584, 0.0664, 0.0218, 0.0198, 0.0441],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,407][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0020, 0.0462, 0.0864, 0.0758, 0.0922, 0.0485, 0.0631, 0.0473, 0.0446,
        0.0638, 0.0421, 0.0381, 0.0718, 0.0310, 0.0881, 0.0390, 0.0420, 0.0779],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,408][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.0002, 0.1350, 0.0475, 0.0607, 0.0462, 0.0516, 0.0996, 0.0398, 0.0990,
        0.0530, 0.0499, 0.0547, 0.0295, 0.0493, 0.0386, 0.0271, 0.0797, 0.0386],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,410][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0425, 0.0073, 0.0280, 0.0266, 0.0412, 0.0253, 0.0226, 0.0089, 0.0526,
        0.0202, 0.0671, 0.0667, 0.0743, 0.0283, 0.1522, 0.1040, 0.0699, 0.1623],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,412][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0626, 0.0054, 0.0085, 0.0046, 0.0238, 0.0108, 0.0072, 0.0079, 0.0321,
        0.0207, 0.0158, 0.0354, 0.0713, 0.0401, 0.1306, 0.2431, 0.0696, 0.2108],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,413][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.7758, 0.0047, 0.0072, 0.0054, 0.0167, 0.0101, 0.0050, 0.0145, 0.0121,
        0.0186, 0.0053, 0.0056, 0.0182, 0.0173, 0.0191, 0.0185, 0.0088, 0.0371],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,415][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.4981, 0.0214, 0.0235, 0.0285, 0.0322, 0.0333, 0.0176, 0.0452, 0.0282,
        0.0268, 0.0273, 0.0209, 0.0327, 0.0384, 0.0333, 0.0363, 0.0241, 0.0324],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,417][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0698, 0.0737, 0.0421, 0.0468, 0.0635, 0.0387, 0.0288, 0.0907, 0.0562,
        0.0396, 0.0568, 0.0277, 0.0833, 0.0588, 0.0626, 0.0708, 0.0359, 0.0541],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,418][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.1647, 0.0073, 0.0113, 0.0025, 0.0356, 0.0069, 0.0039, 0.0078, 0.0167,
        0.0174, 0.0044, 0.0074, 0.0508, 0.0191, 0.1587, 0.1569, 0.0217, 0.3069],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,420][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0166, 0.0119, 0.0150, 0.0037, 0.0671, 0.0200, 0.0056, 0.0286, 0.0387,
        0.0487, 0.0124, 0.0154, 0.0909, 0.0407, 0.1817, 0.1476, 0.0373, 0.2181],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,420][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0025, 0.0749, 0.0757, 0.0381, 0.0840, 0.0453, 0.0778, 0.1135, 0.0660,
        0.0420, 0.0495, 0.0371, 0.0321, 0.0859, 0.0605, 0.0313, 0.0516, 0.0320],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,421][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([1.7147e-04, 7.0405e-02, 8.8843e-03, 1.9986e-02, 1.4493e-02, 1.1243e-02,
        2.3713e-02, 2.2978e-02, 1.3535e-01, 3.9909e-02, 8.3209e-02, 6.2733e-02,
        2.4206e-02, 1.9552e-01, 6.8557e-02, 6.3794e-02, 1.2378e-01, 3.1056e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,421][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1294, 0.0323, 0.1030, 0.0065, 0.1182, 0.0279, 0.0289, 0.1871, 0.0126,
        0.0478, 0.0082, 0.0118, 0.0519, 0.0321, 0.0907, 0.0205, 0.0190, 0.0666,
        0.0055], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,422][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0015, 0.0420, 0.0874, 0.0700, 0.1064, 0.0374, 0.0566, 0.0394, 0.0398,
        0.0666, 0.0354, 0.0383, 0.0718, 0.0305, 0.0985, 0.0367, 0.0391, 0.0729,
        0.0298], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,422][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0003, 0.1483, 0.0483, 0.0652, 0.0395, 0.0403, 0.0700, 0.0379, 0.1050,
        0.0531, 0.0473, 0.0503, 0.0272, 0.0400, 0.0341, 0.0270, 0.0703, 0.0367,
        0.0592], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,423][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0127, 0.0026, 0.0289, 0.0084, 0.0819, 0.0130, 0.0098, 0.0125, 0.0199,
        0.0216, 0.0341, 0.0419, 0.0692, 0.0094, 0.2009, 0.0744, 0.0355, 0.3010,
        0.0222], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,423][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0860, 0.0051, 0.0111, 0.0051, 0.0228, 0.0135, 0.0092, 0.0090, 0.0233,
        0.0165, 0.0134, 0.0292, 0.0714, 0.0316, 0.1124, 0.2058, 0.0615, 0.2120,
        0.0610], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,424][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.7973, 0.0043, 0.0098, 0.0050, 0.0191, 0.0107, 0.0043, 0.0113, 0.0101,
        0.0150, 0.0047, 0.0041, 0.0134, 0.0134, 0.0163, 0.0128, 0.0060, 0.0277,
        0.0147], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,425][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6232, 0.0186, 0.0175, 0.0211, 0.0270, 0.0192, 0.0106, 0.0287, 0.0190,
        0.0203, 0.0181, 0.0146, 0.0231, 0.0289, 0.0246, 0.0224, 0.0145, 0.0246,
        0.0241], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,426][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1394, 0.0619, 0.0513, 0.0455, 0.0769, 0.0418, 0.0234, 0.0716, 0.0619,
        0.0373, 0.0468, 0.0239, 0.0655, 0.0491, 0.0522, 0.0537, 0.0241, 0.0462,
        0.0276], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,428][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0741, 0.0055, 0.0140, 0.0019, 0.0488, 0.0081, 0.0042, 0.0089, 0.0101,
        0.0198, 0.0041, 0.0059, 0.0553, 0.0111, 0.1365, 0.2139, 0.0220, 0.3363,
        0.0193], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,430][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0084, 0.0090, 0.0174, 0.0032, 0.0816, 0.0184, 0.0050, 0.0248, 0.0294,
        0.0410, 0.0107, 0.0142, 0.0718, 0.0298, 0.1738, 0.1385, 0.0317, 0.2333,
        0.0578], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,431][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0028, 0.0747, 0.1029, 0.0456, 0.1194, 0.0483, 0.0863, 0.0803, 0.0655,
        0.0305, 0.0389, 0.0354, 0.0328, 0.0671, 0.0509, 0.0278, 0.0438, 0.0243,
        0.0227], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,433][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0004, 0.0883, 0.0089, 0.0094, 0.0134, 0.0102, 0.0118, 0.0257, 0.1084,
        0.0601, 0.0867, 0.0407, 0.0431, 0.1591, 0.0508, 0.0800, 0.0802, 0.0232,
        0.0997], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,434][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:57,437][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17191],
        [ 1828],
        [ 5150],
        [ 4700],
        [17523],
        [ 5551],
        [ 2537],
        [ 1133],
        [ 1573],
        [  703],
        [  561],
        [  294],
        [   46],
        [ 1015],
        [ 1023],
        [ 1128],
        [  208],
        [  480],
        [  269]], device='cuda:0')
[2024-07-24 10:18:57,438][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17608],
        [ 9126],
        [12181],
        [17025],
        [27570],
        [17030],
        [11510],
        [ 9000],
        [ 9888],
        [14509],
        [ 9331],
        [ 5781],
        [ 2205],
        [12367],
        [13270],
        [13778],
        [ 5777],
        [ 9923],
        [ 7292]], device='cuda:0')
[2024-07-24 10:18:57,439][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[46445],
        [48170],
        [47985],
        [47785],
        [49094],
        [49967],
        [49881],
        [49854],
        [49996],
        [48935],
        [49687],
        [49419],
        [47863],
        [47658],
        [48373],
        [48169],
        [48252],
        [48883],
        [48977]], device='cuda:0')
[2024-07-24 10:18:57,441][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[47980],
        [13137],
        [ 9064],
        [ 5788],
        [11582],
        [ 8889],
        [ 9110],
        [ 7041],
        [ 6728],
        [ 5590],
        [ 5220],
        [ 5234],
        [ 4913],
        [ 5993],
        [ 6247],
        [ 5479],
        [ 5689],
        [ 5326],
        [ 6647]], device='cuda:0')
[2024-07-24 10:18:57,442][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[45973],
        [   52],
        [   81],
        [  111],
        [  951],
        [  795],
        [  641],
        [  500],
        [  499],
        [  587],
        [  621],
        [  655],
        [  576],
        [  612],
        [  635],
        [  648],
        [  633],
        [  568],
        [  537]], device='cuda:0')
[2024-07-24 10:18:57,443][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[3355],
        [ 637],
        [ 330],
        [ 367],
        [ 281],
        [ 315],
        [ 335],
        [ 362],
        [ 393],
        [ 432],
        [ 467],
        [ 467],
        [ 502],
        [ 514],
        [ 487],
        [ 526],
        [ 551],
        [ 578],
        [ 598]], device='cuda:0')
[2024-07-24 10:18:57,445][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[2602],
        [2778],
        [1136],
        [3063],
        [1149],
        [5525],
        [5168],
        [5219],
        [1441],
        [5973],
        [3765],
        [2849],
        [5099],
        [2647],
        [3120],
        [1505],
        [1651],
        [4499],
        [2530]], device='cuda:0')
[2024-07-24 10:18:57,447][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[48871],
        [48733],
        [48596],
        [48371],
        [48872],
        [47645],
        [45458],
        [38406],
        [45344],
        [36356],
        [39087],
        [46300],
        [46555],
        [39130],
        [48180],
        [47300],
        [46891],
        [45890],
        [46504]], device='cuda:0')
[2024-07-24 10:18:57,448][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 76],
        [588],
        [169],
        [167],
        [153],
        [167],
        [172],
        [382],
        [373],
        [385],
        [342],
        [312],
        [295],
        [324],
        [278],
        [293],
        [276],
        [241],
        [233]], device='cuda:0')
[2024-07-24 10:18:57,450][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35684],
        [43368],
        [48543],
        [47713],
        [48921],
        [46643],
        [43128],
        [35810],
        [32792],
        [31790],
        [29855],
        [26421],
        [28222],
        [30783],
        [33657],
        [34155],
        [34095],
        [34388],
        [35257]], device='cuda:0')
[2024-07-24 10:18:57,452][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35959],
        [24739],
        [18245],
        [14024],
        [30722],
        [26386],
        [24085],
        [11198],
        [16836],
        [ 8964],
        [ 9536],
        [14046],
        [ 8588],
        [ 5423],
        [11236],
        [ 5242],
        [ 3733],
        [ 3507],
        [ 3027]], device='cuda:0')
[2024-07-24 10:18:57,454][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39660],
        [40400],
        [40500],
        [41277],
        [40326],
        [41000],
        [40777],
        [41008],
        [41821],
        [41723],
        [41989],
        [42007],
        [42207],
        [41768],
        [42064],
        [42056],
        [41978],
        [42203],
        [42394]], device='cuda:0')
[2024-07-24 10:18:57,455][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12623],
        [26350],
        [26968],
        [26980],
        [50243],
        [50240],
        [50236],
        [50129],
        [49367],
        [47064],
        [49322],
        [46333],
        [47161],
        [45852],
        [36996],
        [40669],
        [34020],
        [35932],
        [37984]], device='cuda:0')
[2024-07-24 10:18:57,457][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31731],
        [33311],
        [46997],
        [47886],
        [45505],
        [44315],
        [44150],
        [42670],
        [37336],
        [36169],
        [35065],
        [37122],
        [37402],
        [36111],
        [39728],
        [37655],
        [37715],
        [36636],
        [37078]], device='cuda:0')
[2024-07-24 10:18:57,458][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[46467],
        [48130],
        [49277],
        [49004],
        [47071],
        [43345],
        [39780],
        [38755],
        [43530],
        [30581],
        [34267],
        [33914],
        [29765],
        [40646],
        [33857],
        [30653],
        [30532],
        [35568],
        [29142]], device='cuda:0')
[2024-07-24 10:18:57,459][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9458],
        [16831],
        [17138],
        [23180],
        [20436],
        [24512],
        [25020],
        [16365],
        [25085],
        [17995],
        [26891],
        [27032],
        [15513],
        [25673],
        [22853],
        [25262],
        [25382],
        [25142],
        [25504]], device='cuda:0')
[2024-07-24 10:18:57,460][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 215],
        [1149],
        [1581],
        [1430],
        [1535],
        [1656],
        [1670],
        [1660],
        [1661],
        [1577],
        [1567],
        [1527],
        [1573],
        [1625],
        [1542],
        [1564],
        [1572],
        [1625],
        [1611]], device='cuda:0')
[2024-07-24 10:18:57,462][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33964],
        [43537],
        [42133],
        [38026],
        [30687],
        [29757],
        [26828],
        [25767],
        [27910],
        [29066],
        [25472],
        [25583],
        [23709],
        [21740],
        [21993],
        [23547],
        [21193],
        [22409],
        [22100]], device='cuda:0')
[2024-07-24 10:18:57,463][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15491],
        [ 3237],
        [23651],
        [21529],
        [12641],
        [24143],
        [18960],
        [13502],
        [21439],
        [ 8144],
        [ 6790],
        [ 2353],
        [ 2253],
        [ 3549],
        [ 5521],
        [15576],
        [ 7816],
        [ 7925],
        [14235]], device='cuda:0')
[2024-07-24 10:18:57,465][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[43038],
        [11939],
        [ 5572],
        [ 4306],
        [ 7605],
        [ 4398],
        [ 3376],
        [ 2046],
        [ 3455],
        [ 2019],
        [ 2589],
        [ 2780],
        [ 2349],
        [ 1534],
        [ 1974],
        [ 1811],
        [ 1530],
        [ 1343],
        [ 1302]], device='cuda:0')
[2024-07-24 10:18:57,466][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[16330],
        [15157],
        [12614],
        [13035],
        [12429],
        [14371],
        [18938],
        [23408],
        [19648],
        [24672],
        [23216],
        [18760],
        [17714],
        [24088],
        [13601],
        [15313],
        [16365],
        [16166],
        [15523]], device='cuda:0')
[2024-07-24 10:18:57,468][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[45537],
        [28889],
        [38264],
        [29774],
        [34156],
        [34625],
        [32946],
        [32294],
        [32074],
        [31906],
        [31366],
        [27434],
        [27746],
        [25077],
        [31003],
        [26734],
        [25992],
        [26398],
        [27724]], device='cuda:0')
[2024-07-24 10:18:57,470][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[32234],
        [15229],
        [12609],
        [14040],
        [10651],
        [10861],
        [ 9926],
        [10062],
        [10848],
        [10401],
        [10983],
        [12192],
        [15496],
        [14646],
        [14665],
        [16283],
        [15479],
        [15664],
        [14977]], device='cuda:0')
[2024-07-24 10:18:57,472][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23398],
        [26270],
        [35509],
        [37733],
        [21911],
        [17835],
        [18335],
        [15036],
        [30793],
        [27415],
        [23324],
        [25281],
        [29233],
        [20470],
        [36551],
        [39955],
        [36777],
        [27392],
        [25341]], device='cuda:0')
[2024-07-24 10:18:57,473][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39717],
        [26603],
        [23709],
        [21361],
        [12318],
        [12255],
        [12634],
        [22697],
        [19062],
        [25875],
        [19656],
        [18998],
        [23649],
        [25316],
        [20247],
        [15894],
        [16591],
        [17817],
        [17426]], device='cuda:0')
[2024-07-24 10:18:57,474][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[36580],
        [47799],
        [47852],
        [47886],
        [48188],
        [49457],
        [49788],
        [49797],
        [49618],
        [49659],
        [49488],
        [49414],
        [49444],
        [49461],
        [48934],
        [48654],
        [48447],
        [48496],
        [48855]], device='cuda:0')
[2024-07-24 10:18:57,476][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19624],
        [25000],
        [22973],
        [22972],
        [22017],
        [21716],
        [22083],
        [20139],
        [20457],
        [20341],
        [20257],
        [19295],
        [17708],
        [16668],
        [14786],
        [13906],
        [14137],
        [12715],
        [13614]], device='cuda:0')
[2024-07-24 10:18:57,477][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30156],
        [36723],
        [29813],
        [31596],
        [40291],
        [37524],
        [37419],
        [38837],
        [33209],
        [36727],
        [37720],
        [40805],
        [41972],
        [40193],
        [40277],
        [37275],
        [39990],
        [40968],
        [39743]], device='cuda:0')
[2024-07-24 10:18:57,478][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 9298],
        [22278],
        [32947],
        [31658],
        [32034],
        [33320],
        [35255],
        [40377],
        [31123],
        [39299],
        [36511],
        [36422],
        [41300],
        [36667],
        [42813],
        [41299],
        [39369],
        [40150],
        [42658]], device='cuda:0')
[2024-07-24 10:18:57,479][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092],
        [20092]], device='cuda:0')
[2024-07-24 10:18:57,532][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:57,533][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,534][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,535][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,537][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,537][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,537][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,537][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,538][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,538][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,538][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,539][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,539][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,539][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9913, 0.0087], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,540][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,541][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.5043, 0.4957], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,542][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([4.8993e-04, 9.9951e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,544][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4763, 0.5237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,545][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8763, 0.1237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,546][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7574, 0.2426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,546][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8166, 0.1834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,546][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9929, 0.0071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,546][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,547][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1098, 0.8902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,547][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0416, 0.9584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,547][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([9.9693e-01, 2.3626e-03, 7.0736e-04], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,548][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0051, 0.5555, 0.4393], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,548][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.4079, 0.3433, 0.2489], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,548][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([5.3400e-04, 4.3396e-01, 5.6551e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,549][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2142, 0.2880, 0.4978], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,549][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.7000, 0.0589, 0.2411], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,550][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.7213, 0.1098, 0.1690], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,551][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.3753, 0.3875, 0.2373], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,551][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.9826, 0.0058, 0.0116], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,551][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.9905, 0.0048, 0.0048], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,552][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0722, 0.4328, 0.4949], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,552][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0290, 0.6379, 0.3331], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,552][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9710e-01, 1.2441e-03, 3.2395e-04, 1.3360e-03], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,553][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0011, 0.4376, 0.3880, 0.1732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,553][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2900, 0.2661, 0.1988, 0.2451], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,553][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.1130e-05, 1.5960e-01, 1.1468e-01, 7.2570e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,555][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3239, 0.2235, 0.2687, 0.1839], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,556][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2690, 0.0763, 0.5945, 0.0602], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,558][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2762, 0.1356, 0.3763, 0.2120], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,559][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4966, 0.2196, 0.1488, 0.1349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,561][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9543, 0.0107, 0.0233, 0.0117], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,563][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9907, 0.0033, 0.0039, 0.0021], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,564][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0460, 0.2995, 0.3468, 0.3077], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,566][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0144, 0.3736, 0.2049, 0.4071], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,566][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([9.9551e-01, 1.4538e-03, 6.0501e-04, 2.1309e-03, 2.9589e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,566][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0041, 0.2250, 0.2451, 0.0810, 0.4447], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,567][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.1767, 0.2085, 0.1540, 0.2059, 0.2548], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,567][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.0025, 0.1418, 0.2247, 0.5287, 0.1023], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,567][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.3914, 0.0465, 0.0482, 0.0684, 0.4455], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,568][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.6251, 0.0118, 0.0339, 0.0099, 0.3194], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,568][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.5199, 0.0802, 0.1507, 0.0929, 0.1564], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,568][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.4838, 0.0401, 0.0170, 0.0266, 0.4326], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,569][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.9497, 0.0064, 0.0093, 0.0067, 0.0279], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,569][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.9748, 0.0047, 0.0045, 0.0030, 0.0130], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,570][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.0434, 0.2113, 0.2398, 0.1987, 0.3069], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,571][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0133, 0.2793, 0.1664, 0.2784, 0.2627], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,572][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.9674e-01, 1.3205e-03, 2.3277e-04, 1.4535e-03, 1.3696e-04, 1.1550e-04],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,574][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0020, 0.1401, 0.2642, 0.0803, 0.4625, 0.0509], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,575][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2776, 0.1538, 0.1163, 0.1474, 0.1925, 0.1124], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,576][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([3.0028e-04, 9.7530e-02, 1.0407e-01, 2.5050e-01, 6.0198e-02, 4.8740e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,578][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1144, 0.0411, 0.0304, 0.0425, 0.4876, 0.2840], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,580][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2830, 0.0091, 0.0513, 0.0051, 0.4214, 0.2301], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,581][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3901, 0.0766, 0.2136, 0.0929, 0.1478, 0.0790], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,582][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4103, 0.0284, 0.0207, 0.0145, 0.3576, 0.1684], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,583][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8820, 0.0070, 0.0170, 0.0080, 0.0574, 0.0287], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,583][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.9641, 0.0037, 0.0031, 0.0028, 0.0107, 0.0155], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,584][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0326, 0.1548, 0.1901, 0.1543, 0.2337, 0.2345], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,584][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0084, 0.1777, 0.0897, 0.1901, 0.1727, 0.3615], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,584][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([7.8902e-01, 1.6140e-03, 2.3107e-04, 1.5849e-03, 1.1008e-04, 1.3845e-04,
        2.0730e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,585][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0028, 0.1730, 0.1980, 0.0818, 0.4406, 0.0533, 0.0505],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,585][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1666, 0.1549, 0.1170, 0.1470, 0.2092, 0.1154, 0.0900],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,586][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([5.5335e-05, 4.8355e-02, 5.6793e-02, 9.6645e-02, 3.5003e-02, 2.5631e-01,
        5.0684e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,586][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0611, 0.0310, 0.0407, 0.0359, 0.4244, 0.3465, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,586][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1005, 0.0065, 0.0569, 0.0040, 0.4839, 0.3159, 0.0323],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,587][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.4770, 0.0471, 0.1240, 0.0613, 0.1275, 0.0991, 0.0639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,587][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0891, 0.0317, 0.0244, 0.0163, 0.5531, 0.2311, 0.0542],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,589][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8089, 0.0114, 0.0283, 0.0124, 0.0802, 0.0395, 0.0193],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,591][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.8563, 0.0094, 0.0098, 0.0079, 0.0281, 0.0647, 0.0237],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,592][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0207, 0.1331, 0.1643, 0.1332, 0.2074, 0.2002, 0.1411],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,593][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0047, 0.1402, 0.0692, 0.1481, 0.1400, 0.2876, 0.2102],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,594][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([8.9897e-01, 1.0840e-03, 2.1928e-04, 1.2865e-03, 1.0243e-04, 1.0127e-04,
        9.7409e-02, 8.2652e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,596][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0021, 0.0795, 0.1610, 0.0415, 0.2996, 0.0391, 0.0887, 0.2886],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,598][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1797, 0.1316, 0.0858, 0.1111, 0.1536, 0.1003, 0.0654, 0.1725],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,599][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0005, 0.0324, 0.0589, 0.0620, 0.0274, 0.1564, 0.2239, 0.4384],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,600][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0978, 0.0039, 0.0065, 0.0101, 0.0943, 0.1692, 0.0240, 0.5941],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,601][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([1.3586e-01, 6.6698e-04, 3.7634e-03, 8.7586e-04, 4.6612e-02, 5.1788e-02,
        3.6803e-03, 7.5676e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,601][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1132, 0.0839, 0.1720, 0.0843, 0.2322, 0.0943, 0.0819, 0.1382],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,602][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.1077, 0.0015, 0.0017, 0.0033, 0.0505, 0.0722, 0.0163, 0.7468],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,602][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.5603, 0.0144, 0.0404, 0.0177, 0.1456, 0.0751, 0.0300, 0.1165],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,602][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.9194, 0.0040, 0.0058, 0.0037, 0.0210, 0.0242, 0.0062, 0.0157],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,603][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0243, 0.1063, 0.1303, 0.1029, 0.1734, 0.1700, 0.1122, 0.1807],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,603][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0045, 0.0962, 0.0547, 0.1048, 0.0993, 0.2755, 0.1809, 0.1842],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,603][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([7.6080e-01, 2.1812e-03, 3.0784e-04, 1.6500e-03, 1.6234e-04, 1.5263e-04,
        2.1353e-01, 1.0634e-03, 2.0148e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,604][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0023, 0.1010, 0.1411, 0.0397, 0.2946, 0.0354, 0.0453, 0.2716, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,604][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1282, 0.1199, 0.0862, 0.1147, 0.1690, 0.0965, 0.0669, 0.1466, 0.0721],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,605][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([8.1749e-06, 1.3314e-02, 1.9115e-02, 5.7563e-02, 1.3748e-02, 1.5396e-01,
        3.0489e-01, 4.0388e-01, 3.3521e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,607][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.3821, 0.0040, 0.0056, 0.0091, 0.0503, 0.0577, 0.0159, 0.0173, 0.4581],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,608][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.4648, 0.0013, 0.0079, 0.0016, 0.0417, 0.0616, 0.0110, 0.0181, 0.3920],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,610][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.2950, 0.0356, 0.1672, 0.0494, 0.1440, 0.0685, 0.0611, 0.0717, 0.1075],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,611][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.5323, 0.0009, 0.0006, 0.0012, 0.0084, 0.0088, 0.0034, 0.0043, 0.4400],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,613][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.8121, 0.0081, 0.0188, 0.0092, 0.0492, 0.0227, 0.0105, 0.0319, 0.0377],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,615][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.9435, 0.0033, 0.0040, 0.0028, 0.0105, 0.0138, 0.0046, 0.0108, 0.0067],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,616][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0195, 0.1001, 0.1217, 0.0973, 0.1518, 0.1437, 0.0997, 0.1402, 0.1259],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,618][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0044, 0.1072, 0.0609, 0.1039, 0.1125, 0.1893, 0.1202, 0.1365, 0.1651],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,618][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([8.1295e-01, 1.5383e-03, 4.5454e-04, 1.8704e-03, 1.9011e-04, 1.4372e-04,
        1.7049e-01, 1.3292e-03, 1.0792e-02, 2.4282e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,619][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0025, 0.0929, 0.1295, 0.0352, 0.2851, 0.0371, 0.0535, 0.2414, 0.0578,
        0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,619][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1633, 0.1121, 0.0764, 0.1080, 0.1200, 0.0795, 0.0510, 0.1238, 0.0628,
        0.1032], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,619][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([3.9502e-05, 1.6024e-02, 3.9375e-02, 5.3576e-02, 1.6900e-02, 1.2166e-01,
        1.9708e-01, 4.0401e-01, 3.2658e-02, 1.1869e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,620][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1082, 0.0015, 0.0031, 0.0034, 0.0277, 0.0426, 0.0095, 0.0170, 0.5595,
        0.2277], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,620][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([2.2442e-01, 2.2120e-04, 9.6755e-04, 2.3162e-04, 9.7382e-03, 1.3399e-02,
        1.7920e-03, 1.0685e-02, 3.6838e-01, 3.7017e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,621][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1418, 0.0429, 0.1101, 0.0532, 0.1144, 0.0642, 0.0677, 0.0887, 0.1245,
        0.1925], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,621][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([1.1136e-01, 1.9203e-04, 1.2909e-04, 3.1453e-04, 3.0681e-03, 4.8983e-03,
        1.4466e-03, 3.8383e-03, 7.1871e-01, 1.5604e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,621][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.6456, 0.0095, 0.0220, 0.0094, 0.0598, 0.0374, 0.0132, 0.0506, 0.0675,
        0.0849], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,622][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([9.7991e-01, 7.7822e-04, 1.0499e-03, 4.5271e-04, 3.6588e-03, 2.6913e-03,
        8.3636e-04, 3.3560e-03, 1.6060e-03, 5.6632e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,624][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0201, 0.0871, 0.1052, 0.0831, 0.1316, 0.1262, 0.0854, 0.1237, 0.1098,
        0.1276], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,625][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0025, 0.0690, 0.0414, 0.0713, 0.0681, 0.2004, 0.1250, 0.1595, 0.1697,
        0.0932], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,626][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([8.2925e-01, 1.6107e-03, 2.0105e-04, 1.4735e-03, 1.2341e-04, 1.0922e-04,
        1.5008e-01, 7.8441e-04, 1.2477e-02, 1.3159e-04, 3.7561e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,628][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0026, 0.0922, 0.1214, 0.0291, 0.2852, 0.0294, 0.0463, 0.2257, 0.0667,
        0.0786, 0.0227], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,629][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1182, 0.1026, 0.0753, 0.0972, 0.1410, 0.0740, 0.0516, 0.1282, 0.0581,
        0.1019, 0.0520], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,630][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([7.1886e-05, 2.7914e-02, 3.7722e-02, 5.3010e-02, 2.1160e-02, 1.1502e-01,
        2.1432e-01, 3.1618e-01, 3.1093e-02, 1.2211e-01, 6.1395e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,632][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1044, 0.0063, 0.0076, 0.0094, 0.0828, 0.0927, 0.0215, 0.0115, 0.2361,
        0.1255, 0.3022], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,634][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.3613, 0.0008, 0.0040, 0.0005, 0.0251, 0.0240, 0.0045, 0.0062, 0.0638,
        0.0767, 0.4331], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,635][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.2022, 0.0314, 0.1024, 0.0389, 0.0973, 0.0561, 0.0543, 0.0693, 0.0916,
        0.1401, 0.1164], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,636][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.3438, 0.0025, 0.0016, 0.0018, 0.0227, 0.0179, 0.0075, 0.0035, 0.2039,
        0.0635, 0.3313], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,636][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.6027, 0.0125, 0.0282, 0.0120, 0.0727, 0.0339, 0.0165, 0.0432, 0.0688,
        0.0690, 0.0405], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,636][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.8263, 0.0060, 0.0071, 0.0051, 0.0201, 0.0229, 0.0088, 0.0233, 0.0147,
        0.0429, 0.0229], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,637][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0165, 0.0812, 0.1001, 0.0774, 0.1207, 0.1103, 0.0793, 0.1113, 0.0957,
        0.1078, 0.0999], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,637][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0025, 0.0846, 0.0491, 0.0891, 0.0941, 0.1551, 0.0988, 0.1183, 0.1377,
        0.0817, 0.0890], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,638][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([6.8075e-01, 1.2760e-03, 1.3076e-04, 9.0574e-04, 5.4673e-05, 6.9956e-05,
        1.0077e-01, 3.9787e-04, 6.8830e-03, 5.6515e-05, 2.0160e-03, 2.0669e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,638][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0028, 0.0852, 0.1064, 0.0379, 0.2366, 0.0274, 0.0274, 0.2380, 0.0632,
        0.1120, 0.0412, 0.0218], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,638][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1205, 0.0963, 0.0707, 0.0885, 0.1287, 0.0702, 0.0488, 0.1216, 0.0576,
        0.0996, 0.0509, 0.0466], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,639][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.4804e-05, 2.1848e-02, 2.6809e-02, 4.0873e-02, 2.0704e-02, 1.1067e-01,
        1.9106e-01, 3.5649e-01, 2.9622e-02, 9.4263e-02, 6.7117e-02, 4.0528e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,640][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1721, 0.0074, 0.0081, 0.0091, 0.0632, 0.0377, 0.0147, 0.0029, 0.0742,
        0.0304, 0.1296, 0.4508], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,641][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([6.4087e-01, 3.7867e-04, 1.4371e-03, 1.5413e-04, 9.9048e-03, 8.0422e-03,
        1.6707e-03, 1.0374e-03, 1.2612e-02, 1.0856e-02, 1.0704e-01, 2.0600e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,643][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.4370, 0.0199, 0.0597, 0.0274, 0.0488, 0.0352, 0.0300, 0.0387, 0.0614,
        0.0869, 0.1024, 0.0528], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,644][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.5087, 0.0048, 0.0016, 0.0020, 0.0260, 0.0140, 0.0058, 0.0010, 0.0787,
        0.0151, 0.1158, 0.2264], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,646][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.7338, 0.0101, 0.0156, 0.0076, 0.0489, 0.0184, 0.0079, 0.0261, 0.0361,
        0.0420, 0.0211, 0.0323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,648][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.8740, 0.0042, 0.0039, 0.0034, 0.0131, 0.0143, 0.0061, 0.0167, 0.0112,
        0.0274, 0.0156, 0.0100], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,649][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0131, 0.0762, 0.0905, 0.0726, 0.1090, 0.1031, 0.0734, 0.1018, 0.0877,
        0.0970, 0.0898, 0.0856], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,651][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0035, 0.0885, 0.0467, 0.0756, 0.0963, 0.1315, 0.0881, 0.1173, 0.1232,
        0.0829, 0.0817, 0.0647], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,652][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ station] are: tensor([7.3164e-01, 1.0528e-03, 2.8320e-04, 1.4133e-03, 1.2212e-04, 8.0177e-05,
        1.0008e-01, 5.7262e-04, 4.4145e-03, 1.3521e-04, 1.2890e-03, 1.5887e-01,
        4.4710e-05], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,653][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0022, 0.0872, 0.0674, 0.0320, 0.1737, 0.0316, 0.0684, 0.2209, 0.0814,
        0.0712, 0.0280, 0.0362, 0.0997], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,653][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1452, 0.0982, 0.0673, 0.0922, 0.1036, 0.0729, 0.0438, 0.0973, 0.0514,
        0.0780, 0.0467, 0.0452, 0.0582], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,654][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ station] are: tensor([6.8952e-06, 1.2049e-02, 1.8772e-02, 4.0956e-02, 1.0431e-02, 8.2149e-02,
        1.5453e-01, 4.3125e-01, 2.3509e-02, 1.0056e-01, 5.1504e-02, 3.0133e-02,
        4.4150e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,654][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1129, 0.0010, 0.0009, 0.0018, 0.0066, 0.0085, 0.0039, 0.0018, 0.0749,
        0.0145, 0.0550, 0.2034, 0.5147], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,654][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ station] are: tensor([3.8488e-01, 5.3686e-05, 1.4113e-04, 3.7588e-05, 1.0788e-03, 1.1716e-03,
        2.3019e-04, 5.0611e-04, 1.1959e-02, 6.6176e-03, 3.8733e-02, 6.1456e-02,
        4.9314e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,655][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2511, 0.0235, 0.0733, 0.0389, 0.0649, 0.0363, 0.0499, 0.0549, 0.0723,
        0.0984, 0.0899, 0.0702, 0.0763], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,655][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ station] are: tensor([2.2533e-01, 4.8306e-04, 1.9354e-04, 4.4104e-04, 3.5761e-03, 2.6601e-03,
        1.5798e-03, 6.9225e-04, 1.2410e-01, 1.6188e-02, 9.5265e-02, 1.5836e-01,
        3.7114e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,656][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.8172, 0.0040, 0.0053, 0.0041, 0.0176, 0.0091, 0.0045, 0.0128, 0.0237,
        0.0190, 0.0112, 0.0175, 0.0540], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,656][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.9650, 0.0017, 0.0014, 0.0010, 0.0041, 0.0027, 0.0013, 0.0040, 0.0019,
        0.0056, 0.0025, 0.0013, 0.0077], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,657][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0181, 0.0682, 0.0783, 0.0618, 0.0969, 0.0897, 0.0630, 0.0895, 0.0774,
        0.0864, 0.0767, 0.0704, 0.1235], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,658][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0039, 0.0625, 0.0354, 0.0583, 0.0562, 0.1179, 0.0965, 0.1132, 0.1207,
        0.0587, 0.0823, 0.0711, 0.1233], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,659][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([7.2732e-01, 6.8734e-04, 9.0974e-05, 7.3213e-04, 6.2852e-05, 4.4651e-05,
        6.6214e-02, 3.4243e-04, 6.5900e-03, 6.2403e-05, 1.8125e-03, 1.9344e-01,
        2.2069e-05, 2.5769e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,661][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0007, 0.0509, 0.0719, 0.0233, 0.2316, 0.0259, 0.0313, 0.1902, 0.0567,
        0.0871, 0.0285, 0.0246, 0.1125, 0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,662][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0638, 0.0901, 0.0610, 0.0896, 0.1256, 0.0668, 0.0433, 0.1041, 0.0536,
        0.0807, 0.0472, 0.0433, 0.0557, 0.0754], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,663][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.8929e-06, 1.4821e-02, 1.6379e-02, 2.8276e-02, 1.2003e-02, 7.8158e-02,
        1.5278e-01, 4.3670e-01, 2.3504e-02, 9.5632e-02, 3.6560e-02, 1.9882e-02,
        2.9518e-02, 5.5786e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,664][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([1.7734e-02, 2.7281e-04, 4.4283e-04, 6.9260e-04, 4.7950e-03, 4.8328e-03,
        9.3524e-04, 3.0813e-03, 7.0182e-02, 4.0195e-02, 8.9562e-02, 2.0228e-01,
        5.2567e-01, 3.9328e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,665][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.3695e-03, 4.0633e-06, 3.1421e-05, 5.1997e-06, 3.0854e-04, 4.3745e-04,
        3.8612e-05, 8.8925e-04, 1.0265e-02, 2.4728e-02, 5.5568e-02, 1.1279e-01,
        7.9126e-01, 2.2964e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,667][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1666, 0.0199, 0.0725, 0.0303, 0.0690, 0.0431, 0.0340, 0.0504, 0.0671,
        0.1119, 0.0978, 0.0628, 0.0750, 0.0995], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,668][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([4.1300e-02, 7.3916e-05, 5.6206e-05, 1.3222e-04, 1.1909e-03, 9.2483e-04,
        2.9861e-04, 1.6777e-03, 1.0920e-01, 3.9708e-02, 8.9980e-02, 1.8700e-01,
        5.0295e-01, 2.5512e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,670][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.4959, 0.0081, 0.0188, 0.0083, 0.0583, 0.0201, 0.0079, 0.0307, 0.0458,
        0.0581, 0.0282, 0.0494, 0.1267, 0.0436], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,670][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.5749e-01, 1.1934e-03, 1.1966e-03, 8.9850e-04, 3.6292e-03, 3.4893e-03,
        1.4301e-03, 4.1332e-03, 2.3373e-03, 6.4759e-03, 4.5382e-03, 2.4821e-03,
        8.2722e-03, 2.4373e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,671][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0129, 0.0571, 0.0708, 0.0551, 0.0909, 0.0794, 0.0553, 0.0819, 0.0719,
        0.0833, 0.0759, 0.0708, 0.1142, 0.0803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,671][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0038, 0.0665, 0.0378, 0.0601, 0.0724, 0.1102, 0.0666, 0.0731, 0.1017,
        0.0560, 0.0720, 0.0634, 0.1096, 0.1067], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,672][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([7.4814e-01, 1.0976e-03, 1.8643e-04, 1.2721e-03, 9.2570e-05, 6.4441e-05,
        9.3096e-02, 5.7549e-04, 5.2376e-03, 1.0920e-04, 1.1826e-03, 1.4619e-01,
        3.1276e-05, 2.4657e-03, 2.6013e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,672][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0035, 0.0546, 0.0497, 0.0238, 0.1407, 0.0367, 0.0477, 0.1383, 0.0751,
        0.0674, 0.0245, 0.0222, 0.0954, 0.0623, 0.1581], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,673][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.1297, 0.0844, 0.0588, 0.0788, 0.1059, 0.0563, 0.0385, 0.0952, 0.0437,
        0.0725, 0.0354, 0.0403, 0.0479, 0.0635, 0.0491], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,673][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([5.6884e-06, 1.0624e-02, 1.5281e-02, 4.1078e-02, 7.2375e-03, 7.5593e-02,
        1.5374e-01, 4.0829e-01, 2.5893e-02, 7.8066e-02, 3.3792e-02, 1.9876e-02,
        2.9061e-02, 8.6229e-02, 1.5236e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,673][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0909, 0.0013, 0.0009, 0.0017, 0.0080, 0.0082, 0.0020, 0.0011, 0.0460,
        0.0114, 0.0353, 0.0916, 0.3436, 0.0235, 0.3344], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,674][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([1.6744e-01, 7.5187e-05, 2.1254e-04, 3.6491e-05, 2.0577e-03, 1.3980e-03,
        2.2584e-04, 1.5544e-03, 1.3536e-02, 1.3180e-02, 2.7725e-02, 3.8564e-02,
        5.8315e-01, 3.0147e-03, 1.4783e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,676][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.4849, 0.0145, 0.0300, 0.0189, 0.0244, 0.0138, 0.0178, 0.0164, 0.0391,
        0.0437, 0.0527, 0.0274, 0.0235, 0.0448, 0.1481], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,676][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([3.1110e-01, 5.9513e-04, 1.4254e-04, 3.2543e-04, 3.5077e-03, 1.6637e-03,
        7.6915e-04, 5.8418e-04, 7.5692e-02, 1.2321e-02, 4.1419e-02, 6.1752e-02,
        2.1443e-01, 2.1491e-02, 2.5421e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,678][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.8947, 0.0017, 0.0021, 0.0017, 0.0067, 0.0039, 0.0018, 0.0043, 0.0107,
        0.0083, 0.0047, 0.0078, 0.0191, 0.0107, 0.0220], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,679][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([9.8160e-01, 8.0843e-04, 6.6473e-04, 4.7798e-04, 2.1275e-03, 1.2330e-03,
        7.7797e-04, 1.8122e-03, 9.1592e-04, 2.3524e-03, 9.5747e-04, 6.7003e-04,
        2.9166e-03, 8.6691e-04, 1.8239e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,681][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0185, 0.0610, 0.0686, 0.0527, 0.0803, 0.0739, 0.0527, 0.0741, 0.0644,
        0.0700, 0.0620, 0.0571, 0.0976, 0.0712, 0.0959], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,682][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0045, 0.0541, 0.0268, 0.0457, 0.0479, 0.0981, 0.0719, 0.0879, 0.1053,
        0.0571, 0.0619, 0.0549, 0.1127, 0.1078, 0.0632], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,684][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([8.3477e-01, 9.0270e-04, 1.3020e-04, 8.4046e-04, 6.9599e-05, 5.1123e-05,
        6.1142e-02, 3.9139e-04, 4.1911e-03, 5.8303e-05, 1.2075e-03, 9.4208e-02,
        2.2787e-05, 1.5772e-03, 2.2574e-04, 2.1558e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,685][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0063, 0.0478, 0.0649, 0.0328, 0.1026, 0.0201, 0.0324, 0.0846, 0.0592,
        0.0700, 0.0365, 0.0418, 0.1242, 0.0776, 0.1588, 0.0404],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,687][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1170, 0.0768, 0.0545, 0.0722, 0.0889, 0.0541, 0.0390, 0.1022, 0.0453,
        0.0731, 0.0373, 0.0384, 0.0438, 0.0610, 0.0486, 0.0478],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,687][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([9.9782e-06, 1.6112e-02, 1.9154e-02, 3.8651e-02, 1.1285e-02, 6.3979e-02,
        1.3579e-01, 3.6226e-01, 2.3053e-02, 9.4142e-02, 4.9676e-02, 2.6876e-02,
        4.0066e-02, 6.9828e-02, 1.8424e-02, 3.0693e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,688][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([5.6744e-02, 4.4033e-04, 2.1525e-04, 4.7208e-04, 2.1913e-03, 2.1468e-03,
        8.5091e-04, 1.0743e-04, 8.8690e-03, 1.5213e-03, 8.9705e-03, 3.2937e-02,
        9.0617e-02, 3.3752e-03, 9.6229e-02, 6.9431e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,688][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.4281e-01, 7.7271e-05, 1.7677e-04, 2.1508e-05, 1.3733e-03, 9.6734e-04,
        1.7359e-04, 3.7518e-04, 3.1028e-03, 2.6186e-03, 8.5519e-03, 1.4499e-02,
        2.6796e-01, 4.7454e-04, 9.4535e-02, 3.6228e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,689][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.4398, 0.0118, 0.0249, 0.0143, 0.0181, 0.0092, 0.0128, 0.0143, 0.0339,
        0.0383, 0.0453, 0.0341, 0.0405, 0.0505, 0.1316, 0.0806],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,689][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([4.3222e-01, 3.0454e-04, 6.9171e-05, 1.2050e-04, 1.5183e-03, 6.8201e-04,
        3.7687e-04, 5.7052e-05, 9.8623e-03, 1.1235e-03, 8.4283e-03, 2.0601e-02,
        6.4192e-02, 1.9046e-03, 1.0443e-01, 3.5410e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,690][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.8459, 0.0018, 0.0021, 0.0018, 0.0061, 0.0040, 0.0019, 0.0041, 0.0111,
        0.0077, 0.0043, 0.0075, 0.0215, 0.0087, 0.0230, 0.0486],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,690][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.6949e-01, 8.7853e-04, 6.2600e-04, 6.7813e-04, 2.4598e-03, 1.4544e-03,
        6.4221e-04, 1.7063e-03, 1.1001e-03, 3.3899e-03, 1.5333e-03, 7.3382e-04,
        4.5041e-03, 1.4335e-03, 2.3632e-03, 7.0057e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,690][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0138, 0.0507, 0.0595, 0.0470, 0.0693, 0.0646, 0.0455, 0.0608, 0.0558,
        0.0598, 0.0581, 0.0527, 0.0964, 0.0624, 0.0935, 0.1102],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,691][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0058, 0.0598, 0.0302, 0.0479, 0.0525, 0.0680, 0.0552, 0.0653, 0.0826,
        0.0431, 0.0525, 0.0439, 0.0925, 0.0946, 0.0616, 0.1443],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,692][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([6.2659e-01, 8.1410e-04, 8.1943e-05, 5.8030e-04, 3.7952e-05, 4.3820e-05,
        7.5311e-02, 3.5098e-04, 5.3969e-03, 4.4455e-05, 1.5534e-03, 1.3557e-01,
        1.8984e-05, 1.9169e-03, 1.7617e-04, 2.1105e-04, 1.5130e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,693][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0049, 0.0478, 0.0547, 0.0235, 0.1289, 0.0140, 0.0107, 0.1928, 0.0489,
        0.0765, 0.0313, 0.0196, 0.0952, 0.0552, 0.1355, 0.0325, 0.0281],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,695][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0789, 0.0725, 0.0549, 0.0681, 0.0925, 0.0540, 0.0419, 0.0956, 0.0481,
        0.0791, 0.0414, 0.0402, 0.0469, 0.0631, 0.0484, 0.0441, 0.0304],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,696][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.5331e-05, 1.7492e-02, 1.9793e-02, 2.5456e-02, 1.0475e-02, 5.2132e-02,
        1.0650e-01, 4.3446e-01, 2.0744e-02, 9.9282e-02, 3.4194e-02, 1.8789e-02,
        2.9907e-02, 6.5530e-02, 1.4530e-02, 1.9999e-02, 3.0706e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,697][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.8628e-02, 6.5382e-04, 6.4243e-04, 6.1513e-04, 5.1837e-03, 3.2711e-03,
        8.5310e-04, 3.7744e-04, 7.8736e-03, 2.6055e-03, 6.8575e-03, 2.9814e-02,
        1.1168e-01, 4.6199e-03, 1.3028e-01, 6.1709e-01, 3.8955e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,698][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.7988e-02, 3.1454e-05, 1.7047e-04, 9.0029e-06, 1.4864e-03, 8.6333e-04,
        8.8149e-05, 1.1297e-03, 2.4425e-03, 5.5210e-03, 7.3980e-03, 1.0651e-02,
        3.2737e-01, 9.2907e-04, 1.1734e-01, 4.8881e-01, 7.7715e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,700][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5316, 0.0077, 0.0197, 0.0122, 0.0182, 0.0134, 0.0103, 0.0161, 0.0339,
        0.0379, 0.0409, 0.0232, 0.0257, 0.0442, 0.0716, 0.0564, 0.0371],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,701][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.0802e-01, 5.4100e-04, 1.7867e-04, 2.0074e-04, 3.5685e-03, 1.4293e-03,
        6.0309e-04, 2.9193e-04, 1.2665e-02, 3.0891e-03, 9.4765e-03, 2.2304e-02,
        1.4241e-01, 3.8640e-03, 1.4133e-01, 3.8971e-01, 6.0315e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,703][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.7353, 0.0026, 0.0041, 0.0025, 0.0131, 0.0051, 0.0024, 0.0087, 0.0146,
        0.0145, 0.0070, 0.0115, 0.0327, 0.0146, 0.0460, 0.0710, 0.0144],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,705][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.8915, 0.0017, 0.0017, 0.0014, 0.0055, 0.0056, 0.0026, 0.0069, 0.0041,
        0.0108, 0.0053, 0.0033, 0.0130, 0.0042, 0.0077, 0.0308, 0.0040],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,705][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0099, 0.0474, 0.0579, 0.0454, 0.0687, 0.0621, 0.0444, 0.0628, 0.0528,
        0.0586, 0.0532, 0.0494, 0.0868, 0.0600, 0.0861, 0.0955, 0.0591],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,706][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0040, 0.0575, 0.0285, 0.0501, 0.0526, 0.0733, 0.0517, 0.0627, 0.0738,
        0.0444, 0.0496, 0.0391, 0.0802, 0.0849, 0.0515, 0.1127, 0.0835],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,706][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([6.7166e-01, 9.1655e-04, 2.2048e-04, 1.1401e-03, 1.0893e-04, 6.6019e-05,
        8.9453e-02, 7.2889e-04, 5.0591e-03, 1.1519e-04, 1.2384e-03, 1.2392e-01,
        3.1263e-05, 2.2549e-03, 2.9006e-04, 2.1025e-04, 1.0252e-01, 6.4869e-05],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,706][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0026, 0.0567, 0.0503, 0.0264, 0.1081, 0.0238, 0.0287, 0.1686, 0.0519,
        0.0529, 0.0240, 0.0195, 0.0655, 0.0650, 0.0895, 0.0290, 0.0384, 0.0991],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,707][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0549, 0.0759, 0.0571, 0.0771, 0.0902, 0.0600, 0.0388, 0.0786, 0.0474,
        0.0710, 0.0382, 0.0368, 0.0454, 0.0607, 0.0468, 0.0474, 0.0276, 0.0462],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,707][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([1.1096e-06, 7.9257e-03, 1.1715e-02, 3.1392e-02, 4.4679e-03, 5.6562e-02,
        1.2783e-01, 5.3126e-01, 1.9103e-02, 6.0411e-02, 2.4848e-02, 1.1304e-02,
        1.4630e-02, 5.7267e-02, 6.2681e-03, 6.7552e-03, 1.8181e-02, 1.0082e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,708][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([3.7830e-02, 5.2204e-04, 3.2416e-04, 7.2922e-04, 4.1785e-03, 2.5888e-03,
        1.2514e-03, 1.3174e-03, 1.8768e-02, 4.8879e-03, 1.1427e-02, 2.3728e-02,
        9.6459e-02, 1.6090e-02, 8.6880e-02, 4.7000e-01, 4.2339e-02, 1.8068e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,708][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([6.2016e-02, 7.3073e-05, 1.9828e-04, 2.6236e-05, 1.7042e-03, 9.7462e-04,
        1.8069e-04, 8.6787e-03, 1.1536e-02, 2.3891e-02, 1.1810e-02, 7.5023e-03,
        3.1895e-01, 7.0177e-03, 8.9692e-02, 2.2172e-01, 8.0131e-03, 2.2601e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,710][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.2170, 0.0157, 0.0225, 0.0207, 0.0251, 0.0215, 0.0191, 0.0299, 0.0457,
        0.0481, 0.0513, 0.0372, 0.0306, 0.0727, 0.1070, 0.0958, 0.0672, 0.0731],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,711][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([1.9944e-01, 2.5332e-04, 7.0211e-05, 1.4174e-04, 1.5676e-03, 7.6159e-04,
        4.6213e-04, 8.3844e-04, 2.3908e-02, 6.0704e-03, 6.8836e-03, 8.9816e-03,
        6.2096e-02, 9.2285e-03, 5.9834e-02, 1.5795e-01, 3.1042e-02, 4.3047e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,713][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.7495, 0.0025, 0.0030, 0.0028, 0.0077, 0.0048, 0.0027, 0.0070, 0.0158,
        0.0115, 0.0069, 0.0087, 0.0235, 0.0154, 0.0258, 0.0457, 0.0122, 0.0544],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,714][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([9.5947e-01, 1.0792e-03, 9.4281e-04, 8.1612e-04, 3.0692e-03, 2.6899e-03,
        8.9667e-04, 2.7661e-03, 1.4355e-03, 3.9043e-03, 1.5689e-03, 7.3524e-04,
        4.2968e-03, 1.6001e-03, 2.0558e-03, 6.4919e-03, 8.5533e-04, 5.3303e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,715][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0130, 0.0435, 0.0513, 0.0409, 0.0607, 0.0570, 0.0412, 0.0559, 0.0497,
        0.0528, 0.0500, 0.0456, 0.0744, 0.0556, 0.0752, 0.0878, 0.0567, 0.0887],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,717][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0014, 0.0377, 0.0202, 0.0407, 0.0339, 0.0756, 0.0558, 0.0638, 0.0739,
        0.0358, 0.0508, 0.0412, 0.0640, 0.0859, 0.0440, 0.1276, 0.0874, 0.0604],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,718][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.3454e-01, 6.6795e-04, 6.9526e-05, 5.0060e-04, 3.8307e-05, 2.9326e-05,
        5.4412e-02, 3.1253e-04, 4.3634e-03, 3.9161e-05, 1.0642e-03, 1.0649e-01,
        1.5046e-05, 1.7191e-03, 1.2486e-04, 1.3178e-04, 9.2057e-02, 2.6461e-05,
        3.4025e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,720][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0074, 0.0375, 0.0558, 0.0200, 0.1237, 0.0178, 0.0221, 0.1281, 0.0497,
        0.0606, 0.0201, 0.0200, 0.0829, 0.0486, 0.0939, 0.0267, 0.0367, 0.1103,
        0.0380], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,722][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0739, 0.0722, 0.0520, 0.0679, 0.0881, 0.0522, 0.0380, 0.0829, 0.0412,
        0.0697, 0.0375, 0.0368, 0.0425, 0.0563, 0.0447, 0.0420, 0.0270, 0.0453,
        0.0297], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,722][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.4303e-06, 1.2088e-02, 1.7095e-02, 2.9098e-02, 5.4537e-03, 6.0294e-02,
        1.4950e-01, 4.6325e-01, 1.9765e-02, 6.8379e-02, 2.0018e-02, 1.2416e-02,
        1.7583e-02, 5.2965e-02, 8.4024e-03, 9.1232e-03, 2.0518e-02, 1.2799e-02,
        2.1251e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,723][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0377, 0.0010, 0.0010, 0.0009, 0.0085, 0.0037, 0.0017, 0.0016, 0.0151,
        0.0074, 0.0113, 0.0209, 0.0965, 0.0108, 0.1134, 0.3682, 0.0323, 0.2097,
        0.0583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,723][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.0470e-02, 5.7554e-05, 3.7718e-04, 2.0070e-05, 2.8126e-03, 1.2566e-03,
        2.1190e-04, 9.0721e-03, 5.4354e-03, 2.0905e-02, 8.0949e-03, 5.6976e-03,
        2.8236e-01, 5.1246e-03, 1.2491e-01, 2.2309e-01, 7.7903e-03, 2.8462e-01,
        7.6936e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,724][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4429, 0.0073, 0.0248, 0.0113, 0.0233, 0.0105, 0.0106, 0.0154, 0.0304,
        0.0335, 0.0313, 0.0199, 0.0269, 0.0370, 0.0760, 0.0557, 0.0338, 0.0415,
        0.0679], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,724][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.8360e-01, 4.6534e-04, 2.1159e-04, 2.1086e-04, 3.7684e-03, 1.1749e-03,
        6.6442e-04, 1.2174e-03, 1.4947e-02, 5.8803e-03, 7.3950e-03, 8.5324e-03,
        6.4524e-02, 5.9320e-03, 5.8154e-02, 1.2087e-01, 2.2890e-02, 4.5212e-01,
        4.7448e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,724][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6995, 0.0027, 0.0057, 0.0026, 0.0164, 0.0056, 0.0027, 0.0113, 0.0130,
        0.0147, 0.0058, 0.0090, 0.0271, 0.0142, 0.0367, 0.0481, 0.0108, 0.0531,
        0.0211], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,725][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.5751e-01, 8.2591e-04, 9.5301e-04, 6.3838e-04, 2.9576e-03, 1.6334e-03,
        8.7599e-04, 2.3184e-03, 1.1758e-03, 4.3020e-03, 1.3366e-03, 7.3636e-04,
        4.7102e-03, 1.4126e-03, 2.6899e-03, 6.5173e-03, 9.3356e-04, 6.2461e-03,
        2.2291e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,725][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0092, 0.0411, 0.0502, 0.0398, 0.0596, 0.0528, 0.0386, 0.0549, 0.0460,
        0.0503, 0.0462, 0.0419, 0.0722, 0.0525, 0.0729, 0.0824, 0.0511, 0.0824,
        0.0558], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,727][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0027, 0.0524, 0.0275, 0.0502, 0.0502, 0.0690, 0.0514, 0.0570, 0.0670,
        0.0380, 0.0441, 0.0331, 0.0623, 0.0746, 0.0411, 0.0929, 0.0681, 0.0502,
        0.0681], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,769][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:57,769][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,769][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,770][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,770][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,770][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,771][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,771][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,771][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,772][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,772][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,772][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,772][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:57,773][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9014, 0.0986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,773][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,773][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7425, 0.2575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,774][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4902, 0.5098], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,774][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4626, 0.5374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,774][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9208, 0.0792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,774][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7574, 0.2426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,775][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8166, 0.1834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,775][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9929, 0.0071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,775][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9872, 0.0128], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,775][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8146, 0.1854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,776][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2815, 0.7185], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:57,777][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.8406, 0.1239, 0.0354], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,779][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0051, 0.5555, 0.4393], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,780][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.6859, 0.1396, 0.1745], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,781][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.5125, 0.2934, 0.1941], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,783][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2052, 0.2924, 0.5024], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,785][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.7285, 0.0886, 0.1829], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,786][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.7213, 0.1098, 0.1690], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,788][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.3753, 0.3875, 0.2373], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,788][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.9826, 0.0058, 0.0116], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,789][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.9575, 0.0174, 0.0252], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,789][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.7942, 0.1039, 0.1019], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,789][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.1798, 0.5257, 0.2944], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:57,790][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6614, 0.1018, 0.0325, 0.2044], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,790][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0011, 0.4376, 0.3880, 0.1732], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,790][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4817, 0.2084, 0.1741, 0.1358], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,791][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2383, 0.3411, 0.1670, 0.2536], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,791][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3130, 0.2274, 0.2725, 0.1870], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,791][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6156, 0.0803, 0.2360, 0.0681], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,792][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2762, 0.1356, 0.3763, 0.2120], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,792][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4966, 0.2196, 0.1488, 0.1349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,794][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9543, 0.0107, 0.0233, 0.0117], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,796][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9465, 0.0136, 0.0211, 0.0188], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,797][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6634, 0.1297, 0.0950, 0.1119], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,798][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1555, 0.3239, 0.2856, 0.2349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:57,800][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.7373, 0.0660, 0.0185, 0.1463, 0.0319], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,802][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0041, 0.2250, 0.2451, 0.0810, 0.4447], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,803][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.3280, 0.0663, 0.0816, 0.0643, 0.4597], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,804][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.4414, 0.1292, 0.0956, 0.0906, 0.2433], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,806][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.3708, 0.0475, 0.0491, 0.0696, 0.4630], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,806][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.7318, 0.0207, 0.0299, 0.0239, 0.1937], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,806][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.5199, 0.0802, 0.1507, 0.0929, 0.1564], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,807][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.4838, 0.0401, 0.0170, 0.0266, 0.4326], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,807][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.9497, 0.0064, 0.0093, 0.0067, 0.0279], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,807][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.9490, 0.0081, 0.0116, 0.0116, 0.0196], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,808][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.6678, 0.0535, 0.0505, 0.0494, 0.1788], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,808][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.1726, 0.2013, 0.1273, 0.1154, 0.3835], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:57,808][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6940, 0.0597, 0.0176, 0.1764, 0.0368, 0.0154], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,809][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0020, 0.1401, 0.2642, 0.0803, 0.4625, 0.0509], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,809][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1467, 0.0892, 0.1193, 0.0692, 0.4053, 0.1703], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,810][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.2752, 0.1510, 0.1263, 0.1196, 0.1993, 0.1287], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,811][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1095, 0.0409, 0.0302, 0.0423, 0.4916, 0.2854], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,813][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3496, 0.0267, 0.0651, 0.0231, 0.3582, 0.1772], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,815][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3901, 0.0766, 0.2136, 0.0929, 0.1478, 0.0790], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,816][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.4103, 0.0284, 0.0207, 0.0145, 0.3576, 0.1684], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,818][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8820, 0.0070, 0.0170, 0.0080, 0.0574, 0.0287], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,819][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.9141, 0.0097, 0.0136, 0.0140, 0.0230, 0.0256], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,821][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5707, 0.0464, 0.0509, 0.0547, 0.1380, 0.1393], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,822][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0981, 0.1314, 0.1094, 0.1007, 0.3114, 0.2490], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:57,823][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0735, 0.0108, 0.0023, 0.0280, 0.0046, 0.0024, 0.8784],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,823][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0028, 0.1730, 0.1980, 0.0818, 0.4406, 0.0533, 0.0505],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,824][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1329, 0.0621, 0.0965, 0.0518, 0.3987, 0.1644, 0.0936],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,824][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1568, 0.1899, 0.1362, 0.1026, 0.2127, 0.1078, 0.0940],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,825][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0584, 0.0310, 0.0403, 0.0357, 0.4270, 0.3471, 0.0606],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,825][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2857, 0.0232, 0.0715, 0.0213, 0.3386, 0.2140, 0.0457],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,825][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4770, 0.0471, 0.1240, 0.0613, 0.1275, 0.0991, 0.0639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,826][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0891, 0.0317, 0.0244, 0.0163, 0.5531, 0.2311, 0.0542],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,826][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8089, 0.0114, 0.0283, 0.0124, 0.0802, 0.0395, 0.0193],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,826][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.8403, 0.0121, 0.0221, 0.0189, 0.0314, 0.0481, 0.0271],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,827][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4614, 0.0541, 0.0512, 0.0523, 0.1474, 0.1486, 0.0849],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,829][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0496, 0.1321, 0.0898, 0.0871, 0.2378, 0.2205, 0.1832],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:57,830][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1271, 0.0113, 0.0020, 0.0315, 0.0039, 0.0030, 0.8124, 0.0087],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,832][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0021, 0.0795, 0.1610, 0.0415, 0.2996, 0.0391, 0.0887, 0.2886],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,833][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1543, 0.0735, 0.0730, 0.0761, 0.1943, 0.1419, 0.0863, 0.2005],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,834][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0404, 0.1312, 0.1104, 0.0902, 0.2362, 0.1081, 0.0678, 0.2157],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,836][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0922, 0.0040, 0.0066, 0.0101, 0.0964, 0.1709, 0.0243, 0.5955],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,838][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.2455, 0.0033, 0.0097, 0.0061, 0.0759, 0.0741, 0.0146, 0.5707],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,839][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.1132, 0.0839, 0.1720, 0.0843, 0.2322, 0.0943, 0.0819, 0.1382],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,840][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.1077, 0.0015, 0.0017, 0.0033, 0.0505, 0.0722, 0.0163, 0.7468],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,841][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.5603, 0.0144, 0.0404, 0.0177, 0.1456, 0.0751, 0.0300, 0.1165],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,841][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.7824, 0.0125, 0.0242, 0.0222, 0.0515, 0.0546, 0.0226, 0.0300],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,841][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.3070, 0.0456, 0.0372, 0.0456, 0.1381, 0.1741, 0.0879, 0.1646],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,842][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0296, 0.0513, 0.0558, 0.0415, 0.2195, 0.1680, 0.1304, 0.3038],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:57,842][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0931, 0.0154, 0.0036, 0.0318, 0.0059, 0.0025, 0.7328, 0.0070, 0.1079],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,843][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0023, 0.1010, 0.1411, 0.0397, 0.2946, 0.0354, 0.0453, 0.2716, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,843][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1888, 0.0549, 0.0524, 0.0612, 0.2062, 0.1068, 0.0750, 0.1870, 0.0676],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,843][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0942, 0.1274, 0.0891, 0.1196, 0.1433, 0.0853, 0.0642, 0.1680, 0.1090],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,844][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3689, 0.0041, 0.0057, 0.0092, 0.0523, 0.0596, 0.0164, 0.0179, 0.4659],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,845][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.7118, 0.0023, 0.0054, 0.0038, 0.0175, 0.0237, 0.0091, 0.0123, 0.2141],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,846][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2950, 0.0356, 0.1672, 0.0494, 0.1440, 0.0685, 0.0611, 0.0717, 0.1075],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,848][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.5323, 0.0009, 0.0006, 0.0012, 0.0084, 0.0088, 0.0034, 0.0043, 0.4400],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,849][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.8121, 0.0081, 0.0188, 0.0092, 0.0492, 0.0227, 0.0105, 0.0319, 0.0377],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,851][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.8755, 0.0074, 0.0134, 0.0128, 0.0161, 0.0225, 0.0127, 0.0138, 0.0257],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,853][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.5467, 0.0277, 0.0256, 0.0320, 0.0660, 0.0685, 0.0411, 0.0444, 0.1480],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,854][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0588, 0.0844, 0.0807, 0.0575, 0.1698, 0.1114, 0.0818, 0.1911, 0.1645],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:57,856][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.1313, 0.0162, 0.0031, 0.0312, 0.0047, 0.0028, 0.6818, 0.0079, 0.1047,
        0.0163], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,857][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0025, 0.0929, 0.1295, 0.0352, 0.2851, 0.0371, 0.0535, 0.2414, 0.0578,
        0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,858][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1785, 0.0409, 0.0406, 0.0503, 0.1614, 0.0940, 0.0684, 0.1438, 0.0642,
        0.1579], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,858][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0861, 0.0789, 0.0762, 0.0613, 0.1575, 0.0848, 0.0517, 0.1789, 0.0994,
        0.1251], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,859][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.1018, 0.0015, 0.0031, 0.0034, 0.0285, 0.0434, 0.0097, 0.0173, 0.5591,
        0.2323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,859][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.3350, 0.0012, 0.0025, 0.0019, 0.0147, 0.0178, 0.0063, 0.0191, 0.4609,
        0.1408], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,860][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1418, 0.0429, 0.1101, 0.0532, 0.1144, 0.0642, 0.0677, 0.0887, 0.1245,
        0.1925], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,860][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([1.1136e-01, 1.9203e-04, 1.2909e-04, 3.1453e-04, 3.0681e-03, 4.8983e-03,
        1.4466e-03, 3.8383e-03, 7.1871e-01, 1.5604e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,860][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6456, 0.0095, 0.0220, 0.0094, 0.0598, 0.0374, 0.0132, 0.0506, 0.0675,
        0.0849], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,861][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.8809, 0.0043, 0.0069, 0.0072, 0.0133, 0.0164, 0.0074, 0.0112, 0.0276,
        0.0247], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,861][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.4464, 0.0198, 0.0179, 0.0220, 0.0580, 0.0619, 0.0366, 0.0442, 0.1638,
        0.1296], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,861][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0335, 0.0494, 0.0426, 0.0313, 0.0986, 0.1126, 0.0653, 0.1958, 0.1735,
        0.1973], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:57,862][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0920, 0.0130, 0.0025, 0.0307, 0.0061, 0.0022, 0.6874, 0.0069, 0.0936,
        0.0153, 0.0503], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,864][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0026, 0.0922, 0.1214, 0.0291, 0.2852, 0.0294, 0.0463, 0.2257, 0.0667,
        0.0786, 0.0227], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,866][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1380, 0.0431, 0.0476, 0.0453, 0.1838, 0.1054, 0.0588, 0.1276, 0.0621,
        0.1376, 0.0507], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,867][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.1434, 0.0932, 0.0664, 0.0751, 0.1131, 0.0679, 0.0540, 0.1168, 0.0850,
        0.1134, 0.0716], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,869][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0994, 0.0063, 0.0076, 0.0094, 0.0843, 0.0935, 0.0217, 0.0117, 0.2361,
        0.1280, 0.3022], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,870][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.5380, 0.0045, 0.0094, 0.0044, 0.0324, 0.0304, 0.0119, 0.0115, 0.1315,
        0.0489, 0.1772], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,872][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.2022, 0.0314, 0.1024, 0.0389, 0.0973, 0.0561, 0.0543, 0.0693, 0.0916,
        0.1401, 0.1164], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,874][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.3438, 0.0025, 0.0016, 0.0018, 0.0227, 0.0179, 0.0075, 0.0035, 0.2039,
        0.0635, 0.3313], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,875][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6027, 0.0125, 0.0282, 0.0120, 0.0727, 0.0339, 0.0165, 0.0432, 0.0688,
        0.0690, 0.0405], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,876][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.7937, 0.0077, 0.0157, 0.0131, 0.0220, 0.0261, 0.0149, 0.0182, 0.0296,
        0.0332, 0.0258], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,876][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.4164, 0.0282, 0.0231, 0.0254, 0.0654, 0.0540, 0.0361, 0.0388, 0.1082,
        0.0830, 0.1214], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,876][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0403, 0.0573, 0.0581, 0.0402, 0.1378, 0.0854, 0.0615, 0.1773, 0.1164,
        0.1142, 0.1115], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:57,877][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0494, 0.0057, 0.0008, 0.0115, 0.0015, 0.0010, 0.2591, 0.0023, 0.0382,
        0.0044, 0.0188, 0.6074], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,877][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0028, 0.0852, 0.1064, 0.0379, 0.2366, 0.0274, 0.0274, 0.2380, 0.0632,
        0.1120, 0.0412, 0.0218], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,877][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3362, 0.0269, 0.0260, 0.0346, 0.1003, 0.0600, 0.0404, 0.0791, 0.0439,
        0.0932, 0.0407, 0.1186], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,878][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1264, 0.1045, 0.0661, 0.0668, 0.1142, 0.0530, 0.0364, 0.0869, 0.0836,
        0.0913, 0.0656, 0.1052], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,878][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1653, 0.0074, 0.0081, 0.0092, 0.0649, 0.0385, 0.0150, 0.0030, 0.0754,
        0.0315, 0.1313, 0.4504], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,878][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7811, 0.0029, 0.0039, 0.0022, 0.0126, 0.0114, 0.0055, 0.0020, 0.0358,
        0.0082, 0.0572, 0.0771], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,879][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4370, 0.0199, 0.0597, 0.0274, 0.0488, 0.0352, 0.0300, 0.0387, 0.0614,
        0.0869, 0.1024, 0.0528], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,879][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5087, 0.0048, 0.0016, 0.0020, 0.0260, 0.0140, 0.0058, 0.0010, 0.0787,
        0.0151, 0.1158, 0.2264], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,881][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.7338, 0.0101, 0.0156, 0.0076, 0.0489, 0.0184, 0.0079, 0.0261, 0.0361,
        0.0420, 0.0211, 0.0323], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,882][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.7557, 0.0098, 0.0126, 0.0143, 0.0208, 0.0233, 0.0138, 0.0172, 0.0313,
        0.0345, 0.0252, 0.0415], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,884][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.4662, 0.0241, 0.0168, 0.0203, 0.0452, 0.0409, 0.0244, 0.0234, 0.0717,
        0.0506, 0.0722, 0.1441], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,885][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0494, 0.0483, 0.0429, 0.0297, 0.1091, 0.0559, 0.0462, 0.1251, 0.1030,
        0.0905, 0.1007, 0.1993], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:57,886][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0863, 0.0052, 0.0010, 0.0116, 0.0020, 0.0010, 0.2568, 0.0018, 0.0302,
        0.0053, 0.0144, 0.5797, 0.0048], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,889][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0022, 0.0872, 0.0674, 0.0320, 0.1737, 0.0316, 0.0684, 0.2209, 0.0814,
        0.0712, 0.0280, 0.0362, 0.0997], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,890][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2947, 0.0276, 0.0176, 0.0341, 0.0618, 0.0591, 0.0441, 0.0480, 0.0373,
        0.0671, 0.0386, 0.1083, 0.1619], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,891][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0662, 0.0850, 0.0443, 0.0663, 0.1218, 0.0504, 0.0381, 0.0999, 0.0826,
        0.1031, 0.0560, 0.0806, 0.1058], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,893][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.1073, 0.0011, 0.0009, 0.0019, 0.0069, 0.0087, 0.0040, 0.0018, 0.0758,
        0.0150, 0.0558, 0.2038, 0.5171], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,893][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.5943, 0.0008, 0.0010, 0.0010, 0.0044, 0.0047, 0.0025, 0.0019, 0.0560,
        0.0093, 0.0446, 0.0667, 0.2128], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,893][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.2511, 0.0235, 0.0733, 0.0389, 0.0649, 0.0363, 0.0499, 0.0549, 0.0723,
        0.0984, 0.0899, 0.0702, 0.0763], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,894][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([2.2533e-01, 4.8306e-04, 1.9354e-04, 4.4104e-04, 3.5761e-03, 2.6601e-03,
        1.5798e-03, 6.9225e-04, 1.2410e-01, 1.6188e-02, 9.5265e-02, 1.5836e-01,
        3.7114e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,894][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.8172, 0.0040, 0.0053, 0.0041, 0.0176, 0.0091, 0.0045, 0.0128, 0.0237,
        0.0190, 0.0112, 0.0175, 0.0540], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,894][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.8552, 0.0060, 0.0071, 0.0088, 0.0105, 0.0100, 0.0063, 0.0072, 0.0170,
        0.0140, 0.0125, 0.0179, 0.0276], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,895][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.3779, 0.0152, 0.0084, 0.0128, 0.0290, 0.0267, 0.0177, 0.0152, 0.0699,
        0.0421, 0.0656, 0.1191, 0.2004], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,895][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0357, 0.0240, 0.0185, 0.0167, 0.0508, 0.0260, 0.0258, 0.0739, 0.0649,
        0.0521, 0.0688, 0.1660, 0.3768], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:57,895][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0392, 0.0045, 0.0009, 0.0108, 0.0019, 0.0008, 0.1968, 0.0023, 0.0383,
        0.0053, 0.0178, 0.6424, 0.0033, 0.0356], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,896][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0007, 0.0509, 0.0719, 0.0233, 0.2316, 0.0259, 0.0313, 0.1902, 0.0567,
        0.0871, 0.0285, 0.0246, 0.1125, 0.0650], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,896][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1210, 0.0318, 0.0252, 0.0291, 0.1180, 0.0464, 0.0341, 0.0795, 0.0355,
        0.1210, 0.0320, 0.0878, 0.1705, 0.0682], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,897][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0470, 0.0695, 0.0499, 0.0508, 0.0943, 0.0467, 0.0331, 0.0926, 0.0798,
        0.1017, 0.0562, 0.0732, 0.0924, 0.1128], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,898][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([1.7389e-02, 2.7824e-04, 4.4544e-04, 7.0016e-04, 4.9507e-03, 4.9484e-03,
        9.5828e-04, 3.1627e-03, 7.0553e-02, 4.1182e-02, 8.9976e-02, 2.0107e-01,
        5.2503e-01, 3.9358e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,899][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.5869e-01, 3.7749e-04, 1.0037e-03, 6.6951e-04, 4.2520e-03, 5.5480e-03,
        1.3878e-03, 7.9919e-03, 8.5356e-02, 4.1263e-02, 1.0114e-01, 1.1865e-01,
        4.1453e-01, 5.9141e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,901][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1666, 0.0199, 0.0725, 0.0303, 0.0690, 0.0431, 0.0340, 0.0504, 0.0671,
        0.1119, 0.0978, 0.0628, 0.0750, 0.0995], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,901][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.1300e-02, 7.3916e-05, 5.6206e-05, 1.3222e-04, 1.1909e-03, 9.2483e-04,
        2.9861e-04, 1.6777e-03, 1.0920e-01, 3.9708e-02, 8.9980e-02, 1.8700e-01,
        5.0295e-01, 2.5512e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,903][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.4959, 0.0081, 0.0188, 0.0083, 0.0583, 0.0201, 0.0079, 0.0307, 0.0458,
        0.0581, 0.0282, 0.0494, 0.1267, 0.0436], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,904][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.6649, 0.0086, 0.0134, 0.0127, 0.0198, 0.0199, 0.0130, 0.0168, 0.0298,
        0.0354, 0.0287, 0.0465, 0.0644, 0.0261], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,906][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.2421, 0.0117, 0.0108, 0.0127, 0.0334, 0.0258, 0.0163, 0.0216, 0.0680,
        0.0578, 0.0764, 0.1470, 0.1988, 0.0776], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,907][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0220, 0.0188, 0.0230, 0.0139, 0.0538, 0.0309, 0.0186, 0.0566, 0.0517,
        0.0588, 0.0656, 0.1638, 0.3299, 0.0928], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:57,909][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.1072, 0.0045, 0.0008, 0.0125, 0.0020, 0.0007, 0.2596, 0.0015, 0.0354,
        0.0040, 0.0104, 0.5180, 0.0024, 0.0297, 0.0111], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,910][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0035, 0.0546, 0.0497, 0.0238, 0.1407, 0.0367, 0.0477, 0.1383, 0.0751,
        0.0674, 0.0245, 0.0222, 0.0954, 0.0623, 0.1581], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,910][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.4992, 0.0146, 0.0136, 0.0231, 0.0597, 0.0324, 0.0258, 0.0273, 0.0278,
        0.0572, 0.0186, 0.0502, 0.0688, 0.0421, 0.0394], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,911][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.1522, 0.0433, 0.0250, 0.0330, 0.0714, 0.0393, 0.0277, 0.0828, 0.0937,
        0.0734, 0.0413, 0.0493, 0.0582, 0.1061, 0.1035], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,911][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0871, 0.0014, 0.0009, 0.0017, 0.0084, 0.0084, 0.0020, 0.0012, 0.0468,
        0.0119, 0.0359, 0.0924, 0.3471, 0.0238, 0.3310], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,911][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.6552, 0.0008, 0.0008, 0.0007, 0.0037, 0.0032, 0.0015, 0.0016, 0.0329,
        0.0059, 0.0199, 0.0271, 0.1059, 0.0227, 0.1181], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,912][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.4849, 0.0145, 0.0300, 0.0189, 0.0244, 0.0138, 0.0178, 0.0164, 0.0391,
        0.0437, 0.0527, 0.0274, 0.0235, 0.0448, 0.1481], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,912][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([3.1110e-01, 5.9513e-04, 1.4254e-04, 3.2543e-04, 3.5077e-03, 1.6637e-03,
        7.6915e-04, 5.8418e-04, 7.5692e-02, 1.2321e-02, 4.1419e-02, 6.1752e-02,
        2.1443e-01, 2.1491e-02, 2.5421e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,912][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.8947, 0.0017, 0.0021, 0.0017, 0.0067, 0.0039, 0.0018, 0.0043, 0.0107,
        0.0083, 0.0047, 0.0078, 0.0191, 0.0107, 0.0220], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,913][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.8803, 0.0031, 0.0042, 0.0053, 0.0062, 0.0055, 0.0043, 0.0042, 0.0112,
        0.0085, 0.0060, 0.0109, 0.0147, 0.0085, 0.0272], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,913][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.5399, 0.0080, 0.0050, 0.0068, 0.0148, 0.0147, 0.0087, 0.0080, 0.0399,
        0.0212, 0.0287, 0.0513, 0.0835, 0.0426, 0.1268], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,914][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0761, 0.0180, 0.0081, 0.0115, 0.0261, 0.0187, 0.0183, 0.0356, 0.0559,
        0.0413, 0.0411, 0.0967, 0.1889, 0.0896, 0.2742], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:57,914][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1009, 0.0046, 0.0011, 0.0134, 0.0027, 0.0010, 0.2552, 0.0024, 0.0409,
        0.0052, 0.0165, 0.5023, 0.0037, 0.0293, 0.0148, 0.0061],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,916][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0063, 0.0478, 0.0649, 0.0328, 0.1026, 0.0201, 0.0324, 0.0846, 0.0592,
        0.0700, 0.0365, 0.0418, 0.1242, 0.0776, 0.1588, 0.0404],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,918][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2820, 0.0159, 0.0178, 0.0256, 0.0542, 0.0311, 0.0258, 0.0324, 0.0261,
        0.0568, 0.0260, 0.0658, 0.1062, 0.0438, 0.0580, 0.1326],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,919][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1314, 0.0464, 0.0323, 0.0338, 0.0648, 0.0269, 0.0226, 0.0450, 0.0463,
        0.0506, 0.0383, 0.0570, 0.0731, 0.0728, 0.1153, 0.1433],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,920][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([5.4657e-02, 4.4921e-04, 2.1876e-04, 4.7919e-04, 2.2886e-03, 2.2229e-03,
        8.7887e-04, 1.1263e-04, 9.0861e-03, 1.5950e-03, 9.1897e-03, 3.3325e-02,
        9.1871e-02, 3.4405e-03, 9.5703e-02, 6.9448e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,921][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.9259e-01, 8.7651e-04, 7.3527e-04, 6.0578e-04, 2.9248e-03, 2.8277e-03,
        1.4033e-03, 4.4885e-04, 1.3873e-02, 2.2013e-03, 1.1808e-02, 2.4125e-02,
        8.2354e-02, 7.6411e-03, 1.2817e-01, 2.2742e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,923][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.4398, 0.0118, 0.0249, 0.0143, 0.0181, 0.0092, 0.0128, 0.0143, 0.0339,
        0.0383, 0.0453, 0.0341, 0.0405, 0.0505, 0.1316, 0.0806],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,924][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([4.3222e-01, 3.0454e-04, 6.9171e-05, 1.2050e-04, 1.5183e-03, 6.8201e-04,
        3.7687e-04, 5.7052e-05, 9.8623e-03, 1.1235e-03, 8.4283e-03, 2.0601e-02,
        6.4192e-02, 1.9046e-03, 1.0443e-01, 3.5410e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,925][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.8459, 0.0018, 0.0021, 0.0018, 0.0061, 0.0040, 0.0019, 0.0041, 0.0111,
        0.0077, 0.0043, 0.0075, 0.0215, 0.0087, 0.0230, 0.0486],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,927][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.8373, 0.0033, 0.0038, 0.0061, 0.0062, 0.0062, 0.0043, 0.0040, 0.0111,
        0.0089, 0.0080, 0.0110, 0.0186, 0.0092, 0.0216, 0.0405],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,927][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.2920, 0.0067, 0.0044, 0.0065, 0.0120, 0.0103, 0.0063, 0.0047, 0.0267,
        0.0148, 0.0273, 0.0426, 0.0845, 0.0302, 0.1131, 0.3180],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,928][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0659, 0.0132, 0.0096, 0.0085, 0.0233, 0.0118, 0.0115, 0.0232, 0.0336,
        0.0220, 0.0271, 0.0657, 0.1584, 0.0635, 0.3049, 0.1579],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:57,928][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0640, 0.0030, 0.0005, 0.0067, 0.0009, 0.0005, 0.1907, 0.0014, 0.0251,
        0.0027, 0.0113, 0.3855, 0.0019, 0.0199, 0.0071, 0.0033, 0.2755],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,929][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0049, 0.0478, 0.0547, 0.0235, 0.1289, 0.0140, 0.0107, 0.1928, 0.0489,
        0.0765, 0.0313, 0.0196, 0.0952, 0.0552, 0.1355, 0.0325, 0.0281],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,929][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2392, 0.0150, 0.0157, 0.0174, 0.0691, 0.0294, 0.0213, 0.0457, 0.0252,
        0.0571, 0.0214, 0.0612, 0.1132, 0.0433, 0.0484, 0.1110, 0.0664],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,929][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1585, 0.0454, 0.0293, 0.0254, 0.0498, 0.0204, 0.0166, 0.0486, 0.0447,
        0.0552, 0.0360, 0.0568, 0.0621, 0.0662, 0.0940, 0.1374, 0.0535],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,930][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.7857e-02, 6.7033e-04, 6.5050e-04, 6.2591e-04, 5.3822e-03, 3.3777e-03,
        8.7985e-04, 3.9352e-04, 8.0616e-03, 2.7239e-03, 7.0249e-03, 3.0097e-02,
        1.1291e-01, 4.6991e-03, 1.2893e-01, 6.1652e-01, 3.9203e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,930][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4020, 0.0009, 0.0013, 0.0006, 0.0047, 0.0039, 0.0012, 0.0010, 0.0134,
        0.0035, 0.0139, 0.0206, 0.0910, 0.0104, 0.1270, 0.2713, 0.0334],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,931][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5316, 0.0077, 0.0197, 0.0122, 0.0182, 0.0134, 0.0103, 0.0161, 0.0339,
        0.0379, 0.0409, 0.0232, 0.0257, 0.0442, 0.0716, 0.0564, 0.0371],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,931][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.0802e-01, 5.4100e-04, 1.7867e-04, 2.0074e-04, 3.5685e-03, 1.4293e-03,
        6.0309e-04, 2.9193e-04, 1.2665e-02, 3.0891e-03, 9.4765e-03, 2.2304e-02,
        1.4241e-01, 3.8640e-03, 1.4133e-01, 3.8971e-01, 6.0315e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,932][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7353, 0.0026, 0.0041, 0.0025, 0.0131, 0.0051, 0.0024, 0.0087, 0.0146,
        0.0145, 0.0070, 0.0115, 0.0327, 0.0146, 0.0460, 0.0710, 0.0144],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,934][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7736, 0.0031, 0.0047, 0.0052, 0.0070, 0.0079, 0.0051, 0.0059, 0.0124,
        0.0124, 0.0090, 0.0147, 0.0214, 0.0099, 0.0305, 0.0602, 0.0170],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,935][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3199, 0.0061, 0.0048, 0.0057, 0.0136, 0.0110, 0.0064, 0.0075, 0.0239,
        0.0182, 0.0218, 0.0406, 0.0736, 0.0272, 0.0997, 0.2644, 0.0558],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,937][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0392, 0.0110, 0.0083, 0.0073, 0.0206, 0.0134, 0.0104, 0.0302, 0.0276,
        0.0257, 0.0233, 0.0560, 0.1402, 0.0548, 0.2616, 0.1475, 0.1230],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:57,938][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0858, 0.0046, 0.0008, 0.0096, 0.0017, 0.0006, 0.2041, 0.0021, 0.0274,
        0.0040, 0.0109, 0.3674, 0.0024, 0.0223, 0.0085, 0.0035, 0.2376, 0.0067],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,940][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0026, 0.0567, 0.0503, 0.0264, 0.1081, 0.0238, 0.0287, 0.1686, 0.0519,
        0.0529, 0.0240, 0.0195, 0.0655, 0.0650, 0.0895, 0.0290, 0.0384, 0.0991],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,942][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.1515, 0.0199, 0.0149, 0.0257, 0.0549, 0.0385, 0.0238, 0.0433, 0.0286,
        0.0525, 0.0266, 0.0517, 0.0941, 0.0453, 0.0399, 0.0918, 0.0602, 0.1368],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,943][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.1173, 0.0435, 0.0303, 0.0458, 0.0675, 0.0299, 0.0223, 0.0745, 0.0630,
        0.0482, 0.0360, 0.0444, 0.0478, 0.0772, 0.0675, 0.0657, 0.0469, 0.0721],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,944][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([3.5787e-02, 5.2853e-04, 3.2730e-04, 7.3301e-04, 4.3224e-03, 2.6600e-03,
        1.2814e-03, 1.3555e-03, 1.9029e-02, 5.0652e-03, 1.1629e-02, 2.3934e-02,
        9.7277e-02, 1.6174e-02, 8.6107e-02, 4.6857e-01, 4.2522e-02, 1.8270e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,945][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.2941, 0.0008, 0.0007, 0.0006, 0.0032, 0.0028, 0.0015, 0.0023, 0.0260,
        0.0066, 0.0146, 0.0152, 0.0718, 0.0237, 0.0891, 0.1687, 0.0342, 0.2441],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,945][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.2170, 0.0157, 0.0225, 0.0207, 0.0251, 0.0215, 0.0191, 0.0299, 0.0457,
        0.0481, 0.0513, 0.0372, 0.0306, 0.0727, 0.1070, 0.0958, 0.0672, 0.0731],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,946][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([1.9944e-01, 2.5332e-04, 7.0211e-05, 1.4174e-04, 1.5676e-03, 7.6159e-04,
        4.6213e-04, 8.3844e-04, 2.3908e-02, 6.0704e-03, 6.8836e-03, 8.9816e-03,
        6.2096e-02, 9.2285e-03, 5.9834e-02, 1.5795e-01, 3.1042e-02, 4.3047e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,946][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.7495, 0.0025, 0.0030, 0.0028, 0.0077, 0.0048, 0.0027, 0.0070, 0.0158,
        0.0115, 0.0069, 0.0087, 0.0235, 0.0154, 0.0258, 0.0457, 0.0122, 0.0544],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,946][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.7292, 0.0045, 0.0044, 0.0071, 0.0072, 0.0081, 0.0051, 0.0052, 0.0151,
        0.0120, 0.0095, 0.0138, 0.0207, 0.0143, 0.0248, 0.0454, 0.0175, 0.0559],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,947][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.2251, 0.0067, 0.0038, 0.0062, 0.0114, 0.0113, 0.0077, 0.0078, 0.0312,
        0.0167, 0.0270, 0.0409, 0.0644, 0.0374, 0.0802, 0.2233, 0.0639, 0.1350],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,947][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0137, 0.0082, 0.0051, 0.0067, 0.0142, 0.0110, 0.0091, 0.0235, 0.0269,
        0.0208, 0.0272, 0.0514, 0.0994, 0.0515, 0.1891, 0.1363, 0.1104, 0.1955],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:57,948][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0949, 0.0045, 0.0007, 0.0087, 0.0015, 0.0006, 0.1838, 0.0020, 0.0316,
        0.0033, 0.0113, 0.3673, 0.0021, 0.0237, 0.0072, 0.0033, 0.2176, 0.0056,
        0.0303], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,948][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0074, 0.0375, 0.0558, 0.0200, 0.1237, 0.0178, 0.0221, 0.1281, 0.0497,
        0.0606, 0.0201, 0.0200, 0.0829, 0.0486, 0.0939, 0.0267, 0.0367, 0.1103,
        0.0380], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,948][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3394, 0.0117, 0.0111, 0.0166, 0.0513, 0.0211, 0.0161, 0.0271, 0.0187,
        0.0407, 0.0151, 0.0411, 0.0662, 0.0306, 0.0279, 0.0652, 0.0438, 0.0973,
        0.0591], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,950][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1333, 0.0458, 0.0278, 0.0388, 0.0494, 0.0233, 0.0211, 0.0696, 0.0478,
        0.0472, 0.0323, 0.0422, 0.0482, 0.0595, 0.0595, 0.0763, 0.0426, 0.0650,
        0.0702], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,952][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0367, 0.0010, 0.0010, 0.0009, 0.0088, 0.0038, 0.0017, 0.0016, 0.0154,
        0.0077, 0.0115, 0.0211, 0.0971, 0.0108, 0.1117, 0.3668, 0.0323, 0.2118,
        0.0583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,953][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2834, 0.0011, 0.0019, 0.0008, 0.0063, 0.0044, 0.0019, 0.0027, 0.0177,
        0.0065, 0.0134, 0.0126, 0.0687, 0.0171, 0.0972, 0.1443, 0.0248, 0.2483,
        0.0469], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,955][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4429, 0.0073, 0.0248, 0.0113, 0.0233, 0.0105, 0.0106, 0.0154, 0.0304,
        0.0335, 0.0313, 0.0199, 0.0269, 0.0370, 0.0760, 0.0557, 0.0338, 0.0415,
        0.0679], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,956][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.8360e-01, 4.6534e-04, 2.1159e-04, 2.1086e-04, 3.7684e-03, 1.1749e-03,
        6.6442e-04, 1.2174e-03, 1.4947e-02, 5.8803e-03, 7.3950e-03, 8.5324e-03,
        6.4524e-02, 5.9320e-03, 5.8154e-02, 1.2087e-01, 2.2890e-02, 4.5212e-01,
        4.7448e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,957][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6995, 0.0027, 0.0057, 0.0026, 0.0164, 0.0056, 0.0027, 0.0113, 0.0130,
        0.0147, 0.0058, 0.0090, 0.0271, 0.0142, 0.0367, 0.0481, 0.0108, 0.0531,
        0.0211], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,959][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.7840, 0.0035, 0.0054, 0.0056, 0.0074, 0.0064, 0.0046, 0.0047, 0.0093,
        0.0105, 0.0063, 0.0097, 0.0154, 0.0088, 0.0200, 0.0336, 0.0111, 0.0373,
        0.0163], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,961][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2922, 0.0062, 0.0048, 0.0061, 0.0130, 0.0101, 0.0072, 0.0086, 0.0229,
        0.0158, 0.0195, 0.0308, 0.0530, 0.0286, 0.0728, 0.1954, 0.0446, 0.1086,
        0.0597], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,962][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0342, 0.0115, 0.0103, 0.0084, 0.0259, 0.0134, 0.0123, 0.0371, 0.0250,
        0.0255, 0.0200, 0.0383, 0.0966, 0.0467, 0.1644, 0.0995, 0.0873, 0.1640,
        0.0796], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:57,963][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:57,965][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[21880],
        [ 5219],
        [ 2437],
        [ 2355],
        [ 8502],
        [ 2119],
        [  236],
        [  670],
        [  325],
        [  142],
        [  209],
        [   17],
        [    8],
        [  116],
        [  118],
        [  339],
        [   45],
        [   53],
        [   44]], device='cuda:0')
[2024-07-24 10:18:57,966][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21312],
        [ 8541],
        [ 6736],
        [ 5300],
        [12244],
        [ 4280],
        [ 1011],
        [ 1277],
        [ 1583],
        [  942],
        [  987],
        [  165],
        [   49],
        [  826],
        [  860],
        [ 1373],
        [  262],
        [  649],
        [  335]], device='cuda:0')
[2024-07-24 10:18:57,967][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11264],
        [11410],
        [11334],
        [11328],
        [11330],
        [11323],
        [18083],
        [14721],
        [18519],
        [17351],
        [16841],
        [19515],
        [18751],
        [18694],
        [18411],
        [16470],
        [20280],
        [19732],
        [18676]], device='cuda:0')
[2024-07-24 10:18:57,968][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33609],
        [38590],
        [47145],
        [47613],
        [49742],
        [49767],
        [49641],
        [49397],
        [49292],
        [49202],
        [49124],
        [48773],
        [47516],
        [48031],
        [47212],
        [46507],
        [47367],
        [45787],
        [45660]], device='cuda:0')
[2024-07-24 10:18:57,970][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9187],
        [23360],
        [25290],
        [28716],
        [14304],
        [15607],
        [17309],
        [16047],
        [15873],
        [15498],
        [15054],
        [16358],
        [19099],
        [19820],
        [20505],
        [21989],
        [22708],
        [23762],
        [23354]], device='cuda:0')
[2024-07-24 10:18:57,972][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[49589],
        [ 6131],
        [ 8858],
        [ 9362],
        [ 8706],
        [ 5201],
        [ 5935],
        [ 3446],
        [ 3640],
        [ 3076],
        [ 3371],
        [ 3406],
        [ 3067],
        [ 3046],
        [ 3231],
        [ 3208],
        [ 2945],
        [ 2854],
        [ 2983]], device='cuda:0')
[2024-07-24 10:18:57,973][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22400],
        [23564],
        [16183],
        [18688],
        [39281],
        [41372],
        [40763],
        [34612],
        [36732],
        [38411],
        [37255],
        [34088],
        [41314],
        [40962],
        [34712],
        [37134],
        [36613],
        [36571],
        [35467]], device='cuda:0')
[2024-07-24 10:18:57,975][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[9446],
        [9470],
        [6254],
        [6177],
        [3218],
        [3314],
        [3454],
        [5039],
        [7091],
        [7657],
        [4592],
        [4036],
        [6779],
        [7110],
        [6695],
        [8655],
        [9122],
        [7236],
        [7016]], device='cuda:0')
[2024-07-24 10:18:57,977][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21274],
        [13280],
        [34269],
        [33174],
        [39568],
        [40426],
        [36346],
        [36347],
        [35245],
        [27764],
        [30903],
        [27537],
        [25227],
        [25536],
        [34087],
        [33451],
        [29381],
        [29960],
        [30484]], device='cuda:0')
[2024-07-24 10:18:57,978][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[40723],
        [40966],
        [36727],
        [36888],
        [34395],
        [34343],
        [29585],
        [35792],
        [35552],
        [27418],
        [21256],
        [34877],
        [31724],
        [29968],
        [32842],
        [34796],
        [31465],
        [36744],
        [37073]], device='cuda:0')
[2024-07-24 10:18:57,980][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38329],
        [37769],
        [37448],
        [35961],
        [40540],
        [40807],
        [39336],
        [31746],
        [33919],
        [26803],
        [24642],
        [27468],
        [23979],
        [14447],
        [31644],
        [27838],
        [22010],
        [22976],
        [21256]], device='cuda:0')
[2024-07-24 10:18:57,981][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[23232],
        [23595],
        [23715],
        [23664],
        [22698],
        [23240],
        [25082],
        [22887],
        [23301],
        [22986],
        [24685],
        [24761],
        [25099],
        [25608],
        [24179],
        [24602],
        [26875],
        [24938],
        [25045]], device='cuda:0')
[2024-07-24 10:18:57,982][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25902],
        [ 1423],
        [ 1044],
        [ 1538],
        [  594],
        [ 1288],
        [ 1419],
        [ 1651],
        [ 1739],
        [ 1923],
        [ 2065],
        [ 2197],
        [ 2043],
        [ 2140],
        [ 1943],
        [ 2022],
        [ 2060],
        [ 2019],
        [ 1989]], device='cuda:0')
[2024-07-24 10:18:57,983][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[   79],
        [47761],
        [47036],
        [46050],
        [50079],
        [49386],
        [48432],
        [46607],
        [47823],
        [46150],
        [47245],
        [47229],
        [44863],
        [46295],
        [44866],
        [45762],
        [45374],
        [43942],
        [45141]], device='cuda:0')
[2024-07-24 10:18:57,984][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[42805],
        [10394],
        [13990],
        [11808],
        [22523],
        [23157],
        [16153],
        [26020],
        [ 8966],
        [17377],
        [21721],
        [13070],
        [15133],
        [ 9742],
        [13345],
        [18199],
        [18016],
        [10115],
        [ 6009]], device='cuda:0')
[2024-07-24 10:18:57,986][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[2137],
        [ 545],
        [ 436],
        [1745],
        [1104],
        [1654],
        [2796],
        [2698],
        [2912],
        [2852],
        [2870],
        [1496],
        [1460],
        [1466],
        [1505],
        [1543],
        [1912],
        [1889],
        [1888]], device='cuda:0')
[2024-07-24 10:18:57,988][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7492],
        [31744],
        [19356],
        [22892],
        [29214],
        [29639],
        [30513],
        [28079],
        [26110],
        [26119],
        [25712],
        [24930],
        [22061],
        [22864],
        [20023],
        [18521],
        [19979],
        [21787],
        [20737]], device='cuda:0')
[2024-07-24 10:18:57,989][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29390],
        [ 5594],
        [11391],
        [ 8368],
        [ 3903],
        [ 4289],
        [ 4481],
        [ 8123],
        [ 8134],
        [11214],
        [10760],
        [14170],
        [17117],
        [16454],
        [15689],
        [16482],
        [16374],
        [17321],
        [17120]], device='cuda:0')
[2024-07-24 10:18:57,991][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[43693],
        [13597],
        [18291],
        [10040],
        [11849],
        [10537],
        [10538],
        [10973],
        [ 9368],
        [10056],
        [ 8433],
        [ 7719],
        [ 7057],
        [ 7139],
        [ 8010],
        [ 7705],
        [ 7913],
        [ 8433],
        [ 8366]], device='cuda:0')
[2024-07-24 10:18:57,993][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[25953],
        [10151],
        [10117],
        [10212],
        [31345],
        [30634],
        [28297],
        [ 8584],
        [26861],
        [30698],
        [27012],
        [19986],
        [16708],
        [18102],
        [18872],
        [21609],
        [21584],
        [19586],
        [18927]], device='cuda:0')
[2024-07-24 10:18:57,994][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[37986],
        [36914],
        [35781],
        [34455],
        [36430],
        [38499],
        [38936],
        [41969],
        [37351],
        [39574],
        [38468],
        [36959],
        [35186],
        [36118],
        [35988],
        [38382],
        [38758],
        [41202],
        [41260]], device='cuda:0')
[2024-07-24 10:18:57,996][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[21820],
        [19204],
        [21701],
        [26813],
        [18468],
        [17283],
        [12496],
        [12254],
        [12717],
        [ 9793],
        [10253],
        [ 9556],
        [ 9199],
        [ 8873],
        [ 8377],
        [ 7641],
        [ 7304],
        [ 9772],
        [ 9011]], device='cuda:0')
[2024-07-24 10:18:57,997][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10747],
        [ 8271],
        [14590],
        [12429],
        [10135],
        [11751],
        [15730],
        [ 4761],
        [13292],
        [25398],
        [22367],
        [13597],
        [19945],
        [22987],
        [19018],
        [19262],
        [22628],
        [18472],
        [17597]], device='cuda:0')
[2024-07-24 10:18:57,999][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33042],
        [33686],
        [34207],
        [35740],
        [36006],
        [38815],
        [41807],
        [45948],
        [41734],
        [42162],
        [43363],
        [42834],
        [41787],
        [44019],
        [39644],
        [42654],
        [43558],
        [43116],
        [43111]], device='cuda:0')
[2024-07-24 10:18:58,000][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[23116],
        [22956],
        [24632],
        [25258],
        [27813],
        [29682],
        [33008],
        [36434],
        [32067],
        [31954],
        [34563],
        [32965],
        [32271],
        [32274],
        [31955],
        [35879],
        [36535],
        [38223],
        [37630]], device='cuda:0')
[2024-07-24 10:18:58,001][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[33331],
        [23724],
        [28050],
        [25524],
        [29752],
        [25214],
        [24540],
        [18595],
        [18883],
        [18493],
        [20244],
        [20945],
        [18415],
        [19042],
        [24068],
        [16629],
        [17351],
        [17252],
        [18063]], device='cuda:0')
[2024-07-24 10:18:58,002][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23450],
        [49003],
        [41487],
        [41091],
        [36921],
        [36136],
        [39440],
        [35689],
        [35741],
        [35036],
        [36677],
        [37071],
        [43939],
        [43523],
        [27062],
        [26279],
        [26282],
        [32636],
        [32991]], device='cuda:0')
[2024-07-24 10:18:58,004][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18670],
        [32641],
        [30956],
        [33074],
        [30400],
        [30444],
        [24324],
        [28781],
        [26150],
        [22688],
        [21754],
        [25273],
        [26876],
        [24226],
        [31698],
        [29782],
        [26609],
        [24749],
        [26158]], device='cuda:0')
[2024-07-24 10:18:58,005][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4885],
        [34191],
        [28791],
        [33894],
        [17777],
        [17493],
        [29321],
        [20250],
        [41026],
        [27337],
        [22760],
        [36079],
        [32402],
        [40686],
        [32495],
        [29052],
        [29460],
        [36920],
        [43300]], device='cuda:0')
[2024-07-24 10:18:58,007][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402],
        [32402]], device='cuda:0')
[2024-07-24 10:18:58,051][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:58,052][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,054][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,055][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,056][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,058][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,059][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,060][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,061][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,062][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,063][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,063][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,063][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,064][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,064][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3727, 0.6273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,064][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9927, 0.0073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,064][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,065][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5552, 0.4448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,065][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9812, 0.0188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,065][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0070, 0.9930], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,066][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7699, 0.2301], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,066][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4940, 0.5060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,067][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.3033e-04, 9.9987e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,068][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7125, 0.2875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,070][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0731, 0.9269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,071][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.9790, 0.0077, 0.0133], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,073][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0451, 0.2160, 0.7389], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,074][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.9688, 0.0119, 0.0192], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,076][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.8636, 0.0315, 0.1049], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,077][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.5648, 0.2210, 0.2142], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,079][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.8216, 0.0443, 0.1341], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,080][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0033, 0.6298, 0.3669], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,080][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.3581, 0.1710, 0.4709], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,080][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0840, 0.7804, 0.1356], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,081][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([2.6272e-04, 7.2959e-01, 2.7014e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,081][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.4950, 0.1837, 0.3213], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,081][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0302, 0.6744, 0.2954], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,082][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9599, 0.0048, 0.0240, 0.0114], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,082][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0390, 0.1853, 0.5975, 0.1783], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,082][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9404, 0.0128, 0.0341, 0.0126], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,082][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8504, 0.0184, 0.0987, 0.0325], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,083][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3784, 0.2808, 0.1992, 0.1416], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,083][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8334, 0.0384, 0.0840, 0.0441], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,083][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0050, 0.4336, 0.3305, 0.2309], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,084][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1787, 0.1340, 0.5609, 0.1264], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,086][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1659, 0.6965, 0.0608, 0.0767], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,087][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.7564e-04, 4.5696e-01, 2.1943e-01, 3.2344e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,089][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4360, 0.1369, 0.2815, 0.1456], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,090][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0202, 0.4698, 0.3381, 0.1719], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,092][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.9573, 0.0027, 0.0067, 0.0065, 0.0268], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,093][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0453, 0.0993, 0.3958, 0.1033, 0.3563], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,095][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.9698, 0.0038, 0.0089, 0.0037, 0.0137], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,096][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.8258, 0.0016, 0.0051, 0.0051, 0.1624], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,097][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.3752, 0.1253, 0.1734, 0.0767, 0.2494], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,097][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.7313, 0.0216, 0.0627, 0.0281, 0.1564], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,098][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0018, 0.2165, 0.1625, 0.1183, 0.5010], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,098][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.2697, 0.0466, 0.1467, 0.0775, 0.4595], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,098][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.0533, 0.5960, 0.0882, 0.1490, 0.1135], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,099][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([2.0790e-04, 4.7262e-01, 1.5216e-01, 1.8159e-01, 1.9342e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,099][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.4021, 0.0214, 0.0230, 0.0383, 0.5152], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,099][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0054, 0.3914, 0.1622, 0.1046, 0.3364], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,100][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.9313, 0.0020, 0.0113, 0.0049, 0.0252, 0.0253], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,100][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0210, 0.0745, 0.3511, 0.0931, 0.3406, 0.1196], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,100][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.9388, 0.0042, 0.0143, 0.0051, 0.0199, 0.0177], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,101][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([8.3661e-01, 7.0867e-04, 2.1734e-03, 1.4557e-03, 7.6807e-02, 8.2248e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,101][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2958, 0.1305, 0.1717, 0.0900, 0.1150, 0.1969], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,103][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.8100, 0.0138, 0.0291, 0.0157, 0.0687, 0.0627], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,105][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0017, 0.1251, 0.1714, 0.0936, 0.4141, 0.1941], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,106][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.2216, 0.0240, 0.0949, 0.0377, 0.3199, 0.3019], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,108][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0376, 0.4348, 0.0800, 0.0845, 0.0927, 0.2704], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,109][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0003, 0.2336, 0.1671, 0.2132, 0.1208, 0.2651], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,111][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3041, 0.0061, 0.0092, 0.0086, 0.2839, 0.3881], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,112][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0062, 0.1223, 0.1234, 0.0612, 0.3680, 0.3189], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,114][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8600, 0.0036, 0.0184, 0.0085, 0.0547, 0.0452, 0.0096],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,115][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0249, 0.0647, 0.2407, 0.0715, 0.3737, 0.1257, 0.0988],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,115][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.8985, 0.0061, 0.0213, 0.0083, 0.0361, 0.0199, 0.0097],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,115][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.4008, 0.0016, 0.0081, 0.0041, 0.2731, 0.2874, 0.0250],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,116][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3044, 0.1426, 0.1605, 0.0924, 0.0914, 0.1523, 0.0564],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,116][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6960, 0.0191, 0.0467, 0.0253, 0.1111, 0.0759, 0.0258],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,116][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0014, 0.1148, 0.1276, 0.0681, 0.4916, 0.1303, 0.0662],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,117][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1363, 0.0345, 0.1126, 0.0417, 0.2904, 0.2914, 0.0931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,117][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2654, 0.3322, 0.0350, 0.0753, 0.0690, 0.1985, 0.0247],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,117][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.1024e-04, 2.4347e-01, 1.2374e-01, 1.6224e-01, 1.2589e-01, 1.4062e-01,
        2.0393e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,118][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0907, 0.0087, 0.0141, 0.0109, 0.2917, 0.5292, 0.0548],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,118][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0082, 0.0997, 0.1039, 0.0492, 0.3715, 0.2190, 0.1485],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,119][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.8653, 0.0053, 0.0119, 0.0089, 0.0341, 0.0413, 0.0096, 0.0235],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,120][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0211, 0.0900, 0.2441, 0.0730, 0.2316, 0.1085, 0.0880, 0.1436],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,122][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.8714, 0.0075, 0.0183, 0.0095, 0.0321, 0.0236, 0.0135, 0.0240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,123][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([3.7017e-01, 2.1651e-05, 1.2147e-04, 2.9408e-04, 1.0507e-02, 5.8485e-02,
        4.6249e-03, 5.5578e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,124][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0751, 0.1677, 0.1266, 0.0783, 0.0880, 0.1789, 0.0728, 0.2126],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,126][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.6328, 0.0201, 0.0497, 0.0281, 0.0926, 0.0855, 0.0284, 0.0629],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,127][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([2.4810e-04, 1.2652e-01, 1.2762e-01, 6.1611e-02, 4.0355e-01, 1.1233e-01,
        7.2339e-02, 9.5793e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,129][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0756, 0.0090, 0.0214, 0.0160, 0.0948, 0.2172, 0.0557, 0.5102],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,130][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0051, 0.4437, 0.0367, 0.1492, 0.0498, 0.1934, 0.0430, 0.0792],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,131][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([3.3780e-05, 1.9507e-01, 1.4281e-01, 1.4109e-01, 1.3645e-01, 1.3103e-01,
        1.6453e-01, 8.8992e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,132][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([6.7717e-02, 2.1295e-04, 4.7940e-04, 8.7939e-04, 2.4819e-02, 1.4127e-01,
        9.5200e-03, 7.5511e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,132][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0021, 0.0889, 0.0797, 0.0493, 0.2252, 0.1917, 0.1495, 0.2137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,133][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.8960, 0.0027, 0.0156, 0.0047, 0.0289, 0.0217, 0.0036, 0.0126, 0.0142],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,133][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0231, 0.0542, 0.3038, 0.0584, 0.1897, 0.0759, 0.0642, 0.1714, 0.0594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,133][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.8715, 0.0052, 0.0230, 0.0069, 0.0380, 0.0152, 0.0065, 0.0119, 0.0217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,134][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([8.3686e-01, 1.0096e-05, 2.3070e-05, 7.6187e-05, 3.4650e-04, 1.6244e-03,
        4.7088e-04, 3.8782e-04, 1.6020e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,134][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1225, 0.1164, 0.1110, 0.0662, 0.0617, 0.1633, 0.0506, 0.1930, 0.1153],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,134][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.6819, 0.0187, 0.0395, 0.0212, 0.0679, 0.0551, 0.0168, 0.0299, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,135][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0013, 0.0996, 0.1710, 0.0479, 0.4193, 0.0776, 0.0394, 0.0856, 0.0582],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,135][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2361, 0.0125, 0.0332, 0.0215, 0.0654, 0.0777, 0.0327, 0.1687, 0.3521],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,135][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0835, 0.3477, 0.0265, 0.1130, 0.0675, 0.1663, 0.0420, 0.0977, 0.0558],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,136][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([3.1582e-05, 1.4226e-01, 1.5993e-01, 9.9990e-02, 1.2600e-01, 8.7230e-02,
        1.4652e-01, 6.1453e-02, 1.7659e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,137][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([5.1457e-01, 7.6475e-05, 8.1083e-05, 2.5193e-04, 8.5518e-04, 6.2866e-03,
        1.2581e-03, 9.9669e-04, 4.7562e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,139][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0090, 0.0800, 0.0797, 0.0431, 0.2285, 0.1298, 0.1043, 0.2296, 0.0959],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,140][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.7882, 0.0044, 0.0127, 0.0082, 0.0352, 0.0280, 0.0082, 0.0241, 0.0275,
        0.0635], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,142][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0166, 0.0718, 0.1673, 0.0653, 0.1740, 0.0941, 0.0595, 0.1681, 0.0593,
        0.1240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,143][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.8317, 0.0061, 0.0226, 0.0098, 0.0303, 0.0183, 0.0116, 0.0167, 0.0288,
        0.0242], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,144][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([2.3563e-01, 2.1095e-06, 6.1117e-06, 1.9875e-05, 2.5087e-04, 1.5269e-03,
        2.4250e-04, 8.4798e-04, 6.7698e-01, 8.4496e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,146][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0445, 0.1022, 0.0819, 0.0565, 0.0796, 0.1205, 0.0562, 0.1603, 0.1311,
        0.1673], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,148][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.5259, 0.0254, 0.0483, 0.0243, 0.0772, 0.0582, 0.0175, 0.0381, 0.0800,
        0.1051], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,149][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0004, 0.0774, 0.1009, 0.0507, 0.2880, 0.0907, 0.0580, 0.0796, 0.0849,
        0.1694], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,149][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0631, 0.0041, 0.0104, 0.0065, 0.0364, 0.0586, 0.0200, 0.1220, 0.3462,
        0.3327], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,150][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0081, 0.2485, 0.0395, 0.1267, 0.0740, 0.1778, 0.0763, 0.1214, 0.0597,
        0.0679], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,150][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([3.2691e-05, 1.2517e-01, 1.0772e-01, 7.6126e-02, 8.0865e-02, 1.0169e-01,
        1.1605e-01, 7.7350e-02, 1.7466e-01, 1.4034e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,150][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([4.4849e-02, 1.2280e-05, 1.0185e-05, 4.4544e-05, 2.8829e-04, 2.6061e-03,
        3.5383e-04, 1.2284e-03, 8.5282e-01, 9.7784e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,151][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0029, 0.0968, 0.0721, 0.0411, 0.2053, 0.1104, 0.1046, 0.1532, 0.0714,
        0.1423], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,151][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8190, 0.0029, 0.0088, 0.0042, 0.0273, 0.0187, 0.0035, 0.0156, 0.0157,
        0.0520, 0.0322], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,151][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0182, 0.0466, 0.1769, 0.0462, 0.1334, 0.0714, 0.0518, 0.1546, 0.0537,
        0.1052, 0.1420], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,152][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.8389, 0.0044, 0.0194, 0.0057, 0.0296, 0.0130, 0.0065, 0.0105, 0.0255,
        0.0182, 0.0282], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,152][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([8.1494e-01, 2.4119e-05, 4.0077e-05, 8.9748e-05, 7.9230e-04, 2.4429e-03,
        7.1275e-04, 2.2439e-04, 5.8829e-02, 9.4579e-03, 1.1245e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,153][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0747, 0.1183, 0.0521, 0.0499, 0.0338, 0.1016, 0.0594, 0.1272, 0.1135,
        0.1351, 0.1344], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,153][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.5342, 0.0169, 0.0316, 0.0206, 0.0571, 0.0501, 0.0144, 0.0245, 0.0547,
        0.0556, 0.1403], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,155][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0017, 0.0568, 0.0955, 0.0376, 0.3207, 0.0716, 0.0360, 0.0759, 0.0672,
        0.1708, 0.0661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,157][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.1375, 0.0094, 0.0185, 0.0126, 0.0488, 0.0580, 0.0216, 0.1023, 0.1672,
        0.2420, 0.1821], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,158][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0283, 0.3566, 0.0339, 0.0894, 0.0938, 0.1195, 0.0321, 0.1220, 0.0265,
        0.0637, 0.0344], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,159][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([3.0130e-05, 9.2637e-02, 9.4620e-02, 7.1816e-02, 8.4199e-02, 7.1983e-02,
        8.8452e-02, 4.8656e-02, 1.5791e-01, 1.4069e-01, 1.4900e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,160][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([3.4704e-01, 1.9284e-04, 1.4577e-04, 2.8924e-04, 1.9156e-03, 9.6625e-03,
        2.1224e-03, 9.1484e-04, 1.9038e-01, 2.9330e-02, 4.1800e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,162][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0074, 0.0631, 0.0559, 0.0299, 0.2197, 0.1139, 0.0892, 0.1577, 0.0733,
        0.1135, 0.0764], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,163][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.9248, 0.0011, 0.0041, 0.0019, 0.0106, 0.0061, 0.0013, 0.0043, 0.0065,
        0.0150, 0.0134, 0.0109], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,165][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0283, 0.0343, 0.1366, 0.0528, 0.1196, 0.0568, 0.0397, 0.1056, 0.0554,
        0.1266, 0.1291, 0.1152], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,167][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.8722, 0.0029, 0.0106, 0.0045, 0.0193, 0.0077, 0.0041, 0.0051, 0.0165,
        0.0125, 0.0217, 0.0229], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,167][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.3780e-01, 1.7349e-05, 1.9715e-05, 4.4903e-05, 3.4929e-04, 6.9451e-04,
        3.1958e-04, 2.0417e-05, 5.5716e-03, 5.9694e-04, 1.4965e-02, 3.9596e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,167][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1772, 0.0720, 0.0568, 0.0397, 0.0281, 0.0803, 0.0308, 0.1257, 0.0852,
        0.0954, 0.1401, 0.0686], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,168][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.6698, 0.0100, 0.0176, 0.0127, 0.0309, 0.0247, 0.0090, 0.0138, 0.0374,
        0.0366, 0.0739, 0.0636], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,168][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0018, 0.0658, 0.0982, 0.0422, 0.2298, 0.0632, 0.0288, 0.0594, 0.0592,
        0.1674, 0.0706, 0.1136], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,168][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2272, 0.0050, 0.0105, 0.0086, 0.0303, 0.0321, 0.0111, 0.0366, 0.0898,
        0.1062, 0.0817, 0.3610], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,169][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2713, 0.2677, 0.0189, 0.0479, 0.0455, 0.1177, 0.0138, 0.0797, 0.0238,
        0.0720, 0.0344, 0.0071], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,169][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([3.8883e-05, 7.6727e-02, 7.8376e-02, 7.0686e-02, 5.9104e-02, 6.2346e-02,
        7.4072e-02, 3.6630e-02, 1.4537e-01, 1.0156e-01, 1.5184e-01, 1.4325e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,170][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([5.4239e-01, 1.7169e-04, 1.0502e-04, 2.0663e-04, 9.7637e-04, 4.6110e-03,
        1.1436e-03, 1.1721e-04, 3.5781e-02, 2.8364e-03, 1.0663e-01, 3.0503e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,170][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0149, 0.0637, 0.0453, 0.0328, 0.1168, 0.0892, 0.0572, 0.1269, 0.0740,
        0.1741, 0.0964, 0.1088], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,170][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ station] are: tensor([9.1493e-01, 7.5324e-04, 1.6801e-03, 1.5559e-03, 5.8248e-03, 3.8532e-03,
        1.1627e-03, 3.6420e-03, 5.9895e-03, 1.1806e-02, 1.0581e-02, 8.4305e-03,
        2.9793e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,172][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0129, 0.0441, 0.1413, 0.0535, 0.1424, 0.0550, 0.0476, 0.0775, 0.0490,
        0.0744, 0.0793, 0.0815, 0.1414], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,174][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.9399, 0.0013, 0.0042, 0.0023, 0.0050, 0.0030, 0.0020, 0.0022, 0.0076,
        0.0051, 0.0089, 0.0091, 0.0096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,174][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ station] are: tensor([7.5992e-01, 3.1127e-06, 3.5116e-06, 1.7461e-05, 1.2436e-04, 3.7526e-04,
        1.0249e-04, 4.2312e-05, 3.6983e-02, 2.4795e-03, 2.6044e-02, 5.9855e-02,
        1.1405e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,176][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0600, 0.0769, 0.0470, 0.0411, 0.0550, 0.0799, 0.0422, 0.1055, 0.1048,
        0.0826, 0.1471, 0.0732, 0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,177][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.6653, 0.0064, 0.0156, 0.0087, 0.0287, 0.0154, 0.0060, 0.0096, 0.0272,
        0.0313, 0.0468, 0.0393, 0.0996], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,179][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0008, 0.0685, 0.0698, 0.0534, 0.1800, 0.0710, 0.0489, 0.0515, 0.0715,
        0.1139, 0.0786, 0.1032, 0.0889], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,181][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1214, 0.0008, 0.0016, 0.0017, 0.0068, 0.0071, 0.0029, 0.0093, 0.0486,
        0.0385, 0.0367, 0.1665, 0.5584], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,183][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0762, 0.2346, 0.0287, 0.0426, 0.0687, 0.1588, 0.0315, 0.0853, 0.0222,
        0.1131, 0.0281, 0.0191, 0.0910], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,183][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ station] are: tensor([4.2265e-05, 9.6738e-02, 5.1947e-02, 8.5139e-02, 3.8031e-02, 6.4254e-02,
        8.9049e-02, 3.4389e-02, 1.4173e-01, 1.1361e-01, 1.4897e-01, 9.4704e-02,
        4.1386e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,184][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ station] are: tensor([1.4333e-01, 2.4722e-05, 1.6542e-05, 4.9388e-05, 2.6281e-04, 1.1545e-03,
        3.1617e-04, 1.2448e-04, 8.3208e-02, 5.3955e-03, 8.1397e-02, 2.2027e-01,
        4.6445e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,184][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0042, 0.0669, 0.0340, 0.0281, 0.1020, 0.1121, 0.0904, 0.1121, 0.0673,
        0.0767, 0.0723, 0.0963, 0.1375], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,185][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.7805, 0.0026, 0.0104, 0.0028, 0.0291, 0.0140, 0.0022, 0.0079, 0.0101,
        0.0262, 0.0162, 0.0162, 0.0650, 0.0167], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,185][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0204, 0.0264, 0.1429, 0.0314, 0.1211, 0.0472, 0.0360, 0.0929, 0.0358,
        0.0842, 0.0781, 0.0742, 0.1482, 0.0611], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,186][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.7650, 0.0053, 0.0221, 0.0057, 0.0365, 0.0136, 0.0053, 0.0083, 0.0194,
        0.0206, 0.0230, 0.0235, 0.0381, 0.0134], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,186][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.1877e-01, 1.5811e-06, 5.1566e-06, 1.3406e-05, 1.1636e-04, 4.0054e-04,
        6.2501e-05, 4.8851e-04, 9.4557e-02, 2.2551e-02, 9.9155e-02, 1.9710e-01,
        4.3933e-01, 2.7446e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,186][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0654, 0.0761, 0.0520, 0.0417, 0.0456, 0.0770, 0.0298, 0.0866, 0.0755,
        0.0730, 0.1075, 0.0601, 0.0774, 0.1322], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,187][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.4587, 0.0102, 0.0215, 0.0130, 0.0446, 0.0308, 0.0096, 0.0191, 0.0468,
        0.0470, 0.0901, 0.0628, 0.1301, 0.0159], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,187][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0007, 0.0600, 0.1052, 0.0321, 0.2705, 0.0546, 0.0291, 0.0401, 0.0383,
        0.1042, 0.0416, 0.0749, 0.1034, 0.0454], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,188][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0159, 0.0007, 0.0017, 0.0011, 0.0046, 0.0051, 0.0021, 0.0120, 0.0341,
        0.0572, 0.0370, 0.1685, 0.6284, 0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,189][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0295, 0.3296, 0.0197, 0.0703, 0.0578, 0.1210, 0.0259, 0.0586, 0.0303,
        0.0526, 0.0396, 0.0169, 0.0562, 0.0922], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,190][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([2.0489e-05, 7.6967e-02, 7.5539e-02, 5.7277e-02, 8.1186e-02, 6.0838e-02,
        8.8330e-02, 3.5448e-02, 1.1032e-01, 9.5957e-02, 1.1181e-01, 9.2142e-02,
        4.0006e-02, 7.4158e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,191][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.1765e-02, 5.1266e-06, 6.5543e-06, 1.5341e-05, 1.0073e-04, 5.6359e-04,
        8.0412e-05, 3.7129e-04, 8.1882e-02, 2.0185e-02, 8.6678e-02, 2.5536e-01,
        5.2162e-01, 2.1371e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,193][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0075, 0.0468, 0.0395, 0.0237, 0.1163, 0.0851, 0.0531, 0.1128, 0.0596,
        0.1047, 0.0647, 0.0812, 0.1343, 0.0705], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,194][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([9.6894e-01, 3.6199e-04, 6.9847e-04, 4.4410e-04, 1.6986e-03, 1.3431e-03,
        2.8982e-04, 7.6110e-04, 2.2709e-03, 3.0924e-03, 2.4114e-03, 2.1448e-03,
        6.8133e-03, 1.7851e-03, 6.9412e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,195][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0420, 0.0308, 0.1138, 0.0385, 0.0796, 0.0404, 0.0290, 0.0490, 0.0353,
        0.0564, 0.0700, 0.0487, 0.0934, 0.0414, 0.2316], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,196][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([9.6798e-01, 4.5292e-04, 1.2699e-03, 8.2491e-04, 1.6807e-03, 1.2232e-03,
        7.7834e-04, 6.7238e-04, 3.7610e-03, 1.7378e-03, 2.9518e-03, 3.5834e-03,
        2.8879e-03, 1.6484e-03, 8.5430e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,198][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([8.5006e-01, 3.0778e-06, 3.5721e-06, 1.1263e-05, 9.0896e-05, 1.4191e-04,
        4.1303e-05, 2.3056e-05, 1.4298e-02, 9.2435e-04, 6.9600e-03, 1.1211e-02,
        3.9623e-02, 5.1175e-03, 7.1489e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,199][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.2729, 0.0252, 0.0298, 0.0199, 0.0285, 0.0393, 0.0178, 0.0635, 0.0717,
        0.0513, 0.0996, 0.0504, 0.0376, 0.0890, 0.1035], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,201][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.7845, 0.0032, 0.0083, 0.0044, 0.0185, 0.0086, 0.0028, 0.0032, 0.0168,
        0.0106, 0.0242, 0.0200, 0.0421, 0.0056, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,201][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0013, 0.0351, 0.0444, 0.0308, 0.1557, 0.0514, 0.0260, 0.0213, 0.0454,
        0.0851, 0.0434, 0.0752, 0.0723, 0.0407, 0.2719], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,202][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.2010, 0.0005, 0.0009, 0.0011, 0.0030, 0.0026, 0.0014, 0.0037, 0.0278,
        0.0223, 0.0182, 0.0809, 0.2353, 0.0212, 0.3803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,202][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0477, 0.1414, 0.0254, 0.0936, 0.0362, 0.1868, 0.0393, 0.0891, 0.0504,
        0.0475, 0.0657, 0.0249, 0.0596, 0.0696, 0.0228], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,202][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([9.1833e-05, 5.4003e-02, 4.9556e-02, 5.8046e-02, 2.2698e-02, 8.9757e-02,
        5.5299e-02, 2.6791e-02, 1.2463e-01, 6.5963e-02, 1.1221e-01, 8.5786e-02,
        3.4619e-02, 5.7213e-02, 1.6333e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,203][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([2.3792e-01, 3.1838e-05, 9.1958e-06, 4.4029e-05, 1.6124e-04, 6.2801e-04,
        2.0967e-04, 1.1097e-04, 5.7075e-02, 2.9667e-03, 3.6154e-02, 9.1049e-02,
        2.3575e-01, 1.3706e-02, 3.2418e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,203][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0226, 0.0569, 0.0278, 0.0214, 0.0578, 0.0743, 0.0785, 0.0738, 0.0679,
        0.0942, 0.0569, 0.0821, 0.1015, 0.0811, 0.1033], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,204][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.1594e-01, 2.8542e-04, 8.0641e-04, 5.4556e-04, 2.2466e-03, 1.5583e-03,
        3.7767e-04, 1.0099e-03, 2.9398e-03, 4.6342e-03, 3.5832e-03, 3.7962e-03,
        1.2216e-02, 2.7888e-03, 1.3752e-02, 3.3520e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,204][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0311, 0.0266, 0.0817, 0.0377, 0.0403, 0.0314, 0.0282, 0.0326, 0.0359,
        0.0416, 0.0665, 0.0663, 0.1116, 0.0444, 0.1740, 0.1500],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,204][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([9.4963e-01, 3.9078e-04, 1.6984e-03, 7.4587e-04, 2.8399e-03, 1.2558e-03,
        5.7032e-04, 6.0421e-04, 3.0720e-03, 1.4722e-03, 2.7633e-03, 3.8648e-03,
        4.3008e-03, 1.6748e-03, 1.0707e-02, 1.4413e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,205][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.8324e-01, 4.8882e-07, 3.6189e-07, 1.6368e-06, 1.0825e-05, 1.9206e-05,
        8.0070e-06, 5.2267e-07, 6.6220e-04, 2.4365e-05, 8.1137e-04, 2.8136e-03,
        5.5835e-03, 2.1521e-04, 1.3315e-02, 9.3289e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,207][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1402, 0.0321, 0.0307, 0.0228, 0.0212, 0.0334, 0.0154, 0.0601, 0.0553,
        0.0592, 0.0872, 0.0548, 0.0594, 0.0861, 0.1031, 0.1391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,208][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.7342, 0.0037, 0.0071, 0.0050, 0.0118, 0.0083, 0.0029, 0.0035, 0.0144,
        0.0112, 0.0243, 0.0246, 0.0478, 0.0056, 0.0372, 0.0584],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,210][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0021, 0.0299, 0.0521, 0.0233, 0.1017, 0.0300, 0.0175, 0.0200, 0.0371,
        0.0733, 0.0368, 0.0718, 0.0851, 0.0343, 0.2316, 0.1535],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,211][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.0142e-01, 2.7413e-04, 4.8231e-04, 5.2858e-04, 1.5399e-03, 1.1078e-03,
        6.3872e-04, 1.2538e-03, 1.0049e-02, 7.1579e-03, 7.1404e-03, 3.7378e-02,
        1.3603e-01, 7.4783e-03, 2.7694e-01, 4.1058e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,212][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0736, 0.2110, 0.0423, 0.1057, 0.0449, 0.0972, 0.0235, 0.0649, 0.0209,
        0.0479, 0.0526, 0.0217, 0.0437, 0.0509, 0.0440, 0.0555],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,213][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.8358e-05, 4.7271e-02, 4.8558e-02, 5.4611e-02, 4.2243e-02, 5.8928e-02,
        6.6046e-02, 2.2556e-02, 1.1656e-01, 7.4312e-02, 1.1402e-01, 1.1051e-01,
        3.5703e-02, 6.2659e-02, 1.1260e-01, 3.3321e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,214][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([1.6337e-01, 3.5700e-06, 1.4093e-06, 7.0080e-06, 2.1879e-05, 7.5472e-05,
        3.0881e-05, 2.0436e-06, 2.7259e-03, 8.0527e-05, 3.2604e-03, 1.2970e-02,
        2.4483e-02, 4.5330e-04, 6.6738e-02, 7.2577e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,216][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0125, 0.0636, 0.0243, 0.0214, 0.0524, 0.0577, 0.0515, 0.0662, 0.0513,
        0.0621, 0.0477, 0.0849, 0.1057, 0.1000, 0.0860, 0.1129],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,217][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.3727e-01, 2.1402e-04, 6.3451e-04, 4.0890e-04, 1.9569e-03, 1.3248e-03,
        2.5387e-04, 7.7649e-04, 1.9791e-03, 3.6976e-03, 2.7886e-03, 2.9199e-03,
        1.0979e-02, 2.1677e-03, 9.9121e-03, 2.0354e-02, 2.3591e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,219][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0286, 0.0131, 0.0544, 0.0192, 0.0660, 0.0209, 0.0163, 0.0529, 0.0286,
        0.0664, 0.0460, 0.0513, 0.1209, 0.0367, 0.1872, 0.1326, 0.0588],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,219][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.1904e-01, 4.7794e-04, 2.2942e-03, 1.0280e-03, 3.7976e-03, 1.6269e-03,
        7.5505e-04, 8.1249e-04, 4.1682e-03, 2.7044e-03, 5.1370e-03, 5.2459e-03,
        5.6062e-03, 2.2720e-03, 1.8945e-02, 2.0858e-02, 5.2274e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,219][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([6.3661e-01, 3.4340e-06, 4.0536e-06, 9.1175e-06, 1.0302e-04, 1.4332e-04,
        3.8787e-05, 1.6480e-05, 1.7924e-03, 2.2541e-04, 1.7868e-03, 5.8527e-03,
        3.1219e-02, 1.1677e-03, 3.7193e-02, 2.6473e-01, 1.9108e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,220][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2363, 0.0310, 0.0312, 0.0260, 0.0168, 0.0267, 0.0124, 0.0560, 0.0550,
        0.0611, 0.0760, 0.0457, 0.0409, 0.0724, 0.0919, 0.0809, 0.0396],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,220][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7533, 0.0029, 0.0066, 0.0043, 0.0131, 0.0074, 0.0031, 0.0039, 0.0126,
        0.0102, 0.0224, 0.0204, 0.0430, 0.0045, 0.0337, 0.0409, 0.0178],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,221][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0018, 0.0257, 0.0385, 0.0169, 0.1041, 0.0223, 0.0110, 0.0222, 0.0264,
        0.0777, 0.0294, 0.0676, 0.0770, 0.0269, 0.2383, 0.1212, 0.0929],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,221][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([7.1412e-02, 3.3785e-04, 8.5586e-04, 6.3087e-04, 2.1274e-03, 1.5976e-03,
        7.2074e-04, 2.6159e-03, 8.7320e-03, 9.1328e-03, 6.4718e-03, 3.2146e-02,
        1.3926e-01, 8.7834e-03, 2.9443e-01, 3.5555e-01, 6.5189e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,222][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3067, 0.1740, 0.0183, 0.0396, 0.0321, 0.0840, 0.0113, 0.0430, 0.0205,
        0.0473, 0.0246, 0.0071, 0.0487, 0.0742, 0.0209, 0.0342, 0.0137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,222][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([5.3641e-05, 4.6416e-02, 3.0073e-02, 4.0525e-02, 3.3694e-02, 3.2908e-02,
        4.2390e-02, 2.2541e-02, 1.0509e-01, 7.2562e-02, 1.1902e-01, 1.1534e-01,
        3.8150e-02, 6.6488e-02, 1.0470e-01, 2.7244e-02, 1.0281e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,222][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.3475e-02, 1.1382e-05, 5.5254e-06, 1.1158e-05, 7.8406e-05, 1.9107e-04,
        5.1097e-05, 1.3551e-05, 3.1584e-03, 2.7482e-04, 3.3337e-03, 1.1049e-02,
        3.5894e-02, 1.0258e-03, 8.0075e-02, 7.7159e-01, 3.9760e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,224][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0201, 0.0355, 0.0264, 0.0189, 0.0765, 0.0520, 0.0382, 0.0832, 0.0525,
        0.1010, 0.0534, 0.0697, 0.1015, 0.0594, 0.0827, 0.0719, 0.0570],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,225][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([7.9757e-01, 7.8419e-04, 1.2846e-03, 2.0828e-03, 4.3198e-03, 4.2812e-03,
        1.0474e-03, 2.1809e-03, 6.4237e-03, 8.2864e-03, 9.2821e-03, 7.3323e-03,
        1.8988e-02, 8.4805e-03, 1.5457e-02, 4.3801e-02, 8.1321e-03, 6.0269e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,227][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0155, 0.0307, 0.0818, 0.0302, 0.0628, 0.0292, 0.0282, 0.0384, 0.0299,
        0.0387, 0.0570, 0.0506, 0.0874, 0.0452, 0.1499, 0.1073, 0.0584, 0.0589],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,228][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.8964, 0.0012, 0.0036, 0.0026, 0.0054, 0.0025, 0.0019, 0.0017, 0.0066,
        0.0035, 0.0054, 0.0067, 0.0061, 0.0039, 0.0135, 0.0175, 0.0070, 0.0144],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,229][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([4.9886e-01, 6.1367e-06, 6.2985e-06, 2.1803e-05, 1.9057e-04, 2.4460e-04,
        7.9353e-05, 1.4755e-04, 1.7159e-02, 2.0615e-03, 4.3989e-03, 5.1866e-03,
        3.4482e-02, 9.0906e-03, 4.9712e-02, 2.0836e-01, 2.0756e-02, 1.4924e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,231][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0612, 0.0483, 0.0281, 0.0268, 0.0256, 0.0389, 0.0218, 0.0710, 0.0614,
        0.0546, 0.0787, 0.0472, 0.0414, 0.0821, 0.0866, 0.0891, 0.0777, 0.0594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,233][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.5585, 0.0062, 0.0086, 0.0068, 0.0188, 0.0120, 0.0045, 0.0063, 0.0194,
        0.0163, 0.0295, 0.0237, 0.0519, 0.0078, 0.0374, 0.0485, 0.0220, 0.1217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,235][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0008, 0.0437, 0.0306, 0.0244, 0.0657, 0.0365, 0.0232, 0.0250, 0.0415,
        0.0609, 0.0403, 0.0616, 0.0484, 0.0381, 0.1393, 0.1053, 0.1162, 0.0985],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,236][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0419, 0.0003, 0.0006, 0.0006, 0.0017, 0.0020, 0.0011, 0.0040, 0.0122,
        0.0119, 0.0084, 0.0316, 0.1166, 0.0134, 0.2000, 0.2829, 0.0761, 0.1948],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,236][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0245, 0.1978, 0.0384, 0.0430, 0.0385, 0.0991, 0.0341, 0.0455, 0.0330,
        0.0491, 0.0382, 0.0403, 0.0483, 0.0501, 0.0425, 0.0594, 0.0392, 0.0791],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,237][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([3.0047e-05, 7.0696e-02, 3.4563e-02, 5.6900e-02, 2.5985e-02, 5.0016e-02,
        6.9962e-02, 2.8959e-02, 1.0563e-01, 6.6039e-02, 1.1326e-01, 7.3885e-02,
        2.2232e-02, 6.4877e-02, 6.5694e-02, 2.3931e-02, 1.0398e-01, 2.3359e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,237][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([1.8298e-02, 1.4709e-05, 7.2611e-06, 1.8357e-05, 1.5272e-04, 2.6839e-04,
        8.7102e-05, 9.5779e-05, 1.2357e-02, 1.3503e-03, 5.1012e-03, 9.2910e-03,
        4.7176e-02, 5.9069e-03, 9.1197e-02, 5.5854e-01, 4.0611e-02, 2.0953e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,237][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0051, 0.0572, 0.0217, 0.0209, 0.0496, 0.0690, 0.0582, 0.0839, 0.0501,
        0.0608, 0.0467, 0.0767, 0.0756, 0.0795, 0.0686, 0.0738, 0.0548, 0.0479],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,238][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.6519e-01, 5.0767e-04, 1.5435e-03, 7.9764e-04, 3.9269e-03, 2.8043e-03,
        4.9224e-04, 1.3632e-03, 2.6646e-03, 5.1370e-03, 4.1175e-03, 3.8612e-03,
        1.2599e-02, 3.4646e-03, 1.1664e-02, 2.4798e-02, 3.7728e-03, 3.6329e-02,
        1.4966e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,238][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0378, 0.0181, 0.0743, 0.0252, 0.0541, 0.0229, 0.0210, 0.0348, 0.0255,
        0.0523, 0.0499, 0.0484, 0.0971, 0.0340, 0.1533, 0.0937, 0.0505, 0.0637,
        0.0434], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,239][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.0308e-01, 7.6842e-04, 3.8352e-03, 1.3135e-03, 5.8542e-03, 1.9575e-03,
        1.0973e-03, 1.2319e-03, 3.9849e-03, 2.7191e-03, 4.3226e-03, 4.7404e-03,
        5.9621e-03, 2.4171e-03, 1.4174e-02, 1.6235e-02, 4.9110e-03, 1.2401e-02,
        8.9994e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,239][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.7988e-01, 2.0329e-05, 3.0576e-05, 4.4922e-05, 5.8263e-04, 5.0014e-04,
        1.7330e-04, 2.1478e-04, 8.4260e-03, 1.8228e-03, 4.3679e-03, 4.6969e-03,
        3.7205e-02, 5.6964e-03, 5.3995e-02, 1.7654e-01, 1.9292e-02, 1.7647e-01,
        3.0045e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,240][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1585, 0.0362, 0.0296, 0.0248, 0.0204, 0.0346, 0.0174, 0.0551, 0.0478,
        0.0472, 0.0638, 0.0418, 0.0411, 0.0639, 0.0657, 0.0728, 0.0505, 0.0603,
        0.0684], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,242][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6365, 0.0038, 0.0083, 0.0052, 0.0143, 0.0090, 0.0031, 0.0044, 0.0140,
        0.0129, 0.0246, 0.0178, 0.0411, 0.0050, 0.0348, 0.0356, 0.0153, 0.0860,
        0.0284], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,243][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0022, 0.0300, 0.0447, 0.0177, 0.0914, 0.0243, 0.0134, 0.0144, 0.0243,
        0.0490, 0.0261, 0.0482, 0.0486, 0.0239, 0.1821, 0.1102, 0.0834, 0.0934,
        0.0724], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,245][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0683, 0.0005, 0.0011, 0.0008, 0.0035, 0.0020, 0.0011, 0.0044, 0.0110,
        0.0131, 0.0073, 0.0261, 0.1234, 0.0115, 0.1817, 0.2333, 0.0494, 0.1965,
        0.0652], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,246][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0801, 0.1461, 0.0239, 0.0468, 0.0476, 0.1151, 0.0212, 0.0404, 0.0216,
        0.0491, 0.0338, 0.0164, 0.0633, 0.0397, 0.0294, 0.0612, 0.0286, 0.0942,
        0.0415], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,248][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.7637e-05, 5.8842e-02, 4.0524e-02, 3.9950e-02, 3.3178e-02, 3.8666e-02,
        5.3939e-02, 2.1087e-02, 8.8359e-02, 6.2903e-02, 8.1115e-02, 9.3004e-02,
        2.8243e-02, 5.3502e-02, 8.8364e-02, 2.6133e-02, 1.0555e-01, 2.7333e-02,
        5.9208e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,249][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.9393e-02, 3.5843e-05, 2.1761e-05, 3.4054e-05, 2.7010e-04, 4.8858e-04,
        1.4473e-04, 1.6556e-04, 8.2978e-03, 1.4199e-03, 5.0291e-03, 8.0511e-03,
        4.9957e-02, 3.5628e-03, 7.8357e-02, 4.4718e-01, 2.8124e-02, 2.4579e-01,
        5.3677e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,250][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0259, 0.0452, 0.0235, 0.0187, 0.0553, 0.0454, 0.0374, 0.0639, 0.0476,
        0.0714, 0.0406, 0.0622, 0.0907, 0.0594, 0.0733, 0.0678, 0.0535, 0.0521,
        0.0661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,294][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:58,295][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,295][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,295][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,296][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,296][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,296][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,297][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,297][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,299][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,300][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,301][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,302][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,304][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,305][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3727, 0.6273], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,307][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9927, 0.0073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,309][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,310][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5552, 0.4448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,310][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9812, 0.0188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,311][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0070, 0.9930], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,311][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7699, 0.2301], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,311][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9794, 0.0206], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,311][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.3033e-04, 9.9987e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,312][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7125, 0.2875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,312][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0731, 0.9269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,312][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.9790, 0.0077, 0.0133], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,313][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0451, 0.2160, 0.7389], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,313][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.9688, 0.0119, 0.0192], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,313][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.8636, 0.0315, 0.1049], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,313][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.5648, 0.2210, 0.2142], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,314][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.8216, 0.0443, 0.1341], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,314][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0033, 0.6298, 0.3669], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,314][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.3581, 0.1710, 0.4709], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,316][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.8814, 0.0501, 0.0685], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,317][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([2.6272e-04, 7.2959e-01, 2.7014e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,319][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.4950, 0.1837, 0.3213], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,320][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0302, 0.6744, 0.2954], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,321][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9599, 0.0048, 0.0240, 0.0114], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,323][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0390, 0.1853, 0.5975, 0.1783], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,325][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9404, 0.0128, 0.0341, 0.0126], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,326][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8504, 0.0184, 0.0987, 0.0325], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,328][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3784, 0.2808, 0.1992, 0.1416], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,328][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8334, 0.0384, 0.0840, 0.0441], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,328][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0050, 0.4336, 0.3305, 0.2309], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,328][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1787, 0.1340, 0.5609, 0.1264], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,329][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8512, 0.0403, 0.0615, 0.0470], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,329][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.7564e-04, 4.5696e-01, 2.1943e-01, 3.2344e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,329][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4360, 0.1369, 0.2815, 0.1456], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,330][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0202, 0.4698, 0.3381, 0.1719], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,330][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.9573, 0.0027, 0.0067, 0.0065, 0.0268], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,330][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0453, 0.0993, 0.3958, 0.1033, 0.3563], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,330][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.9698, 0.0038, 0.0089, 0.0037, 0.0137], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,331][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.8258, 0.0016, 0.0051, 0.0051, 0.1624], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,331][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.3752, 0.1253, 0.1734, 0.0767, 0.2494], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,331][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.7313, 0.0216, 0.0627, 0.0281, 0.1564], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,332][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.0018, 0.2165, 0.1625, 0.1183, 0.5010], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,334][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.2697, 0.0466, 0.1467, 0.0775, 0.4595], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,335][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.7783, 0.0399, 0.0453, 0.0465, 0.0899], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,336][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([2.0790e-04, 4.7262e-01, 1.5216e-01, 1.8159e-01, 1.9342e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,337][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.4021, 0.0214, 0.0230, 0.0383, 0.5152], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,338][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.0054, 0.3914, 0.1622, 0.1046, 0.3364], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,340][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.9313, 0.0020, 0.0113, 0.0049, 0.0252, 0.0253], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,342][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0210, 0.0745, 0.3511, 0.0931, 0.3406, 0.1196], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,344][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.9388, 0.0042, 0.0143, 0.0051, 0.0199, 0.0177], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,344][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([8.3661e-01, 7.0867e-04, 2.1734e-03, 1.4557e-03, 7.6807e-02, 8.2248e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,345][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2958, 0.1305, 0.1717, 0.0900, 0.1150, 0.1969], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,345][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8100, 0.0138, 0.0291, 0.0157, 0.0687, 0.0627], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,346][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0017, 0.1251, 0.1714, 0.0936, 0.4141, 0.1941], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,346][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2216, 0.0240, 0.0949, 0.0377, 0.3199, 0.3019], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,346][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7093, 0.0302, 0.0377, 0.0302, 0.0923, 0.1003], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,347][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0003, 0.2336, 0.1671, 0.2132, 0.1208, 0.2651], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,347][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3041, 0.0061, 0.0092, 0.0086, 0.2839, 0.3881], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,347][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0062, 0.1223, 0.1234, 0.0612, 0.3680, 0.3189], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,348][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.8600, 0.0036, 0.0184, 0.0085, 0.0547, 0.0452, 0.0096],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,348][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0249, 0.0647, 0.2407, 0.0715, 0.3737, 0.1257, 0.0988],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,348][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.8985, 0.0061, 0.0213, 0.0083, 0.0361, 0.0199, 0.0097],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,348][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4008, 0.0016, 0.0081, 0.0041, 0.2731, 0.2874, 0.0250],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,349][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3044, 0.1426, 0.1605, 0.0924, 0.0914, 0.1523, 0.0564],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,349][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6960, 0.0191, 0.0467, 0.0253, 0.1111, 0.0759, 0.0258],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,351][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0014, 0.1148, 0.1276, 0.0681, 0.4916, 0.1303, 0.0662],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,353][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1363, 0.0345, 0.1126, 0.0417, 0.2904, 0.2914, 0.0931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,354][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6006, 0.0344, 0.0525, 0.0397, 0.1116, 0.1162, 0.0449],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,355][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.1024e-04, 2.4347e-01, 1.2374e-01, 1.6224e-01, 1.2589e-01, 1.4062e-01,
        2.0393e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,356][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0907, 0.0087, 0.0141, 0.0109, 0.2917, 0.5292, 0.0548],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,358][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0082, 0.0997, 0.1039, 0.0492, 0.3715, 0.2190, 0.1485],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,360][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.8653, 0.0053, 0.0119, 0.0089, 0.0341, 0.0413, 0.0096, 0.0235],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,361][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0211, 0.0900, 0.2441, 0.0730, 0.2316, 0.1085, 0.0880, 0.1436],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,363][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.8714, 0.0075, 0.0183, 0.0095, 0.0321, 0.0236, 0.0135, 0.0240],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,363][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([3.7017e-01, 2.1651e-05, 1.2147e-04, 2.9408e-04, 1.0507e-02, 5.8485e-02,
        4.6249e-03, 5.5578e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,363][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0751, 0.1677, 0.1266, 0.0783, 0.0880, 0.1789, 0.0728, 0.2126],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,363][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.6328, 0.0201, 0.0497, 0.0281, 0.0926, 0.0855, 0.0284, 0.0629],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,364][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([2.4810e-04, 1.2652e-01, 1.2762e-01, 6.1611e-02, 4.0355e-01, 1.1233e-01,
        7.2339e-02, 9.5793e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,364][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0756, 0.0090, 0.0214, 0.0160, 0.0948, 0.2172, 0.0557, 0.5102],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,364][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.3961, 0.0571, 0.0547, 0.0512, 0.1009, 0.1783, 0.0722, 0.0894],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,365][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([3.3780e-05, 1.9507e-01, 1.4281e-01, 1.4109e-01, 1.3645e-01, 1.3103e-01,
        1.6453e-01, 8.8992e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,365][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([6.7717e-02, 2.1295e-04, 4.7940e-04, 8.7939e-04, 2.4819e-02, 1.4127e-01,
        9.5200e-03, 7.5511e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,365][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0021, 0.0889, 0.0797, 0.0493, 0.2252, 0.1917, 0.1495, 0.2137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,366][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.8960, 0.0027, 0.0156, 0.0047, 0.0289, 0.0217, 0.0036, 0.0126, 0.0142],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,366][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0231, 0.0542, 0.3038, 0.0584, 0.1897, 0.0759, 0.0642, 0.1714, 0.0594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,366][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.8715, 0.0052, 0.0230, 0.0069, 0.0380, 0.0152, 0.0065, 0.0119, 0.0217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,367][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([8.3686e-01, 1.0096e-05, 2.3070e-05, 7.6187e-05, 3.4650e-04, 1.6244e-03,
        4.7088e-04, 3.8782e-04, 1.6020e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,369][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1225, 0.1164, 0.1110, 0.0662, 0.0617, 0.1633, 0.0506, 0.1930, 0.1153],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,370][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.6819, 0.0187, 0.0395, 0.0212, 0.0679, 0.0551, 0.0168, 0.0299, 0.0690],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,372][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0013, 0.0996, 0.1710, 0.0479, 0.4193, 0.0776, 0.0394, 0.0856, 0.0582],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,373][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2361, 0.0125, 0.0332, 0.0215, 0.0654, 0.0777, 0.0327, 0.1687, 0.3521],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,375][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.5634, 0.0298, 0.0534, 0.0355, 0.0976, 0.0953, 0.0286, 0.0437, 0.0527],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,376][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([3.1582e-05, 1.4226e-01, 1.5993e-01, 9.9990e-02, 1.2600e-01, 8.7230e-02,
        1.4652e-01, 6.1453e-02, 1.7659e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,377][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([5.1457e-01, 7.6475e-05, 8.1083e-05, 2.5193e-04, 8.5518e-04, 6.2866e-03,
        1.2581e-03, 9.9669e-04, 4.7562e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,378][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0090, 0.0800, 0.0797, 0.0431, 0.2285, 0.1298, 0.1043, 0.2296, 0.0959],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,380][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.7882, 0.0044, 0.0127, 0.0082, 0.0352, 0.0280, 0.0082, 0.0241, 0.0275,
        0.0635], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,380][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0166, 0.0718, 0.1673, 0.0653, 0.1740, 0.0941, 0.0595, 0.1681, 0.0593,
        0.1240], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,380][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.8317, 0.0061, 0.0226, 0.0098, 0.0303, 0.0183, 0.0116, 0.0167, 0.0288,
        0.0242], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,381][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([2.3563e-01, 2.1095e-06, 6.1117e-06, 1.9875e-05, 2.5087e-04, 1.5269e-03,
        2.4250e-04, 8.4798e-04, 6.7698e-01, 8.4496e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,381][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0445, 0.1022, 0.0819, 0.0565, 0.0796, 0.1205, 0.0562, 0.1603, 0.1311,
        0.1673], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,381][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.5259, 0.0254, 0.0483, 0.0243, 0.0772, 0.0582, 0.0175, 0.0381, 0.0800,
        0.1051], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,382][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0004, 0.0774, 0.1009, 0.0507, 0.2880, 0.0907, 0.0580, 0.0796, 0.0849,
        0.1694], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,382][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0631, 0.0041, 0.0104, 0.0065, 0.0364, 0.0586, 0.0200, 0.1220, 0.3462,
        0.3327], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,382][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.5130, 0.0326, 0.0333, 0.0340, 0.0678, 0.0841, 0.0414, 0.0422, 0.0832,
        0.0686], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,383][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([3.2691e-05, 1.2517e-01, 1.0772e-01, 7.6126e-02, 8.0865e-02, 1.0169e-01,
        1.1605e-01, 7.7350e-02, 1.7466e-01, 1.4034e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,383][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([4.4849e-02, 1.2280e-05, 1.0185e-05, 4.4544e-05, 2.8829e-04, 2.6061e-03,
        3.5383e-04, 1.2284e-03, 8.5282e-01, 9.7784e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,383][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0029, 0.0968, 0.0721, 0.0411, 0.2053, 0.1104, 0.1046, 0.1532, 0.0714,
        0.1423], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,384][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.8190, 0.0029, 0.0088, 0.0042, 0.0273, 0.0187, 0.0035, 0.0156, 0.0157,
        0.0520, 0.0322], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,384][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0182, 0.0466, 0.1769, 0.0462, 0.1334, 0.0714, 0.0518, 0.1546, 0.0537,
        0.1052, 0.1420], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,386][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.8389, 0.0044, 0.0194, 0.0057, 0.0296, 0.0130, 0.0065, 0.0105, 0.0255,
        0.0182, 0.0282], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,387][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([8.1494e-01, 2.4119e-05, 4.0077e-05, 8.9748e-05, 7.9230e-04, 2.4429e-03,
        7.1275e-04, 2.2439e-04, 5.8829e-02, 9.4579e-03, 1.1245e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,389][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0747, 0.1183, 0.0521, 0.0499, 0.0338, 0.1016, 0.0594, 0.1272, 0.1135,
        0.1351, 0.1344], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,390][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.5342, 0.0169, 0.0316, 0.0206, 0.0571, 0.0501, 0.0144, 0.0245, 0.0547,
        0.0556, 0.1403], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,391][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0017, 0.0568, 0.0955, 0.0376, 0.3207, 0.0716, 0.0360, 0.0759, 0.0672,
        0.1708, 0.0661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,393][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1375, 0.0094, 0.0185, 0.0126, 0.0488, 0.0580, 0.0216, 0.1023, 0.1672,
        0.2420, 0.1821], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,395][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6554, 0.0172, 0.0248, 0.0167, 0.0648, 0.0569, 0.0183, 0.0267, 0.0363,
        0.0439, 0.0390], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,395][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([3.0130e-05, 9.2637e-02, 9.4620e-02, 7.1816e-02, 8.4199e-02, 7.1983e-02,
        8.8452e-02, 4.8656e-02, 1.5791e-01, 1.4069e-01, 1.4900e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,396][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([3.4704e-01, 1.9284e-04, 1.4577e-04, 2.8924e-04, 1.9156e-03, 9.6625e-03,
        2.1224e-03, 9.1484e-04, 1.9038e-01, 2.9330e-02, 4.1800e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,398][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0074, 0.0631, 0.0559, 0.0299, 0.2197, 0.1139, 0.0892, 0.1577, 0.0733,
        0.1135, 0.0764], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,398][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.9248, 0.0011, 0.0041, 0.0019, 0.0106, 0.0061, 0.0013, 0.0043, 0.0065,
        0.0150, 0.0134, 0.0109], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,398][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0283, 0.0343, 0.1366, 0.0528, 0.1196, 0.0568, 0.0397, 0.1056, 0.0554,
        0.1266, 0.1291, 0.1152], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,399][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.8722, 0.0029, 0.0106, 0.0045, 0.0193, 0.0077, 0.0041, 0.0051, 0.0165,
        0.0125, 0.0217, 0.0229], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,399][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.3780e-01, 1.7349e-05, 1.9715e-05, 4.4903e-05, 3.4929e-04, 6.9451e-04,
        3.1958e-04, 2.0417e-05, 5.5716e-03, 5.9694e-04, 1.4965e-02, 3.9596e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,399][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1772, 0.0720, 0.0568, 0.0397, 0.0281, 0.0803, 0.0308, 0.1257, 0.0852,
        0.0954, 0.1401, 0.0686], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,400][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.6698, 0.0100, 0.0176, 0.0127, 0.0309, 0.0247, 0.0090, 0.0138, 0.0374,
        0.0366, 0.0739, 0.0636], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,400][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0018, 0.0658, 0.0982, 0.0422, 0.2298, 0.0632, 0.0288, 0.0594, 0.0592,
        0.1674, 0.0706, 0.1136], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,400][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2272, 0.0050, 0.0105, 0.0086, 0.0303, 0.0321, 0.0111, 0.0366, 0.0898,
        0.1062, 0.0817, 0.3610], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,401][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.8081, 0.0064, 0.0106, 0.0095, 0.0263, 0.0215, 0.0082, 0.0085, 0.0200,
        0.0171, 0.0246, 0.0392], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,401][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.8883e-05, 7.6727e-02, 7.8376e-02, 7.0686e-02, 5.9104e-02, 6.2346e-02,
        7.4072e-02, 3.6630e-02, 1.4537e-01, 1.0156e-01, 1.5184e-01, 1.4325e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,401][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([5.4239e-01, 1.7169e-04, 1.0502e-04, 2.0663e-04, 9.7637e-04, 4.6110e-03,
        1.1436e-03, 1.1721e-04, 3.5781e-02, 2.8364e-03, 1.0663e-01, 3.0503e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,403][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0149, 0.0637, 0.0453, 0.0328, 0.1168, 0.0892, 0.0572, 0.1269, 0.0740,
        0.1741, 0.0964, 0.1088], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,404][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([9.1493e-01, 7.5324e-04, 1.6801e-03, 1.5559e-03, 5.8248e-03, 3.8532e-03,
        1.1627e-03, 3.6420e-03, 5.9895e-03, 1.1806e-02, 1.0581e-02, 8.4305e-03,
        2.9793e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,406][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0129, 0.0441, 0.1413, 0.0535, 0.1424, 0.0550, 0.0476, 0.0775, 0.0490,
        0.0744, 0.0793, 0.0815, 0.1414], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,407][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.9399, 0.0013, 0.0042, 0.0023, 0.0050, 0.0030, 0.0020, 0.0022, 0.0076,
        0.0051, 0.0089, 0.0091, 0.0096], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,408][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([7.5992e-01, 3.1127e-06, 3.5116e-06, 1.7461e-05, 1.2436e-04, 3.7526e-04,
        1.0249e-04, 4.2312e-05, 3.6983e-02, 2.4795e-03, 2.6044e-02, 5.9855e-02,
        1.1405e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,409][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0600, 0.0769, 0.0470, 0.0411, 0.0550, 0.0799, 0.0422, 0.1055, 0.1048,
        0.0826, 0.1471, 0.0732, 0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,411][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.6653, 0.0064, 0.0156, 0.0087, 0.0287, 0.0154, 0.0060, 0.0096, 0.0272,
        0.0313, 0.0468, 0.0393, 0.0996], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,412][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0008, 0.0685, 0.0698, 0.0534, 0.1800, 0.0710, 0.0489, 0.0515, 0.0715,
        0.1139, 0.0786, 0.1032, 0.0889], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,414][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.1214, 0.0008, 0.0016, 0.0017, 0.0068, 0.0071, 0.0029, 0.0093, 0.0486,
        0.0385, 0.0367, 0.1665, 0.5584], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,415][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.7266, 0.0048, 0.0060, 0.0097, 0.0153, 0.0183, 0.0098, 0.0082, 0.0255,
        0.0207, 0.0418, 0.0363, 0.0767], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,415][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([4.2265e-05, 9.6738e-02, 5.1947e-02, 8.5139e-02, 3.8031e-02, 6.4254e-02,
        8.9049e-02, 3.4389e-02, 1.4173e-01, 1.1361e-01, 1.4897e-01, 9.4704e-02,
        4.1386e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,416][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([1.4333e-01, 2.4722e-05, 1.6542e-05, 4.9388e-05, 2.6281e-04, 1.1545e-03,
        3.1617e-04, 1.2448e-04, 8.3208e-02, 5.3955e-03, 8.1397e-02, 2.2027e-01,
        4.6445e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,416][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0042, 0.0669, 0.0340, 0.0281, 0.1020, 0.1121, 0.0904, 0.1121, 0.0673,
        0.0767, 0.0723, 0.0963, 0.1375], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,416][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.7805, 0.0026, 0.0104, 0.0028, 0.0291, 0.0140, 0.0022, 0.0079, 0.0101,
        0.0262, 0.0162, 0.0162, 0.0650, 0.0167], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,417][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0204, 0.0264, 0.1429, 0.0314, 0.1211, 0.0472, 0.0360, 0.0929, 0.0358,
        0.0842, 0.0781, 0.0742, 0.1482, 0.0611], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,417][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.7650, 0.0053, 0.0221, 0.0057, 0.0365, 0.0136, 0.0053, 0.0083, 0.0194,
        0.0206, 0.0230, 0.0235, 0.0381, 0.0134], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,417][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.1877e-01, 1.5811e-06, 5.1566e-06, 1.3406e-05, 1.1636e-04, 4.0054e-04,
        6.2501e-05, 4.8851e-04, 9.4557e-02, 2.2551e-02, 9.9155e-02, 1.9710e-01,
        4.3933e-01, 2.7446e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,418][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0654, 0.0761, 0.0520, 0.0417, 0.0456, 0.0770, 0.0298, 0.0866, 0.0755,
        0.0730, 0.1075, 0.0601, 0.0774, 0.1322], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,418][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.4587, 0.0102, 0.0215, 0.0130, 0.0446, 0.0308, 0.0096, 0.0191, 0.0468,
        0.0470, 0.0901, 0.0628, 0.1301, 0.0159], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,419][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0007, 0.0600, 0.1052, 0.0321, 0.2705, 0.0546, 0.0291, 0.0401, 0.0383,
        0.1042, 0.0416, 0.0749, 0.1034, 0.0454], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,419][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0159, 0.0007, 0.0017, 0.0011, 0.0046, 0.0051, 0.0021, 0.0120, 0.0341,
        0.0572, 0.0370, 0.1685, 0.6284, 0.0315], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,421][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.5238, 0.0115, 0.0238, 0.0140, 0.0506, 0.0382, 0.0124, 0.0192, 0.0282,
        0.0306, 0.0363, 0.0467, 0.1232, 0.0414], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,422][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.0489e-05, 7.6967e-02, 7.5539e-02, 5.7277e-02, 8.1186e-02, 6.0838e-02,
        8.8330e-02, 3.5448e-02, 1.1032e-01, 9.5957e-02, 1.1181e-01, 9.2142e-02,
        4.0006e-02, 7.4158e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,423][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.1765e-02, 5.1266e-06, 6.5543e-06, 1.5341e-05, 1.0073e-04, 5.6359e-04,
        8.0412e-05, 3.7129e-04, 8.1882e-02, 2.0185e-02, 8.6678e-02, 2.5536e-01,
        5.2162e-01, 2.1371e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,424][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0075, 0.0468, 0.0395, 0.0237, 0.1163, 0.0851, 0.0531, 0.1128, 0.0596,
        0.1047, 0.0647, 0.0812, 0.1343, 0.0705], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,425][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([9.6894e-01, 3.6199e-04, 6.9847e-04, 4.4410e-04, 1.6986e-03, 1.3431e-03,
        2.8982e-04, 7.6110e-04, 2.2709e-03, 3.0924e-03, 2.4114e-03, 2.1448e-03,
        6.8133e-03, 1.7851e-03, 6.9412e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,427][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0420, 0.0308, 0.1138, 0.0385, 0.0796, 0.0404, 0.0290, 0.0490, 0.0353,
        0.0564, 0.0700, 0.0487, 0.0934, 0.0414, 0.2316], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,428][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([9.6798e-01, 4.5292e-04, 1.2699e-03, 8.2491e-04, 1.6807e-03, 1.2232e-03,
        7.7834e-04, 6.7238e-04, 3.7610e-03, 1.7378e-03, 2.9518e-03, 3.5834e-03,
        2.8879e-03, 1.6484e-03, 8.5430e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,429][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([8.5006e-01, 3.0778e-06, 3.5721e-06, 1.1263e-05, 9.0896e-05, 1.4191e-04,
        4.1303e-05, 2.3056e-05, 1.4298e-02, 9.2435e-04, 6.9600e-03, 1.1211e-02,
        3.9623e-02, 5.1175e-03, 7.1489e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,431][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.2729, 0.0252, 0.0298, 0.0199, 0.0285, 0.0393, 0.0178, 0.0635, 0.0717,
        0.0513, 0.0996, 0.0504, 0.0376, 0.0890, 0.1035], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,432][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.7845, 0.0032, 0.0083, 0.0044, 0.0185, 0.0086, 0.0028, 0.0032, 0.0168,
        0.0106, 0.0242, 0.0200, 0.0421, 0.0056, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,433][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0013, 0.0351, 0.0444, 0.0308, 0.1557, 0.0514, 0.0260, 0.0213, 0.0454,
        0.0851, 0.0434, 0.0752, 0.0723, 0.0407, 0.2719], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,433][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.2010, 0.0005, 0.0009, 0.0011, 0.0030, 0.0026, 0.0014, 0.0037, 0.0278,
        0.0223, 0.0182, 0.0809, 0.2353, 0.0212, 0.3803], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,433][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.9042, 0.0015, 0.0029, 0.0029, 0.0035, 0.0056, 0.0020, 0.0016, 0.0070,
        0.0038, 0.0062, 0.0088, 0.0141, 0.0073, 0.0286], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,434][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([9.1833e-05, 5.4003e-02, 4.9556e-02, 5.8046e-02, 2.2698e-02, 8.9757e-02,
        5.5299e-02, 2.6791e-02, 1.2463e-01, 6.5963e-02, 1.1221e-01, 8.5786e-02,
        3.4619e-02, 5.7213e-02, 1.6333e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,434][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([2.3792e-01, 3.1838e-05, 9.1958e-06, 4.4029e-05, 1.6124e-04, 6.2801e-04,
        2.0967e-04, 1.1097e-04, 5.7075e-02, 2.9667e-03, 3.6154e-02, 9.1049e-02,
        2.3575e-01, 1.3706e-02, 3.2418e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,434][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0226, 0.0569, 0.0278, 0.0214, 0.0578, 0.0743, 0.0785, 0.0738, 0.0679,
        0.0942, 0.0569, 0.0821, 0.1015, 0.0811, 0.1033], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,435][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.1594e-01, 2.8542e-04, 8.0641e-04, 5.4556e-04, 2.2466e-03, 1.5583e-03,
        3.7767e-04, 1.0099e-03, 2.9398e-03, 4.6342e-03, 3.5832e-03, 3.7962e-03,
        1.2216e-02, 2.7888e-03, 1.3752e-02, 3.3520e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,435][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0311, 0.0266, 0.0817, 0.0377, 0.0403, 0.0314, 0.0282, 0.0326, 0.0359,
        0.0416, 0.0665, 0.0663, 0.1116, 0.0444, 0.1740, 0.1500],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,436][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([9.4963e-01, 3.9078e-04, 1.6984e-03, 7.4587e-04, 2.8399e-03, 1.2558e-03,
        5.7032e-04, 6.0421e-04, 3.0720e-03, 1.4722e-03, 2.7633e-03, 3.8648e-03,
        4.3008e-03, 1.6748e-03, 1.0707e-02, 1.4413e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,436][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.8324e-01, 4.8882e-07, 3.6189e-07, 1.6368e-06, 1.0825e-05, 1.9206e-05,
        8.0070e-06, 5.2267e-07, 6.6220e-04, 2.4365e-05, 8.1137e-04, 2.8136e-03,
        5.5835e-03, 2.1521e-04, 1.3315e-02, 9.3289e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,436][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1402, 0.0321, 0.0307, 0.0228, 0.0212, 0.0334, 0.0154, 0.0601, 0.0553,
        0.0592, 0.0872, 0.0548, 0.0594, 0.0861, 0.1031, 0.1391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,438][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.7342, 0.0037, 0.0071, 0.0050, 0.0118, 0.0083, 0.0029, 0.0035, 0.0144,
        0.0112, 0.0243, 0.0246, 0.0478, 0.0056, 0.0372, 0.0584],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,440][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0021, 0.0299, 0.0521, 0.0233, 0.1017, 0.0300, 0.0175, 0.0200, 0.0371,
        0.0733, 0.0368, 0.0718, 0.0851, 0.0343, 0.2316, 0.1535],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,440][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.0142e-01, 2.7413e-04, 4.8231e-04, 5.2858e-04, 1.5399e-03, 1.1078e-03,
        6.3872e-04, 1.2538e-03, 1.0049e-02, 7.1579e-03, 7.1404e-03, 3.7378e-02,
        1.3603e-01, 7.4783e-03, 2.7694e-01, 4.1058e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,442][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.8495, 0.0016, 0.0022, 0.0020, 0.0049, 0.0045, 0.0021, 0.0017, 0.0053,
        0.0048, 0.0056, 0.0112, 0.0199, 0.0073, 0.0244, 0.0528],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,443][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([9.8358e-05, 4.7271e-02, 4.8558e-02, 5.4611e-02, 4.2243e-02, 5.8928e-02,
        6.6046e-02, 2.2556e-02, 1.1656e-01, 7.4312e-02, 1.1402e-01, 1.1051e-01,
        3.5703e-02, 6.2659e-02, 1.1260e-01, 3.3321e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,444][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.6337e-01, 3.5700e-06, 1.4093e-06, 7.0080e-06, 2.1879e-05, 7.5472e-05,
        3.0881e-05, 2.0436e-06, 2.7259e-03, 8.0527e-05, 3.2604e-03, 1.2970e-02,
        2.4483e-02, 4.5330e-04, 6.6738e-02, 7.2577e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,446][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0125, 0.0636, 0.0243, 0.0214, 0.0524, 0.0577, 0.0515, 0.0662, 0.0513,
        0.0621, 0.0477, 0.0849, 0.1057, 0.1000, 0.0860, 0.1129],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,447][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.3727e-01, 2.1402e-04, 6.3451e-04, 4.0890e-04, 1.9569e-03, 1.3248e-03,
        2.5387e-04, 7.7649e-04, 1.9791e-03, 3.6976e-03, 2.7886e-03, 2.9199e-03,
        1.0979e-02, 2.1677e-03, 9.9121e-03, 2.0354e-02, 2.3591e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,448][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0286, 0.0131, 0.0544, 0.0192, 0.0660, 0.0209, 0.0163, 0.0529, 0.0286,
        0.0664, 0.0460, 0.0513, 0.1209, 0.0367, 0.1872, 0.1326, 0.0588],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,449][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.1904e-01, 4.7794e-04, 2.2942e-03, 1.0280e-03, 3.7976e-03, 1.6269e-03,
        7.5505e-04, 8.1249e-04, 4.1682e-03, 2.7044e-03, 5.1370e-03, 5.2459e-03,
        5.6062e-03, 2.2720e-03, 1.8945e-02, 2.0858e-02, 5.2274e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,450][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.3661e-01, 3.4340e-06, 4.0536e-06, 9.1175e-06, 1.0302e-04, 1.4332e-04,
        3.8787e-05, 1.6480e-05, 1.7924e-03, 2.2541e-04, 1.7868e-03, 5.8527e-03,
        3.1219e-02, 1.1677e-03, 3.7193e-02, 2.6473e-01, 1.9108e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,450][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2363, 0.0310, 0.0312, 0.0260, 0.0168, 0.0267, 0.0124, 0.0560, 0.0550,
        0.0611, 0.0760, 0.0457, 0.0409, 0.0724, 0.0919, 0.0809, 0.0396],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,451][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7533, 0.0029, 0.0066, 0.0043, 0.0131, 0.0074, 0.0031, 0.0039, 0.0126,
        0.0102, 0.0224, 0.0204, 0.0430, 0.0045, 0.0337, 0.0409, 0.0178],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,451][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0018, 0.0257, 0.0385, 0.0169, 0.1041, 0.0223, 0.0110, 0.0222, 0.0264,
        0.0777, 0.0294, 0.0676, 0.0770, 0.0269, 0.2383, 0.1212, 0.0929],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,451][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([7.1412e-02, 3.3785e-04, 8.5586e-04, 6.3087e-04, 2.1274e-03, 1.5976e-03,
        7.2074e-04, 2.6159e-03, 8.7320e-03, 9.1328e-03, 6.4718e-03, 3.2146e-02,
        1.3926e-01, 8.7834e-03, 2.9443e-01, 3.5555e-01, 6.5189e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,452][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7559, 0.0021, 0.0037, 0.0036, 0.0083, 0.0071, 0.0025, 0.0028, 0.0072,
        0.0065, 0.0076, 0.0121, 0.0267, 0.0113, 0.0408, 0.0801, 0.0217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,452][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([5.3641e-05, 4.6416e-02, 3.0073e-02, 4.0525e-02, 3.3694e-02, 3.2908e-02,
        4.2390e-02, 2.2541e-02, 1.0509e-01, 7.2562e-02, 1.1902e-01, 1.1534e-01,
        3.8150e-02, 6.6488e-02, 1.0470e-01, 2.7244e-02, 1.0281e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,452][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.3475e-02, 1.1382e-05, 5.5254e-06, 1.1158e-05, 7.8406e-05, 1.9107e-04,
        5.1097e-05, 1.3551e-05, 3.1584e-03, 2.7482e-04, 3.3337e-03, 1.1049e-02,
        3.5894e-02, 1.0258e-03, 8.0075e-02, 7.7159e-01, 3.9760e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,453][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0201, 0.0355, 0.0264, 0.0189, 0.0765, 0.0520, 0.0382, 0.0832, 0.0525,
        0.1010, 0.0534, 0.0697, 0.1015, 0.0594, 0.0827, 0.0719, 0.0570],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,453][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([7.9757e-01, 7.8419e-04, 1.2846e-03, 2.0828e-03, 4.3198e-03, 4.2812e-03,
        1.0474e-03, 2.1809e-03, 6.4237e-03, 8.2864e-03, 9.2821e-03, 7.3323e-03,
        1.8988e-02, 8.4805e-03, 1.5457e-02, 4.3801e-02, 8.1321e-03, 6.0269e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,454][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0155, 0.0307, 0.0818, 0.0302, 0.0628, 0.0292, 0.0282, 0.0384, 0.0299,
        0.0387, 0.0570, 0.0506, 0.0874, 0.0452, 0.1499, 0.1073, 0.0584, 0.0589],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,456][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.8964, 0.0012, 0.0036, 0.0026, 0.0054, 0.0025, 0.0019, 0.0017, 0.0066,
        0.0035, 0.0054, 0.0067, 0.0061, 0.0039, 0.0135, 0.0175, 0.0070, 0.0144],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,457][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([4.9886e-01, 6.1367e-06, 6.2985e-06, 2.1803e-05, 1.9057e-04, 2.4460e-04,
        7.9353e-05, 1.4755e-04, 1.7159e-02, 2.0615e-03, 4.3989e-03, 5.1866e-03,
        3.4482e-02, 9.0906e-03, 4.9712e-02, 2.0836e-01, 2.0756e-02, 1.4924e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,459][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0612, 0.0483, 0.0281, 0.0268, 0.0256, 0.0389, 0.0218, 0.0710, 0.0614,
        0.0546, 0.0787, 0.0472, 0.0414, 0.0821, 0.0866, 0.0891, 0.0777, 0.0594],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,460][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([0.5585, 0.0062, 0.0086, 0.0068, 0.0188, 0.0120, 0.0045, 0.0063, 0.0194,
        0.0163, 0.0295, 0.0237, 0.0519, 0.0078, 0.0374, 0.0485, 0.0220, 0.1217],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,462][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0008, 0.0437, 0.0306, 0.0244, 0.0657, 0.0365, 0.0232, 0.0250, 0.0415,
        0.0609, 0.0403, 0.0616, 0.0484, 0.0381, 0.1393, 0.1053, 0.1162, 0.0985],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,464][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.0419, 0.0003, 0.0006, 0.0006, 0.0017, 0.0020, 0.0011, 0.0040, 0.0122,
        0.0119, 0.0084, 0.0316, 0.1166, 0.0134, 0.2000, 0.2829, 0.0761, 0.1948],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,465][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.5422, 0.0048, 0.0046, 0.0072, 0.0091, 0.0130, 0.0063, 0.0054, 0.0143,
        0.0115, 0.0216, 0.0218, 0.0365, 0.0187, 0.0408, 0.1280, 0.0406, 0.0736],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,466][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([3.0047e-05, 7.0696e-02, 3.4563e-02, 5.6900e-02, 2.5985e-02, 5.0016e-02,
        6.9962e-02, 2.8959e-02, 1.0563e-01, 6.6039e-02, 1.1326e-01, 7.3885e-02,
        2.2232e-02, 6.4877e-02, 6.5694e-02, 2.3931e-02, 1.0398e-01, 2.3359e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,467][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([1.8298e-02, 1.4709e-05, 7.2611e-06, 1.8357e-05, 1.5272e-04, 2.6839e-04,
        8.7102e-05, 9.5779e-05, 1.2357e-02, 1.3503e-03, 5.1012e-03, 9.2910e-03,
        4.7176e-02, 5.9069e-03, 9.1197e-02, 5.5854e-01, 4.0611e-02, 2.0953e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,467][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0051, 0.0572, 0.0217, 0.0209, 0.0496, 0.0690, 0.0582, 0.0839, 0.0501,
        0.0608, 0.0467, 0.0767, 0.0756, 0.0795, 0.0686, 0.0738, 0.0548, 0.0479],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,468][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.6519e-01, 5.0767e-04, 1.5435e-03, 7.9764e-04, 3.9269e-03, 2.8043e-03,
        4.9224e-04, 1.3632e-03, 2.6646e-03, 5.1370e-03, 4.1175e-03, 3.8612e-03,
        1.2599e-02, 3.4646e-03, 1.1664e-02, 2.4798e-02, 3.7728e-03, 3.6329e-02,
        1.4966e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,468][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0378, 0.0181, 0.0743, 0.0252, 0.0541, 0.0229, 0.0210, 0.0348, 0.0255,
        0.0523, 0.0499, 0.0484, 0.0971, 0.0340, 0.1533, 0.0937, 0.0505, 0.0637,
        0.0434], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,468][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.0308e-01, 7.6842e-04, 3.8352e-03, 1.3135e-03, 5.8542e-03, 1.9575e-03,
        1.0973e-03, 1.2319e-03, 3.9849e-03, 2.7191e-03, 4.3226e-03, 4.7404e-03,
        5.9621e-03, 2.4171e-03, 1.4174e-02, 1.6235e-02, 4.9110e-03, 1.2401e-02,
        8.9994e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,469][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.7988e-01, 2.0329e-05, 3.0576e-05, 4.4922e-05, 5.8263e-04, 5.0014e-04,
        1.7330e-04, 2.1478e-04, 8.4260e-03, 1.8228e-03, 4.3679e-03, 4.6969e-03,
        3.7205e-02, 5.6964e-03, 5.3995e-02, 1.7654e-01, 1.9292e-02, 1.7647e-01,
        3.0045e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,469][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1585, 0.0362, 0.0296, 0.0248, 0.0204, 0.0346, 0.0174, 0.0551, 0.0478,
        0.0472, 0.0638, 0.0418, 0.0411, 0.0639, 0.0657, 0.0728, 0.0505, 0.0603,
        0.0684], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,470][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6365, 0.0038, 0.0083, 0.0052, 0.0143, 0.0090, 0.0031, 0.0044, 0.0140,
        0.0129, 0.0246, 0.0178, 0.0411, 0.0050, 0.0348, 0.0356, 0.0153, 0.0860,
        0.0284], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,470][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0022, 0.0300, 0.0447, 0.0177, 0.0914, 0.0243, 0.0134, 0.0144, 0.0243,
        0.0490, 0.0261, 0.0482, 0.0486, 0.0239, 0.1821, 0.1102, 0.0834, 0.0934,
        0.0724], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,470][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0683, 0.0005, 0.0011, 0.0008, 0.0035, 0.0020, 0.0011, 0.0044, 0.0110,
        0.0131, 0.0073, 0.0261, 0.1234, 0.0115, 0.1817, 0.2333, 0.0494, 0.1965,
        0.0652], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,471][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6607, 0.0032, 0.0053, 0.0048, 0.0132, 0.0087, 0.0035, 0.0031, 0.0076,
        0.0063, 0.0084, 0.0122, 0.0239, 0.0111, 0.0371, 0.0801, 0.0228, 0.0620,
        0.0259], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,472][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.7637e-05, 5.8842e-02, 4.0524e-02, 3.9950e-02, 3.3178e-02, 3.8666e-02,
        5.3939e-02, 2.1087e-02, 8.8359e-02, 6.2903e-02, 8.1115e-02, 9.3004e-02,
        2.8243e-02, 5.3502e-02, 8.8364e-02, 2.6133e-02, 1.0555e-01, 2.7333e-02,
        5.9208e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,473][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.9393e-02, 3.5843e-05, 2.1761e-05, 3.4054e-05, 2.7010e-04, 4.8858e-04,
        1.4473e-04, 1.6556e-04, 8.2978e-03, 1.4199e-03, 5.0291e-03, 8.0511e-03,
        4.9957e-02, 3.5628e-03, 7.8357e-02, 4.4718e-01, 2.8124e-02, 2.4579e-01,
        5.3677e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,475][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0259, 0.0452, 0.0235, 0.0187, 0.0553, 0.0454, 0.0374, 0.0639, 0.0476,
        0.0714, 0.0406, 0.0622, 0.0907, 0.0594, 0.0733, 0.0678, 0.0535, 0.0521,
        0.0661], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,476][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:58,478][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[24614],
        [  965],
        [  454],
        [  138],
        [  709],
        [  209],
        [   33],
        [  134],
        [   48],
        [  107],
        [   68],
        [   12],
        [   24],
        [   35],
        [   79],
        [   54],
        [   20],
        [   10],
        [    6]], device='cuda:0')
[2024-07-24 10:18:58,480][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[23653],
        [  520],
        [  211],
        [   38],
        [  185],
        [   34],
        [    4],
        [   25],
        [    9],
        [   27],
        [   17],
        [    4],
        [   10],
        [    8],
        [   21],
        [   20],
        [   11],
        [    7],
        [    6]], device='cuda:0')
[2024-07-24 10:18:58,482][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11404],
        [11134],
        [ 9100],
        [ 7725],
        [14830],
        [12160],
        [14945],
        [ 8682],
        [10074],
        [10871],
        [10094],
        [ 9516],
        [ 9355],
        [11389],
        [10104],
        [ 9704],
        [ 9859],
        [ 8161],
        [ 7805]], device='cuda:0')
[2024-07-24 10:18:58,483][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30599],
        [46937],
        [49386],
        [49371],
        [49817],
        [49808],
        [49816],
        [49606],
        [49510],
        [49468],
        [49220],
        [49129],
        [49014],
        [48869],
        [49075],
        [48846],
        [48924],
        [48916],
        [48816]], device='cuda:0')
[2024-07-24 10:18:58,485][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20363],
        [21541],
        [26193],
        [31581],
        [30266],
        [36620],
        [43709],
        [44231],
        [44962],
        [45739],
        [43580],
        [39683],
        [28647],
        [45051],
        [25607],
        [27787],
        [32202],
        [36438],
        [35490]], device='cuda:0')
[2024-07-24 10:18:58,486][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[43004],
        [43100],
        [43369],
        [43140],
        [44805],
        [43506],
        [41295],
        [44049],
        [42926],
        [41146],
        [41272],
        [42891],
        [44200],
        [43673],
        [43787],
        [43448],
        [43531],
        [43366],
        [43449]], device='cuda:0')
[2024-07-24 10:18:58,487][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 2185],
        [10879],
        [ 6989],
        [ 8124],
        [ 4266],
        [ 8854],
        [ 9050],
        [11642],
        [12366],
        [12578],
        [14953],
        [14424],
        [15389],
        [14554],
        [13936],
        [17633],
        [16100],
        [18149],
        [17243]], device='cuda:0')
[2024-07-24 10:18:58,488][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45446],
        [45221],
        [41329],
        [43059],
        [31874],
        [42105],
        [38383],
        [41393],
        [40778],
        [35629],
        [39103],
        [40924],
        [35934],
        [33291],
        [38776],
        [38951],
        [39226],
        [35262],
        [36582]], device='cuda:0')
[2024-07-24 10:18:58,489][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[38217],
        [35137],
        [43164],
        [44385],
        [50254],
        [50248],
        [50253],
        [50244],
        [50250],
        [50216],
        [50228],
        [50058],
        [49416],
        [50124],
        [49706],
        [48879],
        [48932],
        [47479],
        [48737]], device='cuda:0')
[2024-07-24 10:18:58,491][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8210],
        [14201],
        [17397],
        [17910],
        [ 8711],
        [ 9603],
        [10431],
        [17869],
        [14740],
        [19574],
        [18188],
        [11641],
        [21101],
        [22047],
        [22359],
        [21572],
        [21053],
        [18523],
        [18662]], device='cuda:0')
[2024-07-24 10:18:58,493][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[16243],
        [12109],
        [17485],
        [16508],
        [ 7292],
        [13566],
        [12190],
        [15434],
        [13373],
        [12820],
        [ 9486],
        [12921],
        [14611],
        [15294],
        [23204],
        [22154],
        [19978],
        [19799],
        [20490]], device='cuda:0')
[2024-07-24 10:18:58,494][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25458],
        [40451],
        [38377],
        [42896],
        [50215],
        [50044],
        [49964],
        [50115],
        [50091],
        [49674],
        [49818],
        [49512],
        [48851],
        [49907],
        [47452],
        [49030],
        [48320],
        [47811],
        [48201]], device='cuda:0')
[2024-07-24 10:18:58,496][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15501],
        [30033],
        [19590],
        [18435],
        [12536],
        [10946],
        [11996],
        [20139],
        [23023],
        [25697],
        [16228],
        [19489],
        [21325],
        [21818],
        [14538],
        [16662],
        [17239],
        [17788],
        [17789]], device='cuda:0')
[2024-07-24 10:18:58,498][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27467],
        [39953],
        [45996],
        [47041],
        [48324],
        [48757],
        [48550],
        [46985],
        [46915],
        [45844],
        [46308],
        [44642],
        [45237],
        [45249],
        [45234],
        [45381],
        [45535],
        [44713],
        [44896]], device='cuda:0')
[2024-07-24 10:18:58,499][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15526],
        [25676],
        [33812],
        [43303],
        [14544],
        [37764],
        [42145],
        [40310],
        [37310],
        [35927],
        [30375],
        [39526],
        [30931],
        [35981],
        [37491],
        [34418],
        [36773],
        [30478],
        [30581]], device='cuda:0')
[2024-07-24 10:18:58,501][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[3528],
        [3436],
        [3024],
        [3191],
        [2380],
        [1953],
        [1661],
        [1497],
        [1623],
        [1788],
        [1232],
        [1380],
        [2093],
        [2281],
        [2481],
        [1758],
        [1967],
        [1037],
        [1116]], device='cuda:0')
[2024-07-24 10:18:58,502][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[34414],
        [12132],
        [11764],
        [ 9391],
        [ 8861],
        [ 7724],
        [ 7945],
        [ 7707],
        [ 8027],
        [ 7681],
        [ 7653],
        [ 8049],
        [ 7628],
        [ 7367],
        [ 6935],
        [ 7659],
        [ 7256],
        [ 6253],
        [ 5800]], device='cuda:0')
[2024-07-24 10:18:58,503][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[12742],
        [14118],
        [16939],
        [20559],
        [15954],
        [17742],
        [20046],
        [22110],
        [21113],
        [24393],
        [24733],
        [22464],
        [18587],
        [27229],
        [14307],
        [16517],
        [17735],
        [19516],
        [19513]], device='cuda:0')
[2024-07-24 10:18:58,504][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2974],
        [ 3286],
        [ 8596],
        [ 9531],
        [ 8529],
        [ 8232],
        [25779],
        [13722],
        [ 9279],
        [23198],
        [10660],
        [ 4566],
        [ 8491],
        [18748],
        [ 6212],
        [ 5501],
        [12601],
        [16094],
        [16388]], device='cuda:0')
[2024-07-24 10:18:58,505][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24629],
        [41319],
        [36716],
        [37467],
        [31695],
        [32556],
        [32989],
        [34916],
        [35851],
        [37000],
        [38753],
        [38583],
        [37875],
        [37774],
        [36098],
        [35641],
        [35231],
        [34720],
        [34873]], device='cuda:0')
[2024-07-24 10:18:58,507][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12592],
        [14451],
        [33613],
        [30808],
        [26394],
        [20008],
        [25005],
        [26084],
        [24613],
        [32861],
        [23916],
        [17873],
        [20784],
        [23767],
        [13154],
        [13367],
        [12663],
        [13750],
        [12279]], device='cuda:0')
[2024-07-24 10:18:58,509][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[11436],
        [31602],
        [35892],
        [37822],
        [13800],
        [19168],
        [15878],
        [18983],
        [19918],
        [21989],
        [21389],
        [26654],
        [28804],
        [23671],
        [37259],
        [39047],
        [37886],
        [34537],
        [35709]], device='cuda:0')
[2024-07-24 10:18:58,510][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9399],
        [ 8161],
        [13837],
        [12767],
        [ 8135],
        [ 5090],
        [ 5098],
        [ 8479],
        [10809],
        [12454],
        [ 8938],
        [ 9767],
        [ 6519],
        [ 6542],
        [ 9495],
        [18903],
        [17453],
        [22838],
        [21304]], device='cuda:0')
[2024-07-24 10:18:58,512][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24078],
        [23273],
        [28976],
        [33288],
        [35783],
        [35107],
        [36503],
        [39055],
        [39237],
        [41322],
        [41212],
        [39536],
        [43455],
        [43928],
        [34329],
        [31032],
        [34113],
        [42173],
        [41854]], device='cuda:0')
[2024-07-24 10:18:58,514][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22557],
        [47177],
        [47788],
        [46289],
        [44397],
        [41877],
        [41391],
        [41176],
        [39342],
        [36270],
        [37581],
        [37899],
        [37063],
        [36431],
        [38804],
        [37460],
        [37328],
        [37214],
        [37275]], device='cuda:0')
[2024-07-24 10:18:58,515][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[  693],
        [ 9528],
        [24526],
        [27833],
        [36852],
        [34762],
        [33855],
        [26122],
        [30792],
        [35518],
        [35875],
        [28576],
        [35585],
        [35493],
        [31344],
        [34795],
        [34733],
        [35433],
        [35263]], device='cuda:0')
[2024-07-24 10:18:58,517][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17164],
        [12017],
        [11317],
        [11145],
        [14090],
        [11435],
        [12575],
        [15357],
        [16174],
        [16586],
        [14802],
        [13094],
        [10994],
        [11453],
        [ 9115],
        [ 9839],
        [10313],
        [ 9355],
        [ 8971]], device='cuda:0')
[2024-07-24 10:18:58,518][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48348],
        [39593],
        [27111],
        [25644],
        [32860],
        [36697],
        [31401],
        [32592],
        [31383],
        [22997],
        [28919],
        [33722],
        [30768],
        [26047],
        [35546],
        [35461],
        [32238],
        [32964],
        [32069]], device='cuda:0')
[2024-07-24 10:18:58,520][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[38608],
        [31062],
        [20081],
        [12102],
        [33968],
        [17032],
        [16457],
        [16291],
        [19114],
        [20755],
        [23931],
        [21548],
        [28027],
        [26063],
        [24403],
        [15430],
        [16426],
        [23148],
        [18234]], device='cuda:0')
[2024-07-24 10:18:58,521][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125],
        [28125]], device='cuda:0')
[2024-07-24 10:18:58,567][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:58,569][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,570][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,572][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,573][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,574][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,575][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,576][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,578][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,579][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,580][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,581][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,581][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,581][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5259, 0.4741], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,582][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([9.1223e-04, 9.9909e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,582][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1665, 0.8335], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,582][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1416, 0.8584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,583][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2794, 0.7206], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,583][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3241, 0.6759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,583][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0170, 0.9830], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,583][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0256, 0.9744], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,584][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0051, 0.9949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,584][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0323, 0.9677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,584][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0173, 0.9827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,584][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([4.4712e-04, 9.9955e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,585][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.1716, 0.2487, 0.5797], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,585][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0019, 0.6025, 0.3956], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,587][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0245, 0.4810, 0.4945], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,588][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0461, 0.3177, 0.6362], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,590][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.1122, 0.5214, 0.3665], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,591][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.3960, 0.1023, 0.5017], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,592][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0365, 0.7111, 0.2524], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,594][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.1027, 0.7774, 0.1199], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,595][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0172, 0.6494, 0.3334], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,597][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0777, 0.0324, 0.8899], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,598][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0010, 0.9716, 0.0273], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,599][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([8.1467e-05, 3.5066e-01, 6.4926e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,599][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1005, 0.1690, 0.3177, 0.4128], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,599][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([3.7920e-04, 3.8738e-01, 3.0920e-01, 3.0304e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,599][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1902, 0.0843, 0.6390, 0.0866], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,600][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1518, 0.1999, 0.2534, 0.3949], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,600][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0569, 0.2447, 0.2364, 0.4620], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,600][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6279, 0.0519, 0.2327, 0.0875], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,600][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0117, 0.3194, 0.1473, 0.5216], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,601][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0501, 0.5434, 0.1618, 0.2447], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,601][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0117, 0.6316, 0.1050, 0.2518], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,601][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0236, 0.0415, 0.7277, 0.2073], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,602][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0041, 0.3011, 0.0266, 0.6683], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,602][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([5.2159e-05, 3.0407e-01, 2.9795e-01, 3.9793e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,603][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.0860, 0.0840, 0.1879, 0.2513, 0.3908], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,604][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([3.6792e-04, 7.5463e-02, 1.6114e-01, 5.7572e-02, 7.0545e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,605][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.2523, 0.0818, 0.1843, 0.0573, 0.4244], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,607][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.0194, 0.1041, 0.2577, 0.3015, 0.3173], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,608][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.0518, 0.1560, 0.1040, 0.2752, 0.4130], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,609][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([1.9487e-01, 7.6441e-04, 3.6012e-03, 3.3936e-03, 7.9737e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,611][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0221, 0.2205, 0.1600, 0.2904, 0.3070], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,612][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.1194, 0.0921, 0.0212, 0.0483, 0.7190], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,614][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.0320, 0.3397, 0.2976, 0.2237, 0.1069], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,615][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([7.9068e-02, 4.5874e-04, 9.3952e-03, 5.5189e-03, 9.0556e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,616][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([5.8588e-04, 2.4046e-01, 4.8811e-03, 7.5294e-01, 1.1259e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,616][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0012, 0.1378, 0.1896, 0.2089, 0.4625], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,616][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0826, 0.0434, 0.0790, 0.1522, 0.2231, 0.4197], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,617][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0006, 0.0432, 0.1095, 0.0388, 0.5027, 0.3052], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,617][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3572, 0.0214, 0.0623, 0.0207, 0.3835, 0.1549], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,617][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1011, 0.0655, 0.0545, 0.0606, 0.0679, 0.6503], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,617][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0492, 0.0378, 0.0233, 0.1018, 0.1176, 0.6702], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,618][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([4.6377e-01, 3.0878e-05, 5.0985e-05, 7.4438e-05, 1.3529e-02, 5.2255e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,618][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0323, 0.0752, 0.0599, 0.1074, 0.1235, 0.6018], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,618][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0449, 0.1712, 0.0252, 0.0652, 0.5116, 0.1818], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,619][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0417, 0.5370, 0.1466, 0.1540, 0.0221, 0.0986], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,619][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.1957e-01, 7.3310e-06, 4.4605e-05, 3.5813e-05, 1.0745e-02, 8.6960e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,619][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0019, 0.2020, 0.0054, 0.7045, 0.0024, 0.0838], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,620][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0029, 0.0753, 0.0889, 0.0746, 0.1500, 0.6082], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,622][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0422, 0.0551, 0.0621, 0.1466, 0.2254, 0.3228, 0.1460],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,623][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.4666e-04, 2.8715e-02, 6.3162e-02, 2.8792e-02, 5.6763e-01, 1.9338e-01,
        1.1817e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,624][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0505, 0.0341, 0.0477, 0.0240, 0.6816, 0.1326, 0.0294],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,625][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0272, 0.0320, 0.0402, 0.0496, 0.0704, 0.4187, 0.3619],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,626][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0213, 0.0163, 0.0142, 0.0458, 0.0971, 0.5771, 0.2282],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,628][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.0132e-02, 5.7218e-05, 1.1488e-04, 9.0764e-05, 1.7728e-02, 9.3306e-01,
        8.8139e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,629][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0067, 0.0470, 0.0444, 0.0639, 0.1958, 0.3796, 0.2628],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,631][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0260, 0.2041, 0.0259, 0.0950, 0.5035, 0.0912, 0.0543],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,632][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0633, 0.2724, 0.1412, 0.2432, 0.0742, 0.0784, 0.1273],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,633][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0140e-03, 6.9825e-06, 1.1085e-04, 5.0366e-05, 1.6488e-02, 9.7619e-01,
        6.1388e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,633][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0056, 0.2152, 0.0183, 0.4791, 0.0106, 0.0917, 0.1795],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,634][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0007, 0.0584, 0.0918, 0.0746, 0.2076, 0.4481, 0.1188],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,634][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0290, 0.0445, 0.0557, 0.0940, 0.1770, 0.2360, 0.1277, 0.2361],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,634][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([4.5131e-05, 3.7065e-02, 8.7053e-02, 2.1415e-02, 4.1690e-01, 1.2502e-01,
        7.4069e-02, 2.3843e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,635][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0613, 0.0164, 0.0679, 0.0165, 0.4538, 0.1605, 0.0670, 0.1567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,635][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0151, 0.0534, 0.0449, 0.0516, 0.0485, 0.3044, 0.2630, 0.2191],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,635][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0646, 0.0197, 0.0110, 0.0414, 0.0803, 0.1748, 0.1260, 0.4821],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,636][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([4.8639e-02, 5.4404e-08, 3.8372e-07, 8.5153e-07, 2.0256e-04, 5.7242e-02,
        2.0737e-04, 8.9371e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,636][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0060, 0.0349, 0.0824, 0.0551, 0.2662, 0.2076, 0.1310, 0.2167],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,636][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0769, 0.0807, 0.0258, 0.0283, 0.5850, 0.0586, 0.0197, 0.1250],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,636][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0383, 0.4043, 0.1246, 0.1290, 0.0193, 0.0608, 0.1616, 0.0620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,637][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([1.3099e-04, 1.7597e-10, 4.7545e-09, 7.9139e-09, 5.7047e-06, 1.1067e-02,
        7.5060e-06, 9.8879e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,637][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0017, 0.2059, 0.0078, 0.4533, 0.0043, 0.1003, 0.1953, 0.0314],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,639][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0025, 0.0572, 0.0904, 0.0444, 0.1759, 0.4171, 0.0874, 0.1251],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,641][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0115, 0.0420, 0.0546, 0.1017, 0.1426, 0.2501, 0.1132, 0.1713, 0.1130],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,642][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([3.4077e-05, 3.8989e-02, 1.3167e-01, 2.7598e-02, 4.1998e-01, 1.0277e-01,
        4.6550e-02, 1.9902e-01, 3.3396e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,643][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0081, 0.0195, 0.0234, 0.0367, 0.3904, 0.1470, 0.0874, 0.2543, 0.0333],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,644][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0146, 0.0355, 0.0617, 0.0513, 0.0369, 0.2031, 0.1244, 0.2259, 0.2465],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,646][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0133, 0.0091, 0.0081, 0.0179, 0.0379, 0.0709, 0.0311, 0.2094, 0.6024],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,647][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([6.0713e-01, 5.0463e-08, 5.0270e-08, 4.1602e-07, 2.8748e-06, 6.3436e-04,
        1.5656e-05, 1.0134e-05, 3.9221e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,648][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0014, 0.0549, 0.0610, 0.0653, 0.1718, 0.2083, 0.0957, 0.2140, 0.1276],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,650][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0116, 0.1117, 0.0624, 0.0669, 0.4808, 0.0549, 0.0239, 0.1388, 0.0489],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,651][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0294, 0.3772, 0.1057, 0.1398, 0.0245, 0.0436, 0.0609, 0.1109, 0.1080],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,651][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([3.8610e-02, 2.6781e-09, 7.5535e-09, 6.5840e-08, 5.2033e-07, 2.8772e-04,
        6.2872e-06, 6.0039e-06, 9.6109e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,651][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0014, 0.1987, 0.0122, 0.4171, 0.0061, 0.0798, 0.1839, 0.0310, 0.0697],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,652][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([4.2141e-05, 7.0040e-02, 7.6078e-02, 5.5120e-02, 8.3226e-02, 4.6682e-01,
        7.0212e-02, 2.9993e-02, 1.4847e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,652][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0280, 0.0238, 0.0414, 0.0621, 0.1219, 0.2336, 0.0936, 0.1875, 0.1321,
        0.0760], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,652][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([7.2380e-05, 3.3201e-02, 7.3372e-02, 3.1284e-02, 3.1366e-01, 1.3987e-01,
        8.0113e-02, 1.1790e-01, 6.3717e-02, 1.4681e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,653][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0911, 0.0262, 0.0439, 0.0258, 0.4207, 0.1002, 0.0271, 0.0493, 0.0147,
        0.2009], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,653][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0077, 0.0144, 0.0211, 0.0428, 0.0232, 0.1906, 0.1738, 0.1172, 0.2239,
        0.1852], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,653][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0144, 0.0061, 0.0099, 0.0131, 0.0282, 0.0868, 0.0362, 0.1188, 0.6016,
        0.0849], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,653][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([1.6381e-02, 9.6782e-10, 1.6102e-09, 8.3515e-09, 5.4285e-07, 2.0344e-04,
        1.8226e-06, 2.7677e-05, 9.5405e-01, 2.9340e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,654][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0021, 0.0171, 0.0119, 0.0331, 0.0442, 0.1733, 0.0886, 0.1535, 0.1761,
        0.3000], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,654][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0955, 0.1004, 0.0371, 0.0303, 0.3781, 0.0643, 0.0191, 0.0991, 0.0319,
        0.1442], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,655][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0249, 0.2332, 0.0651, 0.0675, 0.0295, 0.0370, 0.0364, 0.0634, 0.0889,
        0.3541], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,656][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.6636e-04, 8.4794e-12, 3.3896e-11, 1.6984e-10, 2.3111e-08, 3.4095e-05,
        1.3815e-07, 8.9824e-06, 9.5095e-01, 4.8843e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,658][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0015, 0.2069, 0.0050, 0.4658, 0.0024, 0.0809, 0.1448, 0.0263, 0.0607,
        0.0057], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,659][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0015, 0.0291, 0.0479, 0.0396, 0.1005, 0.3415, 0.1002, 0.0440, 0.1951,
        0.1006], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,660][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0116, 0.0343, 0.0533, 0.0859, 0.1599, 0.1799, 0.0826, 0.1562, 0.0850,
        0.0810, 0.0705], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,661][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([1.5659e-04, 2.4031e-02, 7.2653e-02, 1.7954e-02, 3.4522e-01, 8.2454e-02,
        3.0363e-02, 1.2303e-01, 4.2148e-02, 1.3496e-01, 1.2702e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,663][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0136, 0.0144, 0.0357, 0.0166, 0.4272, 0.1043, 0.0351, 0.0952, 0.0101,
        0.2288, 0.0190], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,665][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0786, 0.0198, 0.0232, 0.0175, 0.0278, 0.1160, 0.0846, 0.0766, 0.2120,
        0.1156, 0.2284], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,666][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0480, 0.0051, 0.0046, 0.0121, 0.0227, 0.0454, 0.0249, 0.0890, 0.2567,
        0.1069, 0.3845], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,667][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([9.3913e-01, 7.4285e-08, 5.5520e-08, 2.0314e-07, 4.5766e-06, 3.5639e-04,
        1.1929e-05, 2.7144e-06, 1.5198e-02, 5.1823e-04, 4.4781e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,668][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0085, 0.0260, 0.0194, 0.0398, 0.0780, 0.1490, 0.0798, 0.0958, 0.1326,
        0.2718, 0.0993], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,668][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0216, 0.1189, 0.0345, 0.0435, 0.5131, 0.0490, 0.0179, 0.0657, 0.0382,
        0.0541, 0.0436], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,669][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0232, 0.2828, 0.0416, 0.0770, 0.0233, 0.0378, 0.0379, 0.0713, 0.0705,
        0.1878, 0.1469], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,669][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([5.4021e-01, 2.7614e-08, 2.5319e-08, 1.0625e-07, 2.1684e-06, 4.2694e-04,
        1.5102e-05, 6.0834e-06, 5.5214e-02, 4.3987e-03, 3.9973e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,669][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0020, 0.1701, 0.0105, 0.4148, 0.0049, 0.0654, 0.1514, 0.0284, 0.0541,
        0.0088, 0.0896], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,670][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0585, 0.0436, 0.1291, 0.0798, 0.0514, 0.2307, 0.0356, 0.0492, 0.0856,
        0.0823, 0.1543], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,670][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0426, 0.0301, 0.0378, 0.0697, 0.1048, 0.1377, 0.0757, 0.1220, 0.1048,
        0.0629, 0.0712, 0.1407], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,670][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([6.6871e-05, 1.1556e-02, 3.1385e-02, 1.3191e-02, 1.1577e-01, 4.0472e-02,
        2.4393e-02, 6.1846e-02, 3.4734e-02, 9.4832e-02, 9.9605e-02, 4.7215e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,671][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1715, 0.0217, 0.0271, 0.0253, 0.3199, 0.0628, 0.0102, 0.0938, 0.0121,
        0.2279, 0.0140, 0.0138], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,671][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0344, 0.0057, 0.0069, 0.0110, 0.0090, 0.0601, 0.0403, 0.0310, 0.0861,
        0.0598, 0.1228, 0.5330], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,671][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0296, 0.0022, 0.0012, 0.0059, 0.0088, 0.0183, 0.0121, 0.0233, 0.2244,
        0.0354, 0.2277, 0.4111], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,672][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([8.4587e-01, 1.6832e-08, 3.6200e-09, 1.6807e-08, 3.5136e-07, 1.8633e-05,
        1.0426e-06, 2.1463e-08, 1.9205e-04, 3.3340e-06, 1.4909e-03, 1.5243e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,673][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0054, 0.0147, 0.0094, 0.0246, 0.0379, 0.0761, 0.0444, 0.0481, 0.1112,
        0.1762, 0.0778, 0.3743], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,675][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0575, 0.1376, 0.0328, 0.0530, 0.3117, 0.0318, 0.0198, 0.0637, 0.0605,
        0.0397, 0.0477, 0.1443], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,676][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0097, 0.2203, 0.0383, 0.0814, 0.0121, 0.0213, 0.0250, 0.0692, 0.0568,
        0.2424, 0.0965, 0.1271], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,677][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.4990e-01, 1.4464e-09, 5.5694e-10, 2.9758e-09, 6.6225e-08, 4.9240e-06,
        4.8695e-07, 7.3824e-09, 1.7160e-04, 3.6820e-06, 3.1948e-03, 7.4673e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,678][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0052, 0.1555, 0.0104, 0.3202, 0.0064, 0.0574, 0.1065, 0.0292, 0.0621,
        0.0127, 0.0868, 0.1476], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,680][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0051, 0.0370, 0.0592, 0.0597, 0.0666, 0.2754, 0.0311, 0.0311, 0.1237,
        0.0471, 0.1554, 0.1085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,682][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0524, 0.0288, 0.0409, 0.0653, 0.1070, 0.1109, 0.0766, 0.0846, 0.1005,
        0.0545, 0.0651, 0.1120, 0.1013], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,683][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ station] are: tensor([4.1573e-05, 1.0386e-02, 3.1366e-02, 1.5742e-02, 1.9754e-01, 3.5706e-02,
        3.2632e-02, 2.6597e-02, 2.8369e-02, 4.4796e-02, 6.2021e-02, 2.0066e-01,
        3.1415e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,684][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0312, 0.0215, 0.0291, 0.0343, 0.3059, 0.1082, 0.0592, 0.0908, 0.0232,
        0.1300, 0.0502, 0.0719, 0.0444], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,685][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0207, 0.0077, 0.0079, 0.0137, 0.0099, 0.0725, 0.0481, 0.0175, 0.0863,
        0.0488, 0.1049, 0.3203, 0.2418], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,686][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0442, 0.0034, 0.0019, 0.0057, 0.0099, 0.0248, 0.0129, 0.0129, 0.1570,
        0.0257, 0.1784, 0.2838, 0.2392], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,686][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ station] are: tensor([8.2640e-02, 2.4125e-09, 7.7269e-10, 7.3110e-09, 3.6517e-07, 1.4001e-05,
        7.3804e-07, 2.8186e-07, 5.4252e-03, 1.0335e-04, 7.3405e-03, 4.3788e-01,
        4.6660e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,686][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0190, 0.0146, 0.0256, 0.0255, 0.0862, 0.0646, 0.0556, 0.0508, 0.0876,
        0.2203, 0.0519, 0.2079, 0.0904], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,687][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0813, 0.0504, 0.0274, 0.0292, 0.5266, 0.0206, 0.0095, 0.0176, 0.0244,
        0.0379, 0.0164, 0.0507, 0.1080], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,687][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0095, 0.1917, 0.0454, 0.0804, 0.0183, 0.0298, 0.0449, 0.0251, 0.0587,
        0.1221, 0.1194, 0.1386, 0.1161], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,687][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ station] are: tensor([4.6511e-03, 6.3038e-11, 4.5253e-11, 3.6527e-10, 2.6029e-08, 1.9383e-06,
        4.0612e-08, 5.8099e-08, 2.8082e-03, 7.1601e-05, 5.1421e-03, 3.9587e-01,
        5.9146e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,688][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0011, 0.1630, 0.0041, 0.3641, 0.0014, 0.0429, 0.1279, 0.0143, 0.0450,
        0.0046, 0.0773, 0.1538, 0.0007], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,688][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0041, 0.0305, 0.0370, 0.0410, 0.0756, 0.1259, 0.0423, 0.0245, 0.0902,
        0.0418, 0.1187, 0.0993, 0.2692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,688][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0138, 0.0309, 0.0347, 0.0494, 0.0943, 0.1512, 0.0619, 0.0857, 0.0882,
        0.0595, 0.0632, 0.1198, 0.1006, 0.0467], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,689][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.4926e-05, 1.0512e-02, 3.2817e-02, 9.7647e-03, 1.5198e-01, 3.7290e-02,
        2.7284e-02, 4.3826e-02, 1.8357e-02, 7.4784e-02, 6.4593e-02, 1.7206e-01,
        3.3437e-01, 2.2341e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,689][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0067, 0.0112, 0.0196, 0.0130, 0.3913, 0.1167, 0.0515, 0.1014, 0.0147,
        0.1562, 0.0246, 0.0482, 0.0324, 0.0123], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,691][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0165, 0.0054, 0.0107, 0.0096, 0.0159, 0.0507, 0.0348, 0.0306, 0.0694,
        0.0493, 0.1108, 0.3029, 0.2400, 0.0533], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,693][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0081, 0.0020, 0.0016, 0.0043, 0.0079, 0.0188, 0.0070, 0.0376, 0.1371,
        0.0421, 0.2080, 0.2766, 0.1889, 0.0600], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,694][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([8.3421e-04, 3.0744e-10, 5.3981e-10, 1.8376e-09, 4.9353e-08, 8.2742e-06,
        1.2574e-07, 1.5674e-06, 1.1913e-02, 1.0020e-03, 1.2259e-02, 5.2899e-01,
        4.4323e-01, 1.7567e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,695][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0022, 0.0172, 0.0231, 0.0207, 0.0798, 0.0929, 0.0408, 0.0466, 0.0648,
        0.1389, 0.0500, 0.1843, 0.1345, 0.1043], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,697][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0180, 0.0831, 0.0448, 0.0296, 0.3342, 0.0327, 0.0120, 0.0525, 0.0396,
        0.0514, 0.0250, 0.0882, 0.1310, 0.0578], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,699][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0153, 0.1015, 0.0243, 0.0460, 0.0153, 0.0212, 0.0262, 0.0385, 0.0550,
        0.2292, 0.0915, 0.1053, 0.1405, 0.0901], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,699][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.3937e-06, 2.0012e-12, 1.1373e-11, 3.8812e-11, 1.2078e-09, 4.3404e-07,
        4.9307e-09, 4.0723e-07, 5.2369e-03, 8.2398e-04, 5.4708e-03, 5.0831e-01,
        4.7957e-01, 5.7729e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,701][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0037, 0.1618, 0.0106, 0.2434, 0.0073, 0.0644, 0.1105, 0.0320, 0.0621,
        0.0170, 0.0999, 0.1606, 0.0041, 0.0226], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,702][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0006, 0.0282, 0.0680, 0.0340, 0.0723, 0.1486, 0.0275, 0.0304, 0.0724,
        0.0446, 0.0545, 0.0736, 0.2573, 0.0879], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,703][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0270, 0.0182, 0.0339, 0.0465, 0.0890, 0.1303, 0.0691, 0.1012, 0.0817,
        0.0502, 0.0459, 0.0949, 0.0636, 0.0410, 0.1077], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,703][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([2.1585e-04, 6.3041e-03, 1.6292e-02, 9.3166e-03, 1.1393e-01, 2.6324e-02,
        1.9883e-02, 2.6175e-02, 1.5702e-02, 3.0453e-02, 8.2229e-02, 1.6694e-01,
        2.5372e-01, 1.4833e-02, 2.1769e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,704][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.0047, 0.0384, 0.0223, 0.0397, 0.2318, 0.0822, 0.0585, 0.0465, 0.0208,
        0.2291, 0.0722, 0.0625, 0.0466, 0.0200, 0.0245], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,704][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0277, 0.0030, 0.0069, 0.0103, 0.0078, 0.0339, 0.0233, 0.0086, 0.0502,
        0.0270, 0.0666, 0.1805, 0.0686, 0.0328, 0.4527], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,704][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.1088, 0.0013, 0.0009, 0.0039, 0.0072, 0.0150, 0.0072, 0.0082, 0.1327,
        0.0093, 0.1969, 0.1625, 0.0829, 0.0489, 0.2144], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,705][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([1.6597e-01, 2.0031e-08, 6.4058e-09, 3.8973e-08, 1.4417e-06, 3.1653e-05,
        2.8404e-06, 1.1217e-06, 7.6310e-03, 1.6978e-04, 9.6285e-03, 2.5173e-01,
        3.9355e-01, 1.9505e-03, 1.6932e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,705][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0133, 0.0078, 0.0073, 0.0131, 0.0246, 0.0450, 0.0374, 0.0135, 0.0771,
        0.0587, 0.0611, 0.1962, 0.0705, 0.0837, 0.2905], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,705][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.2712, 0.0797, 0.0159, 0.0348, 0.2146, 0.0209, 0.0100, 0.0218, 0.0455,
        0.0186, 0.0219, 0.0737, 0.0740, 0.0486, 0.0488], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,706][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0293, 0.0847, 0.0511, 0.0522, 0.0306, 0.0165, 0.0323, 0.0229, 0.0584,
        0.1242, 0.1030, 0.0689, 0.0722, 0.0508, 0.2027], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,706][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([4.3964e-02, 4.5897e-10, 4.5437e-10, 2.5413e-09, 8.1696e-08, 2.8009e-06,
        1.4460e-07, 1.5911e-07, 4.1761e-03, 1.8701e-04, 5.8524e-03, 2.0553e-01,
        4.0200e-01, 6.4170e-04, 3.3764e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,707][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([4.2248e-04, 1.4441e-01, 2.7871e-03, 3.8689e-01, 8.7112e-04, 3.4912e-02,
        1.2216e-01, 5.8917e-03, 3.2573e-02, 3.1663e-03, 6.4592e-02, 1.9346e-01,
        2.9606e-04, 6.7987e-03, 7.7003e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,708][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0028, 0.0128, 0.0372, 0.0226, 0.0726, 0.0469, 0.0109, 0.0067, 0.0565,
        0.0143, 0.0601, 0.0240, 0.1549, 0.0459, 0.4319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,710][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0826, 0.0151, 0.0270, 0.0350, 0.0733, 0.0751, 0.0432, 0.0694, 0.0619,
        0.0401, 0.0476, 0.0871, 0.0930, 0.0414, 0.0904, 0.1179],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,712][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0007, 0.0043, 0.0398, 0.0080, 0.0900, 0.0111, 0.0099, 0.0135, 0.0137,
        0.0287, 0.0278, 0.1562, 0.2266, 0.0103, 0.2055, 0.1538],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,713][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.4301, 0.0074, 0.0289, 0.0077, 0.2081, 0.0469, 0.0113, 0.0132, 0.0040,
        0.1076, 0.0131, 0.0125, 0.0442, 0.0025, 0.0360, 0.0265],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,714][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0564, 0.0025, 0.0043, 0.0041, 0.0044, 0.0091, 0.0105, 0.0037, 0.0216,
        0.0162, 0.0252, 0.0910, 0.0664, 0.0203, 0.3943, 0.2699],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,715][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.2614e-01, 6.0873e-04, 3.1415e-04, 1.3781e-03, 1.9429e-03, 5.1740e-03,
        2.1816e-03, 3.6460e-03, 5.2948e-02, 6.1128e-03, 5.6783e-02, 8.8658e-02,
        5.1897e-02, 2.5475e-02, 8.7239e-02, 4.8950e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,716][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([2.2691e-01, 8.5221e-11, 5.1069e-12, 1.3340e-10, 2.3316e-09, 1.1737e-07,
        1.6142e-08, 3.8280e-11, 7.7009e-06, 3.2654e-08, 2.8381e-05, 4.0339e-03,
        1.7787e-03, 1.4430e-06, 1.3408e-03, 7.6590e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,718][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0739, 0.0114, 0.0147, 0.0168, 0.0264, 0.0281, 0.0177, 0.0124, 0.0442,
        0.0829, 0.0247, 0.1271, 0.0531, 0.0468, 0.1622, 0.2576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,719][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.2035, 0.0583, 0.0228, 0.0247, 0.1568, 0.0208, 0.0085, 0.0180, 0.0262,
        0.0288, 0.0236, 0.0659, 0.1079, 0.0248, 0.0479, 0.1614],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,720][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0204, 0.1170, 0.0425, 0.0572, 0.0147, 0.0131, 0.0260, 0.0167, 0.0451,
        0.0798, 0.0557, 0.1319, 0.0600, 0.0546, 0.0964, 0.1688],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,720][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.8485e-02, 4.1293e-13, 5.3927e-14, 9.4198e-13, 2.2984e-11, 8.2892e-10,
        1.1701e-10, 5.6193e-13, 2.8262e-07, 1.5350e-09, 2.6653e-06, 6.5821e-04,
        3.2299e-04, 6.3916e-08, 6.8554e-04, 9.7985e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,721][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0030, 0.1350, 0.0030, 0.3871, 0.0012, 0.0477, 0.0909, 0.0129, 0.0330,
        0.0035, 0.0901, 0.1624, 0.0008, 0.0090, 0.0011, 0.0193],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,721][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0882, 0.0088, 0.0207, 0.0202, 0.0171, 0.0386, 0.0048, 0.0068, 0.0234,
        0.0074, 0.0309, 0.0181, 0.1199, 0.0165, 0.1068, 0.4720],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,721][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0357, 0.0235, 0.0226, 0.0476, 0.0704, 0.0897, 0.0458, 0.0583, 0.0727,
        0.0370, 0.0492, 0.0947, 0.0711, 0.0390, 0.0650, 0.1007, 0.0769],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,722][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.4265e-04, 2.8602e-03, 8.8534e-03, 3.9907e-03, 4.7961e-02, 6.9355e-03,
        6.7170e-03, 9.1988e-03, 1.0062e-02, 2.4796e-02, 2.8981e-02, 1.9376e-01,
        1.8737e-01, 9.8582e-03, 1.5580e-01, 1.0798e-01, 1.9473e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,722][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1094, 0.0225, 0.0279, 0.0162, 0.3268, 0.0548, 0.0106, 0.0350, 0.0131,
        0.1763, 0.0171, 0.0172, 0.0922, 0.0144, 0.0323, 0.0152, 0.0191],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,722][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0503, 0.0017, 0.0020, 0.0027, 0.0026, 0.0076, 0.0073, 0.0045, 0.0237,
        0.0139, 0.0286, 0.1426, 0.0690, 0.0198, 0.1863, 0.2929, 0.1444],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,723][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0548, 0.0006, 0.0006, 0.0017, 0.0031, 0.0073, 0.0025, 0.0072, 0.0448,
        0.0107, 0.0418, 0.0895, 0.0487, 0.0143, 0.0570, 0.5500, 0.0655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,723][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.4479e-02, 2.0624e-09, 5.2626e-10, 2.2844e-09, 6.0740e-08, 1.5666e-06,
        1.0923e-07, 7.8116e-09, 4.8134e-05, 7.0465e-07, 7.7358e-05, 5.3186e-03,
        7.5826e-03, 1.7922e-05, 4.8416e-03, 8.9044e-01, 1.7193e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,724][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0157, 0.0054, 0.0056, 0.0073, 0.0186, 0.0189, 0.0112, 0.0094, 0.0290,
        0.0642, 0.0274, 0.1413, 0.0538, 0.0383, 0.1362, 0.2245, 0.1931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,726][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2527, 0.0701, 0.0150, 0.0262, 0.1277, 0.0148, 0.0090, 0.0197, 0.0351,
        0.0330, 0.0259, 0.0768, 0.0890, 0.0411, 0.0386, 0.0837, 0.0417],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,727][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0302, 0.0416, 0.0216, 0.0499, 0.0138, 0.0102, 0.0124, 0.0321, 0.0384,
        0.1047, 0.0653, 0.1304, 0.0865, 0.0552, 0.1090, 0.1091, 0.0895],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,728][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.3137e-03, 3.8078e-12, 2.9668e-12, 1.1556e-11, 4.1832e-10, 1.1672e-08,
        1.0283e-09, 8.3540e-11, 7.3480e-07, 2.4385e-08, 2.5083e-06, 3.9465e-04,
        8.9147e-04, 3.9786e-07, 1.0298e-03, 9.9347e-01, 2.8981e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,730][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0054, 0.1539, 0.0083, 0.2729, 0.0048, 0.0441, 0.0832, 0.0174, 0.0443,
        0.0087, 0.0771, 0.1295, 0.0027, 0.0170, 0.0037, 0.0279, 0.0993],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,732][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1001, 0.0048, 0.0163, 0.0074, 0.0143, 0.0219, 0.0030, 0.0050, 0.0108,
        0.0124, 0.0120, 0.0130, 0.1279, 0.0371, 0.2124, 0.3711, 0.0304],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,733][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0386, 0.0181, 0.0196, 0.0326, 0.0473, 0.0907, 0.0452, 0.0526, 0.0609,
        0.0291, 0.0423, 0.0710, 0.0663, 0.0353, 0.0600, 0.1090, 0.0658, 0.1155],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,735][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0002, 0.0099, 0.0184, 0.0130, 0.0442, 0.0188, 0.0180, 0.0132, 0.0169,
        0.0221, 0.0375, 0.1431, 0.1348, 0.0242, 0.1500, 0.0917, 0.1997, 0.0445],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,736][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.0421, 0.0318, 0.0123, 0.0269, 0.1193, 0.0530, 0.0283, 0.0501, 0.0212,
        0.1470, 0.0705, 0.0454, 0.0455, 0.0248, 0.0188, 0.0681, 0.0865, 0.1082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,737][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0366, 0.0070, 0.0046, 0.0068, 0.0028, 0.0145, 0.0118, 0.0059, 0.0284,
        0.0179, 0.0338, 0.0826, 0.0908, 0.0396, 0.2052, 0.2128, 0.1367, 0.0622],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,737][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([0.0278, 0.0009, 0.0005, 0.0018, 0.0037, 0.0052, 0.0026, 0.0046, 0.0322,
        0.0057, 0.0439, 0.0672, 0.0427, 0.0206, 0.0534, 0.4840, 0.0642, 0.1391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,738][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([6.5863e-03, 2.5139e-09, 1.3578e-09, 5.4960e-09, 2.0296e-07, 3.3588e-06,
        2.7079e-07, 3.0972e-07, 4.7791e-04, 1.4872e-05, 2.2733e-04, 3.5710e-03,
        1.2136e-02, 2.8650e-04, 6.9656e-03, 9.4770e-01, 1.2336e-02, 9.6974e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,738][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0071, 0.0121, 0.0081, 0.0201, 0.0195, 0.0300, 0.0304, 0.0088, 0.0490,
        0.0467, 0.0230, 0.1091, 0.0357, 0.0700, 0.1252, 0.1102, 0.2214, 0.0736],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,739][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.1501, 0.0437, 0.0242, 0.0260, 0.1954, 0.0150, 0.0091, 0.0166, 0.0247,
        0.0272, 0.0218, 0.0697, 0.0869, 0.0325, 0.0493, 0.1306, 0.0389, 0.0383],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,739][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0115, 0.1665, 0.0360, 0.0735, 0.0102, 0.0131, 0.0199, 0.0129, 0.0345,
        0.0724, 0.0612, 0.0926, 0.0524, 0.0509, 0.0413, 0.0680, 0.0871, 0.0960],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,739][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([2.8275e-04, 2.8488e-11, 2.8521e-11, 1.1026e-10, 5.5090e-09, 8.6793e-08,
        5.8701e-09, 2.7130e-08, 9.0316e-05, 4.6639e-06, 2.9319e-05, 8.8308e-04,
        4.9972e-03, 4.0176e-05, 4.6681e-03, 9.7653e-01, 3.2170e-03, 9.2615e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,740][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0009, 0.1458, 0.0027, 0.2758, 0.0012, 0.0424, 0.0994, 0.0101, 0.0382,
        0.0041, 0.0781, 0.1374, 0.0007, 0.0107, 0.0012, 0.0251, 0.1230, 0.0030],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,740][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0113, 0.0131, 0.0233, 0.0236, 0.0233, 0.0484, 0.0067, 0.0071, 0.0254,
        0.0112, 0.0241, 0.0143, 0.0960, 0.0417, 0.1584, 0.2218, 0.0280, 0.2223],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,741][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0170, 0.0224, 0.0227, 0.0390, 0.0610, 0.0906, 0.0401, 0.0466, 0.0512,
        0.0357, 0.0408, 0.0726, 0.0578, 0.0254, 0.0619, 0.1012, 0.0654, 0.1002,
        0.0483], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,741][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0004, 0.0074, 0.0173, 0.0056, 0.0389, 0.0078, 0.0062, 0.0082, 0.0083,
        0.0189, 0.0286, 0.1226, 0.1753, 0.0108, 0.1411, 0.1204, 0.1248, 0.0566,
        0.1008], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,743][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0200, 0.0126, 0.0138, 0.0318, 0.2139, 0.0912, 0.0437, 0.0522, 0.0118,
        0.1347, 0.0301, 0.0601, 0.0437, 0.0118, 0.0149, 0.0460, 0.0881, 0.0560,
        0.0237], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,745][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0903, 0.0021, 0.0040, 0.0033, 0.0031, 0.0074, 0.0068, 0.0031, 0.0202,
        0.0094, 0.0255, 0.0960, 0.0634, 0.0168, 0.2004, 0.2187, 0.0968, 0.0482,
        0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,746][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0725, 0.0009, 0.0014, 0.0019, 0.0046, 0.0049, 0.0022, 0.0037, 0.0305,
        0.0065, 0.0344, 0.0493, 0.0356, 0.0106, 0.0604, 0.4644, 0.0437, 0.0952,
        0.0775], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,747][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.1889e-02, 2.9043e-08, 1.7066e-08, 3.4872e-08, 1.3383e-06, 1.4444e-05,
        1.3076e-06, 6.8006e-07, 4.4992e-04, 2.4114e-05, 2.7785e-04, 4.7013e-03,
        2.4688e-02, 2.9827e-04, 1.5018e-02, 8.2691e-01, 1.7616e-02, 2.6619e-02,
        1.1491e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,749][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0151, 0.0097, 0.0060, 0.0114, 0.0150, 0.0196, 0.0136, 0.0060, 0.0294,
        0.0266, 0.0260, 0.1036, 0.0413, 0.0510, 0.0829, 0.1790, 0.1822, 0.0848,
        0.0967], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,751][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1401, 0.0830, 0.0292, 0.0282, 0.1339, 0.0122, 0.0060, 0.0138, 0.0263,
        0.0209, 0.0177, 0.0629, 0.1138, 0.0324, 0.0501, 0.1197, 0.0286, 0.0304,
        0.0505], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,753][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0290, 0.0834, 0.0270, 0.0362, 0.0127, 0.0100, 0.0095, 0.0141, 0.0258,
        0.0821, 0.0432, 0.0812, 0.0580, 0.0341, 0.0679, 0.0811, 0.0729, 0.0992,
        0.1327], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,754][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.3527e-03, 4.2548e-10, 4.2881e-10, 8.3005e-10, 4.1170e-08, 4.0088e-07,
        4.8561e-08, 4.3367e-08, 3.8224e-05, 3.5892e-06, 3.0989e-05, 9.1492e-04,
        6.3064e-03, 3.1631e-05, 5.7782e-03, 9.5491e-01, 5.9570e-03, 1.8299e-02,
        5.3765e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,754][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0038, 0.1202, 0.0080, 0.2087, 0.0051, 0.0446, 0.0878, 0.0179, 0.0426,
        0.0109, 0.0697, 0.1360, 0.0029, 0.0166, 0.0041, 0.0326, 0.1081, 0.0077,
        0.0726], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,754][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0121, 0.0119, 0.0411, 0.0191, 0.0282, 0.0295, 0.0050, 0.0050, 0.0201,
        0.0082, 0.0225, 0.0146, 0.0796, 0.0319, 0.1721, 0.2393, 0.0267, 0.1632,
        0.0698], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,801][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:58,803][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,804][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,806][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,807][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,808][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,808][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,808][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,808][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,809][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,809][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,809][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,810][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:58,810][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0330, 0.9670], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,810][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.1223e-04, 9.9909e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,811][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0029, 0.9971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,811][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1416, 0.8584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,811][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2794, 0.7206], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,812][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3241, 0.6759], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,813][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0170, 0.9830], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,815][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0256, 0.9744], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,817][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0051, 0.9949], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,818][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0323, 0.9677], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,818][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5544, 0.4456], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,820][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([4.4712e-04, 9.9955e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:58,821][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0664, 0.7230, 0.2106], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,823][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0019, 0.6025, 0.3956], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,824][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0080, 0.7819, 0.2101], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,825][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0461, 0.3177, 0.6362], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,825][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.1122, 0.5214, 0.3665], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,826][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.3960, 0.1023, 0.5017], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,826][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0365, 0.7111, 0.2524], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,826][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.1027, 0.7774, 0.1199], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,826][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0172, 0.6494, 0.3334], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,827][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0777, 0.0324, 0.8899], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,827][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.1165, 0.0378, 0.8457], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,827][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([8.1467e-05, 3.5066e-01, 6.4926e-01], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:58,827][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0083, 0.4314, 0.1481, 0.4122], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,828][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([3.7920e-04, 3.8738e-01, 3.0920e-01, 3.0304e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,828][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0023, 0.2736, 0.1082, 0.6159], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,828][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1518, 0.1999, 0.2534, 0.3949], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,829][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0569, 0.2447, 0.2364, 0.4620], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,829][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.6279, 0.0519, 0.2327, 0.0875], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,831][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0117, 0.3194, 0.1473, 0.5216], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,833][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0501, 0.5434, 0.1618, 0.2447], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,834][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0117, 0.6316, 0.1050, 0.2518], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,835][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0236, 0.0415, 0.7277, 0.2073], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,836][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0446, 0.0211, 0.9249, 0.0094], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,837][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([5.2159e-05, 3.0407e-01, 2.9795e-01, 3.9793e-01], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:58,839][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.0248, 0.2329, 0.2114, 0.3015, 0.2294], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,840][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([3.6792e-04, 7.5463e-02, 1.6114e-01, 5.7572e-02, 7.0545e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,841][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.0083, 0.3309, 0.0941, 0.4364, 0.1303], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,842][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0194, 0.1041, 0.2577, 0.3015, 0.3173], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,843][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.0518, 0.1560, 0.1040, 0.2752, 0.4130], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,843][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([1.9487e-01, 7.6441e-04, 3.6012e-03, 3.3936e-03, 7.9737e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,843][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.0221, 0.2205, 0.1600, 0.2904, 0.3070], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,844][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.1194, 0.0921, 0.0212, 0.0483, 0.7190], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,844][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.0320, 0.3397, 0.2976, 0.2237, 0.1069], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,844][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([7.9068e-02, 4.5874e-04, 9.3952e-03, 5.5189e-03, 9.0556e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,844][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.0832, 0.0361, 0.7331, 0.0128, 0.1349], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,845][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.0012, 0.1378, 0.1896, 0.2089, 0.4625], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:58,845][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0438, 0.1158, 0.1285, 0.0684, 0.1585, 0.4849], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,845][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0006, 0.0432, 0.1095, 0.0388, 0.5027, 0.3052], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,846][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0032, 0.1343, 0.0397, 0.2128, 0.0609, 0.5491], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,846][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1011, 0.0655, 0.0545, 0.0606, 0.0679, 0.6503], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,846][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0492, 0.0378, 0.0233, 0.1018, 0.1176, 0.6702], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,847][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([4.6377e-01, 3.0878e-05, 5.0985e-05, 7.4438e-05, 1.3529e-02, 5.2255e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,848][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0323, 0.0752, 0.0599, 0.1074, 0.1235, 0.6018], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,850][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0449, 0.1712, 0.0252, 0.0652, 0.5116, 0.1818], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,851][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0417, 0.5370, 0.1466, 0.1540, 0.0221, 0.0986], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,852][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.1957e-01, 7.3310e-06, 4.4605e-05, 3.5813e-05, 1.0745e-02, 8.6960e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,853][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1415, 0.0130, 0.6881, 0.0064, 0.1476, 0.0033], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,855][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0029, 0.0753, 0.0889, 0.0746, 0.1500, 0.6082], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:58,857][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0041, 0.1173, 0.0821, 0.0579, 0.1499, 0.4287, 0.1599],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,858][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.4666e-04, 2.8715e-02, 6.3162e-02, 2.8792e-02, 5.6763e-01, 1.9338e-01,
        1.1817e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,859][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0028, 0.0800, 0.0612, 0.1686, 0.1564, 0.3678, 0.1630],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,860][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0272, 0.0320, 0.0402, 0.0496, 0.0704, 0.4187, 0.3619],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,860][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0213, 0.0163, 0.0142, 0.0458, 0.0971, 0.5771, 0.2282],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,861][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.0132e-02, 5.7218e-05, 1.1488e-04, 9.0764e-05, 1.7728e-02, 9.3306e-01,
        8.8139e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,861][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0067, 0.0470, 0.0444, 0.0639, 0.1958, 0.3796, 0.2628],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,861][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0260, 0.2041, 0.0259, 0.0950, 0.5035, 0.0912, 0.0543],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,862][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0633, 0.2724, 0.1412, 0.2432, 0.0742, 0.0784, 0.1273],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,862][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.0140e-03, 6.9825e-06, 1.1085e-04, 5.0366e-05, 1.6488e-02, 9.7619e-01,
        6.1388e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,862][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0457, 0.0124, 0.6383, 0.0061, 0.2919, 0.0028, 0.0027],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,862][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0007, 0.0584, 0.0918, 0.0746, 0.2076, 0.4481, 0.1188],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:58,863][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0047, 0.0584, 0.1221, 0.0377, 0.2345, 0.1797, 0.0940, 0.2688],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,863][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([4.5131e-05, 3.7065e-02, 8.7053e-02, 2.1415e-02, 4.1690e-01, 1.2502e-01,
        7.4069e-02, 2.3843e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,863][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0009, 0.1170, 0.0279, 0.1362, 0.1265, 0.2591, 0.1959, 0.1365],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,864][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0151, 0.0534, 0.0449, 0.0516, 0.0485, 0.3044, 0.2630, 0.2191],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,864][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0646, 0.0197, 0.0110, 0.0414, 0.0803, 0.1748, 0.1260, 0.4821],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,865][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([4.8639e-02, 5.4404e-08, 3.8372e-07, 8.5153e-07, 2.0256e-04, 5.7242e-02,
        2.0737e-04, 8.9371e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,867][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0060, 0.0349, 0.0824, 0.0551, 0.2662, 0.2076, 0.1310, 0.2167],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,868][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0769, 0.0807, 0.0258, 0.0283, 0.5850, 0.0586, 0.0197, 0.1250],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,870][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0383, 0.4043, 0.1246, 0.1290, 0.0193, 0.0608, 0.1616, 0.0620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,871][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([1.3099e-04, 1.7597e-10, 4.7545e-09, 7.9139e-09, 5.7047e-06, 1.1067e-02,
        7.5060e-06, 9.8879e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,872][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0174, 0.0124, 0.7040, 0.0046, 0.2362, 0.0020, 0.0021, 0.0213],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,874][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0025, 0.0572, 0.0904, 0.0444, 0.1759, 0.4171, 0.0874, 0.1251],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:58,876][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0027, 0.0947, 0.1127, 0.0519, 0.1429, 0.1978, 0.0620, 0.1877, 0.1478],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,877][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([3.4077e-05, 3.8989e-02, 1.3167e-01, 2.7598e-02, 4.1998e-01, 1.0277e-01,
        4.6550e-02, 1.9902e-01, 3.3396e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,877][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0011, 0.0573, 0.0731, 0.1409, 0.1836, 0.1802, 0.0897, 0.2059, 0.0683],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,878][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0146, 0.0355, 0.0617, 0.0513, 0.0369, 0.2031, 0.1244, 0.2259, 0.2465],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,878][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0133, 0.0091, 0.0081, 0.0179, 0.0379, 0.0709, 0.0311, 0.2094, 0.6024],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,878][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([6.0713e-01, 5.0463e-08, 5.0270e-08, 4.1602e-07, 2.8748e-06, 6.3436e-04,
        1.5656e-05, 1.0134e-05, 3.9221e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,879][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0014, 0.0549, 0.0610, 0.0653, 0.1718, 0.2083, 0.0957, 0.2140, 0.1276],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,879][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0116, 0.1117, 0.0624, 0.0669, 0.4808, 0.0549, 0.0239, 0.1388, 0.0489],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,879][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0294, 0.3772, 0.1057, 0.1398, 0.0245, 0.0436, 0.0609, 0.1109, 0.1080],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,880][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([3.8610e-02, 2.6781e-09, 7.5535e-09, 6.5840e-08, 5.2033e-07, 2.8772e-04,
        6.2872e-06, 6.0039e-06, 9.6109e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,880][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([8.8588e-03, 4.7263e-03, 8.7051e-01, 1.6623e-03, 1.0618e-01, 4.6862e-04,
        4.1761e-04, 6.9837e-03, 1.9195e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,880][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([4.2141e-05, 7.0040e-02, 7.6078e-02, 5.5120e-02, 8.3226e-02, 4.6682e-01,
        7.0212e-02, 2.9993e-02, 1.4847e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:58,881][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0039, 0.0477, 0.0316, 0.0380, 0.0452, 0.1634, 0.0763, 0.1626, 0.2795,
        0.1518], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,881][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([7.2380e-05, 3.3201e-02, 7.3372e-02, 3.1284e-02, 3.1366e-01, 1.3987e-01,
        8.0113e-02, 1.1790e-01, 6.3717e-02, 1.4681e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,882][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0012, 0.0608, 0.0144, 0.0685, 0.0354, 0.1967, 0.0959, 0.1325, 0.1092,
        0.2853], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,883][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0077, 0.0144, 0.0211, 0.0428, 0.0232, 0.1906, 0.1738, 0.1172, 0.2239,
        0.1852], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,885][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0144, 0.0061, 0.0099, 0.0131, 0.0282, 0.0868, 0.0362, 0.1188, 0.6016,
        0.0849], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,886][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([1.6381e-02, 9.6782e-10, 1.6102e-09, 8.3515e-09, 5.4285e-07, 2.0344e-04,
        1.8226e-06, 2.7677e-05, 9.5405e-01, 2.9340e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,887][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0021, 0.0171, 0.0119, 0.0331, 0.0442, 0.1733, 0.0886, 0.1535, 0.1761,
        0.3000], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,888][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0955, 0.1004, 0.0371, 0.0303, 0.3781, 0.0643, 0.0191, 0.0991, 0.0319,
        0.1442], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,890][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0249, 0.2332, 0.0651, 0.0675, 0.0295, 0.0370, 0.0364, 0.0634, 0.0889,
        0.3541], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,891][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([1.6636e-04, 8.4794e-12, 3.3896e-11, 1.6984e-10, 2.3111e-08, 3.4095e-05,
        1.3815e-07, 8.9824e-06, 9.5095e-01, 4.8843e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,893][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0134, 0.0178, 0.7347, 0.0109, 0.1292, 0.0033, 0.0026, 0.0273, 0.0026,
        0.0582], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,894][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0015, 0.0291, 0.0479, 0.0396, 0.1005, 0.3415, 0.1002, 0.0440, 0.1951,
        0.1006], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:58,895][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0073, 0.0513, 0.0523, 0.0289, 0.0889, 0.0948, 0.0447, 0.1030, 0.1665,
        0.1838, 0.1785], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,895][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([1.5659e-04, 2.4031e-02, 7.2653e-02, 1.7954e-02, 3.4522e-01, 8.2454e-02,
        3.0363e-02, 1.2303e-01, 4.2148e-02, 1.3496e-01, 1.2702e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,896][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0045, 0.0534, 0.0288, 0.0558, 0.0832, 0.1915, 0.0379, 0.1194, 0.0507,
        0.2232, 0.1516], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,896][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0786, 0.0198, 0.0232, 0.0175, 0.0278, 0.1160, 0.0846, 0.0766, 0.2120,
        0.1156, 0.2284], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,896][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0480, 0.0051, 0.0046, 0.0121, 0.0227, 0.0454, 0.0249, 0.0890, 0.2567,
        0.1069, 0.3845], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,897][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([9.3913e-01, 7.4285e-08, 5.5520e-08, 2.0314e-07, 4.5766e-06, 3.5639e-04,
        1.1929e-05, 2.7144e-06, 1.5198e-02, 5.1823e-04, 4.4781e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,897][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0085, 0.0260, 0.0194, 0.0398, 0.0780, 0.1490, 0.0798, 0.0958, 0.1326,
        0.2718, 0.0993], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,897][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0216, 0.1189, 0.0345, 0.0435, 0.5131, 0.0490, 0.0179, 0.0657, 0.0382,
        0.0541, 0.0436], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,898][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0232, 0.2828, 0.0416, 0.0770, 0.0233, 0.0378, 0.0379, 0.0713, 0.0705,
        0.1878, 0.1469], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,898][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([5.4021e-01, 2.7614e-08, 2.5319e-08, 1.0625e-07, 2.1684e-06, 4.2694e-04,
        1.5102e-05, 6.0834e-06, 5.5214e-02, 4.3987e-03, 3.9973e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,898][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1012, 0.0101, 0.6582, 0.0046, 0.1463, 0.0019, 0.0014, 0.0218, 0.0012,
        0.0503, 0.0030], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,899][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0585, 0.0436, 0.1291, 0.0798, 0.0514, 0.2307, 0.0356, 0.0492, 0.0856,
        0.0823, 0.1543], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:58,899][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0072, 0.0179, 0.0262, 0.0132, 0.0272, 0.0575, 0.0209, 0.0403, 0.0770,
        0.0898, 0.0966, 0.5261], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,901][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([6.6871e-05, 1.1556e-02, 3.1385e-02, 1.3191e-02, 1.1577e-01, 4.0472e-02,
        2.4393e-02, 6.1846e-02, 3.4734e-02, 9.4832e-02, 9.9605e-02, 4.7215e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,902][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0066, 0.0316, 0.0268, 0.0598, 0.0508, 0.1247, 0.0340, 0.0787, 0.0586,
        0.2081, 0.1197, 0.2007], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,904][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0344, 0.0057, 0.0069, 0.0110, 0.0090, 0.0601, 0.0403, 0.0310, 0.0861,
        0.0598, 0.1228, 0.5330], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,905][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0296, 0.0022, 0.0012, 0.0059, 0.0088, 0.0183, 0.0121, 0.0233, 0.2244,
        0.0354, 0.2277, 0.4111], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,906][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([8.4587e-01, 1.6832e-08, 3.6200e-09, 1.6807e-08, 3.5136e-07, 1.8633e-05,
        1.0426e-06, 2.1463e-08, 1.9205e-04, 3.3340e-06, 1.4909e-03, 1.5243e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,908][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0054, 0.0147, 0.0094, 0.0246, 0.0379, 0.0761, 0.0444, 0.0481, 0.1112,
        0.1762, 0.0778, 0.3743], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,910][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0575, 0.1376, 0.0328, 0.0530, 0.3117, 0.0318, 0.0198, 0.0637, 0.0605,
        0.0397, 0.0477, 0.1443], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,911][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0097, 0.2203, 0.0383, 0.0814, 0.0121, 0.0213, 0.0250, 0.0692, 0.0568,
        0.2424, 0.0965, 0.1271], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,912][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.4990e-01, 1.4464e-09, 5.5694e-10, 2.9758e-09, 6.6225e-08, 4.9240e-06,
        4.8695e-07, 7.3824e-09, 1.7160e-04, 3.6820e-06, 3.1948e-03, 7.4673e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,913][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0876, 0.0065, 0.6924, 0.0034, 0.1274, 0.0010, 0.0010, 0.0142, 0.0008,
        0.0549, 0.0024, 0.0085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,913][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0051, 0.0370, 0.0592, 0.0597, 0.0666, 0.2754, 0.0311, 0.0311, 0.1237,
        0.0471, 0.1554, 0.1085], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:58,913][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0163, 0.0175, 0.0406, 0.0167, 0.0340, 0.0554, 0.0322, 0.0350, 0.0795,
        0.0835, 0.0879, 0.3169, 0.1845], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,914][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([4.1573e-05, 1.0386e-02, 3.1366e-02, 1.5742e-02, 1.9754e-01, 3.5706e-02,
        3.2632e-02, 2.6597e-02, 2.8369e-02, 4.4796e-02, 6.2021e-02, 2.0066e-01,
        3.1415e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,914][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0007, 0.0338, 0.0114, 0.0878, 0.0655, 0.1791, 0.0763, 0.0465, 0.0528,
        0.1460, 0.1022, 0.1067, 0.0911], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,914][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0207, 0.0077, 0.0079, 0.0137, 0.0099, 0.0725, 0.0481, 0.0175, 0.0863,
        0.0488, 0.1049, 0.3203, 0.2418], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,915][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0442, 0.0034, 0.0019, 0.0057, 0.0099, 0.0248, 0.0129, 0.0129, 0.1570,
        0.0257, 0.1784, 0.2838, 0.2392], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,915][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([8.2640e-02, 2.4125e-09, 7.7269e-10, 7.3110e-09, 3.6517e-07, 1.4001e-05,
        7.3804e-07, 2.8186e-07, 5.4252e-03, 1.0335e-04, 7.3405e-03, 4.3788e-01,
        4.6660e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,915][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0190, 0.0146, 0.0256, 0.0255, 0.0862, 0.0646, 0.0556, 0.0508, 0.0876,
        0.2203, 0.0519, 0.2079, 0.0904], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,916][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0813, 0.0504, 0.0274, 0.0292, 0.5266, 0.0206, 0.0095, 0.0176, 0.0244,
        0.0379, 0.0164, 0.0507, 0.1080], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,916][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0095, 0.1917, 0.0454, 0.0804, 0.0183, 0.0298, 0.0449, 0.0251, 0.0587,
        0.1221, 0.1194, 0.1386, 0.1161], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,918][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([4.6511e-03, 6.3038e-11, 4.5253e-11, 3.6527e-10, 2.6029e-08, 1.9383e-06,
        4.0612e-08, 5.8099e-08, 2.8082e-03, 7.1601e-05, 5.1421e-03, 3.9587e-01,
        5.9146e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,919][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0386, 0.0123, 0.6037, 0.0076, 0.1544, 0.0016, 0.0029, 0.0129, 0.0015,
        0.0544, 0.0033, 0.0095, 0.0973], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,921][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0041, 0.0305, 0.0370, 0.0410, 0.0756, 0.1259, 0.0423, 0.0245, 0.0902,
        0.0418, 0.1187, 0.0993, 0.2692], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:58,922][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0013, 0.0232, 0.0335, 0.0132, 0.0632, 0.0541, 0.0192, 0.0234, 0.0527,
        0.0493, 0.0636, 0.3620, 0.1950, 0.0463], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,923][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.4926e-05, 1.0512e-02, 3.2817e-02, 9.7647e-03, 1.5198e-01, 3.7290e-02,
        2.7284e-02, 4.3826e-02, 1.8357e-02, 7.4784e-02, 6.4593e-02, 1.7206e-01,
        3.3437e-01, 2.2341e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,925][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0013, 0.0237, 0.0220, 0.0366, 0.0719, 0.1006, 0.0329, 0.0628, 0.0307,
        0.1325, 0.0791, 0.1119, 0.2382, 0.0558], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,927][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0165, 0.0054, 0.0107, 0.0096, 0.0159, 0.0507, 0.0348, 0.0306, 0.0694,
        0.0493, 0.1108, 0.3029, 0.2400, 0.0533], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,928][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0081, 0.0020, 0.0016, 0.0043, 0.0079, 0.0188, 0.0070, 0.0376, 0.1371,
        0.0421, 0.2080, 0.2766, 0.1889, 0.0600], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,929][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([8.3421e-04, 3.0744e-10, 5.3981e-10, 1.8376e-09, 4.9353e-08, 8.2742e-06,
        1.2574e-07, 1.5674e-06, 1.1913e-02, 1.0020e-03, 1.2259e-02, 5.2899e-01,
        4.4323e-01, 1.7567e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,930][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0022, 0.0172, 0.0231, 0.0207, 0.0798, 0.0929, 0.0408, 0.0466, 0.0648,
        0.1389, 0.0500, 0.1843, 0.1345, 0.1043], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,930][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0180, 0.0831, 0.0448, 0.0296, 0.3342, 0.0327, 0.0120, 0.0525, 0.0396,
        0.0514, 0.0250, 0.0882, 0.1310, 0.0578], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,930][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0153, 0.1015, 0.0243, 0.0460, 0.0153, 0.0212, 0.0262, 0.0385, 0.0550,
        0.2292, 0.0915, 0.1053, 0.1405, 0.0901], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,931][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.3937e-06, 2.0012e-12, 1.1373e-11, 3.8812e-11, 1.2078e-09, 4.3404e-07,
        4.9307e-09, 4.0723e-07, 5.2369e-03, 8.2398e-04, 5.4708e-03, 5.0831e-01,
        4.7957e-01, 5.7729e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,931][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([2.0165e-02, 4.4879e-03, 6.6849e-01, 2.2016e-03, 1.5673e-01, 1.1000e-03,
        8.0530e-04, 9.6846e-03, 5.1577e-04, 3.5051e-02, 1.8470e-03, 4.5923e-03,
        9.3597e-02, 7.2665e-04], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,931][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0006, 0.0282, 0.0680, 0.0340, 0.0723, 0.1486, 0.0275, 0.0304, 0.0724,
        0.0446, 0.0545, 0.0736, 0.2573, 0.0879], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:58,932][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0283, 0.0059, 0.0082, 0.0062, 0.0051, 0.0156, 0.0117, 0.0078, 0.0501,
        0.0277, 0.0540, 0.2431, 0.0616, 0.0224, 0.4523], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,932][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([2.1585e-04, 6.3041e-03, 1.6292e-02, 9.3166e-03, 1.1393e-01, 2.6324e-02,
        1.9883e-02, 2.6175e-02, 1.5702e-02, 3.0453e-02, 8.2229e-02, 1.6694e-01,
        2.5372e-01, 1.4833e-02, 2.1769e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,932][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0080, 0.0386, 0.0188, 0.0621, 0.0665, 0.1369, 0.0449, 0.0401, 0.0468,
        0.1099, 0.0982, 0.1065, 0.0951, 0.0568, 0.0709], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,933][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0277, 0.0030, 0.0069, 0.0103, 0.0078, 0.0339, 0.0233, 0.0086, 0.0502,
        0.0270, 0.0666, 0.1805, 0.0686, 0.0328, 0.4527], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,933][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.1088, 0.0013, 0.0009, 0.0039, 0.0072, 0.0150, 0.0072, 0.0082, 0.1327,
        0.0093, 0.1969, 0.1625, 0.0829, 0.0489, 0.2144], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,934][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([1.6597e-01, 2.0031e-08, 6.4058e-09, 3.8973e-08, 1.4417e-06, 3.1653e-05,
        2.8404e-06, 1.1217e-06, 7.6310e-03, 1.6978e-04, 9.6285e-03, 2.5173e-01,
        3.9355e-01, 1.9505e-03, 1.6932e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,936][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0133, 0.0078, 0.0073, 0.0131, 0.0246, 0.0450, 0.0374, 0.0135, 0.0771,
        0.0587, 0.0611, 0.1962, 0.0705, 0.0837, 0.2905], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,938][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.2712, 0.0797, 0.0159, 0.0348, 0.2146, 0.0209, 0.0100, 0.0218, 0.0455,
        0.0186, 0.0219, 0.0737, 0.0740, 0.0486, 0.0488], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,939][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0293, 0.0847, 0.0511, 0.0522, 0.0306, 0.0165, 0.0323, 0.0229, 0.0584,
        0.1242, 0.1030, 0.0689, 0.0722, 0.0508, 0.2027], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,940][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([4.3964e-02, 4.5897e-10, 4.5437e-10, 2.5413e-09, 8.1696e-08, 2.8009e-06,
        1.4460e-07, 1.5911e-07, 4.1761e-03, 1.8701e-04, 5.8524e-03, 2.0553e-01,
        4.0200e-01, 6.4170e-04, 3.3764e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,942][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.2290, 0.0029, 0.3041, 0.0036, 0.1049, 0.0012, 0.0011, 0.0045, 0.0009,
        0.0186, 0.0026, 0.0058, 0.0759, 0.0009, 0.2438], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,943][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0028, 0.0128, 0.0372, 0.0226, 0.0726, 0.0469, 0.0109, 0.0067, 0.0565,
        0.0143, 0.0601, 0.0240, 0.1549, 0.0459, 0.4319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:58,945][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0251, 0.0033, 0.0059, 0.0031, 0.0041, 0.0073, 0.0041, 0.0038, 0.0255,
        0.0160, 0.0219, 0.1132, 0.0368, 0.0113, 0.3511, 0.3674],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,946][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0007, 0.0043, 0.0398, 0.0080, 0.0900, 0.0111, 0.0099, 0.0135, 0.0137,
        0.0287, 0.0278, 0.1562, 0.2266, 0.0103, 0.2055, 0.1538],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,947][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0147, 0.0277, 0.0154, 0.0501, 0.0431, 0.0635, 0.0261, 0.0297, 0.0284,
        0.1518, 0.0764, 0.0981, 0.1120, 0.0495, 0.0519, 0.1615],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,947][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0564, 0.0025, 0.0043, 0.0041, 0.0044, 0.0091, 0.0105, 0.0037, 0.0216,
        0.0162, 0.0252, 0.0910, 0.0664, 0.0203, 0.3943, 0.2699],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,948][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.2614e-01, 6.0873e-04, 3.1415e-04, 1.3781e-03, 1.9429e-03, 5.1740e-03,
        2.1816e-03, 3.6460e-03, 5.2948e-02, 6.1128e-03, 5.6783e-02, 8.8658e-02,
        5.1897e-02, 2.5475e-02, 8.7239e-02, 4.8950e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,948][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.2691e-01, 8.5221e-11, 5.1069e-12, 1.3340e-10, 2.3316e-09, 1.1737e-07,
        1.6142e-08, 3.8280e-11, 7.7009e-06, 3.2654e-08, 2.8381e-05, 4.0339e-03,
        1.7787e-03, 1.4430e-06, 1.3408e-03, 7.6590e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,948][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0739, 0.0114, 0.0147, 0.0168, 0.0264, 0.0281, 0.0177, 0.0124, 0.0442,
        0.0829, 0.0247, 0.1271, 0.0531, 0.0468, 0.1622, 0.2576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,949][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.2035, 0.0583, 0.0228, 0.0247, 0.1568, 0.0208, 0.0085, 0.0180, 0.0262,
        0.0288, 0.0236, 0.0659, 0.1079, 0.0248, 0.0479, 0.1614],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,949][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0204, 0.1170, 0.0425, 0.0572, 0.0147, 0.0131, 0.0260, 0.0167, 0.0451,
        0.0798, 0.0557, 0.1319, 0.0600, 0.0546, 0.0964, 0.1688],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,950][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.8485e-02, 4.1293e-13, 5.3927e-14, 9.4198e-13, 2.2984e-11, 8.2892e-10,
        1.1701e-10, 5.6193e-13, 2.8262e-07, 1.5350e-09, 2.6653e-06, 6.5821e-04,
        3.2299e-04, 6.3916e-08, 6.8554e-04, 9.7985e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,950][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.5344e-01, 3.0696e-03, 2.5403e-01, 2.4178e-03, 6.2386e-02, 3.5679e-04,
        4.1564e-04, 2.5075e-03, 5.0188e-04, 1.3467e-02, 1.0828e-03, 3.9839e-03,
        4.1151e-02, 3.7964e-04, 8.7450e-02, 3.7337e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,950][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0882, 0.0088, 0.0207, 0.0202, 0.0171, 0.0386, 0.0048, 0.0068, 0.0234,
        0.0074, 0.0309, 0.0181, 0.1199, 0.0165, 0.1068, 0.4720],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:58,951][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0090, 0.0036, 0.0045, 0.0023, 0.0075, 0.0067, 0.0030, 0.0045, 0.0166,
        0.0167, 0.0261, 0.1090, 0.0642, 0.0115, 0.2124, 0.3627, 0.1398],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,952][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.4265e-04, 2.8602e-03, 8.8534e-03, 3.9907e-03, 4.7961e-02, 6.9355e-03,
        6.7170e-03, 9.1988e-03, 1.0062e-02, 2.4796e-02, 2.8981e-02, 1.9376e-01,
        1.8737e-01, 9.8582e-03, 1.5580e-01, 1.0798e-01, 1.9473e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,954][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0097, 0.0205, 0.0140, 0.0388, 0.0416, 0.0425, 0.0187, 0.0306, 0.0316,
        0.1262, 0.0564, 0.1175, 0.1365, 0.0399, 0.0566, 0.1145, 0.1044],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,955][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0503, 0.0017, 0.0020, 0.0027, 0.0026, 0.0076, 0.0073, 0.0045, 0.0237,
        0.0139, 0.0286, 0.1426, 0.0690, 0.0198, 0.1863, 0.2929, 0.1444],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,957][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0548, 0.0006, 0.0006, 0.0017, 0.0031, 0.0073, 0.0025, 0.0072, 0.0448,
        0.0107, 0.0418, 0.0895, 0.0487, 0.0143, 0.0570, 0.5500, 0.0655],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,958][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([7.4479e-02, 2.0624e-09, 5.2626e-10, 2.2844e-09, 6.0740e-08, 1.5666e-06,
        1.0923e-07, 7.8116e-09, 4.8134e-05, 7.0465e-07, 7.7358e-05, 5.3186e-03,
        7.5826e-03, 1.7922e-05, 4.8416e-03, 8.9044e-01, 1.7193e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,960][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0157, 0.0054, 0.0056, 0.0073, 0.0186, 0.0189, 0.0112, 0.0094, 0.0290,
        0.0642, 0.0274, 0.1413, 0.0538, 0.0383, 0.1362, 0.2245, 0.1931],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,961][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2527, 0.0701, 0.0150, 0.0262, 0.1277, 0.0148, 0.0090, 0.0197, 0.0351,
        0.0330, 0.0259, 0.0768, 0.0890, 0.0411, 0.0386, 0.0837, 0.0417],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,963][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0302, 0.0416, 0.0216, 0.0499, 0.0138, 0.0102, 0.0124, 0.0321, 0.0384,
        0.1047, 0.0653, 0.1304, 0.0865, 0.0552, 0.1090, 0.1091, 0.0895],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,964][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.3137e-03, 3.8078e-12, 2.9668e-12, 1.1556e-11, 4.1832e-10, 1.1672e-08,
        1.0283e-09, 8.3540e-11, 7.3480e-07, 2.4385e-08, 2.5083e-06, 3.9465e-04,
        8.9147e-04, 3.9786e-07, 1.0298e-03, 9.9347e-01, 2.8981e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,964][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([8.1366e-02, 2.7946e-03, 1.8484e-01, 1.3884e-03, 5.1853e-02, 3.4000e-04,
        3.7229e-04, 3.0626e-03, 4.4029e-04, 1.7835e-02, 1.1069e-03, 5.4933e-03,
        4.3393e-02, 5.6442e-04, 1.1468e-01, 4.1394e-01, 7.6531e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,965][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1001, 0.0048, 0.0163, 0.0074, 0.0143, 0.0219, 0.0030, 0.0050, 0.0108,
        0.0124, 0.0120, 0.0130, 0.1279, 0.0371, 0.2124, 0.3711, 0.0304],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:58,965][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0128, 0.0079, 0.0047, 0.0095, 0.0054, 0.0089, 0.0089, 0.0042, 0.0355,
        0.0136, 0.0344, 0.1426, 0.0514, 0.0222, 0.1344, 0.2129, 0.1560, 0.1348],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,966][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0002, 0.0099, 0.0184, 0.0130, 0.0442, 0.0188, 0.0180, 0.0132, 0.0169,
        0.0221, 0.0375, 0.1431, 0.1348, 0.0242, 0.1500, 0.0917, 0.1997, 0.0445],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,966][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.0035, 0.0304, 0.0081, 0.0595, 0.0269, 0.0710, 0.0290, 0.0333, 0.0334,
        0.1063, 0.0835, 0.0819, 0.0740, 0.0578, 0.0242, 0.0671, 0.1293, 0.0807],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,966][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([0.0366, 0.0070, 0.0046, 0.0068, 0.0028, 0.0145, 0.0118, 0.0059, 0.0284,
        0.0179, 0.0338, 0.0826, 0.0908, 0.0396, 0.2052, 0.2128, 0.1367, 0.0622],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,967][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([0.0278, 0.0009, 0.0005, 0.0018, 0.0037, 0.0052, 0.0026, 0.0046, 0.0322,
        0.0057, 0.0439, 0.0672, 0.0427, 0.0206, 0.0534, 0.4840, 0.0642, 0.1391],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,967][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([6.5863e-03, 2.5139e-09, 1.3578e-09, 5.4960e-09, 2.0296e-07, 3.3588e-06,
        2.7079e-07, 3.0972e-07, 4.7791e-04, 1.4872e-05, 2.2733e-04, 3.5710e-03,
        1.2136e-02, 2.8650e-04, 6.9656e-03, 9.4770e-01, 1.2336e-02, 9.6974e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,967][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0071, 0.0121, 0.0081, 0.0201, 0.0195, 0.0300, 0.0304, 0.0088, 0.0490,
        0.0467, 0.0230, 0.1091, 0.0357, 0.0700, 0.1252, 0.1102, 0.2214, 0.0736],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,968][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([0.1501, 0.0437, 0.0242, 0.0260, 0.1954, 0.0150, 0.0091, 0.0166, 0.0247,
        0.0272, 0.0218, 0.0697, 0.0869, 0.0325, 0.0493, 0.1306, 0.0389, 0.0383],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,969][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.0115, 0.1665, 0.0360, 0.0735, 0.0102, 0.0131, 0.0199, 0.0129, 0.0345,
        0.0724, 0.0612, 0.0926, 0.0524, 0.0509, 0.0413, 0.0680, 0.0871, 0.0960],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,970][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([2.8275e-04, 2.8488e-11, 2.8521e-11, 1.1026e-10, 5.5090e-09, 8.6793e-08,
        5.8701e-09, 2.7130e-08, 9.0316e-05, 4.6639e-06, 2.9319e-05, 8.8308e-04,
        4.9972e-03, 4.0176e-05, 4.6681e-03, 9.7653e-01, 3.2170e-03, 9.2615e-03],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,972][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0694, 0.0111, 0.2126, 0.0059, 0.0657, 0.0010, 0.0013, 0.0049, 0.0011,
        0.0149, 0.0025, 0.0066, 0.0458, 0.0018, 0.0850, 0.3477, 0.0808, 0.0420],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,973][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0113, 0.0131, 0.0233, 0.0236, 0.0233, 0.0484, 0.0067, 0.0071, 0.0254,
        0.0112, 0.0241, 0.0143, 0.0960, 0.0417, 0.1584, 0.2218, 0.0280, 0.2223],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:58,975][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0091, 0.0036, 0.0041, 0.0033, 0.0050, 0.0073, 0.0044, 0.0029, 0.0183,
        0.0100, 0.0197, 0.1182, 0.0442, 0.0132, 0.1323, 0.2216, 0.1412, 0.1147,
        0.1270], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,976][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0004, 0.0074, 0.0173, 0.0056, 0.0389, 0.0078, 0.0062, 0.0082, 0.0083,
        0.0189, 0.0286, 0.1226, 0.1753, 0.0108, 0.1411, 0.1204, 0.1248, 0.0566,
        0.1008], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,978][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0148, 0.0274, 0.0184, 0.0345, 0.0352, 0.0451, 0.0152, 0.0220, 0.0258,
        0.0710, 0.0571, 0.0751, 0.1139, 0.0363, 0.0485, 0.0937, 0.0950, 0.0823,
        0.0887], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,980][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0903, 0.0021, 0.0040, 0.0033, 0.0031, 0.0074, 0.0068, 0.0031, 0.0202,
        0.0094, 0.0255, 0.0960, 0.0634, 0.0168, 0.2004, 0.2187, 0.0968, 0.0482,
        0.0846], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,981][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0725, 0.0009, 0.0014, 0.0019, 0.0046, 0.0049, 0.0022, 0.0037, 0.0305,
        0.0065, 0.0344, 0.0493, 0.0356, 0.0106, 0.0604, 0.4644, 0.0437, 0.0952,
        0.0775], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,982][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.1889e-02, 2.9043e-08, 1.7066e-08, 3.4872e-08, 1.3383e-06, 1.4444e-05,
        1.3076e-06, 6.8006e-07, 4.4992e-04, 2.4114e-05, 2.7785e-04, 4.7013e-03,
        2.4688e-02, 2.9827e-04, 1.5018e-02, 8.2691e-01, 1.7616e-02, 2.6619e-02,
        1.1491e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,982][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0151, 0.0097, 0.0060, 0.0114, 0.0150, 0.0196, 0.0136, 0.0060, 0.0294,
        0.0266, 0.0260, 0.1036, 0.0413, 0.0510, 0.0829, 0.1790, 0.1822, 0.0848,
        0.0967], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,983][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1401, 0.0830, 0.0292, 0.0282, 0.1339, 0.0122, 0.0060, 0.0138, 0.0263,
        0.0209, 0.0177, 0.0629, 0.1138, 0.0324, 0.0501, 0.1197, 0.0286, 0.0304,
        0.0505], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,983][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0290, 0.0834, 0.0270, 0.0362, 0.0127, 0.0100, 0.0095, 0.0141, 0.0258,
        0.0821, 0.0432, 0.0812, 0.0580, 0.0341, 0.0679, 0.0811, 0.0729, 0.0992,
        0.1327], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,983][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.3527e-03, 4.2548e-10, 4.2881e-10, 8.3005e-10, 4.1170e-08, 4.0088e-07,
        4.8561e-08, 4.3367e-08, 3.8224e-05, 3.5892e-06, 3.0989e-05, 9.1492e-04,
        6.3064e-03, 3.1631e-05, 5.7782e-03, 9.5491e-01, 5.9570e-03, 1.8299e-02,
        5.3765e-03], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,984][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.2007, 0.0037, 0.2194, 0.0015, 0.0386, 0.0004, 0.0004, 0.0021, 0.0004,
        0.0099, 0.0011, 0.0031, 0.0401, 0.0004, 0.0770, 0.2983, 0.0473, 0.0355,
        0.0201], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,984][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0121, 0.0119, 0.0411, 0.0191, 0.0282, 0.0295, 0.0050, 0.0050, 0.0201,
        0.0082, 0.0225, 0.0146, 0.0796, 0.0319, 0.1721, 0.2393, 0.0267, 0.1632,
        0.0698], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:58,985][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:58,987][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[20803],
        [  534],
        [  184],
        [   40],
        [   45],
        [    7],
        [    2],
        [   18],
        [    8],
        [   25],
        [   17],
        [    9],
        [   15],
        [   10],
        [   31],
        [   17],
        [   14],
        [   13],
        [    8]], device='cuda:0')
[2024-07-24 10:18:58,988][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17654],
        [  384],
        [   83],
        [   22],
        [  127],
        [    9],
        [    2],
        [   18],
        [   11],
        [   34],
        [   23],
        [   10],
        [   28],
        [   10],
        [   45],
        [   17],
        [   12],
        [   17],
        [    8]], device='cuda:0')
[2024-07-24 10:18:58,990][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3940],
        [  348],
        [13614],
        [ 1922],
        [    7],
        [   53],
        [   35],
        [   37],
        [   75],
        [   72],
        [   38],
        [   75],
        [   75],
        [   96],
        [  214],
        [  226],
        [  183],
        [  203],
        [  185]], device='cuda:0')
[2024-07-24 10:18:58,992][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42859],
        [40203],
        [41284],
        [41370],
        [48489],
        [46260],
        [46752],
        [46831],
        [46975],
        [45084],
        [45317],
        [37226],
        [39085],
        [37882],
        [36044],
        [34355],
        [32312],
        [33473],
        [32987]], device='cuda:0')
[2024-07-24 10:18:58,993][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[3254],
        [4360],
        [1518],
        [1520],
        [  56],
        [  62],
        [  36],
        [ 130],
        [ 303],
        [ 124],
        [ 162],
        [ 196],
        [ 493],
        [ 253],
        [ 770],
        [ 171],
        [ 226],
        [1581],
        [1036]], device='cuda:0')
[2024-07-24 10:18:58,995][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26372],
        [48197],
        [48376],
        [49121],
        [49754],
        [49913],
        [49726],
        [49501],
        [49088],
        [48519],
        [48906],
        [48140],
        [48600],
        [48606],
        [47204],
        [47216],
        [47441],
        [47569],
        [47367]], device='cuda:0')
[2024-07-24 10:18:58,997][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[29280],
        [40903],
        [36331],
        [36697],
        [42828],
        [37764],
        [35856],
        [34510],
        [28870],
        [30177],
        [28218],
        [26561],
        [24338],
        [24523],
        [20350],
        [20691],
        [21914],
        [22057],
        [22075]], device='cuda:0')
[2024-07-24 10:18:58,998][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[37612],
        [38177],
        [34759],
        [38385],
        [27351],
        [20544],
        [18803],
        [41521],
        [40750],
        [40239],
        [39330],
        [41768],
        [43068],
        [42818],
        [42024],
        [30039],
        [29909],
        [30031],
        [31201]], device='cuda:0')
[2024-07-24 10:18:59,000][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[39119],
        [38310],
        [42964],
        [41028],
        [49701],
        [45238],
        [46917],
        [49263],
        [47741],
        [37171],
        [40217],
        [40079],
        [42757],
        [43632],
        [43795],
        [45299],
        [43548],
        [42850],
        [43407]], device='cuda:0')
[2024-07-24 10:18:59,001][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31301],
        [ 8254],
        [ 7716],
        [ 5769],
        [    1],
        [    2],
        [    2],
        [    1],
        [    3],
        [   10],
        [    3],
        [   49],
        [    2],
        [   44],
        [  134],
        [  664],
        [ 1520],
        [  375],
        [ 1648]], device='cuda:0')
[2024-07-24 10:18:59,002][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[36041],
        [35912],
        [38911],
        [34705],
        [34534],
        [35331],
        [33596],
        [36678],
        [36373],
        [36583],
        [36397],
        [35652],
        [34280],
        [33467],
        [36957],
        [35781],
        [35765],
        [35274],
        [34592]], device='cuda:0')
[2024-07-24 10:18:59,003][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[37468],
        [37975],
        [24647],
        [25951],
        [40457],
        [45373],
        [45120],
        [49330],
        [34554],
        [35619],
        [48231],
        [48859],
        [49515],
        [49417],
        [48617],
        [45233],
        [45218],
        [45376],
        [45514]], device='cuda:0')
[2024-07-24 10:18:59,004][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[36104],
        [26249],
        [25905],
        [25923],
        [26118],
        [28048],
        [26703],
        [26785],
        [25766],
        [26417],
        [25118],
        [24933],
        [25516],
        [24479],
        [25613],
        [25447],
        [23376],
        [23756],
        [22564]], device='cuda:0')
[2024-07-24 10:18:59,006][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[15969],
        [ 4285],
        [11983],
        [12051],
        [33714],
        [20136],
        [23444],
        [23584],
        [17362],
        [17747],
        [12342],
        [13394],
        [18114],
        [20147],
        [24891],
        [20427],
        [22307],
        [25309],
        [24759]], device='cuda:0')
[2024-07-24 10:18:59,008][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[34162],
        [32011],
        [40739],
        [36036],
        [27472],
        [34495],
        [39897],
        [32088],
        [27965],
        [28985],
        [27578],
        [22412],
        [22088],
        [20114],
        [23418],
        [29350],
        [33953],
        [22649],
        [20002]], device='cuda:0')
[2024-07-24 10:18:59,009][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35195],
        [34677],
        [32941],
        [35446],
        [31431],
        [34872],
        [35427],
        [33344],
        [35642],
        [39886],
        [37976],
        [40025],
        [38248],
        [38048],
        [36377],
        [32650],
        [33945],
        [36221],
        [36508]], device='cuda:0')
[2024-07-24 10:18:59,011][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[48318],
        [28309],
        [36752],
        [39519],
        [43243],
        [42918],
        [43683],
        [43899],
        [43790],
        [43246],
        [43379],
        [44121],
        [44051],
        [43586],
        [43253],
        [43469],
        [43749],
        [43308],
        [43134]], device='cuda:0')
[2024-07-24 10:18:59,012][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46160],
        [46779],
        [45872],
        [42774],
        [43375],
        [40527],
        [43279],
        [43858],
        [41537],
        [41639],
        [42574],
        [45219],
        [44987],
        [44291],
        [44400],
        [38515],
        [41245],
        [43028],
        [40848]], device='cuda:0')
[2024-07-24 10:18:59,014][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[34687],
        [42297],
        [37480],
        [38864],
        [36861],
        [43195],
        [40647],
        [39365],
        [39900],
        [40275],
        [39163],
        [36069],
        [31591],
        [31329],
        [35220],
        [32974],
        [34094],
        [33269],
        [33623]], device='cuda:0')
[2024-07-24 10:18:59,016][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[43925],
        [45660],
        [40027],
        [39811],
        [34592],
        [35232],
        [37062],
        [37792],
        [41164],
        [40905],
        [39260],
        [37272],
        [36472],
        [36649],
        [36242],
        [27438],
        [26428],
        [28900],
        [28514]], device='cuda:0')
[2024-07-24 10:18:59,017][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24093],
        [20990],
        [28868],
        [23996],
        [13151],
        [26663],
        [26018],
        [24475],
        [15232],
        [13176],
        [19423],
        [16651],
        [11775],
        [11523],
        [10889],
        [16671],
        [15847],
        [15728],
        [15391]], device='cuda:0')
[2024-07-24 10:18:59,019][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22659],
        [29997],
        [27534],
        [31978],
        [25011],
        [19786],
        [21504],
        [20567],
        [23125],
        [28552],
        [28720],
        [31067],
        [29147],
        [28319],
        [25927],
        [30602],
        [30036],
        [28171],
        [29452]], device='cuda:0')
[2024-07-24 10:18:59,020][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[30870],
        [42281],
        [41063],
        [39508],
        [19227],
        [24657],
        [25565],
        [23208],
        [27065],
        [31205],
        [27135],
        [33174],
        [25978],
        [32324],
        [35147],
        [35088],
        [36714],
        [35020],
        [36236]], device='cuda:0')
[2024-07-24 10:18:59,021][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[24109],
        [17843],
        [15209],
        [16545],
        [16085],
        [16732],
        [17331],
        [17445],
        [17100],
        [17578],
        [16811],
        [16682],
        [15781],
        [16416],
        [14889],
        [14099],
        [14103],
        [14697],
        [13981]], device='cuda:0')
[2024-07-24 10:18:59,022][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27698],
        [47655],
        [48228],
        [48014],
        [48765],
        [48369],
        [48419],
        [41936],
        [42517],
        [42735],
        [41623],
        [38435],
        [38519],
        [38855],
        [42079],
        [41872],
        [41798],
        [41748],
        [41667]], device='cuda:0')
[2024-07-24 10:18:59,023][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44484],
        [41108],
        [46895],
        [46936],
        [46984],
        [47093],
        [47139],
        [47048],
        [47088],
        [46416],
        [46566],
        [46544],
        [45324],
        [45952],
        [43652],
        [38054],
        [33945],
        [34971],
        [36096]], device='cuda:0')
[2024-07-24 10:18:59,025][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18988],
        [43855],
        [43314],
        [41240],
        [41218],
        [43348],
        [43316],
        [43716],
        [43780],
        [44025],
        [44223],
        [43413],
        [43783],
        [44115],
        [44529],
        [44947],
        [45165],
        [44620],
        [44644]], device='cuda:0')
[2024-07-24 10:18:59,027][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[4308],
        [1303],
        [1639],
        [1862],
        [4074],
        [2414],
        [1969],
        [2837],
        [2882],
        [2130],
        [2334],
        [2416],
        [3983],
        [3387],
        [3294],
        [4473],
        [4130],
        [4080],
        [4055]], device='cuda:0')
[2024-07-24 10:18:59,028][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[11864],
        [ 9010],
        [ 3662],
        [ 4697],
        [ 4629],
        [ 6251],
        [ 7167],
        [ 4963],
        [ 7908],
        [ 6272],
        [12191],
        [ 9983],
        [ 7333],
        [14836],
        [ 8180],
        [ 9643],
        [ 6647],
        [13373],
        [14660]], device='cuda:0')
[2024-07-24 10:18:59,030][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864],
        [27864]], device='cuda:0')
[2024-07-24 10:18:59,068][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:59,068][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,069][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,069][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,069][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,070][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,070][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,070][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,071][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,071][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,071][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,072][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,072][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,072][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2658, 0.7342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,072][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0214, 0.9786], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,073][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.8567, 0.1433], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,074][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4579, 0.5421], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,076][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0731, 0.9269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,077][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0219, 0.9781], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,078][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0856, 0.9144], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,079][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0073, 0.9927], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,079][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3011, 0.6989], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,079][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0407, 0.9593], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,080][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0176, 0.9824], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,080][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0283, 0.9717], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,080][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.1389, 0.4644, 0.3967], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,080][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0078, 0.8054, 0.1868], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,081][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.5449, 0.1983, 0.2568], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,081][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.2583, 0.3992, 0.3424], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,081][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([0.0314, 0.7834, 0.1853], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,081][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0075, 0.6867, 0.3058], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,082][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0606, 0.4576, 0.4819], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,082][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0058, 0.8783, 0.1159], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,083][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0103, 0.4853, 0.5044], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,084][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0210, 0.5840, 0.3950], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,086][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0028, 0.8163, 0.1810], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,087][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0215, 0.4941, 0.4843], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,089][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1761, 0.4249, 0.1997, 0.1992], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,091][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0029, 0.3216, 0.1406, 0.5349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,092][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5120, 0.1507, 0.2478, 0.0894], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,094][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2309, 0.2785, 0.2871, 0.2034], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,095][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0122, 0.2025, 0.0801, 0.7051], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,097][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0064, 0.4472, 0.2305, 0.3159], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,099][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0287, 0.3030, 0.3456, 0.3227], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,100][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0063, 0.6936, 0.1431, 0.1569], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,101][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0154, 0.4052, 0.3713, 0.2081], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,101][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0127, 0.4125, 0.2734, 0.3013], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,102][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0033, 0.6998, 0.1685, 0.1284], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,102][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0140, 0.2963, 0.2092, 0.4804], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,102][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Cody] are: tensor([0.1622, 0.3050, 0.1859, 0.1341, 0.2127], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,103][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Cody] are: tensor([0.0091, 0.2771, 0.1339, 0.3541, 0.2257], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,103][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Cody] are: tensor([0.2593, 0.2154, 0.3132, 0.1108, 0.1013], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,103][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Cody] are: tensor([0.1136, 0.2049, 0.1837, 0.1430, 0.3547], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,103][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Cody] are: tensor([0.0015, 0.0972, 0.0227, 0.1748, 0.7037], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,104][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Cody] are: tensor([0.0036, 0.4108, 0.1709, 0.2456, 0.1692], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,104][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Cody] are: tensor([0.0268, 0.1997, 0.2189, 0.2051, 0.3495], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,104][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Cody] are: tensor([0.0039, 0.6651, 0.0736, 0.1297, 0.1277], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,105][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Cody] are: tensor([0.0634, 0.2522, 0.4226, 0.1562, 0.1057], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,105][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Cody] are: tensor([0.0098, 0.2161, 0.1070, 0.1693, 0.4978], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,105][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Cody] are: tensor([0.0047, 0.4573, 0.1721, 0.0803, 0.2856], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,107][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Cody] are: tensor([0.0196, 0.2350, 0.2025, 0.3596, 0.1833], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,109][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2256, 0.3470, 0.0895, 0.0998, 0.1275, 0.1106], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,110][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0024, 0.1835, 0.0485, 0.2496, 0.1083, 0.4077], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,112][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3360, 0.1208, 0.1673, 0.0910, 0.0798, 0.2051], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,112][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1436, 0.1416, 0.1395, 0.0957, 0.3240, 0.1557], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,114][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([5.6376e-04, 5.1629e-03, 1.4671e-03, 2.4887e-02, 5.5639e-02, 9.1228e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,115][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0028, 0.3345, 0.1427, 0.2142, 0.1339, 0.1718], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,117][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0124, 0.1135, 0.1270, 0.1276, 0.2519, 0.3677], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,118][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0103, 0.6330, 0.0530, 0.1126, 0.1272, 0.0640], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,119][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0030, 0.2566, 0.1968, 0.1365, 0.0474, 0.3597], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,119][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0048, 0.1479, 0.0638, 0.1157, 0.3513, 0.3165], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,119][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0062, 0.3360, 0.1154, 0.0793, 0.2239, 0.2392], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,120][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0139, 0.2021, 0.0767, 0.2863, 0.1636, 0.2574], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,120][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2105, 0.2661, 0.1039, 0.1055, 0.1376, 0.1128, 0.0637],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,120][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0015, 0.1200, 0.0529, 0.1778, 0.1436, 0.3329, 0.1714],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,121][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3166, 0.1097, 0.1656, 0.0809, 0.0927, 0.1470, 0.0875],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,121][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1304, 0.1417, 0.1263, 0.1049, 0.2852, 0.1332, 0.0783],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,121][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([4.7890e-04, 5.1147e-03, 2.5895e-03, 2.7307e-02, 1.7396e-01, 6.9188e-01,
        9.8676e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,121][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0028, 0.2728, 0.1204, 0.1726, 0.1222, 0.1471, 0.1622],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,122][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0087, 0.1005, 0.1235, 0.1158, 0.2083, 0.2858, 0.1574],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,122][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0124, 0.5621, 0.0598, 0.0930, 0.1327, 0.0400, 0.0999],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,123][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0041, 0.0756, 0.1438, 0.0856, 0.0251, 0.2624, 0.4033],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,124][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0039, 0.1552, 0.0642, 0.1168, 0.2899, 0.2958, 0.0742],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,126][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0044, 0.3409, 0.1093, 0.0630, 0.1839, 0.1548, 0.1437],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,127][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0059, 0.1324, 0.0873, 0.2296, 0.1956, 0.2507, 0.0985],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,129][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0696, 0.2335, 0.0610, 0.0738, 0.1193, 0.1015, 0.0555, 0.2858],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,130][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0013, 0.0972, 0.0463, 0.1384, 0.1113, 0.3395, 0.1825, 0.0834],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,132][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1612, 0.0954, 0.1440, 0.0579, 0.0947, 0.1261, 0.0753, 0.2453],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,133][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0700, 0.1304, 0.1099, 0.0936, 0.2505, 0.1502, 0.1040, 0.0913],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,135][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0010, 0.0086, 0.0059, 0.0193, 0.5080, 0.3256, 0.0670, 0.0647],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,136][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0019, 0.2567, 0.1090, 0.1518, 0.1089, 0.1250, 0.1355, 0.1111],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,136][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0085, 0.0869, 0.0862, 0.0954, 0.1398, 0.2403, 0.1363, 0.2065],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,137][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0119, 0.4664, 0.0324, 0.0788, 0.0766, 0.0271, 0.0581, 0.2488],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,137][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0433, 0.0240, 0.0545, 0.0274, 0.0121, 0.0806, 0.0961, 0.6620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,137][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0043, 0.1919, 0.0485, 0.1145, 0.2274, 0.2635, 0.0705, 0.0793],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,137][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0185, 0.2826, 0.0952, 0.0398, 0.1374, 0.1009, 0.0669, 0.2588],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,138][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0077, 0.1705, 0.0610, 0.1894, 0.0926, 0.2028, 0.1255, 0.1504],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,138][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1312, 0.1411, 0.0650, 0.0579, 0.0777, 0.0746, 0.0413, 0.2259, 0.1853],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,138][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0011, 0.1061, 0.0725, 0.1612, 0.0919, 0.1858, 0.0932, 0.0584, 0.2298],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,139][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2080, 0.0829, 0.1517, 0.0498, 0.0764, 0.0816, 0.0535, 0.1706, 0.1256],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,139][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1351, 0.1050, 0.0973, 0.0806, 0.2269, 0.1102, 0.0686, 0.0686, 0.1076],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,139][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([4.6407e-04, 5.4020e-03, 4.0807e-03, 1.8547e-02, 1.1895e-01, 2.0395e-01,
        3.9783e-02, 5.3384e-02, 5.5544e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,140][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0024, 0.2311, 0.1082, 0.1454, 0.1025, 0.1138, 0.1221, 0.0889, 0.0855],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,142][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0057, 0.0697, 0.0815, 0.0762, 0.1573, 0.2073, 0.1155, 0.1756, 0.1111],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,144][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0044, 0.5117, 0.0557, 0.0783, 0.0782, 0.0188, 0.0479, 0.1691, 0.0360],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,145][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0133, 0.0432, 0.0445, 0.0604, 0.0117, 0.1228, 0.2154, 0.3079, 0.1807],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,146][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0020, 0.1696, 0.0485, 0.1519, 0.1730, 0.2653, 0.0688, 0.0697, 0.0512],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,148][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0044, 0.2486, 0.0913, 0.0502, 0.1193, 0.1034, 0.0876, 0.2352, 0.0601],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,150][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0068, 0.0990, 0.0802, 0.1509, 0.1771, 0.1839, 0.0742, 0.1117, 0.1163],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,151][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1266, 0.1399, 0.0679, 0.0515, 0.0862, 0.0771, 0.0363, 0.1672, 0.1859,
        0.0614], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,153][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0007, 0.0602, 0.0216, 0.1312, 0.0553, 0.1688, 0.1396, 0.0372, 0.2898,
        0.0957], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,154][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0592, 0.0786, 0.0684, 0.0489, 0.0478, 0.0862, 0.0658, 0.1737, 0.1635,
        0.2079], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,154][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0736, 0.0976, 0.0862, 0.0770, 0.1740, 0.1042, 0.0777, 0.0704, 0.1224,
        0.1169], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,154][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([6.4522e-05, 5.0910e-03, 2.3327e-03, 1.1425e-02, 1.1918e-01, 4.1883e-01,
        3.0000e-02, 3.1766e-02, 2.7162e-01, 1.0969e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,155][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0018, 0.2123, 0.0910, 0.1319, 0.0965, 0.1018, 0.1053, 0.0779, 0.0774,
        0.1041], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,155][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0091, 0.0656, 0.0683, 0.0727, 0.1210, 0.1808, 0.1086, 0.1445, 0.1114,
        0.1179], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,155][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0052, 0.4167, 0.0201, 0.0740, 0.0516, 0.0203, 0.0365, 0.1352, 0.0557,
        0.1847], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,156][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.5057, 0.0049, 0.0135, 0.0113, 0.0052, 0.0572, 0.0603, 0.1237, 0.1275,
        0.0908], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,156][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0038, 0.1151, 0.0467, 0.1097, 0.1959, 0.2648, 0.0703, 0.0515, 0.0545,
        0.0878], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,156][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0288, 0.2080, 0.0536, 0.0321, 0.1039, 0.0746, 0.0662, 0.1492, 0.0568,
        0.2270], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,157][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0085, 0.0960, 0.0804, 0.1698, 0.0897, 0.1342, 0.0946, 0.1229, 0.1374,
        0.0666], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,157][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.1128, 0.1222, 0.0445, 0.0450, 0.0612, 0.0608, 0.0338, 0.1750, 0.1505,
        0.0694, 0.1249], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,157][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0019, 0.0823, 0.0420, 0.1140, 0.0911, 0.1661, 0.0777, 0.0589, 0.2028,
        0.1049, 0.0583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,158][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0565, 0.0553, 0.0547, 0.0372, 0.0269, 0.0698, 0.0557, 0.1397, 0.1172,
        0.1470, 0.2401], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,160][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0737, 0.0885, 0.0883, 0.0660, 0.1861, 0.0907, 0.0592, 0.0624, 0.0859,
        0.1154, 0.0839], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,161][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([1.3023e-04, 1.0247e-03, 6.2588e-04, 6.7224e-03, 4.3048e-02, 1.5774e-01,
        2.0250e-02, 1.4471e-02, 2.7935e-01, 3.9016e-02, 4.3762e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,163][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0017, 0.1961, 0.0826, 0.1203, 0.0870, 0.0891, 0.0945, 0.0699, 0.0707,
        0.0929, 0.0953], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,164][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0061, 0.0563, 0.0649, 0.0640, 0.1128, 0.1555, 0.0918, 0.1330, 0.0930,
        0.1307, 0.0920], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,165][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0030, 0.4440, 0.0264, 0.0758, 0.0508, 0.0149, 0.0250, 0.0763, 0.0383,
        0.1293, 0.1163], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,167][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.1259, 0.0063, 0.0207, 0.0217, 0.0059, 0.0799, 0.1542, 0.3073, 0.1278,
        0.0770, 0.0732], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,168][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0019, 0.1092, 0.0488, 0.1146, 0.1559, 0.2223, 0.0577, 0.0555, 0.0503,
        0.1021, 0.0816], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,170][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0126, 0.1160, 0.0423, 0.0308, 0.0927, 0.0651, 0.0693, 0.1703, 0.0444,
        0.1712, 0.1853], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,171][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0034, 0.0876, 0.0702, 0.1230, 0.1314, 0.1531, 0.0659, 0.1205, 0.0984,
        0.0742, 0.0724], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,171][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1329, 0.0816, 0.0279, 0.0348, 0.0425, 0.0383, 0.0260, 0.0909, 0.1168,
        0.0332, 0.0987, 0.2765], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,171][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0013, 0.0558, 0.0299, 0.0883, 0.0617, 0.1226, 0.0690, 0.0448, 0.1871,
        0.0804, 0.0532, 0.2060], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,172][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1237, 0.0410, 0.0406, 0.0259, 0.0213, 0.0396, 0.0368, 0.0735, 0.0972,
        0.0989, 0.1606, 0.2409], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,172][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0823, 0.0842, 0.0788, 0.0612, 0.1795, 0.0826, 0.0495, 0.0523, 0.0807,
        0.1044, 0.0776, 0.0669], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,172][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([2.5243e-04, 4.6219e-04, 1.4351e-04, 2.0782e-03, 6.7699e-03, 2.7955e-02,
        4.9994e-03, 3.3444e-03, 1.3526e-01, 1.2529e-02, 7.9887e-02, 7.2632e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,173][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0025, 0.1734, 0.0724, 0.1052, 0.0756, 0.0749, 0.0877, 0.0572, 0.0633,
        0.0797, 0.0831, 0.1250], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,173][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0057, 0.0555, 0.0656, 0.0608, 0.1153, 0.1419, 0.0773, 0.1118, 0.0841,
        0.1176, 0.0830, 0.0814], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,173][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0049, 0.4273, 0.0158, 0.0551, 0.0428, 0.0125, 0.0231, 0.0629, 0.0307,
        0.1103, 0.1022, 0.1124], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,174][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1107, 0.0097, 0.0165, 0.0245, 0.0052, 0.0620, 0.1365, 0.2295, 0.1351,
        0.0590, 0.0575, 0.1538], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,174][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0032, 0.1222, 0.0489, 0.1115, 0.1585, 0.2285, 0.0510, 0.0451, 0.0415,
        0.0722, 0.0702, 0.0471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,174][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0221, 0.1013, 0.0348, 0.0219, 0.0652, 0.0534, 0.0587, 0.1400, 0.0440,
        0.1666, 0.1643, 0.1277], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,175][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0043, 0.0813, 0.0680, 0.1189, 0.1411, 0.1286, 0.0601, 0.0966, 0.0990,
        0.0610, 0.0729, 0.0683], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,177][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0815, 0.0938, 0.0362, 0.0274, 0.0464, 0.0370, 0.0188, 0.0649, 0.0847,
        0.0274, 0.0989, 0.1884, 0.1947], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,179][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0010, 0.0475, 0.0148, 0.0631, 0.0498, 0.1541, 0.0737, 0.0290, 0.1690,
        0.0790, 0.0428, 0.1435, 0.1328], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,180][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1414, 0.0406, 0.0348, 0.0257, 0.0178, 0.0408, 0.0331, 0.0768, 0.0726,
        0.0876, 0.1331, 0.1541, 0.1415], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,181][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0863, 0.0657, 0.0585, 0.0481, 0.1275, 0.0777, 0.0574, 0.0475, 0.0866,
        0.0867, 0.0789, 0.0763, 0.1028], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,183][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ station] are: tensor([7.1665e-04, 9.5703e-04, 1.7418e-04, 2.6829e-03, 2.6287e-02, 4.4437e-02,
        1.1445e-02, 2.7752e-03, 7.7390e-02, 2.2478e-02, 1.0358e-01, 3.1553e-01,
        3.9155e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,184][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0016, 0.1493, 0.0637, 0.0926, 0.0696, 0.0728, 0.0804, 0.0595, 0.0600,
        0.0784, 0.0730, 0.1055, 0.0935], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,186][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0048, 0.0461, 0.0424, 0.0516, 0.0844, 0.1302, 0.0804, 0.1077, 0.0847,
        0.0835, 0.0797, 0.0858, 0.1186], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,187][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0048, 0.2536, 0.0126, 0.0550, 0.0428, 0.0227, 0.0301, 0.0736, 0.0438,
        0.1333, 0.1490, 0.1208, 0.0580], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,188][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.1476, 0.0059, 0.0076, 0.0125, 0.0043, 0.0332, 0.0585, 0.1287, 0.0869,
        0.0845, 0.0987, 0.1369, 0.1949], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,188][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0027, 0.0985, 0.0284, 0.0868, 0.1504, 0.2111, 0.0571, 0.0436, 0.0546,
        0.0846, 0.0757, 0.0480, 0.0584], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,189][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0306, 0.1052, 0.0448, 0.0246, 0.0930, 0.0491, 0.0497, 0.1087, 0.0376,
        0.1433, 0.1328, 0.0821, 0.0987], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,189][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0073, 0.0833, 0.0431, 0.1244, 0.0775, 0.0928, 0.0720, 0.0719, 0.1118,
        0.0381, 0.0692, 0.0788, 0.1298], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,189][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0551, 0.0481, 0.0267, 0.0249, 0.0321, 0.0280, 0.0208, 0.0948, 0.0756,
        0.0199, 0.0622, 0.1872, 0.1710, 0.1537], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,190][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0004, 0.0380, 0.0242, 0.0675, 0.0702, 0.1332, 0.0468, 0.0304, 0.1193,
        0.0628, 0.0357, 0.1492, 0.1560, 0.0662], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,190][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0762, 0.0322, 0.0354, 0.0207, 0.0202, 0.0355, 0.0295, 0.0714, 0.0708,
        0.0847, 0.1188, 0.1505, 0.1786, 0.0754], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,190][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0827, 0.0720, 0.0558, 0.0496, 0.1336, 0.0742, 0.0416, 0.0409, 0.0744,
        0.0862, 0.0708, 0.0621, 0.1074, 0.0486], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,191][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([6.5052e-05, 2.7149e-04, 8.2507e-05, 1.0114e-03, 1.0840e-02, 2.5751e-02,
        3.2902e-03, 2.3126e-03, 6.4330e-02, 7.7833e-03, 4.7010e-02, 4.5027e-01,
        2.8204e-01, 1.0494e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,191][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0016, 0.1311, 0.0563, 0.0824, 0.0612, 0.0650, 0.0751, 0.0526, 0.0536,
        0.0733, 0.0694, 0.0999, 0.0877, 0.0907], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,191][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0029, 0.0375, 0.0441, 0.0386, 0.1002, 0.1162, 0.0634, 0.0905, 0.0601,
        0.0982, 0.0643, 0.0620, 0.1369, 0.0852], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,192][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0029, 0.4112, 0.0121, 0.0386, 0.0266, 0.0092, 0.0131, 0.0468, 0.0213,
        0.0977, 0.0639, 0.0665, 0.0468, 0.1431], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,194][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0652, 0.0090, 0.0376, 0.0234, 0.0056, 0.0584, 0.0942, 0.2846, 0.0758,
        0.0604, 0.0329, 0.0719, 0.0874, 0.0934], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,196][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0010, 0.1282, 0.0320, 0.1108, 0.1228, 0.1910, 0.0432, 0.0386, 0.0356,
        0.0696, 0.0769, 0.0447, 0.0526, 0.0531], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,197][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0181, 0.1480, 0.0527, 0.0205, 0.0657, 0.0406, 0.0329, 0.1038, 0.0276,
        0.1400, 0.1131, 0.0878, 0.0992, 0.0498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,198][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0030, 0.0709, 0.0397, 0.0797, 0.1254, 0.1059, 0.0382, 0.0490, 0.0814,
        0.0396, 0.0491, 0.0506, 0.1046, 0.1630], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,200][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Thomas] are: tensor([0.0746, 0.0315, 0.0166, 0.0169, 0.0297, 0.0266, 0.0147, 0.0371, 0.0645,
        0.0201, 0.0598, 0.1252, 0.1011, 0.1083, 0.2734], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,202][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Thomas] are: tensor([0.0014, 0.0518, 0.0190, 0.0508, 0.0431, 0.0832, 0.0365, 0.0299, 0.1180,
        0.0696, 0.0399, 0.1080, 0.1031, 0.0927, 0.1530], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,204][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Thomas] are: tensor([0.2886, 0.0325, 0.0318, 0.0200, 0.0181, 0.0309, 0.0245, 0.0520, 0.0534,
        0.0568, 0.0698, 0.0886, 0.0997, 0.0364, 0.0970], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,205][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Thomas] are: tensor([0.0606, 0.0551, 0.0473, 0.0431, 0.0952, 0.0648, 0.0493, 0.0465, 0.0763,
        0.0847, 0.0664, 0.0648, 0.1058, 0.0524, 0.0878], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,206][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Thomas] are: tensor([3.2129e-03, 3.3414e-04, 8.5647e-05, 8.7110e-04, 9.1443e-03, 3.1578e-02,
        2.3839e-03, 1.5034e-03, 2.7888e-02, 9.4018e-03, 6.8970e-02, 2.5137e-01,
        3.8668e-01, 3.0428e-02, 1.7614e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,206][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Thomas] are: tensor([0.0018, 0.1263, 0.0519, 0.0806, 0.0544, 0.0652, 0.0737, 0.0517, 0.0518,
        0.0686, 0.0675, 0.0912, 0.0812, 0.0818, 0.0524], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,206][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Thomas] are: tensor([0.0061, 0.0343, 0.0336, 0.0432, 0.0759, 0.1138, 0.0709, 0.0878, 0.0735,
        0.0720, 0.0701, 0.0807, 0.0974, 0.0788, 0.0620], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,207][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Thomas] are: tensor([0.0041, 0.2940, 0.0154, 0.0421, 0.0357, 0.0135, 0.0288, 0.0573, 0.0296,
        0.1044, 0.0873, 0.0694, 0.0406, 0.1446, 0.0331], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,207][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Thomas] are: tensor([0.0025, 0.0100, 0.0059, 0.0111, 0.0033, 0.0198, 0.0527, 0.0981, 0.0633,
        0.1131, 0.0960, 0.1698, 0.1787, 0.1344, 0.0412], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,207][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Thomas] are: tensor([0.0015, 0.0663, 0.0271, 0.0679, 0.1359, 0.1322, 0.0532, 0.0378, 0.0584,
        0.0935, 0.0769, 0.0659, 0.0879, 0.0652, 0.0302], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,208][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Thomas] are: tensor([0.0114, 0.1164, 0.0308, 0.0207, 0.0698, 0.0455, 0.0435, 0.0988, 0.0357,
        0.1398, 0.1094, 0.0747, 0.0847, 0.0471, 0.0719], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,208][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Thomas] are: tensor([0.0103, 0.0617, 0.0497, 0.0931, 0.0695, 0.0735, 0.0405, 0.0588, 0.0586,
        0.0360, 0.0380, 0.0440, 0.1222, 0.1735, 0.0706], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,208][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1270, 0.0341, 0.0104, 0.0090, 0.0153, 0.0140, 0.0062, 0.0215, 0.0318,
        0.0093, 0.0330, 0.0787, 0.0696, 0.0482, 0.1392, 0.3528],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,209][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0013, 0.0333, 0.0125, 0.0435, 0.0271, 0.0575, 0.0329, 0.0112, 0.0890,
        0.0332, 0.0215, 0.1002, 0.0690, 0.0631, 0.1305, 0.2741],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,209][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2411, 0.0226, 0.0305, 0.0158, 0.0137, 0.0191, 0.0175, 0.0317, 0.0419,
        0.0431, 0.0691, 0.0951, 0.1023, 0.0422, 0.1172, 0.0972],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,211][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0764, 0.0562, 0.0456, 0.0399, 0.1029, 0.0551, 0.0399, 0.0325, 0.0635,
        0.0658, 0.0553, 0.0548, 0.0851, 0.0432, 0.0979, 0.0859],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,212][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.5318e-04, 4.6568e-05, 9.9921e-06, 1.5234e-04, 4.6595e-04, 1.7698e-03,
        2.0954e-04, 5.1341e-05, 4.1197e-03, 3.2882e-04, 5.8864e-03, 3.2897e-02,
        1.5686e-02, 5.6109e-03, 2.8671e-02, 9.0394e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,213][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0017, 0.1236, 0.0587, 0.0805, 0.0562, 0.0558, 0.0656, 0.0483, 0.0477,
        0.0635, 0.0587, 0.0832, 0.0705, 0.0697, 0.0469, 0.0695],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,215][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0090, 0.0344, 0.0332, 0.0372, 0.0675, 0.0887, 0.0584, 0.0704, 0.0648,
        0.0714, 0.0615, 0.0669, 0.0996, 0.0711, 0.0705, 0.0954],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,216][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0043, 0.2795, 0.0146, 0.0463, 0.0294, 0.0095, 0.0180, 0.0515, 0.0286,
        0.0785, 0.0826, 0.0953, 0.0422, 0.1240, 0.0249, 0.0708],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,218][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0117, 0.0061, 0.0061, 0.0101, 0.0023, 0.0198, 0.0454, 0.1061, 0.0471,
        0.0705, 0.0742, 0.1584, 0.1826, 0.1028, 0.0468, 0.1098],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,220][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0045, 0.0717, 0.0332, 0.0627, 0.1628, 0.1345, 0.0428, 0.0327, 0.0382,
        0.0702, 0.0561, 0.0416, 0.0745, 0.0457, 0.0238, 0.1051],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,221][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0105, 0.0721, 0.0222, 0.0173, 0.0600, 0.0361, 0.0353, 0.1069, 0.0331,
        0.1293, 0.0921, 0.0747, 0.0918, 0.0510, 0.0667, 0.1010],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,223][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0120, 0.0762, 0.0380, 0.0917, 0.0652, 0.0654, 0.0415, 0.0421, 0.0555,
        0.0265, 0.0389, 0.0510, 0.0916, 0.1273, 0.0638, 0.1135],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,223][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0722, 0.0241, 0.0079, 0.0119, 0.0133, 0.0142, 0.0084, 0.0216, 0.0414,
        0.0082, 0.0346, 0.0895, 0.0656, 0.0475, 0.1026, 0.2988, 0.1382],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,224][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0016, 0.0219, 0.0124, 0.0281, 0.0296, 0.0502, 0.0249, 0.0167, 0.0607,
        0.0369, 0.0205, 0.0757, 0.0751, 0.0435, 0.0978, 0.2549, 0.1494],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,224][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1814, 0.0202, 0.0266, 0.0156, 0.0128, 0.0167, 0.0142, 0.0332, 0.0449,
        0.0452, 0.0682, 0.1046, 0.0927, 0.0369, 0.1048, 0.1049, 0.0771],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,224][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0739, 0.0571, 0.0490, 0.0433, 0.0981, 0.0511, 0.0340, 0.0305, 0.0574,
        0.0589, 0.0521, 0.0483, 0.0807, 0.0374, 0.0898, 0.0807, 0.0576],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,225][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.0195e-04, 1.6469e-05, 1.1052e-05, 1.0570e-04, 1.3391e-03, 1.4555e-03,
        2.0481e-04, 1.5804e-04, 5.8627e-03, 8.0302e-04, 6.6578e-03, 4.7494e-02,
        2.9807e-02, 4.0929e-03, 4.1004e-02, 8.2039e-01, 4.0499e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,225][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0016, 0.1123, 0.0498, 0.0714, 0.0515, 0.0508, 0.0581, 0.0419, 0.0444,
        0.0573, 0.0549, 0.0794, 0.0644, 0.0663, 0.0435, 0.0627, 0.0897],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,225][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0041, 0.0318, 0.0378, 0.0347, 0.0638, 0.0800, 0.0476, 0.0613, 0.0521,
        0.0695, 0.0515, 0.0530, 0.1036, 0.0611, 0.0769, 0.0959, 0.0754],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,226][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0083, 0.2039, 0.0106, 0.0285, 0.0228, 0.0076, 0.0140, 0.0429, 0.0224,
        0.0769, 0.0748, 0.0774, 0.0458, 0.1009, 0.0291, 0.0774, 0.1567],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,226][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0318, 0.0051, 0.0111, 0.0144, 0.0040, 0.0289, 0.0559, 0.1138, 0.0758,
        0.0540, 0.0400, 0.1122, 0.1103, 0.0919, 0.0469, 0.0797, 0.1243],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,227][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0024, 0.0847, 0.0334, 0.0750, 0.1225, 0.1479, 0.0382, 0.0305, 0.0351,
        0.0589, 0.0578, 0.0371, 0.0621, 0.0393, 0.0200, 0.1062, 0.0491],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,228][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0053, 0.0818, 0.0236, 0.0158, 0.0526, 0.0362, 0.0310, 0.1179, 0.0281,
        0.1283, 0.0787, 0.0722, 0.0953, 0.0440, 0.0563, 0.0799, 0.0531],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,230][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0054, 0.0464, 0.0360, 0.0689, 0.0676, 0.0586, 0.0339, 0.0435, 0.0491,
        0.0292, 0.0430, 0.0400, 0.1032, 0.1175, 0.0719, 0.1219, 0.0639],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,231][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ kiss] are: tensor([0.0524, 0.0238, 0.0077, 0.0070, 0.0113, 0.0105, 0.0056, 0.0204, 0.0264,
        0.0121, 0.0269, 0.0604, 0.0623, 0.0577, 0.1209, 0.2386, 0.1135, 0.1422],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,233][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ kiss] are: tensor([0.0004, 0.0207, 0.0088, 0.0510, 0.0193, 0.0451, 0.0248, 0.0077, 0.0816,
        0.0213, 0.0185, 0.0804, 0.0518, 0.0499, 0.0808, 0.1854, 0.1335, 0.1189],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,234][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ kiss] are: tensor([0.1174, 0.0234, 0.0234, 0.0186, 0.0124, 0.0254, 0.0237, 0.0464, 0.0465,
        0.0491, 0.0704, 0.0722, 0.0847, 0.0363, 0.0755, 0.0885, 0.0795, 0.1066],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,236][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ kiss] are: tensor([0.0584, 0.0519, 0.0438, 0.0345, 0.0965, 0.0502, 0.0330, 0.0275, 0.0537,
        0.0546, 0.0459, 0.0465, 0.0735, 0.0333, 0.0913, 0.0816, 0.0601, 0.0637],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,237][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ kiss] are: tensor([4.2268e-05, 7.0595e-05, 8.8511e-06, 2.1842e-04, 2.2466e-03, 4.2314e-03,
        4.1870e-04, 1.5958e-04, 6.4511e-03, 1.1626e-03, 7.5745e-03, 2.2280e-02,
        3.0760e-02, 3.9055e-03, 1.1744e-02, 7.9627e-01, 2.8068e-02, 8.4387e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,238][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ kiss] are: tensor([0.0014, 0.1061, 0.0472, 0.0699, 0.0481, 0.0489, 0.0555, 0.0406, 0.0413,
        0.0533, 0.0507, 0.0690, 0.0587, 0.0657, 0.0400, 0.0570, 0.0844, 0.0620],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,240][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ kiss] are: tensor([0.0042, 0.0301, 0.0294, 0.0296, 0.0552, 0.0737, 0.0435, 0.0519, 0.0491,
        0.0588, 0.0478, 0.0507, 0.0852, 0.0564, 0.0656, 0.0909, 0.0749, 0.1031],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,240][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ kiss] are: tensor([0.0015, 0.2574, 0.0080, 0.0471, 0.0185, 0.0085, 0.0132, 0.0342, 0.0249,
        0.0529, 0.0796, 0.0639, 0.0262, 0.1557, 0.0169, 0.0365, 0.0992, 0.0556],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,241][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ kiss] are: tensor([0.0100, 0.0072, 0.0128, 0.0199, 0.0042, 0.0341, 0.0574, 0.1296, 0.0536,
        0.0776, 0.0334, 0.0601, 0.0991, 0.1090, 0.0404, 0.0628, 0.1080, 0.0808],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,241][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ kiss] are: tensor([0.0010, 0.0953, 0.0202, 0.1011, 0.0963, 0.1388, 0.0442, 0.0264, 0.0386,
        0.0487, 0.0604, 0.0414, 0.0316, 0.0474, 0.0130, 0.1010, 0.0553, 0.0395],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,242][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ kiss] are: tensor([0.0028, 0.1253, 0.0338, 0.0156, 0.0678, 0.0377, 0.0292, 0.1170, 0.0236,
        0.1471, 0.0736, 0.0527, 0.0747, 0.0405, 0.0491, 0.0590, 0.0422, 0.0082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,242][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ kiss] are: tensor([0.0018, 0.0528, 0.0291, 0.0744, 0.0559, 0.0740, 0.0325, 0.0367, 0.0579,
        0.0204, 0.0331, 0.0357, 0.0675, 0.1357, 0.0517, 0.1515, 0.0529, 0.0365],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,242][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0464, 0.0191, 0.0101, 0.0092, 0.0147, 0.0114, 0.0061, 0.0197, 0.0244,
        0.0082, 0.0227, 0.0638, 0.0540, 0.0358, 0.1131, 0.2251, 0.1017, 0.0955,
        0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,243][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.0249, 0.0106, 0.0373, 0.0249, 0.0359, 0.0198, 0.0097, 0.0622,
        0.0224, 0.0184, 0.0773, 0.0564, 0.0349, 0.0694, 0.1742, 0.1168, 0.1114,
        0.0924], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,243][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1286, 0.0200, 0.0180, 0.0143, 0.0086, 0.0206, 0.0208, 0.0330, 0.0412,
        0.0405, 0.0630, 0.0664, 0.0754, 0.0411, 0.0577, 0.0717, 0.0727, 0.1046,
        0.1018], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,244][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0728, 0.0550, 0.0447, 0.0378, 0.1013, 0.0485, 0.0297, 0.0284, 0.0465,
        0.0587, 0.0435, 0.0391, 0.0639, 0.0301, 0.0811, 0.0696, 0.0487, 0.0587,
        0.0418], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,244][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([8.8431e-05, 4.8930e-05, 1.3991e-05, 1.4362e-04, 1.0980e-03, 3.3891e-03,
        2.2362e-04, 8.8746e-05, 5.3129e-03, 6.0539e-04, 5.6633e-03, 3.0569e-02,
        2.3442e-02, 5.2607e-03, 3.8490e-02, 6.6641e-01, 2.9077e-02, 8.3170e-02,
        1.0691e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,245][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0018, 0.1014, 0.0466, 0.0639, 0.0453, 0.0448, 0.0531, 0.0346, 0.0384,
        0.0476, 0.0460, 0.0653, 0.0527, 0.0623, 0.0371, 0.0494, 0.0793, 0.0567,
        0.0734], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,246][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0032, 0.0245, 0.0291, 0.0253, 0.0568, 0.0695, 0.0391, 0.0462, 0.0372,
        0.0541, 0.0415, 0.0415, 0.0795, 0.0506, 0.0682, 0.0839, 0.0662, 0.1068,
        0.0765], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,248][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0016, 0.2048, 0.0116, 0.0374, 0.0184, 0.0084, 0.0119, 0.0253, 0.0218,
        0.0458, 0.0602, 0.0484, 0.0283, 0.1480, 0.0193, 0.0395, 0.0882, 0.0591,
        0.1219], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,250][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0741, 0.0063, 0.0242, 0.0238, 0.0064, 0.0394, 0.0731, 0.1726, 0.0788,
        0.0406, 0.0240, 0.0491, 0.0500, 0.1005, 0.0303, 0.0336, 0.0687, 0.0559,
        0.0485], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,251][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0009, 0.0892, 0.0263, 0.1062, 0.0856, 0.1596, 0.0387, 0.0216, 0.0294,
        0.0418, 0.0511, 0.0382, 0.0262, 0.0360, 0.0149, 0.0987, 0.0522, 0.0345,
        0.0490], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,253][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0029, 0.1187, 0.0311, 0.0142, 0.0620, 0.0375, 0.0307, 0.1301, 0.0254,
        0.1376, 0.0715, 0.0532, 0.0858, 0.0451, 0.0463, 0.0517, 0.0398, 0.0091,
        0.0074], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,255][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0017, 0.0654, 0.0370, 0.0688, 0.0917, 0.0773, 0.0253, 0.0324, 0.0443,
        0.0245, 0.0296, 0.0296, 0.0732, 0.0947, 0.0693, 0.1247, 0.0384, 0.0288,
        0.0434], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,283][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:18:59,284][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,284][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,284][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,284][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,285][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,285][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,285][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,286][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,286][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,286][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,287][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,287][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:18:59,287][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2658, 0.7342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,287][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0214, 0.9786], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,288][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0109, 0.9891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,288][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0146, 0.9854], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,289][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0080, 0.9920], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,291][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0060, 0.9940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,292][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0513, 0.9487], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,293][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0070, 0.9930], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,295][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3788, 0.6212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,296][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0145, 0.9855], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,298][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,299][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0137, 0.9863], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:18:59,300][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.1389, 0.4644, 0.3967], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,300][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0078, 0.8054, 0.1868], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,301][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0198, 0.7896, 0.1906], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,301][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0112, 0.5366, 0.4522], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,301][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([0.0035, 0.7718, 0.2247], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,301][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0042, 0.7217, 0.2741], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,302][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0538, 0.5033, 0.4429], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,302][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0046, 0.4374, 0.5580], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,302][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0880, 0.2321, 0.6799], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,302][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0192, 0.3250, 0.6559], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,303][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0120, 0.5215, 0.4666], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,303][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0028, 0.1718, 0.8255], device='cuda:0') for source tokens [Then, Thomas]
[2024-07-24 10:18:59,303][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1761, 0.4249, 0.1997, 0.1992], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,304][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0029, 0.3216, 0.1406, 0.5349], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,304][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0030, 0.3989, 0.1748, 0.4232], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,306][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0048, 0.4038, 0.2619, 0.3294], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,308][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0012, 0.2950, 0.0938, 0.6100], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,309][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0010, 0.2772, 0.1256, 0.5962], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,310][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0090, 0.2652, 0.2781, 0.4477], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,311][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0013, 0.1977, 0.4432, 0.3578], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,313][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0286, 0.1889, 0.3287, 0.4538], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,314][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0036, 0.1889, 0.3514, 0.4561], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,316][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0095, 0.2580, 0.2440, 0.4886], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,317][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0026, 0.1442, 0.3755, 0.4777], device='cuda:0') for source tokens [Then, Thomas and]
[2024-07-24 10:18:59,318][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Cody] are: tensor([0.1622, 0.3050, 0.1859, 0.1341, 0.2127], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,318][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Cody] are: tensor([0.0091, 0.2771, 0.1339, 0.3541, 0.2257], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,318][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Cody] are: tensor([0.0132, 0.3277, 0.1697, 0.3053, 0.1840], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,319][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Cody] are: tensor([0.0228, 0.2263, 0.2427, 0.1596, 0.3486], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,319][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Cody] are: tensor([0.0011, 0.1735, 0.0644, 0.3427, 0.4183], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,319][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Cody] are: tensor([0.0023, 0.2539, 0.1149, 0.3442, 0.2847], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,319][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Cody] are: tensor([0.0099, 0.1101, 0.2037, 0.1933, 0.4831], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,320][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Cody] are: tensor([0.0025, 0.1229, 0.2417, 0.1361, 0.4969], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,320][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Cody] are: tensor([0.0918, 0.0834, 0.2164, 0.1653, 0.4432], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,320][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Cody] are: tensor([0.0042, 0.1018, 0.1832, 0.2132, 0.4976], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,321][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Cody] are: tensor([0.0138, 0.0920, 0.1057, 0.0827, 0.7058], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,321][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Cody] are: tensor([0.0033, 0.0568, 0.2600, 0.1964, 0.4835], device='cuda:0') for source tokens [Then, Thomas and Cody]
[2024-07-24 10:18:59,321][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2256, 0.3470, 0.0895, 0.0998, 0.1275, 0.1106], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,322][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0024, 0.1835, 0.0485, 0.2496, 0.1083, 0.4077], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,324][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0019, 0.1372, 0.0803, 0.1871, 0.0831, 0.5104], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,325][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0082, 0.0648, 0.0346, 0.0380, 0.0983, 0.7560], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,326][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([1.9016e-04, 5.0798e-02, 1.7562e-02, 1.1158e-01, 8.9142e-02, 7.3073e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,328][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0007, 0.1481, 0.0998, 0.2478, 0.1740, 0.3295], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,329][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0026, 0.0489, 0.0945, 0.1219, 0.2491, 0.4830], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,330][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([5.7197e-04, 5.2407e-02, 1.1910e-01, 8.6089e-02, 1.6562e-01, 5.7622e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,332][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0209, 0.0723, 0.1057, 0.1384, 0.2210, 0.4418], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,333][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0016, 0.0780, 0.1319, 0.1536, 0.2560, 0.3788], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,335][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0063, 0.0766, 0.0397, 0.0835, 0.3662, 0.4277], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,335][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0021, 0.0409, 0.0786, 0.0697, 0.2052, 0.6034], device='cuda:0') for source tokens [Then, Thomas and Cody had]
[2024-07-24 10:18:59,335][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2105, 0.2661, 0.1039, 0.1055, 0.1376, 0.1128, 0.0637],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,336][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0015, 0.1200, 0.0529, 0.1778, 0.1436, 0.3329, 0.1714],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,336][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0014, 0.1111, 0.1075, 0.1438, 0.0991, 0.3748, 0.1623],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,336][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0029, 0.0668, 0.0351, 0.0420, 0.0852, 0.6867, 0.0813],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,337][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.9448e-04, 4.7269e-02, 1.9704e-02, 1.1314e-01, 1.0717e-01, 5.0988e-01,
        2.0265e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,337][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0006, 0.1054, 0.0858, 0.1831, 0.1682, 0.2060, 0.2509],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,337][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0028, 0.0475, 0.1065, 0.0935, 0.2942, 0.3211, 0.1344],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,337][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0006, 0.0482, 0.1076, 0.0780, 0.1664, 0.3794, 0.2198],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,338][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0176, 0.0510, 0.1151, 0.1163, 0.1991, 0.3766, 0.1244],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,338][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0012, 0.0421, 0.0825, 0.0784, 0.3822, 0.2734, 0.1401],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,338][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0023, 0.0526, 0.0401, 0.0739, 0.4136, 0.3033, 0.1142],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,339][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0016, 0.0370, 0.0800, 0.0935, 0.2438, 0.4715, 0.0726],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a]
[2024-07-24 10:18:59,341][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0696, 0.2335, 0.0610, 0.0738, 0.1193, 0.1015, 0.0555, 0.2858],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,342][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0013, 0.0972, 0.0463, 0.1384, 0.1113, 0.3395, 0.1825, 0.0834],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,344][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0017, 0.0645, 0.0819, 0.0909, 0.1052, 0.2445, 0.1887, 0.2227],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,345][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0043, 0.0357, 0.0148, 0.0162, 0.0633, 0.6833, 0.0743, 0.1082],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,346][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([2.7959e-04, 4.7365e-02, 2.2884e-02, 8.2785e-02, 1.5474e-01, 3.6679e-01,
        1.8299e-01, 1.4216e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,347][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0006, 0.1070, 0.0576, 0.1505, 0.1009, 0.1822, 0.1876, 0.2137],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,349][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0010, 0.0324, 0.0709, 0.0655, 0.2337, 0.2621, 0.1312, 0.2033],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,351][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0006, 0.0456, 0.0789, 0.0658, 0.1041, 0.3101, 0.1762, 0.2188],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,352][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0426, 0.0338, 0.0658, 0.0712, 0.1220, 0.2537, 0.0877, 0.3233],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,353][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0010, 0.0453, 0.0952, 0.0700, 0.2935, 0.1991, 0.1461, 0.1497],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,353][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0022, 0.0315, 0.0352, 0.0358, 0.3670, 0.3068, 0.0805, 0.1410],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,353][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0046, 0.0297, 0.0435, 0.0494, 0.1551, 0.5291, 0.0653, 0.1233],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot]
[2024-07-24 10:18:59,354][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.1312, 0.1411, 0.0650, 0.0579, 0.0777, 0.0746, 0.0413, 0.2259, 0.1853],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,354][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0011, 0.1061, 0.0725, 0.1612, 0.0919, 0.1858, 0.0932, 0.0584, 0.2298],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,354][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0008, 0.0858, 0.0899, 0.0834, 0.0528, 0.2044, 0.0851, 0.1496, 0.2481],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,355][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0077, 0.0383, 0.0083, 0.0200, 0.0203, 0.2688, 0.0391, 0.0222, 0.5752],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,355][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([1.4389e-04, 3.4782e-02, 1.5993e-02, 7.2818e-02, 5.5062e-02, 2.3748e-01,
        1.2270e-01, 1.0770e-01, 3.5332e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,355][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([1.6840e-04, 5.4169e-02, 4.1896e-02, 1.2529e-01, 5.4191e-02, 1.2105e-01,
        1.0083e-01, 1.6592e-01, 3.3649e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,355][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0020, 0.0457, 0.0915, 0.0736, 0.1828, 0.1848, 0.0890, 0.1917, 0.1390],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,356][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.9783e-04, 4.0643e-02, 1.1245e-01, 6.6372e-02, 9.1144e-02, 2.0415e-01,
        1.0988e-01, 1.0155e-01, 2.7361e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,356][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0120, 0.0462, 0.0643, 0.1027, 0.0952, 0.2329, 0.1029, 0.1773, 0.1667],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,358][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0005, 0.0477, 0.1070, 0.0732, 0.2232, 0.1647, 0.0762, 0.2268, 0.0807],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,360][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0024, 0.0340, 0.0404, 0.0460, 0.2544, 0.2217, 0.0823, 0.0777, 0.2411],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,361][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0053, 0.0537, 0.0636, 0.1028, 0.1610, 0.3471, 0.0696, 0.0591, 0.1376],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of]
[2024-07-24 10:18:59,363][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.1266, 0.1399, 0.0679, 0.0515, 0.0862, 0.0771, 0.0363, 0.1672, 0.1859,
        0.0614], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,364][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0007, 0.0602, 0.0216, 0.1312, 0.0553, 0.1688, 0.1396, 0.0372, 0.2898,
        0.0957], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,366][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0004, 0.0386, 0.0223, 0.0566, 0.0439, 0.1605, 0.1155, 0.1394, 0.3472,
        0.0757], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,368][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0058, 0.0148, 0.0052, 0.0097, 0.0214, 0.2562, 0.0382, 0.0276, 0.5062,
        0.1150], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,369][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([7.2186e-05, 2.8303e-02, 1.1459e-02, 5.8419e-02, 5.9690e-02, 2.9266e-01,
        1.0761e-01, 6.7673e-02, 2.6355e-01, 1.1056e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,369][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([1.2361e-04, 5.4385e-02, 1.9554e-02, 1.1237e-01, 4.8819e-02, 1.1926e-01,
        1.2125e-01, 8.7256e-02, 3.4697e-01, 9.0007e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,370][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0009, 0.0266, 0.0367, 0.0536, 0.1447, 0.2143, 0.0942, 0.1388, 0.1445,
        0.1458], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,370][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([1.3729e-04, 1.3528e-02, 2.2933e-02, 2.9609e-02, 5.4190e-02, 1.8946e-01,
        1.0458e-01, 9.7286e-02, 2.7906e-01, 2.0922e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,371][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0083, 0.0231, 0.0404, 0.0527, 0.0822, 0.1901, 0.0580, 0.1614, 0.1241,
        0.2597], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,371][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0007, 0.0299, 0.0491, 0.0627, 0.1971, 0.1932, 0.1178, 0.1496, 0.1189,
        0.0810], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,371][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0010, 0.0277, 0.0300, 0.0289, 0.3102, 0.1945, 0.0693, 0.0598, 0.2175,
        0.0610], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,372][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0031, 0.0150, 0.0400, 0.0543, 0.1173, 0.4638, 0.0641, 0.0575, 0.1342,
        0.0508], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun]
[2024-07-24 10:18:59,372][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.1128, 0.1222, 0.0445, 0.0450, 0.0612, 0.0608, 0.0338, 0.1750, 0.1505,
        0.0694, 0.1249], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,372][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0019, 0.0823, 0.0420, 0.1140, 0.0911, 0.1661, 0.0777, 0.0589, 0.2028,
        0.1049, 0.0583], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,373][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0013, 0.0528, 0.0582, 0.0564, 0.0722, 0.1589, 0.0749, 0.1373, 0.1983,
        0.0732, 0.1166], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,373][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0094, 0.0371, 0.0138, 0.0158, 0.0299, 0.1792, 0.0350, 0.0261, 0.3004,
        0.0961, 0.2571], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,373][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([1.4598e-04, 1.9783e-02, 8.7850e-03, 4.9291e-02, 4.5863e-02, 2.0842e-01,
        8.6106e-02, 6.1801e-02, 2.2830e-01, 6.2678e-02, 2.2883e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,373][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([2.2655e-04, 7.0593e-02, 3.3995e-02, 8.7684e-02, 6.1234e-02, 8.8790e-02,
        6.5604e-02, 1.0161e-01, 2.6412e-01, 9.7999e-02, 1.2815e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,374][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0022, 0.0298, 0.0556, 0.0543, 0.1448, 0.1500, 0.0682, 0.1255, 0.1178,
        0.1198, 0.1319], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,376][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0003, 0.0204, 0.0677, 0.0366, 0.0719, 0.1291, 0.0649, 0.0704, 0.2302,
        0.1685, 0.1400], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,377][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0144, 0.0308, 0.0522, 0.0561, 0.0904, 0.1356, 0.0547, 0.1332, 0.0818,
        0.1632, 0.1878], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,379][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0013, 0.0447, 0.1031, 0.0624, 0.2424, 0.1160, 0.0746, 0.1268, 0.0951,
        0.0903, 0.0435], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,380][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0037, 0.0334, 0.0291, 0.0338, 0.3085, 0.1306, 0.0483, 0.0644, 0.1448,
        0.0351, 0.1684], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,382][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0037, 0.0484, 0.0683, 0.0863, 0.2041, 0.2814, 0.0457, 0.0603, 0.0959,
        0.0356, 0.0703], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at]
[2024-07-24 10:18:59,384][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1329, 0.0816, 0.0279, 0.0348, 0.0425, 0.0383, 0.0260, 0.0909, 0.1168,
        0.0332, 0.0987, 0.2765], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,385][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0013, 0.0558, 0.0299, 0.0883, 0.0617, 0.1226, 0.0690, 0.0448, 0.1871,
        0.0804, 0.0532, 0.2060], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,387][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0007, 0.0363, 0.0362, 0.0413, 0.0309, 0.1117, 0.0582, 0.0870, 0.2075,
        0.0512, 0.0978, 0.2411], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,387][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0120, 0.0208, 0.0041, 0.0094, 0.0152, 0.0775, 0.0209, 0.0082, 0.1691,
        0.0401, 0.1107, 0.5120], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,388][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.4372e-04, 1.9080e-02, 6.7593e-03, 4.8646e-02, 3.0099e-02, 1.5428e-01,
        7.4502e-02, 5.4699e-02, 2.4819e-01, 5.3540e-02, 1.5222e-01, 1.5785e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,388][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.0800e-04, 3.5965e-02, 2.2150e-02, 5.7823e-02, 3.6330e-02, 5.3929e-02,
        6.7397e-02, 7.3965e-02, 2.2634e-01, 7.8456e-02, 1.2971e-01, 2.1773e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,388][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0022, 0.0239, 0.0386, 0.0395, 0.0977, 0.1048, 0.0615, 0.1043, 0.1208,
        0.1125, 0.1072, 0.1869], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,389][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0003, 0.0201, 0.0409, 0.0290, 0.0513, 0.0876, 0.0579, 0.0526, 0.1603,
        0.1236, 0.1250, 0.2514], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,389][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0166, 0.0247, 0.0456, 0.0460, 0.0734, 0.1327, 0.0535, 0.0991, 0.0685,
        0.1381, 0.1462, 0.1556], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,389][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0013, 0.0291, 0.0617, 0.0445, 0.1505, 0.1252, 0.0771, 0.1770, 0.0868,
        0.0858, 0.0531, 0.1080], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,390][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0055, 0.0255, 0.0228, 0.0281, 0.2032, 0.0981, 0.0449, 0.0417, 0.1333,
        0.0166, 0.1246, 0.2558], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,390][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0046, 0.0402, 0.0552, 0.0642, 0.1966, 0.2220, 0.0428, 0.0502, 0.0776,
        0.0213, 0.0770, 0.1481], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the]
[2024-07-24 10:18:59,390][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0815, 0.0938, 0.0362, 0.0274, 0.0464, 0.0370, 0.0188, 0.0649, 0.0847,
        0.0274, 0.0989, 0.1884, 0.1947], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,391][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0010, 0.0475, 0.0148, 0.0631, 0.0498, 0.1541, 0.0737, 0.0290, 0.1690,
        0.0790, 0.0428, 0.1435, 0.1328], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,391][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0004, 0.0280, 0.0274, 0.0356, 0.0323, 0.1023, 0.0521, 0.0673, 0.1593,
        0.0429, 0.0844, 0.1806, 0.1873], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,393][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0038, 0.0038, 0.0010, 0.0023, 0.0035, 0.0239, 0.0083, 0.0031, 0.1252,
        0.0262, 0.0637, 0.3921, 0.3431], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,394][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([1.0009e-04, 1.5516e-02, 4.6137e-03, 4.1924e-02, 4.1171e-02, 1.6959e-01,
        8.0267e-02, 3.6585e-02, 1.9485e-01, 5.9836e-02, 1.5961e-01, 1.1707e-01,
        7.8865e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,395][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([1.2369e-04, 3.0498e-02, 1.3933e-02, 6.3194e-02, 2.7801e-02, 7.3283e-02,
        6.8403e-02, 6.5603e-02, 2.1894e-01, 6.0318e-02, 9.5416e-02, 1.5556e-01,
        1.2693e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,397][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0009, 0.0159, 0.0340, 0.0296, 0.1231, 0.1277, 0.0534, 0.0833, 0.0867,
        0.0954, 0.0884, 0.1259, 0.1357], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,398][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([1.0998e-04, 9.5077e-03, 1.8412e-02, 1.5347e-02, 3.0133e-02, 9.7441e-02,
        4.4197e-02, 4.0063e-02, 1.6797e-01, 1.1995e-01, 1.1595e-01, 1.8842e-01,
        1.5251e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,399][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0037, 0.0108, 0.0170, 0.0206, 0.0566, 0.0778, 0.0283, 0.0919, 0.0453,
        0.1026, 0.1332, 0.1007, 0.3115], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,401][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0007, 0.0352, 0.0570, 0.0642, 0.1444, 0.1321, 0.0964, 0.1064, 0.1060,
        0.0563, 0.0408, 0.0906, 0.0698], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,402][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0024, 0.0145, 0.0222, 0.0163, 0.3016, 0.0749, 0.0227, 0.0325, 0.0876,
        0.0209, 0.0880, 0.1662, 0.1502], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,404][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0042, 0.0115, 0.0283, 0.0281, 0.1018, 0.2134, 0.0269, 0.0250, 0.0651,
        0.0210, 0.0610, 0.1435, 0.2702], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station]
[2024-07-24 10:18:59,405][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0551, 0.0481, 0.0267, 0.0249, 0.0321, 0.0280, 0.0208, 0.0948, 0.0756,
        0.0199, 0.0622, 0.1872, 0.1710, 0.1537], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,405][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0004, 0.0380, 0.0242, 0.0675, 0.0702, 0.1332, 0.0468, 0.0304, 0.1193,
        0.0628, 0.0357, 0.1492, 0.1560, 0.0662], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,405][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.5514e-04, 2.3802e-02, 2.7866e-02, 2.9965e-02, 3.1664e-02, 8.1976e-02,
        3.9431e-02, 5.8556e-02, 1.4162e-01, 2.9912e-02, 4.9508e-02, 1.5406e-01,
        2.1780e-01, 1.1368e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,406][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0004, 0.0050, 0.0010, 0.0025, 0.0032, 0.0434, 0.0048, 0.0039, 0.1195,
        0.0161, 0.0473, 0.3449, 0.3537, 0.0544], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,406][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([5.1045e-05, 1.3438e-02, 5.4490e-03, 2.9772e-02, 3.2450e-02, 1.4197e-01,
        5.9762e-02, 3.6369e-02, 1.7064e-01, 4.4194e-02, 1.1615e-01, 1.3005e-01,
        7.6932e-02, 1.4276e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,406][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([6.9248e-05, 2.2877e-02, 1.3300e-02, 5.5057e-02, 3.0577e-02, 6.4502e-02,
        5.4955e-02, 6.6085e-02, 1.7947e-01, 4.9257e-02, 8.1976e-02, 1.3608e-01,
        1.0484e-01, 1.4096e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,407][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0007, 0.0165, 0.0267, 0.0268, 0.1114, 0.1215, 0.0373, 0.0738, 0.0745,
        0.0669, 0.0774, 0.1115, 0.1411, 0.1140], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,407][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([4.7376e-05, 1.3469e-02, 2.9003e-02, 2.1239e-02, 3.9410e-02, 9.2304e-02,
        4.0754e-02, 3.5251e-02, 1.2084e-01, 1.0633e-01, 8.3825e-02, 1.8112e-01,
        1.3932e-01, 9.7083e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,407][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0044, 0.0101, 0.0182, 0.0219, 0.0353, 0.0667, 0.0281, 0.0670, 0.0450,
        0.0868, 0.1143, 0.0962, 0.3138, 0.0922], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,408][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0003, 0.0293, 0.0608, 0.0472, 0.1779, 0.1689, 0.0608, 0.1459, 0.0499,
        0.0534, 0.0337, 0.0590, 0.0853, 0.0276], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,408][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0007, 0.0094, 0.0129, 0.0138, 0.1308, 0.0672, 0.0267, 0.0246, 0.0997,
        0.0137, 0.0931, 0.2290, 0.1462, 0.1322], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,409][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0015, 0.0252, 0.0447, 0.0431, 0.1560, 0.2024, 0.0235, 0.0455, 0.0630,
        0.0166, 0.0492, 0.0950, 0.1996, 0.0346], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station.]
[2024-07-24 10:18:59,411][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Thomas] are: tensor([0.0746, 0.0315, 0.0166, 0.0169, 0.0297, 0.0266, 0.0147, 0.0371, 0.0645,
        0.0201, 0.0598, 0.1252, 0.1011, 0.1083, 0.2734], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,412][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Thomas] are: tensor([0.0014, 0.0518, 0.0190, 0.0508, 0.0431, 0.0832, 0.0365, 0.0299, 0.1180,
        0.0696, 0.0399, 0.1080, 0.1031, 0.0927, 0.1530], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,414][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Thomas] are: tensor([0.0012, 0.0259, 0.0145, 0.0219, 0.0209, 0.0650, 0.0333, 0.0487, 0.1433,
        0.0228, 0.0779, 0.1234, 0.1327, 0.0897, 0.1788], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,415][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Thomas] are: tensor([0.0055, 0.0047, 0.0011, 0.0021, 0.0035, 0.0226, 0.0061, 0.0015, 0.1206,
        0.0189, 0.0456, 0.1883, 0.2457, 0.0648, 0.2691], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,417][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Thomas] are: tensor([1.4844e-04, 1.1359e-02, 4.0314e-03, 3.2590e-02, 3.3789e-02, 1.6219e-01,
        5.0294e-02, 2.8412e-02, 1.4426e-01, 4.0690e-02, 1.5239e-01, 1.2467e-01,
        6.7691e-02, 8.8392e-02, 5.9090e-02], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,418][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Thomas] are: tensor([0.0002, 0.0240, 0.0094, 0.0296, 0.0264, 0.0433, 0.0379, 0.0496, 0.1422,
        0.0512, 0.0894, 0.1154, 0.1064, 0.1280, 0.1471], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,420][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Thomas] are: tensor([0.0038, 0.0106, 0.0195, 0.0191, 0.0718, 0.0787, 0.0309, 0.0470, 0.0507,
        0.0558, 0.0647, 0.0996, 0.1072, 0.0910, 0.2498], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,421][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Thomas] are: tensor([0.0002, 0.0088, 0.0190, 0.0100, 0.0307, 0.0657, 0.0297, 0.0278, 0.1060,
        0.0855, 0.0955, 0.1194, 0.1098, 0.0894, 0.2025], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,422][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Thomas] are: tensor([0.0034, 0.0120, 0.0243, 0.0172, 0.0591, 0.0586, 0.0207, 0.0687, 0.0394,
        0.0715, 0.0949, 0.0738, 0.1911, 0.0668, 0.1986], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,422][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Thomas] are: tensor([0.0011, 0.0209, 0.0421, 0.0347, 0.1289, 0.1442, 0.0635, 0.0618, 0.0708,
        0.0507, 0.0395, 0.0719, 0.0793, 0.0547, 0.1358], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,423][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Thomas] are: tensor([0.0064, 0.0132, 0.0093, 0.0103, 0.1381, 0.0431, 0.0194, 0.0149, 0.0755,
        0.0133, 0.0684, 0.1166, 0.0851, 0.0675, 0.3188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,423][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Thomas] are: tensor([0.0044, 0.0106, 0.0215, 0.0221, 0.1103, 0.1270, 0.0152, 0.0284, 0.0486,
        0.0152, 0.0559, 0.0866, 0.1690, 0.0157, 0.2694], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas]
[2024-07-24 10:18:59,423][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1270, 0.0341, 0.0104, 0.0090, 0.0153, 0.0140, 0.0062, 0.0215, 0.0318,
        0.0093, 0.0330, 0.0787, 0.0696, 0.0482, 0.1392, 0.3528],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,424][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0013, 0.0333, 0.0125, 0.0435, 0.0271, 0.0575, 0.0329, 0.0112, 0.0890,
        0.0332, 0.0215, 0.1002, 0.0690, 0.0631, 0.1305, 0.2741],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,424][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0007, 0.0177, 0.0144, 0.0208, 0.0190, 0.0395, 0.0221, 0.0300, 0.0991,
        0.0167, 0.0567, 0.1135, 0.1293, 0.0830, 0.2108, 0.1268],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,424][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.2082e-02, 3.3452e-03, 2.7469e-04, 1.0601e-03, 1.3078e-03, 7.2747e-03,
        2.6296e-03, 4.5969e-04, 4.2009e-02, 3.8648e-03, 1.8771e-02, 1.0379e-01,
        9.7762e-02, 2.3786e-02, 1.1130e-01, 5.7028e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,425][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.1915e-04, 1.0033e-02, 3.3092e-03, 3.0147e-02, 2.0540e-02, 1.0321e-01,
        3.7789e-02, 1.7729e-02, 1.2428e-01, 2.2994e-02, 1.0365e-01, 9.7412e-02,
        4.0152e-02, 9.0116e-02, 5.7716e-02, 2.4080e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,425][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0002, 0.0165, 0.0102, 0.0263, 0.0219, 0.0252, 0.0318, 0.0306, 0.1248,
        0.0435, 0.0709, 0.1217, 0.0865, 0.1073, 0.1542, 0.1282],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,426][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0019, 0.0078, 0.0167, 0.0170, 0.0466, 0.0419, 0.0204, 0.0299, 0.0422,
        0.0380, 0.0432, 0.0772, 0.0641, 0.0674, 0.1707, 0.3149],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,426][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.9683e-04, 6.9851e-03, 9.9741e-03, 8.4042e-03, 1.8270e-02, 4.6978e-02,
        2.1007e-02, 1.9974e-02, 9.2714e-02, 5.5017e-02, 6.8450e-02, 1.1700e-01,
        8.3222e-02, 6.9522e-02, 1.0102e-01, 2.8127e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,428][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0052, 0.0105, 0.0147, 0.0148, 0.0376, 0.0457, 0.0193, 0.0461, 0.0275,
        0.0568, 0.0833, 0.0768, 0.1910, 0.0519, 0.1419, 0.1769],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,430][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0025, 0.0225, 0.0494, 0.0479, 0.0890, 0.0630, 0.0735, 0.0582, 0.0769,
        0.0650, 0.0275, 0.0963, 0.0634, 0.0570, 0.1210, 0.0869],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,431][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0077, 0.0094, 0.0048, 0.0069, 0.0848, 0.0234, 0.0120, 0.0088, 0.0508,
        0.0062, 0.0304, 0.0802, 0.0673, 0.0414, 0.1715, 0.3945],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,433][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0059, 0.0065, 0.0076, 0.0088, 0.0363, 0.0456, 0.0072, 0.0065, 0.0187,
        0.0033, 0.0170, 0.0361, 0.0584, 0.0059, 0.1199, 0.6163],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave]
[2024-07-24 10:18:59,434][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0722, 0.0241, 0.0079, 0.0119, 0.0133, 0.0142, 0.0084, 0.0216, 0.0414,
        0.0082, 0.0346, 0.0895, 0.0656, 0.0475, 0.1026, 0.2988, 0.1382],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,436][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0016, 0.0219, 0.0124, 0.0281, 0.0296, 0.0502, 0.0249, 0.0167, 0.0607,
        0.0369, 0.0205, 0.0757, 0.0751, 0.0435, 0.0978, 0.2549, 0.1494],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,438][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0005, 0.0161, 0.0211, 0.0199, 0.0209, 0.0417, 0.0207, 0.0281, 0.0721,
        0.0190, 0.0362, 0.1035, 0.1432, 0.0624, 0.1793, 0.1322, 0.0831],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,439][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0045, 0.0043, 0.0006, 0.0012, 0.0024, 0.0132, 0.0024, 0.0011, 0.0278,
        0.0063, 0.0154, 0.0694, 0.1153, 0.0200, 0.1110, 0.5330, 0.0722],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,440][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.3432e-05, 7.6521e-03, 3.5361e-03, 2.2033e-02, 2.3119e-02, 7.6485e-02,
        3.6871e-02, 2.2339e-02, 1.1367e-01, 2.9519e-02, 8.8514e-02, 9.2283e-02,
        4.2696e-02, 7.2947e-02, 6.0691e-02, 1.9020e-01, 1.1736e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,440][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0002, 0.0171, 0.0109, 0.0234, 0.0259, 0.0207, 0.0303, 0.0280, 0.1110,
        0.0407, 0.0542, 0.0974, 0.0649, 0.0771, 0.1160, 0.0984, 0.1837],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,440][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0018, 0.0076, 0.0147, 0.0135, 0.0501, 0.0342, 0.0179, 0.0269, 0.0351,
        0.0365, 0.0353, 0.0754, 0.0595, 0.0586, 0.1492, 0.2389, 0.1446],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,441][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.0324e-04, 5.9747e-03, 1.2298e-02, 8.0959e-03, 1.7790e-02, 3.5594e-02,
        2.0695e-02, 1.8027e-02, 5.9121e-02, 5.6096e-02, 5.0452e-02, 1.0461e-01,
        7.7653e-02, 5.3802e-02, 1.1165e-01, 2.4537e-01, 1.2257e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,441][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0047, 0.0088, 0.0172, 0.0164, 0.0344, 0.0553, 0.0187, 0.0330, 0.0286,
        0.0501, 0.0620, 0.0599, 0.1602, 0.0505, 0.1510, 0.1608, 0.0883],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,441][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0024, 0.0175, 0.0298, 0.0257, 0.1137, 0.0600, 0.0452, 0.0661, 0.0543,
        0.0581, 0.0271, 0.0935, 0.0643, 0.0429, 0.0989, 0.1041, 0.0965],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,442][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0102, 0.0122, 0.0066, 0.0096, 0.1090, 0.0296, 0.0141, 0.0128, 0.0412,
        0.0060, 0.0323, 0.0735, 0.0636, 0.0439, 0.1718, 0.2612, 0.1024],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,442][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0054, 0.0074, 0.0079, 0.0105, 0.0414, 0.0510, 0.0079, 0.0099, 0.0164,
        0.0044, 0.0122, 0.0282, 0.0584, 0.0085, 0.1029, 0.5577, 0.0699],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a]
[2024-07-24 10:18:59,443][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ kiss] are: tensor([0.0524, 0.0238, 0.0077, 0.0070, 0.0113, 0.0105, 0.0056, 0.0204, 0.0264,
        0.0121, 0.0269, 0.0604, 0.0623, 0.0577, 0.1209, 0.2386, 0.1135, 0.1422],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,443][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ kiss] are: tensor([0.0004, 0.0207, 0.0088, 0.0510, 0.0193, 0.0451, 0.0248, 0.0077, 0.0816,
        0.0213, 0.0185, 0.0804, 0.0518, 0.0499, 0.0808, 0.1854, 0.1335, 0.1189],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,445][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ kiss] are: tensor([0.0001, 0.0116, 0.0082, 0.0180, 0.0142, 0.0332, 0.0232, 0.0217, 0.0864,
        0.0121, 0.0515, 0.0952, 0.1094, 0.0835, 0.1397, 0.0984, 0.0933, 0.1004],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,446][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ kiss] are: tensor([7.1974e-04, 1.1826e-03, 1.5460e-04, 8.1288e-04, 9.1010e-04, 8.6045e-03,
        1.6907e-03, 5.1107e-04, 2.5876e-02, 3.2840e-03, 1.3141e-02, 5.4280e-02,
        7.3361e-02, 1.7721e-02, 6.4743e-02, 4.8642e-01, 9.4834e-02, 1.5176e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,447][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ kiss] are: tensor([4.9235e-05, 9.8356e-03, 2.2681e-03, 2.4929e-02, 2.5266e-02, 1.0436e-01,
        3.1657e-02, 1.7399e-02, 1.1158e-01, 2.1442e-02, 8.8470e-02, 7.1362e-02,
        4.0732e-02, 5.4928e-02, 3.6582e-02, 1.8986e-01, 8.6818e-02, 8.2463e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,448][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ kiss] are: tensor([4.5452e-05, 1.5673e-02, 4.0578e-03, 3.3815e-02, 1.2188e-02, 2.3146e-02,
        2.3152e-02, 1.8882e-02, 1.0577e-01, 1.9445e-02, 5.8845e-02, 1.0294e-01,
        5.3525e-02, 9.9647e-02, 7.3485e-02, 8.3745e-02, 1.5600e-01, 1.1564e-01],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,450][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ kiss] are: tensor([0.0005, 0.0040, 0.0089, 0.0088, 0.0364, 0.0447, 0.0154, 0.0215, 0.0271,
        0.0258, 0.0374, 0.0478, 0.0569, 0.0474, 0.1835, 0.2315, 0.1108, 0.0915],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,451][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ kiss] are: tensor([1.1045e-04, 6.5227e-03, 6.6910e-03, 1.0125e-02, 1.2368e-02, 4.2383e-02,
        1.9091e-02, 1.0655e-02, 8.8590e-02, 3.3279e-02, 6.5936e-02, 1.4248e-01,
        5.0514e-02, 7.6595e-02, 7.2814e-02, 1.6334e-01, 9.8778e-02, 9.9727e-02],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,453][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ kiss] are: tensor([0.0021, 0.0053, 0.0108, 0.0122, 0.0331, 0.0471, 0.0155, 0.0390, 0.0220,
        0.0522, 0.0708, 0.0554, 0.1598, 0.0443, 0.1213, 0.1482, 0.0752, 0.0857],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,454][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ kiss] are: tensor([0.0017, 0.0297, 0.0479, 0.0665, 0.0993, 0.0726, 0.0549, 0.0420, 0.0560,
        0.0349, 0.0251, 0.0738, 0.0575, 0.0396, 0.0846, 0.0711, 0.0811, 0.0617],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,456][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ kiss] are: tensor([0.0025, 0.0049, 0.0041, 0.0044, 0.0540, 0.0267, 0.0109, 0.0079, 0.0354,
        0.0068, 0.0321, 0.0686, 0.0494, 0.0436, 0.2015, 0.2668, 0.1190, 0.0613],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,456][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ kiss] are: tensor([0.0010, 0.0064, 0.0066, 0.0152, 0.0430, 0.0557, 0.0075, 0.0089, 0.0187,
        0.0043, 0.0156, 0.0269, 0.0472, 0.0078, 0.0868, 0.5579, 0.0726, 0.0181],
       device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss]
[2024-07-24 10:18:59,457][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0464, 0.0191, 0.0101, 0.0092, 0.0147, 0.0114, 0.0061, 0.0197, 0.0244,
        0.0082, 0.0227, 0.0638, 0.0540, 0.0358, 0.1131, 0.2251, 0.1017, 0.0955,
        0.1188], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,457][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0011, 0.0249, 0.0106, 0.0373, 0.0249, 0.0359, 0.0198, 0.0097, 0.0622,
        0.0224, 0.0184, 0.0773, 0.0564, 0.0349, 0.0694, 0.1742, 0.1168, 0.1114,
        0.0924], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,458][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0002, 0.0130, 0.0124, 0.0157, 0.0125, 0.0334, 0.0202, 0.0183, 0.0738,
        0.0124, 0.0335, 0.0747, 0.1195, 0.0537, 0.1185, 0.0987, 0.0680, 0.0877,
        0.1339], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,458][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0020, 0.0046, 0.0006, 0.0015, 0.0027, 0.0160, 0.0024, 0.0012, 0.0342,
        0.0051, 0.0148, 0.0564, 0.0766, 0.0150, 0.0830, 0.4540, 0.0593, 0.1135,
        0.0572], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,458][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([6.0181e-05, 9.2395e-03, 2.8882e-03, 1.9894e-02, 1.4157e-02, 8.2756e-02,
        2.7638e-02, 1.3824e-02, 1.0089e-01, 1.8315e-02, 6.8061e-02, 6.9007e-02,
        3.3270e-02, 6.3936e-02, 5.3776e-02, 1.3587e-01, 8.6929e-02, 7.8189e-02,
        1.2130e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,459][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4516e-05, 1.9188e-02, 9.6114e-03, 2.8402e-02, 1.2938e-02, 1.6610e-02,
        2.0450e-02, 1.7153e-02, 9.1702e-02, 2.0279e-02, 4.7669e-02, 8.1759e-02,
        4.7361e-02, 4.8344e-02, 8.2099e-02, 7.4887e-02, 1.4142e-01, 1.1084e-01,
        1.2924e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,459][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0013, 0.0073, 0.0112, 0.0118, 0.0291, 0.0323, 0.0140, 0.0196, 0.0273,
        0.0234, 0.0302, 0.0523, 0.0505, 0.0419, 0.1364, 0.2106, 0.1188, 0.0833,
        0.0988], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,460][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.2033e-04, 8.7124e-03, 1.5472e-02, 1.0796e-02, 1.4617e-02, 3.0623e-02,
        1.6553e-02, 9.0116e-03, 5.8683e-02, 3.0066e-02, 4.7390e-02, 9.6361e-02,
        4.9742e-02, 4.4110e-02, 9.1026e-02, 1.6562e-01, 8.0703e-02, 8.5426e-02,
        1.4497e-01], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,460][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0046, 0.0083, 0.0154, 0.0161, 0.0337, 0.0454, 0.0199, 0.0350, 0.0268,
        0.0492, 0.0565, 0.0499, 0.1280, 0.0464, 0.1277, 0.1283, 0.0807, 0.0843,
        0.0437], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,461][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0016, 0.0338, 0.0480, 0.0404, 0.0931, 0.0549, 0.0327, 0.0513, 0.0418,
        0.0347, 0.0252, 0.0487, 0.0727, 0.0226, 0.0954, 0.1073, 0.0744, 0.0724,
        0.0490], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,462][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0043, 0.0083, 0.0047, 0.0057, 0.0535, 0.0225, 0.0097, 0.0068, 0.0369,
        0.0039, 0.0317, 0.0609, 0.0522, 0.0386, 0.1746, 0.2288, 0.0940, 0.0550,
        0.1079], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,464][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0024, 0.0156, 0.0154, 0.0205, 0.0563, 0.0566, 0.0097, 0.0120, 0.0194,
        0.0041, 0.0148, 0.0251, 0.0529, 0.0073, 0.1127, 0.4529, 0.0631, 0.0212,
        0.0381], device='cuda:0') for source tokens [Then, Thomas and Cody had a lot of fun at the station. Thomas gave a kiss to]
[2024-07-24 10:18:59,465][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:18:59,467][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12227],
        [    8],
        [   40],
        [    9],
        [   38],
        [    1],
        [    1],
        [    7],
        [    1],
        [   34],
        [    5],
        [    2],
        [   19],
        [    5],
        [   87],
        [   25],
        [    2],
        [   16],
        [    1]], device='cuda:0')
[2024-07-24 10:18:59,469][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12516],
        [   13],
        [   31],
        [    7],
        [   58],
        [    3],
        [    1],
        [   21],
        [    2],
        [   58],
        [   10],
        [    2],
        [   24],
        [    4],
        [   81],
        [   36],
        [    7],
        [   15],
        [    3]], device='cuda:0')
[2024-07-24 10:18:59,471][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30260],
        [10890],
        [ 7867],
        [ 9598],
        [ 6700],
        [ 8801],
        [ 8719],
        [11574],
        [13064],
        [12038],
        [13763],
        [11507],
        [11186],
        [11953],
        [10584],
        [12281],
        [12471],
        [12547],
        [12549]], device='cuda:0')
[2024-07-24 10:18:59,472][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 2254],
        [ 4077],
        [ 8882],
        [11971],
        [23910],
        [14308],
        [18030],
        [17462],
        [16476],
        [13938],
        [16809],
        [20893],
        [20124],
        [22925],
        [24745],
        [16802],
        [14745],
        [14543],
        [16227]], device='cuda:0')
[2024-07-24 10:18:59,474][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3255],
        [18188],
        [40888],
        [43371],
        [49611],
        [49583],
        [49602],
        [49058],
        [48784],
        [46699],
        [46950],
        [47927],
        [47154],
        [47674],
        [47497],
        [48229],
        [48267],
        [48716],
        [48625]], device='cuda:0')
[2024-07-24 10:18:59,475][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[46854],
        [41639],
        [36323],
        [35500],
        [12364],
        [14350],
        [17253],
        [19956],
        [21079],
        [22134],
        [20350],
        [20744],
        [26624],
        [26702],
        [27520],
        [26723],
        [27032],
        [26685],
        [26050]], device='cuda:0')
[2024-07-24 10:18:59,476][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15496],
        [14439],
        [15899],
        [17071],
        [22802],
        [14145],
        [15419],
        [20247],
        [19840],
        [16716],
        [15763],
        [23409],
        [18214],
        [19102],
        [16889],
        [12433],
        [12450],
        [11391],
        [11615]], device='cuda:0')
[2024-07-24 10:18:59,477][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[27330],
        [ 1425],
        [  864],
        [  867],
        [  675],
        [  691],
        [  773],
        [  762],
        [  809],
        [  718],
        [  761],
        [  888],
        [  887],
        [ 1029],
        [ 1048],
        [ 1034],
        [ 1113],
        [ 1109],
        [ 1219]], device='cuda:0')
[2024-07-24 10:18:59,478][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35965],
        [42016],
        [37823],
        [39085],
        [25264],
        [29961],
        [31439],
        [32101],
        [31490],
        [30725],
        [32299],
        [32960],
        [36596],
        [35788],
        [36178],
        [36179],
        [36074],
        [37387],
        [38314]], device='cuda:0')
[2024-07-24 10:18:59,480][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[47881],
        [17147],
        [17705],
        [18201],
        [12637],
        [12607],
        [11882],
        [13641],
        [13656],
        [12098],
        [12688],
        [11240],
        [10305],
        [10987],
        [10430],
        [10980],
        [11830],
        [12174],
        [13035]], device='cuda:0')
[2024-07-24 10:18:59,482][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21513],
        [36763],
        [44639],
        [45080],
        [45332],
        [43629],
        [42263],
        [37495],
        [42739],
        [22916],
        [36981],
        [42245],
        [39748],
        [37506],
        [22990],
        [23605],
        [27056],
        [25853],
        [35049]], device='cuda:0')
[2024-07-24 10:18:59,483][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[13568],
        [27416],
        [30301],
        [29579],
        [ 4722],
        [ 6719],
        [ 8556],
        [ 9351],
        [12152],
        [ 8621],
        [11580],
        [12790],
        [10873],
        [13807],
        [11465],
        [ 9825],
        [12893],
        [16801],
        [18302]], device='cuda:0')
[2024-07-24 10:18:59,485][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[46186],
        [ 2051],
        [ 1725],
        [ 1649],
        [  266],
        [  328],
        [  429],
        [  614],
        [  675],
        [  615],
        [  617],
        [  655],
        [  589],
        [  678],
        [  649],
        [  668],
        [  730],
        [  695],
        [  719]], device='cuda:0')
[2024-07-24 10:18:59,487][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 6277],
        [15183],
        [12233],
        [13095],
        [ 7427],
        [ 5620],
        [ 4616],
        [ 5853],
        [ 4781],
        [ 6556],
        [ 5495],
        [ 5511],
        [ 7033],
        [ 5687],
        [ 6991],
        [ 6679],
        [ 6395],
        [ 6410],
        [ 6002]], device='cuda:0')
[2024-07-24 10:18:59,488][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16004],
        [10331],
        [14240],
        [ 7860],
        [ 6935],
        [ 8944],
        [ 8600],
        [ 2081],
        [ 5224],
        [ 2612],
        [ 5098],
        [ 4788],
        [ 4760],
        [10029],
        [14772],
        [ 8647],
        [ 6185],
        [ 4853],
        [ 5337]], device='cuda:0')
[2024-07-24 10:18:59,490][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16021],
        [11688],
        [19870],
        [14673],
        [18086],
        [15108],
        [15831],
        [18798],
        [17915],
        [17774],
        [18967],
        [17777],
        [20266],
        [20862],
        [24376],
        [25900],
        [26276],
        [26838],
        [26554]], device='cuda:0')
[2024-07-24 10:18:59,491][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26604],
        [41964],
        [40809],
        [41388],
        [38815],
        [31595],
        [30252],
        [29663],
        [33792],
        [33704],
        [33765],
        [33721],
        [30061],
        [30167],
        [32431],
        [34631],
        [35243],
        [36813],
        [37503]], device='cuda:0')
[2024-07-24 10:18:59,493][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[44197],
        [42140],
        [41513],
        [42634],
        [39179],
        [39080],
        [39167],
        [38981],
        [40791],
        [41251],
        [39791],
        [40072],
        [39409],
        [39346],
        [38332],
        [37691],
        [37639],
        [37119],
        [37814]], device='cuda:0')
[2024-07-24 10:18:59,494][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14535],
        [19239],
        [21551],
        [18461],
        [21468],
        [18760],
        [18821],
        [19358],
        [18280],
        [18423],
        [18227],
        [18598],
        [17332],
        [17417],
        [20064],
        [21316],
        [21455],
        [21416],
        [21316]], device='cuda:0')
[2024-07-24 10:18:59,495][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19878],
        [17516],
        [18904],
        [19208],
        [19690],
        [16011],
        [17731],
        [17496],
        [17476],
        [17530],
        [16354],
        [16694],
        [16825],
        [17040],
        [16985],
        [17442],
        [18219],
        [17839],
        [17999]], device='cuda:0')
[2024-07-24 10:18:59,496][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28540],
        [14338],
        [14946],
        [16578],
        [17161],
        [16692],
        [16660],
        [15835],
        [16736],
        [17830],
        [18066],
        [17801],
        [17889],
        [17925],
        [17918],
        [17808],
        [18290],
        [18430],
        [18512]], device='cuda:0')
[2024-07-24 10:18:59,497][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 6538],
        [30471],
        [19157],
        [20946],
        [15021],
        [20642],
        [18408],
        [16511],
        [17140],
        [15613],
        [14809],
        [14717],
        [14629],
        [16059],
        [14032],
        [12854],
        [13643],
        [14193],
        [14577]], device='cuda:0')
[2024-07-24 10:18:59,499][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35726],
        [33149],
        [21137],
        [21788],
        [26559],
        [26268],
        [27467],
        [26484],
        [26903],
        [28536],
        [27473],
        [27619],
        [28674],
        [28710],
        [27154],
        [28565],
        [28872],
        [29280],
        [29878]], device='cuda:0')
[2024-07-24 10:18:59,501][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22389],
        [20739],
        [15195],
        [16077],
        [15134],
        [15860],
        [15889],
        [15758],
        [16182],
        [16246],
        [16130],
        [16105],
        [16221],
        [16321],
        [16313],
        [16310],
        [16331],
        [16424],
        [16496]], device='cuda:0')
[2024-07-24 10:18:59,502][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11381],
        [ 6028],
        [11461],
        [ 7949],
        [10523],
        [15377],
        [15293],
        [14871],
        [14422],
        [15307],
        [14555],
        [15389],
        [15572],
        [16412],
        [17019],
        [16737],
        [17356],
        [16153],
        [16818]], device='cuda:0')
[2024-07-24 10:18:59,504][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17459],
        [40783],
        [42899],
        [36077],
        [39939],
        [38701],
        [38365],
        [38194],
        [33677],
        [34381],
        [34831],
        [25935],
        [28835],
        [20726],
        [25330],
        [23370],
        [24499],
        [22815],
        [22066]], device='cuda:0')
[2024-07-24 10:18:59,506][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9706],
        [21713],
        [27440],
        [32988],
        [26803],
        [23607],
        [24104],
        [23849],
        [24878],
        [23153],
        [22879],
        [20644],
        [21286],
        [21800],
        [19954],
        [22644],
        [22133],
        [22364],
        [21984]], device='cuda:0')
[2024-07-24 10:18:59,507][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[27295],
        [21282],
        [21810],
        [22302],
        [22558],
        [24554],
        [24401],
        [25366],
        [24108],
        [23444],
        [24763],
        [26351],
        [26604],
        [27654],
        [25958],
        [24718],
        [23697],
        [23684],
        [23161]], device='cuda:0')
[2024-07-24 10:18:59,509][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34551],
        [38427],
        [35517],
        [39739],
        [41447],
        [39638],
        [39764],
        [43189],
        [41764],
        [43749],
        [42224],
        [42038],
        [41764],
        [37950],
        [37296],
        [39177],
        [40192],
        [43235],
        [42007]], device='cuda:0')
[2024-07-24 10:18:59,510][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410],
        [20410]], device='cuda:0')
