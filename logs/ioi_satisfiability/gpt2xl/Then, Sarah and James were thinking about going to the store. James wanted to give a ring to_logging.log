[2024-07-24 10:16:44,296][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Sarah and James were thinking about going to the store. James wanted to give a ring to
[2024-07-24 10:16:44,296][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Sarah
[2024-07-24 10:16:44,297][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:16:44,297][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:16:44,297][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:16:44,297][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,298][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:16:44,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,298][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:16:44,298][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit26']
[2024-07-24 10:16:44,299][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:16:44,299][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,299][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:16:44,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:44,300][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:16:44,300][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,300][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:16:44,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,301][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:16:44,301][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:16:44,301][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:16:44,302][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:16:44,303][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2']
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:16:44,304][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:16:44,305][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,306][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:16:44,307][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit13', 'circuit16']
[2024-07-24 10:16:44,308][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:16:44,309][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit25']
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20']
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,310][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:16:44,311][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit8']
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,312][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit13']
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:16:44,313][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,314][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,315][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22']
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,316][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit24']
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,317][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:16:44,318][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21']
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:16:44,319][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,320][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,321][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,322][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,323][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:16:44,324][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:16:44,325][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:16:44,326][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,327][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,328][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,329][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,330][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,331][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,332][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,333][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,334][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,335][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit20', 'circuit26']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit27']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit16']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15']
[2024-07-24 10:16:44,336][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,337][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,338][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:16:44,339][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit26']
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:16:44,340][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,341][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit26']
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,342][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,343][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,344][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8']
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit20']
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit16', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:16:44,345][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit27']
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,346][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,347][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,348][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,349][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:16:44,350][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,351][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,352][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:16:44,353][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:16:44,354][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit26']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,355][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit26']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,356][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:16:44,357][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit28']
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit26']
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,358][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:44,359][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,360][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:16:44,361][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:16:44,362][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21']
[2024-07-24 10:16:44,363][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,364][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:16:44,365][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,366][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit5']
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit22']
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,367][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,368][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:16:44,369][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:16:44,370][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,371][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,372][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,373][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7']
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,375][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,376][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,377][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,378][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit11']
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit26']
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,379][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit22', 'circuit25']
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,380][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,381][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit26']
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,382][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit14', 'circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,383][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:16:44,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit10', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:16:44,385][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17']
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:16:44,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:16:44,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit26']
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit26']
[2024-07-24 10:16:44,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,390][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,391][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,392][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,393][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,394][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,395][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,396][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,397][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,398][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:16:44,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:16:44,400][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,403][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,404][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,405][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:16:44,406][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:16:44,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8']
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,408][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,409][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,410][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,411][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:16:44,412][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit27']
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:16:44,413][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,414][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,415][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,416][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,417][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:44,418][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,419][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:16:44,420][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:16:44,421][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,422][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,423][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,424][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,425][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,426][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,427][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,428][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,429][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,431][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,432][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,433][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:16:44,434][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,435][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,436][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,437][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,438][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,439][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,440][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,441][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,442][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,443][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,444][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,445][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:16:44,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,447][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,448][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,449][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit2']
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:16:44,450][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit27']
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,451][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9']
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit9']
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23']
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:16:44,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,453][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,454][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,455][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,456][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:16:44,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,459][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,460][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,461][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,462][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:16:44,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,465][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,466][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,467][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,468][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:16:44,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,470][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,471][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,472][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:16:44,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,474][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,475][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,476][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:16:44,477][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,478][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,479][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,480][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:16:44,481][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,482][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,483][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,484][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit21']
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:16:44,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,486][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,487][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit26']
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,488][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,489][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,490][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,491][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,492][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,493][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,494][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,495][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,497][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,498][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,499][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,500][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,501][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,502][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,503][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,505][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,506][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,507][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:16:44,508][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,509][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,510][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit15', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit17', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,511][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,512][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,513][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,514][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,515][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,516][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,518][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,519][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,520][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,521][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,522][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit19', 'circuit20']
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,523][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,524][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,525][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,526][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,527][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,528][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,529][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,530][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,531][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,532][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,533][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,534][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,535][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:16:44,536][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,537][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,538][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:16:44,539][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,540][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,541][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:16:44,542][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,543][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,544][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,545][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,546][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,547][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,548][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,549][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,550][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:16:44,551][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,552][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23']
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:16:44,553][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit13', 'circuit21', 'circuit26']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,554][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,555][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,556][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,557][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,558][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:16:44,559][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,560][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,561][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,562][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,563][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,565][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,566][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:16:44,567][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16']
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,568][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,569][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,570][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,571][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,573][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,574][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14', 'circuit18', 'circuit22']
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:16:44,575][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,576][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,577][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,578][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,579][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:16:44,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,581][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,582][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,583][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,584][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,586][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,587][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:16:44,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,589][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,590][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,591][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,592][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:16:44,593][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:16:44,594][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,596][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,597][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,599][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,600][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:44,600][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:16:46,281][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:46,287][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,287][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,288][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,291][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,294][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,298][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,298][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,299][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,300][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,300][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,301][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,303][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,309][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,311][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,312][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,313][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,313][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,314][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,318][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,324][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,324][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,325][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,326][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,327][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,327][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.3700, 0.4246, 0.2054], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,329][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([7.8483e-05, 1.6108e-04, 9.9976e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,337][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.5669, 0.2434, 0.1897], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,338][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([3.8862e-02, 5.9965e-04, 9.6054e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,338][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0315, 0.0039, 0.9645], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,339][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([8.5224e-03, 4.2562e-06, 9.9147e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,340][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.4668, 0.2322, 0.3011], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,340][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.4708, 0.4025, 0.1268], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,345][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.4420, 0.3215, 0.2365], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,350][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.6468, 0.3179, 0.0353], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,351][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.3892, 0.2718, 0.3390], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,351][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.5006, 0.3411, 0.1583], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,352][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6909, 0.0783, 0.1697, 0.0610], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,353][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3020e-03, 3.9238e-02, 7.2293e-04, 9.5774e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,354][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2338, 0.1750, 0.0526, 0.5386], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,360][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1096, 0.3746, 0.0576, 0.4582], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,363][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3388, 0.1535, 0.2298, 0.2780], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,364][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1228, 0.1966, 0.0091, 0.6715], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,364][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6810, 0.0326, 0.2618, 0.0247], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,365][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2434, 0.1851, 0.2928, 0.2787], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,366][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0667, 0.4669, 0.0286, 0.4378], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,368][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4315, 0.2410, 0.1037, 0.2238], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,376][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4142, 0.3085, 0.0738, 0.2035], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,377][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4657, 0.2034, 0.0652, 0.2657], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,377][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.2792, 0.1894, 0.1422, 0.1027, 0.2865], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,378][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ James] are: tensor([3.3434e-04, 1.1669e-04, 3.7649e-04, 1.2579e-04, 9.9905e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,379][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.4274, 0.2094, 0.1603, 0.0912, 0.1118], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,380][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ James] are: tensor([4.6974e-03, 1.1912e-04, 1.9576e-03, 5.0978e-04, 9.9272e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,386][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0553, 0.0179, 0.0997, 0.0273, 0.7998], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,389][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ James] are: tensor([2.6504e-02, 5.2225e-05, 4.8449e-04, 7.0580e-06, 9.7295e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,390][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.2997, 0.1326, 0.3290, 0.0628, 0.1759], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,390][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.2265, 0.1591, 0.1222, 0.3907, 0.1015], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,391][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.2170, 0.2085, 0.1645, 0.1510, 0.2590], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,392][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.3723, 0.2265, 0.1823, 0.1854, 0.0335], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,394][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.3135, 0.1933, 0.0778, 0.1213, 0.2941], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,402][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.3899, 0.1675, 0.0850, 0.2095, 0.1481], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,403][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.4223, 0.0410, 0.0621, 0.0379, 0.0648, 0.3719], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,403][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ were] are: tensor([1.2374e-03, 8.2990e-03, 8.3548e-03, 7.9439e-03, 5.0690e-04, 9.7366e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,404][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.3978, 0.1337, 0.0920, 0.1394, 0.0835, 0.1536], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,405][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0321, 0.0155, 0.0059, 0.0293, 0.0142, 0.9031], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,408][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3282, 0.0659, 0.0478, 0.1050, 0.1120, 0.3411], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,412][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ were] are: tensor([4.4479e-02, 3.7331e-03, 1.4048e-03, 1.0998e-03, 1.9773e-04, 9.4909e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,415][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.2790, 0.0406, 0.3545, 0.0393, 0.2535, 0.0331], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,416][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1178, 0.0956, 0.0988, 0.1808, 0.3108, 0.1962], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,417][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0882, 0.2938, 0.0271, 0.3655, 0.0242, 0.2012], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,417][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.3128, 0.1779, 0.0907, 0.1834, 0.1017, 0.1336], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,418][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2528, 0.1922, 0.0753, 0.1495, 0.0500, 0.2801], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,421][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.3635, 0.1793, 0.0556, 0.2034, 0.0698, 0.1284], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,428][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.2774, 0.0600, 0.1216, 0.0741, 0.2161, 0.1442, 0.1066],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,429][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([1.0312e-04, 2.0813e-04, 3.5007e-04, 1.2234e-04, 2.7811e-04, 8.1595e-05,
        9.9886e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,430][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.3468, 0.1508, 0.0689, 0.1712, 0.0681, 0.1386, 0.0555],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,431][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([1.8102e-03, 4.1794e-05, 3.0292e-04, 1.1039e-04, 9.6225e-05, 2.6038e-04,
        9.9738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,431][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0735, 0.0099, 0.0183, 0.0108, 0.0086, 0.0320, 0.8470],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,433][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([6.1933e-03, 1.4063e-05, 4.6282e-05, 2.5017e-06, 1.5658e-04, 7.5419e-07,
        9.9359e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,439][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.2802, 0.0613, 0.2113, 0.0417, 0.1458, 0.0282, 0.2315],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,444][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1130, 0.0873, 0.0425, 0.1190, 0.3058, 0.2099, 0.1224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,445][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2156, 0.1986, 0.0532, 0.2241, 0.0907, 0.1717, 0.0461],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,446][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.2879, 0.1630, 0.0996, 0.1474, 0.0964, 0.1318, 0.0738],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,446][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.2535, 0.1649, 0.0515, 0.1158, 0.0492, 0.0768, 0.2883],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,447][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.3460, 0.1918, 0.0436, 0.2041, 0.0564, 0.0579, 0.1003],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,452][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.3133, 0.0735, 0.2039, 0.0488, 0.1290, 0.0930, 0.1092, 0.0292],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,455][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ about] are: tensor([1.2849e-03, 2.7251e-03, 1.1808e-03, 5.2378e-03, 1.0934e-03, 3.0876e-04,
        2.2905e-03, 9.8588e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,457][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.2781, 0.1526, 0.0337, 0.1363, 0.0644, 0.1403, 0.1085, 0.0861],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,458][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ about] are: tensor([1.3371e-03, 8.0087e-04, 2.8840e-03, 2.1648e-03, 6.3449e-04, 9.3775e-03,
        7.3547e-01, 2.4733e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,459][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0774, 0.0139, 0.0182, 0.0169, 0.0169, 0.0667, 0.6928, 0.0972],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,460][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ about] are: tensor([3.1328e-02, 6.3521e-03, 1.6143e-03, 3.2795e-03, 6.3329e-04, 1.5876e-03,
        2.9248e-03, 9.5228e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,460][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.2718, 0.0235, 0.1786, 0.0209, 0.1683, 0.0417, 0.2487, 0.0465],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,465][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0885, 0.0485, 0.0721, 0.0897, 0.1301, 0.1692, 0.2015, 0.2004],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,470][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0693, 0.2075, 0.0221, 0.3320, 0.0259, 0.1865, 0.0408, 0.1160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,471][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.2253, 0.1517, 0.0730, 0.1513, 0.0736, 0.1197, 0.0801, 0.1252],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,472][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.2198, 0.1513, 0.0593, 0.1351, 0.0661, 0.0730, 0.0581, 0.2373],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,472][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.3045, 0.1218, 0.0374, 0.1792, 0.0549, 0.0835, 0.0724, 0.1463],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,473][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.2533, 0.0587, 0.1153, 0.0539, 0.0939, 0.1042, 0.1635, 0.0754, 0.0819],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,475][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ going] are: tensor([7.2437e-04, 4.5709e-04, 1.2680e-03, 3.5411e-04, 1.9785e-04, 3.7575e-04,
        3.6157e-03, 5.6256e-03, 9.8738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,482][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.2673, 0.0878, 0.0275, 0.1464, 0.0985, 0.0875, 0.1185, 0.1205, 0.0461],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,483][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ going] are: tensor([1.4781e-02, 8.0695e-04, 7.5287e-04, 1.4388e-03, 1.0352e-03, 2.3865e-02,
        3.8336e-02, 4.4590e-02, 8.7439e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,484][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0916, 0.0249, 0.0172, 0.0379, 0.0238, 0.0719, 0.1707, 0.1067, 0.4552],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,485][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ going] are: tensor([6.8381e-02, 2.0060e-04, 8.2067e-04, 9.2468e-05, 5.3474e-04, 1.2304e-04,
        4.9469e-03, 4.7046e-04, 9.2443e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,486][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1797, 0.0302, 0.2262, 0.0227, 0.2048, 0.0263, 0.2013, 0.0444, 0.0644],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,487][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0816, 0.0303, 0.0103, 0.0744, 0.0366, 0.1106, 0.1270, 0.3598, 0.1694],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,492][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1031, 0.1484, 0.0313, 0.2285, 0.0296, 0.2192, 0.0396, 0.1420, 0.0583],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,496][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.2150, 0.1302, 0.0665, 0.1275, 0.0761, 0.1093, 0.0786, 0.1207, 0.0760],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,497][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.1742, 0.1142, 0.0629, 0.1087, 0.0443, 0.0759, 0.0808, 0.0981, 0.2410],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,498][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.2779, 0.0857, 0.0527, 0.1007, 0.0488, 0.0613, 0.1040, 0.1762, 0.0927],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,499][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3602, 0.0413, 0.0620, 0.0343, 0.0820, 0.1178, 0.1274, 0.0393, 0.1130,
        0.0227], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,499][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.3159e-03, 1.7471e-02, 2.9676e-04, 4.6861e-02, 1.2862e-04, 3.1138e-04,
        3.1295e-04, 3.9352e-02, 3.5659e-03, 8.8738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,504][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1880, 0.0940, 0.0257, 0.1145, 0.0307, 0.0785, 0.0826, 0.1179, 0.0890,
        0.1792], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,508][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.2098e-02, 2.8863e-03, 4.1519e-04, 3.2888e-03, 7.2053e-04, 2.3908e-02,
        5.6206e-03, 9.9285e-02, 1.3474e-01, 7.1703e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,510][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0339, 0.0030, 0.0013, 0.0057, 0.0049, 0.0463, 0.0828, 0.0404, 0.6851,
        0.0968], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,510][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0684, 0.0837, 0.0041, 0.0969, 0.0041, 0.0208, 0.0226, 0.0812, 0.0460,
        0.5722], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,511][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1881, 0.0111, 0.0812, 0.0090, 0.0522, 0.0328, 0.1192, 0.0618, 0.0960,
        0.3488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,512][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0483, 0.0164, 0.0269, 0.0328, 0.0349, 0.0548, 0.1069, 0.1340, 0.2806,
        0.2645], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,513][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0180, 0.1417, 0.0086, 0.2296, 0.0067, 0.1119, 0.0138, 0.0550, 0.0297,
        0.3849], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,518][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1750, 0.1137, 0.0554, 0.1205, 0.0659, 0.0882, 0.0657, 0.1111, 0.0750,
        0.1294], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,522][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1617, 0.1424, 0.0551, 0.1479, 0.0506, 0.0836, 0.0487, 0.0908, 0.0810,
        0.1382], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,523][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2424, 0.0988, 0.0422, 0.1058, 0.0544, 0.0822, 0.0750, 0.1106, 0.0773,
        0.1113], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:46,524][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3936, 0.0350, 0.1066, 0.0227, 0.1176, 0.0394, 0.1242, 0.0346, 0.0885,
        0.0147, 0.0231], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,525][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([3.2687e-03, 2.1466e-02, 4.2376e-04, 4.5966e-02, 2.1048e-03, 9.9004e-04,
        6.9717e-05, 1.6263e-02, 5.7571e-04, 6.9949e-02, 8.3892e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,526][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1659, 0.0830, 0.0234, 0.0918, 0.0265, 0.1171, 0.0509, 0.1326, 0.0843,
        0.1977, 0.0269], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,531][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0135, 0.0025, 0.0016, 0.0032, 0.0025, 0.0207, 0.0212, 0.0407, 0.0668,
        0.1785, 0.6488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,535][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1221, 0.0146, 0.0104, 0.0202, 0.0233, 0.0932, 0.0971, 0.0697, 0.2047,
        0.1639, 0.1807], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,536][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0813, 0.1207, 0.0121, 0.0960, 0.0157, 0.0790, 0.0115, 0.0876, 0.0703,
        0.0852, 0.3404], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,537][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2626, 0.0047, 0.2564, 0.0044, 0.1698, 0.0266, 0.1608, 0.0245, 0.0781,
        0.0092, 0.0030], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,538][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0457, 0.0126, 0.0110, 0.0256, 0.0186, 0.0362, 0.0654, 0.0950, 0.1395,
        0.2352, 0.3152], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,539][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0108, 0.0929, 0.0052, 0.1470, 0.0070, 0.1000, 0.0078, 0.0308, 0.0219,
        0.1755, 0.4011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,544][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1749, 0.0995, 0.0537, 0.1026, 0.0605, 0.0790, 0.0596, 0.1017, 0.0658,
        0.1098, 0.0930], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,548][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1807, 0.1119, 0.0606, 0.1085, 0.0730, 0.0570, 0.0420, 0.0821, 0.0548,
        0.0828, 0.1465], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,549][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2089, 0.0852, 0.0424, 0.0907, 0.0527, 0.0679, 0.0883, 0.0953, 0.0819,
        0.0881, 0.0985], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:46,550][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1715, 0.0783, 0.0694, 0.0701, 0.0614, 0.0667, 0.2436, 0.0172, 0.0823,
        0.0514, 0.0695, 0.0188], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,551][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ store] are: tensor([9.8317e-04, 2.3743e-03, 1.1143e-03, 1.8415e-03, 8.4782e-04, 8.1261e-04,
        4.4930e-04, 9.0210e-04, 8.2237e-04, 7.5195e-04, 1.0302e-03, 9.8807e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,552][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1936, 0.0680, 0.1215, 0.0589, 0.0957, 0.0818, 0.0614, 0.0588, 0.0690,
        0.0613, 0.0663, 0.0636], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,554][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ store] are: tensor([3.3241e-04, 1.0377e-06, 1.2880e-06, 3.0536e-06, 1.1932e-04, 2.5213e-05,
        4.6790e-04, 6.7456e-05, 5.2744e-04, 6.0019e-04, 3.6073e-04, 9.9749e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,561][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0398, 0.0026, 0.0035, 0.0046, 0.0028, 0.0034, 0.0067, 0.0064, 0.0383,
        0.0151, 0.0269, 0.8498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,562][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ store] are: tensor([1.1383e-02, 3.9178e-05, 5.6043e-05, 6.7550e-06, 4.0568e-05, 2.5577e-06,
        8.1834e-06, 8.8087e-06, 6.0308e-06, 6.0253e-07, 1.9439e-06, 9.8845e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,563][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2624, 0.0543, 0.1308, 0.0338, 0.1922, 0.0202, 0.0532, 0.0218, 0.0309,
        0.0173, 0.0224, 0.1607], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,564][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0469, 0.0090, 0.0015, 0.0274, 0.0045, 0.0324, 0.0383, 0.1189, 0.1275,
        0.2014, 0.3048, 0.0875], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,565][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1435, 0.0994, 0.0559, 0.1141, 0.0465, 0.0690, 0.0811, 0.0660, 0.0745,
        0.0977, 0.1006, 0.0515], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,570][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1889, 0.1003, 0.0727, 0.0935, 0.0555, 0.0767, 0.0767, 0.0866, 0.0593,
        0.0834, 0.0890, 0.0175], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,574][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1266, 0.0898, 0.0429, 0.0912, 0.0362, 0.0556, 0.0434, 0.0771, 0.0485,
        0.0708, 0.0685, 0.2492], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,575][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.2638, 0.0960, 0.0343, 0.0674, 0.0509, 0.0524, 0.0640, 0.1053, 0.0942,
        0.0706, 0.0282, 0.0731], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:46,576][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4455, 0.0144, 0.0572, 0.0119, 0.0661, 0.0481, 0.1167, 0.0221, 0.0998,
        0.0097, 0.0378, 0.0604, 0.0103], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,577][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.1879e-03, 3.5193e-02, 6.2127e-04, 6.5405e-03, 1.2928e-04, 2.6342e-04,
        1.3579e-03, 2.7273e-03, 9.8722e-04, 4.1142e-03, 2.9267e-04, 5.1283e-05,
        9.4453e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,578][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3560, 0.0466, 0.0287, 0.0387, 0.0371, 0.1781, 0.0717, 0.0543, 0.0617,
        0.0450, 0.0216, 0.0143, 0.0462], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,583][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0164, 0.0022, 0.0012, 0.0024, 0.0017, 0.0116, 0.0079, 0.0188, 0.0384,
        0.0752, 0.1765, 0.1359, 0.5117], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,587][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0348, 0.0117, 0.0068, 0.0224, 0.0098, 0.0224, 0.0264, 0.0354, 0.0865,
        0.1025, 0.1063, 0.2208, 0.3142], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,588][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1084, 0.1752, 0.0293, 0.1102, 0.0225, 0.0810, 0.0299, 0.0461, 0.0250,
        0.0610, 0.0665, 0.0126, 0.2323], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,589][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.3046, 0.0079, 0.1392, 0.0058, 0.1183, 0.0225, 0.1544, 0.0286, 0.0399,
        0.0106, 0.0051, 0.1593, 0.0038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,590][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0227, 0.0058, 0.0056, 0.0113, 0.0101, 0.0153, 0.0167, 0.0320, 0.0553,
        0.0721, 0.1447, 0.1907, 0.4179], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,591][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0161, 0.1423, 0.0060, 0.1131, 0.0055, 0.0274, 0.0068, 0.0198, 0.0098,
        0.1042, 0.1417, 0.0078, 0.3997], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,595][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1520, 0.0854, 0.0544, 0.0880, 0.0569, 0.0700, 0.0592, 0.0790, 0.0646,
        0.0851, 0.0743, 0.0405, 0.0906], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,600][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1173, 0.1002, 0.0525, 0.1055, 0.0491, 0.0800, 0.0555, 0.0705, 0.0567,
        0.0903, 0.0628, 0.0288, 0.1307], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,601][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2276, 0.0805, 0.0359, 0.0760, 0.0455, 0.0547, 0.0639, 0.0870, 0.0680,
        0.0663, 0.0374, 0.0529, 0.1042], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:46,602][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.1526, 0.0761, 0.0677, 0.0432, 0.1605, 0.0200, 0.0604, 0.0241, 0.0403,
        0.0373, 0.0430, 0.0459, 0.0303, 0.1986], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,603][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ James] are: tensor([1.5866e-04, 2.2826e-05, 8.1254e-05, 3.0196e-05, 5.1073e-01, 7.3298e-06,
        2.3676e-05, 2.4615e-04, 7.4647e-05, 3.3376e-05, 7.7072e-05, 5.9719e-06,
        3.7141e-06, 4.8850e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,603][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.1999, 0.0829, 0.0859, 0.0476, 0.0795, 0.0445, 0.0801, 0.0644, 0.0472,
        0.0421, 0.0638, 0.0256, 0.0591, 0.0774], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,606][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ James] are: tensor([1.7801e-04, 4.0375e-07, 3.7830e-06, 6.9263e-07, 1.6735e-03, 6.5452e-06,
        1.7440e-05, 1.1360e-05, 5.7022e-05, 7.9640e-05, 1.5809e-04, 3.4397e-03,
        1.4702e-04, 9.9423e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,613][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0072, 0.0015, 0.0054, 0.0019, 0.0471, 0.0010, 0.0018, 0.0017, 0.0089,
        0.0091, 0.0064, 0.0158, 0.0271, 0.8652], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,614][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ James] are: tensor([4.3490e-03, 7.3272e-06, 1.1084e-04, 1.0260e-06, 5.9963e-01, 6.1421e-07,
        2.2266e-05, 1.1401e-06, 4.2606e-06, 2.0448e-07, 3.6954e-07, 2.0465e-06,
        2.3701e-07, 3.9587e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,615][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.1605, 0.0615, 0.2557, 0.0334, 0.1217, 0.0132, 0.0406, 0.0128, 0.0258,
        0.0148, 0.0320, 0.0630, 0.0338, 0.1312], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,615][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0496, 0.0114, 0.0089, 0.0223, 0.0050, 0.0290, 0.0109, 0.0384, 0.0597,
        0.1011, 0.1512, 0.0195, 0.3898, 0.1032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,616][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0858, 0.0752, 0.0758, 0.0639, 0.1504, 0.0292, 0.0275, 0.0339, 0.0366,
        0.0550, 0.0782, 0.0249, 0.0728, 0.1910], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,621][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.1582, 0.0990, 0.1037, 0.0865, 0.0172, 0.0672, 0.0452, 0.0700, 0.0601,
        0.0737, 0.0881, 0.0318, 0.0825, 0.0168], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,626][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0990, 0.0622, 0.0447, 0.0587, 0.2390, 0.0299, 0.0227, 0.0474, 0.0271,
        0.0440, 0.0539, 0.0131, 0.0413, 0.2170], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,627][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.1330, 0.0535, 0.0323, 0.0578, 0.0511, 0.1078, 0.0838, 0.0850, 0.0736,
        0.0551, 0.0401, 0.0829, 0.0759, 0.0682], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:46,627][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.1941, 0.0229, 0.0515, 0.0229, 0.0680, 0.2249, 0.0781, 0.0136, 0.0396,
        0.0128, 0.0187, 0.0345, 0.0145, 0.0884, 0.1153], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,628][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([7.6149e-05, 3.4625e-05, 1.1764e-04, 6.3678e-05, 2.0642e-04, 8.6301e-04,
        2.2765e-02, 1.5237e-04, 2.5745e-03, 4.9057e-05, 1.5941e-05, 1.5952e-05,
        1.4166e-05, 1.2821e-04, 9.7292e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,629][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1781, 0.0380, 0.0282, 0.0521, 0.0409, 0.0560, 0.1299, 0.0628, 0.0719,
        0.0697, 0.0623, 0.0451, 0.0868, 0.0394, 0.0387], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,633][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([9.0810e-04, 1.2129e-05, 1.3217e-05, 1.2117e-05, 1.0464e-05, 9.5669e-05,
        8.3175e-04, 1.7554e-04, 6.1610e-04, 1.9287e-04, 3.7794e-04, 1.8548e-03,
        1.0505e-03, 2.0600e-03, 9.9179e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,638][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0285, 0.0044, 0.0032, 0.0048, 0.0037, 0.0124, 0.0184, 0.0096, 0.0351,
        0.0193, 0.0183, 0.0322, 0.0584, 0.0573, 0.6944], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,639][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([3.5765e-02, 6.2828e-05, 5.6376e-04, 3.5108e-05, 8.4311e-04, 3.0203e-04,
        3.3040e-03, 9.1484e-05, 1.1626e-03, 1.5454e-05, 7.0737e-06, 1.1396e-05,
        4.7841e-06, 2.7295e-04, 9.5756e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,640][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.1024, 0.0229, 0.1665, 0.0149, 0.1569, 0.0116, 0.1031, 0.0223, 0.0346,
        0.0088, 0.0153, 0.0756, 0.0221, 0.1984, 0.0445], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,641][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0176, 0.0043, 0.0075, 0.0086, 0.0028, 0.0096, 0.0164, 0.0199, 0.0299,
        0.0549, 0.0829, 0.0371, 0.4082, 0.1069, 0.1933], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,642][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.1001, 0.0759, 0.0210, 0.1135, 0.0306, 0.0676, 0.0385, 0.0601, 0.0433,
        0.1126, 0.0896, 0.0632, 0.1050, 0.0383, 0.0408], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,649][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.1266, 0.0685, 0.0515, 0.0697, 0.0484, 0.0616, 0.0639, 0.0765, 0.0579,
        0.0680, 0.0628, 0.0353, 0.0906, 0.0580, 0.0608], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,651][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0924, 0.0627, 0.0346, 0.0666, 0.0382, 0.0809, 0.0724, 0.0551, 0.0605,
        0.0602, 0.0505, 0.0235, 0.0621, 0.0336, 0.2066], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,652][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.2176, 0.0873, 0.0269, 0.0732, 0.0355, 0.0481, 0.0426, 0.0918, 0.0568,
        0.0633, 0.0280, 0.0430, 0.0944, 0.0354, 0.0561], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:46,653][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2271, 0.0211, 0.0330, 0.0179, 0.0464, 0.0670, 0.0720, 0.0211, 0.0621,
        0.0117, 0.0284, 0.0640, 0.0194, 0.0687, 0.2251, 0.0152],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,654][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3140e-03, 6.1151e-03, 9.9034e-05, 1.7722e-02, 4.8542e-05, 1.2764e-04,
        1.1954e-04, 1.7573e-02, 1.6666e-03, 4.3379e-01, 9.2491e-04, 4.0848e-05,
        3.7853e-03, 3.1432e-05, 5.2622e-05, 5.1559e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,657][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1065, 0.0463, 0.0142, 0.0649, 0.0187, 0.0481, 0.0510, 0.0716, 0.0541,
        0.1027, 0.0193, 0.0224, 0.1888, 0.0195, 0.0518, 0.1203],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,661][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.2326e-03, 2.4578e-04, 2.3825e-05, 1.4910e-04, 2.2207e-05, 5.9936e-04,
        1.3492e-04, 1.9311e-03, 2.4277e-03, 1.0807e-02, 1.5237e-02, 3.5095e-03,
        2.4922e-02, 4.5935e-03, 7.4044e-02, 8.5812e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,664][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3646e-02, 8.2185e-04, 2.6939e-04, 1.3110e-03, 8.0347e-04, 7.7912e-03,
        1.3992e-02, 5.5965e-03, 9.1003e-02, 1.1823e-02, 7.7274e-03, 1.0433e-02,
        1.2594e-02, 1.2675e-02, 6.8939e-01, 1.2013e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,665][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0287, 0.0390, 0.0020, 0.0511, 0.0025, 0.0125, 0.0110, 0.0484, 0.0298,
        0.3310, 0.1247, 0.0014, 0.0147, 0.0011, 0.0277, 0.2744],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,666][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0927, 0.0044, 0.0410, 0.0038, 0.0255, 0.0150, 0.0604, 0.0304, 0.0479,
        0.1761, 0.0031, 0.0595, 0.0050, 0.0437, 0.1211, 0.2704],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,667][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0191, 0.0034, 0.0046, 0.0051, 0.0039, 0.0054, 0.0104, 0.0108, 0.0221,
        0.0175, 0.0426, 0.0452, 0.2069, 0.1159, 0.2160, 0.2712],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,669][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0073, 0.0538, 0.0035, 0.0941, 0.0028, 0.0462, 0.0060, 0.0214, 0.0118,
        0.1507, 0.1950, 0.0084, 0.1521, 0.0043, 0.0155, 0.2271],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,677][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1083, 0.0668, 0.0359, 0.0741, 0.0442, 0.0553, 0.0444, 0.0676, 0.0482,
        0.0773, 0.0702, 0.0339, 0.0726, 0.0507, 0.0588, 0.0918],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,678][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0880, 0.0714, 0.0350, 0.0875, 0.0350, 0.0572, 0.0368, 0.0650, 0.0648,
        0.1018, 0.0715, 0.0275, 0.0737, 0.0323, 0.0482, 0.1043],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,678][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1787, 0.0709, 0.0322, 0.0712, 0.0384, 0.0571, 0.0493, 0.0703, 0.0538,
        0.0691, 0.0337, 0.0446, 0.0762, 0.0366, 0.0465, 0.0714],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:46,679][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.2068, 0.0203, 0.0373, 0.0213, 0.0325, 0.0372, 0.0816, 0.0354, 0.0933,
        0.0191, 0.0240, 0.0684, 0.0162, 0.0420, 0.1999, 0.0231, 0.0415],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,681][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.7640e-04, 4.5177e-04, 1.1801e-04, 3.7694e-04, 9.3848e-05, 1.5238e-04,
        2.3507e-03, 2.9230e-04, 2.1399e-03, 5.6518e-04, 1.8095e-04, 3.3762e-04,
        4.2976e-05, 5.9375e-05, 3.1954e-04, 5.0181e-04, 9.9174e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,687][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1207, 0.0321, 0.0182, 0.0423, 0.0186, 0.0699, 0.0747, 0.0799, 0.0681,
        0.0814, 0.0425, 0.0365, 0.0646, 0.0182, 0.0977, 0.0921, 0.0423],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,690][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ give] are: tensor([4.1106e-04, 3.0603e-06, 1.3487e-06, 3.2306e-06, 3.1051e-06, 1.2389e-05,
        6.0377e-05, 4.4930e-05, 9.1826e-05, 1.2106e-04, 2.0477e-04, 3.5748e-03,
        3.3589e-04, 8.1618e-04, 1.5189e-02, 8.3276e-03, 9.7080e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,691][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0282, 0.0036, 0.0072, 0.0043, 0.0080, 0.0094, 0.0120, 0.0048, 0.0153,
        0.0148, 0.0135, 0.0136, 0.0183, 0.0761, 0.1905, 0.1074, 0.4728],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,691][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ give] are: tensor([1.3152e-02, 5.7554e-05, 3.9815e-05, 2.8089e-05, 4.0744e-04, 3.7689e-05,
        3.9484e-04, 4.6907e-05, 1.6301e-04, 1.1253e-05, 1.6548e-05, 3.0309e-05,
        3.2562e-06, 1.4108e-04, 8.8122e-05, 6.6103e-06, 9.8538e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,692][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1457, 0.0148, 0.1215, 0.0133, 0.1054, 0.0171, 0.0899, 0.0226, 0.0368,
        0.0111, 0.0136, 0.1313, 0.0130, 0.1444, 0.0759, 0.0137, 0.0299],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,695][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0114, 0.0025, 0.0016, 0.0032, 0.0098, 0.0031, 0.0041, 0.0069, 0.0075,
        0.0166, 0.0241, 0.0197, 0.0980, 0.2334, 0.1499, 0.2369, 0.1713],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,702][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0520, 0.0535, 0.0276, 0.0816, 0.0115, 0.0799, 0.0240, 0.0532, 0.0335,
        0.1093, 0.0844, 0.0534, 0.0711, 0.0148, 0.0647, 0.1453, 0.0402],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,703][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1009, 0.0555, 0.0293, 0.0615, 0.0346, 0.0607, 0.0515, 0.0606, 0.0496,
        0.0681, 0.0565, 0.0427, 0.0773, 0.0412, 0.0779, 0.0828, 0.0494],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,704][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0733, 0.0482, 0.0284, 0.0583, 0.0271, 0.0483, 0.0470, 0.0401, 0.0595,
        0.0709, 0.0526, 0.0333, 0.0630, 0.0288, 0.0549, 0.0770, 0.1894],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,705][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.2413, 0.0673, 0.0254, 0.0789, 0.0305, 0.0339, 0.0428, 0.0749, 0.0569,
        0.0555, 0.0174, 0.0268, 0.0634, 0.0260, 0.0376, 0.0557, 0.0656],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:46,708][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2672, 0.0205, 0.0519, 0.0159, 0.0408, 0.0237, 0.0816, 0.0194, 0.0402,
        0.0128, 0.0240, 0.0924, 0.0181, 0.0588, 0.1028, 0.0169, 0.0914, 0.0218],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,713][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.2052e-04, 1.7492e-03, 4.7866e-04, 1.9186e-03, 6.1337e-04, 7.0285e-05,
        4.9436e-05, 1.1627e-02, 1.6701e-03, 6.4051e-03, 2.4450e-02, 9.1319e-05,
        4.6051e-04, 4.7143e-04, 6.0524e-05, 6.2405e-03, 9.3886e-04, 9.4198e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,715][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0813, 0.0408, 0.0132, 0.0623, 0.0212, 0.0495, 0.0374, 0.0686, 0.0582,
        0.1101, 0.0143, 0.0231, 0.1287, 0.0238, 0.0644, 0.1316, 0.0571, 0.0145],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,716][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.0440e-03, 1.9363e-04, 1.0364e-04, 1.1365e-04, 5.3316e-05, 2.4846e-04,
        3.1493e-04, 5.1568e-04, 4.8582e-04, 1.3023e-03, 5.1721e-03, 2.9580e-03,
        8.5401e-03, 6.4507e-03, 3.4362e-02, 6.5386e-02, 1.2902e-01, 7.4174e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,717][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0213, 0.0025, 0.0024, 0.0025, 0.0031, 0.0091, 0.0077, 0.0061, 0.0234,
        0.0095, 0.0101, 0.0164, 0.0123, 0.0312, 0.1886, 0.0739, 0.3751, 0.2046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,718][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0257, 0.0824, 0.0078, 0.0751, 0.0068, 0.0127, 0.0064, 0.0370, 0.0187,
        0.0653, 0.1742, 0.0038, 0.0219, 0.0027, 0.0062, 0.0486, 0.0096, 0.3949],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,723][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1207, 0.0027, 0.0951, 0.0026, 0.0684, 0.0171, 0.1020, 0.0175, 0.0476,
        0.0064, 0.0023, 0.1497, 0.0024, 0.1155, 0.1527, 0.0087, 0.0840, 0.0047],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,728][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0142, 0.0025, 0.0024, 0.0037, 0.0020, 0.0034, 0.0046, 0.0061, 0.0104,
        0.0104, 0.0182, 0.0162, 0.1029, 0.0422, 0.0825, 0.1463, 0.2339, 0.2979],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,729][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0340, 0.0027, 0.0603, 0.0033, 0.0428, 0.0054, 0.0162, 0.0109,
        0.0777, 0.1787, 0.0080, 0.0961, 0.0054, 0.0167, 0.1155, 0.0176, 0.3017],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,730][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0992, 0.0597, 0.0361, 0.0660, 0.0348, 0.0487, 0.0398, 0.0597, 0.0434,
        0.0686, 0.0596, 0.0297, 0.0639, 0.0397, 0.0500, 0.0824, 0.0509, 0.0678],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,731][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0716, 0.0547, 0.0398, 0.0657, 0.0322, 0.0334, 0.0284, 0.0678, 0.0477,
        0.0711, 0.0805, 0.0288, 0.0557, 0.0326, 0.0386, 0.0756, 0.0350, 0.1407],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,733][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1694, 0.0636, 0.0289, 0.0607, 0.0346, 0.0480, 0.0498, 0.0587, 0.0484,
        0.0643, 0.0339, 0.0437, 0.0666, 0.0320, 0.0389, 0.0660, 0.0475, 0.0451],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:46,739][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0905, 0.0459, 0.0280, 0.0332, 0.0968, 0.0234, 0.0692, 0.0253, 0.0156,
        0.0257, 0.0365, 0.0859, 0.0307, 0.1204, 0.0151, 0.0308, 0.0553, 0.0319,
        0.1398], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,741][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([6.7823e-05, 9.0268e-05, 1.0976e-04, 1.4709e-04, 2.7431e-04, 9.5625e-05,
        3.0094e-05, 3.5242e-05, 4.4275e-05, 1.9438e-05, 8.2231e-05, 7.6729e-05,
        2.3005e-06, 1.9046e-04, 2.0491e-05, 1.5793e-05, 3.9628e-05, 6.8173e-06,
        9.9865e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,742][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0869, 0.0343, 0.0210, 0.0607, 0.1238, 0.0242, 0.0216, 0.0878, 0.0390,
        0.0643, 0.0430, 0.0245, 0.0349, 0.1238, 0.0225, 0.0673, 0.0403, 0.0461,
        0.0340], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,743][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([2.5928e-04, 7.0957e-07, 4.7194e-06, 5.8033e-07, 4.0556e-06, 6.8153e-06,
        3.0657e-06, 6.1305e-06, 3.5754e-05, 1.0479e-05, 3.3937e-05, 4.0593e-04,
        5.5976e-05, 7.3779e-04, 1.1830e-03, 5.9403e-04, 1.8785e-03, 2.8612e-03,
        9.9192e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,744][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0292, 0.0025, 0.0027, 0.0018, 0.0041, 0.0018, 0.0039, 0.0017, 0.0069,
        0.0020, 0.0055, 0.0277, 0.0084, 0.0182, 0.0168, 0.0101, 0.0367, 0.0304,
        0.7893], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,746][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([2.5107e-03, 7.4246e-06, 6.4672e-05, 2.4574e-06, 3.0243e-05, 9.7073e-07,
        1.9263e-07, 3.3435e-07, 2.3075e-06, 2.0107e-07, 5.6848e-07, 1.7360e-06,
        1.1718e-07, 7.7609e-06, 7.0896e-07, 1.0373e-07, 9.2737e-08, 4.6066e-07,
        9.9737e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,752][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1068, 0.0388, 0.0897, 0.0243, 0.1527, 0.0125, 0.0452, 0.0159, 0.0191,
        0.0135, 0.0113, 0.1159, 0.0283, 0.1668, 0.0292, 0.0139, 0.0224, 0.0146,
        0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,754][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0251, 0.0097, 0.0016, 0.0080, 0.0045, 0.0053, 0.0027, 0.0101, 0.0058,
        0.0175, 0.0198, 0.0147, 0.0640, 0.0476, 0.1083, 0.1640, 0.1836, 0.2441,
        0.0635], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,755][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.1088, 0.0577, 0.0356, 0.0715, 0.0403, 0.0354, 0.0381, 0.0265, 0.0542,
        0.0594, 0.0483, 0.0211, 0.0555, 0.0438, 0.0502, 0.0691, 0.0405, 0.0806,
        0.0632], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,756][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0880, 0.0655, 0.0433, 0.0630, 0.0541, 0.0462, 0.0468, 0.0484, 0.0353,
        0.0623, 0.0572, 0.0416, 0.0628, 0.0603, 0.0390, 0.0725, 0.0384, 0.0707,
        0.0045], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,757][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0657, 0.0441, 0.0279, 0.0487, 0.0336, 0.0424, 0.0220, 0.0410, 0.0379,
        0.0567, 0.0472, 0.0272, 0.0472, 0.0374, 0.0348, 0.0616, 0.0272, 0.0502,
        0.2471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,762][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.1289, 0.0622, 0.0325, 0.0434, 0.0385, 0.0454, 0.0428, 0.0749, 0.0643,
        0.0436, 0.0226, 0.0469, 0.0383, 0.0358, 0.0591, 0.0455, 0.0745, 0.0323,
        0.0684], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:46,767][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1861, 0.0157, 0.0266, 0.0132, 0.0358, 0.0513, 0.0544, 0.0151, 0.0468,
        0.0084, 0.0207, 0.0477, 0.0141, 0.0517, 0.1665, 0.0108, 0.0694, 0.0235,
        0.1290, 0.0134], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,768][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5353e-03, 3.2720e-03, 5.0292e-05, 9.5139e-03, 2.7509e-05, 7.5052e-05,
        6.6820e-05, 1.0197e-02, 9.6836e-04, 2.5979e-01, 5.4315e-04, 2.5504e-05,
        2.5321e-03, 2.0135e-05, 3.4451e-05, 3.2994e-01, 2.5556e-04, 3.9130e-04,
        6.8134e-06, 3.8076e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,768][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0893, 0.0358, 0.0114, 0.0528, 0.0158, 0.0398, 0.0415, 0.0597, 0.0452,
        0.0835, 0.0156, 0.0187, 0.1534, 0.0167, 0.0424, 0.0985, 0.0429, 0.0151,
        0.0131, 0.1089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,769][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.2597e-04, 3.9283e-05, 3.3418e-06, 1.7487e-05, 2.0778e-06, 4.2010e-05,
        9.1864e-06, 1.0198e-04, 1.1342e-04, 4.1374e-04, 5.5751e-04, 1.5803e-04,
        9.9181e-04, 1.6819e-04, 2.5815e-03, 2.7723e-02, 2.3512e-01, 6.2993e-02,
        1.1633e-01, 5.5180e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,771][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.4791e-02, 7.9477e-04, 2.1193e-04, 1.1669e-03, 5.4989e-04, 4.9597e-03,
        8.4888e-03, 3.1630e-03, 4.4298e-02, 5.5717e-03, 3.4533e-03, 4.3434e-03,
        5.4109e-03, 4.7118e-03, 2.7895e-01, 4.8879e-02, 2.2484e-01, 7.2243e-02,
        4.0852e-02, 2.3232e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,778][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0181, 0.0262, 0.0014, 0.0364, 0.0020, 0.0101, 0.0080, 0.0362, 0.0237,
        0.2446, 0.0923, 0.0010, 0.0102, 0.0008, 0.0227, 0.2021, 0.0066, 0.0697,
        0.0013, 0.1865], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,779][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0615, 0.0027, 0.0275, 0.0024, 0.0171, 0.0092, 0.0392, 0.0202, 0.0316,
        0.1201, 0.0018, 0.0390, 0.0031, 0.0296, 0.0793, 0.1874, 0.0464, 0.0037,
        0.0415, 0.2367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,780][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0158, 0.0022, 0.0026, 0.0029, 0.0017, 0.0022, 0.0036, 0.0034, 0.0061,
        0.0042, 0.0101, 0.0106, 0.0481, 0.0233, 0.0435, 0.0540, 0.1113, 0.1925,
        0.1320, 0.3299], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,781][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0048, 0.0338, 0.0022, 0.0614, 0.0019, 0.0303, 0.0040, 0.0137, 0.0075,
        0.0957, 0.1209, 0.0054, 0.0965, 0.0028, 0.0099, 0.1444, 0.0113, 0.1552,
        0.0134, 0.1850], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,782][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0849, 0.0502, 0.0279, 0.0571, 0.0353, 0.0428, 0.0354, 0.0522, 0.0376,
        0.0585, 0.0533, 0.0266, 0.0569, 0.0407, 0.0459, 0.0701, 0.0484, 0.0640,
        0.0326, 0.0797], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,787][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0630, 0.0476, 0.0255, 0.0620, 0.0270, 0.0430, 0.0288, 0.0499, 0.0513,
        0.0785, 0.0562, 0.0236, 0.0615, 0.0285, 0.0419, 0.0872, 0.0453, 0.0654,
        0.0218, 0.0919], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,792][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1572, 0.0605, 0.0288, 0.0600, 0.0329, 0.0492, 0.0419, 0.0564, 0.0459,
        0.0567, 0.0278, 0.0362, 0.0586, 0.0289, 0.0375, 0.0560, 0.0435, 0.0356,
        0.0303, 0.0562], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:46,815][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:46,820][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,820][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,821][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,822][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,823][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,824][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,825][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,825][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,826][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,827][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,827][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,828][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:46,829][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,831][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,836][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,838][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,839][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,840][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,840][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,841][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,843][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,851][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,851][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,852][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:46,853][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.3700, 0.4246, 0.2054], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,853][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([7.8483e-05, 1.6108e-04, 9.9976e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,855][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.5669, 0.2434, 0.1897], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,858][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([3.8862e-02, 5.9965e-04, 9.6054e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,863][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0315, 0.0039, 0.9645], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,864][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([8.5224e-03, 4.2562e-06, 9.9147e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,865][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.4668, 0.2322, 0.3011], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,865][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.4708, 0.4025, 0.1268], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,866][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.4420, 0.3215, 0.2365], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,868][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.6468, 0.3179, 0.0353], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,874][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.3892, 0.2718, 0.3390], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,876][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.5006, 0.3411, 0.1583], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:46,877][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6909, 0.0783, 0.1697, 0.0610], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,877][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3020e-03, 3.9238e-02, 7.2293e-04, 9.5774e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,878][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2338, 0.1750, 0.0526, 0.5386], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,879][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1096, 0.3746, 0.0576, 0.4582], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,881][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3388, 0.1535, 0.2298, 0.2780], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,889][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1228, 0.1966, 0.0091, 0.6715], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,889][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6810, 0.0326, 0.2618, 0.0247], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,890][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2434, 0.1851, 0.2928, 0.2787], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,891][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0667, 0.4669, 0.0286, 0.4378], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,892][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4315, 0.2410, 0.1037, 0.2238], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,894][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4142, 0.3085, 0.0738, 0.2035], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,900][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4657, 0.2034, 0.0652, 0.2657], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:46,902][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.2792, 0.1894, 0.1422, 0.1027, 0.2865], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,902][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([3.3434e-04, 1.1669e-04, 3.7649e-04, 1.2579e-04, 9.9905e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,903][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.4274, 0.2094, 0.1603, 0.0912, 0.1118], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,904][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([4.6974e-03, 1.1912e-04, 1.9576e-03, 5.0978e-04, 9.9272e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,905][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0553, 0.0179, 0.0997, 0.0273, 0.7998], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,906][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([2.6504e-02, 5.2225e-05, 4.8449e-04, 7.0580e-06, 9.7295e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,912][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.2997, 0.1326, 0.3290, 0.0628, 0.1759], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,914][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.2265, 0.1591, 0.1222, 0.3907, 0.1015], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,915][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.2170, 0.2085, 0.1645, 0.1510, 0.2590], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,916][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.3723, 0.2265, 0.1823, 0.1854, 0.0335], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,917][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.3135, 0.1933, 0.0778, 0.1213, 0.2941], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,917][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.3899, 0.1675, 0.0850, 0.2095, 0.1481], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:46,922][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4223, 0.0410, 0.0621, 0.0379, 0.0648, 0.3719], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,927][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([1.2374e-03, 8.2990e-03, 8.3548e-03, 7.9439e-03, 5.0690e-04, 9.7366e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,927][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.3978, 0.1337, 0.0920, 0.1394, 0.0835, 0.1536], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,928][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0321, 0.0155, 0.0059, 0.0293, 0.0142, 0.9031], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,929][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.3282, 0.0659, 0.0478, 0.1050, 0.1120, 0.3411], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,930][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([4.4479e-02, 3.7331e-03, 1.4048e-03, 1.0998e-03, 1.9773e-04, 9.4909e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,934][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.2790, 0.0406, 0.3545, 0.0393, 0.2535, 0.0331], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,935][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1178, 0.0956, 0.0988, 0.1808, 0.3108, 0.1962], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,941][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0882, 0.2938, 0.0271, 0.3655, 0.0242, 0.2012], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,941][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.3128, 0.1779, 0.0907, 0.1834, 0.1017, 0.1336], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,942][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.2528, 0.1922, 0.0753, 0.1495, 0.0500, 0.2801], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,943][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.3635, 0.1793, 0.0556, 0.2034, 0.0698, 0.1284], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:46,944][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.2774, 0.0600, 0.1216, 0.0741, 0.2161, 0.1442, 0.1066],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,945][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([1.0312e-04, 2.0813e-04, 3.5007e-04, 1.2234e-04, 2.7811e-04, 8.1595e-05,
        9.9886e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,952][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.3468, 0.1508, 0.0689, 0.1712, 0.0681, 0.1386, 0.0555],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,953][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([1.8102e-03, 4.1794e-05, 3.0292e-04, 1.1039e-04, 9.6225e-05, 2.6038e-04,
        9.9738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,954][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0735, 0.0099, 0.0183, 0.0108, 0.0086, 0.0320, 0.8470],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,955][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([6.1933e-03, 1.4063e-05, 4.6282e-05, 2.5017e-06, 1.5658e-04, 7.5419e-07,
        9.9359e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,956][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.2802, 0.0613, 0.2113, 0.0417, 0.1458, 0.0282, 0.2315],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,956][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.1130, 0.0873, 0.0425, 0.1190, 0.3058, 0.2099, 0.1224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,961][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.2156, 0.1986, 0.0532, 0.2241, 0.0907, 0.1717, 0.0461],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,966][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.2879, 0.1630, 0.0996, 0.1474, 0.0964, 0.1318, 0.0738],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,967][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.2535, 0.1649, 0.0515, 0.1158, 0.0492, 0.0768, 0.2883],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,967][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.3460, 0.1918, 0.0436, 0.2041, 0.0564, 0.0579, 0.1003],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:46,968][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.3133, 0.0735, 0.2039, 0.0488, 0.1290, 0.0930, 0.1092, 0.0292],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,969][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([1.2849e-03, 2.7251e-03, 1.1808e-03, 5.2378e-03, 1.0934e-03, 3.0876e-04,
        2.2905e-03, 9.8588e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,973][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2781, 0.1526, 0.0337, 0.1363, 0.0644, 0.1403, 0.1085, 0.0861],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,977][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([1.3371e-03, 8.0087e-04, 2.8840e-03, 2.1648e-03, 6.3449e-04, 9.3775e-03,
        7.3547e-01, 2.4733e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,979][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0774, 0.0139, 0.0182, 0.0169, 0.0169, 0.0667, 0.6928, 0.0972],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,980][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([3.1328e-02, 6.3521e-03, 1.6143e-03, 3.2795e-03, 6.3329e-04, 1.5876e-03,
        2.9248e-03, 9.5228e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,980][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.2718, 0.0235, 0.1786, 0.0209, 0.1683, 0.0417, 0.2487, 0.0465],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,981][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0885, 0.0485, 0.0721, 0.0897, 0.1301, 0.1692, 0.2015, 0.2004],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,982][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0693, 0.2075, 0.0221, 0.3320, 0.0259, 0.1865, 0.0408, 0.1160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,987][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.2253, 0.1517, 0.0730, 0.1513, 0.0736, 0.1197, 0.0801, 0.1252],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,991][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.2198, 0.1513, 0.0593, 0.1351, 0.0661, 0.0730, 0.0581, 0.2373],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,992][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.3045, 0.1218, 0.0374, 0.1792, 0.0549, 0.0835, 0.0724, 0.1463],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:46,993][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.2533, 0.0587, 0.1153, 0.0539, 0.0939, 0.1042, 0.1635, 0.0754, 0.0819],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,994][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([7.2437e-04, 4.5709e-04, 1.2680e-03, 3.5411e-04, 1.9785e-04, 3.7575e-04,
        3.6157e-03, 5.6256e-03, 9.8738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,995][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2673, 0.0878, 0.0275, 0.1464, 0.0985, 0.0875, 0.1185, 0.1205, 0.0461],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:46,997][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([1.4781e-02, 8.0695e-04, 7.5287e-04, 1.4388e-03, 1.0352e-03, 2.3865e-02,
        3.8336e-02, 4.4590e-02, 8.7439e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,004][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0916, 0.0249, 0.0172, 0.0379, 0.0238, 0.0719, 0.1707, 0.1067, 0.4552],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,005][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([6.8381e-02, 2.0060e-04, 8.2067e-04, 9.2468e-05, 5.3474e-04, 1.2304e-04,
        4.9469e-03, 4.7046e-04, 9.2443e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,006][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.1797, 0.0302, 0.2262, 0.0227, 0.2048, 0.0263, 0.2013, 0.0444, 0.0644],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,006][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0816, 0.0303, 0.0103, 0.0744, 0.0366, 0.1106, 0.1270, 0.3598, 0.1694],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,007][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1031, 0.1484, 0.0313, 0.2285, 0.0296, 0.2192, 0.0396, 0.1420, 0.0583],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,012][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.2150, 0.1302, 0.0665, 0.1275, 0.0761, 0.1093, 0.0786, 0.1207, 0.0760],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,017][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1742, 0.1142, 0.0629, 0.1087, 0.0443, 0.0759, 0.0808, 0.0981, 0.2410],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,018][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.2779, 0.0857, 0.0527, 0.1007, 0.0488, 0.0613, 0.1040, 0.1762, 0.0927],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,019][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3602, 0.0413, 0.0620, 0.0343, 0.0820, 0.1178, 0.1274, 0.0393, 0.1130,
        0.0227], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,019][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.3159e-03, 1.7471e-02, 2.9676e-04, 4.6861e-02, 1.2862e-04, 3.1138e-04,
        3.1295e-04, 3.9352e-02, 3.5659e-03, 8.8738e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,020][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1880, 0.0940, 0.0257, 0.1145, 0.0307, 0.0785, 0.0826, 0.1179, 0.0890,
        0.1792], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,022][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.2098e-02, 2.8863e-03, 4.1519e-04, 3.2888e-03, 7.2053e-04, 2.3908e-02,
        5.6206e-03, 9.9285e-02, 1.3474e-01, 7.1703e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,030][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0339, 0.0030, 0.0013, 0.0057, 0.0049, 0.0463, 0.0828, 0.0404, 0.6851,
        0.0968], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,030][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0684, 0.0837, 0.0041, 0.0969, 0.0041, 0.0208, 0.0226, 0.0812, 0.0460,
        0.5722], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,031][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1881, 0.0111, 0.0812, 0.0090, 0.0522, 0.0328, 0.1192, 0.0618, 0.0960,
        0.3488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,032][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0483, 0.0164, 0.0269, 0.0328, 0.0349, 0.0548, 0.1069, 0.1340, 0.2806,
        0.2645], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,033][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0180, 0.1417, 0.0086, 0.2296, 0.0067, 0.1119, 0.0138, 0.0550, 0.0297,
        0.3849], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,038][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1750, 0.1137, 0.0554, 0.1205, 0.0659, 0.0882, 0.0657, 0.1111, 0.0750,
        0.1294], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,042][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1617, 0.1424, 0.0551, 0.1479, 0.0506, 0.0836, 0.0487, 0.0908, 0.0810,
        0.1382], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,043][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2424, 0.0988, 0.0422, 0.1058, 0.0544, 0.0822, 0.0750, 0.1106, 0.0773,
        0.1113], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,044][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3936, 0.0350, 0.1066, 0.0227, 0.1176, 0.0394, 0.1242, 0.0346, 0.0885,
        0.0147, 0.0231], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,045][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([3.2687e-03, 2.1466e-02, 4.2376e-04, 4.5966e-02, 2.1048e-03, 9.9004e-04,
        6.9717e-05, 1.6263e-02, 5.7571e-04, 6.9949e-02, 8.3892e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,046][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1659, 0.0830, 0.0234, 0.0918, 0.0265, 0.1171, 0.0509, 0.1326, 0.0843,
        0.1977, 0.0269], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,051][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0135, 0.0025, 0.0016, 0.0032, 0.0025, 0.0207, 0.0212, 0.0407, 0.0668,
        0.1785, 0.6488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,055][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1221, 0.0146, 0.0104, 0.0202, 0.0233, 0.0932, 0.0971, 0.0697, 0.2047,
        0.1639, 0.1807], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,056][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0813, 0.1207, 0.0121, 0.0960, 0.0157, 0.0790, 0.0115, 0.0876, 0.0703,
        0.0852, 0.3404], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,057][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2626, 0.0047, 0.2564, 0.0044, 0.1698, 0.0266, 0.1608, 0.0245, 0.0781,
        0.0092, 0.0030], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,058][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0457, 0.0126, 0.0110, 0.0256, 0.0186, 0.0362, 0.0654, 0.0950, 0.1395,
        0.2352, 0.3152], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,058][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0108, 0.0929, 0.0052, 0.1470, 0.0070, 0.1000, 0.0078, 0.0308, 0.0219,
        0.1755, 0.4011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,063][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1749, 0.0995, 0.0537, 0.1026, 0.0605, 0.0790, 0.0596, 0.1017, 0.0658,
        0.1098, 0.0930], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,068][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1807, 0.1119, 0.0606, 0.1085, 0.0730, 0.0570, 0.0420, 0.0821, 0.0548,
        0.0828, 0.1465], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,069][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2089, 0.0852, 0.0424, 0.0907, 0.0527, 0.0679, 0.0883, 0.0953, 0.0819,
        0.0881, 0.0985], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,070][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.1715, 0.0783, 0.0694, 0.0701, 0.0614, 0.0667, 0.2436, 0.0172, 0.0823,
        0.0514, 0.0695, 0.0188], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,070][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([9.8317e-04, 2.3743e-03, 1.1143e-03, 1.8415e-03, 8.4782e-04, 8.1261e-04,
        4.4930e-04, 9.0210e-04, 8.2237e-04, 7.5195e-04, 1.0302e-03, 9.8807e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,071][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1936, 0.0680, 0.1215, 0.0589, 0.0957, 0.0818, 0.0614, 0.0588, 0.0690,
        0.0613, 0.0663, 0.0636], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,073][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([3.3241e-04, 1.0377e-06, 1.2880e-06, 3.0536e-06, 1.1932e-04, 2.5213e-05,
        4.6790e-04, 6.7456e-05, 5.2744e-04, 6.0019e-04, 3.6073e-04, 9.9749e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,081][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0398, 0.0026, 0.0035, 0.0046, 0.0028, 0.0034, 0.0067, 0.0064, 0.0383,
        0.0151, 0.0269, 0.8498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,082][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.1383e-02, 3.9178e-05, 5.6043e-05, 6.7550e-06, 4.0568e-05, 2.5577e-06,
        8.1834e-06, 8.8087e-06, 6.0308e-06, 6.0253e-07, 1.9439e-06, 9.8845e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,082][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.2624, 0.0543, 0.1308, 0.0338, 0.1922, 0.0202, 0.0532, 0.0218, 0.0309,
        0.0173, 0.0224, 0.1607], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,083][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0469, 0.0090, 0.0015, 0.0274, 0.0045, 0.0324, 0.0383, 0.1189, 0.1275,
        0.2014, 0.3048, 0.0875], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,084][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.1435, 0.0994, 0.0559, 0.1141, 0.0465, 0.0690, 0.0811, 0.0660, 0.0745,
        0.0977, 0.1006, 0.0515], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,089][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1889, 0.1003, 0.0727, 0.0935, 0.0555, 0.0767, 0.0767, 0.0866, 0.0593,
        0.0834, 0.0890, 0.0175], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,094][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1266, 0.0898, 0.0429, 0.0912, 0.0362, 0.0556, 0.0434, 0.0771, 0.0485,
        0.0708, 0.0685, 0.2492], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,094][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2638, 0.0960, 0.0343, 0.0674, 0.0509, 0.0524, 0.0640, 0.1053, 0.0942,
        0.0706, 0.0282, 0.0731], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,095][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4455, 0.0144, 0.0572, 0.0119, 0.0661, 0.0481, 0.1167, 0.0221, 0.0998,
        0.0097, 0.0378, 0.0604, 0.0103], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,096][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.1879e-03, 3.5193e-02, 6.2127e-04, 6.5405e-03, 1.2928e-04, 2.6342e-04,
        1.3579e-03, 2.7273e-03, 9.8722e-04, 4.1142e-03, 2.9267e-04, 5.1283e-05,
        9.4453e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,097][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3560, 0.0466, 0.0287, 0.0387, 0.0371, 0.1781, 0.0717, 0.0543, 0.0617,
        0.0450, 0.0216, 0.0143, 0.0462], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,102][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0164, 0.0022, 0.0012, 0.0024, 0.0017, 0.0116, 0.0079, 0.0188, 0.0384,
        0.0752, 0.1765, 0.1359, 0.5117], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,106][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0348, 0.0117, 0.0068, 0.0224, 0.0098, 0.0224, 0.0264, 0.0354, 0.0865,
        0.1025, 0.1063, 0.2208, 0.3142], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,107][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1084, 0.1752, 0.0293, 0.1102, 0.0225, 0.0810, 0.0299, 0.0461, 0.0250,
        0.0610, 0.0665, 0.0126, 0.2323], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,108][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3046, 0.0079, 0.1392, 0.0058, 0.1183, 0.0225, 0.1544, 0.0286, 0.0399,
        0.0106, 0.0051, 0.1593, 0.0038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,109][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0227, 0.0058, 0.0056, 0.0113, 0.0101, 0.0153, 0.0167, 0.0320, 0.0553,
        0.0721, 0.1447, 0.1907, 0.4179], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,110][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0161, 0.1423, 0.0060, 0.1131, 0.0055, 0.0274, 0.0068, 0.0198, 0.0098,
        0.1042, 0.1417, 0.0078, 0.3997], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,115][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1520, 0.0854, 0.0544, 0.0880, 0.0569, 0.0700, 0.0592, 0.0790, 0.0646,
        0.0851, 0.0743, 0.0405, 0.0906], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,119][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1173, 0.1002, 0.0525, 0.1055, 0.0491, 0.0800, 0.0555, 0.0705, 0.0567,
        0.0903, 0.0628, 0.0288, 0.1307], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,120][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2276, 0.0805, 0.0359, 0.0760, 0.0455, 0.0547, 0.0639, 0.0870, 0.0680,
        0.0663, 0.0374, 0.0529, 0.1042], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,121][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.1526, 0.0761, 0.0677, 0.0432, 0.1605, 0.0200, 0.0604, 0.0241, 0.0403,
        0.0373, 0.0430, 0.0459, 0.0303, 0.1986], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,122][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([1.5866e-04, 2.2826e-05, 8.1254e-05, 3.0196e-05, 5.1073e-01, 7.3298e-06,
        2.3676e-05, 2.4615e-04, 7.4647e-05, 3.3376e-05, 7.7072e-05, 5.9719e-06,
        3.7141e-06, 4.8850e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,123][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1999, 0.0829, 0.0859, 0.0476, 0.0795, 0.0445, 0.0801, 0.0644, 0.0472,
        0.0421, 0.0638, 0.0256, 0.0591, 0.0774], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,125][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([1.7801e-04, 4.0375e-07, 3.7830e-06, 6.9263e-07, 1.6735e-03, 6.5452e-06,
        1.7440e-05, 1.1360e-05, 5.7022e-05, 7.9640e-05, 1.5809e-04, 3.4397e-03,
        1.4702e-04, 9.9423e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,132][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0072, 0.0015, 0.0054, 0.0019, 0.0471, 0.0010, 0.0018, 0.0017, 0.0089,
        0.0091, 0.0064, 0.0158, 0.0271, 0.8652], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,133][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([4.3490e-03, 7.3272e-06, 1.1084e-04, 1.0260e-06, 5.9963e-01, 6.1421e-07,
        2.2266e-05, 1.1401e-06, 4.2606e-06, 2.0448e-07, 3.6954e-07, 2.0465e-06,
        2.3701e-07, 3.9587e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,134][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.1605, 0.0615, 0.2557, 0.0334, 0.1217, 0.0132, 0.0406, 0.0128, 0.0258,
        0.0148, 0.0320, 0.0630, 0.0338, 0.1312], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,135][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0496, 0.0114, 0.0089, 0.0223, 0.0050, 0.0290, 0.0109, 0.0384, 0.0597,
        0.1011, 0.1512, 0.0195, 0.3898, 0.1032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,135][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0858, 0.0752, 0.0758, 0.0639, 0.1504, 0.0292, 0.0275, 0.0339, 0.0366,
        0.0550, 0.0782, 0.0249, 0.0728, 0.1910], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,140][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.1582, 0.0990, 0.1037, 0.0865, 0.0172, 0.0672, 0.0452, 0.0700, 0.0601,
        0.0737, 0.0881, 0.0318, 0.0825, 0.0168], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,145][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0990, 0.0622, 0.0447, 0.0587, 0.2390, 0.0299, 0.0227, 0.0474, 0.0271,
        0.0440, 0.0539, 0.0131, 0.0413, 0.2170], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,146][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.1330, 0.0535, 0.0323, 0.0578, 0.0511, 0.1078, 0.0838, 0.0850, 0.0736,
        0.0551, 0.0401, 0.0829, 0.0759, 0.0682], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,147][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.1941, 0.0229, 0.0515, 0.0229, 0.0680, 0.2249, 0.0781, 0.0136, 0.0396,
        0.0128, 0.0187, 0.0345, 0.0145, 0.0884, 0.1153], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,148][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([7.6149e-05, 3.4625e-05, 1.1764e-04, 6.3678e-05, 2.0642e-04, 8.6301e-04,
        2.2765e-02, 1.5237e-04, 2.5745e-03, 4.9057e-05, 1.5941e-05, 1.5952e-05,
        1.4166e-05, 1.2821e-04, 9.7292e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,149][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1781, 0.0380, 0.0282, 0.0521, 0.0409, 0.0560, 0.1299, 0.0628, 0.0719,
        0.0697, 0.0623, 0.0451, 0.0868, 0.0394, 0.0387], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,152][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([9.0810e-04, 1.2129e-05, 1.3217e-05, 1.2117e-05, 1.0464e-05, 9.5669e-05,
        8.3175e-04, 1.7554e-04, 6.1610e-04, 1.9287e-04, 3.7794e-04, 1.8548e-03,
        1.0505e-03, 2.0600e-03, 9.9179e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,158][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0285, 0.0044, 0.0032, 0.0048, 0.0037, 0.0124, 0.0184, 0.0096, 0.0351,
        0.0193, 0.0183, 0.0322, 0.0584, 0.0573, 0.6944], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,158][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([3.5765e-02, 6.2828e-05, 5.6376e-04, 3.5108e-05, 8.4311e-04, 3.0203e-04,
        3.3040e-03, 9.1484e-05, 1.1626e-03, 1.5454e-05, 7.0737e-06, 1.1396e-05,
        4.7841e-06, 2.7295e-04, 9.5756e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,159][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.1024, 0.0229, 0.1665, 0.0149, 0.1569, 0.0116, 0.1031, 0.0223, 0.0346,
        0.0088, 0.0153, 0.0756, 0.0221, 0.1984, 0.0445], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,160][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0176, 0.0043, 0.0075, 0.0086, 0.0028, 0.0096, 0.0164, 0.0199, 0.0299,
        0.0549, 0.0829, 0.0371, 0.4082, 0.1069, 0.1933], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,161][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.1001, 0.0759, 0.0210, 0.1135, 0.0306, 0.0676, 0.0385, 0.0601, 0.0433,
        0.1126, 0.0896, 0.0632, 0.1050, 0.0383, 0.0408], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,168][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.1266, 0.0685, 0.0515, 0.0697, 0.0484, 0.0616, 0.0639, 0.0765, 0.0579,
        0.0680, 0.0628, 0.0353, 0.0906, 0.0580, 0.0608], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,170][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0924, 0.0627, 0.0346, 0.0666, 0.0382, 0.0809, 0.0724, 0.0551, 0.0605,
        0.0602, 0.0505, 0.0235, 0.0621, 0.0336, 0.2066], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,171][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.2176, 0.0873, 0.0269, 0.0732, 0.0355, 0.0481, 0.0426, 0.0918, 0.0568,
        0.0633, 0.0280, 0.0430, 0.0944, 0.0354, 0.0561], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,172][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2271, 0.0211, 0.0330, 0.0179, 0.0464, 0.0670, 0.0720, 0.0211, 0.0621,
        0.0117, 0.0284, 0.0640, 0.0194, 0.0687, 0.2251, 0.0152],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,173][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3140e-03, 6.1151e-03, 9.9034e-05, 1.7722e-02, 4.8542e-05, 1.2764e-04,
        1.1954e-04, 1.7573e-02, 1.6666e-03, 4.3379e-01, 9.2491e-04, 4.0848e-05,
        3.7853e-03, 3.1432e-05, 5.2622e-05, 5.1559e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,176][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1065, 0.0463, 0.0142, 0.0649, 0.0187, 0.0481, 0.0510, 0.0716, 0.0541,
        0.1027, 0.0193, 0.0224, 0.1888, 0.0195, 0.0518, 0.1203],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,180][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.2326e-03, 2.4578e-04, 2.3825e-05, 1.4910e-04, 2.2207e-05, 5.9936e-04,
        1.3492e-04, 1.9311e-03, 2.4277e-03, 1.0807e-02, 1.5237e-02, 3.5095e-03,
        2.4922e-02, 4.5935e-03, 7.4044e-02, 8.5812e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,183][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3646e-02, 8.2185e-04, 2.6939e-04, 1.3110e-03, 8.0347e-04, 7.7912e-03,
        1.3992e-02, 5.5965e-03, 9.1003e-02, 1.1823e-02, 7.7274e-03, 1.0433e-02,
        1.2594e-02, 1.2675e-02, 6.8939e-01, 1.2013e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,184][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0287, 0.0390, 0.0020, 0.0511, 0.0025, 0.0125, 0.0110, 0.0484, 0.0298,
        0.3310, 0.1247, 0.0014, 0.0147, 0.0011, 0.0277, 0.2744],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,185][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0927, 0.0044, 0.0410, 0.0038, 0.0255, 0.0150, 0.0604, 0.0304, 0.0479,
        0.1761, 0.0031, 0.0595, 0.0050, 0.0437, 0.1211, 0.2704],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,186][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0191, 0.0034, 0.0046, 0.0051, 0.0039, 0.0054, 0.0104, 0.0108, 0.0221,
        0.0175, 0.0426, 0.0452, 0.2069, 0.1159, 0.2160, 0.2712],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,190][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0073, 0.0538, 0.0035, 0.0941, 0.0028, 0.0462, 0.0060, 0.0214, 0.0118,
        0.1507, 0.1950, 0.0084, 0.1521, 0.0043, 0.0155, 0.2271],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,196][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1083, 0.0668, 0.0359, 0.0741, 0.0442, 0.0553, 0.0444, 0.0676, 0.0482,
        0.0773, 0.0702, 0.0339, 0.0726, 0.0507, 0.0588, 0.0918],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,198][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0880, 0.0714, 0.0350, 0.0875, 0.0350, 0.0572, 0.0368, 0.0650, 0.0648,
        0.1018, 0.0715, 0.0275, 0.0737, 0.0323, 0.0482, 0.1043],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,199][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1787, 0.0709, 0.0322, 0.0712, 0.0384, 0.0571, 0.0493, 0.0703, 0.0538,
        0.0691, 0.0337, 0.0446, 0.0762, 0.0366, 0.0465, 0.0714],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,200][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2068, 0.0203, 0.0373, 0.0213, 0.0325, 0.0372, 0.0816, 0.0354, 0.0933,
        0.0191, 0.0240, 0.0684, 0.0162, 0.0420, 0.1999, 0.0231, 0.0415],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,201][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.7640e-04, 4.5177e-04, 1.1801e-04, 3.7694e-04, 9.3848e-05, 1.5238e-04,
        2.3507e-03, 2.9230e-04, 2.1399e-03, 5.6518e-04, 1.8095e-04, 3.3762e-04,
        4.2976e-05, 5.9375e-05, 3.1954e-04, 5.0181e-04, 9.9174e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,205][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1207, 0.0321, 0.0182, 0.0423, 0.0186, 0.0699, 0.0747, 0.0799, 0.0681,
        0.0814, 0.0425, 0.0365, 0.0646, 0.0182, 0.0977, 0.0921, 0.0423],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,209][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.1106e-04, 3.0603e-06, 1.3487e-06, 3.2306e-06, 3.1051e-06, 1.2389e-05,
        6.0377e-05, 4.4930e-05, 9.1826e-05, 1.2106e-04, 2.0477e-04, 3.5748e-03,
        3.3589e-04, 8.1618e-04, 1.5189e-02, 8.3276e-03, 9.7080e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,211][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0282, 0.0036, 0.0072, 0.0043, 0.0080, 0.0094, 0.0120, 0.0048, 0.0153,
        0.0148, 0.0135, 0.0136, 0.0183, 0.0761, 0.1905, 0.1074, 0.4728],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,212][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.3152e-02, 5.7554e-05, 3.9815e-05, 2.8089e-05, 4.0744e-04, 3.7689e-05,
        3.9484e-04, 4.6907e-05, 1.6301e-04, 1.1253e-05, 1.6548e-05, 3.0309e-05,
        3.2562e-06, 1.4108e-04, 8.8122e-05, 6.6103e-06, 9.8538e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,213][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.1457, 0.0148, 0.1215, 0.0133, 0.1054, 0.0171, 0.0899, 0.0226, 0.0368,
        0.0111, 0.0136, 0.1313, 0.0130, 0.1444, 0.0759, 0.0137, 0.0299],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,213][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0114, 0.0025, 0.0016, 0.0032, 0.0098, 0.0031, 0.0041, 0.0069, 0.0075,
        0.0166, 0.0241, 0.0197, 0.0980, 0.2334, 0.1499, 0.2369, 0.1713],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,218][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0520, 0.0535, 0.0276, 0.0816, 0.0115, 0.0799, 0.0240, 0.0532, 0.0335,
        0.1093, 0.0844, 0.0534, 0.0711, 0.0148, 0.0647, 0.1453, 0.0402],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,223][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.1009, 0.0555, 0.0293, 0.0615, 0.0346, 0.0607, 0.0515, 0.0606, 0.0496,
        0.0681, 0.0565, 0.0427, 0.0773, 0.0412, 0.0779, 0.0828, 0.0494],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,224][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0733, 0.0482, 0.0284, 0.0583, 0.0271, 0.0483, 0.0470, 0.0401, 0.0595,
        0.0709, 0.0526, 0.0333, 0.0630, 0.0288, 0.0549, 0.0770, 0.1894],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,225][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.2413, 0.0673, 0.0254, 0.0789, 0.0305, 0.0339, 0.0428, 0.0749, 0.0569,
        0.0555, 0.0174, 0.0268, 0.0634, 0.0260, 0.0376, 0.0557, 0.0656],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,226][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2672, 0.0205, 0.0519, 0.0159, 0.0408, 0.0237, 0.0816, 0.0194, 0.0402,
        0.0128, 0.0240, 0.0924, 0.0181, 0.0588, 0.1028, 0.0169, 0.0914, 0.0218],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,227][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.2052e-04, 1.7492e-03, 4.7866e-04, 1.9186e-03, 6.1337e-04, 7.0285e-05,
        4.9436e-05, 1.1627e-02, 1.6701e-03, 6.4051e-03, 2.4450e-02, 9.1319e-05,
        4.6051e-04, 4.7143e-04, 6.0524e-05, 6.2405e-03, 9.3886e-04, 9.4198e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,233][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0813, 0.0408, 0.0132, 0.0623, 0.0212, 0.0495, 0.0374, 0.0686, 0.0582,
        0.1101, 0.0143, 0.0231, 0.1287, 0.0238, 0.0644, 0.1316, 0.0571, 0.0145],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,236][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.0440e-03, 1.9363e-04, 1.0364e-04, 1.1365e-04, 5.3316e-05, 2.4846e-04,
        3.1493e-04, 5.1568e-04, 4.8582e-04, 1.3023e-03, 5.1721e-03, 2.9580e-03,
        8.5401e-03, 6.4507e-03, 3.4362e-02, 6.5386e-02, 1.2902e-01, 7.4174e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,237][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0213, 0.0025, 0.0024, 0.0025, 0.0031, 0.0091, 0.0077, 0.0061, 0.0234,
        0.0095, 0.0101, 0.0164, 0.0123, 0.0312, 0.1886, 0.0739, 0.3751, 0.2046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,238][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0257, 0.0824, 0.0078, 0.0751, 0.0068, 0.0127, 0.0064, 0.0370, 0.0187,
        0.0653, 0.1742, 0.0038, 0.0219, 0.0027, 0.0062, 0.0486, 0.0096, 0.3949],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,239][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1207, 0.0027, 0.0951, 0.0026, 0.0684, 0.0171, 0.1020, 0.0175, 0.0476,
        0.0064, 0.0023, 0.1497, 0.0024, 0.1155, 0.1527, 0.0087, 0.0840, 0.0047],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,243][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0142, 0.0025, 0.0024, 0.0037, 0.0020, 0.0034, 0.0046, 0.0061, 0.0104,
        0.0104, 0.0182, 0.0162, 0.1029, 0.0422, 0.0825, 0.1463, 0.2339, 0.2979],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,248][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0340, 0.0027, 0.0603, 0.0033, 0.0428, 0.0054, 0.0162, 0.0109,
        0.0777, 0.1787, 0.0080, 0.0961, 0.0054, 0.0167, 0.1155, 0.0176, 0.3017],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,249][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0992, 0.0597, 0.0361, 0.0660, 0.0348, 0.0487, 0.0398, 0.0597, 0.0434,
        0.0686, 0.0596, 0.0297, 0.0639, 0.0397, 0.0500, 0.0824, 0.0509, 0.0678],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,250][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0716, 0.0547, 0.0398, 0.0657, 0.0322, 0.0334, 0.0284, 0.0678, 0.0477,
        0.0711, 0.0805, 0.0288, 0.0557, 0.0326, 0.0386, 0.0756, 0.0350, 0.1407],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,251][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1694, 0.0636, 0.0289, 0.0607, 0.0346, 0.0480, 0.0498, 0.0587, 0.0484,
        0.0643, 0.0339, 0.0437, 0.0666, 0.0320, 0.0389, 0.0660, 0.0475, 0.0451],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,256][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0905, 0.0459, 0.0280, 0.0332, 0.0968, 0.0234, 0.0692, 0.0253, 0.0156,
        0.0257, 0.0365, 0.0859, 0.0307, 0.1204, 0.0151, 0.0308, 0.0553, 0.0319,
        0.1398], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,259][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([6.7823e-05, 9.0268e-05, 1.0976e-04, 1.4709e-04, 2.7431e-04, 9.5625e-05,
        3.0094e-05, 3.5242e-05, 4.4275e-05, 1.9438e-05, 8.2231e-05, 7.6729e-05,
        2.3005e-06, 1.9046e-04, 2.0491e-05, 1.5793e-05, 3.9628e-05, 6.8173e-06,
        9.9865e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,261][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0869, 0.0343, 0.0210, 0.0607, 0.1238, 0.0242, 0.0216, 0.0878, 0.0390,
        0.0643, 0.0430, 0.0245, 0.0349, 0.1238, 0.0225, 0.0673, 0.0403, 0.0461,
        0.0340], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,262][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([2.5928e-04, 7.0957e-07, 4.7194e-06, 5.8033e-07, 4.0556e-06, 6.8153e-06,
        3.0657e-06, 6.1305e-06, 3.5754e-05, 1.0479e-05, 3.3937e-05, 4.0593e-04,
        5.5976e-05, 7.3779e-04, 1.1830e-03, 5.9403e-04, 1.8785e-03, 2.8612e-03,
        9.9192e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,263][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0292, 0.0025, 0.0027, 0.0018, 0.0041, 0.0018, 0.0039, 0.0017, 0.0069,
        0.0020, 0.0055, 0.0277, 0.0084, 0.0182, 0.0168, 0.0101, 0.0367, 0.0304,
        0.7893], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,264][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([2.5107e-03, 7.4246e-06, 6.4672e-05, 2.4574e-06, 3.0243e-05, 9.7073e-07,
        1.9263e-07, 3.3435e-07, 2.3075e-06, 2.0107e-07, 5.6848e-07, 1.7360e-06,
        1.1718e-07, 7.7609e-06, 7.0896e-07, 1.0373e-07, 9.2737e-08, 4.6066e-07,
        9.9737e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,269][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1068, 0.0388, 0.0897, 0.0243, 0.1527, 0.0125, 0.0452, 0.0159, 0.0191,
        0.0135, 0.0113, 0.1159, 0.0283, 0.1668, 0.0292, 0.0139, 0.0224, 0.0146,
        0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,274][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0251, 0.0097, 0.0016, 0.0080, 0.0045, 0.0053, 0.0027, 0.0101, 0.0058,
        0.0175, 0.0198, 0.0147, 0.0640, 0.0476, 0.1083, 0.1640, 0.1836, 0.2441,
        0.0635], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,275][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.1088, 0.0577, 0.0356, 0.0715, 0.0403, 0.0354, 0.0381, 0.0265, 0.0542,
        0.0594, 0.0483, 0.0211, 0.0555, 0.0438, 0.0502, 0.0691, 0.0405, 0.0806,
        0.0632], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,275][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0880, 0.0655, 0.0433, 0.0630, 0.0541, 0.0462, 0.0468, 0.0484, 0.0353,
        0.0623, 0.0572, 0.0416, 0.0628, 0.0603, 0.0390, 0.0725, 0.0384, 0.0707,
        0.0045], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,276][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0657, 0.0441, 0.0279, 0.0487, 0.0336, 0.0424, 0.0220, 0.0410, 0.0379,
        0.0567, 0.0472, 0.0272, 0.0472, 0.0374, 0.0348, 0.0616, 0.0272, 0.0502,
        0.2471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,281][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.1289, 0.0622, 0.0325, 0.0434, 0.0385, 0.0454, 0.0428, 0.0749, 0.0643,
        0.0436, 0.0226, 0.0469, 0.0383, 0.0358, 0.0591, 0.0455, 0.0745, 0.0323,
        0.0684], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,286][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1861, 0.0157, 0.0266, 0.0132, 0.0358, 0.0513, 0.0544, 0.0151, 0.0468,
        0.0084, 0.0207, 0.0477, 0.0141, 0.0517, 0.1665, 0.0108, 0.0694, 0.0235,
        0.1290, 0.0134], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,287][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5353e-03, 3.2720e-03, 5.0292e-05, 9.5139e-03, 2.7509e-05, 7.5052e-05,
        6.6820e-05, 1.0197e-02, 9.6836e-04, 2.5979e-01, 5.4315e-04, 2.5504e-05,
        2.5321e-03, 2.0135e-05, 3.4451e-05, 3.2994e-01, 2.5556e-04, 3.9130e-04,
        6.8134e-06, 3.8076e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,288][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0893, 0.0358, 0.0114, 0.0528, 0.0158, 0.0398, 0.0415, 0.0597, 0.0452,
        0.0835, 0.0156, 0.0187, 0.1534, 0.0167, 0.0424, 0.0985, 0.0429, 0.0151,
        0.0131, 0.1089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,289][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.2597e-04, 3.9283e-05, 3.3418e-06, 1.7487e-05, 2.0778e-06, 4.2010e-05,
        9.1864e-06, 1.0198e-04, 1.1342e-04, 4.1374e-04, 5.5751e-04, 1.5803e-04,
        9.9181e-04, 1.6819e-04, 2.5815e-03, 2.7723e-02, 2.3512e-01, 6.2993e-02,
        1.1633e-01, 5.5180e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,291][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.4791e-02, 7.9477e-04, 2.1193e-04, 1.1669e-03, 5.4989e-04, 4.9597e-03,
        8.4888e-03, 3.1630e-03, 4.4298e-02, 5.5717e-03, 3.4533e-03, 4.3434e-03,
        5.4109e-03, 4.7118e-03, 2.7895e-01, 4.8879e-02, 2.2484e-01, 7.2243e-02,
        4.0852e-02, 2.3232e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,297][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0181, 0.0262, 0.0014, 0.0364, 0.0020, 0.0101, 0.0080, 0.0362, 0.0237,
        0.2446, 0.0923, 0.0010, 0.0102, 0.0008, 0.0227, 0.2021, 0.0066, 0.0697,
        0.0013, 0.1865], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,299][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0615, 0.0027, 0.0275, 0.0024, 0.0171, 0.0092, 0.0392, 0.0202, 0.0316,
        0.1201, 0.0018, 0.0390, 0.0031, 0.0296, 0.0793, 0.1874, 0.0464, 0.0037,
        0.0415, 0.2367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,300][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0158, 0.0022, 0.0026, 0.0029, 0.0017, 0.0022, 0.0036, 0.0034, 0.0061,
        0.0042, 0.0101, 0.0106, 0.0481, 0.0233, 0.0435, 0.0540, 0.1113, 0.1925,
        0.1320, 0.3299], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,301][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0048, 0.0338, 0.0022, 0.0614, 0.0019, 0.0303, 0.0040, 0.0137, 0.0075,
        0.0957, 0.1209, 0.0054, 0.0965, 0.0028, 0.0099, 0.1444, 0.0113, 0.1552,
        0.0134, 0.1850], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,302][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0849, 0.0502, 0.0279, 0.0571, 0.0353, 0.0428, 0.0354, 0.0522, 0.0376,
        0.0585, 0.0533, 0.0266, 0.0569, 0.0407, 0.0459, 0.0701, 0.0484, 0.0640,
        0.0326, 0.0797], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,307][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0630, 0.0476, 0.0255, 0.0620, 0.0270, 0.0430, 0.0288, 0.0499, 0.0513,
        0.0785, 0.0562, 0.0236, 0.0615, 0.0285, 0.0419, 0.0872, 0.0453, 0.0654,
        0.0218, 0.0919], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,311][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1572, 0.0605, 0.0288, 0.0600, 0.0329, 0.0492, 0.0419, 0.0564, 0.0459,
        0.0567, 0.0278, 0.0362, 0.0586, 0.0289, 0.0375, 0.0560, 0.0435, 0.0356,
        0.0303, 0.0562], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,315][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:47,318][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[31254],
        [14121],
        [    1],
        [ 8554],
        [ 2372],
        [ 3447],
        [ 4736],
        [ 3883],
        [27215],
        [ 7263],
        [21252],
        [15469],
        [ 3675],
        [ 4944],
        [12923],
        [ 7867],
        [10205],
        [15170],
        [36697],
        [ 9629]], device='cuda:0')
[2024-07-24 10:16:47,321][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[41490],
        [34525],
        [    1],
        [31104],
        [  767],
        [38690],
        [35884],
        [29690],
        [25628],
        [33336],
        [21064],
        [40401],
        [32854],
        [  784],
        [36599],
        [30154],
        [33116],
        [19211],
        [37414],
        [27971]], device='cuda:0')
[2024-07-24 10:16:47,324][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13897],
        [13351],
        [ 4518],
        [ 6580],
        [ 8488],
        [13736],
        [10687],
        [ 6929],
        [12243],
        [15440],
        [12239],
        [14441],
        [12382],
        [15112],
        [12917],
        [10931],
        [12159],
        [10927],
        [15437],
        [11616]], device='cuda:0')
[2024-07-24 10:16:47,327][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42442],
        [ 2023],
        [ 5542],
        [12889],
        [ 2233],
        [16577],
        [15184],
        [ 6996],
        [20932],
        [13276],
        [45658],
        [ 8821],
        [ 5580],
        [ 2380],
        [18916],
        [13915],
        [17582],
        [40736],
        [29557],
        [14399]], device='cuda:0')
[2024-07-24 10:16:47,328][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 9493],
        [11632],
        [ 7999],
        [24681],
        [10573],
        [15702],
        [17389],
        [17292],
        [16685],
        [19560],
        [19180],
        [14996],
        [16375],
        [14524],
        [18912],
        [24685],
        [21335],
        [23070],
        [18477],
        [23944]], device='cuda:0')
[2024-07-24 10:16:47,330][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[37205],
        [38831],
        [  183],
        [22325],
        [20014],
        [ 1287],
        [ 8265],
        [ 6216],
        [ 5651],
        [13310],
        [11774],
        [14405],
        [23252],
        [16360],
        [  634],
        [13613],
        [ 1126],
        [ 4889],
        [20458],
        [ 8790]], device='cuda:0')
[2024-07-24 10:16:47,332][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3350],
        [ 3154],
        [   24],
        [   97],
        [ 2731],
        [  970],
        [26551],
        [21310],
        [ 5764],
        [ 6371],
        [ 1732],
        [28720],
        [  530],
        [ 5225],
        [19122],
        [19344],
        [ 6083],
        [ 4706],
        [ 5826],
        [ 4289]], device='cuda:0')
[2024-07-24 10:16:47,335][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24808],
        [37494],
        [11781],
        [40029],
        [32635],
        [32995],
        [40066],
        [44248],
        [38803],
        [37686],
        [37838],
        [34984],
        [38565],
        [32424],
        [34006],
        [36177],
        [40916],
        [34429],
        [40719],
        [35238]], device='cuda:0')
[2024-07-24 10:16:47,339][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[41131],
        [41617],
        [16221],
        [11916],
        [ 2106],
        [  362],
        [ 4505],
        [ 4587],
        [ 1371],
        [11674],
        [  950],
        [ 9637],
        [12704],
        [ 1428],
        [  622],
        [10853],
        [ 2526],
        [ 5182],
        [ 4222],
        [11276]], device='cuda:0')
[2024-07-24 10:16:47,341][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[11968],
        [11903],
        [10777],
        [15226],
        [21314],
        [24044],
        [23359],
        [21014],
        [22653],
        [23295],
        [38737],
        [37898],
        [22547],
        [28876],
        [26402],
        [27404],
        [23273],
        [29518],
        [32730],
        [34930]], device='cuda:0')
[2024-07-24 10:16:47,343][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22456],
        [11685],
        [ 7176],
        [ 8883],
        [ 9525],
        [13203],
        [14231],
        [12814],
        [15353],
        [ 9718],
        [10253],
        [ 9990],
        [ 8811],
        [13470],
        [11526],
        [ 8404],
        [ 9845],
        [ 9025],
        [12870],
        [ 8294]], device='cuda:0')
[2024-07-24 10:16:47,344][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[25386],
        [33646],
        [33695],
        [36178],
        [32251],
        [35110],
        [33392],
        [37165],
        [36277],
        [38647],
        [37541],
        [35756],
        [36809],
        [36280],
        [35857],
        [38509],
        [39041],
        [38521],
        [36210],
        [39206]], device='cuda:0')
[2024-07-24 10:16:47,346][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 7851],
        [ 2427],
        [17527],
        [ 1298],
        [18059],
        [  909],
        [  919],
        [  986],
        [ 1749],
        [  766],
        [ 3151],
        [ 8962],
        [  942],
        [39335],
        [ 1364],
        [ 1046],
        [ 1407],
        [ 3898],
        [12313],
        [ 1474]], device='cuda:0')
[2024-07-24 10:16:47,350][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22825],
        [18349],
        [15832],
        [11699],
        [11938],
        [ 8243],
        [ 8385],
        [ 6485],
        [ 5740],
        [ 4823],
        [ 5328],
        [ 6146],
        [ 6832],
        [ 5426],
        [ 6721],
        [ 5685],
        [ 7419],
        [ 6737],
        [ 7157],
        [ 6431]], device='cuda:0')
[2024-07-24 10:16:47,353][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[42719],
        [10871],
        [    5],
        [13839],
        [ 8811],
        [ 1733],
        [10322],
        [11674],
        [33950],
        [ 6616],
        [34247],
        [28840],
        [ 3185],
        [ 8300],
        [27756],
        [ 6267],
        [16889],
        [24939],
        [42819],
        [ 5719]], device='cuda:0')
[2024-07-24 10:16:47,355][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[11812],
        [11879],
        [ 8905],
        [10714],
        [10943],
        [13811],
        [12452],
        [12007],
        [ 9964],
        [10686],
        [10470],
        [ 8737],
        [ 9806],
        [10795],
        [12221],
        [13687],
        [12899],
        [11828],
        [ 8803],
        [12553]], device='cuda:0')
[2024-07-24 10:16:47,357][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 4900],
        [ 6650],
        [ 6469],
        [ 1473],
        [17791],
        [ 3372],
        [ 9017],
        [ 5182],
        [ 5814],
        [  508],
        [  189],
        [ 4769],
        [ 1883],
        [14396],
        [ 7962],
        [  453],
        [ 5604],
        [  528],
        [ 4764],
        [  457]], device='cuda:0')
[2024-07-24 10:16:47,359][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[35827],
        [31920],
        [32781],
        [40396],
        [33432],
        [37827],
        [38257],
        [37926],
        [39134],
        [32803],
        [32949],
        [38816],
        [38063],
        [38849],
        [38743],
        [33180],
        [35986],
        [33872],
        [38180],
        [32481]], device='cuda:0')
[2024-07-24 10:16:47,361][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[27442],
        [31731],
        [16565],
        [21787],
        [23147],
        [23400],
        [14420],
        [23686],
        [22875],
        [24631],
        [19697],
        [13338],
        [20959],
        [22396],
        [26979],
        [23231],
        [20062],
        [19235],
        [28441],
        [22326]], device='cuda:0')
[2024-07-24 10:16:47,364][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11010],
        [11337],
        [ 9998],
        [21577],
        [28639],
        [18201],
        [ 9850],
        [13063],
        [22799],
        [21797],
        [19215],
        [19698],
        [29272],
        [25357],
        [11914],
        [12487],
        [26495],
        [21912],
        [38540],
        [20656]], device='cuda:0')
[2024-07-24 10:16:47,367][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[22973],
        [18556],
        [31524],
        [20429],
        [15168],
        [ 9421],
        [ 6588],
        [10881],
        [ 7911],
        [21209],
        [13869],
        [12085],
        [18585],
        [16330],
        [ 7245],
        [21504],
        [17094],
        [17156],
        [21602],
        [22370]], device='cuda:0')
[2024-07-24 10:16:47,370][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[24695],
        [24793],
        [ 2691],
        [ 4553],
        [  652],
        [  455],
        [ 1009],
        [ 1278],
        [  649],
        [34344],
        [  781],
        [ 1212],
        [ 1965],
        [  472],
        [  587],
        [39186],
        [  961],
        [ 2749],
        [  731],
        [42726]], device='cuda:0')
[2024-07-24 10:16:47,371][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10127],
        [10503],
        [ 9333],
        [ 4367],
        [ 5407],
        [10742],
        [11622],
        [ 6746],
        [ 3695],
        [ 1843],
        [ 3436],
        [ 3717],
        [27699],
        [16875],
        [12727],
        [ 3201],
        [ 6027],
        [ 3355],
        [ 2747],
        [ 2485]], device='cuda:0')
[2024-07-24 10:16:47,373][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[29817],
        [13013],
        [14162],
        [ 8893],
        [18120],
        [10873],
        [16233],
        [10624],
        [11834],
        [ 4520],
        [ 3667],
        [ 9533],
        [ 1426],
        [16158],
        [ 8022],
        [ 1983],
        [ 5314],
        [ 1526],
        [ 8790],
        [ 1700]], device='cuda:0')
[2024-07-24 10:16:47,375][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[28920],
        [20292],
        [19269],
        [17669],
        [18462],
        [21778],
        [23164],
        [24685],
        [26380],
        [25135],
        [25820],
        [25997],
        [23962],
        [23619],
        [25272],
        [24231],
        [25079],
        [25304],
        [25101],
        [24259]], device='cuda:0')
[2024-07-24 10:16:47,378][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38949],
        [46208],
        [45190],
        [47675],
        [44873],
        [48156],
        [46061],
        [48872],
        [47263],
        [48733],
        [48028],
        [47080],
        [48262],
        [44984],
        [47231],
        [48494],
        [48094],
        [47905],
        [46531],
        [48400]], device='cuda:0')
[2024-07-24 10:16:47,382][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8097],
        [ 6248],
        [21048],
        [10681],
        [19216],
        [17778],
        [16054],
        [19959],
        [22238],
        [22912],
        [18065],
        [21838],
        [19475],
        [23380],
        [24075],
        [23628],
        [22796],
        [22566],
        [27390],
        [22889]], device='cuda:0')
[2024-07-24 10:16:47,384][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 8433],
        [ 6812],
        [10544],
        [11829],
        [11188],
        [14177],
        [12360],
        [11634],
        [12278],
        [ 9051],
        [16308],
        [11390],
        [11157],
        [10902],
        [12437],
        [ 9158],
        [11961],
        [14556],
        [10974],
        [ 9590]], device='cuda:0')
[2024-07-24 10:16:47,386][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 2804],
        [25993],
        [50235],
        [22472],
        [30025],
        [43657],
        [28445],
        [26174],
        [ 8556],
        [33448],
        [ 6241],
        [11674],
        [40028],
        [31020],
        [11537],
        [34020],
        [21222],
        [13567],
        [ 3222],
        [35056]], device='cuda:0')
[2024-07-24 10:16:47,387][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586],
        [12586]], device='cuda:0')
[2024-07-24 10:16:47,407][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:47,411][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,413][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,414][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,415][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,416][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,416][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,417][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,418][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,418][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,421][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,422][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,422][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,423][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9682, 0.0318], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,424][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9610, 0.0390], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,426][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6347, 0.3653], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,430][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5351, 0.4649], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,434][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2893, 0.7107], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,435][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,436][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6937, 0.3063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,436][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4592, 0.5408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,437][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9479, 0.0521], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,439][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0911, 0.9089], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,445][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2403, 0.7597], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,447][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6220, 0.3780], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,448][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.8690, 0.0720, 0.0591], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,448][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.5169, 0.4094, 0.0736], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,449][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.4492, 0.2803, 0.2706], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,450][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.4730, 0.3186, 0.2084], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,454][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1446, 0.4315, 0.4238], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,459][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.3875, 0.2819, 0.3306], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,460][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.4038, 0.3561, 0.2402], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,460][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0897, 0.3041, 0.6062], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,461][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.8345, 0.1277, 0.0378], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,462][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0438, 0.9083, 0.0479], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,464][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.1520, 0.4161, 0.4319], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,471][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0048, 0.0477, 0.9475], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,472][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9138, 0.0374, 0.0316, 0.0173], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,473][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6489, 0.1373, 0.2096, 0.0042], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,473][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3438, 0.2041, 0.2184, 0.2338], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,474][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3542, 0.2282, 0.1985, 0.2191], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,477][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1137, 0.2812, 0.3395, 0.2655], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,484][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0557, 0.2185, 0.0045, 0.7212], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,484][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3947, 0.1757, 0.1034, 0.3261], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,485][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1344, 0.5209, 0.2374, 0.1073], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,486][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7859, 0.0589, 0.0528, 0.1024], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,487][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0137, 0.0657, 0.1003, 0.8203], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,489][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1052, 0.3005, 0.3410, 0.2534], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,492][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([7.3839e-02, 6.7879e-02, 2.1767e-04, 8.5806e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,496][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.8704, 0.0566, 0.0315, 0.0244, 0.0171], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,497][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.5845, 0.2349, 0.0634, 0.1127, 0.0045], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,498][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.2786, 0.1734, 0.1637, 0.1907, 0.1937], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,499][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.2962, 0.2118, 0.1505, 0.1873, 0.1542], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,499][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0762, 0.2250, 0.2340, 0.2054, 0.2594], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,503][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0377, 0.0384, 0.4641, 0.2399, 0.2200], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,509][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.2999, 0.1574, 0.0768, 0.3762, 0.0897], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,509][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0206, 0.0620, 0.7606, 0.0668, 0.0900], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,510][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.6707, 0.1034, 0.0477, 0.1155, 0.0627], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,511][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0158, 0.1694, 0.0694, 0.7146, 0.0309], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,512][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0848, 0.2321, 0.2473, 0.1936, 0.2421], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,514][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0037, 0.1074, 0.0014, 0.0597, 0.8279], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:47,521][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.9403, 0.0288, 0.0107, 0.0099, 0.0055, 0.0049], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,522][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.4870, 0.3749, 0.0618, 0.0502, 0.0193, 0.0067], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,523][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.2259, 0.1417, 0.1443, 0.1545, 0.1717, 0.1619], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,523][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.2326, 0.1564, 0.1395, 0.1461, 0.1425, 0.1830], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,524][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0619, 0.1761, 0.2007, 0.1560, 0.2186, 0.1868], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,528][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0398, 0.1301, 0.0196, 0.4453, 0.0081, 0.3570], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,534][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.2463, 0.0722, 0.0943, 0.2455, 0.0447, 0.2970], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,534][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0607, 0.0749, 0.2854, 0.0625, 0.0476, 0.4690], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,535][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.5097, 0.1333, 0.0757, 0.0632, 0.0704, 0.1476], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,536][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0154, 0.1073, 0.2052, 0.5594, 0.0741, 0.0386], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,537][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0654, 0.1863, 0.2022, 0.1516, 0.2002, 0.1943], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,538][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ were] are: tensor([1.7763e-03, 3.2932e-03, 1.4838e-04, 7.3260e-03, 3.1708e-04, 9.8714e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:47,544][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.9265, 0.0326, 0.0127, 0.0114, 0.0061, 0.0076, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,546][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.5018, 0.1343, 0.1701, 0.1073, 0.0189, 0.0655, 0.0020],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,547][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.2098, 0.1198, 0.1155, 0.1280, 0.1388, 0.1351, 0.1529],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,548][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.2142, 0.1437, 0.1037, 0.1204, 0.1210, 0.1537, 0.1433],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,549][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0520, 0.1523, 0.1514, 0.1313, 0.1725, 0.1529, 0.1875],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,549][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0354, 0.3488, 0.0512, 0.2645, 0.0140, 0.2312, 0.0550],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,554][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.1986, 0.0787, 0.0826, 0.2531, 0.0230, 0.3262, 0.0378],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,558][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0265, 0.0366, 0.2351, 0.0352, 0.0535, 0.6051, 0.0080],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,559][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.5160, 0.0886, 0.0470, 0.0523, 0.0575, 0.1945, 0.0441],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,560][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0096, 0.1540, 0.0623, 0.3374, 0.0615, 0.0201, 0.3550],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,561][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0532, 0.1485, 0.1633, 0.1194, 0.1604, 0.1550, 0.2003],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,561][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([1.4629e-02, 9.2942e-02, 1.9862e-04, 6.5578e-02, 1.8912e-03, 9.5668e-04,
        8.2380e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:47,566][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.8980, 0.0378, 0.0194, 0.0146, 0.0100, 0.0108, 0.0048, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,571][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.4800, 0.2718, 0.1206, 0.0560, 0.0254, 0.0293, 0.0129, 0.0039],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,572][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.1818, 0.1043, 0.1069, 0.1129, 0.1251, 0.1174, 0.1375, 0.1141],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,572][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.1855, 0.1161, 0.1020, 0.1020, 0.1097, 0.1270, 0.1393, 0.1184],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,573][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0471, 0.1218, 0.1389, 0.1080, 0.1492, 0.1272, 0.1631, 0.1448],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,574][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0261, 0.0970, 0.0174, 0.1226, 0.0091, 0.0445, 0.0474, 0.6360],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,578][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.1498, 0.0523, 0.0467, 0.2249, 0.0244, 0.3784, 0.0777, 0.0458],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,585][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1158, 0.0706, 0.1503, 0.0360, 0.0333, 0.4220, 0.1190, 0.0530],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,587][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.4960, 0.0706, 0.0429, 0.0588, 0.0594, 0.1347, 0.0647, 0.0729],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,587][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0138, 0.0632, 0.0807, 0.1544, 0.0639, 0.0322, 0.5815, 0.0103],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,588][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0443, 0.1237, 0.1404, 0.1028, 0.1360, 0.1304, 0.1749, 0.1476],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,589][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ about] are: tensor([1.7458e-03, 8.2288e-03, 5.6636e-06, 3.5718e-03, 1.0279e-04, 8.2836e-05,
        2.1962e-04, 9.8604e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:47,590][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.8969, 0.0378, 0.0179, 0.0144, 0.0090, 0.0093, 0.0042, 0.0041, 0.0064],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,595][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.4389, 0.2297, 0.1227, 0.0751, 0.0106, 0.0370, 0.0120, 0.0729, 0.0011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,599][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.1562, 0.0968, 0.0973, 0.1046, 0.1142, 0.1045, 0.1263, 0.1055, 0.0947],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,600][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.1632, 0.1044, 0.0869, 0.0949, 0.0979, 0.1144, 0.1193, 0.1274, 0.0916],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,601][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0402, 0.1132, 0.1188, 0.1019, 0.1335, 0.1107, 0.1491, 0.1336, 0.0991],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,601][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0242, 0.0929, 0.0033, 0.5915, 0.0030, 0.0765, 0.0776, 0.0718, 0.0592],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,602][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.3034, 0.0534, 0.0401, 0.1947, 0.0261, 0.2049, 0.0528, 0.0528, 0.0717],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,607][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0102, 0.0282, 0.3170, 0.0227, 0.0520, 0.4063, 0.0822, 0.0689, 0.0124],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,612][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.4119, 0.0530, 0.0291, 0.0543, 0.0505, 0.1657, 0.0768, 0.0894, 0.0693],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,612][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0041, 0.0807, 0.0485, 0.2593, 0.0625, 0.0084, 0.5022, 0.0050, 0.0293],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,613][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0409, 0.1120, 0.1209, 0.0921, 0.1206, 0.1130, 0.1504, 0.1336, 0.1165],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,614][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ going] are: tensor([6.9174e-04, 8.8730e-03, 8.7637e-06, 5.2600e-03, 1.1782e-04, 3.1785e-04,
        1.9264e-04, 2.6646e-04, 9.8427e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:47,615][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8837, 0.0365, 0.0204, 0.0148, 0.0109, 0.0096, 0.0049, 0.0047, 0.0072,
        0.0074], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,619][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5997, 0.0779, 0.1742, 0.0370, 0.0145, 0.0386, 0.0163, 0.0395, 0.0015,
        0.0008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,624][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1407, 0.0843, 0.0890, 0.0926, 0.1058, 0.1009, 0.1124, 0.0953, 0.0856,
        0.0932], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,625][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1498, 0.0880, 0.0822, 0.0817, 0.0928, 0.1144, 0.1088, 0.1098, 0.0837,
        0.0889], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,626][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0411, 0.0976, 0.1102, 0.0901, 0.1247, 0.1069, 0.1322, 0.1167, 0.0915,
        0.0892], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,627][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0297, 0.0626, 0.0034, 0.3005, 0.0018, 0.0769, 0.0629, 0.0597, 0.0570,
        0.3456], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,628][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2498, 0.0521, 0.0344, 0.1262, 0.0154, 0.1589, 0.0608, 0.0453, 0.1049,
        0.1523], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,633][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0107, 0.0448, 0.0495, 0.0253, 0.0196, 0.5027, 0.1709, 0.1172, 0.0485,
        0.0108], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,637][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4573, 0.0359, 0.0511, 0.0363, 0.0531, 0.0888, 0.0778, 0.0861, 0.0444,
        0.0692], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,638][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0097, 0.0228, 0.0510, 0.2524, 0.0343, 0.0200, 0.5730, 0.0025, 0.0335,
        0.0008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,639][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0352, 0.0992, 0.1134, 0.0819, 0.1115, 0.1073, 0.1403, 0.1208, 0.1061,
        0.0844], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,639][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.3519e-02, 1.9335e-02, 3.9633e-05, 4.4800e-02, 3.0532e-04, 1.2249e-03,
        5.9282e-05, 6.2309e-03, 5.3640e-04, 9.0395e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:47,640][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.8521, 0.0397, 0.0249, 0.0168, 0.0139, 0.0122, 0.0062, 0.0058, 0.0090,
        0.0093, 0.0102], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,645][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.7384, 0.1138, 0.0429, 0.0308, 0.0054, 0.0269, 0.0091, 0.0250, 0.0022,
        0.0046, 0.0009], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,650][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1299, 0.0774, 0.0826, 0.0862, 0.0957, 0.0911, 0.1058, 0.0867, 0.0785,
        0.0833, 0.0828], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,651][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1426, 0.0811, 0.0787, 0.0787, 0.0842, 0.0991, 0.1047, 0.0974, 0.0748,
        0.0717, 0.0870], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,651][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0359, 0.0884, 0.1029, 0.0808, 0.1116, 0.0951, 0.1267, 0.1077, 0.0830,
        0.0758, 0.0920], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,652][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0521, 0.1601, 0.0410, 0.3062, 0.0084, 0.1283, 0.0349, 0.0648, 0.0778,
        0.0930, 0.0336], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,653][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0640, 0.0181, 0.0172, 0.0473, 0.0154, 0.0687, 0.0190, 0.0251, 0.0216,
        0.0590, 0.6447], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,658][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0033, 0.0034, 0.0525, 0.0021, 0.0246, 0.6002, 0.0826, 0.1350, 0.0637,
        0.0021, 0.0305], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,662][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.3249, 0.0414, 0.0428, 0.0327, 0.0517, 0.0778, 0.0662, 0.0700, 0.0383,
        0.0617, 0.1924], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,663][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.8044e-03, 1.1223e-02, 4.2403e-02, 2.3490e-01, 2.8471e-02, 1.4062e-02,
        6.2366e-01, 1.2685e-03, 2.2948e-02, 3.4407e-04, 1.5915e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,664][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0334, 0.0910, 0.1044, 0.0763, 0.1026, 0.0984, 0.1300, 0.1111, 0.0972,
        0.0765, 0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,665][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.0231e-02, 1.0264e-02, 4.7286e-04, 3.7070e-02, 1.1009e-03, 1.8953e-03,
        3.2622e-04, 7.1027e-03, 6.9726e-04, 1.4162e-02, 8.9668e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:47,666][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.8646, 0.0397, 0.0202, 0.0153, 0.0097, 0.0103, 0.0045, 0.0044, 0.0069,
        0.0075, 0.0081, 0.0087], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,668][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ store] are: tensor([5.0992e-01, 1.5362e-01, 1.0620e-01, 5.3759e-02, 2.7469e-02, 4.8556e-02,
        1.5820e-02, 5.9211e-02, 6.9075e-03, 4.6886e-03, 1.3566e-02, 2.7781e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,675][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1293, 0.0739, 0.0722, 0.0795, 0.0860, 0.0826, 0.0947, 0.0785, 0.0691,
        0.0770, 0.0728, 0.0843], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,676][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1260, 0.0866, 0.0680, 0.0798, 0.0729, 0.0892, 0.0917, 0.0891, 0.0682,
        0.0707, 0.0725, 0.0853], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,677][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0285, 0.0855, 0.0849, 0.0765, 0.0950, 0.0852, 0.1069, 0.0964, 0.0705,
        0.0698, 0.0829, 0.1181], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,678][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0071, 0.0256, 0.0106, 0.0090, 0.0099, 0.0051, 0.0109, 0.0244, 0.0109,
        0.0449, 0.0052, 0.8363], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,678][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0690, 0.0307, 0.0094, 0.0957, 0.0119, 0.0536, 0.0022, 0.0105, 0.0122,
        0.1068, 0.5965, 0.0015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,683][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0011, 0.0154, 0.3195, 0.0208, 0.0226, 0.4705, 0.0493, 0.0457, 0.0189,
        0.0085, 0.0189, 0.0090], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,688][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.2524, 0.0381, 0.0249, 0.0317, 0.0427, 0.1460, 0.0378, 0.0698, 0.0366,
        0.0699, 0.2315, 0.0185], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,689][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0094, 0.0376, 0.0324, 0.1073, 0.0566, 0.0340, 0.4482, 0.0113, 0.0802,
        0.0013, 0.0244, 0.1573], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,690][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0302, 0.0849, 0.0930, 0.0696, 0.0905, 0.0886, 0.1158, 0.0994, 0.0864,
        0.0684, 0.0707, 0.1025], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,690][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.5130e-03, 1.3068e-02, 2.0539e-05, 1.0707e-02, 1.6128e-04, 2.8776e-04,
        1.0527e-05, 1.1035e-03, 3.4873e-05, 1.0503e-02, 1.3838e-04, 9.6245e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:47,691][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.8572, 0.0328, 0.0211, 0.0135, 0.0125, 0.0094, 0.0053, 0.0050, 0.0076,
        0.0076, 0.0086, 0.0095, 0.0098], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,693][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([8.0757e-01, 4.3236e-02, 5.8873e-02, 8.9909e-03, 8.8194e-03, 9.7309e-03,
        3.6902e-02, 1.9892e-02, 3.3716e-03, 8.9411e-04, 1.1683e-03, 4.0135e-04,
        1.4842e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,701][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1108, 0.0644, 0.0703, 0.0724, 0.0824, 0.0773, 0.0874, 0.0723, 0.0664,
        0.0711, 0.0685, 0.0813, 0.0755], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,701][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1272, 0.0734, 0.0667, 0.0749, 0.0746, 0.0818, 0.0919, 0.0820, 0.0688,
        0.0682, 0.0659, 0.0872, 0.0374], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,702][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0291, 0.0705, 0.0877, 0.0657, 0.0947, 0.0762, 0.1016, 0.0846, 0.0713,
        0.0622, 0.0736, 0.1103, 0.0726], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,703][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0335, 0.1291, 0.0920, 0.0936, 0.0303, 0.2027, 0.0091, 0.0169, 0.0895,
        0.2873, 0.0109, 0.0037, 0.0015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,704][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0175, 0.0171, 0.0193, 0.0374, 0.0078, 0.0348, 0.0127, 0.0100, 0.0180,
        0.0560, 0.7190, 0.0010, 0.0493], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,709][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0020, 0.0217, 0.0844, 0.0311, 0.0816, 0.2838, 0.0821, 0.0826, 0.0177,
        0.0205, 0.0496, 0.2083, 0.0347], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,713][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3122, 0.0643, 0.0503, 0.0296, 0.0520, 0.0785, 0.0763, 0.0557, 0.0321,
        0.0235, 0.0869, 0.0304, 0.1082], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,714][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([5.4615e-03, 1.4422e-02, 6.4799e-02, 1.1666e-01, 3.2781e-02, 1.4690e-02,
        5.1105e-01, 1.4941e-03, 2.4505e-02, 3.1289e-04, 1.1318e-02, 1.9097e-01,
        1.1529e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,715][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0270, 0.0771, 0.0873, 0.0643, 0.0866, 0.0827, 0.1095, 0.0942, 0.0829,
        0.0651, 0.0653, 0.1008, 0.0572], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,716][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0776, 0.1023, 0.0043, 0.2746, 0.0269, 0.0599, 0.0050, 0.0592, 0.0109,
        0.2426, 0.0534, 0.0027, 0.0805], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:47,717][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.8111, 0.0485, 0.0212, 0.0185, 0.0103, 0.0139, 0.0056, 0.0056, 0.0090,
        0.0105, 0.0108, 0.0111, 0.0127, 0.0112], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,722][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.4737, 0.1356, 0.0606, 0.0626, 0.0038, 0.0601, 0.0161, 0.1444, 0.0063,
        0.0071, 0.0143, 0.0051, 0.0082, 0.0020], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,726][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.1062, 0.0641, 0.0605, 0.0699, 0.0712, 0.0709, 0.0801, 0.0667, 0.0596,
        0.0663, 0.0621, 0.0715, 0.0699, 0.0810], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,727][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.1189, 0.0755, 0.0567, 0.0723, 0.0599, 0.0895, 0.0853, 0.0805, 0.0596,
        0.0655, 0.0620, 0.0751, 0.0381, 0.0611], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,728][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0231, 0.0703, 0.0720, 0.0639, 0.0803, 0.0725, 0.0879, 0.0799, 0.0583,
        0.0558, 0.0674, 0.0974, 0.0711, 0.1001], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,729][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0011, 0.0053, 0.1125, 0.0213, 0.0592, 0.0149, 0.2350, 0.1067, 0.0419,
        0.0355, 0.0024, 0.0793, 0.0346, 0.2503], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,730][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0665, 0.0358, 0.0137, 0.0871, 0.0179, 0.0550, 0.0081, 0.0184, 0.0095,
        0.0864, 0.5062, 0.0006, 0.0816, 0.0133], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,736][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0016, 0.0101, 0.1434, 0.0119, 0.0205, 0.2185, 0.1004, 0.0781, 0.0731,
        0.0215, 0.0251, 0.0429, 0.2106, 0.0423], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,739][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.1920, 0.0411, 0.0155, 0.0162, 0.0120, 0.1883, 0.0375, 0.0309, 0.0299,
        0.0408, 0.1820, 0.0219, 0.1764, 0.0153], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,740][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ James] are: tensor([1.8444e-03, 1.9074e-02, 3.5401e-02, 5.1728e-02, 1.6352e-02, 7.7180e-03,
        6.2845e-01, 3.6869e-03, 2.9659e-02, 5.0586e-04, 1.2773e-02, 1.7698e-01,
        9.8526e-03, 5.9764e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,740][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0276, 0.0731, 0.0791, 0.0612, 0.0777, 0.0770, 0.0985, 0.0845, 0.0749,
        0.0604, 0.0604, 0.0900, 0.0529, 0.0826], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,741][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ James] are: tensor([1.6360e-04, 2.1095e-02, 1.4991e-03, 2.1355e-03, 3.9271e-01, 3.0765e-04,
        1.1597e-04, 1.6501e-04, 4.2117e-04, 9.0630e-04, 1.0576e-04, 1.0008e-04,
        8.5688e-02, 4.9459e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:47,743][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.9044, 0.0324, 0.0103, 0.0108, 0.0047, 0.0053, 0.0021, 0.0023, 0.0033,
        0.0041, 0.0041, 0.0040, 0.0054, 0.0042, 0.0027], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,749][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.4982, 0.1871, 0.1162, 0.0563, 0.0247, 0.0323, 0.0140, 0.0327, 0.0037,
        0.0094, 0.0078, 0.0031, 0.0049, 0.0068, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,751][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0979, 0.0589, 0.0576, 0.0628, 0.0684, 0.0643, 0.0754, 0.0623, 0.0571,
        0.0613, 0.0564, 0.0682, 0.0633, 0.0769, 0.0695], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,752][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.1067, 0.0668, 0.0552, 0.0647, 0.0602, 0.0793, 0.0779, 0.0765, 0.0546,
        0.0662, 0.0601, 0.0687, 0.0357, 0.0607, 0.0667], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,753][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0221, 0.0648, 0.0660, 0.0569, 0.0730, 0.0639, 0.0830, 0.0750, 0.0580,
        0.0522, 0.0609, 0.0875, 0.0633, 0.0904, 0.0831], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,754][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0167, 0.1995, 0.0080, 0.1012, 0.0025, 0.1545, 0.0296, 0.0290, 0.1023,
        0.2956, 0.0199, 0.0072, 0.0074, 0.0018, 0.0248], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,757][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0713, 0.0198, 0.0084, 0.0634, 0.0057, 0.0715, 0.0111, 0.0198, 0.0153,
        0.0740, 0.5543, 0.0012, 0.0651, 0.0046, 0.0145], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,764][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0135, 0.0353, 0.0845, 0.0305, 0.0198, 0.1004, 0.0436, 0.1130, 0.0359,
        0.0065, 0.0178, 0.0598, 0.1369, 0.0441, 0.2584], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,765][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.2358, 0.0389, 0.0282, 0.0187, 0.0334, 0.1004, 0.0361, 0.0373, 0.0347,
        0.0403, 0.1368, 0.0283, 0.1447, 0.0409, 0.0456], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,766][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([2.0256e-03, 2.3028e-02, 2.7606e-02, 2.4547e-02, 3.5700e-02, 1.0898e-02,
        6.3900e-01, 4.3667e-03, 4.6390e-02, 4.3568e-04, 2.5819e-02, 1.2905e-01,
        6.7602e-03, 1.5058e-02, 9.3110e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,767][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0233, 0.0665, 0.0738, 0.0542, 0.0723, 0.0690, 0.0914, 0.0791, 0.0707,
        0.0540, 0.0544, 0.0827, 0.0476, 0.0761, 0.0851], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,768][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([6.6218e-04, 6.3457e-03, 1.1641e-05, 3.3257e-03, 1.3910e-04, 6.5798e-04,
        8.0570e-04, 1.0504e-03, 3.1343e-03, 2.8401e-03, 1.3663e-04, 6.4287e-05,
        1.1232e-02, 7.8613e-06, 9.6959e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:47,774][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.8778, 0.0346, 0.0135, 0.0125, 0.0064, 0.0069, 0.0029, 0.0031, 0.0047,
        0.0054, 0.0056, 0.0058, 0.0071, 0.0062, 0.0038, 0.0037],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,777][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.2197e-01, 7.4730e-02, 1.5669e-01, 3.3097e-02, 1.2619e-02, 3.5462e-02,
        1.2591e-02, 3.0291e-02, 1.2309e-03, 7.0494e-04, 4.5374e-03, 9.6202e-04,
        3.5417e-04, 3.1713e-03, 1.1259e-02, 3.2544e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,777][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0873, 0.0524, 0.0550, 0.0575, 0.0657, 0.0626, 0.0696, 0.0590, 0.0532,
        0.0579, 0.0549, 0.0650, 0.0603, 0.0747, 0.0657, 0.0591],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,778][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1007, 0.0558, 0.0541, 0.0534, 0.0617, 0.0750, 0.0716, 0.0717, 0.0549,
        0.0583, 0.0539, 0.0712, 0.0308, 0.0635, 0.0685, 0.0548],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,779][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0239, 0.0567, 0.0634, 0.0524, 0.0725, 0.0620, 0.0762, 0.0675, 0.0529,
        0.0518, 0.0591, 0.0851, 0.0579, 0.0887, 0.0758, 0.0539],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,782][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0044, 0.0747, 0.0031, 0.0849, 0.0009, 0.0946, 0.0087, 0.0083, 0.0299,
        0.4395, 0.0181, 0.0010, 0.0060, 0.0007, 0.0256, 0.1995],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,788][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1054, 0.0195, 0.0121, 0.0473, 0.0056, 0.0630, 0.0234, 0.0164, 0.0420,
        0.0581, 0.4685, 0.0033, 0.0411, 0.0047, 0.0389, 0.0505],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,789][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0048, 0.0268, 0.0190, 0.0156, 0.0097, 0.1566, 0.0539, 0.0436, 0.0171,
        0.0057, 0.0062, 0.0237, 0.0703, 0.0153, 0.5238, 0.0078],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,790][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2541, 0.0346, 0.0400, 0.0177, 0.0374, 0.0747, 0.0534, 0.0517, 0.0280,
        0.0304, 0.0836, 0.0419, 0.1479, 0.0359, 0.0437, 0.0252],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,791][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.3483e-03, 3.7474e-03, 1.8222e-02, 2.7097e-02, 2.1998e-02, 9.2572e-03,
        6.3682e-01, 9.9014e-04, 3.4258e-02, 1.1657e-04, 2.9383e-02, 1.9595e-01,
        2.4502e-03, 5.9948e-03, 1.1236e-02, 1.2559e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,792][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0219, 0.0613, 0.0700, 0.0508, 0.0690, 0.0664, 0.0869, 0.0746, 0.0656,
        0.0522, 0.0519, 0.0783, 0.0450, 0.0737, 0.0805, 0.0520],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,794][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0144e-02, 2.2093e-02, 3.3242e-05, 3.3211e-02, 1.9498e-04, 6.5474e-04,
        3.3054e-05, 2.4744e-03, 3.7024e-04, 7.4211e-01, 3.6146e-04, 5.6410e-05,
        3.4403e-02, 4.8855e-06, 1.2750e-04, 1.5373e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:47,800][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.8634, 0.0349, 0.0147, 0.0129, 0.0072, 0.0078, 0.0033, 0.0034, 0.0052,
        0.0058, 0.0062, 0.0063, 0.0075, 0.0068, 0.0043, 0.0040, 0.0063],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,802][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.5446, 0.0592, 0.1877, 0.0291, 0.0273, 0.0472, 0.0132, 0.0391, 0.0032,
        0.0055, 0.0127, 0.0018, 0.0011, 0.0082, 0.0138, 0.0027, 0.0035],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,803][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0851, 0.0514, 0.0509, 0.0551, 0.0601, 0.0567, 0.0670, 0.0559, 0.0501,
        0.0537, 0.0501, 0.0609, 0.0563, 0.0679, 0.0616, 0.0544, 0.0628],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,804][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0981, 0.0560, 0.0470, 0.0547, 0.0552, 0.0682, 0.0663, 0.0680, 0.0493,
        0.0555, 0.0515, 0.0636, 0.0292, 0.0574, 0.0640, 0.0515, 0.0644],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,805][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0199, 0.0554, 0.0587, 0.0489, 0.0639, 0.0561, 0.0741, 0.0644, 0.0508,
        0.0459, 0.0531, 0.0787, 0.0549, 0.0796, 0.0729, 0.0477, 0.0750],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,809][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0103, 0.0575, 0.0009, 0.1335, 0.0007, 0.0810, 0.0141, 0.0199, 0.0555,
        0.0397, 0.0141, 0.0122, 0.0481, 0.0021, 0.3064, 0.1422, 0.0617],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,814][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0636, 0.0164, 0.0080, 0.0880, 0.0062, 0.0452, 0.0107, 0.0235, 0.0164,
        0.0676, 0.4513, 0.0014, 0.0703, 0.0047, 0.0130, 0.0603, 0.0536],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,815][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ give] are: tensor([2.4221e-04, 1.1660e-03, 2.2573e-02, 1.1592e-03, 2.7856e-03, 8.3646e-02,
        1.8334e-02, 1.9469e-02, 8.2719e-03, 1.8008e-03, 1.9570e-03, 5.7369e-02,
        7.5452e-03, 6.3665e-03, 7.6057e-01, 3.2960e-03, 3.4481e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,816][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.2023, 0.0262, 0.0172, 0.0155, 0.0280, 0.1669, 0.0218, 0.0345, 0.0273,
        0.0297, 0.1342, 0.0201, 0.1258, 0.0305, 0.0565, 0.0240, 0.0396],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,817][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.5026e-03, 1.6067e-02, 1.2953e-02, 1.3603e-02, 3.3845e-02, 6.4113e-03,
        6.1030e-01, 5.0423e-03, 7.0590e-02, 3.8082e-04, 3.7583e-02, 1.1507e-01,
        6.0464e-03, 1.4625e-02, 1.3474e-02, 3.8548e-04, 4.2121e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,820][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0202, 0.0571, 0.0652, 0.0472, 0.0648, 0.0614, 0.0816, 0.0692, 0.0619,
        0.0476, 0.0482, 0.0750, 0.0422, 0.0689, 0.0763, 0.0473, 0.0660],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,824][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ give] are: tensor([6.0998e-04, 6.9550e-03, 1.7477e-06, 5.0415e-03, 2.6940e-05, 7.3573e-05,
        2.4483e-05, 2.1688e-04, 1.9826e-04, 1.9184e-03, 6.6281e-05, 3.2091e-05,
        7.9421e-03, 3.4020e-07, 1.2679e-03, 3.8739e-04, 9.7524e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:47,827][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.8451, 0.0349, 0.0170, 0.0131, 0.0086, 0.0080, 0.0037, 0.0037, 0.0058,
        0.0064, 0.0069, 0.0073, 0.0082, 0.0085, 0.0047, 0.0044, 0.0069, 0.0068],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,828][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.5912e-01, 1.2423e-01, 8.1137e-02, 2.3511e-02, 2.6115e-02, 4.0162e-02,
        1.0770e-02, 5.0391e-02, 3.2086e-03, 6.9326e-03, 1.0554e-02, 3.1679e-03,
        3.2184e-03, 1.0648e-02, 1.2260e-02, 3.9103e-03, 3.0126e-02, 5.3853e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,829][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0789, 0.0473, 0.0488, 0.0524, 0.0567, 0.0551, 0.0631, 0.0524, 0.0468,
        0.0508, 0.0491, 0.0581, 0.0541, 0.0648, 0.0584, 0.0517, 0.0582, 0.0532],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,830][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0899, 0.0518, 0.0485, 0.0492, 0.0558, 0.0666, 0.0632, 0.0637, 0.0465,
        0.0478, 0.0543, 0.0597, 0.0284, 0.0575, 0.0601, 0.0444, 0.0586, 0.0542],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,834][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0204, 0.0510, 0.0557, 0.0471, 0.0620, 0.0541, 0.0694, 0.0609, 0.0455,
        0.0439, 0.0526, 0.0759, 0.0524, 0.0766, 0.0680, 0.0453, 0.0691, 0.0501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,839][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0190, 0.0690, 0.0060, 0.1805, 0.0017, 0.0860, 0.0222, 0.0281, 0.0678,
        0.0671, 0.0197, 0.0047, 0.0325, 0.0014, 0.1145, 0.1421, 0.1267, 0.0112],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,840][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0315, 0.0124, 0.0050, 0.0264, 0.0058, 0.0317, 0.0080, 0.0133, 0.0112,
        0.0411, 0.4119, 0.0010, 0.0327, 0.0047, 0.0102, 0.0372, 0.0217, 0.2943],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,841][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0015, 0.0013, 0.0110, 0.0011, 0.0038, 0.0566, 0.0143, 0.0278, 0.0106,
        0.0013, 0.0053, 0.0297, 0.0219, 0.0086, 0.7961, 0.0026, 0.0045, 0.0018],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,842][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1833, 0.0238, 0.0266, 0.0169, 0.0254, 0.0753, 0.0336, 0.0367, 0.0203,
        0.0272, 0.0860, 0.0400, 0.1298, 0.0297, 0.0294, 0.0229, 0.0269, 0.1660],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,844][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.8620e-03, 3.4172e-03, 1.9450e-02, 3.3204e-02, 2.6791e-02, 1.0805e-02,
        6.1415e-01, 1.1579e-03, 3.0323e-02, 1.4478e-04, 1.6258e-02, 1.9384e-01,
        3.2995e-03, 8.7534e-03, 9.8428e-03, 1.5046e-04, 2.3719e-02, 2.8329e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,850][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0198, 0.0541, 0.0618, 0.0456, 0.0608, 0.0591, 0.0779, 0.0662, 0.0578,
        0.0456, 0.0466, 0.0707, 0.0403, 0.0651, 0.0728, 0.0454, 0.0637, 0.0467],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,852][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.2818e-03, 3.0336e-03, 3.8793e-05, 2.8901e-03, 4.7860e-05, 1.2335e-04,
        1.6167e-04, 5.2034e-04, 1.1265e-03, 1.0136e-02, 8.2150e-04, 1.9733e-05,
        4.5464e-03, 7.1761e-07, 1.8518e-04, 1.7976e-03, 7.4617e-05, 9.7019e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:47,853][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.8861, 0.0302, 0.0111, 0.0093, 0.0052, 0.0056, 0.0023, 0.0024, 0.0038,
        0.0044, 0.0047, 0.0048, 0.0057, 0.0054, 0.0030, 0.0029, 0.0047, 0.0047,
        0.0036], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,854][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([3.3764e-01, 1.4835e-01, 9.9769e-02, 5.7623e-02, 2.7112e-02, 5.7065e-02,
        2.5180e-02, 1.3194e-01, 1.0500e-02, 8.6643e-03, 1.5452e-02, 1.0177e-03,
        1.8679e-03, 6.1988e-03, 4.2065e-02, 3.6982e-03, 9.9836e-03, 1.5632e-02,
        2.4280e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,855][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0823, 0.0473, 0.0445, 0.0506, 0.0528, 0.0504, 0.0582, 0.0485, 0.0430,
        0.0487, 0.0446, 0.0526, 0.0508, 0.0593, 0.0540, 0.0494, 0.0556, 0.0477,
        0.0595], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,860][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0884, 0.0535, 0.0439, 0.0523, 0.0499, 0.0622, 0.0623, 0.0633, 0.0429,
        0.0509, 0.0433, 0.0585, 0.0279, 0.0507, 0.0590, 0.0472, 0.0560, 0.0442,
        0.0439], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,864][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0170, 0.0522, 0.0519, 0.0470, 0.0585, 0.0499, 0.0630, 0.0578, 0.0416,
        0.0415, 0.0492, 0.0681, 0.0512, 0.0723, 0.0621, 0.0431, 0.0661, 0.0450,
        0.0626], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,865][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0104, 0.0273, 0.0448, 0.0625, 0.0428, 0.1055, 0.0403, 0.0293, 0.1031,
        0.1637, 0.0081, 0.0799, 0.0084, 0.0396, 0.0749, 0.0715, 0.0434, 0.0087,
        0.0357], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,866][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0246, 0.0220, 0.0149, 0.0409, 0.0104, 0.0446, 0.0014, 0.0201, 0.0087,
        0.0442, 0.2668, 0.0006, 0.0443, 0.0088, 0.0061, 0.0430, 0.0346, 0.2678,
        0.0962], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,867][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0006, 0.0058, 0.1155, 0.0066, 0.0258, 0.1067, 0.0582, 0.0448, 0.0314,
        0.0074, 0.0277, 0.0857, 0.0512, 0.0513, 0.3355, 0.0122, 0.0224, 0.0086,
        0.0025], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,872][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0976, 0.0249, 0.0200, 0.0147, 0.0126, 0.3305, 0.0093, 0.0119, 0.0124,
        0.0115, 0.1617, 0.0058, 0.0662, 0.0116, 0.0266, 0.0086, 0.0115, 0.1393,
        0.0234], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,875][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([7.1352e-04, 6.5313e-03, 2.9853e-02, 1.0309e-02, 6.6535e-02, 9.0164e-03,
        5.5989e-01, 1.9378e-03, 3.6826e-02, 6.0462e-05, 3.1609e-03, 1.8619e-01,
        1.1442e-03, 2.8066e-02, 9.0691e-03, 6.5911e-05, 1.9980e-02, 5.2711e-04,
        3.0121e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,877][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0188, 0.0535, 0.0581, 0.0444, 0.0573, 0.0550, 0.0724, 0.0622, 0.0539,
        0.0439, 0.0438, 0.0660, 0.0385, 0.0606, 0.0678, 0.0435, 0.0584, 0.0434,
        0.0587], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,878][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([3.7891e-03, 3.6169e-02, 5.7624e-04, 2.6583e-02, 3.2397e-03, 1.9736e-02,
        2.1022e-04, 1.6274e-03, 5.2358e-03, 2.1260e-02, 8.9322e-04, 1.7144e-03,
        2.3076e-02, 4.0208e-05, 2.4978e-03, 4.1870e-03, 3.8635e-03, 1.2176e-03,
        8.4408e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:47,879][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.9000, 0.0277, 0.0097, 0.0088, 0.0044, 0.0048, 0.0019, 0.0020, 0.0031,
        0.0036, 0.0038, 0.0039, 0.0048, 0.0043, 0.0025, 0.0024, 0.0038, 0.0036,
        0.0027, 0.0019], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,880][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.3820e-01, 7.4584e-02, 1.8857e-01, 3.9128e-02, 1.8979e-02, 4.3100e-02,
        1.2774e-02, 3.9273e-02, 1.3185e-03, 8.7786e-04, 6.8855e-03, 1.4074e-03,
        4.1025e-04, 5.2233e-03, 1.2419e-02, 4.3579e-04, 8.8578e-03, 5.0713e-03,
        2.0797e-03, 3.9871e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,885][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0686, 0.0416, 0.0441, 0.0455, 0.0524, 0.0500, 0.0555, 0.0467, 0.0423,
        0.0459, 0.0435, 0.0519, 0.0479, 0.0596, 0.0522, 0.0468, 0.0539, 0.0469,
        0.0592, 0.0454], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,889][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0827, 0.0449, 0.0439, 0.0432, 0.0501, 0.0609, 0.0583, 0.0578, 0.0441,
        0.0474, 0.0434, 0.0574, 0.0252, 0.0515, 0.0555, 0.0446, 0.0550, 0.0434,
        0.0465, 0.0439], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,890][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0187, 0.0447, 0.0500, 0.0413, 0.0573, 0.0489, 0.0598, 0.0529, 0.0415,
        0.0407, 0.0467, 0.0669, 0.0458, 0.0703, 0.0594, 0.0423, 0.0650, 0.0451,
        0.0620, 0.0407], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,891][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0062, 0.0579, 0.0021, 0.1139, 0.0010, 0.1054, 0.0081, 0.0087, 0.0283,
        0.1850, 0.0164, 0.0003, 0.0070, 0.0007, 0.0519, 0.2484, 0.0405, 0.0150,
        0.0016, 0.1015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,892][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0620, 0.0119, 0.0068, 0.0287, 0.0032, 0.0340, 0.0132, 0.0100, 0.0247,
        0.0353, 0.2820, 0.0019, 0.0252, 0.0027, 0.0219, 0.0308, 0.0695, 0.2925,
        0.0187, 0.0250], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,896][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0033, 0.0144, 0.0138, 0.0083, 0.0068, 0.1098, 0.0470, 0.0387, 0.0133,
        0.0039, 0.0041, 0.0215, 0.0550, 0.0121, 0.6066, 0.0061, 0.0130, 0.0020,
        0.0175, 0.0029], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,902][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1659, 0.0211, 0.0291, 0.0095, 0.0227, 0.0649, 0.0365, 0.0346, 0.0187,
        0.0168, 0.0551, 0.0300, 0.1210, 0.0222, 0.0318, 0.0135, 0.0245, 0.2003,
        0.0689, 0.0129], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,903][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.9972e-04, 1.1077e-03, 1.1282e-02, 1.4398e-02, 1.6476e-02, 5.2087e-03,
        5.7927e-01, 3.9815e-04, 2.2800e-02, 3.6520e-05, 1.5840e-02, 1.5802e-01,
        7.8738e-04, 3.9551e-03, 8.1401e-03, 4.3314e-05, 2.7391e-02, 2.6430e-03,
        1.3129e-01, 1.8234e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,904][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0178, 0.0491, 0.0561, 0.0407, 0.0553, 0.0533, 0.0698, 0.0597, 0.0524,
        0.0419, 0.0416, 0.0627, 0.0361, 0.0591, 0.0645, 0.0417, 0.0572, 0.0414,
        0.0582, 0.0415], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,904][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1523e-02, 2.3331e-02, 2.5075e-05, 2.8943e-02, 2.6280e-04, 7.3006e-04,
        5.3348e-05, 3.5555e-03, 4.5151e-04, 6.0666e-01, 3.5071e-04, 5.8983e-05,
        3.2791e-02, 9.9724e-06, 2.5326e-04, 1.2143e-01, 1.7970e-04, 6.0739e-04,
        9.0003e-05, 1.6870e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:47,932][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:47,933][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,933][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,934][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,935][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,935][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,936][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,937][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,937][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,938][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,939][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,939][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,940][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:47,941][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9885, 0.0115], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,941][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1852, 0.8148], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,942][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5331, 0.4669], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,943][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9073, 0.0927], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,944][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6539, 0.3461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,944][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,945][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5004, 0.4996], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,946][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,947][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,947][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5013, 0.4987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,950][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,954][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0404, 0.9596], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:47,956][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.4004, 0.1338, 0.4658], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,957][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0563, 0.4830, 0.4607], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,957][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.2411, 0.4060, 0.3529], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,958][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.8320, 0.0729, 0.0951], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,959][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.4452, 0.2342, 0.3206], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,963][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.3334, 0.3331, 0.3335], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,970][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.3335, 0.3330, 0.3336], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,971][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.3334, 0.3331, 0.3334], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,972][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.3329, 0.3331, 0.3340], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,973][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.3345, 0.3327, 0.3327], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,974][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.3336, 0.3332, 0.3332], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,974][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0117, 0.4919, 0.4964], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:47,979][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1261, 0.0780, 0.7004, 0.0955], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,984][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0509, 0.2934, 0.3752, 0.2805], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,985][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2113, 0.2618, 0.3279, 0.1989], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,986][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4981, 0.1345, 0.2332, 0.1342], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,987][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3606, 0.1958, 0.2674, 0.1762], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,987][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2500, 0.2498, 0.2501, 0.2502], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,990][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2501, 0.2497, 0.2502, 0.2501], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,997][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2501, 0.2499, 0.2501, 0.2500], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,998][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2496, 0.2498, 0.2504, 0.2501], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:47,999][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2506, 0.2492, 0.2492, 0.2509], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,000][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2502, 0.2500, 0.2499, 0.2499], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,000][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0015, 0.0370, 0.0360, 0.9254], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,002][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0257, 0.0235, 0.4207, 0.0842, 0.4459], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,009][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0267, 0.1984, 0.2317, 0.2844, 0.2587], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,011][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1258, 0.2585, 0.2137, 0.1566, 0.2454], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,011][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.4996, 0.0986, 0.1789, 0.1007, 0.1223], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,012][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.2747, 0.1461, 0.2077, 0.1351, 0.2364], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,013][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.2000, 0.1998, 0.2000, 0.2001, 0.2001], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,014][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.2000, 0.1997, 0.2001, 0.2001, 0.2001], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,019][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.2001, 0.1999, 0.2001, 0.2000, 0.1999], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,023][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.1996, 0.1997, 0.2002, 0.2000, 0.2006], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,024][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.2005, 0.1995, 0.1995, 0.2008, 0.1997], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,025][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.2002, 0.2000, 0.1999, 0.1999, 0.2000], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,026][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([5.1214e-04, 1.7091e-02, 1.5731e-02, 9.0580e-01, 6.0868e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,026][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.6877, 0.0161, 0.0096, 0.1882, 0.0748, 0.0237], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,029][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0244, 0.1598, 0.1660, 0.1903, 0.2367, 0.2228], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,036][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1004, 0.2170, 0.1956, 0.1205, 0.2350, 0.1315], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,037][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.6363, 0.0625, 0.0922, 0.0565, 0.0745, 0.0780], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,038][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.2404, 0.1281, 0.1724, 0.1145, 0.1931, 0.1515], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,039][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1666, 0.1665, 0.1667, 0.1667, 0.1668, 0.1667], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,039][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.1667, 0.1664, 0.1667, 0.1667, 0.1667, 0.1667], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,044][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.1667, 0.1666, 0.1667, 0.1667, 0.1666, 0.1667], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,049][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1663, 0.1664, 0.1668, 0.1667, 0.1672, 0.1666], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,050][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.1671, 0.1662, 0.1662, 0.1673, 0.1664, 0.1668], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,051][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.1668, 0.1666, 0.1666, 0.1666, 0.1667, 0.1666], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,052][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([1.0555e-04, 3.9665e-03, 5.4533e-03, 1.1732e-01, 1.0698e-02, 8.6246e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,052][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0029, 0.0010, 0.0349, 0.0042, 0.3443, 0.5986, 0.0141],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,057][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0142, 0.1183, 0.1511, 0.1940, 0.1788, 0.2834, 0.0602],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,062][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.1125, 0.1954, 0.1632, 0.1018, 0.1944, 0.1225, 0.1101],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,063][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.7024, 0.0402, 0.0633, 0.0399, 0.0487, 0.0432, 0.0623],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,064][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.2196, 0.1182, 0.1491, 0.1028, 0.1636, 0.1308, 0.1158],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,065][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.1428, 0.1427, 0.1429, 0.1429, 0.1430, 0.1429, 0.1427],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,065][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.1429, 0.1427, 0.1429, 0.1429, 0.1429, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,070][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.1429, 0.1428, 0.1429, 0.1429, 0.1428, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,075][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.1426, 0.1427, 0.1430, 0.1429, 0.1433, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,076][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.1432, 0.1424, 0.1424, 0.1434, 0.1426, 0.1430, 0.1430],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,077][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.1430, 0.1428, 0.1428, 0.1428, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,078][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([4.1243e-05, 1.8313e-03, 1.5091e-03, 1.1030e-01, 5.3628e-03, 8.4509e-01,
        3.5871e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,078][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0127, 0.0046, 0.0133, 0.0297, 0.0245, 0.3011, 0.5945, 0.0195],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,083][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0174, 0.1111, 0.1270, 0.1458, 0.1672, 0.2066, 0.0851, 0.1399],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,088][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.1028, 0.1565, 0.1719, 0.0850, 0.1871, 0.0954, 0.1088, 0.0926],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,089][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.6438, 0.0442, 0.0640, 0.0401, 0.0492, 0.0452, 0.0669, 0.0467],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,090][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.1920, 0.1070, 0.1326, 0.0951, 0.1489, 0.1167, 0.1029, 0.1050],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,091][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.1250, 0.1249, 0.1250, 0.1251, 0.1251, 0.1251, 0.1249, 0.1249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,092][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.1250, 0.1249, 0.1251, 0.1251, 0.1251, 0.1251, 0.1249, 0.1249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,097][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.1250, 0.1249, 0.1251, 0.1250, 0.1250, 0.1251, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,101][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.1248, 0.1248, 0.1251, 0.1250, 0.1254, 0.1249, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,102][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.1253, 0.1246, 0.1246, 0.1255, 0.1248, 0.1251, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,103][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.1251, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,104][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([1.8030e-04, 4.7407e-03, 4.0772e-03, 1.3280e-01, 9.9248e-03, 7.6874e-01,
        5.0330e-02, 2.9211e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,104][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([2.2028e-03, 3.0500e-04, 8.7169e-04, 1.0510e-03, 3.6179e-03, 9.2290e-01,
        9.8376e-04, 6.0534e-02, 7.5309e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,109][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0120, 0.0940, 0.1065, 0.1382, 0.1262, 0.2042, 0.0687, 0.2117, 0.0386],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,114][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0655, 0.1385, 0.1437, 0.0777, 0.1545, 0.0690, 0.0948, 0.0887, 0.1676],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,115][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.6287, 0.0438, 0.0586, 0.0390, 0.0444, 0.0418, 0.0631, 0.0430, 0.0375],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,116][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.1694, 0.0959, 0.1226, 0.0878, 0.1385, 0.1059, 0.0923, 0.0936, 0.0940],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,117][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.1111, 0.1110, 0.1111, 0.1112, 0.1112, 0.1112, 0.1110, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,118][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.1111, 0.1110, 0.1112, 0.1112, 0.1112, 0.1112, 0.1111, 0.1110, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,123][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.1111, 0.1111, 0.1112, 0.1111, 0.1111, 0.1112, 0.1111, 0.1110, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,127][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1109, 0.1110, 0.1112, 0.1111, 0.1115, 0.1110, 0.1111, 0.1111, 0.1112],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,128][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.1114, 0.1108, 0.1108, 0.1116, 0.1109, 0.1112, 0.1112, 0.1110, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,129][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,130][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([7.8977e-05, 2.5450e-03, 2.0173e-03, 1.0568e-01, 6.2150e-03, 8.0334e-01,
        3.8579e-02, 1.9735e-02, 2.1810e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,131][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.8662e-04, 8.2869e-05, 2.4894e-04, 1.7516e-04, 6.5202e-04, 4.0854e-02,
        1.7640e-03, 9.8738e-03, 9.4564e-01, 2.3639e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,135][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0163, 0.0829, 0.1117, 0.1166, 0.1306, 0.1708, 0.0791, 0.1588, 0.0491,
        0.0839], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,140][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0700, 0.1052, 0.1327, 0.0609, 0.1581, 0.0866, 0.0820, 0.0760, 0.1518,
        0.0767], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,141][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4419, 0.0548, 0.0803, 0.0542, 0.0616, 0.0635, 0.0695, 0.0621, 0.0560,
        0.0562], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,142][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1704, 0.0963, 0.1115, 0.0816, 0.1174, 0.0950, 0.0874, 0.0909, 0.0901,
        0.0595], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,143][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1000, 0.0999, 0.1000, 0.1001, 0.1001, 0.1001, 0.0999, 0.0999, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,144][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1000, 0.0999, 0.1001, 0.1000, 0.1000, 0.1001, 0.1000, 0.0999, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,149][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1000, 0.0999, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0999, 0.1000,
        0.1000], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,153][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0998, 0.0999, 0.1001, 0.1000, 0.1003, 0.0999, 0.1000, 0.1000, 0.1001,
        0.1000], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,154][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1002, 0.0997, 0.0997, 0.1003, 0.0998, 0.1000, 0.1001, 0.0999, 0.0999,
        0.1004], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,155][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1001, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.1000, 0.0999,
        0.1000], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,156][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.7548e-04, 4.3370e-03, 4.5085e-03, 1.0019e-01, 9.1047e-03, 5.8537e-01,
        4.9788e-02, 2.2797e-02, 2.5726e-02, 1.9800e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,157][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0062, 0.0032, 0.0087, 0.0259, 0.0254, 0.2419, 0.0222, 0.1455, 0.1047,
        0.3858, 0.0303], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,162][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0149, 0.0790, 0.0846, 0.1059, 0.1063, 0.1591, 0.0672, 0.1342, 0.0490,
        0.1029, 0.0967], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,166][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0638, 0.0985, 0.1275, 0.0603, 0.1361, 0.0725, 0.0846, 0.0646, 0.1382,
        0.0595, 0.0944], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,167][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4547, 0.0521, 0.0757, 0.0471, 0.0565, 0.0578, 0.0681, 0.0502, 0.0481,
        0.0461, 0.0437], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,168][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1469, 0.0835, 0.1079, 0.0781, 0.1230, 0.0948, 0.0819, 0.0833, 0.0827,
        0.0569, 0.0609], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,169][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0909, 0.0908, 0.0909, 0.0910, 0.0910, 0.0910, 0.0908, 0.0909, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,170][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0909, 0.0908, 0.0910, 0.0909, 0.0909, 0.0910, 0.0909, 0.0908, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,175][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0908, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,179][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0907, 0.0908, 0.0910, 0.0909, 0.0912, 0.0909, 0.0909, 0.0909, 0.0910,
        0.0909, 0.0908], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,180][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0911, 0.0906, 0.0906, 0.0912, 0.0907, 0.0909, 0.0909, 0.0908, 0.0908,
        0.0913, 0.0911], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,181][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0910, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,182][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.0075e-04, 3.1368e-03, 3.2875e-03, 8.6586e-02, 7.3408e-03, 5.3210e-01,
        3.5319e-02, 1.6242e-02, 1.7541e-02, 1.5948e-01, 1.3887e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,182][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([2.0015e-04, 1.9317e-03, 6.7978e-03, 6.9442e-03, 8.0003e-03, 5.8577e-02,
        2.0185e-03, 7.9147e-03, 6.6043e-01, 1.6787e-01, 6.3785e-02, 1.5524e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,188][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0080, 0.0688, 0.0763, 0.0894, 0.1110, 0.1507, 0.0584, 0.1385, 0.0415,
        0.0833, 0.1182, 0.0560], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,192][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0656, 0.1137, 0.1035, 0.0640, 0.1189, 0.0703, 0.0701, 0.0660, 0.1017,
        0.0640, 0.0720, 0.0902], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,193][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.6557, 0.0253, 0.0431, 0.0250, 0.0338, 0.0276, 0.0436, 0.0286, 0.0271,
        0.0298, 0.0249, 0.0356], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,194][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1381, 0.0768, 0.1015, 0.0712, 0.1136, 0.0886, 0.0774, 0.0780, 0.0781,
        0.0518, 0.0552, 0.0696], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,195][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0833, 0.0833, 0.0833, 0.0834, 0.0834, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0834, 0.0833, 0.0833], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,195][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0834, 0.0832, 0.0834, 0.0834, 0.0834, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0833, 0.0833], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,200][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0834, 0.0833, 0.0834, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833,
        0.0834, 0.0833, 0.0834], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,205][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0832, 0.0832, 0.0834, 0.0833, 0.0836, 0.0833, 0.0833, 0.0833, 0.0834,
        0.0833, 0.0833, 0.0835], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,206][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0835, 0.0830, 0.0830, 0.0836, 0.0831, 0.0834, 0.0834, 0.0832, 0.0832,
        0.0837, 0.0835, 0.0834], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,207][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0834, 0.0833, 0.0833, 0.0833, 0.0834, 0.0833, 0.0833, 0.0833, 0.0833,
        0.0833, 0.0834, 0.0833], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,207][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.3971e-05, 9.1702e-04, 8.1371e-04, 7.0145e-02, 3.1233e-03, 6.0448e-01,
        1.9732e-02, 6.7832e-03, 7.4984e-03, 1.5158e-01, 1.1916e-01, 1.5750e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,208][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0097, 0.0045, 0.0363, 0.0309, 0.1176, 0.2304, 0.0846, 0.0630, 0.1671,
        0.0601, 0.0470, 0.0482, 0.1008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,213][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0153, 0.0650, 0.0741, 0.0753, 0.0959, 0.1076, 0.0753, 0.1127, 0.0472,
        0.0734, 0.0905, 0.0716, 0.0962], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,218][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0521, 0.0730, 0.1074, 0.0488, 0.1223, 0.0616, 0.0641, 0.0499, 0.1151,
        0.0503, 0.0685, 0.1043, 0.0825], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,218][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.2331, 0.0525, 0.0991, 0.0577, 0.0600, 0.0752, 0.0716, 0.0619, 0.0661,
        0.0482, 0.0563, 0.0609, 0.0575], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,219][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1412, 0.0757, 0.0911, 0.0662, 0.0993, 0.0778, 0.0687, 0.0704, 0.0689,
        0.0485, 0.0486, 0.0631, 0.0804], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,220][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0769, 0.0769, 0.0769, 0.0770, 0.0770, 0.0770, 0.0769, 0.0769, 0.0769,
        0.0770, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,221][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0769, 0.0768, 0.0770, 0.0770, 0.0770, 0.0770, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,226][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0769, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,230][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0768, 0.0768, 0.0770, 0.0769, 0.0772, 0.0769, 0.0769, 0.0769, 0.0770,
        0.0769, 0.0769, 0.0770, 0.0769], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,231][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0771, 0.0767, 0.0767, 0.0772, 0.0767, 0.0769, 0.0770, 0.0768, 0.0769,
        0.0772, 0.0771, 0.0770, 0.0768], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,232][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769,
        0.0769, 0.0770, 0.0769, 0.0769], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,233][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.2940e-04, 3.1901e-03, 3.7862e-03, 6.6572e-02, 6.6023e-03, 3.5347e-01,
        3.6827e-02, 1.3052e-02, 1.5154e-02, 1.0660e-01, 8.9030e-02, 2.6897e-02,
        2.7870e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,234][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0026, 0.0027, 0.0422, 0.0098, 0.0449, 0.1475, 0.0079, 0.0256, 0.0396,
        0.0264, 0.0820, 0.0610, 0.3812, 0.1267], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,239][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0063, 0.0504, 0.0588, 0.0755, 0.0664, 0.1380, 0.0451, 0.1416, 0.0319,
        0.0693, 0.0958, 0.0606, 0.1072, 0.0533], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,243][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0439, 0.0993, 0.0839, 0.0572, 0.0949, 0.0619, 0.0588, 0.0520, 0.0990,
        0.0521, 0.0615, 0.0818, 0.0753, 0.0784], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,244][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.4354, 0.0363, 0.0607, 0.0348, 0.0374, 0.0431, 0.0512, 0.0407, 0.0399,
        0.0385, 0.0389, 0.0466, 0.0516, 0.0450], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,245][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.1244, 0.0678, 0.0826, 0.0604, 0.0918, 0.0706, 0.0618, 0.0646, 0.0642,
        0.0452, 0.0454, 0.0565, 0.0794, 0.0853], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,246][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0714, 0.0714, 0.0714, 0.0715, 0.0715, 0.0715, 0.0714, 0.0714, 0.0714,
        0.0715, 0.0714, 0.0714, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,247][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0714, 0.0713, 0.0715, 0.0715, 0.0715, 0.0715, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0714, 0.0714, 0.0714, 0.0715], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,254][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0715, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0714, 0.0715, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,256][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0713, 0.0713, 0.0715, 0.0714, 0.0717, 0.0714, 0.0714, 0.0714, 0.0715,
        0.0714, 0.0714, 0.0715, 0.0714, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,257][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0716, 0.0712, 0.0712, 0.0717, 0.0713, 0.0715, 0.0715, 0.0713, 0.0714,
        0.0717, 0.0716, 0.0715, 0.0713, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,258][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0715, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714,
        0.0714, 0.0715, 0.0714, 0.0714, 0.0715], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,259][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([2.2675e-05, 8.9356e-04, 9.5146e-04, 5.2617e-02, 4.2882e-03, 3.7981e-01,
        1.2342e-02, 6.0036e-03, 5.6937e-03, 1.0081e-01, 8.5943e-02, 9.1366e-03,
        3.3385e-01, 7.6401e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,261][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0092, 0.0028, 0.0093, 0.0145, 0.0377, 0.4680, 0.0412, 0.0329, 0.0453,
        0.0992, 0.0331, 0.0119, 0.0736, 0.0837, 0.0374], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,267][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0071, 0.0517, 0.0616, 0.0741, 0.0828, 0.1102, 0.0407, 0.1049, 0.0294,
        0.0701, 0.0894, 0.0578, 0.1170, 0.0661, 0.0371], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,269][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0396, 0.0892, 0.0823, 0.0459, 0.0950, 0.0493, 0.0567, 0.0481, 0.1039,
        0.0484, 0.0505, 0.0832, 0.0655, 0.0797, 0.0626], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,270][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.6519, 0.0204, 0.0294, 0.0183, 0.0185, 0.0199, 0.0270, 0.0232, 0.0215,
        0.0253, 0.0225, 0.0257, 0.0334, 0.0261, 0.0370], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,271][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.1105, 0.0607, 0.0761, 0.0546, 0.0851, 0.0657, 0.0571, 0.0593, 0.0593,
        0.0410, 0.0417, 0.0527, 0.0716, 0.0793, 0.0852], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,272][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0666, 0.0667,
        0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,276][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0666, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0666, 0.0667,
        0.0667, 0.0667, 0.0667, 0.0666, 0.0667, 0.0666], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,282][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0667, 0.0667, 0.0666, 0.0667,
        0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,283][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0665, 0.0666, 0.0667, 0.0667, 0.0669, 0.0666, 0.0666, 0.0666, 0.0667,
        0.0666, 0.0666, 0.0668, 0.0666, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,283][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0668, 0.0664, 0.0664, 0.0669, 0.0665, 0.0667, 0.0667, 0.0666, 0.0666,
        0.0669, 0.0668, 0.0667, 0.0665, 0.0666, 0.0669], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,284][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0666, 0.0667, 0.0666, 0.0666,
        0.0667, 0.0667, 0.0667, 0.0667, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,285][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([1.9757e-05, 8.6416e-04, 8.2450e-04, 3.9744e-02, 2.4827e-03, 3.6333e-01,
        1.7066e-02, 6.4840e-03, 7.7716e-03, 9.5693e-02, 7.1932e-02, 1.0959e-02,
        2.8031e-01, 3.6416e-03, 9.8883e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,289][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.3406e-04, 7.9764e-05, 1.9908e-04, 1.7025e-04, 5.2703e-04, 3.9451e-02,
        1.2783e-03, 9.6844e-03, 8.6622e-01, 1.8580e-05, 1.2481e-03, 7.3065e-04,
        3.3261e-03, 1.1597e-03, 7.5328e-02, 4.2588e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,294][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0095, 0.0493, 0.0693, 0.0688, 0.0809, 0.1027, 0.0484, 0.0980, 0.0302,
        0.0500, 0.0816, 0.0520, 0.0860, 0.0696, 0.0541, 0.0496],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,295][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0390, 0.0620, 0.0817, 0.0352, 0.0964, 0.0526, 0.0504, 0.0462, 0.0941,
        0.0449, 0.0544, 0.0870, 0.0641, 0.0836, 0.0568, 0.0515],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,296][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4836, 0.0316, 0.0434, 0.0302, 0.0312, 0.0307, 0.0331, 0.0343, 0.0289,
        0.0351, 0.0352, 0.0317, 0.0411, 0.0334, 0.0371, 0.0395],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,297][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1136, 0.0644, 0.0701, 0.0531, 0.0727, 0.0588, 0.0548, 0.0576, 0.0567,
        0.0390, 0.0402, 0.0511, 0.0700, 0.0754, 0.0809, 0.0416],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,300][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0625, 0.0624, 0.0625, 0.0625, 0.0626, 0.0625, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,307][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0625, 0.0624, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0624, 0.0625,
        0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0624],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,308][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0624, 0.0625],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,309][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0624, 0.0624, 0.0626, 0.0625, 0.0627, 0.0625, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0624, 0.0626, 0.0624, 0.0625, 0.0625, 0.0625],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,310][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0626, 0.0623, 0.0623, 0.0627, 0.0623, 0.0625, 0.0625, 0.0624, 0.0624,
        0.0627, 0.0626, 0.0625, 0.0624, 0.0625, 0.0627, 0.0625],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,313][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0626, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625,
        0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,317][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.0875e-05, 1.9531e-03, 2.1961e-03, 4.0178e-02, 4.0533e-03, 2.3132e-01,
        2.3171e-02, 9.2919e-03, 1.1538e-02, 7.7929e-02, 6.2817e-02, 1.8274e-02,
        1.8835e-01, 4.7523e-03, 9.1934e-02, 2.3216e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,320][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.6260e-04, 3.0317e-04, 9.8666e-04, 4.2068e-04, 2.1741e-03, 1.2529e-02,
        1.6672e-03, 3.6749e-03, 6.0002e-02, 2.0026e-01, 5.6386e-04, 2.0951e-03,
        2.3250e-02, 4.9008e-03, 6.5038e-02, 5.9945e-01, 2.2415e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,321][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0075, 0.0424, 0.0589, 0.0593, 0.0699, 0.1018, 0.0381, 0.0916, 0.0268,
        0.0554, 0.0812, 0.0504, 0.0872, 0.0584, 0.0461, 0.0547, 0.0702],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,322][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0394, 0.0777, 0.0725, 0.0422, 0.0804, 0.0429, 0.0509, 0.0472, 0.0852,
        0.0419, 0.0463, 0.0744, 0.0649, 0.0678, 0.0545, 0.0464, 0.0655],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,323][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.5769, 0.0220, 0.0280, 0.0188, 0.0242, 0.0208, 0.0298, 0.0218, 0.0188,
        0.0251, 0.0206, 0.0261, 0.0349, 0.0334, 0.0387, 0.0335, 0.0267],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,327][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0966, 0.0544, 0.0696, 0.0484, 0.0763, 0.0608, 0.0539, 0.0545, 0.0547,
        0.0350, 0.0380, 0.0487, 0.0659, 0.0745, 0.0799, 0.0375, 0.0514],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,333][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0588, 0.0588, 0.0588, 0.0589, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588,
        0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,334][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0588, 0.0588, 0.0589, 0.0588, 0.0589, 0.0589, 0.0588, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0589, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,334][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,335][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0587, 0.0587, 0.0589, 0.0588, 0.0590, 0.0588, 0.0588, 0.0588, 0.0589,
        0.0588, 0.0588, 0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,340][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0589, 0.0586, 0.0586, 0.0590, 0.0587, 0.0588, 0.0588, 0.0588, 0.0588,
        0.0591, 0.0589, 0.0589, 0.0587, 0.0588, 0.0590, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,346][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0589, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588, 0.0588,
        0.0588, 0.0588, 0.0588, 0.0588, 0.0589, 0.0588, 0.0588, 0.0588],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,348][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([1.9142e-05, 6.3206e-04, 6.1591e-04, 2.1560e-02, 1.5563e-03, 1.7802e-01,
        1.1215e-02, 4.3571e-03, 5.9205e-03, 5.5247e-02, 4.0645e-02, 7.8293e-03,
        1.4615e-01, 2.2081e-03, 6.1981e-02, 1.9966e-01, 2.6238e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,349][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0017, 0.0011, 0.0016, 0.0064, 0.0124, 0.3280, 0.0021, 0.0143, 0.0209,
        0.0331, 0.0321, 0.0031, 0.0557, 0.0289, 0.0287, 0.0831, 0.3222, 0.0245],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,350][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0075, 0.0416, 0.0465, 0.0521, 0.0669, 0.0863, 0.0364, 0.0775, 0.0262,
        0.0532, 0.0716, 0.0466, 0.0894, 0.0569, 0.0407, 0.0525, 0.0904, 0.0576],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,351][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0381, 0.0632, 0.0719, 0.0386, 0.0768, 0.0438, 0.0477, 0.0412, 0.0782,
        0.0387, 0.0524, 0.0761, 0.0636, 0.0666, 0.0522, 0.0438, 0.0581, 0.0490],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,355][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5326, 0.0261, 0.0354, 0.0232, 0.0265, 0.0245, 0.0291, 0.0247, 0.0206,
        0.0268, 0.0249, 0.0261, 0.0351, 0.0301, 0.0308, 0.0315, 0.0209, 0.0311],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,361][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0920, 0.0514, 0.0656, 0.0477, 0.0745, 0.0596, 0.0522, 0.0530, 0.0524,
        0.0354, 0.0376, 0.0475, 0.0612, 0.0705, 0.0739, 0.0375, 0.0496, 0.0385],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,362][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0556, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0556,
        0.0556, 0.0555, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0555, 0.0556],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,363][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0556, 0.0555, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0556,
        0.0556, 0.0556, 0.0556, 0.0555, 0.0556, 0.0555, 0.0555, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,364][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0556, 0.0555, 0.0556, 0.0556, 0.0555, 0.0556, 0.0556, 0.0555, 0.0556,
        0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0555, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,368][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0554, 0.0555, 0.0556, 0.0556, 0.0557, 0.0555, 0.0555, 0.0555, 0.0556,
        0.0555, 0.0555, 0.0556, 0.0555, 0.0555, 0.0556, 0.0556, 0.0556, 0.0555],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,373][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0557, 0.0554, 0.0554, 0.0557, 0.0554, 0.0556, 0.0556, 0.0555, 0.0555,
        0.0558, 0.0557, 0.0556, 0.0555, 0.0555, 0.0557, 0.0555, 0.0555, 0.0556],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,374][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0556, 0.0556, 0.0555, 0.0555, 0.0556, 0.0555, 0.0555, 0.0555, 0.0555,
        0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0556, 0.0555, 0.0556, 0.0556],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,375][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.2625e-05, 1.0783e-03, 1.2751e-03, 2.2115e-02, 2.3553e-03, 1.3397e-01,
        1.2405e-02, 5.2081e-03, 6.8344e-03, 4.4585e-02, 3.8438e-02, 1.0956e-02,
        1.0769e-01, 2.9110e-03, 5.4479e-02, 1.3599e-01, 1.7297e-01, 2.4670e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,376][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.3990e-04, 2.5591e-04, 9.2518e-04, 6.0086e-04, 3.4666e-03, 2.4539e-02,
        3.3767e-04, 8.0539e-04, 1.6776e-01, 4.4739e-03, 1.6380e-02, 1.9200e-02,
        2.2636e-02, 8.7897e-03, 8.9036e-04, 1.2220e-02, 6.7243e-01, 3.1582e-02,
        1.2570e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,380][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0040, 0.0376, 0.0385, 0.0499, 0.0558, 0.0879, 0.0344, 0.0913, 0.0237,
        0.0531, 0.0668, 0.0369, 0.0819, 0.0454, 0.0423, 0.0518, 0.0796, 0.0886,
        0.0305], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,386][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0369, 0.0752, 0.0627, 0.0444, 0.0745, 0.0415, 0.0418, 0.0419, 0.0677,
        0.0433, 0.0417, 0.0634, 0.0603, 0.0614, 0.0498, 0.0485, 0.0617, 0.0401,
        0.0433], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,387][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.6238, 0.0170, 0.0231, 0.0163, 0.0183, 0.0144, 0.0224, 0.0175, 0.0148,
        0.0216, 0.0175, 0.0184, 0.0315, 0.0236, 0.0266, 0.0274, 0.0147, 0.0218,
        0.0294], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,388][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0825, 0.0463, 0.0632, 0.0438, 0.0723, 0.0565, 0.0487, 0.0499, 0.0506,
        0.0321, 0.0356, 0.0439, 0.0600, 0.0698, 0.0743, 0.0345, 0.0474, 0.0361,
        0.0523], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,389][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0526, 0.0526, 0.0526, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526,
        0.0527, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0527,
        0.0526], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,393][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0527, 0.0526, 0.0527, 0.0527, 0.0527, 0.0527, 0.0526, 0.0526, 0.0526,
        0.0526, 0.0526, 0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0527, 0.0526,
        0.0527], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,398][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0526,
        0.0527, 0.0526, 0.0527, 0.0526, 0.0527, 0.0526, 0.0526, 0.0526, 0.0526,
        0.0526], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,399][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0525, 0.0526, 0.0527, 0.0526, 0.0528, 0.0526, 0.0526, 0.0526, 0.0527,
        0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0526,
        0.0526], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,400][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0527, 0.0524, 0.0524, 0.0528, 0.0525, 0.0526, 0.0526, 0.0526, 0.0526,
        0.0528, 0.0527, 0.0527, 0.0525, 0.0526, 0.0528, 0.0526, 0.0526, 0.0527,
        0.0528], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,401][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0527, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526, 0.0526,
        0.0526, 0.0527, 0.0526, 0.0526, 0.0527, 0.0526, 0.0526, 0.0526, 0.0527,
        0.0526], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,403][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([4.7117e-06, 2.5803e-04, 2.3488e-04, 1.5638e-02, 8.1624e-04, 1.3237e-01,
        4.9163e-03, 1.8264e-03, 2.1550e-03, 3.5119e-02, 2.7547e-02, 4.0132e-03,
        1.1758e-01, 1.1943e-03, 2.6175e-02, 1.5681e-01, 1.3515e-01, 3.2230e-01,
        1.5890e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:48,406][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.0494e-04, 4.7941e-05, 1.1401e-04, 1.0282e-04, 3.1368e-04, 2.4467e-02,
        7.5323e-04, 5.9432e-03, 5.4808e-01, 1.1036e-05, 7.4630e-04, 4.3002e-04,
        1.9877e-03, 6.8422e-04, 4.8758e-02, 2.5822e-05, 3.5895e-01, 4.4202e-03,
        3.8257e-03, 3.3462e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,411][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0078, 0.0388, 0.0517, 0.0526, 0.0594, 0.0791, 0.0379, 0.0734, 0.0232,
        0.0376, 0.0603, 0.0394, 0.0676, 0.0511, 0.0418, 0.0373, 0.0723, 0.0783,
        0.0533, 0.0372], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,412][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0307, 0.0500, 0.0663, 0.0282, 0.0783, 0.0426, 0.0411, 0.0375, 0.0763,
        0.0359, 0.0432, 0.0708, 0.0514, 0.0676, 0.0461, 0.0412, 0.0610, 0.0397,
        0.0471, 0.0449], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,413][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5349, 0.0224, 0.0298, 0.0211, 0.0208, 0.0194, 0.0211, 0.0232, 0.0187,
        0.0259, 0.0254, 0.0201, 0.0308, 0.0227, 0.0239, 0.0300, 0.0170, 0.0301,
        0.0284, 0.0343], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,414][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0887, 0.0512, 0.0584, 0.0450, 0.0630, 0.0509, 0.0468, 0.0495, 0.0486,
        0.0329, 0.0352, 0.0436, 0.0590, 0.0653, 0.0693, 0.0349, 0.0440, 0.0367,
        0.0494, 0.0275], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,418][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,423][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0500, 0.0499, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0499, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,424][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0499, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,425][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0499, 0.0499, 0.0501, 0.0500, 0.0502, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0501, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0499], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,426][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0501, 0.0498, 0.0498, 0.0501, 0.0499, 0.0500, 0.0500, 0.0499, 0.0499,
        0.0502, 0.0501, 0.0500, 0.0499, 0.0500, 0.0501, 0.0500, 0.0499, 0.0500,
        0.0501, 0.0502], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,431][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500, 0.0500,
        0.0500, 0.0500], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,434][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.9415e-05, 8.9841e-04, 1.0259e-03, 1.6937e-02, 1.8211e-03, 9.9583e-02,
        1.0565e-02, 4.3328e-03, 5.8344e-03, 3.5568e-02, 2.8684e-02, 8.9497e-03,
        8.2012e-02, 2.1947e-03, 4.4912e-02, 1.0482e-01, 1.4114e-01, 1.7968e-01,
        2.2785e-02, 2.0822e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:48,438][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:48,439][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9719],
        [15979],
        [   12],
        [ 8811],
        [  934],
        [ 4732],
        [ 1914],
        [ 4599],
        [15274],
        [ 9346],
        [17661],
        [12322],
        [ 6174],
        [10492],
        [12617],
        [ 9786],
        [ 7362],
        [13061],
        [24985],
        [10950]], device='cuda:0')
[2024-07-24 10:16:48,442][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[24624],
        [15896],
        [    9],
        [10218],
        [ 6092],
        [ 5892],
        [ 2670],
        [ 3790],
        [32001],
        [ 6456],
        [19901],
        [13121],
        [ 4100],
        [14411],
        [17712],
        [ 6007],
        [11207],
        [13189],
        [36827],
        [10618]], device='cuda:0')
[2024-07-24 10:16:48,445][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12238],
        [12201],
        [11979],
        [12059],
        [12020],
        [12177],
        [12181],
        [12137],
        [12138],
        [12126],
        [12099],
        [12096],
        [12074],
        [12071],
        [12136],
        [12084],
        [12075],
        [12050],
        [12065],
        [12107]], device='cuda:0')
[2024-07-24 10:16:48,449][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[39824],
        [39253],
        [29795],
        [33908],
        [34212],
        [30694],
        [35303],
        [32290],
        [33865],
        [36681],
        [38070],
        [37113],
        [38884],
        [38775],
        [35468],
        [37411],
        [37896],
        [39102],
        [39337],
        [37522]], device='cuda:0')
[2024-07-24 10:16:48,451][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[17482],
        [21792],
        [25126],
        [25783],
        [27359],
        [26457],
        [26559],
        [26995],
        [27083],
        [27277],
        [27667],
        [27029],
        [27172],
        [27874],
        [27890],
        [28092],
        [27807],
        [28147],
        [28253],
        [28487]], device='cuda:0')
[2024-07-24 10:16:48,452][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9030],
        [ 8971],
        [10011],
        [11027],
        [10944],
        [ 9339],
        [ 8247],
        [ 7636],
        [ 6946],
        [ 7178],
        [ 6904],
        [ 6775],
        [ 7245],
        [ 7497],
        [ 7574],
        [ 7671],
        [ 7575],
        [ 7504],
        [ 7361],
        [ 7377]], device='cuda:0')
[2024-07-24 10:16:48,454][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1614],
        [1425],
        [1080],
        [1150],
        [1283],
        [1144],
        [1219],
        [1112],
        [1131],
        [1183],
        [1232],
        [1204],
        [1288],
        [1303],
        [1200],
        [1230],
        [1272],
        [1282],
        [1283],
        [1296]], device='cuda:0')
[2024-07-24 10:16:48,456][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4689],
        [ 3813],
        [ 5966],
        [ 3468],
        [12520],
        [ 6337],
        [ 5065],
        [ 2708],
        [ 3654],
        [ 7935],
        [ 5766],
        [32984],
        [10544],
        [ 7522],
        [ 8420],
        [ 9859],
        [ 3508],
        [ 5171],
        [ 8381],
        [ 6369]], device='cuda:0')
[2024-07-24 10:16:48,460][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[150],
        [120],
        [ 29],
        [114],
        [168],
        [ 78],
        [ 77],
        [ 78],
        [ 91],
        [146],
        [227],
        [269],
        [240],
        [221],
        [227],
        [227],
        [220],
        [359],
        [298],
        [301]], device='cuda:0')
[2024-07-24 10:16:48,463][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45997],
        [45266],
        [ 1801],
        [36100],
        [  167],
        [23383],
        [24465],
        [34290],
        [11219],
        [38711],
        [36711],
        [13604],
        [35517],
        [27103],
        [34497],
        [36616],
        [32823],
        [33137],
        [26938],
        [35605]], device='cuda:0')
[2024-07-24 10:16:48,465][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24785],
        [25577],
        [31870],
        [31241],
        [34625],
        [35808],
        [28717],
        [29971],
        [22702],
        [29852],
        [28431],
        [23246],
        [28836],
        [18863],
        [21136],
        [22590],
        [14949],
        [17684],
        [14436],
        [18806]], device='cuda:0')
[2024-07-24 10:16:48,467][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19211],
        [ 9244],
        [10949],
        [12986],
        [11880],
        [24647],
        [26059],
        [29200],
        [25796],
        [26524],
        [25530],
        [19098],
        [19783],
        [18556],
        [19087],
        [17027],
        [18068],
        [17230],
        [16888],
        [17347]], device='cuda:0')
[2024-07-24 10:16:48,468][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31669],
        [37783],
        [38303],
        [38964],
        [38262],
        [37235],
        [37214],
        [36658],
        [36330],
        [36579],
        [36649],
        [36214],
        [36529],
        [36444],
        [36322],
        [36498],
        [36605],
        [36489],
        [36286],
        [36398]], device='cuda:0')
[2024-07-24 10:16:48,471][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 9276],
        [ 8533],
        [43848],
        [ 7905],
        [24893],
        [26381],
        [23154],
        [25139],
        [28982],
        [20313],
        [16068],
        [24252],
        [13091],
        [42916],
        [30279],
        [21422],
        [ 6957],
        [18694],
        [33013],
        [23220]], device='cuda:0')
[2024-07-24 10:16:48,474][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 8614],
        [21114],
        [19557],
        [33012],
        [20775],
        [28871],
        [ 9187],
        [27547],
        [45578],
        [34538],
        [28255],
        [36465],
        [28709],
        [33223],
        [28919],
        [32018],
        [27601],
        [32497],
        [23794],
        [33070]], device='cuda:0')
[2024-07-24 10:16:48,477][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 4338],
        [ 4390],
        [27737],
        [28101],
        [29453],
        [ 8526],
        [46877],
        [18895],
        [44959],
        [15741],
        [33791],
        [19400],
        [42063],
        [45230],
        [45243],
        [16068],
        [24434],
        [40971],
        [25473],
        [18382]], device='cuda:0')
[2024-07-24 10:16:48,480][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[3707],
        [9634],
        [9400],
        [8390],
        [8125],
        [7771],
        [7044],
        [6459],
        [6268],
        [6066],
        [5680],
        [5474],
        [5687],
        [5919],
        [5982],
        [5795],
        [5578],
        [5436],
        [5402],
        [5424]], device='cuda:0')
[2024-07-24 10:16:48,481][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5291],
        [5301],
        [6520],
        [6223],
        [6215],
        [6068],
        [6023],
        [6155],
        [6211],
        [6119],
        [6210],
        [5982],
        [5997],
        [5992],
        [5962],
        [5957],
        [5870],
        [5916],
        [5934],
        [5961]], device='cuda:0')
[2024-07-24 10:16:48,483][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1328],
        [ 1379],
        [ 1415],
        [ 4145],
        [ 3649],
        [ 1728],
        [ 1446],
        [ 1591],
        [ 1575],
        [ 5452],
        [ 4632],
        [ 1494],
        [21696],
        [ 5492],
        [ 1463],
        [ 3146],
        [ 1575],
        [ 1969],
        [ 1447],
        [ 1875]], device='cuda:0')
[2024-07-24 10:16:48,485][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17832],
        [19099],
        [20984],
        [21428],
        [22699],
        [23381],
        [23602],
        [24077],
        [24654],
        [24438],
        [24854],
        [24981],
        [25116],
        [25572],
        [26079],
        [26098],
        [26435],
        [26506],
        [26647],
        [26481]], device='cuda:0')
[2024-07-24 10:16:48,488][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[29188],
        [29183],
        [29108],
        [29115],
        [29170],
        [29207],
        [29235],
        [29222],
        [29216],
        [29210],
        [29225],
        [29216],
        [29216],
        [29231],
        [29240],
        [29229],
        [29213],
        [29214],
        [29207],
        [29219]], device='cuda:0')
[2024-07-24 10:16:48,492][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34066],
        [34040],
        [34106],
        [34093],
        [34031],
        [34035],
        [34033],
        [34032],
        [34036],
        [34029],
        [34024],
        [34026],
        [34028],
        [34025],
        [34028],
        [34034],
        [34031],
        [34029],
        [34030],
        [34030]], device='cuda:0')
[2024-07-24 10:16:48,494][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31155],
        [31052],
        [31042],
        [31089],
        [31080],
        [31046],
        [31056],
        [31039],
        [31026],
        [31018],
        [31008],
        [30998],
        [30997],
        [30985],
        [31016],
        [31018],
        [31025],
        [31024],
        [31026],
        [31035]], device='cuda:0')
[2024-07-24 10:16:48,495][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[4909],
        [4923],
        [4928],
        [4926],
        [4923],
        [4929],
        [4929],
        [4924],
        [4924],
        [4923],
        [4925],
        [4930],
        [4930],
        [4930],
        [4929],
        [4930],
        [4930],
        [4931],
        [4930],
        [4928]], device='cuda:0')
[2024-07-24 10:16:48,497][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10766],
        [10764],
        [10757],
        [10766],
        [10768],
        [10769],
        [10768],
        [10762],
        [10762],
        [10765],
        [10766],
        [10764],
        [10766],
        [10763],
        [10762],
        [10762],
        [10762],
        [10762],
        [10763],
        [10763]], device='cuda:0')
[2024-07-24 10:16:48,499][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[8874],
        [8879],
        [8872],
        [8869],
        [8870],
        [8870],
        [8872],
        [8872],
        [8874],
        [8875],
        [8875],
        [8874],
        [8873],
        [8875],
        [8873],
        [8873],
        [8873],
        [8873],
        [8874],
        [8875]], device='cuda:0')
[2024-07-24 10:16:48,503][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14163],
        [14770],
        [10145],
        [20625],
        [20369],
        [25074],
        [24581],
        [24013],
        [24349],
        [24465],
        [24782],
        [25142],
        [24536],
        [25555],
        [24605],
        [24886],
        [24822],
        [25924],
        [26956],
        [26778]], device='cuda:0')
[2024-07-24 10:16:48,506][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23353],
        [21052],
        [13514],
        [ 8583],
        [ 8978],
        [17711],
        [ 9867],
        [15938],
        [11313],
        [ 8832],
        [ 7749],
        [15278],
        [ 3034],
        [ 5616],
        [10896],
        [11194],
        [15004],
        [10441],
        [13170],
        [12948]], device='cuda:0')
[2024-07-24 10:16:48,508][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 1180],
        [22746],
        [23521],
        [  840],
        [ 8469],
        [ 2262],
        [28897],
        [10295],
        [ 1938],
        [ 2146],
        [ 8040],
        [11332],
        [ 3403],
        [ 2212],
        [10469],
        [ 2908],
        [ 8249],
        [ 5748],
        [22128],
        [ 3739]], device='cuda:0')
[2024-07-24 10:16:48,510][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446],
        [23446]], device='cuda:0')
[2024-07-24 10:16:48,550][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:48,553][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,554][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,555][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,555][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,556][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,557][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,557][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,558][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,559][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,559][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,560][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,561][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:48,561][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4055, 0.5945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,562][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7514, 0.2486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,563][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9976, 0.0024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,565][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8882, 0.1118], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,565][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5007, 0.4993], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,566][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2460, 0.7540], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,567][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3254, 0.6746], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,568][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5433, 0.4567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,569][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2251, 0.7749], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,572][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2028, 0.7972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,577][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4918, 0.5082], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,579][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0486, 0.9514], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:48,579][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2760, 0.4752, 0.2488], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,580][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.4131, 0.4806, 0.1063], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,581][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.9953, 0.0036, 0.0011], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,582][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.6871, 0.1592, 0.1537], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,586][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.2562, 0.4623, 0.2815], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,591][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.1282, 0.7390, 0.1328], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,592][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.1379, 0.3496, 0.5124], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,593][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.2878, 0.3776, 0.3346], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,594][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0744, 0.3207, 0.6048], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,594][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1278, 0.4150, 0.4571], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,595][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.1801, 0.2407, 0.5792], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,600][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0262, 0.4611, 0.5128], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:48,604][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1691, 0.3257, 0.2538, 0.2514], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,605][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3522, 0.3514, 0.1481, 0.1483], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,606][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.9478, 0.0020, 0.0285, 0.0217], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,607][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6017, 0.1059, 0.0818, 0.2107], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,607][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1115, 0.3336, 0.3062, 0.2487], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,610][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0949, 0.4666, 0.2908, 0.1477], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,617][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1345, 0.2867, 0.3896, 0.1892], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,618][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3184, 0.2270, 0.3449, 0.1097], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,619][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0578, 0.2028, 0.3958, 0.3436], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,620][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0481, 0.1913, 0.3645, 0.3960], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,620][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1451, 0.1715, 0.3527, 0.3306], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,622][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0232, 0.3255, 0.3227, 0.3286], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:48,629][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0970, 0.2001, 0.2007, 0.2260, 0.2761], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,631][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.2674, 0.3981, 0.0915, 0.1772, 0.0657], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,632][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.7635, 0.0046, 0.0141, 0.1879, 0.0298], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,632][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.4265, 0.1112, 0.0851, 0.2130, 0.1641], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,633][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0898, 0.1762, 0.1730, 0.3071, 0.2539], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,634][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0526, 0.3609, 0.2133, 0.3261, 0.0470], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,639][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0828, 0.2003, 0.3088, 0.1490, 0.2590], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,644][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1775, 0.2435, 0.2135, 0.1410, 0.2244], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,644][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0304, 0.1182, 0.2218, 0.2274, 0.4022], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,645][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0514, 0.1477, 0.1579, 0.3108, 0.3323], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,646][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0711, 0.0991, 0.2351, 0.2166, 0.3780], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,646][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0115, 0.1358, 0.1514, 0.2341, 0.4673], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:48,651][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1016, 0.1911, 0.1074, 0.1840, 0.3416, 0.0742], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,656][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.4004, 0.1350, 0.0721, 0.1757, 0.0806, 0.1361], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,657][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.6549, 0.0039, 0.0108, 0.1080, 0.2113, 0.0111], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,658][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.3601, 0.0841, 0.0742, 0.1741, 0.1531, 0.1544], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,659][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0954, 0.1391, 0.1039, 0.2735, 0.1817, 0.2064], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,659][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0593, 0.3184, 0.2144, 0.2132, 0.1486, 0.0462], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,664][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0751, 0.1693, 0.2058, 0.1165, 0.1976, 0.2358], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,669][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1584, 0.1902, 0.1939, 0.0958, 0.1944, 0.1674], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,670][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0230, 0.0828, 0.1638, 0.1578, 0.3133, 0.2593], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,671][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0188, 0.0807, 0.1478, 0.1663, 0.3154, 0.2709], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,672][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0426, 0.0671, 0.1538, 0.1460, 0.2493, 0.3412], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,672][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0079, 0.1473, 0.1241, 0.1537, 0.3300, 0.2370], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:48,677][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0616, 0.1450, 0.1197, 0.1543, 0.2897, 0.1113, 0.1184],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,682][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.2984, 0.1238, 0.0290, 0.1096, 0.0190, 0.1695, 0.2508],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,683][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.5276, 0.0039, 0.0262, 0.0981, 0.1819, 0.1610, 0.0013],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,684][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.3289, 0.0701, 0.0646, 0.1667, 0.1513, 0.1512, 0.0672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,685][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0471, 0.1089, 0.1180, 0.1855, 0.1831, 0.2194, 0.1380],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,685][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0500, 0.2728, 0.1933, 0.2047, 0.0845, 0.1741, 0.0206],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,690][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0491, 0.1110, 0.1820, 0.0745, 0.1546, 0.1859, 0.2428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,695][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1196, 0.1323, 0.1575, 0.0888, 0.1392, 0.1730, 0.1896],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,696][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0168, 0.0668, 0.1278, 0.1353, 0.2531, 0.2424, 0.1577],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,697][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0245, 0.0739, 0.0818, 0.1507, 0.1742, 0.2378, 0.2572],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,698][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0369, 0.0538, 0.1196, 0.1125, 0.1906, 0.2802, 0.2065],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,698][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0060, 0.1205, 0.0776, 0.1501, 0.2049, 0.2043, 0.2367],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:48,703][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0700, 0.1243, 0.0812, 0.1434, 0.1795, 0.0806, 0.1489, 0.1721],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,708][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.3183, 0.0646, 0.0184, 0.0860, 0.0327, 0.0762, 0.2937, 0.1100],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,709][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.5338, 0.0094, 0.0079, 0.1526, 0.1274, 0.1231, 0.0202, 0.0256],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,710][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.3070, 0.0660, 0.0608, 0.1544, 0.1382, 0.1406, 0.0610, 0.0720],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,711][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0364, 0.0801, 0.0580, 0.1185, 0.0734, 0.0676, 0.5364, 0.0298],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,712][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0471, 0.2390, 0.2472, 0.1605, 0.0460, 0.1647, 0.0456, 0.0499],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,716][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0477, 0.1016, 0.1456, 0.0708, 0.1388, 0.1742, 0.2064, 0.1149],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,717][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1326, 0.0973, 0.1255, 0.0698, 0.1061, 0.1221, 0.2272, 0.1193],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,723][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0154, 0.0559, 0.1101, 0.1076, 0.2160, 0.1911, 0.1551, 0.1489],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,723][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0113, 0.0431, 0.0682, 0.0976, 0.1485, 0.1601, 0.2314, 0.2397],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,724][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0297, 0.0420, 0.0949, 0.0928, 0.1548, 0.2185, 0.1749, 0.1924],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,725][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0066, 0.0892, 0.0813, 0.1035, 0.1896, 0.1593, 0.1839, 0.1865],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:48,726][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0525, 0.1021, 0.0653, 0.1309, 0.1530, 0.0668, 0.1289, 0.2394, 0.0611],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,730][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.1059, 0.1709, 0.0147, 0.0769, 0.0217, 0.1017, 0.2606, 0.1680, 0.0796],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,736][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.5203, 0.0017, 0.0039, 0.0776, 0.0304, 0.1260, 0.0066, 0.2267, 0.0068],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,737][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.3203, 0.0553, 0.0514, 0.1443, 0.1297, 0.1296, 0.0522, 0.0628, 0.0544],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,737][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0464, 0.0971, 0.0521, 0.1663, 0.0898, 0.1979, 0.2275, 0.0829, 0.0400],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,738][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0259, 0.1864, 0.0903, 0.1324, 0.0660, 0.0874, 0.1246, 0.2838, 0.0033],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,739][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0414, 0.0834, 0.1360, 0.0581, 0.1230, 0.1588, 0.1989, 0.1094, 0.0910],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,744][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0685, 0.1254, 0.0969, 0.0854, 0.1116, 0.1048, 0.1682, 0.1366, 0.1025],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,751][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.0141, 0.0496, 0.0915, 0.1003, 0.1772, 0.1688, 0.1233, 0.1323, 0.1430],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,752][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0132, 0.0432, 0.0556, 0.0916, 0.1147, 0.1430, 0.1817, 0.2133, 0.1438],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,753][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0226, 0.0324, 0.0770, 0.0738, 0.1285, 0.1823, 0.1423, 0.1578, 0.1833],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,754][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0042, 0.0479, 0.0365, 0.0621, 0.0996, 0.0820, 0.1064, 0.1318, 0.4295],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:48,755][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0505, 0.0904, 0.0599, 0.1027, 0.1364, 0.0715, 0.1274, 0.2012, 0.0587,
        0.1013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,760][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1009, 0.0852, 0.0591, 0.0697, 0.0516, 0.1088, 0.3187, 0.0874, 0.0798,
        0.0389], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,764][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.5861, 0.0012, 0.0035, 0.0666, 0.0425, 0.0811, 0.0053, 0.0936, 0.0946,
        0.0256], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,765][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3459, 0.0639, 0.0444, 0.1281, 0.0921, 0.0921, 0.0376, 0.0425, 0.0378,
        0.1155], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,766][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0367, 0.0669, 0.0678, 0.1112, 0.1214, 0.1136, 0.2388, 0.0737, 0.0884,
        0.0815], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,767][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0299, 0.1304, 0.1327, 0.1373, 0.1226, 0.1698, 0.1307, 0.1129, 0.0105,
        0.0232], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,768][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0499, 0.0907, 0.1181, 0.0717, 0.1106, 0.1379, 0.1727, 0.1118, 0.0820,
        0.0547], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,773][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0960, 0.0821, 0.1075, 0.0467, 0.1079, 0.1004, 0.1650, 0.1416, 0.1122,
        0.0407], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,777][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0144, 0.0453, 0.0883, 0.0880, 0.1661, 0.1295, 0.1098, 0.1124, 0.1165,
        0.1298], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,778][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0091, 0.0314, 0.0590, 0.0718, 0.1231, 0.1164, 0.1919, 0.1834, 0.1360,
        0.0778], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,779][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0264, 0.0341, 0.0733, 0.0707, 0.1129, 0.1608, 0.1314, 0.1441, 0.1615,
        0.0847], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,780][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0042, 0.0450, 0.0306, 0.0482, 0.0763, 0.0722, 0.0857, 0.0901, 0.3244,
        0.2231], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:48,781][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0431, 0.0815, 0.0629, 0.0941, 0.1159, 0.0529, 0.0973, 0.1805, 0.0774,
        0.1290, 0.0654], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,786][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0955, 0.0859, 0.0478, 0.0781, 0.0779, 0.0959, 0.2044, 0.0893, 0.1110,
        0.0325, 0.0816], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,790][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([6.0757e-01, 4.2641e-04, 1.9223e-03, 3.7824e-02, 3.0384e-02, 3.6234e-02,
        3.7555e-03, 2.8001e-02, 2.6531e-02, 2.2021e-01, 7.1467e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,791][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3904, 0.0460, 0.0321, 0.1193, 0.0837, 0.0827, 0.0271, 0.0319, 0.0275,
        0.1066, 0.0528], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,792][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0490, 0.0750, 0.0428, 0.1194, 0.1827, 0.1204, 0.1094, 0.0774, 0.0313,
        0.1051, 0.0874], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,793][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0272, 0.1412, 0.0978, 0.1279, 0.0874, 0.1044, 0.1240, 0.1800, 0.0148,
        0.0631, 0.0322], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,794][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0426, 0.0840, 0.1146, 0.0631, 0.0987, 0.1318, 0.1568, 0.1079, 0.0913,
        0.0502, 0.0589], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,799][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0860, 0.0829, 0.1051, 0.0556, 0.1042, 0.1044, 0.1497, 0.1117, 0.0944,
        0.0455, 0.0605], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,803][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0124, 0.0387, 0.0702, 0.0740, 0.1348, 0.1153, 0.0979, 0.0997, 0.1041,
        0.1193, 0.1335], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,804][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0074, 0.0277, 0.0492, 0.0594, 0.1046, 0.0944, 0.1709, 0.1666, 0.1260,
        0.0762, 0.1175], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,805][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0169, 0.0260, 0.0611, 0.0595, 0.1007, 0.1426, 0.1180, 0.1285, 0.1482,
        0.0758, 0.1226], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,806][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0032, 0.0344, 0.0273, 0.0367, 0.0633, 0.0587, 0.0783, 0.0671, 0.2843,
        0.1770, 0.1697], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:48,807][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0418, 0.0739, 0.0497, 0.0779, 0.1303, 0.0441, 0.0828, 0.1423, 0.0833,
        0.1194, 0.0682, 0.0863], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,812][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1859, 0.0640, 0.0174, 0.0880, 0.0448, 0.0486, 0.1338, 0.1039, 0.0859,
        0.0242, 0.0941, 0.1095], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,816][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.4532, 0.0014, 0.0034, 0.0330, 0.0496, 0.0356, 0.0038, 0.0463, 0.0861,
        0.1672, 0.1149, 0.0054], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,817][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.2263, 0.0445, 0.0434, 0.1122, 0.1025, 0.1045, 0.0458, 0.0548, 0.0476,
        0.1095, 0.0648, 0.0440], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,818][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0255, 0.0866, 0.0566, 0.1181, 0.0544, 0.1529, 0.1245, 0.0520, 0.0303,
        0.0932, 0.1692, 0.0367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,819][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0181, 0.1209, 0.2125, 0.0767, 0.0605, 0.0698, 0.1095, 0.1471, 0.0135,
        0.0653, 0.0938, 0.0123], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,820][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0280, 0.0610, 0.1068, 0.0415, 0.0965, 0.1175, 0.1635, 0.0820, 0.0768,
        0.0345, 0.0499, 0.1420], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,825][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0821, 0.0986, 0.0842, 0.0556, 0.0675, 0.0829, 0.1388, 0.0903, 0.0758,
        0.0445, 0.0411, 0.1385], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,830][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0093, 0.0319, 0.0545, 0.0642, 0.1086, 0.1060, 0.0703, 0.0811, 0.0846,
        0.1195, 0.1185, 0.1515], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,830][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0142, 0.0339, 0.0329, 0.0672, 0.0664, 0.0989, 0.1038, 0.1466, 0.0961,
        0.0729, 0.1210, 0.1461], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,831][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0171, 0.0249, 0.0561, 0.0531, 0.0894, 0.1306, 0.1001, 0.1114, 0.1272,
        0.0620, 0.1072, 0.1209], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,832][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0032, 0.0338, 0.0218, 0.0396, 0.0546, 0.0486, 0.0607, 0.0561, 0.2142,
        0.1575, 0.1431, 0.1669], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:48,833][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0351, 0.0592, 0.0490, 0.0639, 0.1254, 0.0465, 0.0694, 0.1314, 0.0604,
        0.0926, 0.0699, 0.1067, 0.0903], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,838][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0700, 0.0649, 0.0490, 0.0682, 0.0483, 0.0537, 0.1582, 0.0777, 0.0598,
        0.0424, 0.1013, 0.1075, 0.0989], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,843][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([6.3308e-01, 1.9908e-04, 4.0402e-03, 1.6047e-02, 4.6433e-02, 5.6085e-02,
        7.8752e-03, 2.1187e-02, 3.8005e-02, 1.0091e-01, 3.3522e-02, 3.8916e-02,
        3.7050e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,843][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.3414, 0.0487, 0.0356, 0.1072, 0.0738, 0.0779, 0.0265, 0.0297, 0.0261,
        0.0807, 0.0451, 0.0278, 0.0794], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,844][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0231, 0.0460, 0.0627, 0.0673, 0.1398, 0.1258, 0.1231, 0.0700, 0.0304,
        0.0680, 0.1178, 0.0711, 0.0548], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,845][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0328, 0.1212, 0.0876, 0.1039, 0.0636, 0.1000, 0.0578, 0.1206, 0.0142,
        0.0789, 0.0794, 0.0694, 0.0707], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,846][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0302, 0.0660, 0.0978, 0.0472, 0.0864, 0.0956, 0.1211, 0.0811, 0.0621,
        0.0403, 0.0536, 0.1295, 0.0892], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,851][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0749, 0.0628, 0.1095, 0.0368, 0.0950, 0.0680, 0.1187, 0.0669, 0.1049,
        0.0323, 0.0404, 0.1702, 0.0195], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,856][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0089, 0.0277, 0.0560, 0.0511, 0.1062, 0.0814, 0.0715, 0.0702, 0.0764,
        0.0814, 0.0904, 0.1521, 0.1266], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,857][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0052, 0.0196, 0.0391, 0.0423, 0.0805, 0.0654, 0.1212, 0.1129, 0.0897,
        0.0534, 0.0851, 0.1887, 0.0971], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,857][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0149, 0.0223, 0.0502, 0.0496, 0.0808, 0.1107, 0.0933, 0.1025, 0.1146,
        0.0598, 0.0946, 0.1054, 0.1012], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,858][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0033, 0.0275, 0.0235, 0.0315, 0.0579, 0.0381, 0.0583, 0.0464, 0.2043,
        0.1073, 0.1102, 0.1645, 0.1272], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:48,859][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0236, 0.0532, 0.0509, 0.0573, 0.0727, 0.0372, 0.0581, 0.1255, 0.0634,
        0.0929, 0.0539, 0.1064, 0.1100, 0.0947], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,864][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0817, 0.0944, 0.0258, 0.0626, 0.0213, 0.0447, 0.1550, 0.0671, 0.0768,
        0.0194, 0.0826, 0.1332, 0.1155, 0.0199], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,869][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.4775, 0.0013, 0.0048, 0.0661, 0.0109, 0.0365, 0.0080, 0.0236, 0.0134,
        0.1006, 0.0920, 0.1071, 0.0230, 0.0353], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,870][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.2717, 0.0479, 0.0329, 0.1000, 0.0698, 0.0701, 0.0288, 0.0326, 0.0295,
        0.0919, 0.0557, 0.0308, 0.0910, 0.0474], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,871][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0244, 0.0515, 0.0434, 0.0899, 0.0673, 0.1130, 0.0605, 0.0351, 0.0272,
        0.0958, 0.1126, 0.0896, 0.1047, 0.0851], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,871][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0197, 0.1325, 0.0755, 0.1205, 0.0162, 0.0852, 0.0938, 0.0958, 0.0150,
        0.0561, 0.0968, 0.0662, 0.1006, 0.0262], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,872][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0228, 0.0559, 0.0878, 0.0427, 0.0734, 0.0979, 0.1404, 0.0747, 0.0646,
        0.0281, 0.0392, 0.1377, 0.0654, 0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,877][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0550, 0.0997, 0.0730, 0.0558, 0.0739, 0.0731, 0.1114, 0.0827, 0.0625,
        0.0437, 0.0513, 0.1350, 0.0294, 0.0535], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,882][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0059, 0.0199, 0.0379, 0.0404, 0.0706, 0.0694, 0.0521, 0.0537, 0.0583,
        0.0778, 0.0758, 0.1204, 0.1409, 0.1768], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,883][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0087, 0.0218, 0.0234, 0.0474, 0.0488, 0.0697, 0.0872, 0.1121, 0.0742,
        0.0529, 0.0880, 0.1313, 0.1227, 0.1119], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,884][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0068, 0.0130, 0.0364, 0.0357, 0.0660, 0.0928, 0.0709, 0.0804, 0.0949,
        0.0454, 0.0798, 0.0961, 0.0813, 0.2004], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,885][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0034, 0.0198, 0.0170, 0.0275, 0.0426, 0.0336, 0.0393, 0.0325, 0.1233,
        0.0789, 0.0798, 0.1043, 0.1131, 0.2848], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:48,885][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0241, 0.0501, 0.0309, 0.0559, 0.0851, 0.0386, 0.0688, 0.1254, 0.0507,
        0.0809, 0.0449, 0.1067, 0.0927, 0.1066, 0.0388], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,890][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.1748, 0.0577, 0.0151, 0.0892, 0.0224, 0.0641, 0.1276, 0.1060, 0.0710,
        0.0219, 0.0479, 0.1055, 0.0456, 0.0146, 0.0367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,895][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.1949, 0.0014, 0.0118, 0.0663, 0.0827, 0.0843, 0.0052, 0.0321, 0.0311,
        0.0848, 0.0764, 0.0796, 0.0383, 0.2026, 0.0084], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,896][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.2228, 0.0358, 0.0345, 0.0960, 0.0856, 0.0898, 0.0359, 0.0431, 0.0369,
        0.0919, 0.0527, 0.0359, 0.0611, 0.0477, 0.0303], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,897][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0207, 0.0386, 0.0517, 0.0617, 0.0580, 0.0992, 0.1751, 0.0322, 0.0502,
        0.0597, 0.0926, 0.0445, 0.0878, 0.0658, 0.0622], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,898][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0240, 0.1224, 0.1058, 0.0875, 0.0343, 0.0582, 0.0393, 0.0895, 0.0143,
        0.0500, 0.0899, 0.1097, 0.0941, 0.0527, 0.0282], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,899][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0234, 0.0504, 0.0798, 0.0347, 0.0685, 0.0929, 0.1287, 0.0668, 0.0595,
        0.0311, 0.0384, 0.1207, 0.0625, 0.0647, 0.0777], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,905][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0450, 0.0761, 0.0724, 0.0567, 0.0694, 0.0621, 0.0935, 0.0917, 0.0791,
        0.0476, 0.0537, 0.1244, 0.0280, 0.0527, 0.0478], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,908][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0051, 0.0175, 0.0344, 0.0357, 0.0660, 0.0574, 0.0448, 0.0461, 0.0505,
        0.0675, 0.0671, 0.1057, 0.1187, 0.1638, 0.1199], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,909][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0078, 0.0205, 0.0239, 0.0421, 0.0489, 0.0571, 0.0756, 0.0959, 0.0654,
        0.0465, 0.0766, 0.1145, 0.1009, 0.1096, 0.1147], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,910][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0088, 0.0140, 0.0348, 0.0333, 0.0590, 0.0822, 0.0650, 0.0716, 0.0833,
        0.0405, 0.0688, 0.0818, 0.0702, 0.1601, 0.1266], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,911][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0030, 0.0243, 0.0129, 0.0234, 0.0286, 0.0224, 0.0320, 0.0341, 0.1050,
        0.0797, 0.0720, 0.0758, 0.0959, 0.2063, 0.1847], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:48,913][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0271, 0.0493, 0.0342, 0.0553, 0.0815, 0.0392, 0.0698, 0.1112, 0.0318,
        0.0554, 0.0414, 0.1100, 0.0815, 0.1066, 0.0466, 0.0591],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,919][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0682, 0.0475, 0.0417, 0.0510, 0.0369, 0.0603, 0.1812, 0.0500, 0.0474,
        0.0278, 0.0873, 0.1153, 0.0643, 0.0330, 0.0606, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,921][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4635, 0.0007, 0.0025, 0.0436, 0.0322, 0.0534, 0.0037, 0.0655, 0.0623,
        0.0199, 0.0658, 0.0307, 0.0087, 0.0934, 0.0266, 0.0275],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,922][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2534, 0.0405, 0.0319, 0.0904, 0.0699, 0.0738, 0.0288, 0.0329, 0.0286,
        0.0798, 0.0434, 0.0301, 0.0640, 0.0398, 0.0255, 0.0672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,923][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0220, 0.0427, 0.0440, 0.0699, 0.0786, 0.0668, 0.1557, 0.0468, 0.0575,
        0.0496, 0.0579, 0.0377, 0.0714, 0.0896, 0.0590, 0.0509],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,924][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0183, 0.0782, 0.0772, 0.0852, 0.0707, 0.1025, 0.0749, 0.0625, 0.0059,
        0.0128, 0.0569, 0.0719, 0.0684, 0.1170, 0.0836, 0.0140],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,929][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0302, 0.0538, 0.0740, 0.0438, 0.0690, 0.0848, 0.1064, 0.0679, 0.0504,
        0.0339, 0.0438, 0.1020, 0.0682, 0.0627, 0.0787, 0.0304],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,934][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0551, 0.0553, 0.0722, 0.0315, 0.0727, 0.0613, 0.1084, 0.0946, 0.0756,
        0.0268, 0.0331, 0.1455, 0.0176, 0.0545, 0.0746, 0.0211],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,935][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0062, 0.0178, 0.0362, 0.0345, 0.0670, 0.0503, 0.0452, 0.0444, 0.0473,
        0.0484, 0.0642, 0.0988, 0.0913, 0.1566, 0.1106, 0.0811],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,936][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0044, 0.0138, 0.0271, 0.0321, 0.0558, 0.0465, 0.0872, 0.0770, 0.0601,
        0.0325, 0.0586, 0.1301, 0.0708, 0.1269, 0.1191, 0.0579],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,937][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0118, 0.0163, 0.0355, 0.0351, 0.0558, 0.0774, 0.0638, 0.0703, 0.0789,
        0.0421, 0.0658, 0.0726, 0.0701, 0.1379, 0.1144, 0.0523],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,939][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0029, 0.0188, 0.0109, 0.0160, 0.0233, 0.0197, 0.0253, 0.0247, 0.0794,
        0.0540, 0.0544, 0.0692, 0.0672, 0.1618, 0.1588, 0.2136],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:48,946][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0275, 0.0465, 0.0281, 0.0449, 0.0577, 0.0333, 0.0620, 0.0986, 0.0580,
        0.0840, 0.0461, 0.0889, 0.0772, 0.0775, 0.0580, 0.0862, 0.0255],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,947][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0506, 0.0379, 0.0113, 0.0420, 0.0245, 0.0669, 0.2390, 0.0741, 0.0831,
        0.0116, 0.0362, 0.1335, 0.0294, 0.0179, 0.0604, 0.0097, 0.0717],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,948][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.1573, 0.0005, 0.0048, 0.0168, 0.0280, 0.0248, 0.0041, 0.0318, 0.0090,
        0.2167, 0.0307, 0.0199, 0.0116, 0.0797, 0.0536, 0.3037, 0.0071],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,949][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.2093, 0.0346, 0.0327, 0.0883, 0.0765, 0.0776, 0.0317, 0.0382, 0.0330,
        0.0824, 0.0458, 0.0323, 0.0572, 0.0432, 0.0280, 0.0654, 0.0236],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,950][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0217, 0.0524, 0.0469, 0.0745, 0.0712, 0.0768, 0.0819, 0.0338, 0.0329,
        0.0599, 0.0903, 0.0425, 0.0874, 0.0883, 0.0674, 0.0622, 0.0100],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,955][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0220, 0.0951, 0.0678, 0.0629, 0.0526, 0.0439, 0.0522, 0.1356, 0.0105,
        0.0412, 0.0873, 0.0549, 0.0928, 0.0852, 0.0452, 0.0440, 0.0068],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,960][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0244, 0.0469, 0.0733, 0.0319, 0.0634, 0.0837, 0.1136, 0.0618, 0.0497,
        0.0282, 0.0333, 0.1020, 0.0611, 0.0608, 0.0753, 0.0255, 0.0650],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,961][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0452, 0.0816, 0.0590, 0.0477, 0.0571, 0.0595, 0.1062, 0.0754, 0.0611,
        0.0402, 0.0364, 0.1075, 0.0255, 0.0417, 0.0492, 0.0293, 0.0774],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,962][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0040, 0.0141, 0.0277, 0.0288, 0.0542, 0.0453, 0.0383, 0.0377, 0.0412,
        0.0502, 0.0532, 0.0873, 0.0869, 0.1333, 0.0976, 0.0916, 0.1087],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,963][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0048, 0.0154, 0.0209, 0.0320, 0.0416, 0.0425, 0.0664, 0.0719, 0.0508,
        0.0334, 0.0562, 0.0999, 0.0736, 0.0924, 0.0976, 0.0614, 0.1392],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,966][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0089, 0.0139, 0.0305, 0.0308, 0.0508, 0.0697, 0.0580, 0.0625, 0.0736,
        0.0383, 0.0608, 0.0698, 0.0633, 0.1275, 0.1076, 0.0486, 0.0855],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,973][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0019, 0.0142, 0.0076, 0.0125, 0.0166, 0.0126, 0.0203, 0.0176, 0.0628,
        0.0434, 0.0387, 0.0523, 0.0552, 0.1263, 0.1272, 0.1836, 0.2073],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:48,974][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0226, 0.0419, 0.0320, 0.0573, 0.0671, 0.0242, 0.0497, 0.0909, 0.0415,
        0.0726, 0.0453, 0.0899, 0.0831, 0.0858, 0.0492, 0.0749, 0.0364, 0.0357],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,975][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0659, 0.0483, 0.0279, 0.0487, 0.0279, 0.0557, 0.1521, 0.0683, 0.0663,
        0.0195, 0.0397, 0.1174, 0.0485, 0.0249, 0.0712, 0.0194, 0.0623, 0.0359],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,976][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([4.9886e-01, 4.6830e-04, 8.3163e-04, 2.8628e-02, 1.6837e-02, 3.0525e-02,
        2.2064e-03, 1.2040e-02, 1.1023e-02, 9.8428e-02, 1.9873e-02, 1.5830e-02,
        8.1142e-03, 5.1169e-02, 1.0647e-02, 1.3705e-01, 5.4500e-02, 2.9670e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,979][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2471, 0.0317, 0.0284, 0.0869, 0.0714, 0.0735, 0.0265, 0.0316, 0.0268,
        0.0782, 0.0393, 0.0274, 0.0544, 0.0370, 0.0227, 0.0612, 0.0199, 0.0361],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,986][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0328, 0.0469, 0.0268, 0.0847, 0.0687, 0.0857, 0.0573, 0.0503, 0.0217,
        0.0669, 0.0774, 0.0331, 0.0757, 0.0781, 0.0579, 0.0681, 0.0152, 0.0529],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,987][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0169, 0.0810, 0.0636, 0.0532, 0.0662, 0.0659, 0.0625, 0.0934, 0.0072,
        0.0386, 0.0418, 0.0530, 0.0977, 0.1040, 0.0657, 0.0420, 0.0357, 0.0117],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,988][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0242, 0.0518, 0.0635, 0.0369, 0.0583, 0.0787, 0.0969, 0.0622, 0.0500,
        0.0306, 0.0374, 0.0973, 0.0589, 0.0545, 0.0690, 0.0275, 0.0663, 0.0362],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,989][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0432, 0.0656, 0.0666, 0.0325, 0.0634, 0.0553, 0.0972, 0.0710, 0.0638,
        0.0273, 0.0368, 0.1335, 0.0204, 0.0486, 0.0512, 0.0204, 0.0718, 0.0315],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,992][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0044, 0.0135, 0.0271, 0.0259, 0.0528, 0.0401, 0.0413, 0.0362, 0.0394,
        0.0380, 0.0460, 0.0874, 0.0688, 0.1260, 0.0936, 0.0627, 0.0974, 0.0996],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:48,999][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0023, 0.0099, 0.0207, 0.0223, 0.0443, 0.0317, 0.0724, 0.0599, 0.0473,
        0.0249, 0.0400, 0.1122, 0.0495, 0.1027, 0.0981, 0.0453, 0.1291, 0.0873],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,000][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0080, 0.0118, 0.0283, 0.0284, 0.0474, 0.0642, 0.0550, 0.0594, 0.0686,
        0.0357, 0.0562, 0.0643, 0.0603, 0.1243, 0.1021, 0.0456, 0.0783, 0.0621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,001][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0021, 0.0136, 0.0087, 0.0110, 0.0159, 0.0130, 0.0177, 0.0151, 0.0509,
        0.0343, 0.0324, 0.0477, 0.0424, 0.1057, 0.1013, 0.1395, 0.1728, 0.1759],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,002][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0188, 0.0373, 0.0297, 0.0429, 0.0632, 0.0280, 0.0652, 0.0862, 0.0409,
        0.0627, 0.0359, 0.0884, 0.0720, 0.0824, 0.0458, 0.0680, 0.0428, 0.0292,
        0.0606], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,004][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0590, 0.0644, 0.0198, 0.0648, 0.0365, 0.0331, 0.0611, 0.1026, 0.0465,
        0.0168, 0.0730, 0.1144, 0.0630, 0.0280, 0.0604, 0.0151, 0.0646, 0.0391,
        0.0378], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,012][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.3508, 0.0011, 0.0072, 0.0366, 0.0318, 0.0387, 0.0039, 0.0161, 0.0097,
        0.1222, 0.0201, 0.0184, 0.0170, 0.0781, 0.0177, 0.1595, 0.0418, 0.0260,
        0.0033], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,013][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.1674, 0.0329, 0.0328, 0.0785, 0.0709, 0.0742, 0.0335, 0.0398, 0.0347,
        0.0746, 0.0440, 0.0331, 0.0500, 0.0403, 0.0290, 0.0592, 0.0252, 0.0411,
        0.0388], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,014][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0189, 0.0463, 0.0309, 0.0559, 0.0772, 0.0540, 0.0832, 0.0256, 0.0153,
        0.0522, 0.0783, 0.0219, 0.0820, 0.0926, 0.0297, 0.0589, 0.0144, 0.0660,
        0.0966], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,015][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0110, 0.0655, 0.0564, 0.0421, 0.0390, 0.0516, 0.0626, 0.1791, 0.0102,
        0.0396, 0.0456, 0.0653, 0.0637, 0.0556, 0.0640, 0.0398, 0.0409, 0.0595,
        0.0085], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,019][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0168, 0.0363, 0.0680, 0.0261, 0.0562, 0.0741, 0.1026, 0.0535, 0.0490,
        0.0217, 0.0302, 0.0965, 0.0462, 0.0539, 0.0647, 0.0202, 0.0640, 0.0278,
        0.0921], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,025][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0451, 0.0916, 0.0607, 0.0370, 0.0543, 0.0488, 0.0954, 0.0611, 0.0519,
        0.0288, 0.0271, 0.1196, 0.0174, 0.0384, 0.0444, 0.0205, 0.0694, 0.0264,
        0.0620], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,026][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0036, 0.0122, 0.0217, 0.0249, 0.0421, 0.0376, 0.0272, 0.0304, 0.0306,
        0.0422, 0.0436, 0.0616, 0.0790, 0.1010, 0.0708, 0.0773, 0.0829, 0.1112,
        0.1002], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,027][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0067, 0.0158, 0.0155, 0.0311, 0.0297, 0.0400, 0.0467, 0.0613, 0.0403,
        0.0298, 0.0487, 0.0661, 0.0661, 0.0574, 0.0695, 0.0491, 0.1057, 0.1136,
        0.1070], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,027][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0077, 0.0117, 0.0282, 0.0267, 0.0462, 0.0645, 0.0512, 0.0548, 0.0650,
        0.0325, 0.0541, 0.0632, 0.0551, 0.1177, 0.0970, 0.0413, 0.0755, 0.0567,
        0.0507], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,032][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0017, 0.0098, 0.0055, 0.0097, 0.0120, 0.0087, 0.0128, 0.0107, 0.0353,
        0.0250, 0.0221, 0.0311, 0.0346, 0.0819, 0.0723, 0.1119, 0.1198, 0.1395,
        0.2556], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,038][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0220, 0.0391, 0.0273, 0.0450, 0.0644, 0.0318, 0.0552, 0.0886, 0.0255,
        0.0437, 0.0335, 0.0878, 0.0664, 0.0844, 0.0355, 0.0468, 0.0350, 0.0351,
        0.0840, 0.0487], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,039][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0666, 0.0341, 0.0321, 0.0489, 0.0301, 0.0434, 0.1268, 0.0397, 0.0398,
        0.0276, 0.0761, 0.0882, 0.0536, 0.0264, 0.0395, 0.0273, 0.0538, 0.0647,
        0.0558, 0.0254], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,039][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3952, 0.0006, 0.0019, 0.0348, 0.0246, 0.0421, 0.0030, 0.0521, 0.0440,
        0.0143, 0.0559, 0.0259, 0.0071, 0.0721, 0.0210, 0.0202, 0.0812, 0.0522,
        0.0274, 0.0243], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,040][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2036, 0.0320, 0.0287, 0.0774, 0.0643, 0.0693, 0.0272, 0.0320, 0.0273,
        0.0677, 0.0367, 0.0276, 0.0479, 0.0334, 0.0229, 0.0545, 0.0200, 0.0351,
        0.0355, 0.0570], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,045][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0169, 0.0339, 0.0305, 0.0571, 0.0581, 0.0578, 0.1099, 0.0363, 0.0443,
        0.0424, 0.0480, 0.0305, 0.0600, 0.0667, 0.0468, 0.0435, 0.0246, 0.0485,
        0.1097, 0.0343], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,050][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0147, 0.0613, 0.0604, 0.0688, 0.0570, 0.0808, 0.0604, 0.0515, 0.0046,
        0.0105, 0.0466, 0.0583, 0.0562, 0.0944, 0.0673, 0.0113, 0.0543, 0.0350,
        0.0960, 0.0109], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,051][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0238, 0.0438, 0.0576, 0.0352, 0.0550, 0.0673, 0.0845, 0.0546, 0.0397,
        0.0268, 0.0350, 0.0823, 0.0557, 0.0497, 0.0623, 0.0238, 0.0538, 0.0352,
        0.0909, 0.0229], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,052][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0436, 0.0589, 0.0603, 0.0279, 0.0602, 0.0487, 0.0921, 0.0803, 0.0593,
        0.0226, 0.0254, 0.1194, 0.0135, 0.0419, 0.0564, 0.0169, 0.0676, 0.0245,
        0.0630, 0.0174], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,053][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0047, 0.0126, 0.0242, 0.0240, 0.0452, 0.0318, 0.0307, 0.0295, 0.0303,
        0.0305, 0.0413, 0.0673, 0.0610, 0.1039, 0.0720, 0.0490, 0.0722, 0.0883,
        0.1113, 0.0702], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,058][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0024, 0.0086, 0.0181, 0.0201, 0.0367, 0.0273, 0.0580, 0.0468, 0.0371,
        0.0190, 0.0333, 0.0842, 0.0398, 0.0780, 0.0736, 0.0325, 0.0964, 0.0697,
        0.1630, 0.0553], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,063][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0097, 0.0132, 0.0283, 0.0281, 0.0443, 0.0593, 0.0516, 0.0548, 0.0625,
        0.0351, 0.0524, 0.0581, 0.0562, 0.1040, 0.0890, 0.0437, 0.0698, 0.0573,
        0.0493, 0.0333], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,064][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0021, 0.0106, 0.0056, 0.0080, 0.0106, 0.0086, 0.0114, 0.0104, 0.0312,
        0.0216, 0.0218, 0.0274, 0.0283, 0.0614, 0.0579, 0.0783, 0.0968, 0.1051,
        0.1823, 0.2205], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,103][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:49,104][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,105][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,105][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,106][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,109][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,113][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,116][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,117][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,118][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,118][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,119][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,119][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,122][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4306, 0.5694], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,127][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2475, 0.7525], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,133][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9124, 0.0876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,134][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,134][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2561, 0.7439], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,135][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,136][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3860, 0.6140], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,138][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2820, 0.7180], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,144][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4496, 0.5504], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,146][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2101, 0.7899], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,147][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0939, 0.9061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,148][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5756, 0.4244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,148][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.2993, 0.4367, 0.2640], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,149][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0226, 0.8243, 0.1531], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,153][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.4892, 0.0703, 0.4405], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,159][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0016, 0.2233, 0.7751], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,160][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0597, 0.2494, 0.6909], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,160][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0014, 0.5190, 0.4796], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,161][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.1529, 0.2588, 0.5884], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,162][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.1819, 0.4790, 0.3390], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,163][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.2495, 0.5525, 0.1980], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,170][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0839, 0.5985, 0.3177], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,172][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0377, 0.4959, 0.4664], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,173][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.3487, 0.2705, 0.3809], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,173][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1965, 0.3124, 0.2654, 0.2257], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,174][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0289, 0.7320, 0.2195, 0.0196], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,175][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.5448, 0.0506, 0.3014, 0.1032], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,179][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0007, 0.0523, 0.4710, 0.4759], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,184][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0630, 0.1637, 0.5337, 0.2396], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,185][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([4.7134e-04, 8.5851e-02, 1.9541e-01, 7.1826e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,186][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1441, 0.2368, 0.4499, 0.1692], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,186][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1396, 0.3429, 0.2578, 0.2597], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,187][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1368, 0.2970, 0.2420, 0.3242], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,190][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0527, 0.3509, 0.4334, 0.1631], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,197][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0371, 0.2586, 0.2260, 0.4783], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,198][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2541, 0.2204, 0.2887, 0.2369], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,198][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.1189, 0.1909, 0.2068, 0.2045, 0.2789], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,199][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0550, 0.6431, 0.2339, 0.0376, 0.0304], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,200][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1772, 0.0167, 0.1259, 0.0613, 0.6188], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,201][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([1.8574e-04, 1.4567e-02, 1.1104e-01, 3.3459e-01, 5.3961e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,207][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0215, 0.0826, 0.2342, 0.1429, 0.5188], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,210][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([5.4781e-05, 1.8485e-02, 4.0255e-02, 5.0447e-01, 4.3674e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,211][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0874, 0.1509, 0.3497, 0.1207, 0.2913], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,211][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.1023, 0.2651, 0.1962, 0.2106, 0.2258], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,212][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0806, 0.1905, 0.1207, 0.3533, 0.2550], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,213][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0396, 0.2702, 0.3399, 0.1979, 0.1523], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,217][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0148, 0.1737, 0.1572, 0.3920, 0.2623], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,222][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.1978, 0.1533, 0.2191, 0.2091, 0.2208], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,223][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.1166, 0.1810, 0.1164, 0.1590, 0.3522, 0.0747], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,224][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0894, 0.2127, 0.3744, 0.0902, 0.0999, 0.1335], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,225][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1288, 0.0095, 0.1076, 0.0320, 0.6261, 0.0959], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,225][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([8.6875e-05, 9.5597e-03, 4.0440e-02, 1.6072e-01, 5.2197e-01, 2.6722e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,230][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0241, 0.0652, 0.1984, 0.0985, 0.4482, 0.1655], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,234][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([3.7295e-05, 6.3160e-03, 1.9087e-02, 1.5260e-01, 3.2062e-01, 5.0133e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,235][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0817, 0.1326, 0.2320, 0.0982, 0.2230, 0.2325], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,236][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0836, 0.2260, 0.1646, 0.1772, 0.1885, 0.1601], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,237][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0922, 0.1720, 0.0880, 0.2227, 0.1832, 0.2419], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,238][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0378, 0.2466, 0.1996, 0.1713, 0.2759, 0.0689], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,238][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0180, 0.1281, 0.1123, 0.2514, 0.1819, 0.3084], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,242][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.1526, 0.1355, 0.2054, 0.1486, 0.1972, 0.1608], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,245][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0753, 0.1361, 0.1226, 0.1362, 0.2975, 0.1167, 0.1156],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,249][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0476, 0.1745, 0.1252, 0.0239, 0.0065, 0.0587, 0.5636],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,250][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0536, 0.0048, 0.0375, 0.0162, 0.1753, 0.0553, 0.6573],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,250][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([3.9500e-05, 3.7880e-03, 1.5244e-02, 8.4575e-02, 2.5695e-01, 4.4484e-01,
        1.9456e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,251][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0145, 0.0497, 0.1403, 0.0863, 0.3136, 0.1571, 0.2384],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,252][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([9.7759e-06, 1.9220e-03, 4.7718e-03, 6.1484e-02, 7.6267e-02, 7.6274e-01,
        9.2810e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,253][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0548, 0.0852, 0.2017, 0.0607, 0.1721, 0.1784, 0.2471],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,255][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0688, 0.1851, 0.1384, 0.1517, 0.1585, 0.1446, 0.1530],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,257][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0284, 0.0709, 0.0480, 0.1138, 0.1383, 0.4535, 0.1471],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,260][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0242, 0.1830, 0.1589, 0.1498, 0.2755, 0.1720, 0.0367],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,264][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0078, 0.0955, 0.0813, 0.2139, 0.1392, 0.2697, 0.1925],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,265][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.1327, 0.1108, 0.1415, 0.1384, 0.1549, 0.1827, 0.1389],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,266][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0874, 0.1222, 0.0874, 0.1288, 0.1883, 0.0841, 0.1439, 0.1580],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,266][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.1030, 0.0597, 0.0279, 0.0551, 0.0135, 0.0149, 0.5698, 0.1562],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,267][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0448, 0.0034, 0.0302, 0.0111, 0.1262, 0.0333, 0.4656, 0.2854],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,268][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([4.5961e-05, 1.3195e-03, 5.0515e-03, 3.0033e-02, 1.1064e-01, 9.5055e-02,
        1.2273e-01, 6.3513e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,270][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0136, 0.0416, 0.1352, 0.0685, 0.2957, 0.1164, 0.2100, 0.1191],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,272][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([1.0875e-05, 6.4601e-04, 2.1837e-03, 1.8922e-02, 1.8245e-02, 2.6159e-01,
        9.7006e-02, 6.0139e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,274][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0511, 0.0798, 0.1611, 0.0594, 0.1560, 0.1711, 0.2136, 0.1080],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,279][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0666, 0.1614, 0.1190, 0.1271, 0.1331, 0.1173, 0.1365, 0.1389],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,280][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0134, 0.0513, 0.0409, 0.0866, 0.1134, 0.2640, 0.3690, 0.0614],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,281][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0287, 0.1785, 0.1453, 0.1237, 0.2182, 0.1277, 0.1022, 0.0758],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,281][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0097, 0.0785, 0.0660, 0.1597, 0.1103, 0.2061, 0.1610, 0.2088],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,282][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.1287, 0.0969, 0.1585, 0.1101, 0.1446, 0.1417, 0.1318, 0.0878],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,285][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0681, 0.1015, 0.0713, 0.1193, 0.1648, 0.0713, 0.1259, 0.2198, 0.0579],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,292][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0030, 0.1733, 0.0127, 0.0080, 0.0038, 0.0075, 0.4324, 0.3329, 0.0263],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,293][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0273, 0.0024, 0.0187, 0.0093, 0.0782, 0.0254, 0.3204, 0.2359, 0.2826],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,293][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([4.8328e-06, 1.2614e-04, 5.3484e-04, 2.7833e-03, 1.7627e-02, 8.0234e-03,
        3.6187e-02, 2.5609e-01, 6.7863e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,294][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0113, 0.0358, 0.1046, 0.0621, 0.2285, 0.1073, 0.1787, 0.1118, 0.1598],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,295][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([6.7336e-07, 5.3139e-05, 1.2292e-04, 1.8119e-03, 3.1541e-03, 1.6722e-02,
        1.3888e-02, 3.2265e-01, 6.4160e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,299][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0446, 0.0656, 0.1527, 0.0493, 0.1382, 0.1544, 0.2059, 0.1023, 0.0869],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,305][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0565, 0.1464, 0.1046, 0.1186, 0.1215, 0.1058, 0.1211, 0.1270, 0.0985],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,305][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0128, 0.0429, 0.0266, 0.0692, 0.1080, 0.3209, 0.1666, 0.2217, 0.0312],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,306][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0191, 0.1641, 0.1098, 0.1067, 0.2429, 0.1106, 0.0844, 0.1255, 0.0370],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,307][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0066, 0.0638, 0.0543, 0.1419, 0.0939, 0.1832, 0.1335, 0.1905, 0.1323],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,308][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.1072, 0.0929, 0.1284, 0.1139, 0.1361, 0.1211, 0.1217, 0.1004, 0.0782],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,313][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0655, 0.0939, 0.0674, 0.0961, 0.1523, 0.0744, 0.1204, 0.1877, 0.0563,
        0.0861], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,317][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0119, 0.0800, 0.1700, 0.0147, 0.0151, 0.0452, 0.5856, 0.0642, 0.0091,
        0.0043], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,318][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0613, 0.0024, 0.0214, 0.0075, 0.0726, 0.0233, 0.3329, 0.2094, 0.2483,
        0.0209], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,319][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.4815e-06, 7.5191e-05, 3.6467e-04, 1.2820e-03, 7.4476e-03, 4.8044e-03,
        2.4773e-02, 1.1425e-01, 3.0647e-01, 5.4052e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,320][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0109, 0.0328, 0.0961, 0.0499, 0.2142, 0.0928, 0.1742, 0.1057, 0.1538,
        0.0697], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,320][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.2722e-07, 1.5735e-05, 4.2612e-05, 5.2568e-04, 5.7904e-04, 4.6428e-03,
        3.9668e-03, 2.3967e-02, 1.4136e-01, 8.2490e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,325][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0495, 0.0731, 0.1337, 0.0621, 0.1252, 0.1420, 0.1848, 0.1064, 0.0792,
        0.0440], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,330][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0542, 0.1325, 0.0980, 0.1044, 0.1120, 0.0953, 0.1110, 0.1183, 0.0919,
        0.0824], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,331][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0121, 0.0393, 0.0271, 0.0657, 0.1238, 0.2163, 0.2153, 0.1457, 0.1217,
        0.0331], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,332][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0263, 0.1267, 0.1455, 0.0792, 0.1701, 0.0893, 0.1325, 0.1351, 0.0726,
        0.0226], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,332][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0102, 0.0638, 0.0525, 0.1144, 0.0813, 0.1353, 0.1189, 0.1447, 0.1085,
        0.1704], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,333][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0965, 0.0957, 0.0987, 0.1173, 0.1163, 0.1161, 0.1005, 0.0953, 0.0681,
        0.0954], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,338][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0546, 0.0839, 0.0712, 0.0903, 0.1324, 0.0586, 0.0973, 0.1744, 0.0755,
        0.1097, 0.0522], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,343][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0125, 0.0150, 0.0808, 0.0087, 0.0367, 0.0230, 0.6128, 0.1301, 0.0715,
        0.0011, 0.0077], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,343][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0299, 0.0024, 0.0187, 0.0078, 0.0676, 0.0223, 0.2701, 0.1940, 0.2388,
        0.0478, 0.1006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,344][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.1648e-06, 1.5167e-05, 9.6873e-05, 3.7751e-04, 2.0291e-03, 1.6135e-03,
        7.0266e-03, 2.7187e-02, 1.8905e-01, 4.3512e-01, 3.3748e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,345][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0085, 0.0273, 0.0844, 0.0430, 0.1958, 0.0797, 0.1570, 0.0911, 0.1368,
        0.0697, 0.1067], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,346][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.4106e-07, 4.4847e-06, 1.3495e-05, 1.2642e-04, 2.0304e-04, 1.4298e-03,
        1.3894e-03, 1.3455e-02, 8.8912e-02, 6.7718e-01, 2.1728e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,351][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0457, 0.0707, 0.1288, 0.0569, 0.1124, 0.1349, 0.1646, 0.1046, 0.0876,
        0.0427, 0.0510], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,355][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0494, 0.1204, 0.0909, 0.0965, 0.1031, 0.0892, 0.1006, 0.1052, 0.0822,
        0.0750, 0.0876], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,356][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0155, 0.0432, 0.0336, 0.0802, 0.1007, 0.1529, 0.1934, 0.1679, 0.0759,
        0.1053, 0.0314], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,357][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0188, 0.1249, 0.1084, 0.0784, 0.1745, 0.0731, 0.0960, 0.1499, 0.0664,
        0.0453, 0.0642], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,358][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0075, 0.0526, 0.0437, 0.0990, 0.0689, 0.1171, 0.1008, 0.1262, 0.0935,
        0.1518, 0.1390], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,359][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0946, 0.0844, 0.1000, 0.1065, 0.1030, 0.1044, 0.1063, 0.0807, 0.0620,
        0.0862, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,364][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0524, 0.0751, 0.0563, 0.0744, 0.1432, 0.0506, 0.0863, 0.1390, 0.0820,
        0.0993, 0.0526, 0.0887], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,368][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0118, 0.0482, 0.0173, 0.0184, 0.0162, 0.0013, 0.1226, 0.1262, 0.1040,
        0.0019, 0.0177, 0.5143], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,369][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0093, 0.0008, 0.0067, 0.0041, 0.0292, 0.0107, 0.1385, 0.1037, 0.1466,
        0.0306, 0.0746, 0.4452], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,370][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([1.9501e-07, 3.9926e-06, 1.8926e-05, 8.0059e-05, 3.3272e-04, 6.6130e-04,
        1.2913e-03, 9.8596e-03, 7.0906e-02, 8.5418e-02, 5.6180e-01, 2.6963e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,370][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0054, 0.0213, 0.0599, 0.0401, 0.1361, 0.0741, 0.1165, 0.0693, 0.0965,
        0.0512, 0.0842, 0.2455], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,371][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([3.5426e-08, 1.0666e-06, 9.8311e-06, 3.3905e-05, 8.0455e-05, 4.9522e-04,
        1.3648e-03, 5.7111e-03, 5.0222e-02, 3.3985e-01, 3.8991e-01, 2.1232e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,375][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0319, 0.0482, 0.1201, 0.0347, 0.1076, 0.1140, 0.1732, 0.0784, 0.0724,
        0.0276, 0.0397, 0.1521], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,381][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0414, 0.1101, 0.0812, 0.0901, 0.0918, 0.0827, 0.0932, 0.0966, 0.0751,
        0.0696, 0.0796, 0.0888], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,381][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0165, 0.0444, 0.0214, 0.0690, 0.0617, 0.1120, 0.1585, 0.1640, 0.1449,
        0.0883, 0.0643, 0.0549], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,382][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0119, 0.0924, 0.1167, 0.0712, 0.1689, 0.0562, 0.0633, 0.1026, 0.0543,
        0.0327, 0.1047, 0.1252], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,383][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0038, 0.0422, 0.0365, 0.0934, 0.0606, 0.1118, 0.0842, 0.1210, 0.0832,
        0.1447, 0.1340, 0.0847], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,384][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0870, 0.0683, 0.0953, 0.0818, 0.0939, 0.0959, 0.1062, 0.0700, 0.0578,
        0.0654, 0.0648, 0.1137], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,391][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0464, 0.0644, 0.0582, 0.0637, 0.1432, 0.0506, 0.0698, 0.1281, 0.0606,
        0.0809, 0.0555, 0.1080, 0.0706], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,393][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0317, 0.0391, 0.0989, 0.0099, 0.0154, 0.0255, 0.3435, 0.1846, 0.0078,
        0.0040, 0.0299, 0.0419, 0.1678], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,394][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0210, 0.0013, 0.0105, 0.0044, 0.0367, 0.0125, 0.1408, 0.0976, 0.1235,
        0.0256, 0.0591, 0.3663, 0.1008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,395][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([5.1124e-07, 6.4309e-06, 5.2326e-05, 1.4011e-04, 4.3159e-04, 6.3287e-04,
        9.7800e-04, 6.1582e-03, 3.4454e-02, 8.8941e-02, 1.2170e-01, 3.0036e-01,
        4.4614e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,396][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0061, 0.0188, 0.0593, 0.0304, 0.1401, 0.0563, 0.0930, 0.0567, 0.0849,
        0.0485, 0.0717, 0.2303, 0.1038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,397][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([4.7169e-08, 1.1206e-06, 2.5885e-06, 2.0437e-05, 3.1996e-05, 2.6410e-04,
        1.8342e-04, 1.5357e-03, 9.4394e-03, 9.2834e-02, 9.3008e-02, 2.3750e-01,
        5.6518e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,403][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0323, 0.0571, 0.1091, 0.0434, 0.0995, 0.1000, 0.1256, 0.0794, 0.0599,
        0.0347, 0.0466, 0.1385, 0.0739], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,406][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0411, 0.1018, 0.0797, 0.0803, 0.0903, 0.0730, 0.0839, 0.0878, 0.0731,
        0.0636, 0.0747, 0.0819, 0.0687], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,406][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0221, 0.0406, 0.0404, 0.0575, 0.1155, 0.1120, 0.1412, 0.1036, 0.0790,
        0.0891, 0.0580, 0.1032, 0.0380], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,407][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0178, 0.0725, 0.0754, 0.0647, 0.1080, 0.0656, 0.0617, 0.0913, 0.0510,
        0.0347, 0.0801, 0.2233, 0.0538], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,408][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0076, 0.0456, 0.0386, 0.0795, 0.0583, 0.0904, 0.0846, 0.0994, 0.0752,
        0.1161, 0.1066, 0.0765, 0.1214], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,411][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0787, 0.0621, 0.0860, 0.0825, 0.0921, 0.0807, 0.0922, 0.0658, 0.0552,
        0.0734, 0.0670, 0.1001, 0.0643], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:49,418][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0351, 0.0593, 0.0604, 0.0622, 0.0836, 0.0444, 0.0620, 0.1267, 0.0662,
        0.0818, 0.0448, 0.1093, 0.0867, 0.0775], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,419][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([1.8585e-03, 2.5145e-02, 1.6873e-02, 1.1585e-03, 1.5032e-03, 1.0612e-03,
        1.6894e-01, 1.7711e-02, 3.2680e-02, 1.8324e-04, 5.8416e-03, 2.0537e-01,
        5.1807e-01, 3.6037e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,420][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([5.6117e-03, 3.8544e-04, 2.7899e-03, 2.0230e-03, 9.5136e-03, 4.4918e-03,
        6.4244e-02, 4.7222e-02, 6.2988e-02, 1.0943e-02, 3.4028e-02, 2.3833e-01,
        7.7413e-02, 4.4002e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,421][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([1.3003e-07, 9.6329e-07, 6.3646e-06, 1.4853e-05, 2.3215e-05, 1.0604e-04,
        1.4994e-04, 1.3807e-03, 7.6067e-03, 1.9359e-02, 4.1648e-02, 7.1487e-02,
        1.8945e-01, 6.6877e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,422][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0042, 0.0156, 0.0428, 0.0287, 0.0992, 0.0494, 0.0815, 0.0519, 0.0665,
        0.0374, 0.0628, 0.1804, 0.1008, 0.1791], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,425][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([1.6679e-08, 3.1702e-07, 6.0965e-07, 5.7432e-06, 2.9490e-06, 7.8941e-05,
        7.0927e-05, 3.8110e-04, 3.8420e-03, 2.5687e-02, 3.8507e-02, 5.1440e-02,
        4.0637e-01, 4.7361e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,430][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0243, 0.0430, 0.1009, 0.0352, 0.0838, 0.0964, 0.1522, 0.0727, 0.0625,
        0.0222, 0.0310, 0.1504, 0.0499, 0.0755], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,431][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0370, 0.0928, 0.0710, 0.0753, 0.0818, 0.0721, 0.0791, 0.0821, 0.0638,
        0.0589, 0.0697, 0.0775, 0.0654, 0.0737], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,432][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0133, 0.0303, 0.0200, 0.0562, 0.0416, 0.1338, 0.1637, 0.1788, 0.0489,
        0.0772, 0.0439, 0.0989, 0.0359, 0.0575], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,433][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0099, 0.0692, 0.0808, 0.0511, 0.0353, 0.0575, 0.0473, 0.1239, 0.0704,
        0.0255, 0.0881, 0.2498, 0.0611, 0.0299], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,436][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0028, 0.0321, 0.0284, 0.0736, 0.0480, 0.0931, 0.0671, 0.0955, 0.0664,
        0.1161, 0.1098, 0.0679, 0.1216, 0.0777], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,443][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0685, 0.0533, 0.0755, 0.0712, 0.0758, 0.0856, 0.0973, 0.0556, 0.0499,
        0.0603, 0.0583, 0.1073, 0.0581, 0.0832], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:49,444][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0331, 0.0550, 0.0368, 0.0567, 0.0974, 0.0448, 0.0717, 0.1262, 0.0524,
        0.0728, 0.0377, 0.1120, 0.0727, 0.0930, 0.0377], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,445][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0024, 0.0199, 0.0084, 0.0072, 0.0025, 0.0062, 0.0715, 0.1277, 0.0182,
        0.0007, 0.0017, 0.1858, 0.3541, 0.0055, 0.1881], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,445][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([3.4523e-03, 3.1804e-04, 2.2371e-03, 1.5230e-03, 9.5076e-03, 3.0011e-03,
        4.9559e-02, 3.3599e-02, 4.4176e-02, 7.0621e-03, 2.3992e-02, 1.8368e-01,
        4.9893e-02, 3.7868e-01, 2.0931e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,447][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([2.9304e-08, 3.4614e-07, 1.9826e-06, 4.9799e-06, 1.4495e-05, 9.0096e-06,
        5.8205e-05, 4.3648e-04, 1.9556e-03, 8.3018e-03, 1.0770e-02, 3.7837e-02,
        8.9538e-02, 5.6461e-01, 2.8646e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,453][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0054, 0.0152, 0.0404, 0.0264, 0.0918, 0.0409, 0.0656, 0.0475, 0.0595,
        0.0369, 0.0594, 0.1463, 0.0942, 0.1716, 0.0988], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,455][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([6.0324e-09, 6.5249e-08, 1.8218e-07, 1.3578e-06, 1.6166e-06, 1.0162e-05,
        6.6098e-06, 7.2517e-05, 9.8442e-04, 5.0443e-03, 6.6794e-03, 1.8082e-02,
        1.1751e-01, 4.3650e-01, 4.1511e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,456][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0265, 0.0386, 0.0906, 0.0285, 0.0771, 0.0894, 0.1373, 0.0625, 0.0566,
        0.0247, 0.0304, 0.1301, 0.0482, 0.0696, 0.0900], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,457][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0349, 0.0880, 0.0656, 0.0723, 0.0754, 0.0657, 0.0733, 0.0797, 0.0629,
        0.0571, 0.0664, 0.0724, 0.0609, 0.0684, 0.0570], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,458][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0127, 0.0378, 0.0275, 0.0512, 0.0470, 0.1446, 0.1659, 0.0999, 0.0391,
        0.0841, 0.0406, 0.0907, 0.0431, 0.0657, 0.0502], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,461][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0100, 0.0744, 0.0765, 0.0511, 0.0921, 0.0426, 0.0365, 0.0789, 0.0502,
        0.0233, 0.0893, 0.1855, 0.0736, 0.0825, 0.0334], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,468][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0037, 0.0330, 0.0275, 0.0683, 0.0461, 0.0821, 0.0643, 0.0888, 0.0622,
        0.1057, 0.0983, 0.0618, 0.1098, 0.0704, 0.0780], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,469][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0637, 0.0522, 0.0791, 0.0620, 0.0762, 0.0719, 0.0814, 0.0540, 0.0502,
        0.0533, 0.0555, 0.0973, 0.0519, 0.0854, 0.0660], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:49,470][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0379, 0.0569, 0.0417, 0.0576, 0.0958, 0.0451, 0.0689, 0.1130, 0.0334,
        0.0528, 0.0349, 0.1132, 0.0672, 0.0913, 0.0421, 0.0482],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,471][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0083, 0.0482, 0.0841, 0.0084, 0.0071, 0.0192, 0.2103, 0.0241, 0.0030,
        0.0027, 0.0165, 0.0832, 0.3024, 0.0093, 0.1700, 0.0033],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,473][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0116, 0.0005, 0.0038, 0.0019, 0.0114, 0.0043, 0.0610, 0.0384, 0.0457,
        0.0039, 0.0223, 0.1522, 0.0515, 0.3086, 0.2401, 0.0428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,478][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.3622e-08, 1.3542e-07, 6.1025e-07, 1.5133e-06, 7.5082e-06, 5.0205e-06,
        2.5615e-05, 1.1075e-04, 2.3383e-04, 4.1634e-04, 3.5276e-03, 8.1105e-03,
        2.2791e-02, 2.0743e-01, 2.5980e-01, 4.9755e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,480][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0049, 0.0138, 0.0377, 0.0198, 0.0834, 0.0358, 0.0661, 0.0433, 0.0598,
        0.0280, 0.0527, 0.1499, 0.0787, 0.1765, 0.1057, 0.0437],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,481][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.7887e-09, 1.0589e-08, 2.4113e-08, 2.2439e-07, 1.9631e-07, 1.8177e-06,
        1.4647e-06, 7.6525e-06, 3.3836e-05, 2.0088e-04, 8.5508e-04, 1.7360e-03,
        1.6973e-02, 4.2189e-02, 1.2888e-01, 8.0912e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,482][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0304, 0.0438, 0.0839, 0.0382, 0.0782, 0.0875, 0.1152, 0.0650, 0.0492,
        0.0272, 0.0374, 0.1102, 0.0545, 0.0677, 0.0876, 0.0241],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,483][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0355, 0.0844, 0.0632, 0.0669, 0.0723, 0.0618, 0.0716, 0.0765, 0.0595,
        0.0532, 0.0609, 0.0697, 0.0565, 0.0655, 0.0555, 0.0470],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,486][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0255, 0.0169, 0.0415, 0.0727, 0.1214, 0.1323, 0.0918, 0.0755,
        0.0191, 0.0308, 0.0858, 0.0293, 0.0998, 0.1309, 0.0187],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,493][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0128, 0.0620, 0.0704, 0.0387, 0.0831, 0.0443, 0.0646, 0.0683, 0.0363,
        0.0115, 0.0733, 0.2393, 0.0520, 0.0804, 0.0542, 0.0087],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,494][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0065, 0.0365, 0.0291, 0.0614, 0.0439, 0.0690, 0.0639, 0.0764, 0.0577,
        0.0897, 0.0810, 0.0573, 0.0921, 0.0592, 0.0738, 0.1025],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,495][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0592, 0.0594, 0.0600, 0.0732, 0.0716, 0.0713, 0.0622, 0.0581, 0.0423,
        0.0590, 0.0567, 0.0712, 0.0578, 0.0783, 0.0655, 0.0543],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:49,496][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0357, 0.0508, 0.0335, 0.0460, 0.0690, 0.0393, 0.0670, 0.1057, 0.0604,
        0.0769, 0.0391, 0.0943, 0.0637, 0.0686, 0.0558, 0.0679, 0.0262],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,497][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.4566e-04, 5.3624e-03, 2.4550e-03, 6.1813e-04, 8.9931e-04, 8.3130e-04,
        1.3424e-01, 1.2448e-02, 9.3353e-03, 2.8770e-05, 3.5959e-04, 3.0267e-01,
        4.3509e-02, 2.6430e-03, 4.6813e-01, 4.8351e-05, 1.6274e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,500][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([2.5231e-03, 1.9748e-04, 1.4072e-03, 1.1179e-03, 6.2179e-03, 2.4106e-03,
        3.1678e-02, 2.3048e-02, 3.0105e-02, 6.6151e-03, 1.6804e-02, 9.8806e-02,
        3.4913e-02, 2.3431e-01, 1.6328e-01, 8.0897e-02, 2.6567e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,504][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([7.8335e-09, 3.2094e-08, 1.2525e-07, 6.1457e-07, 1.2985e-06, 2.3996e-06,
        6.9009e-06, 2.8905e-05, 1.1239e-04, 1.9452e-04, 1.3712e-03, 1.4310e-03,
        9.2576e-03, 4.5823e-02, 1.0691e-01, 2.7201e-01, 5.6285e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,508][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0041, 0.0118, 0.0348, 0.0198, 0.0800, 0.0365, 0.0552, 0.0382, 0.0522,
        0.0289, 0.0469, 0.1328, 0.0754, 0.1607, 0.0970, 0.0483, 0.0774],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,509][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([4.6215e-10, 2.3753e-09, 6.7103e-09, 4.6538e-08, 7.6912e-08, 4.1497e-07,
        4.3384e-07, 3.9984e-06, 2.2020e-05, 1.2623e-04, 2.6052e-04, 5.8218e-04,
        6.4519e-03, 2.2105e-02, 3.7490e-02, 6.2971e-01, 3.0325e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,510][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0258, 0.0358, 0.0825, 0.0264, 0.0710, 0.0821, 0.1213, 0.0588, 0.0482,
        0.0225, 0.0270, 0.1118, 0.0474, 0.0653, 0.0871, 0.0201, 0.0670],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,511][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0310, 0.0809, 0.0586, 0.0646, 0.0670, 0.0588, 0.0679, 0.0710, 0.0556,
        0.0516, 0.0581, 0.0647, 0.0547, 0.0603, 0.0521, 0.0456, 0.0574],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,515][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0128, 0.0295, 0.0222, 0.0328, 0.0615, 0.1172, 0.1327, 0.0778, 0.0343,
        0.0555, 0.0373, 0.0584, 0.0280, 0.0846, 0.1044, 0.0537, 0.0572],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,521][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0106, 0.0516, 0.0520, 0.0361, 0.0901, 0.0402, 0.0519, 0.0755, 0.0348,
        0.0166, 0.0748, 0.2425, 0.0580, 0.0841, 0.0448, 0.0125, 0.0237],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,522][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0043, 0.0305, 0.0244, 0.0573, 0.0389, 0.0664, 0.0557, 0.0731, 0.0525,
        0.0861, 0.0786, 0.0515, 0.0893, 0.0561, 0.0666, 0.0999, 0.0686],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,522][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0585, 0.0488, 0.0628, 0.0548, 0.0698, 0.0600, 0.0719, 0.0533, 0.0449,
        0.0494, 0.0511, 0.0868, 0.0458, 0.0786, 0.0689, 0.0448, 0.0497],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:49,523][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0309, 0.0479, 0.0392, 0.0602, 0.0806, 0.0296, 0.0541, 0.0968, 0.0442,
        0.0679, 0.0390, 0.0955, 0.0690, 0.0756, 0.0460, 0.0598, 0.0362, 0.0277],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,525][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.5634e-04, 4.4908e-03, 8.8497e-03, 9.9222e-04, 1.0247e-03, 3.3612e-03,
        1.0959e-01, 2.1304e-02, 4.7286e-03, 7.4723e-05, 4.2760e-04, 5.5251e-02,
        1.0473e-01, 2.2557e-03, 6.7611e-01, 1.0405e-04, 6.3014e-03, 4.8292e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,529][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.5431e-03, 2.2483e-04, 2.0698e-03, 1.2012e-03, 7.4844e-03, 2.6457e-03,
        3.2359e-02, 2.2493e-02, 2.6801e-02, 5.3512e-03, 1.4229e-02, 8.5271e-02,
        2.8615e-02, 1.9320e-01, 1.5049e-01, 5.7108e-02, 2.2876e-01, 1.3815e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,533][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([6.0764e-09, 1.5643e-08, 9.8297e-08, 2.2148e-07, 1.1226e-06, 4.7624e-07,
        2.9427e-06, 1.0638e-05, 7.4355e-05, 1.5317e-04, 3.5249e-04, 8.8110e-04,
        2.5353e-03, 2.8209e-02, 4.0104e-02, 1.7481e-01, 5.3175e-01, 2.2112e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,534][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0032, 0.0102, 0.0319, 0.0156, 0.0749, 0.0297, 0.0578, 0.0345, 0.0502,
        0.0277, 0.0387, 0.1375, 0.0669, 0.1560, 0.1034, 0.0457, 0.0753, 0.0407],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,535][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([6.9494e-10, 2.2542e-09, 6.4152e-09, 3.5596e-08, 7.0025e-08, 2.8076e-07,
        3.2509e-07, 2.1074e-06, 9.8486e-06, 9.9483e-05, 9.8773e-05, 3.9203e-04,
        2.6714e-03, 1.1625e-02, 1.7932e-02, 3.7653e-01, 3.3797e-01, 2.5267e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,536][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0257, 0.0423, 0.0725, 0.0321, 0.0663, 0.0795, 0.1044, 0.0603, 0.0488,
        0.0249, 0.0317, 0.1060, 0.0473, 0.0591, 0.0772, 0.0221, 0.0692, 0.0305],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,541][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0316, 0.0765, 0.0579, 0.0604, 0.0648, 0.0564, 0.0638, 0.0667, 0.0525,
        0.0473, 0.0557, 0.0627, 0.0518, 0.0593, 0.0491, 0.0420, 0.0525, 0.0488],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,546][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0106, 0.0241, 0.0177, 0.0392, 0.0430, 0.0840, 0.1121, 0.0674, 0.0387,
        0.0424, 0.0236, 0.0895, 0.0260, 0.0611, 0.0770, 0.0424, 0.1832, 0.0179],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,547][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0104, 0.0676, 0.0577, 0.0447, 0.0838, 0.0433, 0.0464, 0.0660, 0.0383,
        0.0264, 0.0435, 0.1697, 0.0634, 0.0769, 0.0537, 0.0198, 0.0592, 0.0290],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,548][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0052, 0.0308, 0.0241, 0.0524, 0.0367, 0.0572, 0.0534, 0.0646, 0.0484,
        0.0773, 0.0694, 0.0487, 0.0805, 0.0496, 0.0624, 0.0895, 0.0650, 0.0849],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,549][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0591, 0.0490, 0.0610, 0.0595, 0.0615, 0.0712, 0.0673, 0.0460, 0.0392,
        0.0502, 0.0462, 0.0775, 0.0469, 0.0685, 0.0629, 0.0456, 0.0539, 0.0345],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:49,553][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0268, 0.0416, 0.0355, 0.0455, 0.0750, 0.0349, 0.0711, 0.0913, 0.0462,
        0.0589, 0.0304, 0.0938, 0.0581, 0.0714, 0.0462, 0.0539, 0.0437, 0.0223,
        0.0533], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,557][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([5.5462e-04, 2.0271e-02, 3.0507e-02, 1.1194e-03, 8.6965e-03, 2.9205e-04,
        1.0393e-02, 2.9884e-02, 3.3382e-03, 1.0111e-04, 8.5963e-04, 1.4755e-01,
        1.2636e-01, 2.2909e-02, 5.5569e-01, 2.2519e-04, 2.7315e-02, 2.2778e-04,
        1.3704e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,558][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([8.6005e-04, 8.1236e-05, 6.1861e-04, 4.8345e-04, 1.7754e-03, 8.4057e-04,
        9.9272e-03, 7.0285e-03, 8.8536e-03, 1.8499e-03, 4.9853e-03, 2.3723e-02,
        1.0578e-02, 4.4700e-02, 4.4257e-02, 1.9325e-02, 7.8571e-02, 5.4513e-02,
        6.8703e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,559][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([3.1775e-10, 1.4093e-09, 8.2877e-09, 2.1399e-08, 5.5959e-08, 1.6316e-07,
        4.6679e-07, 2.1575e-06, 1.8398e-05, 2.2947e-05, 9.4085e-05, 1.6346e-04,
        5.9322e-04, 2.1363e-03, 6.9747e-03, 3.0554e-02, 1.3022e-01, 4.0423e-01,
        4.2500e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,560][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0025, 0.0095, 0.0265, 0.0181, 0.0621, 0.0324, 0.0510, 0.0332, 0.0434,
        0.0231, 0.0396, 0.1145, 0.0638, 0.1092, 0.0754, 0.0378, 0.0702, 0.0462,
        0.1417], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,561][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([3.7718e-11, 1.7919e-10, 8.6608e-10, 3.0056e-09, 5.3750e-09, 3.9069e-08,
        7.2346e-08, 4.7553e-07, 3.2191e-06, 1.7456e-05, 1.9470e-05, 6.6576e-05,
        5.4116e-04, 1.3987e-03, 4.8706e-03, 9.5619e-02, 1.7344e-01, 3.7098e-01,
        3.5305e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,566][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0187, 0.0284, 0.0755, 0.0221, 0.0625, 0.0725, 0.1087, 0.0513, 0.0468,
        0.0174, 0.0245, 0.1050, 0.0361, 0.0573, 0.0730, 0.0159, 0.0665, 0.0231,
        0.0948], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,571][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0264, 0.0710, 0.0528, 0.0587, 0.0606, 0.0530, 0.0597, 0.0621, 0.0489,
        0.0457, 0.0529, 0.0596, 0.0506, 0.0548, 0.0463, 0.0405, 0.0511, 0.0463,
        0.0589], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,572][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0111, 0.0243, 0.0124, 0.0420, 0.0332, 0.0749, 0.1077, 0.0963, 0.0434,
        0.0469, 0.0251, 0.0857, 0.0249, 0.0432, 0.0677, 0.0452, 0.1478, 0.0244,
        0.0438], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,572][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0067, 0.0563, 0.0694, 0.0367, 0.0722, 0.0465, 0.0504, 0.0556, 0.0332,
        0.0203, 0.0672, 0.1292, 0.0493, 0.0624, 0.0513, 0.0148, 0.0732, 0.0529,
        0.0525], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,573][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0022, 0.0239, 0.0198, 0.0510, 0.0325, 0.0590, 0.0446, 0.0646, 0.0445,
        0.0774, 0.0715, 0.0449, 0.0799, 0.0493, 0.0538, 0.0905, 0.0579, 0.0861,
        0.0465], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,578][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0516, 0.0398, 0.0613, 0.0463, 0.0658, 0.0644, 0.0643, 0.0389, 0.0381,
        0.0377, 0.0387, 0.0814, 0.0402, 0.0739, 0.0594, 0.0345, 0.0471, 0.0313,
        0.0855], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:49,583][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0321, 0.0468, 0.0342, 0.0485, 0.0777, 0.0381, 0.0571, 0.0929, 0.0282,
        0.0434, 0.0296, 0.0929, 0.0566, 0.0743, 0.0343, 0.0397, 0.0354, 0.0272,
        0.0730, 0.0379], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,584][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0034, 0.0345, 0.0578, 0.0043, 0.0042, 0.0132, 0.2234, 0.0165, 0.0021,
        0.0011, 0.0123, 0.0787, 0.2699, 0.0065, 0.2455, 0.0013, 0.0140, 0.0007,
        0.0099, 0.0007], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,585][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.5347e-03, 9.7766e-05, 7.7575e-04, 4.1609e-04, 1.9660e-03, 7.9761e-04,
        1.0985e-02, 6.8234e-03, 7.9952e-03, 7.3533e-04, 4.0827e-03, 2.4418e-02,
        9.8542e-03, 4.4779e-02, 3.9990e-02, 7.5224e-03, 7.6700e-02, 4.2971e-02,
        6.9797e-01, 1.8590e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,586][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6460e-09, 2.4927e-09, 1.2493e-08, 2.3872e-08, 1.3294e-07, 7.8065e-08,
        3.6062e-07, 1.4447e-06, 3.0534e-06, 5.1443e-06, 4.0628e-05, 9.4229e-05,
        2.5307e-04, 2.3367e-03, 2.6449e-03, 5.2852e-03, 5.9307e-02, 1.2530e-01,
        3.4189e-01, 4.6284e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,590][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0033, 0.0094, 0.0271, 0.0134, 0.0606, 0.0251, 0.0501, 0.0307, 0.0441,
        0.0199, 0.0360, 0.1146, 0.0547, 0.1263, 0.0807, 0.0301, 0.0611, 0.0373,
        0.1370, 0.0383], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,593][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.9222e-11, 1.2888e-10, 2.8059e-10, 2.1913e-09, 1.9046e-09, 1.5483e-08,
        1.3162e-08, 5.3812e-08, 2.3026e-07, 1.2405e-06, 4.7638e-06, 1.3113e-05,
        1.2404e-04, 2.1941e-04, 6.8766e-04, 4.1399e-03, 1.7521e-02, 5.1007e-02,
        2.6330e-01, 6.6298e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,595][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0239, 0.0357, 0.0661, 0.0306, 0.0626, 0.0698, 0.0920, 0.0527, 0.0391,
        0.0216, 0.0299, 0.0903, 0.0447, 0.0541, 0.0700, 0.0191, 0.0564, 0.0296,
        0.0935, 0.0185], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,596][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0287, 0.0682, 0.0514, 0.0546, 0.0590, 0.0507, 0.0587, 0.0620, 0.0483,
        0.0435, 0.0497, 0.0574, 0.0464, 0.0535, 0.0453, 0.0383, 0.0483, 0.0439,
        0.0590, 0.0329], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,597][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0058, 0.0180, 0.0121, 0.0291, 0.0517, 0.0848, 0.0891, 0.0654, 0.0510,
        0.0130, 0.0207, 0.0651, 0.0202, 0.0703, 0.0964, 0.0125, 0.1970, 0.0268,
        0.0581, 0.0131], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,598][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0106, 0.0479, 0.0547, 0.0304, 0.0644, 0.0346, 0.0511, 0.0538, 0.0284,
        0.0090, 0.0582, 0.1836, 0.0405, 0.0621, 0.0423, 0.0068, 0.0459, 0.0545,
        0.1153, 0.0059], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,602][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0054, 0.0285, 0.0224, 0.0465, 0.0331, 0.0503, 0.0479, 0.0570, 0.0433,
        0.0670, 0.0600, 0.0429, 0.0690, 0.0437, 0.0551, 0.0763, 0.0567, 0.0716,
        0.0422, 0.0812], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,607][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0479, 0.0476, 0.0483, 0.0590, 0.0575, 0.0583, 0.0507, 0.0465, 0.0344,
        0.0471, 0.0459, 0.0578, 0.0468, 0.0626, 0.0529, 0.0433, 0.0432, 0.0341,
        0.0738, 0.0423], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:49,611][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:49,614][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4950],
        [23562],
        [ 3018],
        [18339],
        [ 9489],
        [22988],
        [13275],
        [17270],
        [29963],
        [34977],
        [28516],
        [29222],
        [23698],
        [17662],
        [22403],
        [30866],
        [26754],
        [30371],
        [38417],
        [34139]], device='cuda:0')
[2024-07-24 10:16:49,617][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 8756],
        [27000],
        [  270],
        [19059],
        [ 2258],
        [10005],
        [ 3653],
        [12668],
        [27977],
        [20341],
        [23110],
        [17029],
        [15672],
        [22297],
        [22712],
        [20212],
        [15544],
        [16968],
        [28941],
        [20412]], device='cuda:0')
[2024-07-24 10:16:49,620][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13106],
        [11499],
        [13463],
        [15642],
        [18568],
        [19205],
        [19737],
        [18288],
        [19793],
        [19623],
        [20674],
        [20465],
        [19250],
        [19257],
        [19237],
        [18755],
        [19917],
        [20344],
        [20134],
        [19363]], device='cuda:0')
[2024-07-24 10:16:49,622][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27491],
        [28349],
        [39198],
        [40528],
        [36722],
        [33995],
        [31424],
        [31478],
        [32810],
        [36953],
        [36625],
        [31317],
        [33220],
        [31087],
        [29818],
        [32664],
        [32250],
        [32282],
        [30440],
        [31463]], device='cuda:0')
[2024-07-24 10:16:49,624][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[43164],
        [43190],
        [43218],
        [43670],
        [44002],
        [39972],
        [41628],
        [42893],
        [43177],
        [43369],
        [42505],
        [40703],
        [42191],
        [39969],
        [32631],
        [39553],
        [34748],
        [41053],
        [39191],
        [40371]], device='cuda:0')
[2024-07-24 10:16:49,626][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[166],
        [171],
        [176],
        [182],
        [189],
        [201],
        [208],
        [208],
        [209],
        [189],
        [184],
        [198],
        [187],
        [193],
        [198],
        [190],
        [197],
        [197],
        [213],
        [202]], device='cuda:0')
[2024-07-24 10:16:49,628][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[20475],
        [24929],
        [21376],
        [20703],
        [22746],
        [24646],
        [19991],
        [ 8398],
        [15438],
        [14819],
        [20721],
        [20867],
        [20333],
        [24456],
        [18091],
        [18876],
        [22162],
        [22863],
        [21873],
        [19725]], device='cuda:0')
[2024-07-24 10:16:49,631][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[33986],
        [27064],
        [25143],
        [26831],
        [30280],
        [28735],
        [28009],
        [28542],
        [36414],
        [32473],
        [35389],
        [34568],
        [35349],
        [36244],
        [34837],
        [33491],
        [35844],
        [34781],
        [37399],
        [34218]], device='cuda:0')
[2024-07-24 10:16:49,634][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25996],
        [29077],
        [29169],
        [29162],
        [26666],
        [28297],
        [29980],
        [30657],
        [30881],
        [31484],
        [31763],
        [31299],
        [31767],
        [30944],
        [31009],
        [31340],
        [31246],
        [31321],
        [30684],
        [31093]], device='cuda:0')
[2024-07-24 10:16:49,637][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 6013],
        [ 9177],
        [14028],
        [10968],
        [14056],
        [13621],
        [13181],
        [14912],
        [16338],
        [16817],
        [15707],
        [14403],
        [15309],
        [15317],
        [16592],
        [18026],
        [15756],
        [16750],
        [14018],
        [14780]], device='cuda:0')
[2024-07-24 10:16:49,638][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21818],
        [30869],
        [32832],
        [33955],
        [34077],
        [33792],
        [34669],
        [34489],
        [34825],
        [35518],
        [35300],
        [36086],
        [36287],
        [36328],
        [36618],
        [36887],
        [37073],
        [36681],
        [37025],
        [37224]], device='cuda:0')
[2024-07-24 10:16:49,640][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16726],
        [13505],
        [16451],
        [12233],
        [11405],
        [ 9801],
        [ 9910],
        [ 9516],
        [ 9395],
        [ 9528],
        [ 8972],
        [ 9186],
        [ 9296],
        [ 8756],
        [ 9000],
        [ 9487],
        [ 9141],
        [ 9245],
        [ 8966],
        [ 9875]], device='cuda:0')
[2024-07-24 10:16:49,642][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15434],
        [12605],
        [14814],
        [13852],
        [13742],
        [12219],
        [11886],
        [11448],
        [11009],
        [11024],
        [10615],
        [10714],
        [10627],
        [10639],
        [10685],
        [10698],
        [10447],
        [10328],
        [10397],
        [10357]], device='cuda:0')
[2024-07-24 10:16:49,645][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12092],
        [16049],
        [13210],
        [15790],
        [15816],
        [16864],
        [18377],
        [17346],
        [19871],
        [18201],
        [17702],
        [17997],
        [19102],
        [18313],
        [19391],
        [18642],
        [20631],
        [20283],
        [21066],
        [20254]], device='cuda:0')
[2024-07-24 10:16:49,648][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4518],
        [14366],
        [ 2979],
        [ 2150],
        [ 1536],
        [14502],
        [ 6342],
        [ 8086],
        [15260],
        [17094],
        [ 6401],
        [16392],
        [ 7725],
        [ 2264],
        [17169],
        [19785],
        [ 6177],
        [ 9785],
        [33881],
        [23656]], device='cuda:0')
[2024-07-24 10:16:49,651][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23500],
        [23863],
        [23016],
        [22067],
        [20255],
        [20004],
        [21476],
        [23398],
        [23507],
        [23176],
        [22879],
        [23286],
        [23778],
        [23487],
        [23586],
        [23400],
        [23513],
        [23234],
        [23594],
        [23521]], device='cuda:0')
[2024-07-24 10:16:49,652][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9563],
        [10297],
        [21761],
        [25360],
        [26776],
        [29876],
        [24299],
        [18928],
        [18543],
        [25123],
        [22517],
        [18711],
        [20332],
        [ 9586],
        [ 7459],
        [17773],
        [18961],
        [24856],
        [23468],
        [18845]], device='cuda:0')
[2024-07-24 10:16:49,654][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28422],
        [27810],
        [22975],
        [23938],
        [16878],
        [15564],
        [13985],
        [14170],
        [13564],
        [13849],
        [13350],
        [11868],
        [12360],
        [12388],
        [12095],
        [12030],
        [11886],
        [11896],
        [12510],
        [12546]], device='cuda:0')
[2024-07-24 10:16:49,656][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[26967],
        [28931],
        [29241],
        [32940],
        [34457],
        [34610],
        [34268],
        [45025],
        [35973],
        [38786],
        [36699],
        [25063],
        [25180],
        [31993],
        [32287],
        [37547],
        [39145],
        [39562],
        [30202],
        [35789]], device='cuda:0')
[2024-07-24 10:16:49,659][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17338],
        [19081],
        [23323],
        [23040],
        [25696],
        [25558],
        [23020],
        [21887],
        [21119],
        [21185],
        [21300],
        [22673],
        [23378],
        [24141],
        [24513],
        [24645],
        [24904],
        [25096],
        [25368],
        [25463]], device='cuda:0')
[2024-07-24 10:16:49,663][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28607],
        [26146],
        [24093],
        [24220],
        [20551],
        [13993],
        [13432],
        [ 9902],
        [14681],
        [19249],
        [20102],
        [22192],
        [26483],
        [21261],
        [14446],
        [19214],
        [19648],
        [19007],
        [14470],
        [21123]], device='cuda:0')
[2024-07-24 10:16:49,665][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[6758],
        [5761],
        [6832],
        [6523],
        [7737],
        [7293],
        [7564],
        [7483],
        [7152],
        [6937],
        [6943],
        [7616],
        [7402],
        [7894],
        [7668],
        [7501],
        [7649],
        [7623],
        [8053],
        [7900]], device='cuda:0')
[2024-07-24 10:16:49,666][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13294],
        [12113],
        [13201],
        [13238],
        [13159],
        [12806],
        [12670],
        [12091],
        [12001],
        [11839],
        [11823],
        [11655],
        [11601],
        [11719],
        [11514],
        [11465],
        [11446],
        [11385],
        [11442],
        [11453]], device='cuda:0')
[2024-07-24 10:16:49,668][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38924],
        [39230],
        [39625],
        [40780],
        [39899],
        [38368],
        [34329],
        [33518],
        [33433],
        [32632],
        [34279],
        [33734],
        [34904],
        [34590],
        [34771],
        [33856],
        [35231],
        [35947],
        [35613],
        [35395]], device='cuda:0')
[2024-07-24 10:16:49,670][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[20405],
        [21825],
        [25275],
        [26946],
        [27268],
        [26304],
        [25403],
        [24585],
        [24244],
        [23922],
        [23737],
        [23258],
        [21098],
        [20376],
        [21811],
        [20996],
        [20635],
        [20956],
        [21126],
        [20276]], device='cuda:0')
[2024-07-24 10:16:49,673][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7243],
        [ 9983],
        [ 8912],
        [12279],
        [13191],
        [14010],
        [13557],
        [13493],
        [13081],
        [14258],
        [15126],
        [14866],
        [15788],
        [16326],
        [15953],
        [16498],
        [16570],
        [16805],
        [17050],
        [17263]], device='cuda:0')
[2024-07-24 10:16:49,677][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8605],
        [ 8336],
        [ 7911],
        [ 9826],
        [10791],
        [11340],
        [10185],
        [ 9863],
        [ 9617],
        [ 9910],
        [10173],
        [10292],
        [10756],
        [11027],
        [11327],
        [11590],
        [11289],
        [11666],
        [11594],
        [11841]], device='cuda:0')
[2024-07-24 10:16:49,679][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[2663],
        [1227],
        [ 987],
        [ 862],
        [ 977],
        [1578],
        [1689],
        [1864],
        [1692],
        [1548],
        [1732],
        [1663],
        [1532],
        [1455],
        [1869],
        [1371],
        [1168],
        [1220],
        [1604],
        [1231]], device='cuda:0')
[2024-07-24 10:16:49,681][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 2554],
        [ 8234],
        [14982],
        [18100],
        [22789],
        [ 4085],
        [17870],
        [13613],
        [11986],
        [ 7877],
        [14309],
        [18801],
        [15418],
        [33357],
        [12488],
        [ 8003],
        [19718],
        [ 8551],
        [ 1323],
        [ 6427]], device='cuda:0')
[2024-07-24 10:16:49,682][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627],
        [36627]], device='cuda:0')
[2024-07-24 10:16:49,731][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:49,735][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,738][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,739][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,739][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,740][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,741][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,741][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,743][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,743][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,744][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,745][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,745][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:49,746][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9780, 0.0220], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,747][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4230, 0.5770], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,747][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0033, 0.9967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,748][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0777, 0.9223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,749][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5638, 0.4362], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,749][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4872, 0.5128], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,750][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5502, 0.4498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,751][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1699, 0.8301], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,754][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6639, 0.3361], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,759][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7451, 0.2549], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,760][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6621, 0.3379], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,761][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7385, 0.2615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:49,761][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.3719, 0.0009, 0.6272], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,762][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.2552, 0.3452, 0.3996], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,765][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0027, 0.4131, 0.5843], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,772][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0135, 0.8798, 0.1068], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,773][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.3846, 0.2978, 0.3177], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,773][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.2988, 0.3454, 0.3558], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,774][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0515, 0.7130, 0.2355], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,775][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.3077, 0.6096, 0.0827], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,776][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.4907, 0.2648, 0.2445], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,782][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1321, 0.7299, 0.1380], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,785][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.4318, 0.0646, 0.5036], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,786][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.1550, 0.7249, 0.1202], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:49,786][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9592, 0.0117, 0.0017, 0.0274], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,787][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1911, 0.2590, 0.2966, 0.2533], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,788][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0010, 0.2395, 0.3685, 0.3911], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,792][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0117, 0.5628, 0.1016, 0.3239], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,798][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3038, 0.2225, 0.2378, 0.2359], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,798][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2314, 0.2523, 0.2670, 0.2493], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,799][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0017, 0.4379, 0.5587, 0.0016], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,800][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0666, 0.4491, 0.4478, 0.0365], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,800][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3251, 0.1138, 0.1093, 0.4518], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,803][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0094, 0.9276, 0.0570, 0.0060], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,810][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6145, 0.1732, 0.0740, 0.1383], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,811][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0061, 0.8682, 0.1195, 0.0062], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:49,812][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.9848, 0.0038, 0.0024, 0.0027, 0.0063], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,813][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.1503, 0.2034, 0.2331, 0.2004, 0.2129], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,813][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0010, 0.1877, 0.2451, 0.3132, 0.2531], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,816][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0044, 0.5359, 0.0761, 0.3672, 0.0164], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,823][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.2354, 0.1769, 0.1873, 0.1877, 0.2127], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,824][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.1785, 0.2032, 0.2123, 0.1994, 0.2065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,825][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ James] are: tensor([7.7168e-04, 8.0209e-01, 1.8918e-01, 3.0539e-03, 4.9103e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,826][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1202, 0.5172, 0.2860, 0.0653, 0.0113], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,826][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.2261, 0.0780, 0.0741, 0.3406, 0.2812], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,829][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0067, 0.8309, 0.1450, 0.0109, 0.0065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,836][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.1383, 0.0086, 0.5814, 0.0141, 0.2577], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,837][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0025, 0.8887, 0.1002, 0.0075, 0.0012], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:49,838][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ were] are: tensor([9.8411e-01, 1.7752e-03, 1.7630e-03, 2.0911e-03, 1.5363e-05, 1.0246e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,839][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1253, 0.1685, 0.1946, 0.1682, 0.1780, 0.1655], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,839][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0004, 0.1651, 0.2273, 0.2540, 0.2265, 0.1268], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,844][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0046, 0.4489, 0.0857, 0.2756, 0.0180, 0.1671], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,849][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.1914, 0.1452, 0.1533, 0.1547, 0.1758, 0.1795], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,850][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.1494, 0.1650, 0.1751, 0.1707, 0.1732, 0.1667], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,851][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0035, 0.6311, 0.3266, 0.0058, 0.0149, 0.0181], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,851][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0942, 0.4140, 0.3127, 0.0521, 0.1037, 0.0234], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,852][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.1797, 0.0776, 0.0734, 0.2882, 0.2543, 0.1268], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,857][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0696, 0.8566, 0.0283, 0.0058, 0.0014, 0.0384], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,862][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.3833, 0.0216, 0.0832, 0.0997, 0.1276, 0.2846], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,863][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0231, 0.8380, 0.0829, 0.0121, 0.0016, 0.0423], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:49,864][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([9.8939e-01, 2.9170e-03, 9.0823e-04, 3.9525e-03, 3.2641e-05, 4.1156e-04,
        2.3898e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,864][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1042, 0.1405, 0.1639, 0.1395, 0.1507, 0.1403, 0.1609],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,865][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0009, 0.1522, 0.1953, 0.2530, 0.1992, 0.1240, 0.0754],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,870][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0032, 0.4164, 0.0615, 0.2780, 0.0139, 0.2122, 0.0149],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,875][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.1564, 0.1211, 0.1280, 0.1303, 0.1477, 0.1510, 0.1656],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,876][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.1301, 0.1375, 0.1487, 0.1401, 0.1451, 0.1492, 0.1492],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,877][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0034, 0.5958, 0.3193, 0.0056, 0.0241, 0.0478, 0.0041],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,878][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1053, 0.2969, 0.3969, 0.0523, 0.0888, 0.0420, 0.0178],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,878][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.1470, 0.0693, 0.0639, 0.2774, 0.2496, 0.1138, 0.0791],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,883][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0164, 0.6313, 0.1603, 0.0130, 0.0120, 0.1613, 0.0058],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,888][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.1519, 0.0150, 0.1190, 0.0779, 0.3070, 0.0527, 0.2765],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,889][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0199, 0.8028, 0.0910, 0.0064, 0.0043, 0.0602, 0.0154],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:49,890][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ about] are: tensor([9.6734e-01, 3.2556e-03, 7.3835e-04, 5.8307e-03, 7.8740e-05, 1.3214e-03,
        4.8626e-04, 2.0951e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,890][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0897, 0.1218, 0.1423, 0.1227, 0.1308, 0.1213, 0.1391, 0.1322],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,891][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0008, 0.1413, 0.1922, 0.2241, 0.1872, 0.1086, 0.0755, 0.0703],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,896][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0027, 0.3791, 0.0700, 0.2696, 0.0154, 0.2113, 0.0233, 0.0285],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,904][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.1400, 0.1051, 0.1121, 0.1126, 0.1281, 0.1303, 0.1430, 0.1290],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,904][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.1152, 0.1208, 0.1289, 0.1209, 0.1277, 0.1265, 0.1300, 0.1299],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,905][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0008, 0.5640, 0.3689, 0.0073, 0.0239, 0.0282, 0.0063, 0.0007],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,906][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1087, 0.4079, 0.2256, 0.0687, 0.0540, 0.0505, 0.0792, 0.0055],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,907][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.1454, 0.0637, 0.0591, 0.2445, 0.2161, 0.1048, 0.0725, 0.0940],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,911][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0099, 0.6681, 0.1369, 0.0139, 0.0092, 0.1095, 0.0500, 0.0024],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,917][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.1685, 0.0245, 0.1118, 0.0709, 0.1006, 0.2765, 0.0313, 0.2159],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,917][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0050, 0.7553, 0.0956, 0.0144, 0.0042, 0.0866, 0.0353, 0.0035],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:49,918][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ going] are: tensor([9.8808e-01, 3.4146e-03, 2.6772e-04, 4.3104e-03, 1.0515e-05, 7.8358e-04,
        7.3125e-05, 5.1312e-04, 2.5449e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,919][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0787, 0.1066, 0.1250, 0.1072, 0.1153, 0.1067, 0.1229, 0.1177, 0.1200],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,920][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0008, 0.1340, 0.1751, 0.2137, 0.1717, 0.1034, 0.0692, 0.0693, 0.0627],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,924][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0029, 0.3981, 0.0669, 0.2589, 0.0143, 0.1865, 0.0163, 0.0351, 0.0210],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,930][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.1215, 0.0934, 0.1001, 0.1003, 0.1131, 0.1152, 0.1256, 0.1139, 0.1169],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,930][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0996, 0.1076, 0.1120, 0.1074, 0.1106, 0.1132, 0.1132, 0.1137, 0.1227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,931][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0044, 0.6225, 0.2985, 0.0057, 0.0146, 0.0425, 0.0050, 0.0009, 0.0059],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,932][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.1537, 0.3677, 0.1768, 0.0865, 0.0545, 0.0393, 0.0933, 0.0179, 0.0103],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,933][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1290, 0.0559, 0.0515, 0.2355, 0.2072, 0.0941, 0.0643, 0.0852, 0.0772],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,938][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0253, 0.6780, 0.0876, 0.0138, 0.0042, 0.1682, 0.0089, 0.0049, 0.0091],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,943][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0878, 0.0102, 0.0594, 0.0123, 0.0558, 0.3679, 0.1621, 0.0446, 0.1999],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,943][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0222, 0.7512, 0.0674, 0.0079, 0.0026, 0.0701, 0.0515, 0.0081, 0.0191],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:49,944][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.6869e-01, 5.0838e-03, 1.3427e-03, 6.3269e-03, 1.7981e-04, 1.5732e-03,
        2.3809e-04, 3.6604e-03, 3.3396e-04, 1.2575e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,945][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0718, 0.0966, 0.1115, 0.0961, 0.1029, 0.0962, 0.1105, 0.1054, 0.1081,
        0.1007], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,946][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.1197, 0.1602, 0.1866, 0.1560, 0.0917, 0.0649, 0.0618, 0.0562,
        0.1024], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,951][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0111, 0.3306, 0.0587, 0.1998, 0.0139, 0.1349, 0.0221, 0.0278, 0.0246,
        0.1766], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,955][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1103, 0.0846, 0.0905, 0.0903, 0.1026, 0.1042, 0.1132, 0.1024, 0.1042,
        0.0976], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,956][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0918, 0.0969, 0.1032, 0.0957, 0.0993, 0.0987, 0.1020, 0.1024, 0.1106,
        0.0992], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,957][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0274, 0.5308, 0.3267, 0.0061, 0.0158, 0.0343, 0.0103, 0.0017, 0.0273,
        0.0195], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,958][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0550, 0.2812, 0.3596, 0.0311, 0.0789, 0.0326, 0.1242, 0.0053, 0.0264,
        0.0058], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,959][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1309, 0.0424, 0.0408, 0.1800, 0.1464, 0.0742, 0.0475, 0.0650, 0.0555,
        0.2173], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,964][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1092, 0.5877, 0.1161, 0.0122, 0.0068, 0.0902, 0.0151, 0.0033, 0.0396,
        0.0199], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,968][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0273, 0.0236, 0.0467, 0.0599, 0.0779, 0.1932, 0.0110, 0.0894, 0.0127,
        0.4582], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,969][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0988, 0.6443, 0.0752, 0.0099, 0.0030, 0.0390, 0.0427, 0.0107, 0.0265,
        0.0498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:49,970][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.7012e-01, 3.0653e-03, 1.5844e-03, 6.1500e-03, 1.3187e-04, 3.0661e-03,
        2.1962e-04, 1.2008e-03, 1.5636e-04, 1.4216e-03, 1.2881e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,971][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0650, 0.0878, 0.1023, 0.0882, 0.0940, 0.0877, 0.1007, 0.0959, 0.0986,
        0.0924, 0.0874], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,971][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0005, 0.1133, 0.1486, 0.1661, 0.1462, 0.0930, 0.0635, 0.0609, 0.0583,
        0.1063, 0.0433], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,976][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0031, 0.2809, 0.0469, 0.1810, 0.0110, 0.1188, 0.0170, 0.0225, 0.0180,
        0.1777, 0.1230], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,981][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1014, 0.0771, 0.0819, 0.0820, 0.0933, 0.0952, 0.1037, 0.0935, 0.0950,
        0.0892, 0.0876], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,982][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0809, 0.0869, 0.0952, 0.0864, 0.0926, 0.0897, 0.0920, 0.0939, 0.0996,
        0.0893, 0.0936], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,983][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0865, 0.3922, 0.3485, 0.0037, 0.0202, 0.0330, 0.0109, 0.0024, 0.0283,
        0.0325, 0.0418], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,983][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0810, 0.3072, 0.2316, 0.0398, 0.0776, 0.0421, 0.1114, 0.0102, 0.0478,
        0.0114, 0.0399], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,984][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1077, 0.0343, 0.0325, 0.1470, 0.1197, 0.0601, 0.0381, 0.0528, 0.0450,
        0.1772, 0.1857], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,989][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2061, 0.4851, 0.1049, 0.0096, 0.0070, 0.0685, 0.0105, 0.0067, 0.0206,
        0.0396, 0.0414], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,994][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1125, 0.0074, 0.0927, 0.0162, 0.0501, 0.2193, 0.0329, 0.0130, 0.0576,
        0.0142, 0.3842], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,994][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2237, 0.4427, 0.0774, 0.0052, 0.0035, 0.0361, 0.0277, 0.0089, 0.0252,
        0.0753, 0.0744], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:49,995][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ store] are: tensor([9.8807e-01, 1.6670e-03, 1.0791e-04, 3.0317e-03, 1.3020e-05, 2.2826e-04,
        8.7494e-06, 2.5423e-04, 1.1059e-05, 1.6069e-03, 3.0669e-03, 1.9343e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,996][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0595, 0.0795, 0.0929, 0.0799, 0.0854, 0.0797, 0.0914, 0.0879, 0.0900,
        0.0838, 0.0804, 0.0897], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:49,997][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0010, 0.1095, 0.1312, 0.1819, 0.1315, 0.0845, 0.0517, 0.0555, 0.0531,
        0.1080, 0.0494, 0.0428], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,002][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0026, 0.2454, 0.0359, 0.1690, 0.0092, 0.1449, 0.0123, 0.0268, 0.0192,
        0.1729, 0.1542, 0.0076], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,006][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0919, 0.0701, 0.0742, 0.0748, 0.0851, 0.0872, 0.0958, 0.0862, 0.0876,
        0.0812, 0.0799, 0.0860], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,007][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0701, 0.0802, 0.0879, 0.0815, 0.0822, 0.0866, 0.0850, 0.0860, 0.0927,
        0.0840, 0.0898, 0.0741], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,008][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0872, 0.4308, 0.2115, 0.0040, 0.0105, 0.0428, 0.0085, 0.0021, 0.0207,
        0.0431, 0.0688, 0.0699], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,009][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0949, 0.2854, 0.2275, 0.0662, 0.0365, 0.0569, 0.0685, 0.0129, 0.0572,
        0.0123, 0.0642, 0.0175], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,010][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0742, 0.0363, 0.0332, 0.1417, 0.1269, 0.0582, 0.0414, 0.0532, 0.0496,
        0.1689, 0.1792, 0.0372], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,015][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.2254, 0.4267, 0.1118, 0.0110, 0.0044, 0.0529, 0.0030, 0.0030, 0.0210,
        0.0504, 0.0795, 0.0109], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,019][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0754, 0.0119, 0.1007, 0.0146, 0.0365, 0.1231, 0.1557, 0.0311, 0.1873,
        0.0578, 0.0316, 0.1743], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,020][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.1888, 0.4403, 0.0614, 0.0046, 0.0017, 0.0420, 0.0234, 0.0060, 0.0270,
        0.0765, 0.1014, 0.0270], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,021][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.0053e-01, 1.5305e-02, 5.4335e-03, 1.8180e-02, 1.6375e-03, 3.4610e-03,
        4.6325e-04, 2.6620e-03, 5.6922e-04, 7.9928e-03, 1.4025e-02, 1.9427e-04,
        2.9551e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,022][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0549, 0.0741, 0.0862, 0.0740, 0.0798, 0.0743, 0.0843, 0.0806, 0.0827,
        0.0777, 0.0737, 0.0816, 0.0763], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,022][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0006, 0.0997, 0.1210, 0.1451, 0.1264, 0.0779, 0.0536, 0.0547, 0.0511,
        0.0929, 0.0411, 0.0442, 0.0918], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,027][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0032, 0.2001, 0.0338, 0.1364, 0.0082, 0.1003, 0.0145, 0.0191, 0.0164,
        0.1536, 0.1210, 0.0103, 0.1831], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,032][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0858, 0.0661, 0.0701, 0.0701, 0.0788, 0.0804, 0.0878, 0.0794, 0.0809,
        0.0757, 0.0740, 0.0793, 0.0717], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,033][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0694, 0.0731, 0.0798, 0.0723, 0.0757, 0.0757, 0.0777, 0.0797, 0.0856,
        0.0771, 0.0798, 0.0703, 0.0837], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,033][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0009, 0.4010, 0.3550, 0.0057, 0.0112, 0.0332, 0.0070, 0.0012, 0.0169,
        0.0161, 0.0590, 0.0890, 0.0038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,034][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0418, 0.1626, 0.3032, 0.0213, 0.0685, 0.0232, 0.0764, 0.0118, 0.0515,
        0.0067, 0.0899, 0.1374, 0.0057], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,035][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0970, 0.0389, 0.0371, 0.1043, 0.0885, 0.0567, 0.0403, 0.0518, 0.0445,
        0.1153, 0.1234, 0.0380, 0.1644], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,040][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0127, 0.5608, 0.1255, 0.0135, 0.0094, 0.1082, 0.0085, 0.0068, 0.0140,
        0.0305, 0.0597, 0.0336, 0.0167], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,045][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.2321, 0.0577, 0.0752, 0.0516, 0.0295, 0.0528, 0.0471, 0.0416, 0.0249,
        0.0222, 0.0945, 0.0919, 0.1789], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,045][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0041, 0.4096, 0.0655, 0.0107, 0.0028, 0.0648, 0.0458, 0.0062, 0.0354,
        0.0768, 0.1708, 0.0832, 0.0242], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,046][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ James] are: tensor([9.7466e-01, 3.2321e-03, 1.8520e-03, 2.2448e-03, 4.0124e-03, 5.5021e-04,
        5.3557e-05, 1.9984e-04, 5.8692e-05, 1.2105e-03, 1.4254e-03, 1.2332e-05,
        8.3685e-03, 2.1150e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,047][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0504, 0.0680, 0.0791, 0.0673, 0.0729, 0.0680, 0.0783, 0.0755, 0.0771,
        0.0715, 0.0689, 0.0766, 0.0701, 0.0763], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,048][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0005, 0.1008, 0.1216, 0.1513, 0.1224, 0.0763, 0.0492, 0.0488, 0.0477,
        0.0894, 0.0411, 0.0416, 0.0876, 0.0217], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,055][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0007, 0.1634, 0.0256, 0.1274, 0.0052, 0.1297, 0.0092, 0.0190, 0.0147,
        0.1473, 0.1383, 0.0056, 0.2112, 0.0026], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,057][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0800, 0.0610, 0.0651, 0.0646, 0.0729, 0.0746, 0.0816, 0.0737, 0.0758,
        0.0702, 0.0685, 0.0737, 0.0664, 0.0718], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,058][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0599, 0.0673, 0.0713, 0.0665, 0.0691, 0.0725, 0.0720, 0.0745, 0.0815,
        0.0700, 0.0774, 0.0652, 0.0810, 0.0718], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,059][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0164, 0.4737, 0.1983, 0.0034, 0.0074, 0.0179, 0.0077, 0.0025, 0.0263,
        0.0296, 0.0400, 0.1236, 0.0200, 0.0331], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,060][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1350, 0.2474, 0.1747, 0.0406, 0.0077, 0.0334, 0.0555, 0.0105, 0.0414,
        0.0106, 0.1279, 0.0996, 0.0134, 0.0024], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,062][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0704, 0.0238, 0.0229, 0.0996, 0.0809, 0.0408, 0.0266, 0.0361, 0.0309,
        0.1194, 0.1246, 0.0249, 0.1697, 0.1295], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,070][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0808, 0.4593, 0.1935, 0.0132, 0.0099, 0.0417, 0.0054, 0.0041, 0.0058,
        0.0243, 0.0838, 0.0273, 0.0231, 0.0280], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,071][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0554, 0.0036, 0.2769, 0.0053, 0.1069, 0.0754, 0.0893, 0.0074, 0.0538,
        0.0085, 0.0760, 0.0565, 0.0090, 0.1760], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,071][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0278, 0.3964, 0.0737, 0.0069, 0.0013, 0.0453, 0.0318, 0.0065, 0.0551,
        0.0570, 0.1660, 0.0912, 0.0364, 0.0046], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,072][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([9.8394e-01, 3.0953e-03, 2.6067e-04, 3.8641e-03, 2.1291e-05, 8.3218e-04,
        8.8040e-05, 4.3124e-04, 8.2425e-05, 1.8034e-03, 1.1287e-03, 5.6666e-06,
        3.6235e-03, 1.1439e-05, 8.1328e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,073][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0472, 0.0636, 0.0739, 0.0635, 0.0678, 0.0631, 0.0727, 0.0696, 0.0711,
        0.0669, 0.0640, 0.0709, 0.0657, 0.0712, 0.0688], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,080][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0008, 0.1017, 0.1214, 0.1567, 0.1182, 0.0717, 0.0462, 0.0456, 0.0428,
        0.0864, 0.0391, 0.0396, 0.0898, 0.0218, 0.0184], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,082][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0024, 0.2129, 0.0398, 0.1432, 0.0083, 0.1026, 0.0093, 0.0187, 0.0115,
        0.1308, 0.1242, 0.0072, 0.1677, 0.0036, 0.0178], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,083][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0738, 0.0560, 0.0599, 0.0600, 0.0681, 0.0691, 0.0764, 0.0690, 0.0704,
        0.0647, 0.0634, 0.0685, 0.0614, 0.0667, 0.0726], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,084][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0596, 0.0625, 0.0667, 0.0633, 0.0666, 0.0658, 0.0670, 0.0681, 0.0751,
        0.0655, 0.0709, 0.0632, 0.0738, 0.0682, 0.0637], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,085][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0069, 0.3590, 0.3177, 0.0070, 0.0189, 0.0260, 0.0088, 0.0016, 0.0188,
        0.0239, 0.0463, 0.0663, 0.0146, 0.0577, 0.0264], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,088][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.1750, 0.1900, 0.1529, 0.0426, 0.0410, 0.0327, 0.0543, 0.0106, 0.0195,
        0.0129, 0.1674, 0.0673, 0.0165, 0.0163, 0.0009], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,095][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0567, 0.0286, 0.0264, 0.1011, 0.0920, 0.0444, 0.0319, 0.0410, 0.0378,
        0.1177, 0.1257, 0.0290, 0.1087, 0.1275, 0.0315], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,096][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0935, 0.5570, 0.0591, 0.0081, 0.0022, 0.0551, 0.0116, 0.0039, 0.0079,
        0.0281, 0.0807, 0.0116, 0.0490, 0.0065, 0.0259], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,097][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0678, 0.0049, 0.0174, 0.0157, 0.0359, 0.2177, 0.0617, 0.0448, 0.1327,
        0.0296, 0.0447, 0.0945, 0.0149, 0.0633, 0.1543], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,098][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0695, 0.4868, 0.0467, 0.0124, 0.0022, 0.0514, 0.0289, 0.0093, 0.0166,
        0.0594, 0.0962, 0.0481, 0.0349, 0.0051, 0.0324], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,099][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.5636e-01, 4.3078e-03, 9.3149e-04, 5.4508e-03, 9.9988e-05, 1.0688e-03,
        1.3382e-04, 2.4250e-03, 2.2012e-04, 9.3046e-03, 3.7675e-03, 3.9785e-05,
        1.0594e-02, 5.9310e-05, 1.1468e-04, 5.1229e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,105][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0453, 0.0600, 0.0688, 0.0597, 0.0635, 0.0596, 0.0679, 0.0649, 0.0666,
        0.0623, 0.0594, 0.0656, 0.0618, 0.0666, 0.0646, 0.0633],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,108][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0004, 0.0911, 0.1187, 0.1410, 0.1147, 0.0694, 0.0471, 0.0461, 0.0418,
        0.0778, 0.0358, 0.0399, 0.0931, 0.0222, 0.0193, 0.0417],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,109][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0086, 0.1928, 0.0328, 0.1098, 0.0078, 0.0689, 0.0130, 0.0144, 0.0137,
        0.0958, 0.0769, 0.0094, 0.1202, 0.0031, 0.0257, 0.2070],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,109][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0693, 0.0525, 0.0563, 0.0563, 0.0640, 0.0649, 0.0710, 0.0642, 0.0655,
        0.0609, 0.0596, 0.0642, 0.0578, 0.0631, 0.0677, 0.0627],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,110][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0570, 0.0604, 0.0648, 0.0594, 0.0619, 0.0614, 0.0644, 0.0638, 0.0692,
        0.0618, 0.0646, 0.0576, 0.0697, 0.0635, 0.0593, 0.0613],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,115][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0826, 0.2719, 0.2371, 0.0046, 0.0123, 0.0262, 0.0075, 0.0015, 0.0204,
        0.0125, 0.0586, 0.1026, 0.0117, 0.0557, 0.0284, 0.0664],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,120][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0538, 0.1837, 0.2546, 0.0195, 0.0564, 0.0194, 0.0751, 0.0032, 0.0208,
        0.0040, 0.0868, 0.1900, 0.0073, 0.0200, 0.0043, 0.0010],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,121][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0672, 0.0235, 0.0225, 0.0870, 0.0728, 0.0391, 0.0258, 0.0347, 0.0299,
        0.1015, 0.1057, 0.0243, 0.1339, 0.1108, 0.0284, 0.0929],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,122][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2292, 0.3350, 0.0641, 0.0093, 0.0040, 0.0700, 0.0098, 0.0030, 0.0176,
        0.0136, 0.0648, 0.0185, 0.0297, 0.0135, 0.0654, 0.0525],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,123][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0138, 0.0112, 0.0279, 0.0303, 0.0480, 0.1049, 0.0053, 0.0447, 0.0052,
        0.2179, 0.0470, 0.0521, 0.0352, 0.0635, 0.0072, 0.2859],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,126][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.2179, 0.2975, 0.0379, 0.0055, 0.0018, 0.0245, 0.0279, 0.0078, 0.0150,
        0.0271, 0.1115, 0.0553, 0.0270, 0.0056, 0.0374, 0.1001],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,130][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ give] are: tensor([9.2284e-01, 8.7819e-03, 7.1681e-05, 1.3383e-02, 4.0044e-05, 6.3086e-04,
        1.2315e-04, 1.7498e-03, 3.5476e-04, 1.1972e-02, 2.5441e-03, 2.6301e-05,
        1.1770e-02, 2.6378e-05, 3.0332e-04, 5.8485e-03, 1.9531e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,133][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0422, 0.0560, 0.0643, 0.0557, 0.0593, 0.0554, 0.0634, 0.0607, 0.0624,
        0.0584, 0.0557, 0.0617, 0.0581, 0.0626, 0.0606, 0.0595, 0.0640],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,134][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0006, 0.0894, 0.1149, 0.1395, 0.1151, 0.0676, 0.0435, 0.0444, 0.0418,
        0.0816, 0.0362, 0.0372, 0.0832, 0.0218, 0.0182, 0.0427, 0.0225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,135][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0037, 0.1887, 0.0375, 0.1176, 0.0085, 0.0677, 0.0093, 0.0143, 0.0112,
        0.0968, 0.0819, 0.0080, 0.1151, 0.0033, 0.0173, 0.1909, 0.0284],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,136][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0647, 0.0486, 0.0522, 0.0524, 0.0597, 0.0606, 0.0667, 0.0605, 0.0617,
        0.0569, 0.0558, 0.0604, 0.0539, 0.0589, 0.0638, 0.0590, 0.0642],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,140][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0511, 0.0566, 0.0605, 0.0565, 0.0580, 0.0603, 0.0599, 0.0594, 0.0647,
        0.0578, 0.0606, 0.0550, 0.0647, 0.0602, 0.0555, 0.0575, 0.0617],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,146][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0283, 0.2283, 0.2687, 0.0042, 0.0154, 0.0174, 0.0061, 0.0014, 0.0146,
        0.0242, 0.0371, 0.0682, 0.0116, 0.0640, 0.0286, 0.1498, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,146][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0604, 0.2159, 0.1782, 0.0285, 0.0685, 0.0453, 0.1323, 0.0134, 0.0270,
        0.0118, 0.0891, 0.0827, 0.0149, 0.0217, 0.0035, 0.0034, 0.0034],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,147][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0519, 0.0247, 0.0229, 0.0878, 0.0786, 0.0387, 0.0274, 0.0355, 0.0323,
        0.1026, 0.1098, 0.0250, 0.1027, 0.1105, 0.0278, 0.0883, 0.0336],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,148][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0819, 0.4247, 0.0623, 0.0093, 0.0058, 0.0594, 0.0077, 0.0033, 0.0068,
        0.0384, 0.0450, 0.0210, 0.0229, 0.0158, 0.0361, 0.1421, 0.0174],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,151][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0237, 0.0064, 0.0123, 0.0179, 0.0166, 0.3092, 0.0721, 0.0157, 0.0614,
        0.0312, 0.0457, 0.0537, 0.0120, 0.0298, 0.0464, 0.0400, 0.2058],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,157][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.1130, 0.3835, 0.0409, 0.0066, 0.0023, 0.0281, 0.0252, 0.0085, 0.0137,
        0.0410, 0.0741, 0.0490, 0.0253, 0.0053, 0.0232, 0.1382, 0.0225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,159][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.6262e-01, 2.9367e-03, 1.7900e-03, 6.3267e-03, 1.2205e-04, 1.9981e-03,
        5.4569e-05, 1.2601e-03, 1.2243e-04, 2.4979e-03, 4.9030e-03, 3.4457e-05,
        7.9431e-03, 5.5768e-05, 5.8940e-05, 1.4403e-03, 6.6231e-05, 5.7680e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,160][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0408, 0.0531, 0.0606, 0.0532, 0.0558, 0.0524, 0.0594, 0.0566, 0.0582,
        0.0551, 0.0523, 0.0577, 0.0545, 0.0586, 0.0569, 0.0562, 0.0601, 0.0584],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,161][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0003, 0.0820, 0.1159, 0.1289, 0.1185, 0.0678, 0.0466, 0.0447, 0.0413,
        0.0809, 0.0313, 0.0381, 0.0791, 0.0211, 0.0179, 0.0411, 0.0225, 0.0221],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,161][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0052, 0.1638, 0.0306, 0.0921, 0.0068, 0.0530, 0.0100, 0.0110, 0.0105,
        0.0877, 0.0511, 0.0069, 0.0924, 0.0023, 0.0182, 0.1852, 0.0320, 0.1412],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,166][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0615, 0.0462, 0.0493, 0.0495, 0.0564, 0.0573, 0.0631, 0.0570, 0.0580,
        0.0537, 0.0527, 0.0568, 0.0509, 0.0556, 0.0600, 0.0556, 0.0600, 0.0564],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,171][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0489, 0.0523, 0.0571, 0.0517, 0.0564, 0.0540, 0.0566, 0.0560, 0.0612,
        0.0538, 0.0570, 0.0529, 0.0609, 0.0582, 0.0527, 0.0536, 0.0573, 0.0594],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,172][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3904, 0.0556, 0.0702, 0.0009, 0.0041, 0.0086, 0.0024, 0.0006, 0.0048,
        0.0079, 0.0089, 0.0389, 0.0043, 0.0330, 0.0153, 0.0496, 0.0383, 0.2662],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,173][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0580, 0.2492, 0.1341, 0.0294, 0.0337, 0.0333, 0.0738, 0.0080, 0.0504,
        0.0156, 0.0672, 0.1715, 0.0196, 0.0138, 0.0062, 0.0043, 0.0288, 0.0032],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,174][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0564, 0.0227, 0.0215, 0.0815, 0.0705, 0.0366, 0.0251, 0.0331, 0.0293,
        0.0947, 0.0994, 0.0233, 0.1080, 0.1031, 0.0264, 0.0842, 0.0327, 0.0515],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,178][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4912, 0.0787, 0.0291, 0.0031, 0.0015, 0.0200, 0.0055, 0.0032, 0.0046,
        0.0118, 0.0142, 0.0150, 0.0081, 0.0049, 0.0205, 0.0474, 0.1133, 0.1279],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,183][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0943, 0.0073, 0.0660, 0.0298, 0.0744, 0.1003, 0.0387, 0.0131, 0.0184,
        0.0169, 0.1260, 0.0983, 0.0280, 0.1161, 0.0287, 0.0228, 0.0272, 0.0937],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,184][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.9986e-01, 4.5270e-02, 8.8695e-03, 7.8550e-04, 5.1558e-04, 6.4281e-03,
        8.0451e-03, 2.4188e-03, 5.8202e-03, 1.3773e-02, 3.1409e-02, 1.4936e-02,
        8.6307e-03, 2.5843e-03, 1.4675e-02, 5.4329e-02, 2.5773e-02, 1.5588e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,185][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([9.7658e-01, 2.2882e-03, 4.9049e-04, 4.8245e-03, 4.8669e-05, 2.2986e-04,
        1.3067e-05, 1.0013e-04, 2.5730e-05, 2.7366e-03, 1.6489e-03, 1.2648e-05,
        7.4096e-03, 3.8081e-05, 1.9187e-05, 1.4363e-03, 7.1648e-05, 5.6093e-04,
        1.4606e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,186][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0374, 0.0490, 0.0568, 0.0490, 0.0524, 0.0490, 0.0557, 0.0539, 0.0552,
        0.0517, 0.0497, 0.0550, 0.0509, 0.0549, 0.0533, 0.0524, 0.0567, 0.0553,
        0.0617], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,189][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0007, 0.0839, 0.1035, 0.1349, 0.0995, 0.0689, 0.0397, 0.0440, 0.0406,
        0.0830, 0.0376, 0.0342, 0.0794, 0.0188, 0.0171, 0.0434, 0.0231, 0.0282,
        0.0194], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,196][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0015, 0.1152, 0.0192, 0.0778, 0.0050, 0.0649, 0.0070, 0.0138, 0.0103,
        0.0885, 0.0739, 0.0051, 0.1006, 0.0024, 0.0148, 0.1712, 0.0337, 0.1905,
        0.0046], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,197][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0561, 0.0438, 0.0470, 0.0470, 0.0532, 0.0543, 0.0593, 0.0539, 0.0552,
        0.0508, 0.0499, 0.0538, 0.0482, 0.0525, 0.0570, 0.0525, 0.0567, 0.0535,
        0.0552], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,198][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0459, 0.0482, 0.0546, 0.0489, 0.0533, 0.0530, 0.0542, 0.0540, 0.0586,
        0.0490, 0.0537, 0.0501, 0.0550, 0.0546, 0.0514, 0.0487, 0.0551, 0.0553,
        0.0564], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,199][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([2.0970e-01, 3.5353e-02, 2.8566e-02, 3.3022e-04, 9.6779e-04, 2.5016e-03,
        7.0139e-04, 3.7045e-04, 2.4019e-03, 4.1424e-03, 9.4170e-03, 1.2476e-02,
        2.6644e-03, 1.1064e-02, 6.7102e-03, 3.0395e-02, 2.0470e-02, 5.5088e-01,
        7.0891e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,203][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0850, 0.2468, 0.1971, 0.0312, 0.0447, 0.0388, 0.0522, 0.0160, 0.0341,
        0.0149, 0.1155, 0.0445, 0.0172, 0.0168, 0.0038, 0.0045, 0.0120, 0.0232,
        0.0019], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,209][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0460, 0.0227, 0.0211, 0.0821, 0.0743, 0.0356, 0.0258, 0.0329, 0.0305,
        0.0969, 0.1021, 0.0237, 0.0891, 0.1051, 0.0255, 0.0804, 0.0317, 0.0491,
        0.0254], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,210][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.5101, 0.0569, 0.0061, 0.0014, 0.0006, 0.0122, 0.0005, 0.0008, 0.0034,
        0.0119, 0.0220, 0.0046, 0.0069, 0.0030, 0.0071, 0.0434, 0.0401, 0.2081,
        0.0610], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,210][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0420, 0.0091, 0.0520, 0.0101, 0.0144, 0.1522, 0.0962, 0.0152, 0.0463,
        0.0199, 0.0228, 0.0988, 0.0170, 0.0212, 0.0453, 0.0280, 0.1434, 0.0242,
        0.1420], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,211][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([4.2553e-01, 4.4326e-02, 6.2382e-03, 7.3480e-04, 3.0124e-04, 3.3953e-03,
        4.3084e-03, 2.2261e-03, 3.0276e-03, 8.1094e-03, 1.9501e-02, 2.0313e-02,
        4.4795e-03, 1.7293e-03, 6.7989e-03, 3.1681e-02, 2.8857e-02, 2.7696e-01,
        1.1148e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,213][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([9.4003e-01, 5.3934e-03, 8.2027e-04, 7.2865e-03, 1.3374e-04, 1.1212e-03,
        1.4434e-04, 2.8794e-03, 2.2993e-04, 1.1763e-02, 4.7154e-03, 4.0100e-05,
        1.3030e-02, 7.8170e-05, 1.2987e-04, 6.2642e-03, 1.9557e-04, 8.8261e-04,
        2.4265e-05, 4.8399e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,220][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0361, 0.0471, 0.0536, 0.0467, 0.0497, 0.0467, 0.0531, 0.0509, 0.0521,
        0.0489, 0.0468, 0.0514, 0.0483, 0.0521, 0.0507, 0.0496, 0.0533, 0.0521,
        0.0576, 0.0532], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,221][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0003, 0.0813, 0.1085, 0.1267, 0.1071, 0.0643, 0.0426, 0.0408, 0.0368,
        0.0704, 0.0314, 0.0353, 0.0836, 0.0195, 0.0166, 0.0369, 0.0217, 0.0220,
        0.0206, 0.0334], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,222][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0119, 0.1229, 0.0218, 0.0626, 0.0054, 0.0351, 0.0088, 0.0082, 0.0091,
        0.0529, 0.0393, 0.0068, 0.0600, 0.0020, 0.0159, 0.1071, 0.0235, 0.1091,
        0.0051, 0.2925], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,223][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0544, 0.0416, 0.0448, 0.0448, 0.0509, 0.0518, 0.0561, 0.0509, 0.0520,
        0.0485, 0.0475, 0.0511, 0.0460, 0.0503, 0.0539, 0.0499, 0.0534, 0.0504,
        0.0524, 0.0493], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,224][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0448, 0.0477, 0.0509, 0.0468, 0.0492, 0.0487, 0.0509, 0.0506, 0.0546,
        0.0487, 0.0513, 0.0458, 0.0549, 0.0505, 0.0468, 0.0483, 0.0520, 0.0538,
        0.0543, 0.0494], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,227][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.9750e-01, 1.1244e-02, 1.4311e-02, 1.9801e-04, 7.3742e-04, 1.6793e-03,
        4.8602e-04, 1.6160e-04, 1.4808e-03, 9.0180e-04, 5.5058e-03, 9.6376e-03,
        9.8402e-04, 6.9627e-03, 2.8069e-03, 6.6633e-03, 6.3673e-03, 2.7098e-01,
        1.2182e-01, 2.3958e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,234][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0516, 0.1699, 0.2567, 0.0182, 0.0522, 0.0197, 0.0696, 0.0029, 0.0186,
        0.0035, 0.0752, 0.1873, 0.0062, 0.0174, 0.0034, 0.0008, 0.0191, 0.0099,
        0.0172, 0.0006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,235][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0557, 0.0231, 0.0218, 0.0741, 0.0647, 0.0357, 0.0249, 0.0325, 0.0288,
        0.0838, 0.0883, 0.0232, 0.0954, 0.0909, 0.0261, 0.0760, 0.0315, 0.0482,
        0.0262, 0.0492], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,236][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.6921e-01, 2.5805e-02, 5.5864e-03, 7.6513e-04, 3.5320e-04, 6.4880e-03,
        8.8180e-04, 4.5457e-04, 1.9905e-03, 1.5130e-03, 9.6878e-03, 2.2990e-03,
        3.9060e-03, 1.9657e-03, 9.2510e-03, 7.1207e-03, 3.5839e-02, 1.2583e-01,
        8.7687e-02, 1.0336e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,237][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0120, 0.0070, 0.0192, 0.0196, 0.0316, 0.0670, 0.0035, 0.0276, 0.0028,
        0.1289, 0.0269, 0.0353, 0.0236, 0.0413, 0.0042, 0.1685, 0.0649, 0.0077,
        0.0034, 0.3048], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,241][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.1408e-01, 1.3306e-02, 2.0549e-03, 2.5584e-04, 1.1979e-04, 1.6256e-03,
        2.2241e-03, 7.9156e-04, 1.0621e-03, 2.0040e-03, 1.0941e-02, 4.5104e-03,
        2.3830e-03, 5.9440e-04, 3.2422e-03, 9.2722e-03, 1.1609e-02, 1.3947e-01,
        9.6854e-02, 1.8360e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,291][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:50,296][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,298][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,298][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,299][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,300][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,301][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,302][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,305][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,308][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,311][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,312][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,312][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,313][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8664, 0.1336], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,314][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3439, 0.6561], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,316][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2170, 0.7830], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,319][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([5.0491e-04, 9.9950e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,324][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2453, 0.7547], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,324][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7539, 0.2461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,325][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5502, 0.4498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,326][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,326][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1731, 0.8269], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,329][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7451, 0.2549], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,335][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9593, 0.0407], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,337][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7385, 0.2615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,337][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.5473, 0.0112, 0.4415], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,338][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0538, 0.8225, 0.1238], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,339][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0091, 0.9205, 0.0704], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,339][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([2.0317e-05, 9.4345e-01, 5.6533e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,342][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.1850, 0.5113, 0.3037], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,349][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.3155, 0.4036, 0.2809], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,350][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0515, 0.7130, 0.2355], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,350][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([9.0795e-05, 9.7664e-01, 2.3266e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,351][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0135, 0.9479, 0.0386], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,352][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.1321, 0.7299, 0.1380], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,354][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.7493, 0.1424, 0.1084], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,360][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1550, 0.7249, 0.1202], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,362][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2115, 0.4448, 0.0933, 0.2504], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,363][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0026, 0.8923, 0.1018, 0.0033], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,363][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.1875e-05, 9.0889e-01, 9.0940e-02, 1.6312e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,364][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.3377e-08, 8.6219e-01, 1.3777e-01, 4.1694e-05], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,365][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0789, 0.2430, 0.3375, 0.3407], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,367][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1070, 0.6309, 0.2157, 0.0464], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,373][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0017, 0.4379, 0.5587, 0.0016], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,375][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.0181e-06, 8.2602e-01, 1.7378e-01, 1.9889e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,376][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([9.6498e-05, 9.4791e-01, 5.1445e-02, 5.4908e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,376][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0094, 0.9276, 0.0570, 0.0060], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,377][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2558, 0.5040, 0.2121, 0.0281], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,378][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0061, 0.8682, 0.1195, 0.0062], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,382][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.5877, 0.0304, 0.0249, 0.0186, 0.3384], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,388][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0021, 0.9148, 0.0723, 0.0084, 0.0024], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,388][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([3.9836e-05, 9.2180e-01, 7.6909e-02, 8.5564e-04, 3.9049e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,389][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([3.9006e-08, 8.9279e-01, 1.0706e-01, 6.2616e-05, 8.3273e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,390][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0367, 0.1645, 0.3577, 0.2374, 0.2037], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,391][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0813, 0.6234, 0.1922, 0.0539, 0.0492], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,392][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([7.7168e-04, 8.0209e-01, 1.8918e-01, 3.0539e-03, 4.9103e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,395][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([3.2545e-07, 9.3167e-01, 6.8008e-02, 2.1405e-04, 1.0523e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,399][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([1.1703e-04, 9.6225e-01, 3.5468e-02, 1.9264e-03, 2.4056e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,401][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0067, 0.8309, 0.1450, 0.0109, 0.0065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,401][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.3065, 0.2706, 0.3224, 0.0389, 0.0616], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,402][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0025, 0.8887, 0.1002, 0.0075, 0.0012], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:50,403][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.4451, 0.1192, 0.0645, 0.0368, 0.0122, 0.3223], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,404][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0525, 0.7853, 0.0690, 0.0193, 0.0075, 0.0664], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,406][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([4.0799e-04, 9.0713e-01, 8.7213e-02, 7.2049e-04, 1.0050e-03, 3.5211e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,411][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([2.5039e-06, 9.4342e-01, 5.4068e-02, 1.7781e-04, 3.2124e-04, 2.0101e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,413][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0448, 0.1460, 0.1412, 0.2161, 0.2543, 0.1976], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,414][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.1176, 0.3912, 0.1382, 0.0747, 0.0514, 0.2270], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,415][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0035, 0.6311, 0.3266, 0.0058, 0.0149, 0.0181], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,415][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([1.9599e-05, 8.5515e-01, 1.3866e-01, 3.7689e-04, 9.1161e-04, 4.8804e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,416][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([1.3116e-03, 9.5290e-01, 3.6662e-02, 1.8253e-03, 5.7336e-04, 6.7251e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,421][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0696, 0.8566, 0.0283, 0.0058, 0.0014, 0.0384], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,426][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.3901, 0.2127, 0.1088, 0.0209, 0.0292, 0.2383], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,427][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0231, 0.8380, 0.0829, 0.0121, 0.0016, 0.0423], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:50,428][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.5597, 0.0655, 0.0488, 0.0358, 0.0319, 0.0202, 0.2380],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,428][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0189, 0.8347, 0.0712, 0.0132, 0.0068, 0.0500, 0.0052],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,429][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([4.5330e-04, 7.9821e-01, 1.6157e-01, 8.4490e-04, 1.6791e-03, 3.5560e-02,
        1.6778e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,431][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([1.2384e-06, 9.6684e-01, 3.0654e-02, 1.2163e-04, 1.6114e-04, 2.0501e-03,
        1.7566e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,437][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0262, 0.1089, 0.1385, 0.1874, 0.1821, 0.2792, 0.0778],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,439][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.1079, 0.2894, 0.1411, 0.0507, 0.0470, 0.1942, 0.1699],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,440][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0034, 0.5958, 0.3193, 0.0056, 0.0241, 0.0478, 0.0041],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,441][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([8.6417e-06, 8.9844e-01, 9.1887e-02, 3.3388e-04, 4.4425e-04, 8.4587e-03,
        4.2892e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,441][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([9.0158e-04, 9.0201e-01, 6.8881e-02, 2.1442e-03, 8.0437e-04, 2.4026e-02,
        1.2332e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,442][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0164, 0.6313, 0.1603, 0.0130, 0.0120, 0.1613, 0.0058],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,447][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.4200, 0.1428, 0.1421, 0.0229, 0.0370, 0.1559, 0.0793],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,452][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0199, 0.8028, 0.0910, 0.0064, 0.0043, 0.0602, 0.0154],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:50,452][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.2774, 0.1087, 0.0407, 0.0587, 0.0191, 0.0176, 0.0981, 0.3797],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,453][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0072, 0.8289, 0.0617, 0.0188, 0.0068, 0.0648, 0.0105, 0.0013],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,454][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([3.3656e-05, 8.6923e-01, 8.5517e-02, 1.1076e-03, 1.1293e-03, 3.5926e-02,
        6.9561e-03, 1.0169e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,455][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([1.8409e-07, 9.3599e-01, 5.2373e-02, 3.0019e-04, 5.0674e-04, 7.3106e-03,
        3.5083e-03, 8.0372e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,457][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0252, 0.0822, 0.0930, 0.1497, 0.1201, 0.2498, 0.1577, 0.1224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,465][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0856, 0.3410, 0.1261, 0.0446, 0.0581, 0.1668, 0.1323, 0.0455],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,465][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0008, 0.5640, 0.3689, 0.0073, 0.0239, 0.0282, 0.0063, 0.0007],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,466][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([1.1714e-06, 8.9744e-01, 8.7361e-02, 6.1321e-04, 6.8712e-04, 1.0631e-02,
        3.2304e-03, 3.4496e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,467][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([2.3059e-04, 9.0946e-01, 5.8761e-02, 3.1547e-03, 9.5302e-04, 2.4115e-02,
        3.0941e-03, 2.3564e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,468][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0099, 0.6681, 0.1369, 0.0139, 0.0092, 0.1095, 0.0500, 0.0024],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,472][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.2757, 0.1684, 0.1356, 0.0298, 0.0343, 0.2419, 0.0615, 0.0528],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,477][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0050, 0.7553, 0.0956, 0.0144, 0.0042, 0.0866, 0.0353, 0.0035],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:50,478][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.4286, 0.0755, 0.0172, 0.0424, 0.0092, 0.0387, 0.0710, 0.0479, 0.2695],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,479][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0118, 0.8179, 0.0811, 0.0128, 0.0050, 0.0522, 0.0091, 0.0018, 0.0084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,480][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([5.0679e-04, 8.5252e-01, 9.7335e-02, 9.2770e-04, 1.4211e-03, 4.0520e-02,
        4.3541e-03, 8.5255e-04, 1.5601e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,481][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([1.2164e-06, 9.7559e-01, 2.0493e-02, 9.7953e-05, 9.1676e-05, 3.1717e-03,
        3.4240e-04, 1.5177e-05, 1.9619e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,485][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0240, 0.0477, 0.0739, 0.0814, 0.2700, 0.2026, 0.0956, 0.1225, 0.0824],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,490][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.1183, 0.2867, 0.0866, 0.0382, 0.0297, 0.1968, 0.1119, 0.0488, 0.0830],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,491][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0044, 0.6225, 0.2985, 0.0057, 0.0146, 0.0425, 0.0050, 0.0009, 0.0059],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,492][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([6.1228e-06, 8.4627e-01, 1.3621e-01, 5.0356e-04, 8.2494e-04, 1.2877e-02,
        2.4175e-03, 7.4169e-05, 8.1691e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,493][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([7.5407e-04, 9.1431e-01, 5.1695e-02, 2.6352e-03, 7.8728e-04, 2.0342e-02,
        5.7422e-03, 1.2046e-03, 2.5262e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,493][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0253, 0.6780, 0.0876, 0.0138, 0.0042, 0.1682, 0.0089, 0.0049, 0.0091],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,498][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.3378, 0.1853, 0.1234, 0.0191, 0.0274, 0.1152, 0.0877, 0.0398, 0.0643],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,503][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0222, 0.7512, 0.0674, 0.0079, 0.0026, 0.0701, 0.0515, 0.0081, 0.0191],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:50,504][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2058, 0.1340, 0.0847, 0.0748, 0.0527, 0.0436, 0.1048, 0.0988, 0.1176,
        0.0832], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,505][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0603, 0.7460, 0.0827, 0.0138, 0.0054, 0.0529, 0.0116, 0.0021, 0.0080,
        0.0171], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,505][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([5.9675e-03, 8.0389e-01, 1.2914e-01, 7.8150e-04, 1.0622e-03, 3.3106e-02,
        1.1287e-02, 9.2023e-04, 6.1996e-03, 7.6520e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,506][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9820e-05, 9.1810e-01, 4.7273e-02, 1.3503e-04, 1.6674e-04, 1.7006e-02,
        3.1963e-03, 1.5427e-04, 7.7977e-03, 6.1436e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,511][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0237, 0.0569, 0.0537, 0.0971, 0.1637, 0.2849, 0.0627, 0.1246, 0.0921,
        0.0405], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,516][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2377, 0.2154, 0.0911, 0.0320, 0.0352, 0.1347, 0.0713, 0.0427, 0.0549,
        0.0851], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,517][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0274, 0.5308, 0.3267, 0.0061, 0.0158, 0.0343, 0.0103, 0.0017, 0.0273,
        0.0195], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,517][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.9001e-04, 8.5381e-01, 1.0815e-01, 3.2239e-04, 6.3350e-04, 1.7312e-02,
        6.2250e-03, 1.1707e-04, 3.1781e-03, 1.0056e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,518][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.7892e-03, 8.8369e-01, 3.5915e-02, 2.4010e-03, 6.1123e-04, 2.6646e-02,
        8.5080e-03, 9.3020e-04, 4.7385e-03, 2.6775e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,519][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1092, 0.5877, 0.1161, 0.0122, 0.0068, 0.0902, 0.0151, 0.0033, 0.0396,
        0.0199], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,524][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4538, 0.0993, 0.0801, 0.0110, 0.0208, 0.1123, 0.0360, 0.0305, 0.0330,
        0.1231], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,528][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0988, 0.6443, 0.0752, 0.0099, 0.0030, 0.0390, 0.0427, 0.0107, 0.0265,
        0.0498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:50,529][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3043, 0.1569, 0.0825, 0.0635, 0.0305, 0.0815, 0.0564, 0.0687, 0.0398,
        0.0431, 0.0727], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,530][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1381, 0.5606, 0.0794, 0.0125, 0.0068, 0.0555, 0.0122, 0.0020, 0.0140,
        0.0264, 0.0925], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,531][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0474, 0.5828, 0.1221, 0.0009, 0.0021, 0.0646, 0.0220, 0.0017, 0.0213,
        0.0670, 0.0683], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,532][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0941e-04, 8.4329e-01, 1.1003e-01, 1.9307e-04, 1.3992e-03, 1.1893e-02,
        3.0890e-03, 2.3102e-04, 4.0369e-03, 1.6114e-02, 9.6160e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,537][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0216, 0.0547, 0.0744, 0.0958, 0.1510, 0.1582, 0.0712, 0.1264, 0.0832,
        0.0351, 0.1285], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,541][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1937, 0.2101, 0.0956, 0.0335, 0.0332, 0.0994, 0.0667, 0.0362, 0.0517,
        0.0708, 0.1092], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,542][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0865, 0.3922, 0.3485, 0.0037, 0.0202, 0.0330, 0.0109, 0.0024, 0.0283,
        0.0325, 0.0418], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,543][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([6.5474e-04, 8.2066e-01, 7.0482e-02, 2.6143e-04, 8.0133e-04, 1.7279e-02,
        5.7967e-03, 2.4238e-04, 1.1888e-02, 2.0976e-02, 5.0953e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,544][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0492, 0.6289, 0.0521, 0.0018, 0.0009, 0.0310, 0.0115, 0.0027, 0.0221,
        0.1005, 0.0994], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,545][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2061, 0.4851, 0.1049, 0.0096, 0.0070, 0.0685, 0.0105, 0.0067, 0.0206,
        0.0396, 0.0414], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,550][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.4192, 0.0493, 0.0428, 0.0058, 0.0106, 0.0640, 0.0340, 0.0143, 0.0376,
        0.0567, 0.2658], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,554][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2237, 0.4427, 0.0774, 0.0052, 0.0035, 0.0361, 0.0277, 0.0089, 0.0252,
        0.0753, 0.0744], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:50,555][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.6154, 0.0281, 0.0072, 0.0086, 0.0057, 0.0053, 0.0037, 0.0082, 0.0029,
        0.0139, 0.0122, 0.2889], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,556][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.1490, 0.5699, 0.0676, 0.0155, 0.0031, 0.0373, 0.0115, 0.0019, 0.0083,
        0.0221, 0.0985, 0.0153], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,557][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0345, 0.4169, 0.0774, 0.0005, 0.0012, 0.0269, 0.0043, 0.0018, 0.0099,
        0.0566, 0.3358, 0.0342], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,557][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.0236e-04, 8.6659e-01, 6.3930e-02, 1.8745e-04, 4.2013e-04, 1.8041e-02,
        1.8036e-03, 8.9449e-05, 2.5714e-03, 1.4330e-02, 2.3857e-02, 7.9739e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,562][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0125, 0.0583, 0.0917, 0.1055, 0.0947, 0.1635, 0.1061, 0.1318, 0.0969,
        0.0337, 0.0738, 0.0316], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,567][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.3033, 0.1790, 0.0863, 0.0176, 0.0151, 0.0692, 0.0752, 0.0265, 0.0393,
        0.0467, 0.0889, 0.0529], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,568][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0872, 0.4308, 0.2115, 0.0040, 0.0105, 0.0428, 0.0085, 0.0021, 0.0207,
        0.0431, 0.0688, 0.0699], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,569][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([5.2124e-04, 7.8358e-01, 5.4967e-02, 2.6563e-04, 4.6886e-04, 1.6988e-02,
        3.9513e-03, 1.7983e-04, 6.1531e-03, 1.4944e-02, 1.0531e-01, 1.2668e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,569][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0339, 0.6334, 0.0630, 0.0022, 0.0010, 0.0366, 0.0063, 0.0015, 0.0169,
        0.0842, 0.0871, 0.0340], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,570][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.2254, 0.4267, 0.1118, 0.0110, 0.0044, 0.0529, 0.0030, 0.0030, 0.0210,
        0.0504, 0.0795, 0.0109], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,575][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.5635, 0.0497, 0.0466, 0.0057, 0.0088, 0.0460, 0.0264, 0.0131, 0.0288,
        0.0376, 0.1046, 0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,579][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.1888, 0.4403, 0.0614, 0.0046, 0.0017, 0.0420, 0.0234, 0.0060, 0.0270,
        0.0765, 0.1014, 0.0270], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:50,580][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0397, 0.1083, 0.1895, 0.0569, 0.1673, 0.0353, 0.0385, 0.0557, 0.0402,
        0.0268, 0.0171, 0.0510, 0.1738], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,581][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0059, 0.6514, 0.0656, 0.0194, 0.0063, 0.0718, 0.0114, 0.0027, 0.0069,
        0.0230, 0.1134, 0.0089, 0.0132], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,582][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([7.3236e-05, 8.4125e-01, 3.7167e-02, 5.7005e-04, 3.9770e-04, 2.2211e-02,
        3.1698e-03, 3.4762e-04, 3.0394e-03, 8.8940e-03, 6.7168e-02, 1.4541e-02,
        1.1716e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,583][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([3.3193e-06, 8.3284e-01, 6.6378e-02, 2.2930e-04, 3.8435e-04, 1.3076e-02,
        2.3926e-03, 8.8444e-05, 2.8941e-03, 1.0327e-02, 2.9553e-02, 4.0513e-02,
        1.3203e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,588][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0143, 0.0521, 0.0737, 0.1006, 0.1297, 0.1952, 0.0360, 0.0803, 0.0672,
        0.0375, 0.0959, 0.0390, 0.0786], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,592][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0144, 0.2000, 0.0858, 0.0439, 0.0343, 0.1545, 0.0709, 0.0349, 0.0521,
        0.0723, 0.1367, 0.0288, 0.0713], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,593][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0009, 0.4010, 0.3550, 0.0057, 0.0112, 0.0332, 0.0070, 0.0012, 0.0169,
        0.0161, 0.0590, 0.0890, 0.0038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,594][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([1.0267e-05, 6.7684e-01, 8.0398e-02, 3.9963e-04, 5.7100e-04, 1.7233e-02,
        4.6907e-03, 1.8039e-04, 6.2566e-03, 1.3621e-02, 1.0328e-01, 9.4082e-02,
        2.4372e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,594][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([5.6946e-04, 6.7854e-01, 3.1102e-02, 1.6283e-03, 4.2330e-04, 2.5087e-02,
        3.8973e-03, 9.2937e-04, 1.3965e-02, 3.8488e-02, 1.4059e-01, 5.7328e-02,
        7.4533e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,596][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0127, 0.5608, 0.1255, 0.0135, 0.0094, 0.1082, 0.0085, 0.0068, 0.0140,
        0.0305, 0.0597, 0.0336, 0.0167], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,602][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1228, 0.1321, 0.0722, 0.0094, 0.0145, 0.1295, 0.0310, 0.0169, 0.0316,
        0.0616, 0.2459, 0.0856, 0.0469], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,604][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0041, 0.4096, 0.0655, 0.0107, 0.0028, 0.0648, 0.0458, 0.0062, 0.0354,
        0.0768, 0.1708, 0.0832, 0.0242], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:50,605][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.1184, 0.0353, 0.0272, 0.0252, 0.2930, 0.0059, 0.0138, 0.0070, 0.0069,
        0.0289, 0.0159, 0.0053, 0.1136, 0.3036], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,606][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0156, 0.5942, 0.0669, 0.0119, 0.0034, 0.0658, 0.0107, 0.0033, 0.0148,
        0.0326, 0.1055, 0.0350, 0.0309, 0.0094], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,607][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([3.8740e-03, 7.2896e-01, 8.4749e-02, 1.3575e-03, 8.2344e-04, 1.8347e-02,
        9.1828e-03, 5.7440e-04, 1.0830e-02, 1.5896e-02, 9.3974e-02, 2.4182e-02,
        4.0138e-03, 3.2401e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,608][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([8.0732e-06, 7.9531e-01, 1.5287e-01, 1.3682e-04, 2.3693e-04, 5.7453e-03,
        2.3389e-03, 4.8428e-05, 3.6788e-03, 5.9795e-03, 8.5923e-03, 2.2577e-02,
        1.2467e-03, 1.2317e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,614][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0094, 0.0492, 0.1078, 0.0795, 0.0598, 0.1200, 0.0680, 0.0949, 0.1418,
        0.0301, 0.0849, 0.0331, 0.0835, 0.0380], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,617][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0691, 0.1692, 0.0654, 0.0238, 0.0246, 0.1447, 0.0746, 0.0267, 0.0506,
        0.0687, 0.1071, 0.0445, 0.0873, 0.0437], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,618][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0164, 0.4737, 0.1983, 0.0034, 0.0074, 0.0179, 0.0077, 0.0025, 0.0263,
        0.0296, 0.0400, 0.1236, 0.0200, 0.0331], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,619][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([3.0909e-05, 7.1794e-01, 6.3620e-02, 2.6160e-04, 1.5689e-04, 1.3993e-02,
        2.6749e-03, 1.5701e-04, 7.8801e-03, 1.3813e-02, 9.4069e-02, 8.1097e-02,
        3.6535e-03, 6.5508e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,619][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([4.7557e-03, 6.7789e-01, 3.3441e-02, 2.3668e-03, 3.3410e-04, 2.5872e-02,
        6.0652e-03, 1.1698e-03, 1.0374e-02, 4.2549e-02, 7.9216e-02, 1.0436e-01,
        9.6392e-03, 1.9610e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,622][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0808, 0.4593, 0.1935, 0.0132, 0.0099, 0.0417, 0.0054, 0.0041, 0.0058,
        0.0243, 0.0838, 0.0273, 0.0231, 0.0280], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,628][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.2803, 0.0875, 0.1174, 0.0096, 0.0232, 0.0561, 0.0321, 0.0149, 0.0248,
        0.0455, 0.1477, 0.0452, 0.0347, 0.0809], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,630][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0278, 0.3964, 0.0737, 0.0069, 0.0013, 0.0453, 0.0318, 0.0065, 0.0551,
        0.0570, 0.1660, 0.0912, 0.0364, 0.0046], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:50,631][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.2153, 0.0551, 0.0124, 0.0290, 0.0054, 0.0227, 0.0559, 0.0388, 0.0310,
        0.0490, 0.0210, 0.0335, 0.1395, 0.0062, 0.2852], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,631][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0345, 0.5170, 0.0538, 0.0143, 0.0064, 0.0687, 0.0150, 0.0032, 0.0127,
        0.0250, 0.1620, 0.0181, 0.0354, 0.0169, 0.0171], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,632][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([3.6089e-03, 6.9433e-01, 9.5809e-02, 9.7759e-04, 1.2098e-03, 2.0657e-02,
        4.1540e-03, 4.5742e-04, 2.9956e-03, 2.0976e-02, 1.1669e-01, 1.6276e-02,
        4.4169e-03, 7.0663e-03, 1.0377e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,634][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([4.8643e-05, 9.0982e-01, 3.2804e-02, 2.5566e-04, 2.0589e-04, 7.8445e-03,
        1.1796e-03, 6.4147e-05, 6.8688e-04, 1.0029e-02, 1.2764e-02, 2.0225e-02,
        1.3864e-03, 4.9666e-04, 2.1867e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,640][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0137, 0.0495, 0.0526, 0.0709, 0.1047, 0.1142, 0.0783, 0.1225, 0.0993,
        0.0185, 0.0807, 0.0363, 0.0584, 0.0680, 0.0325], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,642][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0466, 0.1326, 0.0511, 0.0253, 0.0300, 0.1443, 0.0611, 0.0272, 0.0478,
        0.0922, 0.1301, 0.0348, 0.0866, 0.0432, 0.0471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,643][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0069, 0.3590, 0.3177, 0.0070, 0.0189, 0.0260, 0.0088, 0.0016, 0.0188,
        0.0239, 0.0463, 0.0663, 0.0146, 0.0577, 0.0264], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,644][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([9.6915e-05, 7.1330e-01, 1.4359e-01, 5.2772e-04, 8.8675e-04, 1.0084e-02,
        5.1540e-03, 1.3811e-04, 3.0909e-03, 6.8453e-03, 4.5193e-02, 6.0929e-02,
        3.4656e-03, 2.6191e-03, 4.0724e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,645][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0053, 0.7475, 0.0359, 0.0041, 0.0011, 0.0185, 0.0052, 0.0009, 0.0087,
        0.0416, 0.0743, 0.0276, 0.0175, 0.0039, 0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,649][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0935, 0.5570, 0.0591, 0.0081, 0.0022, 0.0551, 0.0116, 0.0039, 0.0079,
        0.0281, 0.0807, 0.0116, 0.0490, 0.0065, 0.0259], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,650][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.2888, 0.0765, 0.0488, 0.0081, 0.0122, 0.0896, 0.0310, 0.0181, 0.0413,
        0.0521, 0.1359, 0.0660, 0.0392, 0.0337, 0.0588], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,651][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0695, 0.4868, 0.0467, 0.0124, 0.0022, 0.0514, 0.0289, 0.0093, 0.0166,
        0.0594, 0.0962, 0.0481, 0.0349, 0.0051, 0.0324], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:50,659][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0850, 0.0691, 0.0606, 0.0451, 0.0571, 0.0206, 0.0699, 0.0549, 0.0881,
        0.0591, 0.0147, 0.0453, 0.1428, 0.0570, 0.0604, 0.0702],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,659][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1651, 0.4424, 0.0530, 0.0124, 0.0044, 0.0440, 0.0084, 0.0021, 0.0059,
        0.0140, 0.1017, 0.0162, 0.0310, 0.0184, 0.0176, 0.0633],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,660][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0300, 0.4921, 0.0838, 0.0007, 0.0007, 0.0264, 0.0089, 0.0010, 0.0045,
        0.0050, 0.1966, 0.0265, 0.0047, 0.0079, 0.0642, 0.0469],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,661][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.3721e-04, 6.9264e-01, 3.9133e-02, 1.7672e-04, 2.0264e-04, 2.2368e-02,
        4.1673e-03, 2.9018e-04, 9.0099e-03, 7.3308e-03, 3.5270e-02, 3.2481e-02,
        2.3495e-03, 1.0565e-03, 8.5292e-02, 6.7597e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,664][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0157, 0.0383, 0.0395, 0.0651, 0.1118, 0.1957, 0.0410, 0.0823, 0.0624,
        0.0282, 0.0797, 0.0504, 0.0626, 0.0693, 0.0349, 0.0232],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,671][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2229, 0.1141, 0.0576, 0.0241, 0.0236, 0.0857, 0.0290, 0.0245, 0.0273,
        0.0481, 0.0932, 0.0246, 0.0693, 0.0409, 0.0424, 0.0726],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,672][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0826, 0.2719, 0.2371, 0.0046, 0.0123, 0.0262, 0.0075, 0.0015, 0.0204,
        0.0125, 0.0586, 0.1026, 0.0117, 0.0557, 0.0284, 0.0664],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,673][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.0663e-03, 5.3682e-01, 9.6826e-02, 2.9644e-04, 7.2662e-04, 1.7600e-02,
        6.9257e-03, 1.6948e-04, 3.4244e-03, 9.4828e-03, 1.0935e-01, 1.0379e-01,
        5.6608e-03, 3.6655e-03, 1.3533e-02, 8.9665e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,674][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0460, 0.5030, 0.0250, 0.0020, 0.0005, 0.0233, 0.0088, 0.0010, 0.0046,
        0.0205, 0.1026, 0.0657, 0.0161, 0.0041, 0.0267, 0.1501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,676][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2292, 0.3350, 0.0641, 0.0093, 0.0040, 0.0700, 0.0098, 0.0030, 0.0176,
        0.0136, 0.0648, 0.0185, 0.0297, 0.0135, 0.0654, 0.0525],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,684][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3549, 0.0404, 0.0405, 0.0049, 0.0119, 0.0522, 0.0168, 0.0164, 0.0154,
        0.0576, 0.1194, 0.0469, 0.0280, 0.0429, 0.0328, 0.1190],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,684][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2179, 0.2975, 0.0379, 0.0055, 0.0018, 0.0245, 0.0279, 0.0078, 0.0150,
        0.0271, 0.1115, 0.0553, 0.0270, 0.0056, 0.0374, 0.1001],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:50,685][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.2130, 0.0444, 0.0073, 0.0214, 0.0116, 0.0046, 0.0252, 0.0291, 0.0258,
        0.0368, 0.0116, 0.0210, 0.0959, 0.0097, 0.0254, 0.0382, 0.3790],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,686][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1316, 0.4125, 0.0508, 0.0162, 0.0045, 0.0451, 0.0111, 0.0026, 0.0071,
        0.0182, 0.0896, 0.0188, 0.0333, 0.0185, 0.0265, 0.0828, 0.0308],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,689][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0171, 0.3392, 0.0932, 0.0009, 0.0014, 0.0188, 0.0040, 0.0014, 0.0025,
        0.0263, 0.1223, 0.0199, 0.0049, 0.0119, 0.0413, 0.2441, 0.0509],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,692][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([3.5511e-04, 7.7113e-01, 7.2723e-02, 3.0364e-04, 7.5900e-04, 5.7639e-03,
        1.1938e-03, 1.2847e-04, 1.6943e-03, 1.0234e-02, 1.6535e-02, 2.4523e-02,
        1.3568e-03, 2.8307e-03, 7.8324e-03, 6.5878e-02, 1.6757e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,696][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0142, 0.0466, 0.0558, 0.0634, 0.1031, 0.1221, 0.0767, 0.0708, 0.0635,
        0.0254, 0.0619, 0.0634, 0.0415, 0.0683, 0.0649, 0.0207, 0.0377],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,697][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.2163, 0.1132, 0.0672, 0.0281, 0.0232, 0.0733, 0.0352, 0.0206, 0.0266,
        0.0508, 0.0583, 0.0417, 0.0777, 0.0372, 0.0315, 0.0708, 0.0281],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,698][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0283, 0.2283, 0.2687, 0.0042, 0.0154, 0.0174, 0.0061, 0.0014, 0.0146,
        0.0242, 0.0371, 0.0682, 0.0116, 0.0640, 0.0286, 0.1498, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,699][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([6.9617e-04, 7.0301e-01, 8.7281e-02, 4.4584e-04, 1.5281e-03, 1.0158e-02,
        4.9552e-03, 1.3241e-04, 3.2541e-03, 7.2268e-03, 3.7185e-02, 5.1395e-02,
        4.6027e-03, 5.7645e-03, 9.3988e-03, 5.4791e-02, 1.8174e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,702][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0154, 0.3620, 0.0357, 0.0019, 0.0012, 0.0162, 0.0080, 0.0010, 0.0087,
        0.0436, 0.0775, 0.1021, 0.0131, 0.0073, 0.0289, 0.2537, 0.0237],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,709][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0819, 0.4247, 0.0623, 0.0093, 0.0058, 0.0594, 0.0077, 0.0033, 0.0068,
        0.0384, 0.0450, 0.0210, 0.0229, 0.0158, 0.0361, 0.1421, 0.0174],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,710][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.2854, 0.0474, 0.0401, 0.0081, 0.0141, 0.0613, 0.0263, 0.0115, 0.0248,
        0.0339, 0.1356, 0.0520, 0.0288, 0.0434, 0.0374, 0.0686, 0.0811],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,711][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.1130, 0.3835, 0.0409, 0.0066, 0.0023, 0.0281, 0.0252, 0.0085, 0.0137,
        0.0410, 0.0741, 0.0490, 0.0253, 0.0053, 0.0232, 0.1382, 0.0225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:50,712][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2210, 0.0879, 0.0922, 0.0430, 0.0434, 0.0238, 0.0262, 0.0341, 0.0242,
        0.0274, 0.0176, 0.0352, 0.1069, 0.0444, 0.0160, 0.0347, 0.0239, 0.0982],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,714][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4649, 0.1040, 0.0170, 0.0042, 0.0017, 0.0140, 0.0032, 0.0009, 0.0030,
        0.0077, 0.0352, 0.0078, 0.0145, 0.0095, 0.0092, 0.0384, 0.0199, 0.2449],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,719][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.3325e-01, 3.5892e-02, 1.4546e-02, 8.1142e-05, 2.2131e-04, 6.0867e-03,
        1.5619e-03, 3.3998e-04, 1.7719e-03, 4.5248e-03, 2.4759e-02, 1.1167e-02,
        1.0359e-03, 4.1304e-03, 2.2414e-02, 5.6874e-02, 9.8680e-02, 4.8266e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,722][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.9838e-03, 1.9456e-01, 2.2283e-02, 6.6268e-05, 2.3008e-04, 6.1446e-03,
        1.9396e-03, 2.6868e-04, 3.2734e-03, 8.5097e-03, 7.7328e-03, 2.5308e-02,
        1.2228e-03, 1.8710e-03, 1.5299e-02, 8.2262e-02, 1.3870e-01, 4.8134e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,723][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0158, 0.0314, 0.0496, 0.0542, 0.1275, 0.1131, 0.0449, 0.0756, 0.0541,
        0.0223, 0.0780, 0.0465, 0.0491, 0.0829, 0.0318, 0.0198, 0.0307, 0.0727],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,723][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3125, 0.0958, 0.0506, 0.0190, 0.0225, 0.0511, 0.0198, 0.0159, 0.0197,
        0.0333, 0.0635, 0.0226, 0.0535, 0.0458, 0.0295, 0.0529, 0.0229, 0.0692],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,724][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3904, 0.0556, 0.0702, 0.0009, 0.0041, 0.0086, 0.0024, 0.0006, 0.0048,
        0.0079, 0.0089, 0.0389, 0.0043, 0.0330, 0.0153, 0.0496, 0.0383, 0.2662],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,726][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.4165e-02, 6.6697e-02, 1.8937e-02, 5.0889e-05, 1.8061e-04, 3.5766e-03,
        2.2043e-03, 1.1932e-04, 2.9430e-03, 5.6532e-03, 2.5291e-02, 3.7293e-02,
        1.7195e-03, 2.4578e-03, 8.1176e-03, 5.7860e-02, 9.8539e-02, 6.5420e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,730][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.6939e-01, 4.5831e-02, 5.6109e-03, 2.2782e-04, 1.2822e-04, 3.8393e-03,
        2.6539e-03, 5.6019e-04, 3.8719e-03, 1.1363e-02, 1.1260e-02, 2.5130e-02,
        2.9467e-03, 1.9744e-03, 1.3235e-02, 9.2570e-02, 4.4642e-02, 5.6477e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,734][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.4912, 0.0787, 0.0291, 0.0031, 0.0015, 0.0200, 0.0055, 0.0032, 0.0046,
        0.0118, 0.0142, 0.0150, 0.0081, 0.0049, 0.0205, 0.0474, 0.1133, 0.1279],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,735][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4288, 0.0176, 0.0165, 0.0022, 0.0055, 0.0167, 0.0120, 0.0067, 0.0098,
        0.0194, 0.0664, 0.0284, 0.0135, 0.0278, 0.0142, 0.0424, 0.0350, 0.2371],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,736][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.9986e-01, 4.5270e-02, 8.8695e-03, 7.8550e-04, 5.1558e-04, 6.4281e-03,
        8.0451e-03, 2.4188e-03, 5.8202e-03, 1.3773e-02, 3.1409e-02, 1.4936e-02,
        8.6307e-03, 2.5843e-03, 1.4675e-02, 5.4329e-02, 2.5773e-02, 1.5588e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:50,737][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.3816, 0.0226, 0.0158, 0.0101, 0.0204, 0.0037, 0.0055, 0.0029, 0.0045,
        0.0118, 0.0070, 0.0042, 0.0292, 0.0092, 0.0039, 0.0109, 0.0131, 0.0127,
        0.4308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,741][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.2558, 0.1320, 0.0205, 0.0037, 0.0013, 0.0199, 0.0026, 0.0013, 0.0044,
        0.0120, 0.0417, 0.0081, 0.0129, 0.0073, 0.0127, 0.0591, 0.0189, 0.3150,
        0.0708], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,745][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([4.5240e-02, 5.8573e-03, 1.4132e-03, 8.7016e-06, 1.6072e-05, 7.9289e-04,
        1.1776e-04, 7.7287e-05, 1.3155e-04, 1.3361e-03, 7.7294e-03, 1.8389e-03,
        1.4841e-04, 4.7863e-04, 4.2662e-03, 1.7463e-02, 1.4707e-02, 7.2598e-01,
        1.7240e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,747][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([4.6724e-03, 3.7362e-02, 2.4846e-03, 1.0182e-05, 2.7744e-05, 1.0072e-03,
        2.5917e-04, 2.5956e-05, 1.9470e-04, 3.1700e-03, 4.5726e-03, 4.2060e-03,
        3.9703e-04, 4.4841e-04, 1.6635e-03, 3.5901e-02, 6.6516e-02, 6.6313e-01,
        1.7395e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,748][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0090, 0.0400, 0.0649, 0.0525, 0.1249, 0.1016, 0.0766, 0.0648, 0.0485,
        0.0242, 0.0503, 0.0540, 0.0525, 0.0791, 0.0298, 0.0225, 0.0270, 0.0545,
        0.0231], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,749][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.3075, 0.0838, 0.0551, 0.0117, 0.0141, 0.0634, 0.0269, 0.0149, 0.0157,
        0.0297, 0.0808, 0.0442, 0.0376, 0.0299, 0.0273, 0.0394, 0.0352, 0.0684,
        0.0144], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,750][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([2.0970e-01, 3.5353e-02, 2.8566e-02, 3.3022e-04, 9.6779e-04, 2.5016e-03,
        7.0139e-04, 3.7045e-04, 2.4019e-03, 4.1424e-03, 9.4170e-03, 1.2476e-02,
        2.6644e-03, 1.1064e-02, 6.7102e-03, 3.0395e-02, 2.0470e-02, 5.5088e-01,
        7.0891e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,752][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([3.1404e-03, 2.8710e-02, 5.3678e-03, 1.0799e-05, 3.4981e-05, 7.2327e-04,
        3.8266e-04, 2.0917e-05, 4.7869e-04, 1.4254e-03, 9.8235e-03, 4.5183e-03,
        3.9722e-04, 5.3042e-04, 2.7003e-03, 1.6193e-02, 2.1456e-02, 7.2911e-01,
        1.7498e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,757][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([7.8721e-02, 3.9699e-02, 2.8633e-03, 1.6528e-04, 7.5490e-05, 4.7864e-03,
        1.2971e-03, 3.8314e-04, 3.0057e-03, 1.0931e-02, 1.5360e-02, 1.7475e-02,
        1.5717e-03, 1.0179e-03, 9.5476e-03, 6.5955e-02, 4.3628e-02, 6.2613e-01,
        7.7389e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,759][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.5101, 0.0569, 0.0061, 0.0014, 0.0006, 0.0122, 0.0005, 0.0008, 0.0034,
        0.0119, 0.0220, 0.0046, 0.0069, 0.0030, 0.0071, 0.0434, 0.0401, 0.2081,
        0.0610], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,760][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.5820, 0.0169, 0.0142, 0.0017, 0.0026, 0.0204, 0.0087, 0.0051, 0.0059,
        0.0105, 0.0323, 0.0276, 0.0120, 0.0131, 0.0130, 0.0233, 0.0347, 0.0965,
        0.0798], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,761][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([4.2553e-01, 4.4326e-02, 6.2382e-03, 7.3480e-04, 3.0124e-04, 3.3953e-03,
        4.3084e-03, 2.2261e-03, 3.0276e-03, 8.1094e-03, 1.9501e-02, 2.0313e-02,
        4.4795e-03, 1.7293e-03, 6.7989e-03, 3.1681e-02, 2.8857e-02, 2.7696e-01,
        1.1148e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:50,762][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0806, 0.0567, 0.0414, 0.0379, 0.0376, 0.0140, 0.0594, 0.0474, 0.0674,
        0.0493, 0.0097, 0.0449, 0.1091, 0.0387, 0.0492, 0.0601, 0.0866, 0.0146,
        0.0329, 0.0625], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,764][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.4700e-01, 4.0996e-02, 5.4865e-03, 1.2480e-03, 4.9235e-04, 6.1316e-03,
        9.8079e-04, 3.4603e-04, 7.3261e-04, 2.1285e-03, 1.8189e-02, 2.2422e-03,
        5.7319e-03, 3.5915e-03, 3.1936e-03, 1.2322e-02, 7.4438e-03, 1.5929e-01,
        3.5136e-02, 2.4731e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,767][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6130e-01, 4.5999e-03, 1.2023e-03, 6.8332e-06, 1.1424e-05, 5.3968e-04,
        1.7314e-04, 3.6900e-05, 9.2993e-05, 1.0690e-04, 6.1758e-03, 8.8966e-04,
        1.3868e-04, 3.5052e-04, 3.0212e-03, 1.6296e-03, 1.9742e-02, 4.2180e-01,
        1.4911e-01, 2.2908e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,772][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.2340e-03, 3.1146e-03, 2.4371e-04, 8.6564e-07, 1.3133e-06, 2.1081e-04,
        4.2018e-05, 6.2674e-06, 1.2739e-04, 9.7511e-05, 7.1779e-04, 4.8992e-04,
        3.8089e-05, 2.1611e-05, 1.7772e-03, 1.3716e-03, 8.2183e-03, 1.5550e-01,
        9.1126e-02, 7.3367e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,773][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0125, 0.0304, 0.0315, 0.0526, 0.0935, 0.1713, 0.0355, 0.0700, 0.0496,
        0.0226, 0.0650, 0.0419, 0.0493, 0.0576, 0.0285, 0.0185, 0.0291, 0.0567,
        0.0687, 0.0154], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,774][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.4218, 0.0496, 0.0277, 0.0106, 0.0119, 0.0399, 0.0134, 0.0141, 0.0131,
        0.0249, 0.0491, 0.0126, 0.0375, 0.0240, 0.0228, 0.0410, 0.0197, 0.0627,
        0.0154, 0.0884], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,774][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.9750e-01, 1.1244e-02, 1.4311e-02, 1.9801e-04, 7.3742e-04, 1.6793e-03,
        4.8602e-04, 1.6160e-04, 1.4808e-03, 9.0180e-04, 5.5058e-03, 9.6376e-03,
        9.8402e-04, 6.9627e-03, 2.8069e-03, 6.6633e-03, 6.3673e-03, 2.7098e-01,
        1.2182e-01, 2.3958e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,776][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([7.0239e-03, 2.3181e-03, 7.5192e-04, 1.5201e-06, 5.4368e-06, 1.7786e-04,
        7.5999e-05, 3.2011e-06, 3.4908e-05, 1.1849e-04, 1.8733e-03, 1.6913e-03,
        7.7434e-05, 7.9458e-05, 2.4318e-04, 1.7951e-03, 7.4456e-03, 1.7311e-01,
        1.7704e-01, 6.2614e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,780][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.3260e-01, 5.6147e-03, 3.7976e-04, 2.2581e-05, 8.3465e-06, 5.1924e-04,
        1.9228e-04, 3.7250e-05, 1.1960e-04, 5.2490e-04, 3.8510e-03, 2.1078e-03,
        4.6339e-04, 1.5904e-04, 1.0156e-03, 5.5619e-03, 5.2185e-03, 1.9753e-01,
        4.2880e-02, 6.0119e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,784][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.6921e-01, 2.5805e-02, 5.5864e-03, 7.6513e-04, 3.5320e-04, 6.4880e-03,
        8.8180e-04, 4.5457e-04, 1.9905e-03, 1.5130e-03, 9.6878e-03, 2.2990e-03,
        3.9060e-03, 1.9657e-03, 9.2510e-03, 7.1207e-03, 3.5839e-02, 1.2583e-01,
        8.7687e-02, 1.0336e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,785][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.4629, 0.0080, 0.0082, 0.0009, 0.0025, 0.0101, 0.0036, 0.0042, 0.0030,
        0.0128, 0.0296, 0.0119, 0.0072, 0.0121, 0.0078, 0.0308, 0.0238, 0.0982,
        0.0417, 0.2205], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,786][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([5.1408e-01, 1.3306e-02, 2.0549e-03, 2.5584e-04, 1.1979e-04, 1.6256e-03,
        2.2241e-03, 7.9156e-04, 1.0621e-03, 2.0040e-03, 1.0941e-02, 4.5104e-03,
        2.3830e-03, 5.9440e-04, 3.2422e-03, 9.2722e-03, 1.1609e-02, 1.3947e-01,
        9.6854e-02, 1.8360e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:50,789][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:50,794][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4437],
        [22049],
        [24005],
        [24285],
        [27625],
        [29174],
        [14935],
        [21480],
        [41613],
        [39601],
        [35548],
        [39846],
        [31305],
        [28977],
        [29316],
        [36790],
        [34849],
        [35420],
        [40255],
        [38169]], device='cuda:0')
[2024-07-24 10:16:50,797][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4230],
        [12558],
        [19244],
        [14484],
        [20135],
        [24986],
        [11637],
        [14524],
        [35283],
        [34243],
        [27171],
        [30971],
        [23903],
        [18363],
        [22874],
        [29188],
        [26911],
        [29843],
        [40198],
        [34513]], device='cuda:0')
[2024-07-24 10:16:50,799][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[23125],
        [22138],
        [10011],
        [21125],
        [22529],
        [22612],
        [22657],
        [22086],
        [22767],
        [21548],
        [21763],
        [22517],
        [18112],
        [21807],
        [22262],
        [20624],
        [19860],
        [21196],
        [21763],
        [19809]], device='cuda:0')
[2024-07-24 10:16:50,801][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 8468],
        [10130],
        [10844],
        [10510],
        [10901],
        [11247],
        [11201],
        [11313],
        [11657],
        [11855],
        [11935],
        [11975],
        [12230],
        [12298],
        [12381],
        [12524],
        [12668],
        [13000],
        [13147],
        [13282]], device='cuda:0')
[2024-07-24 10:16:50,802][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[5021],
        [9549],
        [7977],
        [9049],
        [8574],
        [8975],
        [9062],
        [8995],
        [8952],
        [9038],
        [9219],
        [9361],
        [9387],
        [9320],
        [9323],
        [9271],
        [9312],
        [9324],
        [9450],
        [9338]], device='cuda:0')
[2024-07-24 10:16:50,804][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35683],
        [35944],
        [35512],
        [36573],
        [36729],
        [36843],
        [37135],
        [37174],
        [37221],
        [37456],
        [37520],
        [37568],
        [37652],
        [37717],
        [37563],
        [37618],
        [37635],
        [38034],
        [38128],
        [37871]], device='cuda:0')
[2024-07-24 10:16:50,808][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32481],
        [31198],
        [28854],
        [28135],
        [27435],
        [27180],
        [27100],
        [27262],
        [26615],
        [26527],
        [26494],
        [26239],
        [26297],
        [26204],
        [25917],
        [25862],
        [25726],
        [25692],
        [25442],
        [25420]], device='cuda:0')
[2024-07-24 10:16:50,811][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19215],
        [16864],
        [13496],
        [13068],
        [10023],
        [ 8785],
        [ 8557],
        [ 8728],
        [ 8938],
        [ 9601],
        [ 9303],
        [ 9473],
        [ 9497],
        [ 8671],
        [ 8556],
        [ 9054],
        [ 8892],
        [ 8982],
        [ 8855],
        [ 9331]], device='cuda:0')
[2024-07-24 10:16:50,813][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13044],
        [13658],
        [20165],
        [31181],
        [18963],
        [23686],
        [24325],
        [25709],
        [23462],
        [25489],
        [27891],
        [24753],
        [29073],
        [24314],
        [28641],
        [28474],
        [30792],
        [25176],
        [27000],
        [27028]], device='cuda:0')
[2024-07-24 10:16:50,815][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[36437],
        [43901],
        [41825],
        [33551],
        [38413],
        [37495],
        [34516],
        [40115],
        [40826],
        [36002],
        [40163],
        [40513],
        [37976],
        [41883],
        [42634],
        [39262],
        [41880],
        [42375],
        [41902],
        [39118]], device='cuda:0')
[2024-07-24 10:16:50,816][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[25278],
        [27068],
        [27877],
        [26978],
        [27330],
        [27345],
        [27522],
        [27603],
        [27455],
        [27433],
        [27324],
        [27446],
        [27606],
        [27592],
        [27627],
        [27625],
        [27687],
        [27674],
        [27741],
        [27768]], device='cuda:0')
[2024-07-24 10:16:50,819][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[2211],
        [1921],
        [3143],
        [3121],
        [3480],
        [2760],
        [2933],
        [3160],
        [2602],
        [2500],
        [2190],
        [2087],
        [2686],
        [3192],
        [2320],
        [1735],
        [1356],
        [1126],
        [ 765],
        [ 568]], device='cuda:0')
[2024-07-24 10:16:50,822][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[45074],
        [35899],
        [12898],
        [34692],
        [ 8140],
        [33107],
        [25024],
        [21585],
        [30519],
        [18329],
        [26017],
        [23180],
        [19981],
        [14900],
        [25214],
        [15933],
        [26551],
        [21492],
        [20032],
        [16087]], device='cuda:0')
[2024-07-24 10:16:50,825][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[47596],
        [47740],
        [47671],
        [47414],
        [47307],
        [47311],
        [47371],
        [47428],
        [47309],
        [47704],
        [47918],
        [47848],
        [47697],
        [47752],
        [47698],
        [48056],
        [48048],
        [46969],
        [44156],
        [46918]], device='cuda:0')
[2024-07-24 10:16:50,828][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 2219],
        [17931],
        [17461],
        [32852],
        [34207],
        [ 9441],
        [20847],
        [22717],
        [21237],
        [24184],
        [29193],
        [25277],
        [30721],
        [32558],
        [12844],
        [30740],
        [23119],
        [25361],
        [ 6229],
        [25419]], device='cuda:0')
[2024-07-24 10:16:50,829][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21609],
        [19606],
        [25178],
        [19201],
        [26480],
        [29315],
        [29339],
        [26476],
        [29939],
        [27273],
        [26179],
        [22902],
        [24394],
        [28475],
        [25142],
        [25071],
        [24349],
        [23367],
        [31144],
        [24105]], device='cuda:0')
[2024-07-24 10:16:50,831][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[19810],
        [10388],
        [12135],
        [12016],
        [11752],
        [11015],
        [11285],
        [11070],
        [11234],
        [11029],
        [ 9886],
        [ 9815],
        [ 9992],
        [10148],
        [ 9622],
        [10242],
        [10407],
        [ 8871],
        [ 8936],
        [11291]], device='cuda:0')
[2024-07-24 10:16:50,833][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22282],
        [14536],
        [15387],
        [15333],
        [15421],
        [15370],
        [15461],
        [15812],
        [15795],
        [15747],
        [17635],
        [18000],
        [16711],
        [16886],
        [17168],
        [19444],
        [24560],
        [30162],
        [36041],
        [33280]], device='cuda:0')
[2024-07-24 10:16:50,836][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13676],
        [18391],
        [18322],
        [18129],
        [18204],
        [18325],
        [18355],
        [18294],
        [18377],
        [18382],
        [18391],
        [18935],
        [19325],
        [18465],
        [18885],
        [18548],
        [19869],
        [17704],
        [12953],
        [20330]], device='cuda:0')
[2024-07-24 10:16:50,839][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9659],
        [18402],
        [19422],
        [19259],
        [19415],
        [20114],
        [21011],
        [21495],
        [21444],
        [22170],
        [22166],
        [23089],
        [22528],
        [23549],
        [22780],
        [22433],
        [23197],
        [21856],
        [22249],
        [22781]], device='cuda:0')
[2024-07-24 10:16:50,842][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6933],
        [3137],
        [2205],
        [2155],
        [2469],
        [5082],
        [5677],
        [4972],
        [5231],
        [5261],
        [5441],
        [5048],
        [6185],
        [7336],
        [8255],
        [8064],
        [7858],
        [8267],
        [8350],
        [9152]], device='cuda:0')
[2024-07-24 10:16:50,843][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34989],
        [30321],
        [24884],
        [23901],
        [24190],
        [24705],
        [24654],
        [24801],
        [24553],
        [25031],
        [26323],
        [25591],
        [23974],
        [24444],
        [24933],
        [24990],
        [23237],
        [32637],
        [31371],
        [26133]], device='cuda:0')
[2024-07-24 10:16:50,845][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23865],
        [28998],
        [28692],
        [26806],
        [28098],
        [27228],
        [27774],
        [27817],
        [27186],
        [27471],
        [29150],
        [30553],
        [28756],
        [29072],
        [26908],
        [28451],
        [27910],
        [37086],
        [35631],
        [26321]], device='cuda:0')
[2024-07-24 10:16:50,847][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[26148],
        [31249],
        [28551],
        [28075],
        [28571],
        [28677],
        [28044],
        [28389],
        [28590],
        [29179],
        [28052],
        [27688],
        [29419],
        [29528],
        [29116],
        [28543],
        [26537],
        [25531],
        [25628],
        [20135]], device='cuda:0')
[2024-07-24 10:16:50,850][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[16551],
        [11035],
        [ 5889],
        [ 5063],
        [ 5515],
        [ 5414],
        [ 6692],
        [ 6661],
        [ 6596],
        [ 7089],
        [ 7874],
        [ 8511],
        [ 7783],
        [ 8200],
        [ 8368],
        [11742],
        [10732],
        [14759],
        [14109],
        [14073]], device='cuda:0')
[2024-07-24 10:16:50,854][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14971],
        [15793],
        [24331],
        [14729],
        [18558],
        [ 9996],
        [13533],
        [ 6958],
        [ 9057],
        [ 8802],
        [ 4518],
        [10796],
        [ 4631],
        [ 9874],
        [ 6848],
        [ 9218],
        [ 6274],
        [ 8282],
        [12137],
        [ 9642]], device='cuda:0')
[2024-07-24 10:16:50,856][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6894],
        [ 8857],
        [13339],
        [13837],
        [13707],
        [13602],
        [13698],
        [13850],
        [13862],
        [13992],
        [13299],
        [13684],
        [15335],
        [15635],
        [14136],
        [13512],
        [14323],
        [ 6723],
        [ 8878],
        [ 7959]], device='cuda:0')
[2024-07-24 10:16:50,858][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 6867],
        [ 8060],
        [ 8003],
        [10262],
        [ 8063],
        [ 8320],
        [ 7977],
        [ 8530],
        [ 8351],
        [ 8416],
        [ 8432],
        [ 7643],
        [ 8465],
        [ 7119],
        [ 8132],
        [ 7431],
        [ 7031],
        [ 6144],
        [ 4935],
        [ 6659]], device='cuda:0')
[2024-07-24 10:16:50,859][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32124],
        [18152],
        [17830],
        [10548],
        [15001],
        [25693],
        [16955],
        [18176],
        [16981],
        [13893],
        [13060],
        [16481],
        [11794],
        [12673],
        [20148],
        [ 9927],
        [13364],
        [11143],
        [17659],
        [ 8420]], device='cuda:0')
[2024-07-24 10:16:50,861][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421],
        [35421]], device='cuda:0')
[2024-07-24 10:16:50,916][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:50,918][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,919][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,920][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,920][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,921][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,923][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,923][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,924][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,925][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,925][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,926][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,928][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:50,933][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0411, 0.9589], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,935][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1994, 0.8006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,936][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.8033, 0.1967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,937][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4611, 0.5389], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,937][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4735, 0.5265], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,938][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0856, 0.9144], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,940][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8620, 0.1380], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,944][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4927, 0.5073], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,949][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5588, 0.4412], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,949][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3923, 0.6077], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,950][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5915, 0.4085], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,951][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.0000e+00, 6.6649e-09], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:50,951][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0302, 0.5209, 0.4489], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,954][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1657, 0.6379, 0.1964], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,961][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.6349, 0.2458, 0.1193], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,962][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1208, 0.7666, 0.1125], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,962][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.3040, 0.3384, 0.3576], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,963][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0379, 0.4880, 0.4740], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,964][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.5330, 0.3379, 0.1291], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,966][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.1154, 0.7772, 0.1073], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,973][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.4055, 0.3601, 0.2344], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,974][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.2071, 0.5278, 0.2650], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,975][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.3950, 0.2754, 0.3296], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,975][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([7.4402e-02, 9.2560e-01, 2.1624e-07], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:50,976][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0148, 0.3734, 0.3656, 0.2461], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,979][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1315, 0.5039, 0.1877, 0.1769], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,986][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.6098, 0.2129, 0.1166, 0.0606], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,986][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0240, 0.5313, 0.4237, 0.0210], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,987][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2250, 0.2507, 0.2656, 0.2586], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,988][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0255, 0.3360, 0.3412, 0.2973], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,989][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5042, 0.1447, 0.1857, 0.1654], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,992][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1961, 0.5310, 0.0426, 0.2303], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,998][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3555, 0.2320, 0.1472, 0.2653], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:50,999][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.6104, 0.1044, 0.0709, 0.2143], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,000][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3276, 0.2117, 0.2422, 0.2185], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,000][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([3.6344e-03, 8.6104e-09, 9.9637e-01, 2.2350e-12], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,001][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0144, 0.2728, 0.2765, 0.2104, 0.2260], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,003][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.1142, 0.4223, 0.1578, 0.1965, 0.1093], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,011][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.4292, 0.2321, 0.1181, 0.0875, 0.1332], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,011][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0232, 0.7110, 0.2442, 0.0122, 0.0094], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,012][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.1783, 0.1990, 0.2106, 0.2050, 0.2071], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,013][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0199, 0.2690, 0.2620, 0.2448, 0.2043], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,013][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.3210, 0.1896, 0.1435, 0.2181, 0.1278], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,018][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1012, 0.5179, 0.0751, 0.2022, 0.1035], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,023][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.2617, 0.1795, 0.1344, 0.2181, 0.2064], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,024][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.2920, 0.1501, 0.0983, 0.3064, 0.1533], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,024][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.2525, 0.1700, 0.2031, 0.1802, 0.1942], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,025][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ James] are: tensor([2.4074e-03, 3.6463e-01, 9.9216e-03, 6.2304e-01, 2.3997e-07],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,026][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0151, 0.2279, 0.2274, 0.1766, 0.1956, 0.1575], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,030][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0979, 0.3545, 0.1462, 0.1423, 0.1225, 0.1367], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,036][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.4573, 0.1940, 0.1050, 0.0645, 0.0986, 0.0806], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,038][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0281, 0.6394, 0.2759, 0.0184, 0.0124, 0.0258], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,039][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.1478, 0.1646, 0.1746, 0.1698, 0.1716, 0.1717], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,040][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0242, 0.2203, 0.2253, 0.2286, 0.1767, 0.1249], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,040][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3241, 0.1303, 0.1063, 0.1589, 0.2121, 0.0683], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,041][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.1401, 0.5332, 0.0509, 0.1469, 0.0725, 0.0564], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,046][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.3385, 0.1345, 0.0810, 0.1816, 0.1474, 0.1171], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,050][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2177, 0.1195, 0.0602, 0.3793, 0.1717, 0.0516], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,051][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.2207, 0.1480, 0.1724, 0.1500, 0.1604, 0.1485], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,052][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ were] are: tensor([1.8668e-03, 1.4918e-05, 9.8702e-01, 2.7115e-04, 1.0818e-02, 4.8183e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,053][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0159, 0.1955, 0.1913, 0.1497, 0.1664, 0.1441, 0.1372],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,053][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0780, 0.2961, 0.1414, 0.1357, 0.1044, 0.1451, 0.0993],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,058][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.4174, 0.1395, 0.0809, 0.0591, 0.0893, 0.0766, 0.1372],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,063][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0277, 0.4236, 0.4791, 0.0146, 0.0136, 0.0318, 0.0096],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,063][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.1259, 0.1392, 0.1474, 0.1436, 0.1453, 0.1456, 0.1530],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,064][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0239, 0.1927, 0.2039, 0.1856, 0.1655, 0.1059, 0.1225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,065][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.2660, 0.1117, 0.0984, 0.1365, 0.1647, 0.1013, 0.1213],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,066][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0872, 0.5237, 0.0477, 0.1877, 0.0538, 0.0534, 0.0466],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,070][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.2098, 0.1432, 0.0882, 0.1637, 0.1377, 0.1053, 0.1520],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,075][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1721, 0.1983, 0.0863, 0.2841, 0.1366, 0.0821, 0.0405],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,076][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.1752, 0.1279, 0.1509, 0.1347, 0.1419, 0.1248, 0.1446],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,076][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([3.3657e-03, 6.5705e-03, 3.4415e-02, 3.8058e-02, 3.1569e-03, 9.1443e-01,
        2.2929e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,077][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0147, 0.1676, 0.1658, 0.1282, 0.1546, 0.1295, 0.1330, 0.1065],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,078][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0683, 0.2861, 0.1130, 0.1263, 0.0948, 0.1302, 0.1277, 0.0536],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,083][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.4115, 0.1275, 0.0814, 0.0413, 0.0751, 0.0533, 0.1148, 0.0952],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,087][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0189, 0.4913, 0.3820, 0.0181, 0.0174, 0.0405, 0.0255, 0.0061],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,088][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.1093, 0.1211, 0.1281, 0.1247, 0.1265, 0.1265, 0.1327, 0.1310],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,089][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0219, 0.1649, 0.1747, 0.1698, 0.1427, 0.0981, 0.1181, 0.1098],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,089][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.2230, 0.0930, 0.0879, 0.1307, 0.1388, 0.0957, 0.1827, 0.0483],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,090][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.1115, 0.4936, 0.0432, 0.1697, 0.0434, 0.0467, 0.0407, 0.0512],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,095][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.2401, 0.1189, 0.0733, 0.1430, 0.1219, 0.0841, 0.1117, 0.1071],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,099][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.2303, 0.1487, 0.0694, 0.2912, 0.1305, 0.0679, 0.0344, 0.0277],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,100][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.1553, 0.1090, 0.1267, 0.1131, 0.1178, 0.1071, 0.1257, 0.1453],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,101][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ about] are: tensor([4.4226e-06, 3.5309e-06, 5.8756e-01, 9.8202e-06, 1.3868e-03, 2.9829e-02,
        3.8121e-01, 2.0206e-09], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,102][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0108, 0.1466, 0.1425, 0.1171, 0.1291, 0.1198, 0.1067, 0.1203, 0.1070],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,102][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0788, 0.2619, 0.0923, 0.1353, 0.0923, 0.1237, 0.1089, 0.0638, 0.0432],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,107][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.3678, 0.1234, 0.0708, 0.0380, 0.0649, 0.0541, 0.1097, 0.1022, 0.0690],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,112][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0240, 0.4682, 0.4096, 0.0192, 0.0136, 0.0346, 0.0170, 0.0048, 0.0090],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,112][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0968, 0.1069, 0.1132, 0.1102, 0.1116, 0.1116, 0.1170, 0.1154, 0.1173],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,113][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0261, 0.1529, 0.1510, 0.1526, 0.1244, 0.0868, 0.1040, 0.1061, 0.0962],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,114][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1696, 0.0950, 0.0894, 0.1277, 0.1280, 0.1122, 0.1776, 0.0654, 0.0351],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,115][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.1102, 0.3661, 0.0449, 0.1738, 0.0655, 0.0662, 0.0527, 0.0577, 0.0629],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,120][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1828, 0.1108, 0.0656, 0.1271, 0.1057, 0.0820, 0.1164, 0.1030, 0.1066],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,124][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.1703, 0.1551, 0.0720, 0.2838, 0.1303, 0.0655, 0.0350, 0.0273, 0.0608],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,125][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.1353, 0.0966, 0.1121, 0.0999, 0.1037, 0.0962, 0.1133, 0.1289, 0.1139],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,126][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ going] are: tensor([2.4925e-03, 2.4041e-03, 7.0798e-03, 1.0334e-01, 1.2492e-02, 1.4914e-01,
        4.0205e-01, 3.2100e-01, 6.8108e-09], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,126][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0084, 0.1328, 0.1313, 0.0967, 0.1165, 0.1065, 0.1119, 0.0989, 0.1167,
        0.0804], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,127][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0698, 0.2458, 0.1050, 0.1009, 0.0834, 0.1112, 0.1016, 0.0545, 0.0475,
        0.0802], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,132][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3598, 0.1149, 0.0705, 0.0375, 0.0601, 0.0442, 0.0961, 0.0831, 0.0647,
        0.0690], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,136][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1295, 0.4713, 0.2400, 0.0208, 0.0149, 0.0527, 0.0215, 0.0097, 0.0200,
        0.0196], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,137][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0872, 0.0954, 0.1011, 0.0986, 0.1000, 0.1001, 0.1050, 0.1036, 0.1051,
        0.1039], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,138][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0126, 0.1340, 0.1432, 0.1319, 0.1205, 0.0821, 0.1028, 0.0900, 0.0982,
        0.0847], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,139][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1859, 0.0700, 0.0828, 0.1068, 0.1143, 0.0932, 0.1998, 0.0690, 0.0338,
        0.0443], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,140][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1389, 0.3927, 0.0390, 0.1261, 0.0418, 0.0269, 0.0452, 0.0375, 0.0496,
        0.1024], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,144][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2065, 0.0979, 0.0608, 0.1119, 0.0981, 0.0678, 0.0934, 0.0862, 0.0844,
        0.0929], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,149][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3322, 0.0823, 0.0439, 0.2298, 0.1169, 0.0246, 0.0207, 0.0175, 0.0374,
        0.0948], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,150][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1292, 0.0849, 0.0982, 0.0878, 0.0904, 0.0844, 0.1001, 0.1128, 0.1021,
        0.1100], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,150][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.6525e-08, 3.9910e-11, 4.9620e-03, 4.7817e-13, 7.3621e-06, 5.0202e-07,
        9.9475e-01, 2.0300e-10, 2.7979e-04, 4.1521e-18], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,151][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0069, 0.1234, 0.1169, 0.0911, 0.1003, 0.0971, 0.1032, 0.0939, 0.0954,
        0.0864, 0.0855], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,152][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0615, 0.2445, 0.0865, 0.0970, 0.0687, 0.1059, 0.0926, 0.0432, 0.0404,
        0.0825, 0.0772], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,157][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3726, 0.0867, 0.0585, 0.0332, 0.0542, 0.0439, 0.0859, 0.0806, 0.0603,
        0.0684, 0.0558], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,161][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.1978, 0.4148, 0.2168, 0.0207, 0.0140, 0.0453, 0.0191, 0.0098, 0.0214,
        0.0236, 0.0168], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,162][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0791, 0.0865, 0.0918, 0.0895, 0.0909, 0.0910, 0.0954, 0.0942, 0.0956,
        0.0944, 0.0917], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,163][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0093, 0.1211, 0.1253, 0.1205, 0.1029, 0.0757, 0.0898, 0.0842, 0.0872,
        0.0862, 0.0979], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,164][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1961, 0.0647, 0.0813, 0.1009, 0.1124, 0.0720, 0.1835, 0.0567, 0.0410,
        0.0481, 0.0433], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,165][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0937, 0.3136, 0.0656, 0.0812, 0.0652, 0.0387, 0.0453, 0.0426, 0.0469,
        0.0701, 0.1370], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,171][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1629, 0.0939, 0.0578, 0.1044, 0.0906, 0.0618, 0.0867, 0.0786, 0.0774,
        0.0818, 0.1041], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,173][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3219, 0.0880, 0.0450, 0.1779, 0.0957, 0.0260, 0.0226, 0.0177, 0.0382,
        0.0742, 0.0928], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,174][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1172, 0.0777, 0.0884, 0.0792, 0.0821, 0.0765, 0.0919, 0.1025, 0.0923,
        0.0989, 0.0934], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,175][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.4905e-06, 1.9164e-06, 4.6214e-05, 8.1332e-07, 9.9485e-07, 1.3218e-02,
        9.8654e-01, 1.0159e-04, 7.7171e-05, 2.2965e-06, 6.5168e-13],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,176][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0079, 0.1134, 0.1188, 0.0933, 0.0911, 0.0816, 0.0763, 0.0792, 0.0863,
        0.0769, 0.0844, 0.0908], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,178][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0588, 0.2042, 0.0837, 0.1023, 0.0722, 0.0940, 0.0743, 0.0491, 0.0390,
        0.0868, 0.0939, 0.0418], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,184][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.2470, 0.0950, 0.0625, 0.0407, 0.0545, 0.0503, 0.0861, 0.0847, 0.0709,
        0.0748, 0.0603, 0.0733], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,186][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.2260, 0.4234, 0.2094, 0.0175, 0.0115, 0.0355, 0.0153, 0.0061, 0.0119,
        0.0160, 0.0147, 0.0128], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,186][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0722, 0.0794, 0.0843, 0.0821, 0.0833, 0.0835, 0.0874, 0.0861, 0.0877,
        0.0863, 0.0838, 0.0838], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,187][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0106, 0.1154, 0.1153, 0.1168, 0.0899, 0.0623, 0.0780, 0.0754, 0.0789,
        0.0801, 0.0883, 0.0891], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,188][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1358, 0.0797, 0.0743, 0.0997, 0.1045, 0.0704, 0.1700, 0.0664, 0.0419,
        0.0526, 0.0491, 0.0556], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,192][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0682, 0.3168, 0.0328, 0.1481, 0.0364, 0.0453, 0.0400, 0.0362, 0.0386,
        0.0729, 0.1242, 0.0403], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,197][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1455, 0.0890, 0.0500, 0.0897, 0.0779, 0.0552, 0.0774, 0.0736, 0.0714,
        0.0771, 0.0985, 0.0949], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,198][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1433, 0.1215, 0.0591, 0.1892, 0.0876, 0.0501, 0.0296, 0.0239, 0.0515,
        0.0868, 0.0957, 0.0616], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,199][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1041, 0.0707, 0.0815, 0.0727, 0.0758, 0.0716, 0.0815, 0.0924, 0.0837,
        0.0907, 0.0848, 0.0904], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,200][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ store] are: tensor([3.1336e-05, 5.8762e-04, 6.7108e-03, 1.6103e-01, 2.0373e-02, 7.6908e-01,
        2.6028e-02, 1.0401e-02, 4.7043e-03, 3.8332e-04, 6.6185e-04, 1.5352e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,202][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0058, 0.1010, 0.1040, 0.0699, 0.0855, 0.0761, 0.0844, 0.0728, 0.0825,
        0.0658, 0.0768, 0.0962, 0.0792], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,208][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0550, 0.1924, 0.0752, 0.0641, 0.0570, 0.0935, 0.0820, 0.0461, 0.0411,
        0.0647, 0.0738, 0.0488, 0.1062], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,210][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3155, 0.0862, 0.0517, 0.0318, 0.0445, 0.0337, 0.0719, 0.0696, 0.0559,
        0.0588, 0.0511, 0.0646, 0.0648], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,211][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0641, 0.5193, 0.2569, 0.0134, 0.0121, 0.0428, 0.0171, 0.0065, 0.0173,
        0.0148, 0.0133, 0.0146, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,212][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0668, 0.0734, 0.0775, 0.0757, 0.0765, 0.0768, 0.0806, 0.0797, 0.0807,
        0.0798, 0.0776, 0.0768, 0.0781], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,212][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0082, 0.1044, 0.1096, 0.0974, 0.0831, 0.0605, 0.0801, 0.0697, 0.0736,
        0.0704, 0.0853, 0.0821, 0.0756], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,215][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2145, 0.0446, 0.0732, 0.0686, 0.1108, 0.0685, 0.1242, 0.0531, 0.0346,
        0.0412, 0.0453, 0.0837, 0.0378], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,222][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0603, 0.3753, 0.0285, 0.1135, 0.0344, 0.0234, 0.0307, 0.0316, 0.0383,
        0.0638, 0.0883, 0.0257, 0.0863], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,223][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1390, 0.0860, 0.0570, 0.0903, 0.0865, 0.0558, 0.0740, 0.0672, 0.0616,
        0.0646, 0.0820, 0.0822, 0.0539], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,224][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.2050, 0.1314, 0.0704, 0.1463, 0.0879, 0.0362, 0.0234, 0.0177, 0.0417,
        0.0587, 0.0726, 0.0793, 0.0294], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,224][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1022, 0.0654, 0.0744, 0.0677, 0.0685, 0.0652, 0.0768, 0.0857, 0.0789,
        0.0863, 0.0794, 0.0841, 0.0653], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,226][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([6.9838e-11, 3.6443e-18, 1.3604e-06, 1.5161e-18, 5.9854e-09, 1.4854e-10,
        6.9147e-06, 2.6788e-10, 5.1506e-07, 1.5451e-17, 5.2321e-10, 9.9999e-01,
        4.7015e-21], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,232][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0070, 0.0945, 0.0928, 0.0750, 0.0776, 0.0708, 0.0712, 0.0739, 0.0692,
        0.0677, 0.0724, 0.0824, 0.0761, 0.0695], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,234][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0487, 0.1562, 0.0652, 0.0799, 0.0451, 0.0860, 0.0759, 0.0378, 0.0353,
        0.0779, 0.0830, 0.0430, 0.1267, 0.0393], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,235][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.2435, 0.1006, 0.0566, 0.0314, 0.0561, 0.0444, 0.0810, 0.0704, 0.0540,
        0.0556, 0.0475, 0.0601, 0.0562, 0.0425], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,236][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.1008, 0.5448, 0.1872, 0.0166, 0.0105, 0.0384, 0.0138, 0.0072, 0.0147,
        0.0189, 0.0154, 0.0173, 0.0106, 0.0039], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,237][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0619, 0.0682, 0.0720, 0.0702, 0.0710, 0.0710, 0.0744, 0.0735, 0.0745,
        0.0735, 0.0715, 0.0711, 0.0719, 0.0754], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,239][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0086, 0.1004, 0.0956, 0.0921, 0.0777, 0.0555, 0.0654, 0.0649, 0.0643,
        0.0659, 0.0814, 0.0876, 0.0754, 0.0652], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,246][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.1135, 0.0713, 0.0608, 0.0861, 0.0585, 0.0807, 0.1506, 0.0528, 0.0364,
        0.0416, 0.0531, 0.1029, 0.0573, 0.0345], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,247][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0414, 0.2698, 0.0343, 0.1018, 0.0445, 0.0411, 0.0408, 0.0390, 0.0342,
        0.0613, 0.1366, 0.0382, 0.0912, 0.0257], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,248][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.1317, 0.0669, 0.0526, 0.0821, 0.0804, 0.0477, 0.0675, 0.0651, 0.0611,
        0.0606, 0.0787, 0.0748, 0.0524, 0.0784], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,249][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.2390, 0.0744, 0.0424, 0.1351, 0.0687, 0.0265, 0.0175, 0.0152, 0.0304,
        0.0619, 0.0675, 0.0433, 0.0382, 0.1400], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,251][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0884, 0.0620, 0.0730, 0.0647, 0.0690, 0.0620, 0.0712, 0.0794, 0.0728,
        0.0812, 0.0728, 0.0789, 0.0600, 0.0646], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,254][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ James] are: tensor([2.8361e-06, 3.4035e-05, 3.7068e-07, 4.2441e-05, 1.4682e-11, 1.0675e-04,
        5.3704e-03, 1.3729e-04, 3.0428e-07, 5.6843e-08, 2.6559e-07, 9.9411e-01,
        1.9657e-04, 2.1411e-10], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,259][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0088, 0.0889, 0.0839, 0.0741, 0.0747, 0.0690, 0.0603, 0.0680, 0.0662,
        0.0669, 0.0692, 0.0755, 0.0726, 0.0662, 0.0559], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,259][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0449, 0.1775, 0.0664, 0.0768, 0.0585, 0.0739, 0.0698, 0.0404, 0.0255,
        0.0638, 0.0727, 0.0360, 0.1129, 0.0455, 0.0353], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,260][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.2536, 0.0956, 0.0567, 0.0310, 0.0489, 0.0401, 0.0744, 0.0678, 0.0509,
        0.0541, 0.0444, 0.0561, 0.0567, 0.0423, 0.0274], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,261][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0250, 0.4896, 0.3554, 0.0168, 0.0132, 0.0225, 0.0103, 0.0039, 0.0094,
        0.0120, 0.0093, 0.0128, 0.0073, 0.0054, 0.0070], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,264][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0578, 0.0633, 0.0668, 0.0651, 0.0659, 0.0660, 0.0691, 0.0682, 0.0691,
        0.0682, 0.0664, 0.0660, 0.0668, 0.0700, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,271][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0166, 0.0908, 0.0936, 0.0903, 0.0778, 0.0515, 0.0653, 0.0589, 0.0609,
        0.0624, 0.0763, 0.0747, 0.0665, 0.0646, 0.0499], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,272][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0943, 0.0614, 0.0590, 0.0876, 0.1053, 0.0628, 0.1097, 0.0464, 0.0393,
        0.0428, 0.0448, 0.0967, 0.0434, 0.0593, 0.0471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,272][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0403, 0.2965, 0.0198, 0.1311, 0.0302, 0.0410, 0.0270, 0.0296, 0.0360,
        0.0665, 0.0935, 0.0353, 0.1009, 0.0177, 0.0346], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,273][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.1051, 0.0707, 0.0436, 0.0824, 0.0718, 0.0484, 0.0672, 0.0611, 0.0601,
        0.0606, 0.0790, 0.0737, 0.0488, 0.0744, 0.0530], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,276][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0828, 0.0938, 0.0481, 0.1612, 0.0755, 0.0442, 0.0216, 0.0185, 0.0396,
        0.0851, 0.0864, 0.0464, 0.0225, 0.1465, 0.0278], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,281][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0804, 0.0592, 0.0696, 0.0615, 0.0658, 0.0591, 0.0673, 0.0761, 0.0674,
        0.0740, 0.0685, 0.0749, 0.0546, 0.0595, 0.0620], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,283][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([2.0613e-05, 3.6070e-06, 4.8875e-02, 1.1520e-04, 1.0577e-03, 1.7678e-05,
        7.4685e-06, 6.9232e-06, 1.5986e-07, 1.3650e-07, 2.5261e-05, 9.3615e-01,
        1.3028e-05, 1.3705e-02, 1.9997e-09], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,284][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0059, 0.0801, 0.0797, 0.0592, 0.0709, 0.0647, 0.0691, 0.0599, 0.0730,
        0.0496, 0.0625, 0.0789, 0.0650, 0.0658, 0.0659, 0.0498],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,285][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0436, 0.1593, 0.0692, 0.0658, 0.0555, 0.0736, 0.0634, 0.0364, 0.0318,
        0.0528, 0.0644, 0.0404, 0.1162, 0.0453, 0.0405, 0.0418],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,286][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2422, 0.0926, 0.0563, 0.0292, 0.0468, 0.0361, 0.0719, 0.0623, 0.0489,
        0.0523, 0.0447, 0.0571, 0.0543, 0.0387, 0.0279, 0.0385],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,291][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1855, 0.3679, 0.1940, 0.0225, 0.0175, 0.0555, 0.0198, 0.0095, 0.0198,
        0.0192, 0.0185, 0.0165, 0.0141, 0.0075, 0.0147, 0.0173],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,295][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0540, 0.0588, 0.0622, 0.0607, 0.0615, 0.0615, 0.0645, 0.0636, 0.0645,
        0.0638, 0.0620, 0.0616, 0.0624, 0.0653, 0.0665, 0.0672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,296][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0080, 0.0834, 0.0904, 0.0822, 0.0761, 0.0519, 0.0655, 0.0563, 0.0634,
        0.0527, 0.0692, 0.0698, 0.0630, 0.0667, 0.0532, 0.0481],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,297][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1156, 0.0494, 0.0601, 0.0752, 0.0870, 0.0682, 0.1513, 0.0535, 0.0257,
        0.0337, 0.0424, 0.0804, 0.0376, 0.0449, 0.0520, 0.0232],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,298][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0703, 0.3089, 0.0296, 0.0994, 0.0314, 0.0212, 0.0346, 0.0278, 0.0353,
        0.0773, 0.0784, 0.0265, 0.0725, 0.0171, 0.0237, 0.0461],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,302][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1224, 0.0656, 0.0408, 0.0717, 0.0650, 0.0407, 0.0566, 0.0543, 0.0510,
        0.0573, 0.0729, 0.0696, 0.0481, 0.0700, 0.0478, 0.0663],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,307][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1552, 0.0501, 0.0276, 0.1496, 0.0734, 0.0198, 0.0133, 0.0123, 0.0246,
        0.0682, 0.0760, 0.0359, 0.0280, 0.1850, 0.0189, 0.0622],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,308][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0814, 0.0548, 0.0631, 0.0566, 0.0578, 0.0536, 0.0635, 0.0714, 0.0647,
        0.0699, 0.0641, 0.0682, 0.0519, 0.0547, 0.0572, 0.0670],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,309][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([5.5333e-11, 1.1397e-14, 4.9658e-06, 1.5823e-16, 9.1712e-09, 2.8393e-10,
        3.8076e-04, 8.4526e-14, 1.5035e-07, 9.6797e-22, 1.6315e-12, 9.9961e-01,
        1.5408e-15, 4.0408e-07, 3.7096e-06, 3.7078e-21], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,310][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0066, 0.0776, 0.0738, 0.0608, 0.0630, 0.0625, 0.0598, 0.0629, 0.0594,
        0.0560, 0.0609, 0.0705, 0.0631, 0.0562, 0.0584, 0.0554, 0.0530],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,312][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0404, 0.1581, 0.0515, 0.0705, 0.0556, 0.0649, 0.0541, 0.0369, 0.0231,
        0.0583, 0.0555, 0.0282, 0.1087, 0.0435, 0.0355, 0.0457, 0.0695],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,319][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.2093, 0.0846, 0.0502, 0.0293, 0.0492, 0.0415, 0.0670, 0.0616, 0.0499,
        0.0542, 0.0446, 0.0531, 0.0519, 0.0394, 0.0297, 0.0404, 0.0440],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,320][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0692, 0.4038, 0.3138, 0.0225, 0.0249, 0.0442, 0.0155, 0.0056, 0.0120,
        0.0139, 0.0126, 0.0129, 0.0089, 0.0073, 0.0088, 0.0126, 0.0113],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,321][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0504, 0.0549, 0.0581, 0.0566, 0.0574, 0.0576, 0.0602, 0.0595, 0.0603,
        0.0596, 0.0580, 0.0577, 0.0583, 0.0610, 0.0621, 0.0628, 0.0655],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,322][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0101, 0.0819, 0.0850, 0.0818, 0.0665, 0.0464, 0.0573, 0.0545, 0.0559,
        0.0597, 0.0639, 0.0625, 0.0616, 0.0558, 0.0484, 0.0547, 0.0539],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,325][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1071, 0.0618, 0.0563, 0.0754, 0.0771, 0.0642, 0.1173, 0.0488, 0.0319,
        0.0374, 0.0393, 0.0680, 0.0490, 0.0446, 0.0611, 0.0254, 0.0354],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,332][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0520, 0.2791, 0.0183, 0.1102, 0.0317, 0.0305, 0.0259, 0.0306, 0.0261,
        0.0633, 0.0798, 0.0284, 0.0858, 0.0164, 0.0243, 0.0355, 0.0621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,333][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0990, 0.0636, 0.0407, 0.0702, 0.0614, 0.0421, 0.0574, 0.0536, 0.0513,
        0.0539, 0.0692, 0.0664, 0.0434, 0.0647, 0.0454, 0.0602, 0.0575],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,333][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1047, 0.0676, 0.0354, 0.1463, 0.0704, 0.0330, 0.0191, 0.0172, 0.0322,
        0.0712, 0.0785, 0.0358, 0.0230, 0.1398, 0.0239, 0.0710, 0.0308],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,334][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0738, 0.0521, 0.0590, 0.0533, 0.0556, 0.0515, 0.0592, 0.0667, 0.0587,
        0.0643, 0.0600, 0.0647, 0.0486, 0.0521, 0.0540, 0.0624, 0.0641],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,336][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ give] are: tensor([1.9972e-04, 7.6279e-05, 1.6754e-01, 6.6195e-04, 2.5208e-03, 1.7700e-02,
        1.3628e-01, 5.9463e-03, 4.6589e-05, 1.7392e-04, 5.2144e-05, 6.3381e-01,
        1.2055e-03, 3.0941e-02, 2.2422e-03, 6.0588e-04, 2.2276e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,342][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0058, 0.0724, 0.0654, 0.0547, 0.0594, 0.0578, 0.0595, 0.0538, 0.0604,
        0.0526, 0.0531, 0.0699, 0.0602, 0.0554, 0.0571, 0.0523, 0.0578, 0.0524],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,344][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0373, 0.1575, 0.0546, 0.0613, 0.0468, 0.0654, 0.0538, 0.0292, 0.0241,
        0.0557, 0.0489, 0.0318, 0.1100, 0.0393, 0.0302, 0.0421, 0.0792, 0.0328],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,345][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1947, 0.0759, 0.0484, 0.0294, 0.0396, 0.0371, 0.0613, 0.0603, 0.0486,
        0.0548, 0.0437, 0.0532, 0.0529, 0.0358, 0.0287, 0.0422, 0.0403, 0.0533],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,346][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2606, 0.2833, 0.1601, 0.0249, 0.0183, 0.0474, 0.0162, 0.0092, 0.0196,
        0.0210, 0.0175, 0.0152, 0.0153, 0.0086, 0.0161, 0.0213, 0.0230, 0.0224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,347][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0471, 0.0515, 0.0545, 0.0531, 0.0540, 0.0541, 0.0565, 0.0560, 0.0565,
        0.0559, 0.0545, 0.0543, 0.0548, 0.0573, 0.0584, 0.0591, 0.0615, 0.0610],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,352][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0067, 0.0744, 0.0785, 0.0723, 0.0625, 0.0473, 0.0538, 0.0520, 0.0528,
        0.0535, 0.0612, 0.0612, 0.0587, 0.0549, 0.0500, 0.0492, 0.0530, 0.0580],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,356][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1113, 0.0484, 0.0496, 0.0701, 0.0709, 0.0606, 0.1332, 0.0459, 0.0293,
        0.0365, 0.0407, 0.0631, 0.0454, 0.0427, 0.0578, 0.0258, 0.0470, 0.0216],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,357][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0408, 0.2791, 0.0313, 0.0846, 0.0324, 0.0303, 0.0302, 0.0346, 0.0327,
        0.0533, 0.1018, 0.0253, 0.0656, 0.0159, 0.0232, 0.0301, 0.0373, 0.0517],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,358][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0914, 0.0564, 0.0353, 0.0589, 0.0517, 0.0359, 0.0511, 0.0508, 0.0483,
        0.0513, 0.0660, 0.0629, 0.0452, 0.0604, 0.0454, 0.0607, 0.0548, 0.0736],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,359][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1231, 0.0590, 0.0307, 0.1285, 0.0678, 0.0239, 0.0168, 0.0153, 0.0285,
        0.0622, 0.0723, 0.0355, 0.0234, 0.1494, 0.0217, 0.0636, 0.0292, 0.0493],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,361][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0740, 0.0487, 0.0551, 0.0497, 0.0509, 0.0482, 0.0564, 0.0640, 0.0564,
        0.0610, 0.0577, 0.0612, 0.0453, 0.0479, 0.0506, 0.0590, 0.0607, 0.0534],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,366][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.4883e-07, 2.9481e-08, 9.5931e-07, 7.0398e-08, 4.2474e-07, 4.1307e-04,
        5.8258e-03, 2.6519e-06, 2.1798e-06, 3.3906e-08, 1.4572e-12, 3.9675e-01,
        1.2342e-07, 8.7118e-06, 1.5238e-03, 1.1505e-07, 5.9547e-01, 5.7934e-14],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,368][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0068, 0.0685, 0.0665, 0.0542, 0.0549, 0.0526, 0.0515, 0.0544, 0.0510,
        0.0510, 0.0537, 0.0621, 0.0563, 0.0502, 0.0483, 0.0508, 0.0502, 0.0554,
        0.0617], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,369][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0360, 0.1399, 0.0626, 0.0611, 0.0465, 0.0574, 0.0476, 0.0303, 0.0252,
        0.0587, 0.0592, 0.0318, 0.0970, 0.0368, 0.0303, 0.0462, 0.0682, 0.0407,
        0.0246], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,370][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.1684, 0.0596, 0.0326, 0.0281, 0.0337, 0.0376, 0.0521, 0.0570, 0.0458,
        0.0531, 0.0406, 0.0451, 0.0520, 0.0333, 0.0283, 0.0429, 0.0390, 0.0440,
        0.1068], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,371][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.2241, 0.3124, 0.1861, 0.0208, 0.0146, 0.0477, 0.0157, 0.0078, 0.0129,
        0.0181, 0.0170, 0.0140, 0.0118, 0.0068, 0.0111, 0.0192, 0.0204, 0.0231,
        0.0165], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,376][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0444, 0.0485, 0.0514, 0.0500, 0.0508, 0.0509, 0.0532, 0.0527, 0.0533,
        0.0526, 0.0512, 0.0511, 0.0515, 0.0540, 0.0550, 0.0557, 0.0580, 0.0574,
        0.0583], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,380][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0114, 0.0745, 0.0721, 0.0717, 0.0561, 0.0396, 0.0504, 0.0496, 0.0468,
        0.0507, 0.0587, 0.0603, 0.0553, 0.0452, 0.0414, 0.0461, 0.0481, 0.0603,
        0.0615], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,381][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0829, 0.0603, 0.0434, 0.0682, 0.0602, 0.0437, 0.1393, 0.0522, 0.0331,
        0.0392, 0.0394, 0.0699, 0.0484, 0.0349, 0.0539, 0.0256, 0.0482, 0.0283,
        0.0288], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,382][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0349, 0.2975, 0.0207, 0.0900, 0.0232, 0.0332, 0.0204, 0.0280, 0.0263,
        0.0628, 0.0890, 0.0295, 0.0818, 0.0128, 0.0174, 0.0351, 0.0346, 0.0508,
        0.0119], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,383][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0767, 0.0506, 0.0366, 0.0527, 0.0491, 0.0361, 0.0491, 0.0479, 0.0478,
        0.0469, 0.0596, 0.0577, 0.0415, 0.0570, 0.0456, 0.0550, 0.0543, 0.0699,
        0.0658], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,387][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0627, 0.0651, 0.0301, 0.1423, 0.0550, 0.0349, 0.0175, 0.0157, 0.0320,
        0.0758, 0.0825, 0.0334, 0.0185, 0.1147, 0.0217, 0.0725, 0.0269, 0.0493,
        0.0493], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,394][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0659, 0.0442, 0.0533, 0.0461, 0.0502, 0.0471, 0.0532, 0.0600, 0.0541,
        0.0577, 0.0534, 0.0588, 0.0426, 0.0471, 0.0501, 0.0555, 0.0581, 0.0495,
        0.0528], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,395][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([2.5523e-06, 1.2268e-06, 1.1842e-05, 9.2495e-05, 2.0082e-03, 4.3967e-05,
        9.0150e-03, 3.9921e-01, 1.3118e-05, 1.3870e-05, 4.0750e-04, 2.9235e-01,
        8.9317e-06, 1.3889e-02, 7.1714e-02, 4.4926e-05, 2.1087e-01, 3.0045e-04,
        2.0351e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,396][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0047, 0.0640, 0.0622, 0.0477, 0.0552, 0.0514, 0.0542, 0.0488, 0.0562,
        0.0400, 0.0502, 0.0620, 0.0522, 0.0512, 0.0518, 0.0401, 0.0510, 0.0515,
        0.0641, 0.0415], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,397][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0361, 0.1341, 0.0584, 0.0567, 0.0490, 0.0599, 0.0514, 0.0309, 0.0272,
        0.0453, 0.0527, 0.0330, 0.0952, 0.0392, 0.0332, 0.0359, 0.0657, 0.0404,
        0.0274, 0.0283], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,402][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1710, 0.0588, 0.0362, 0.0244, 0.0307, 0.0311, 0.0498, 0.0511, 0.0419,
        0.0459, 0.0361, 0.0418, 0.0448, 0.0284, 0.0252, 0.0361, 0.0340, 0.0449,
        0.0969, 0.0710], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,406][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3395, 0.2144, 0.1189, 0.0188, 0.0150, 0.0542, 0.0171, 0.0087, 0.0181,
        0.0158, 0.0182, 0.0146, 0.0126, 0.0072, 0.0138, 0.0160, 0.0206, 0.0242,
        0.0206, 0.0316], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,407][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0422, 0.0459, 0.0485, 0.0473, 0.0480, 0.0481, 0.0504, 0.0498, 0.0504,
        0.0499, 0.0485, 0.0482, 0.0489, 0.0510, 0.0520, 0.0526, 0.0546, 0.0539,
        0.0546, 0.0553], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,408][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0065, 0.0668, 0.0725, 0.0654, 0.0609, 0.0412, 0.0522, 0.0449, 0.0500,
        0.0416, 0.0557, 0.0566, 0.0508, 0.0530, 0.0428, 0.0380, 0.0467, 0.0565,
        0.0600, 0.0379], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,409][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0881, 0.0427, 0.0510, 0.0632, 0.0727, 0.0617, 0.1366, 0.0482, 0.0227,
        0.0292, 0.0372, 0.0698, 0.0330, 0.0381, 0.0447, 0.0201, 0.0514, 0.0268,
        0.0466, 0.0160], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,414][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0567, 0.2807, 0.0265, 0.0907, 0.0268, 0.0182, 0.0280, 0.0232, 0.0290,
        0.0647, 0.0679, 0.0229, 0.0635, 0.0140, 0.0184, 0.0381, 0.0461, 0.0416,
        0.0123, 0.0308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,418][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0772, 0.0493, 0.0314, 0.0509, 0.0469, 0.0334, 0.0454, 0.0446, 0.0431,
        0.0460, 0.0583, 0.0546, 0.0396, 0.0529, 0.0399, 0.0516, 0.0488, 0.0638,
        0.0605, 0.0619], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,419][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0967, 0.0497, 0.0245, 0.1328, 0.0588, 0.0224, 0.0137, 0.0128, 0.0248,
        0.0621, 0.0686, 0.0311, 0.0196, 0.1381, 0.0181, 0.0631, 0.0253, 0.0469,
        0.0406, 0.0503], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,420][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0643, 0.0437, 0.0507, 0.0453, 0.0467, 0.0437, 0.0506, 0.0567, 0.0514,
        0.0553, 0.0513, 0.0549, 0.0410, 0.0439, 0.0462, 0.0534, 0.0541, 0.0477,
        0.0493, 0.0498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,421][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9861e-10, 3.7662e-15, 4.3860e-06, 8.0261e-17, 7.9248e-09, 1.6265e-10,
        2.0100e-04, 7.8761e-14, 8.7124e-08, 3.4318e-22, 2.2488e-12, 8.8381e-01,
        8.7214e-16, 3.6700e-07, 2.3024e-06, 1.3859e-21, 5.8030e-07, 5.0455e-12,
        1.1598e-01, 9.0285e-20], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,468][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:51,470][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,471][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,471][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,472][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,473][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,473][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,474][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,475][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,475][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,476][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,477][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,477][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:51,478][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0747, 0.9253], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,479][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6511, 0.3489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,479][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6897, 0.3103], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,480][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2824, 0.7176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,481][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3868, 0.6132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,482][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5716, 0.4284], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,483][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1547, 0.8453], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,484][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3158, 0.6842], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,484][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1665, 0.8335], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,485][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0746, 0.9254], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,486][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1298, 0.8702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,486][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9989e-01, 1.1123e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:51,487][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0012, 0.9693, 0.0296], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,488][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.4661, 0.4890, 0.0449], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,488][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.5431, 0.1941, 0.2628], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,489][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1413, 0.4440, 0.4147], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,491][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0587, 0.0343, 0.9070], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,492][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0232, 0.9081, 0.0686], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,493][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0777, 0.4938, 0.4286], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,494][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.1856, 0.4025, 0.4119], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,494][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0853, 0.4822, 0.4325], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,497][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0423, 0.5372, 0.4204], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,504][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0653, 0.4032, 0.5315], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,504][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([2.3135e-07, 1.0000e+00, 6.8270e-08], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:51,505][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([7.6107e-05, 9.3556e-01, 6.4212e-02, 1.5561e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,506][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2955, 0.4178, 0.1133, 0.1734], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,506][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4686, 0.1710, 0.1841, 0.1763], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,509][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0742, 0.3011, 0.3798, 0.2449], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,516][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2903, 0.2724, 0.1130, 0.3243], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,516][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0033, 0.9131, 0.0820, 0.0016], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,517][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0469, 0.3125, 0.3877, 0.2529], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,518][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1373, 0.2803, 0.2854, 0.2971], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,519][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0667, 0.3337, 0.2971, 0.3025], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,521][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0313, 0.4036, 0.3198, 0.2453], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,528][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0549, 0.3399, 0.3436, 0.2616], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,528][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([3.1662e-12, 9.9973e-01, 2.7413e-04, 1.4634e-13], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:51,529][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([9.2861e-06, 9.3345e-01, 6.6323e-02, 9.5007e-05, 1.2422e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,530][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.3672, 0.3810, 0.0490, 0.1698, 0.0330], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,531][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.4286, 0.1474, 0.1581, 0.1609, 0.1050], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,533][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0562, 0.2533, 0.2873, 0.2298, 0.1734], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,540][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.2216, 0.0828, 0.6255, 0.0483, 0.0218], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,540][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([4.6594e-04, 9.3824e-01, 5.9923e-02, 9.4483e-04, 4.2145e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,541][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0353, 0.2594, 0.2760, 0.2192, 0.2101], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,542][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.1005, 0.2126, 0.2200, 0.2291, 0.2378], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,543][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0457, 0.2627, 0.2354, 0.2396, 0.2166], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,545][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0222, 0.3196, 0.2950, 0.2031, 0.1601], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,552][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0397, 0.2646, 0.2830, 0.1824, 0.2303], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,552][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([3.2088e-17, 1.0000e+00, 1.9785e-06, 5.2363e-13, 1.6554e-15],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:51,553][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([1.7487e-03, 9.1778e-01, 7.8257e-02, 4.0581e-04, 4.1005e-04, 1.3982e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,554][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.2546, 0.3043, 0.0776, 0.1568, 0.1073, 0.0994], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,555][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.3727, 0.1213, 0.1404, 0.1441, 0.0859, 0.1356], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,557][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0684, 0.2102, 0.2309, 0.1937, 0.1598, 0.1370], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,564][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0489, 0.0580, 0.0453, 0.0135, 0.0021, 0.8322], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,565][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0154, 0.8829, 0.0940, 0.0036, 0.0017, 0.0024], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,565][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.0334, 0.2094, 0.2275, 0.1746, 0.2161, 0.1389], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,566][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0902, 0.1706, 0.1766, 0.1832, 0.1904, 0.1889], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,567][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0396, 0.2160, 0.1929, 0.1966, 0.1768, 0.1782], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,569][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0155, 0.2446, 0.2283, 0.1749, 0.1288, 0.2079], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,577][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0312, 0.2208, 0.2617, 0.1522, 0.1865, 0.1475], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,577][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([7.9130e-11, 9.9885e-01, 1.1515e-03, 2.0733e-11, 2.1218e-10, 9.2442e-10],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:51,578][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([2.1855e-04, 9.5093e-01, 4.6122e-02, 4.5828e-04, 2.8065e-04, 1.8004e-03,
        1.8934e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,579][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.2145, 0.2732, 0.0776, 0.1332, 0.0625, 0.1490, 0.0900],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,580][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.3437, 0.1079, 0.1410, 0.1301, 0.0821, 0.1378, 0.0574],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,584][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0556, 0.1832, 0.2235, 0.1587, 0.1358, 0.1330, 0.1101],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,590][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.2947, 0.1307, 0.1529, 0.0928, 0.0152, 0.2458, 0.0679],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,590][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([6.0543e-03, 8.7790e-01, 1.1004e-01, 2.0645e-03, 1.3436e-03, 1.9713e-03,
        6.2876e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,591][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.0309, 0.1758, 0.1929, 0.1501, 0.1773, 0.1457, 0.1271],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,592][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0716, 0.1478, 0.1512, 0.1569, 0.1625, 0.1613, 0.1488],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,593][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0328, 0.1838, 0.1637, 0.1674, 0.1508, 0.1516, 0.1500],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,597][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0141, 0.2013, 0.1967, 0.1540, 0.1266, 0.1963, 0.1110],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,602][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0241, 0.1857, 0.1959, 0.1526, 0.1441, 0.1204, 0.1773],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,603][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([3.1443e-12, 9.9982e-01, 1.8242e-04, 5.7332e-12, 2.7347e-11, 8.9721e-08,
        4.0053e-12], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:51,604][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([3.0411e-05, 9.1443e-01, 8.1439e-02, 6.3352e-04, 6.3321e-04, 2.0240e-03,
        7.7525e-04, 3.1088e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,605][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0901, 0.2406, 0.0548, 0.1301, 0.0563, 0.1019, 0.2883, 0.0380],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,606][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.3132, 0.0969, 0.1137, 0.1202, 0.0871, 0.1341, 0.0561, 0.0788],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,610][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0538, 0.1587, 0.1864, 0.1367, 0.1196, 0.1149, 0.1126, 0.1173],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,615][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.2663, 0.2366, 0.0620, 0.1969, 0.0066, 0.1428, 0.0322, 0.0566],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,616][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([1.1800e-03, 8.6916e-01, 1.1828e-01, 3.8455e-03, 2.1128e-03, 3.3920e-03,
        1.9199e-03, 1.1662e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,617][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0285, 0.1516, 0.1707, 0.1347, 0.1564, 0.1349, 0.1309, 0.0923],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,618][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0632, 0.1267, 0.1308, 0.1359, 0.1409, 0.1397, 0.1270, 0.1356],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,618][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0280, 0.1604, 0.1425, 0.1462, 0.1309, 0.1316, 0.1301, 0.1303],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,623][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0124, 0.1865, 0.1724, 0.1234, 0.1116, 0.1746, 0.1049, 0.1143],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,628][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0233, 0.1650, 0.1714, 0.1186, 0.1269, 0.1042, 0.1480, 0.1424],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,629][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([4.4554e-17, 9.9930e-01, 7.0438e-04, 1.7845e-12, 2.6041e-10, 1.1001e-08,
        1.8829e-09, 3.9108e-16], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:51,630][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([7.6954e-05, 9.2226e-01, 7.4799e-02, 4.4359e-04, 3.7410e-04, 1.6622e-03,
        2.4339e-04, 8.3393e-05, 5.8278e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,631][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.1656, 0.2464, 0.0251, 0.1391, 0.0417, 0.1005, 0.1746, 0.0874, 0.0196],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,631][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.2430, 0.0954, 0.1264, 0.1099, 0.0647, 0.1262, 0.0518, 0.0963, 0.0864],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,636][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0553, 0.1492, 0.1609, 0.1423, 0.1035, 0.1075, 0.1017, 0.1159, 0.0637],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,641][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.1669, 0.2608, 0.0336, 0.0785, 0.0160, 0.1073, 0.0027, 0.0069, 0.3272],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,642][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([2.4051e-03, 9.2355e-01, 6.7866e-02, 1.9035e-03, 7.6831e-04, 2.2861e-03,
        7.8698e-04, 1.4146e-04, 2.9010e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,643][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0263, 0.1355, 0.1562, 0.1213, 0.1381, 0.1256, 0.1196, 0.0903, 0.0872],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,643][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0543, 0.1131, 0.1165, 0.1199, 0.1247, 0.1231, 0.1126, 0.1195, 0.1164],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,644][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0248, 0.1415, 0.1262, 0.1291, 0.1159, 0.1162, 0.1150, 0.1152, 0.1161],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,649][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0131, 0.1625, 0.1356, 0.1142, 0.1049, 0.1633, 0.1027, 0.1232, 0.0804],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,654][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0208, 0.1382, 0.1479, 0.1131, 0.1144, 0.0884, 0.1191, 0.1213, 0.1368],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,655][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([2.9180e-15, 9.9977e-01, 2.3041e-04, 2.4751e-12, 1.3000e-11, 1.1268e-08,
        3.4888e-11, 1.7848e-14, 4.9646e-13], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:51,655][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2452e-03, 9.2599e-01, 6.8546e-02, 6.1057e-04, 3.4927e-04, 1.7700e-03,
        6.0630e-04, 1.0811e-04, 4.4016e-04, 3.3517e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,656][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1205, 0.1821, 0.0694, 0.0892, 0.0890, 0.1062, 0.2122, 0.0488, 0.0387,
        0.0440], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,657][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2617, 0.0898, 0.1024, 0.1008, 0.0711, 0.1044, 0.0478, 0.0662, 0.0887,
        0.0670], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,662][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0368, 0.1291, 0.1534, 0.1117, 0.1004, 0.0985, 0.0940, 0.1048, 0.0662,
        0.1052], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,667][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2831, 0.2121, 0.1359, 0.1642, 0.0049, 0.1102, 0.0033, 0.0052, 0.0600,
        0.0209], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,667][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.4274e-02, 8.4979e-01, 1.1202e-01, 3.7486e-03, 2.0515e-03, 2.8917e-03,
        1.9319e-03, 2.1040e-04, 1.4497e-03, 1.6363e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,668][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0215, 0.1200, 0.1459, 0.1081, 0.1262, 0.1095, 0.1139, 0.0863, 0.0843,
        0.0843], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,669][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0501, 0.1007, 0.1030, 0.1069, 0.1107, 0.1098, 0.1011, 0.1072, 0.1039,
        0.1067], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,670][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0249, 0.1255, 0.1116, 0.1144, 0.1028, 0.1037, 0.1026, 0.1030, 0.1032,
        0.1082], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,675][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0122, 0.1490, 0.1405, 0.1015, 0.0930, 0.1363, 0.0952, 0.1059, 0.0766,
        0.0895], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,679][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0200, 0.1299, 0.1400, 0.0981, 0.1034, 0.0738, 0.1097, 0.1153, 0.1077,
        0.1022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,680][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.8708e-11, 9.9951e-01, 4.9159e-04, 2.5025e-12, 1.7555e-10, 1.5358e-07,
        4.5327e-08, 9.9585e-13, 5.2166e-08, 3.1739e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:51,681][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.2610e-03, 9.2898e-01, 5.9972e-02, 9.6933e-04, 3.7751e-04, 2.9697e-03,
        1.0254e-03, 3.9227e-04, 5.8426e-04, 1.6109e-03, 1.8550e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,682][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0953, 0.2121, 0.0441, 0.0940, 0.0652, 0.1215, 0.2221, 0.0346, 0.0386,
        0.0549, 0.0176], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,683][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1974, 0.0736, 0.1050, 0.0841, 0.0663, 0.1046, 0.0442, 0.0566, 0.0773,
        0.0563, 0.1346], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,688][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0249, 0.1224, 0.1440, 0.1084, 0.0920, 0.0898, 0.0802, 0.0941, 0.0594,
        0.1044, 0.0805], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,692][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1947, 0.1144, 0.1895, 0.0784, 0.0120, 0.2520, 0.0225, 0.0411, 0.0084,
        0.0073, 0.0797], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,693][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.5765e-02, 8.3784e-01, 1.0170e-01, 4.0928e-03, 2.4003e-03, 3.3757e-03,
        1.8329e-03, 4.8083e-04, 3.4974e-03, 5.2129e-03, 3.8009e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,694][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0186, 0.1092, 0.1368, 0.0986, 0.1190, 0.0951, 0.1021, 0.0762, 0.0818,
        0.0802, 0.0824], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,695][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0437, 0.0914, 0.0934, 0.0970, 0.1005, 0.0998, 0.0914, 0.0973, 0.0942,
        0.0969, 0.0943], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,696][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0221, 0.1142, 0.1009, 0.1035, 0.0928, 0.0937, 0.0927, 0.0934, 0.0936,
        0.0983, 0.0947], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,701][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0094, 0.1379, 0.1334, 0.0924, 0.0842, 0.1292, 0.0856, 0.1018, 0.0656,
        0.0818, 0.0785], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,705][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0171, 0.1172, 0.1273, 0.0890, 0.0927, 0.0760, 0.1012, 0.1035, 0.0989,
        0.0895, 0.0876], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,706][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.2353e-12, 9.9985e-01, 1.5085e-04, 1.8005e-11, 7.6778e-11, 2.8056e-07,
        8.4484e-09, 8.5558e-12, 5.0413e-09, 1.6001e-07, 4.8678e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:51,707][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([1.1456e-03, 8.2919e-01, 1.6345e-01, 4.1016e-04, 2.9237e-04, 1.4801e-03,
        3.1138e-04, 5.4899e-05, 5.1998e-04, 8.3862e-04, 9.7051e-04, 1.3396e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,708][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.1051, 0.1644, 0.0315, 0.1249, 0.0371, 0.1106, 0.1775, 0.0602, 0.0252,
        0.1103, 0.0404, 0.0129], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,708][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.2380, 0.0716, 0.1093, 0.0777, 0.0591, 0.1031, 0.0301, 0.0516, 0.0483,
        0.0420, 0.1300, 0.0392], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,713][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0387, 0.1063, 0.1396, 0.0981, 0.0833, 0.0785, 0.0746, 0.0878, 0.0498,
        0.0927, 0.0747, 0.0758], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,718][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([9.6245e-02, 1.2267e-01, 3.5924e-03, 7.8268e-02, 2.1979e-04, 2.0519e-02,
        3.0892e-04, 1.6856e-03, 1.0309e-02, 1.8361e-03, 3.4875e-02, 6.2947e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,719][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.2842e-02, 8.4036e-01, 1.1474e-01, 4.4125e-03, 1.3714e-03, 3.4964e-03,
        1.3312e-03, 3.0583e-04, 1.6606e-03, 3.0684e-03, 3.1752e-03, 3.2359e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,720][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0181, 0.1036, 0.1196, 0.0901, 0.1068, 0.0882, 0.0958, 0.0736, 0.0736,
        0.0763, 0.0783, 0.0760], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,720][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0389, 0.0847, 0.0865, 0.0898, 0.0929, 0.0923, 0.0848, 0.0896, 0.0869,
        0.0889, 0.0863, 0.0784], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,721][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0193, 0.1035, 0.0923, 0.0946, 0.0851, 0.0854, 0.0845, 0.0852, 0.0857,
        0.0895, 0.0859, 0.0889], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,726][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0089, 0.1268, 0.1217, 0.0882, 0.0782, 0.1218, 0.0809, 0.0945, 0.0642,
        0.0773, 0.0784, 0.0590], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,731][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0119, 0.1029, 0.1039, 0.0753, 0.0866, 0.0621, 0.0902, 0.0963, 0.0882,
        0.0906, 0.0791, 0.1128], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,732][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.1132e-09, 9.9973e-01, 2.7261e-04, 1.7377e-10, 9.9934e-10, 2.5544e-07,
        1.3519e-08, 1.8164e-12, 7.9824e-08, 7.6542e-08, 5.5070e-07, 4.6324e-10],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:51,733][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([6.3549e-05, 9.5061e-01, 4.1094e-02, 3.8141e-04, 1.7493e-04, 1.4691e-03,
        6.3463e-04, 1.3282e-04, 3.2801e-04, 9.5819e-04, 1.3738e-03, 2.6723e-03,
        1.0372e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,733][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0879, 0.1606, 0.0557, 0.0690, 0.0643, 0.1308, 0.1917, 0.0602, 0.0465,
        0.0548, 0.0301, 0.0287, 0.0198], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,734][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1978, 0.0697, 0.0896, 0.0767, 0.0572, 0.0883, 0.0343, 0.0538, 0.0654,
        0.0500, 0.1175, 0.0390, 0.0608], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,739][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0242, 0.0961, 0.1272, 0.0858, 0.0845, 0.0742, 0.0708, 0.0782, 0.0538,
        0.0838, 0.0728, 0.0775, 0.0711], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,744][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1508, 0.1481, 0.1311, 0.2064, 0.0238, 0.0801, 0.0201, 0.0199, 0.0175,
        0.0078, 0.0256, 0.0887, 0.0799], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,745][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([2.3096e-03, 9.0223e-01, 7.5930e-02, 2.9094e-03, 9.9693e-04, 2.2247e-03,
        1.1573e-03, 2.6985e-04, 7.4849e-04, 2.3728e-03, 3.5121e-03, 4.1245e-03,
        1.2149e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,745][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0152, 0.0903, 0.1135, 0.0793, 0.1014, 0.0818, 0.0813, 0.0658, 0.0683,
        0.0702, 0.0742, 0.0836, 0.0751], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,746][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0387, 0.0773, 0.0794, 0.0817, 0.0853, 0.0846, 0.0778, 0.0824, 0.0801,
        0.0811, 0.0789, 0.0726, 0.0801], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,747][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0195, 0.0949, 0.0839, 0.0861, 0.0777, 0.0786, 0.0780, 0.0785, 0.0786,
        0.0822, 0.0793, 0.0812, 0.0815], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,752][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0092, 0.1257, 0.1126, 0.0782, 0.0642, 0.1079, 0.0754, 0.0939, 0.0646,
        0.0697, 0.0745, 0.0569, 0.0673], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,757][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0163, 0.0995, 0.1046, 0.0713, 0.0765, 0.0545, 0.0837, 0.0801, 0.0823,
        0.0778, 0.0659, 0.0810, 0.1064], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,757][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.5593e-14, 9.9910e-01, 8.9694e-04, 3.3103e-12, 1.9644e-10, 8.0295e-08,
        4.6913e-08, 4.0177e-12, 1.3932e-08, 5.6629e-08, 2.2704e-07, 8.8934e-07,
        4.1174e-13], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:51,758][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([7.1654e-05, 8.8626e-01, 1.0721e-01, 3.5586e-04, 3.0123e-04, 1.2482e-03,
        5.9741e-04, 8.1897e-05, 3.1259e-04, 4.6440e-04, 8.9693e-04, 2.0075e-03,
        1.1038e-04, 7.5941e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,759][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.1320, 0.1982, 0.0286, 0.0961, 0.0208, 0.1144, 0.1727, 0.0411, 0.0274,
        0.0620, 0.0333, 0.0303, 0.0358, 0.0075], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,760][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1906, 0.0630, 0.0787, 0.0717, 0.0492, 0.0818, 0.0357, 0.0624, 0.0540,
        0.0421, 0.1119, 0.0501, 0.0627, 0.0460], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,763][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0214, 0.0985, 0.1152, 0.0910, 0.0723, 0.0692, 0.0564, 0.0761, 0.0420,
        0.0863, 0.0629, 0.0693, 0.0679, 0.0715], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,766][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.1678, 0.0650, 0.4996, 0.0349, 0.0165, 0.0404, 0.0066, 0.0151, 0.0048,
        0.0118, 0.0263, 0.0114, 0.0698, 0.0300], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,768][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([2.3856e-03, 9.0528e-01, 7.6749e-02, 3.0830e-03, 1.0324e-03, 1.5213e-03,
        8.1335e-04, 1.5837e-04, 1.1214e-03, 1.2820e-03, 2.3439e-03, 2.6086e-03,
        1.3180e-03, 3.0133e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,771][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0142, 0.0905, 0.1033, 0.0793, 0.0783, 0.0795, 0.0816, 0.0591, 0.0626,
        0.0629, 0.0690, 0.0843, 0.0757, 0.0598], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,772][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0350, 0.0706, 0.0731, 0.0754, 0.0787, 0.0777, 0.0714, 0.0755, 0.0737,
        0.0750, 0.0730, 0.0665, 0.0740, 0.0804], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,773][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0170, 0.0873, 0.0778, 0.0797, 0.0721, 0.0723, 0.0716, 0.0722, 0.0723,
        0.0758, 0.0728, 0.0749, 0.0750, 0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,774][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0080, 0.1205, 0.1187, 0.0794, 0.0647, 0.1135, 0.0649, 0.0753, 0.0488,
        0.0663, 0.0732, 0.0533, 0.0693, 0.0442], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,774][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0118, 0.0842, 0.0908, 0.0627, 0.0731, 0.0556, 0.0818, 0.0855, 0.0784,
        0.0664, 0.0647, 0.0759, 0.1033, 0.0659], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,776][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([6.9284e-14, 9.9999e-01, 5.9866e-06, 2.0644e-11, 1.5775e-13, 3.0115e-08,
        6.2878e-10, 5.5001e-13, 4.4388e-10, 2.9051e-09, 1.0519e-08, 1.5403e-09,
        4.1154e-13, 2.6560e-15], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:51,778][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([9.5282e-04, 9.0161e-01, 8.9509e-02, 5.6725e-04, 4.7028e-04, 1.7738e-03,
        4.7588e-04, 1.0197e-04, 2.3243e-04, 6.9091e-04, 1.7728e-03, 1.5041e-03,
        1.3738e-04, 1.0627e-04, 9.5933e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,783][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0853, 0.1789, 0.0291, 0.1017, 0.0429, 0.0916, 0.1575, 0.0610, 0.0158,
        0.0734, 0.0448, 0.0240, 0.0380, 0.0161, 0.0399], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,787][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.1977, 0.0620, 0.0623, 0.0738, 0.0423, 0.0722, 0.0405, 0.0497, 0.0626,
        0.0449, 0.1268, 0.0383, 0.0612, 0.0393, 0.0265], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,788][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0341, 0.0838, 0.1068, 0.0820, 0.0748, 0.0617, 0.0554, 0.0647, 0.0418,
        0.0746, 0.0625, 0.0634, 0.0671, 0.0782, 0.0492], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,789][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.1265, 0.1718, 0.0280, 0.0371, 0.0067, 0.2647, 0.0083, 0.0137, 0.0050,
        0.0023, 0.0194, 0.0420, 0.0962, 0.0130, 0.1655], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,790][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([5.2737e-03, 8.2550e-01, 1.4252e-01, 4.0632e-03, 2.5921e-03, 2.7241e-03,
        1.5978e-03, 1.4255e-04, 7.0051e-04, 1.7016e-03, 4.5736e-03, 5.6912e-03,
        1.3876e-03, 9.8919e-04, 5.4255e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,792][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0194, 0.0791, 0.0931, 0.0723, 0.0884, 0.0697, 0.0716, 0.0550, 0.0623,
        0.0596, 0.0627, 0.0788, 0.0655, 0.0697, 0.0528], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,798][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0316, 0.0662, 0.0687, 0.0704, 0.0738, 0.0728, 0.0666, 0.0706, 0.0688,
        0.0698, 0.0680, 0.0619, 0.0682, 0.0747, 0.0678], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,800][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0156, 0.0811, 0.0723, 0.0740, 0.0668, 0.0670, 0.0663, 0.0667, 0.0671,
        0.0700, 0.0673, 0.0696, 0.0691, 0.0736, 0.0733], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,801][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0093, 0.1069, 0.1001, 0.0775, 0.0662, 0.0969, 0.0569, 0.0761, 0.0506,
        0.0727, 0.0749, 0.0501, 0.0666, 0.0488, 0.0463], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,802][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0118, 0.0798, 0.0835, 0.0628, 0.0626, 0.0579, 0.0703, 0.0755, 0.0725,
        0.0686, 0.0591, 0.0757, 0.0915, 0.0564, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,803][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([1.5436e-10, 9.9489e-01, 5.1107e-03, 4.4248e-11, 2.4356e-09, 3.5854e-08,
        6.8927e-10, 1.3644e-13, 4.4305e-10, 3.9548e-09, 1.6773e-08, 3.7018e-08,
        2.6198e-13, 1.4205e-10, 5.7455e-12], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:51,805][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.2204e-03, 8.9190e-01, 9.1383e-02, 8.6832e-04, 6.0721e-04, 2.4919e-03,
        8.1757e-04, 1.6676e-04, 6.6768e-04, 5.0977e-04, 2.5577e-03, 2.8089e-03,
        2.0266e-04, 2.3529e-04, 6.3798e-04, 9.2133e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,811][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0759, 0.1450, 0.0586, 0.0747, 0.0743, 0.0920, 0.1787, 0.0419, 0.0363,
        0.0368, 0.0278, 0.0263, 0.0274, 0.0254, 0.0592, 0.0198],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,813][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1836, 0.0608, 0.0721, 0.0683, 0.0481, 0.0725, 0.0357, 0.0436, 0.0620,
        0.0438, 0.1087, 0.0334, 0.0545, 0.0433, 0.0295, 0.0403],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,814][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0205, 0.0796, 0.0985, 0.0689, 0.0649, 0.0624, 0.0592, 0.0649, 0.0421,
        0.0643, 0.0591, 0.0643, 0.0607, 0.0710, 0.0547, 0.0651],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,815][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2184, 0.1632, 0.1095, 0.1234, 0.0053, 0.0739, 0.0032, 0.0048, 0.0426,
        0.0154, 0.0424, 0.0548, 0.0739, 0.0083, 0.0450, 0.0159],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,816][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.1026e-02, 7.8953e-01, 1.3109e-01, 6.5030e-03, 2.9653e-03, 3.0795e-03,
        2.3402e-03, 2.7445e-04, 1.5530e-03, 1.6528e-03, 5.0452e-03, 6.7902e-03,
        2.9166e-03, 1.3738e-03, 1.3753e-03, 2.4816e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,818][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0144, 0.0757, 0.0946, 0.0684, 0.0822, 0.0713, 0.0743, 0.0559, 0.0536,
        0.0537, 0.0606, 0.0706, 0.0610, 0.0637, 0.0521, 0.0480],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,825][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0317, 0.0623, 0.0636, 0.0657, 0.0683, 0.0676, 0.0621, 0.0659, 0.0641,
        0.0655, 0.0636, 0.0581, 0.0640, 0.0690, 0.0628, 0.0658],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,826][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0164, 0.0745, 0.0666, 0.0681, 0.0617, 0.0621, 0.0612, 0.0617, 0.0620,
        0.0646, 0.0626, 0.0642, 0.0639, 0.0675, 0.0673, 0.0757],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,827][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0081, 0.0964, 0.0958, 0.0684, 0.0625, 0.0918, 0.0630, 0.0709, 0.0531,
        0.0601, 0.0634, 0.0505, 0.0646, 0.0465, 0.0517, 0.0532],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,828][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0132, 0.0822, 0.0837, 0.0607, 0.0616, 0.0440, 0.0687, 0.0703, 0.0671,
        0.0644, 0.0590, 0.0647, 0.0850, 0.0555, 0.0574, 0.0623],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,829][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.6298e-08, 9.9782e-01, 2.1749e-03, 9.8996e-12, 1.7120e-09, 4.1466e-07,
        1.5794e-07, 2.7053e-12, 1.9047e-07, 4.9014e-08, 1.2769e-07, 5.8863e-07,
        2.6887e-12, 7.6494e-10, 1.1687e-08, 6.0869e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:51,833][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.0160e-03, 9.0287e-01, 8.0910e-02, 1.0727e-03, 5.7104e-04, 2.2709e-03,
        5.5894e-04, 2.7230e-04, 2.1231e-04, 1.0914e-03, 2.5412e-03, 2.6039e-03,
        1.4970e-04, 1.1576e-04, 2.3561e-04, 1.4059e-03, 1.1035e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,838][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0839, 0.1554, 0.0266, 0.0928, 0.0575, 0.0853, 0.1218, 0.0617, 0.0141,
        0.0816, 0.0286, 0.0127, 0.0344, 0.0199, 0.0499, 0.0483, 0.0255],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,839][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1533, 0.0619, 0.0569, 0.0611, 0.0479, 0.0635, 0.0434, 0.0485, 0.0493,
        0.0464, 0.1092, 0.0336, 0.0553, 0.0457, 0.0334, 0.0444, 0.0460],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,840][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0162, 0.0743, 0.1004, 0.0671, 0.0629, 0.0599, 0.0494, 0.0584, 0.0382,
        0.0675, 0.0538, 0.0566, 0.0632, 0.0703, 0.0449, 0.0696, 0.0474],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,841][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.1030, 0.0919, 0.0994, 0.0674, 0.0086, 0.0696, 0.0021, 0.0048, 0.0344,
        0.0350, 0.0802, 0.0784, 0.0378, 0.0126, 0.0668, 0.0408, 0.1672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,842][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.3018e-02, 7.8446e-01, 1.7246e-01, 5.8186e-03, 3.3174e-03, 2.2042e-03,
        1.3861e-03, 3.0798e-04, 8.7904e-04, 2.4082e-03, 2.6425e-03, 3.0467e-03,
        1.7710e-03, 1.2181e-03, 6.3555e-04, 3.2830e-03, 1.1382e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,848][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0139, 0.0743, 0.0863, 0.0652, 0.0760, 0.0691, 0.0667, 0.0515, 0.0548,
        0.0526, 0.0578, 0.0651, 0.0621, 0.0594, 0.0540, 0.0474, 0.0438],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,851][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0291, 0.0590, 0.0604, 0.0620, 0.0643, 0.0637, 0.0585, 0.0621, 0.0606,
        0.0616, 0.0600, 0.0548, 0.0600, 0.0650, 0.0592, 0.0619, 0.0576],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,852][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0154, 0.0691, 0.0617, 0.0631, 0.0572, 0.0575, 0.0568, 0.0574, 0.0575,
        0.0600, 0.0580, 0.0596, 0.0590, 0.0627, 0.0623, 0.0702, 0.0725],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,853][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0081, 0.0938, 0.0779, 0.0650, 0.0533, 0.0828, 0.0651, 0.0735, 0.0575,
        0.0630, 0.0599, 0.0497, 0.0549, 0.0402, 0.0567, 0.0553, 0.0433],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,854][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0105, 0.0683, 0.0718, 0.0558, 0.0557, 0.0433, 0.0682, 0.0723, 0.0705,
        0.0602, 0.0565, 0.0589, 0.0812, 0.0497, 0.0562, 0.0572, 0.0638],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,855][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([6.1422e-12, 9.7994e-01, 2.0056e-02, 3.1571e-11, 3.6011e-09, 9.3507e-08,
        8.3390e-10, 3.5857e-13, 3.8263e-10, 2.3477e-08, 6.4290e-09, 1.5941e-08,
        5.9272e-14, 2.2322e-10, 7.3768e-11, 2.3341e-07, 6.7952e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:51,859][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.2614e-02, 8.4264e-01, 9.2665e-02, 1.2802e-03, 8.9658e-04, 3.6422e-03,
        1.1559e-03, 4.9123e-04, 8.6392e-04, 2.1733e-03, 4.3214e-03, 6.3518e-03,
        3.4147e-04, 4.3245e-04, 9.8769e-04, 3.7739e-03, 1.0824e-02, 1.4549e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,863][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0550, 0.1712, 0.0343, 0.0756, 0.0513, 0.1015, 0.1439, 0.0394, 0.0305,
        0.0546, 0.0199, 0.0249, 0.0306, 0.0213, 0.0516, 0.0327, 0.0481, 0.0134],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,864][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1256, 0.0537, 0.0718, 0.0606, 0.0414, 0.0715, 0.0366, 0.0419, 0.0503,
        0.0408, 0.0999, 0.0300, 0.0604, 0.0401, 0.0307, 0.0392, 0.0442, 0.0613],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,865][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0154, 0.0716, 0.0883, 0.0641, 0.0562, 0.0581, 0.0499, 0.0568, 0.0383,
        0.0633, 0.0496, 0.0550, 0.0593, 0.0628, 0.0471, 0.0643, 0.0502, 0.0496],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,866][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0920, 0.0766, 0.2373, 0.0447, 0.0142, 0.0923, 0.0058, 0.0079, 0.0269,
        0.0028, 0.0306, 0.1078, 0.0260, 0.0214, 0.0374, 0.0030, 0.0028, 0.1705],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,868][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.6406e-01, 6.2216e-01, 1.5587e-01, 6.6359e-03, 3.3370e-03, 4.1312e-03,
        2.2851e-03, 5.6933e-04, 1.1880e-03, 3.0479e-03, 6.6560e-03, 9.9428e-03,
        3.0489e-03, 1.7374e-03, 9.1383e-04, 4.5151e-03, 3.2284e-03, 6.6786e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,874][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0113, 0.0671, 0.0860, 0.0624, 0.0748, 0.0649, 0.0634, 0.0485, 0.0514,
        0.0509, 0.0566, 0.0609, 0.0589, 0.0595, 0.0510, 0.0459, 0.0462, 0.0403],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,876][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0282, 0.0557, 0.0566, 0.0583, 0.0603, 0.0600, 0.0551, 0.0585, 0.0571,
        0.0582, 0.0568, 0.0515, 0.0569, 0.0613, 0.0559, 0.0585, 0.0544, 0.0566],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,877][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0153, 0.0642, 0.0572, 0.0583, 0.0529, 0.0532, 0.0527, 0.0535, 0.0536,
        0.0557, 0.0542, 0.0554, 0.0550, 0.0581, 0.0578, 0.0649, 0.0672, 0.0707],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,878][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0070, 0.0882, 0.0902, 0.0634, 0.0537, 0.0847, 0.0588, 0.0670, 0.0468,
        0.0575, 0.0542, 0.0481, 0.0565, 0.0397, 0.0517, 0.0502, 0.0444, 0.0380],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,879][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0110, 0.0698, 0.0803, 0.0493, 0.0563, 0.0416, 0.0607, 0.0590, 0.0566,
        0.0526, 0.0487, 0.0657, 0.0740, 0.0517, 0.0527, 0.0519, 0.0577, 0.0605],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,881][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.0840e-09, 9.9911e-01, 7.7576e-04, 1.7542e-11, 9.8403e-10, 6.0922e-07,
        4.0225e-08, 8.8808e-12, 2.2736e-08, 9.9776e-08, 3.2701e-08, 2.6584e-07,
        7.7697e-13, 2.2363e-10, 7.4880e-09, 8.4104e-07, 3.6436e-05, 8.0237e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:51,886][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([7.7588e-03, 8.9605e-01, 6.6475e-02, 6.1058e-04, 2.0112e-04, 3.4657e-03,
        3.6259e-04, 1.4725e-04, 2.3773e-04, 1.2704e-03, 2.5071e-03, 1.6720e-03,
        1.6864e-04, 8.6166e-05, 2.6844e-04, 1.8425e-03, 4.0193e-03, 7.7793e-03,
        5.0808e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,889][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0822, 0.1979, 0.0336, 0.0881, 0.0297, 0.0832, 0.1184, 0.0337, 0.0140,
        0.0751, 0.0336, 0.0160, 0.0327, 0.0102, 0.0327, 0.0444, 0.0315, 0.0276,
        0.0153], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,890][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1445, 0.0499, 0.0649, 0.0561, 0.0379, 0.0669, 0.0388, 0.0443, 0.0510,
        0.0390, 0.0966, 0.0310, 0.0466, 0.0356, 0.0316, 0.0360, 0.0439, 0.0618,
        0.0234], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,891][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0148, 0.0693, 0.0856, 0.0636, 0.0545, 0.0536, 0.0458, 0.0524, 0.0294,
        0.0612, 0.0494, 0.0490, 0.0568, 0.0578, 0.0404, 0.0622, 0.0442, 0.0543,
        0.0559], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,891][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0597, 0.0177, 0.0736, 0.0143, 0.0041, 0.0340, 0.0014, 0.0027, 0.0132,
        0.0011, 0.0169, 0.0993, 0.0174, 0.0065, 0.0044, 0.0012, 0.0016, 0.1444,
        0.4866], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,893][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([8.7806e-02, 6.9137e-01, 1.5832e-01, 9.0589e-03, 3.2529e-03, 4.0574e-03,
        1.7777e-03, 3.5863e-04, 1.5293e-03, 2.3847e-03, 6.3415e-03, 4.3536e-03,
        1.8628e-03, 1.3130e-03, 5.8117e-04, 2.9551e-03, 1.5216e-03, 1.2690e-02,
        8.4622e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,900][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.0117, 0.0690, 0.0766, 0.0589, 0.0676, 0.0572, 0.0642, 0.0472, 0.0500,
        0.0499, 0.0528, 0.0610, 0.0572, 0.0517, 0.0483, 0.0445, 0.0451, 0.0419,
        0.0452], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,901][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0263, 0.0525, 0.0536, 0.0552, 0.0574, 0.0572, 0.0528, 0.0557, 0.0545,
        0.0550, 0.0537, 0.0492, 0.0537, 0.0584, 0.0532, 0.0553, 0.0514, 0.0538,
        0.0510], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,902][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0145, 0.0595, 0.0535, 0.0544, 0.0496, 0.0497, 0.0491, 0.0500, 0.0501,
        0.0519, 0.0505, 0.0517, 0.0511, 0.0542, 0.0540, 0.0604, 0.0625, 0.0654,
        0.0679], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,903][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0070, 0.0835, 0.0843, 0.0583, 0.0514, 0.0838, 0.0519, 0.0646, 0.0494,
        0.0542, 0.0581, 0.0456, 0.0476, 0.0364, 0.0472, 0.0469, 0.0416, 0.0435,
        0.0446], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,904][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0095, 0.0642, 0.0682, 0.0483, 0.0507, 0.0373, 0.0532, 0.0605, 0.0602,
        0.0540, 0.0491, 0.0586, 0.0719, 0.0451, 0.0481, 0.0529, 0.0553, 0.0622,
        0.0507], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,907][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([1.4322e-07, 9.6758e-01, 4.2959e-04, 2.8197e-11, 6.1268e-10, 2.1515e-07,
        2.9368e-08, 1.3224e-11, 1.3675e-08, 5.5931e-08, 8.9509e-07, 3.3809e-07,
        2.3760e-13, 2.4917e-10, 2.3601e-08, 9.3230e-07, 6.8815e-05, 3.1831e-02,
        8.7984e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:51,911][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.5197e-02, 7.5566e-01, 9.3798e-02, 1.3127e-03, 8.5066e-04, 3.7220e-03,
        1.0364e-03, 2.8847e-04, 9.0526e-04, 8.4832e-04, 5.6859e-03, 4.2354e-03,
        3.2557e-04, 5.2923e-04, 9.8031e-04, 1.7591e-03, 7.8929e-03, 2.0704e-02,
        2.3427e-02, 2.0846e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,914][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0602, 0.1252, 0.0512, 0.0692, 0.0643, 0.0896, 0.1669, 0.0389, 0.0337,
        0.0317, 0.0263, 0.0233, 0.0254, 0.0216, 0.0550, 0.0170, 0.0275, 0.0247,
        0.0352, 0.0128], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,915][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1324, 0.0531, 0.0617, 0.0577, 0.0392, 0.0589, 0.0350, 0.0397, 0.0492,
        0.0384, 0.0916, 0.0274, 0.0514, 0.0367, 0.0263, 0.0362, 0.0437, 0.0565,
        0.0252, 0.0398], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,916][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0133, 0.0647, 0.0802, 0.0558, 0.0525, 0.0511, 0.0470, 0.0508, 0.0330,
        0.0517, 0.0464, 0.0507, 0.0499, 0.0574, 0.0430, 0.0519, 0.0445, 0.0492,
        0.0537, 0.0531], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,917][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1937, 0.1329, 0.0969, 0.0983, 0.0047, 0.0586, 0.0024, 0.0041, 0.0333,
        0.0124, 0.0353, 0.0416, 0.0632, 0.0073, 0.0362, 0.0128, 0.0029, 0.0469,
        0.1020, 0.0146], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,919][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.8084e-01, 5.1685e-01, 1.0230e-01, 6.8384e-03, 3.2238e-03, 2.8670e-03,
        1.9639e-03, 3.2680e-04, 1.4462e-03, 1.5736e-03, 6.1124e-03, 5.9391e-03,
        3.2443e-03, 1.8890e-03, 1.5272e-03, 3.0413e-03, 5.0192e-03, 1.4488e-02,
        1.7665e-02, 2.2843e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,926][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0120, 0.0611, 0.0798, 0.0559, 0.0687, 0.0606, 0.0606, 0.0463, 0.0443,
        0.0435, 0.0501, 0.0571, 0.0492, 0.0529, 0.0433, 0.0388, 0.0438, 0.0395,
        0.0538, 0.0387], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,927][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0264, 0.0503, 0.0511, 0.0525, 0.0545, 0.0541, 0.0499, 0.0528, 0.0515,
        0.0523, 0.0510, 0.0467, 0.0511, 0.0551, 0.0505, 0.0525, 0.0486, 0.0504,
        0.0476, 0.0512], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,928][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0135, 0.0558, 0.0502, 0.0512, 0.0467, 0.0468, 0.0463, 0.0470, 0.0470,
        0.0488, 0.0475, 0.0484, 0.0482, 0.0509, 0.0507, 0.0566, 0.0584, 0.0613,
        0.0635, 0.0613], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,929][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0073, 0.0767, 0.0775, 0.0557, 0.0514, 0.0780, 0.0531, 0.0589, 0.0446,
        0.0503, 0.0529, 0.0427, 0.0518, 0.0385, 0.0454, 0.0443, 0.0386, 0.0404,
        0.0454, 0.0465], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,934][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0099, 0.0662, 0.0667, 0.0488, 0.0480, 0.0351, 0.0540, 0.0568, 0.0537,
        0.0522, 0.0476, 0.0510, 0.0686, 0.0433, 0.0453, 0.0504, 0.0507, 0.0599,
        0.0436, 0.0481], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,937][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.5271e-04, 4.5340e-01, 2.1352e-03, 3.5184e-11, 2.8502e-09, 6.8176e-07,
        3.2320e-07, 1.4648e-11, 4.5190e-07, 1.1695e-07, 1.3393e-06, 3.6763e-06,
        6.7771e-12, 5.9364e-09, 5.6913e-08, 2.9624e-06, 3.7603e-04, 3.0310e-02,
        4.4663e-01, 6.6985e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:51,941][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:51,942][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 4010],
        [  619],
        [ 6785],
        [ 2531],
        [ 2697],
        [ 5854],
        [  638],
        [ 5069],
        [10173],
        [ 9457],
        [ 6076],
        [ 2844],
        [ 2726],
        [ 4791],
        [ 5274],
        [ 4998],
        [ 8205],
        [11689],
        [12127],
        [ 6922]], device='cuda:0')
[2024-07-24 10:16:51,945][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4138],
        [15334],
        [38562],
        [17034],
        [23496],
        [25205],
        [10978],
        [19384],
        [39453],
        [35440],
        [31075],
        [35432],
        [25270],
        [28218],
        [27401],
        [33306],
        [32234],
        [32776],
        [35431],
        [35013]], device='cuda:0')
[2024-07-24 10:16:51,948][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16553],
        [14537],
        [16711],
        [17680],
        [21071],
        [21558],
        [21046],
        [21441],
        [21253],
        [20759],
        [20960],
        [22153],
        [21760],
        [22267],
        [21904],
        [21799],
        [21379],
        [21346],
        [21135],
        [21072]], device='cuda:0')
[2024-07-24 10:16:51,952][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30496],
        [31301],
        [32730],
        [32711],
        [32317],
        [34225],
        [35249],
        [35028],
        [34604],
        [34556],
        [34048],
        [33626],
        [33532],
        [33195],
        [33481],
        [33536],
        [34932],
        [35384],
        [35059],
        [35080]], device='cuda:0')
[2024-07-24 10:16:51,954][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8732],
        [7835],
        [8534],
        [8096],
        [8945],
        [8658],
        [8537],
        [8362],
        [8365],
        [8450],
        [8344],
        [8541],
        [8313],
        [8522],
        [8414],
        [8344],
        [8432],
        [8309],
        [8732],
        [8789]], device='cuda:0')
[2024-07-24 10:16:51,956][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5599],
        [29875],
        [41523],
        [48835],
        [46124],
        [46862],
        [49334],
        [48548],
        [48817],
        [46212],
        [45429],
        [45176],
        [46647],
        [44792],
        [48241],
        [44837],
        [47782],
        [43136],
        [44508],
        [39948]], device='cuda:0')
[2024-07-24 10:16:51,957][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[5340],
        [4231],
        [3949],
        [3908],
        [3929],
        [3907],
        [3930],
        [3968],
        [3994],
        [4106],
        [4184],
        [4250],
        [4219],
        [4180],
        [4152],
        [4136],
        [4117],
        [4091],
        [4053],
        [4061]], device='cuda:0')
[2024-07-24 10:16:51,959][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[25542],
        [41601],
        [38717],
        [38696],
        [40448],
        [39953],
        [39222],
        [39553],
        [39527],
        [40265],
        [40288],
        [39892],
        [40180],
        [40617],
        [40310],
        [40753],
        [40892],
        [40967],
        [40975],
        [41219]], device='cuda:0')
[2024-07-24 10:16:51,963][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23177],
        [23272],
        [24006],
        [23052],
        [23054],
        [23295],
        [24411],
        [24983],
        [24692],
        [25062],
        [24686],
        [24450],
        [24246],
        [24066],
        [23915],
        [24354],
        [23911],
        [24075],
        [24260],
        [24436]], device='cuda:0')
[2024-07-24 10:16:51,966][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 824],
        [ 711],
        [ 946],
        [ 857],
        [ 988],
        [ 982],
        [1048],
        [1036],
        [1134],
        [1009],
        [1216],
        [1202],
        [1118],
        [1239],
        [1204],
        [1141],
        [1163],
        [1217],
        [1177],
        [1144]], device='cuda:0')
[2024-07-24 10:16:51,968][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[17139],
        [21421],
        [21665],
        [21332],
        [21606],
        [22191],
        [23243],
        [23751],
        [24478],
        [24049],
        [24323],
        [24292],
        [24252],
        [24598],
        [25006],
        [24943],
        [25074],
        [25260],
        [25257],
        [25179]], device='cuda:0')
[2024-07-24 10:16:51,970][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[11825],
        [17620],
        [15839],
        [14750],
        [14420],
        [14424],
        [14413],
        [14194],
        [14310],
        [14369],
        [14662],
        [14975],
        [14463],
        [14527],
        [14885],
        [15244],
        [15387],
        [15590],
        [16182],
        [16320]], device='cuda:0')
[2024-07-24 10:16:51,972][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[40457],
        [40369],
        [41224],
        [40547],
        [40942],
        [40315],
        [40810],
        [41039],
        [41308],
        [40921],
        [40670],
        [40592],
        [40607],
        [40476],
        [40539],
        [40252],
        [40294],
        [40384],
        [40412],
        [40333]], device='cuda:0')
[2024-07-24 10:16:51,974][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 5886],
        [ 5886],
        [ 3580],
        [43613],
        [ 1585],
        [43507],
        [ 5063],
        [40399],
        [ 7837],
        [25094],
        [24687],
        [ 3509],
        [21168],
        [21180],
        [22823],
        [21166],
        [28001],
        [16125],
        [ 7882],
        [21657]], device='cuda:0')
[2024-07-24 10:16:51,977][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9686],
        [ 6815],
        [ 1273],
        [ 2743],
        [ 3227],
        [ 1711],
        [ 2952],
        [ 4764],
        [ 2570],
        [ 5307],
        [ 3001],
        [ 4466],
        [ 6210],
        [ 6345],
        [10913],
        [ 4933],
        [ 5764],
        [ 3670],
        [ 7950],
        [ 3557]], device='cuda:0')
[2024-07-24 10:16:51,980][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[  395],
        [ 7623],
        [ 8227],
        [ 8788],
        [ 8828],
        [ 9031],
        [ 8496],
        [ 9113],
        [ 8976],
        [ 8870],
        [ 8723],
        [10512],
        [ 8438],
        [ 9536],
        [ 9245],
        [ 9294],
        [ 9118],
        [ 9429],
        [ 8756],
        [ 8815]], device='cuda:0')
[2024-07-24 10:16:51,983][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11663],
        [14076],
        [14505],
        [16099],
        [15833],
        [15796],
        [15537],
        [15933],
        [16056],
        [16117],
        [16028],
        [16902],
        [16268],
        [16455],
        [16981],
        [16711],
        [17627],
        [17266],
        [17535],
        [17212]], device='cuda:0')
[2024-07-24 10:16:51,984][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14745],
        [ 6746],
        [ 9837],
        [ 8204],
        [ 8218],
        [ 7502],
        [ 6578],
        [ 5670],
        [ 5197],
        [ 5510],
        [ 4461],
        [ 4635],
        [ 4036],
        [ 3975],
        [ 3764],
        [ 4076],
        [ 3562],
        [ 3846],
        [ 3915],
        [ 4144]], device='cuda:0')
[2024-07-24 10:16:51,986][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16002],
        [17546],
        [20482],
        [18936],
        [18846],
        [18142],
        [17637],
        [17689],
        [17448],
        [17141],
        [16938],
        [17214],
        [17088],
        [17053],
        [17015],
        [16669],
        [16576],
        [16477],
        [16432],
        [16300]], device='cuda:0')
[2024-07-24 10:16:51,988][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17428],
        [14405],
        [ 2380],
        [ 8414],
        [ 4049],
        [ 3461],
        [ 4592],
        [ 6085],
        [11734],
        [ 9143],
        [ 5414],
        [ 9158],
        [ 6979],
        [ 5847],
        [ 2717],
        [ 7784],
        [ 8829],
        [ 7891],
        [12414],
        [ 6410]], device='cuda:0')
[2024-07-24 10:16:51,991][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[20104],
        [30200],
        [32597],
        [32699],
        [32598],
        [32765],
        [32834],
        [32894],
        [32656],
        [32816],
        [32631],
        [32732],
        [32570],
        [32599],
        [32820],
        [32661],
        [32900],
        [32267],
        [32463],
        [31282]], device='cuda:0')
[2024-07-24 10:16:51,995][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12010],
        [ 6069],
        [ 5066],
        [ 4675],
        [ 4831],
        [ 4793],
        [ 4813],
        [ 4870],
        [ 4967],
        [ 4876],
        [ 4841],
        [ 4796],
        [ 4736],
        [ 4715],
        [ 4716],
        [ 4637],
        [ 4675],
        [ 4741],
        [ 4779],
        [ 4793]], device='cuda:0')
[2024-07-24 10:16:51,997][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[5760],
        [5484],
        [5436],
        [5511],
        [5534],
        [5536],
        [5525],
        [5530],
        [5540],
        [5542],
        [5560],
        [5537],
        [5556],
        [5558],
        [5552],
        [5557],
        [5555],
        [5571],
        [5572],
        [5575]], device='cuda:0')
[2024-07-24 10:16:51,998][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10795],
        [12150],
        [11723],
        [11399],
        [11669],
        [11827],
        [11930],
        [11832],
        [11810],
        [11845],
        [11993],
        [12081],
        [12190],
        [12357],
        [12535],
        [12529],
        [12578],
        [12617],
        [12775],
        [12812]], device='cuda:0')
[2024-07-24 10:16:52,000][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8502],
        [10086],
        [10561],
        [10802],
        [11551],
        [11736],
        [11131],
        [11012],
        [11642],
        [12057],
        [12252],
        [12438],
        [12477],
        [12610],
        [13028],
        [13140],
        [13511],
        [13512],
        [13859],
        [14062]], device='cuda:0')
[2024-07-24 10:16:52,002][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1034],
        [ 288],
        [ 458],
        [ 367],
        [ 306],
        [ 383],
        [ 413],
        [ 434],
        [ 429],
        [ 398],
        [ 419],
        [ 365],
        [ 321],
        [ 305],
        [ 314],
        [ 299],
        [ 284],
        [ 276],
        [ 273],
        [ 268]], device='cuda:0')
[2024-07-24 10:16:52,005][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[30156],
        [30156],
        [30237],
        [30229],
        [30237],
        [30196],
        [30230],
        [30208],
        [30230],
        [30216],
        [30230],
        [30229],
        [30200],
        [30237],
        [30091],
        [30173],
        [29667],
        [30207],
        [31149],
        [25176]], device='cuda:0')
[2024-07-24 10:16:52,009][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33180],
        [27680],
        [26268],
        [23316],
        [25565],
        [24953],
        [24981],
        [23884],
        [22927],
        [23455],
        [24581],
        [24596],
        [24165],
        [24922],
        [24586],
        [23329],
        [23383],
        [23537],
        [23637],
        [24525]], device='cuda:0')
[2024-07-24 10:16:52,011][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27534],
        [38513],
        [31320],
        [41848],
        [32591],
        [38971],
        [37355],
        [41597],
        [38615],
        [37614],
        [39169],
        [24422],
        [37465],
        [34584],
        [36597],
        [38651],
        [38368],
        [40706],
        [32888],
        [40563]], device='cuda:0')
[2024-07-24 10:16:52,013][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562],
        [3562]], device='cuda:0')
[2024-07-24 10:16:52,064][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:52,065][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,065][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,066][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,067][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,067][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,068][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,069][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,069][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,070][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,070][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,071][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,072][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,075][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1793, 0.8207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,079][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9161, 0.0839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,080][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2918, 0.7082], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,081][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1900, 0.8100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,082][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9438, 0.0562], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,082][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2633, 0.7367], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,085][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6990, 0.3010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,092][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9144, 0.0856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,092][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1231, 0.8769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,093][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9344, 0.0656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,094][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0769, 0.9231], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,095][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1482, 0.8518], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,097][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1553, 0.4885, 0.3563], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,103][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.8747, 0.0730, 0.0523], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,105][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.2330, 0.4217, 0.3453], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,105][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0947, 0.5242, 0.3811], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,106][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.8640, 0.0721, 0.0638], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,107][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0812, 0.4353, 0.4835], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,107][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.6317, 0.2586, 0.1097], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,112][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.3698, 0.5729, 0.0573], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,117][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0501, 0.5465, 0.4035], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,117][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.9321, 0.0443, 0.0236], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,118][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0290, 0.4083, 0.5627], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,119][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0852, 0.4814, 0.4334], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,120][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1785, 0.2501, 0.3768, 0.1946], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,124][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8062, 0.0703, 0.0516, 0.0718], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,129][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1457, 0.2986, 0.2724, 0.2833], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,130][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0574, 0.3638, 0.2734, 0.3054], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,131][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8717, 0.0492, 0.0450, 0.0341], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,131][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0589, 0.2113, 0.5258, 0.2039], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,132][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5082, 0.2278, 0.1469, 0.1171], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,136][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3588, 0.4851, 0.1359, 0.0202], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,141][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0392, 0.2597, 0.4973, 0.2038], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,142][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7701, 0.0590, 0.0373, 0.1336], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,143][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0289, 0.2938, 0.3807, 0.2965], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,144][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0576, 0.3466, 0.3087, 0.2872], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,144][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0411, 0.2474, 0.1329, 0.4138, 0.1649], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,149][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.7827, 0.0639, 0.0458, 0.0626, 0.0450], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,154][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.1200, 0.2566, 0.2296, 0.2295, 0.1643], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,155][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0439, 0.2880, 0.2104, 0.2398, 0.2178], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,155][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.8344, 0.0505, 0.0459, 0.0348, 0.0344], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,156][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0405, 0.1691, 0.3685, 0.1599, 0.2620], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,157][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.4383, 0.2211, 0.1202, 0.1175, 0.1029], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,161][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0447, 0.8160, 0.1241, 0.0134, 0.0019], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,166][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0351, 0.2346, 0.2404, 0.2332, 0.2567], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,167][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.7581, 0.0402, 0.0250, 0.1052, 0.0716], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,168][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0162, 0.2157, 0.2843, 0.2148, 0.2690], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,169][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0446, 0.2685, 0.2419, 0.2245, 0.2204], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,169][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0405, 0.2084, 0.1446, 0.3122, 0.1494, 0.1451], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,174][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.7440, 0.0614, 0.0418, 0.0598, 0.0418, 0.0512], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,180][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1254, 0.2033, 0.1698, 0.1896, 0.1201, 0.1917], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,182][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0385, 0.2329, 0.1720, 0.2006, 0.1837, 0.1724], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,183][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.7711, 0.0634, 0.0580, 0.0425, 0.0432, 0.0218], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,184][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0343, 0.1442, 0.2504, 0.1428, 0.2604, 0.1678], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,184][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.3613, 0.1955, 0.1222, 0.1084, 0.1150, 0.0976], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,185][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.4254, 0.4498, 0.0984, 0.0178, 0.0026, 0.0061], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,190][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0152, 0.1825, 0.2692, 0.1746, 0.2719, 0.0866], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,195][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.6011, 0.0560, 0.0377, 0.1229, 0.0940, 0.0884], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,195][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0156, 0.1723, 0.2150, 0.1830, 0.2030, 0.2110], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,196][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0386, 0.2233, 0.1983, 0.1849, 0.1800, 0.1748], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,197][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0435, 0.2220, 0.1324, 0.1795, 0.1111, 0.1745, 0.1370],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,198][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.7420, 0.0545, 0.0370, 0.0527, 0.0365, 0.0445, 0.0327],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,203][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0897, 0.1721, 0.1491, 0.1599, 0.1055, 0.1672, 0.1565],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,208][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0347, 0.1986, 0.1471, 0.1697, 0.1556, 0.1453, 0.1490],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,208][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.7161, 0.0679, 0.0657, 0.0495, 0.0498, 0.0236, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,209][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0224, 0.0904, 0.2271, 0.0994, 0.2137, 0.1524, 0.1944],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,210][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.2997, 0.1882, 0.1260, 0.1052, 0.1116, 0.0962, 0.0732],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,211][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1260, 0.6257, 0.1870, 0.0223, 0.0070, 0.0092, 0.0227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,215][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0142, 0.1483, 0.2478, 0.1419, 0.2476, 0.1193, 0.0809],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,220][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.6811, 0.0349, 0.0212, 0.0989, 0.0644, 0.0682, 0.0313],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,221][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0112, 0.1475, 0.1834, 0.1555, 0.1801, 0.1639, 0.1584],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,222][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0336, 0.1910, 0.1711, 0.1581, 0.1559, 0.1485, 0.1418],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,223][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0400, 0.2112, 0.0992, 0.2130, 0.0728, 0.1429, 0.1410, 0.0798],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,224][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.7112, 0.0537, 0.0360, 0.0515, 0.0361, 0.0445, 0.0326, 0.0344],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,229][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0845, 0.1485, 0.1281, 0.1371, 0.0902, 0.1420, 0.1363, 0.1333],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,233][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0276, 0.1687, 0.1272, 0.1443, 0.1348, 0.1244, 0.1287, 0.1442],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,234][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.7079, 0.0668, 0.0629, 0.0468, 0.0472, 0.0228, 0.0276, 0.0180],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,235][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0258, 0.0850, 0.2330, 0.0921, 0.1631, 0.1134, 0.1875, 0.1000],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,236][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.2973, 0.1651, 0.1139, 0.0885, 0.0965, 0.0843, 0.0697, 0.0847],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,236][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0558, 0.7037, 0.1244, 0.0216, 0.0069, 0.0080, 0.0753, 0.0042],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,241][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0138, 0.1282, 0.2468, 0.1289, 0.2341, 0.0918, 0.1021, 0.0542],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,246][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.5672, 0.0471, 0.0288, 0.1094, 0.0768, 0.0775, 0.0398, 0.0534],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,247][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0109, 0.1292, 0.1576, 0.1302, 0.1514, 0.1441, 0.1317, 0.1450],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,248][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0272, 0.1689, 0.1505, 0.1407, 0.1377, 0.1310, 0.1241, 0.1199],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,249][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0306, 0.2036, 0.1271, 0.1496, 0.0849, 0.1312, 0.0865, 0.0932, 0.0933],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,249][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.7073, 0.0500, 0.0335, 0.0479, 0.0331, 0.0406, 0.0298, 0.0310, 0.0268],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,254][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0566, 0.1214, 0.1157, 0.1244, 0.0835, 0.1360, 0.1277, 0.1234, 0.1113],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,259][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0256, 0.1490, 0.1111, 0.1274, 0.1174, 0.1087, 0.1116, 0.1265, 0.1227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,260][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.6741, 0.0667, 0.0647, 0.0490, 0.0499, 0.0237, 0.0281, 0.0189, 0.0249],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,261][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0149, 0.0779, 0.1940, 0.0853, 0.1589, 0.0977, 0.1759, 0.1048, 0.0906],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,262][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.3049, 0.1449, 0.0895, 0.0851, 0.0854, 0.0799, 0.0619, 0.0859, 0.0624],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,262][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0608, 0.7233, 0.1156, 0.0269, 0.0051, 0.0074, 0.0461, 0.0022, 0.0128],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,268][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.0102, 0.1167, 0.2148, 0.1402, 0.2197, 0.0856, 0.0969, 0.0606, 0.0554],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,272][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.6020, 0.0343, 0.0217, 0.0966, 0.0666, 0.0651, 0.0332, 0.0471, 0.0334],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,273][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0072, 0.1081, 0.1485, 0.1107, 0.1406, 0.1396, 0.1152, 0.1278, 0.1022],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,274][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0257, 0.1484, 0.1337, 0.1228, 0.1219, 0.1159, 0.1100, 0.1053, 0.1162],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,275][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0431, 0.1312, 0.1186, 0.1258, 0.0928, 0.1323, 0.1106, 0.0706, 0.0873,
        0.0877], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,275][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.6361, 0.0522, 0.0368, 0.0518, 0.0366, 0.0446, 0.0330, 0.0344, 0.0299,
        0.0445], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,280][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0527, 0.1054, 0.1003, 0.1142, 0.0720, 0.1220, 0.1148, 0.1147, 0.1016,
        0.1022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,285][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0236, 0.1305, 0.0982, 0.1127, 0.1044, 0.0970, 0.1003, 0.1130, 0.1102,
        0.1102], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,286][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7595, 0.0443, 0.0429, 0.0314, 0.0321, 0.0160, 0.0195, 0.0132, 0.0173,
        0.0238], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,287][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0175, 0.0663, 0.1661, 0.0717, 0.1545, 0.0968, 0.1416, 0.0916, 0.1322,
        0.0616], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,287][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2318, 0.1306, 0.1004, 0.0726, 0.0890, 0.0751, 0.0633, 0.0769, 0.0720,
        0.0883], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,288][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3394, 0.4783, 0.1041, 0.0133, 0.0041, 0.0043, 0.0290, 0.0034, 0.0194,
        0.0047], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,293][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0133, 0.1019, 0.2117, 0.1026, 0.2141, 0.0858, 0.0841, 0.0577, 0.0716,
        0.0572], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,298][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.5087, 0.0369, 0.0238, 0.0927, 0.0638, 0.0636, 0.0348, 0.0468, 0.0351,
        0.0939], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,299][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0112, 0.1024, 0.1288, 0.1045, 0.1184, 0.1214, 0.1055, 0.1124, 0.0874,
        0.1080], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,300][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0250, 0.1320, 0.1180, 0.1104, 0.1085, 0.1037, 0.0990, 0.0954, 0.1037,
        0.1043], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,300][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0398, 0.1513, 0.0766, 0.1361, 0.0614, 0.1173, 0.0777, 0.0789, 0.0670,
        0.1215, 0.0724], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,301][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.6401, 0.0475, 0.0327, 0.0466, 0.0323, 0.0398, 0.0293, 0.0303, 0.0262,
        0.0394, 0.0359], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,306][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0537, 0.1070, 0.0952, 0.1045, 0.0671, 0.1095, 0.1020, 0.1018, 0.0909,
        0.0925, 0.0758], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,311][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0220, 0.1186, 0.0895, 0.1024, 0.0950, 0.0877, 0.0900, 0.1009, 0.0988,
        0.0989, 0.0963], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,312][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.7149, 0.0488, 0.0483, 0.0346, 0.0358, 0.0173, 0.0207, 0.0139, 0.0183,
        0.0252, 0.0221], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,312][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0207, 0.0684, 0.1466, 0.0710, 0.1340, 0.0885, 0.1316, 0.0939, 0.1100,
        0.0736, 0.0617], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,313][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2386, 0.1176, 0.0808, 0.0642, 0.0723, 0.0632, 0.0564, 0.0682, 0.0636,
        0.0849, 0.0903], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,314][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1979, 0.6172, 0.1052, 0.0152, 0.0043, 0.0075, 0.0292, 0.0049, 0.0097,
        0.0056, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,319][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0149, 0.1067, 0.1772, 0.1045, 0.1851, 0.0774, 0.0817, 0.0552, 0.0675,
        0.0746, 0.0553], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,324][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4965, 0.0311, 0.0196, 0.0824, 0.0556, 0.0566, 0.0300, 0.0417, 0.0304,
        0.0866, 0.0696], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,325][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0091, 0.0934, 0.1173, 0.0952, 0.1083, 0.1086, 0.0923, 0.1001, 0.0767,
        0.0985, 0.1005], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,325][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0224, 0.1192, 0.1063, 0.0994, 0.0975, 0.0942, 0.0903, 0.0872, 0.0947,
        0.0945, 0.0944], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,326][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0201, 0.1340, 0.1013, 0.1199, 0.0790, 0.0747, 0.0922, 0.0644, 0.0693,
        0.1042, 0.0813, 0.0596], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,327][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.6365, 0.0462, 0.0315, 0.0441, 0.0308, 0.0381, 0.0278, 0.0286, 0.0245,
        0.0366, 0.0335, 0.0217], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,332][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0583, 0.1033, 0.0884, 0.0966, 0.0638, 0.1024, 0.0952, 0.0978, 0.0866,
        0.0895, 0.0734, 0.0447], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,337][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0206, 0.1061, 0.0813, 0.0931, 0.0866, 0.0792, 0.0825, 0.0917, 0.0900,
        0.0899, 0.0891, 0.0900], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,338][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.6675, 0.0554, 0.0522, 0.0385, 0.0404, 0.0192, 0.0221, 0.0147, 0.0199,
        0.0282, 0.0244, 0.0175], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,338][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0115, 0.0595, 0.1487, 0.0609, 0.1416, 0.0706, 0.1246, 0.0790, 0.0969,
        0.0618, 0.0571, 0.0877], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,339][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2260, 0.1097, 0.0736, 0.0630, 0.0673, 0.0602, 0.0493, 0.0647, 0.0545,
        0.0816, 0.0942, 0.0558], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,340][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0823, 0.7036, 0.1298, 0.0244, 0.0033, 0.0028, 0.0291, 0.0024, 0.0119,
        0.0038, 0.0033, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,345][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0081, 0.1009, 0.1851, 0.0969, 0.1989, 0.0632, 0.0701, 0.0420, 0.0516,
        0.0623, 0.0561, 0.0647], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,350][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.4894, 0.0293, 0.0174, 0.0813, 0.0532, 0.0528, 0.0283, 0.0415, 0.0298,
        0.0846, 0.0669, 0.0256], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,351][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0044, 0.0820, 0.1058, 0.0847, 0.1023, 0.0989, 0.0796, 0.0843, 0.0729,
        0.0873, 0.0940, 0.1040], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,351][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0190, 0.1098, 0.0981, 0.0908, 0.0897, 0.0861, 0.0820, 0.0787, 0.0857,
        0.0850, 0.0851, 0.0899], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,352][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0275, 0.0795, 0.0819, 0.0853, 0.0839, 0.0900, 0.0947, 0.0829, 0.0617,
        0.0837, 0.0822, 0.0660, 0.0808], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,353][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5811, 0.0472, 0.0333, 0.0464, 0.0325, 0.0389, 0.0288, 0.0298, 0.0259,
        0.0383, 0.0346, 0.0222, 0.0410], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,358][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0420, 0.0885, 0.0827, 0.0900, 0.0606, 0.0970, 0.0929, 0.0918, 0.0825,
        0.0840, 0.0718, 0.0497, 0.0665], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,363][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0174, 0.1015, 0.0758, 0.0859, 0.0796, 0.0737, 0.0757, 0.0856, 0.0840,
        0.0835, 0.0816, 0.0839, 0.0718], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,364][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.7632, 0.0373, 0.0355, 0.0223, 0.0230, 0.0121, 0.0149, 0.0103, 0.0133,
        0.0169, 0.0152, 0.0121, 0.0238], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,364][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0141, 0.0455, 0.1375, 0.0530, 0.1181, 0.0802, 0.1169, 0.0791, 0.1001,
        0.0547, 0.0547, 0.1108, 0.0354], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,365][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1704, 0.0918, 0.0756, 0.0539, 0.0684, 0.0577, 0.0494, 0.0638, 0.0561,
        0.0727, 0.0988, 0.0610, 0.0805], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,366][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0602, 0.6339, 0.2108, 0.0144, 0.0054, 0.0052, 0.0320, 0.0051, 0.0135,
        0.0056, 0.0034, 0.0086, 0.0019], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,371][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0145, 0.0739, 0.1703, 0.0746, 0.1638, 0.0618, 0.0841, 0.0522, 0.0623,
        0.0504, 0.0592, 0.0927, 0.0400], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,375][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.3755, 0.0384, 0.0253, 0.0785, 0.0576, 0.0615, 0.0360, 0.0473, 0.0363,
        0.0828, 0.0690, 0.0350, 0.0568], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,376][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0083, 0.0803, 0.0951, 0.0798, 0.0870, 0.0897, 0.0774, 0.0857, 0.0650,
        0.0832, 0.0862, 0.0858, 0.0766], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,377][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0188, 0.1010, 0.0906, 0.0841, 0.0824, 0.0786, 0.0756, 0.0726, 0.0796,
        0.0789, 0.0789, 0.0823, 0.0767], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,378][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0134, 0.0938, 0.0457, 0.1443, 0.0553, 0.0884, 0.0656, 0.0619, 0.0617,
        0.0809, 0.0752, 0.0620, 0.1023, 0.0495], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,379][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.5586, 0.0463, 0.0324, 0.0444, 0.0318, 0.0378, 0.0281, 0.0287, 0.0253,
        0.0364, 0.0330, 0.0216, 0.0392, 0.0366], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,386][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0438, 0.0837, 0.0793, 0.0824, 0.0613, 0.0907, 0.0830, 0.0838, 0.0747,
        0.0773, 0.0669, 0.0481, 0.0620, 0.0630], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,388][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0149, 0.0945, 0.0703, 0.0797, 0.0735, 0.0688, 0.0716, 0.0802, 0.0787,
        0.0781, 0.0760, 0.0777, 0.0674, 0.0687], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,389][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.7129, 0.0370, 0.0354, 0.0281, 0.0278, 0.0130, 0.0154, 0.0104, 0.0142,
        0.0217, 0.0190, 0.0124, 0.0314, 0.0212], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,390][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0102, 0.0502, 0.1175, 0.0485, 0.0796, 0.0706, 0.1282, 0.0707, 0.0932,
        0.0429, 0.0504, 0.1318, 0.0343, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,391][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.1935, 0.0973, 0.0617, 0.0542, 0.0515, 0.0498, 0.0385, 0.0544, 0.0436,
        0.0718, 0.0915, 0.0497, 0.0906, 0.0518], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,394][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1205, 0.6252, 0.1249, 0.0176, 0.0038, 0.0035, 0.0566, 0.0054, 0.0242,
        0.0059, 0.0033, 0.0046, 0.0031, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,401][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0120, 0.0966, 0.1043, 0.1014, 0.1131, 0.0570, 0.0674, 0.0442, 0.0603,
        0.0584, 0.0665, 0.0745, 0.0618, 0.0826], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,402][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.4609, 0.0245, 0.0149, 0.0681, 0.0436, 0.0489, 0.0241, 0.0347, 0.0249,
        0.0761, 0.0601, 0.0249, 0.0512, 0.0431], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,403][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0057, 0.0706, 0.0912, 0.0719, 0.0873, 0.0836, 0.0705, 0.0780, 0.0563,
        0.0763, 0.0764, 0.0819, 0.0691, 0.0813], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,403][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0157, 0.0937, 0.0842, 0.0782, 0.0765, 0.0732, 0.0699, 0.0668, 0.0736,
        0.0723, 0.0720, 0.0763, 0.0697, 0.0780], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,404][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0154, 0.0991, 0.0677, 0.1074, 0.0546, 0.0495, 0.0717, 0.0605, 0.0629,
        0.0684, 0.0874, 0.0665, 0.0907, 0.0604, 0.0378], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,411][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.5970, 0.0404, 0.0273, 0.0394, 0.0270, 0.0328, 0.0236, 0.0248, 0.0211,
        0.0319, 0.0292, 0.0182, 0.0346, 0.0313, 0.0215], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,413][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0473, 0.0849, 0.0740, 0.0806, 0.0546, 0.0817, 0.0792, 0.0759, 0.0705,
        0.0693, 0.0599, 0.0413, 0.0584, 0.0593, 0.0631], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,414][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0140, 0.0868, 0.0657, 0.0747, 0.0700, 0.0640, 0.0662, 0.0745, 0.0731,
        0.0731, 0.0719, 0.0735, 0.0629, 0.0657, 0.0640], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,415][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.5767, 0.0558, 0.0537, 0.0397, 0.0421, 0.0193, 0.0232, 0.0150, 0.0205,
        0.0284, 0.0246, 0.0185, 0.0361, 0.0315, 0.0148], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,416][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0112, 0.0456, 0.1026, 0.0542, 0.1044, 0.0602, 0.1037, 0.0625, 0.0669,
        0.0462, 0.0497, 0.1037, 0.0356, 0.0827, 0.0709], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,419][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.1765, 0.0951, 0.0594, 0.0552, 0.0543, 0.0489, 0.0366, 0.0533, 0.0395,
        0.0692, 0.0853, 0.0426, 0.0885, 0.0549, 0.0408], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,426][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0847, 0.6037, 0.1509, 0.0174, 0.0055, 0.0072, 0.0650, 0.0055, 0.0191,
        0.0074, 0.0057, 0.0107, 0.0034, 0.0019, 0.0119], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,427][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0064, 0.0849, 0.1290, 0.0819, 0.1524, 0.0479, 0.0607, 0.0381, 0.0432,
        0.0486, 0.0507, 0.0761, 0.0453, 0.1060, 0.0288], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,428][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.4367, 0.0276, 0.0169, 0.0698, 0.0483, 0.0489, 0.0256, 0.0359, 0.0273,
        0.0759, 0.0606, 0.0253, 0.0431, 0.0439, 0.0143], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,429][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0042, 0.0646, 0.0841, 0.0677, 0.0830, 0.0815, 0.0633, 0.0732, 0.0571,
        0.0715, 0.0752, 0.0738, 0.0643, 0.0764, 0.0602], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,431][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0159, 0.0868, 0.0776, 0.0722, 0.0707, 0.0679, 0.0644, 0.0620, 0.0687,
        0.0674, 0.0666, 0.0705, 0.0647, 0.0720, 0.0727], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,437][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0229, 0.0840, 0.0703, 0.0821, 0.0569, 0.0787, 0.0662, 0.0434, 0.0515,
        0.0550, 0.0740, 0.0585, 0.0859, 0.0530, 0.0631, 0.0547],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,439][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.5164, 0.0424, 0.0302, 0.0426, 0.0299, 0.0364, 0.0268, 0.0281, 0.0242,
        0.0360, 0.0327, 0.0210, 0.0377, 0.0340, 0.0242, 0.0373],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,440][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0342, 0.0701, 0.0680, 0.0769, 0.0500, 0.0818, 0.0764, 0.0753, 0.0676,
        0.0677, 0.0596, 0.0409, 0.0554, 0.0536, 0.0604, 0.0621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,441][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0155, 0.0798, 0.0615, 0.0694, 0.0657, 0.0597, 0.0619, 0.0693, 0.0678,
        0.0677, 0.0666, 0.0683, 0.0589, 0.0623, 0.0609, 0.0649],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,442][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6600, 0.0424, 0.0410, 0.0285, 0.0300, 0.0152, 0.0186, 0.0121, 0.0161,
        0.0212, 0.0194, 0.0143, 0.0298, 0.0226, 0.0116, 0.0172],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,446][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0113, 0.0426, 0.1061, 0.0461, 0.0983, 0.0619, 0.0871, 0.0583, 0.0828,
        0.0400, 0.0511, 0.0870, 0.0333, 0.0754, 0.0783, 0.0403],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,451][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1416, 0.0834, 0.0645, 0.0468, 0.0566, 0.0480, 0.0405, 0.0492, 0.0462,
        0.0561, 0.0801, 0.0522, 0.0762, 0.0561, 0.0474, 0.0549],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,452][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3296, 0.4153, 0.1437, 0.0115, 0.0050, 0.0060, 0.0279, 0.0054, 0.0243,
        0.0047, 0.0057, 0.0043, 0.0028, 0.0028, 0.0076, 0.0033],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,453][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0074, 0.0670, 0.1386, 0.0677, 0.1461, 0.0555, 0.0558, 0.0379, 0.0481,
        0.0383, 0.0526, 0.0689, 0.0370, 0.1078, 0.0396, 0.0317],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,454][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.4069, 0.0272, 0.0168, 0.0669, 0.0459, 0.0476, 0.0252, 0.0342, 0.0257,
        0.0690, 0.0568, 0.0252, 0.0479, 0.0436, 0.0155, 0.0457],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,457][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0065, 0.0632, 0.0789, 0.0646, 0.0733, 0.0745, 0.0642, 0.0681, 0.0536,
        0.0661, 0.0669, 0.0722, 0.0604, 0.0685, 0.0551, 0.0638],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,464][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0156, 0.0810, 0.0720, 0.0676, 0.0660, 0.0635, 0.0606, 0.0581, 0.0630,
        0.0632, 0.0631, 0.0658, 0.0614, 0.0671, 0.0670, 0.0649],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,465][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0243, 0.0949, 0.0705, 0.0795, 0.0478, 0.0637, 0.0586, 0.0480, 0.0464,
        0.0640, 0.0618, 0.0410, 0.1011, 0.0544, 0.0518, 0.0602, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,466][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.5460, 0.0387, 0.0263, 0.0381, 0.0261, 0.0325, 0.0236, 0.0247, 0.0210,
        0.0317, 0.0293, 0.0183, 0.0336, 0.0299, 0.0211, 0.0333, 0.0257],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,467][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0423, 0.0734, 0.0662, 0.0731, 0.0484, 0.0741, 0.0713, 0.0676, 0.0626,
        0.0603, 0.0522, 0.0363, 0.0527, 0.0509, 0.0562, 0.0562, 0.0563],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,470][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0151, 0.0766, 0.0586, 0.0669, 0.0628, 0.0565, 0.0579, 0.0651, 0.0640,
        0.0639, 0.0627, 0.0639, 0.0555, 0.0584, 0.0568, 0.0609, 0.0545],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,475][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.6164, 0.0466, 0.0457, 0.0330, 0.0348, 0.0167, 0.0195, 0.0127, 0.0173,
        0.0235, 0.0206, 0.0151, 0.0298, 0.0254, 0.0123, 0.0190, 0.0114],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,476][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0064, 0.0370, 0.0928, 0.0368, 0.0932, 0.0542, 0.0815, 0.0642, 0.0675,
        0.0395, 0.0427, 0.0935, 0.0338, 0.0775, 0.0796, 0.0410, 0.0586],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,478][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.1531, 0.0839, 0.0556, 0.0475, 0.0483, 0.0441, 0.0357, 0.0462, 0.0380,
        0.0624, 0.0710, 0.0428, 0.0778, 0.0474, 0.0407, 0.0603, 0.0452],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,479][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.1318, 0.6111, 0.1614, 0.0120, 0.0051, 0.0049, 0.0282, 0.0057, 0.0065,
        0.0064, 0.0033, 0.0064, 0.0023, 0.0014, 0.0045, 0.0054, 0.0036],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,480][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0062, 0.0697, 0.1227, 0.0632, 0.1519, 0.0478, 0.0495, 0.0401, 0.0434,
        0.0437, 0.0453, 0.0625, 0.0427, 0.1091, 0.0307, 0.0347, 0.0368],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,481][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.4895, 0.0208, 0.0125, 0.0610, 0.0405, 0.0399, 0.0197, 0.0284, 0.0203,
        0.0653, 0.0491, 0.0195, 0.0368, 0.0367, 0.0112, 0.0405, 0.0083],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,486][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0048, 0.0598, 0.0751, 0.0597, 0.0701, 0.0689, 0.0575, 0.0646, 0.0484,
        0.0630, 0.0649, 0.0688, 0.0573, 0.0652, 0.0508, 0.0613, 0.0600],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,491][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0138, 0.0759, 0.0678, 0.0631, 0.0621, 0.0594, 0.0569, 0.0546, 0.0595,
        0.0587, 0.0589, 0.0621, 0.0570, 0.0630, 0.0633, 0.0605, 0.0636],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:52,492][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0176, 0.0852, 0.0473, 0.1036, 0.0376, 0.0733, 0.0448, 0.0491, 0.0432,
        0.0744, 0.0500, 0.0499, 0.0875, 0.0357, 0.0515, 0.0684, 0.0461, 0.0347],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,493][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.5151, 0.0382, 0.0264, 0.0383, 0.0264, 0.0323, 0.0236, 0.0248, 0.0211,
        0.0318, 0.0291, 0.0183, 0.0337, 0.0299, 0.0212, 0.0332, 0.0255, 0.0310],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,494][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0361, 0.0672, 0.0638, 0.0676, 0.0467, 0.0707, 0.0680, 0.0658, 0.0593,
        0.0590, 0.0522, 0.0353, 0.0504, 0.0502, 0.0536, 0.0538, 0.0541, 0.0464],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,496][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0142, 0.0717, 0.0561, 0.0622, 0.0598, 0.0536, 0.0552, 0.0617, 0.0599,
        0.0602, 0.0596, 0.0611, 0.0527, 0.0563, 0.0544, 0.0579, 0.0526, 0.0508],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,504][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6325, 0.0431, 0.0443, 0.0295, 0.0321, 0.0153, 0.0179, 0.0115, 0.0158,
        0.0213, 0.0189, 0.0139, 0.0277, 0.0234, 0.0114, 0.0172, 0.0109, 0.0135],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,504][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0111, 0.0393, 0.0872, 0.0416, 0.0793, 0.0554, 0.0868, 0.0557, 0.0594,
        0.0406, 0.0372, 0.0793, 0.0290, 0.0627, 0.0660, 0.0408, 0.0762, 0.0523],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,505][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1441, 0.0783, 0.0511, 0.0428, 0.0429, 0.0402, 0.0365, 0.0440, 0.0401,
        0.0572, 0.0604, 0.0433, 0.0735, 0.0427, 0.0406, 0.0563, 0.0493, 0.0567],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,506][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3451, 0.3982, 0.1271, 0.0113, 0.0043, 0.0073, 0.0249, 0.0089, 0.0169,
        0.0069, 0.0051, 0.0073, 0.0040, 0.0019, 0.0089, 0.0046, 0.0146, 0.0028],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,509][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0071, 0.0692, 0.1059, 0.0655, 0.1203, 0.0505, 0.0599, 0.0345, 0.0462,
        0.0485, 0.0421, 0.0594, 0.0425, 0.0910, 0.0369, 0.0390, 0.0579, 0.0235],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,516][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4515, 0.0219, 0.0135, 0.0618, 0.0416, 0.0419, 0.0213, 0.0303, 0.0221,
        0.0662, 0.0522, 0.0201, 0.0408, 0.0380, 0.0120, 0.0410, 0.0093, 0.0147],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,517][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0062, 0.0550, 0.0704, 0.0553, 0.0668, 0.0645, 0.0556, 0.0597, 0.0468,
        0.0569, 0.0601, 0.0647, 0.0533, 0.0639, 0.0502, 0.0554, 0.0566, 0.0587],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,518][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0152, 0.0695, 0.0627, 0.0590, 0.0579, 0.0557, 0.0533, 0.0515, 0.0553,
        0.0556, 0.0558, 0.0577, 0.0543, 0.0592, 0.0590, 0.0571, 0.0590, 0.0622],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:52,519][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0175, 0.0750, 0.0627, 0.0745, 0.0515, 0.0534, 0.0484, 0.0502, 0.0474,
        0.0571, 0.0524, 0.0434, 0.0741, 0.0508, 0.0462, 0.0555, 0.0402, 0.0502,
        0.0495], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,522][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.4882, 0.0393, 0.0273, 0.0379, 0.0269, 0.0327, 0.0243, 0.0253, 0.0216,
        0.0314, 0.0289, 0.0189, 0.0338, 0.0307, 0.0218, 0.0329, 0.0258, 0.0305,
        0.0218], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,529][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0491, 0.0760, 0.0620, 0.0651, 0.0430, 0.0639, 0.0626, 0.0619, 0.0565,
        0.0574, 0.0478, 0.0311, 0.0470, 0.0485, 0.0514, 0.0538, 0.0541, 0.0452,
        0.0233], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,530][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0124, 0.0701, 0.0540, 0.0603, 0.0575, 0.0510, 0.0527, 0.0593, 0.0569,
        0.0575, 0.0575, 0.0591, 0.0505, 0.0536, 0.0520, 0.0556, 0.0502, 0.0491,
        0.0406], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,531][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.6220, 0.0430, 0.0426, 0.0329, 0.0332, 0.0148, 0.0164, 0.0108, 0.0151,
        0.0232, 0.0195, 0.0131, 0.0277, 0.0245, 0.0109, 0.0183, 0.0103, 0.0134,
        0.0083], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,532][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0052, 0.0326, 0.0751, 0.0312, 0.0718, 0.0451, 0.0804, 0.0535, 0.0531,
        0.0319, 0.0312, 0.0801, 0.0254, 0.0596, 0.0743, 0.0326, 0.0625, 0.0479,
        0.1067], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,536][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1438, 0.0734, 0.0453, 0.0429, 0.0435, 0.0390, 0.0329, 0.0433, 0.0359,
        0.0551, 0.0632, 0.0366, 0.0699, 0.0433, 0.0355, 0.0537, 0.0443, 0.0605,
        0.0380], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,542][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.3928, 0.4089, 0.0978, 0.0165, 0.0048, 0.0022, 0.0125, 0.0039, 0.0180,
        0.0050, 0.0043, 0.0041, 0.0019, 0.0018, 0.0040, 0.0036, 0.0079, 0.0022,
        0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,543][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0047, 0.0704, 0.1021, 0.0687, 0.1218, 0.0417, 0.0516, 0.0326, 0.0364,
        0.0449, 0.0416, 0.0573, 0.0404, 0.0845, 0.0324, 0.0342, 0.0436, 0.0293,
        0.0618], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,544][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.4453, 0.0215, 0.0130, 0.0617, 0.0415, 0.0403, 0.0202, 0.0292, 0.0208,
        0.0678, 0.0518, 0.0201, 0.0424, 0.0390, 0.0114, 0.0410, 0.0090, 0.0143,
        0.0098], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,545][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0044, 0.0519, 0.0664, 0.0534, 0.0617, 0.0632, 0.0494, 0.0578, 0.0454,
        0.0556, 0.0576, 0.0577, 0.0507, 0.0589, 0.0486, 0.0542, 0.0525, 0.0558,
        0.0548], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,547][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0135, 0.0661, 0.0597, 0.0555, 0.0550, 0.0527, 0.0503, 0.0488, 0.0526,
        0.0521, 0.0524, 0.0547, 0.0508, 0.0561, 0.0557, 0.0534, 0.0555, 0.0582,
        0.0568], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:52,555][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0306, 0.0659, 0.0593, 0.0593, 0.0410, 0.0607, 0.0544, 0.0358, 0.0396,
        0.0457, 0.0538, 0.0464, 0.0626, 0.0398, 0.0508, 0.0444, 0.0485, 0.0522,
        0.0629, 0.0462], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,557][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4503, 0.0373, 0.0271, 0.0381, 0.0271, 0.0328, 0.0245, 0.0257, 0.0223,
        0.0326, 0.0296, 0.0191, 0.0337, 0.0308, 0.0220, 0.0337, 0.0263, 0.0311,
        0.0216, 0.0343], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,558][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0442, 0.0744, 0.0594, 0.0675, 0.0413, 0.0645, 0.0622, 0.0594, 0.0547,
        0.0528, 0.0453, 0.0297, 0.0451, 0.0443, 0.0490, 0.0497, 0.0514, 0.0440,
        0.0226, 0.0386], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,559][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0134, 0.0647, 0.0514, 0.0563, 0.0547, 0.0483, 0.0500, 0.0558, 0.0540,
        0.0544, 0.0543, 0.0558, 0.0480, 0.0519, 0.0496, 0.0529, 0.0485, 0.0467,
        0.0394, 0.0498], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,560][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.6159, 0.0427, 0.0420, 0.0292, 0.0308, 0.0157, 0.0184, 0.0119, 0.0163,
        0.0211, 0.0195, 0.0139, 0.0276, 0.0228, 0.0118, 0.0170, 0.0111, 0.0138,
        0.0090, 0.0095], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,565][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0067, 0.0302, 0.0789, 0.0332, 0.0733, 0.0478, 0.0670, 0.0428, 0.0614,
        0.0288, 0.0372, 0.0650, 0.0234, 0.0564, 0.0587, 0.0288, 0.0634, 0.0545,
        0.1089, 0.0337], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,570][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1145, 0.0672, 0.0522, 0.0379, 0.0464, 0.0393, 0.0332, 0.0401, 0.0377,
        0.0454, 0.0641, 0.0421, 0.0607, 0.0456, 0.0387, 0.0445, 0.0440, 0.0603,
        0.0410, 0.0454], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,571][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4968, 0.2695, 0.1262, 0.0088, 0.0041, 0.0042, 0.0155, 0.0046, 0.0157,
        0.0039, 0.0051, 0.0039, 0.0024, 0.0027, 0.0060, 0.0028, 0.0106, 0.0026,
        0.0106, 0.0039], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,572][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0049, 0.0561, 0.1156, 0.0534, 0.1220, 0.0453, 0.0462, 0.0315, 0.0404,
        0.0305, 0.0418, 0.0584, 0.0277, 0.0889, 0.0326, 0.0255, 0.0503, 0.0316,
        0.0787, 0.0187], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,573][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3692, 0.0266, 0.0164, 0.0625, 0.0433, 0.0449, 0.0242, 0.0329, 0.0246,
        0.0641, 0.0525, 0.0234, 0.0430, 0.0403, 0.0145, 0.0421, 0.0121, 0.0178,
        0.0141, 0.0317], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,577][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0050, 0.0502, 0.0641, 0.0511, 0.0595, 0.0602, 0.0516, 0.0542, 0.0428,
        0.0519, 0.0529, 0.0589, 0.0479, 0.0557, 0.0449, 0.0502, 0.0506, 0.0513,
        0.0487, 0.0485], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,582][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0133, 0.0629, 0.0560, 0.0527, 0.0516, 0.0495, 0.0476, 0.0459, 0.0490,
        0.0496, 0.0496, 0.0514, 0.0483, 0.0525, 0.0523, 0.0509, 0.0526, 0.0551,
        0.0534, 0.0556], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:52,636][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:52,636][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,637][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,638][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,638][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,639][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,640][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,641][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,642][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,642][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,643][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,644][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,644][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:52,645][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,646][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0515, 0.9485], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,647][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9239, 0.0761], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,647][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6912, 0.3088], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,648][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3287, 0.6713], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,649][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0868, 0.9132], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,649][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9896, 0.0104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,650][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8620, 0.1380], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,656][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1639, 0.8361], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,658][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1522, 0.8478], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,659][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0511, 0.9489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,660][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9668, 0.0332], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:52,660][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0007, 0.3973, 0.6020], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,661][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0237, 0.4713, 0.5051], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,665][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.1749, 0.7763, 0.0488], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,670][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1590, 0.6353, 0.2057], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,671][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0012, 0.9787, 0.0201], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,672][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0380, 0.4666, 0.4954], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,673][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.5567, 0.4287, 0.0146], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,673][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.1043, 0.0980, 0.7977], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,676][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0961, 0.4592, 0.4447], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,683][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0731, 0.5051, 0.4219], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,684][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0209, 0.5462, 0.4329], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,684][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.9645, 0.0258, 0.0097], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:52,685][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([3.2673e-04, 2.8570e-01, 4.3497e-01, 2.7900e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,686][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0089, 0.2475, 0.5110, 0.2327], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,688][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0316, 0.7176, 0.2474, 0.0034], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,695][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1818, 0.4587, 0.3072, 0.0522], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,696][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0052, 0.8948, 0.0984, 0.0016], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,697][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0184, 0.2946, 0.4330, 0.2540], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,698][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5709, 0.3276, 0.0973, 0.0041], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,698][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1970, 0.1753, 0.5844, 0.0433], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,703][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0580, 0.3773, 0.3713, 0.1933], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,708][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0479, 0.3514, 0.3098, 0.2909], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,709][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0144, 0.3750, 0.2949, 0.3157], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,709][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8938, 0.0578, 0.0177, 0.0307], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:52,710][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0003, 0.2077, 0.3035, 0.2172, 0.2712], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,711][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0083, 0.2242, 0.3285, 0.2063, 0.2327], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,715][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0033, 0.8235, 0.1713, 0.0011, 0.0008], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,720][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0738, 0.5216, 0.2126, 0.1174, 0.0746], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,721][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([4.2775e-05, 9.6087e-01, 3.8406e-02, 5.6508e-04, 1.2024e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,722][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0136, 0.2282, 0.3169, 0.1899, 0.2514], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,723][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0482, 0.7769, 0.1595, 0.0113, 0.0041], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,723][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0509, 0.1042, 0.6994, 0.0653, 0.0801], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,728][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0433, 0.2859, 0.2794, 0.1549, 0.2365], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,733][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0403, 0.2732, 0.2461, 0.2309, 0.2094], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,734][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0099, 0.2905, 0.2283, 0.2456, 0.2258], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,734][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.8859, 0.0435, 0.0259, 0.0308, 0.0140], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:52,735][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([2.0136e-04, 1.7185e-01, 2.6023e-01, 1.7342e-01, 2.2160e-01, 1.7270e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,736][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0071, 0.1693, 0.2493, 0.1651, 0.2041, 0.2052], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,740][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0490, 0.7210, 0.2153, 0.0039, 0.0028, 0.0080], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,745][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0760, 0.4352, 0.2462, 0.0864, 0.1043, 0.0519], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,746][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0064, 0.8724, 0.1135, 0.0020, 0.0016, 0.0041], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,747][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0142, 0.1811, 0.2291, 0.1588, 0.2228, 0.1941], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,748][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.4825, 0.4136, 0.0653, 0.0152, 0.0115, 0.0118], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,749][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0578, 0.1045, 0.5648, 0.0628, 0.0868, 0.1233], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,753][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0402, 0.2416, 0.2434, 0.1342, 0.2081, 0.1325], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,758][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0318, 0.2258, 0.1942, 0.1904, 0.1760, 0.1818], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,759][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0082, 0.2426, 0.1894, 0.2035, 0.1863, 0.1699], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,760][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.9313, 0.0313, 0.0085, 0.0125, 0.0014, 0.0149], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:52,760][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([1.9386e-04, 1.4715e-01, 2.1450e-01, 1.4889e-01, 1.8388e-01, 1.4367e-01,
        1.6171e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,761][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0051, 0.1377, 0.2113, 0.1452, 0.1640, 0.1725, 0.1642],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,765][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0150, 0.7525, 0.2126, 0.0057, 0.0020, 0.0107, 0.0016],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,771][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0536, 0.2379, 0.3017, 0.0916, 0.1375, 0.1394, 0.0385],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,772][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([6.0672e-04, 9.1848e-01, 7.6242e-02, 1.5233e-03, 5.3942e-04, 2.1591e-03,
        4.5055e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,772][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0105, 0.1317, 0.1980, 0.1244, 0.1825, 0.1712, 0.1817],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,773][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.2205, 0.6418, 0.0492, 0.0184, 0.0037, 0.0519, 0.0144],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,774][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0175, 0.0895, 0.5597, 0.0634, 0.0874, 0.1758, 0.0068],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,778][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0286, 0.2073, 0.2061, 0.1137, 0.1771, 0.1179, 0.1493],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,784][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0267, 0.1880, 0.1672, 0.1587, 0.1452, 0.1594, 0.1548],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,785][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0068, 0.2093, 0.1648, 0.1756, 0.1618, 0.1455, 0.1363],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,785][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.9475, 0.0139, 0.0148, 0.0082, 0.0029, 0.0082, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:52,786][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([1.4279e-04, 1.3127e-01, 1.9014e-01, 1.2872e-01, 1.5952e-01, 1.3214e-01,
        1.4491e-01, 1.1315e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,787][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0040, 0.1181, 0.1991, 0.1153, 0.1431, 0.1446, 0.1531, 0.1227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,789][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([7.0750e-03, 7.0626e-01, 2.6531e-01, 5.2060e-03, 3.2042e-03, 1.0425e-02,
        2.1769e-03, 3.4175e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,795][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0509, 0.1900, 0.2633, 0.0801, 0.1328, 0.1704, 0.0770, 0.0357],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,797][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([5.3068e-04, 8.5574e-01, 1.3168e-01, 2.7621e-03, 1.4638e-03, 5.3286e-03,
        2.3164e-03, 1.8588e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,798][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0093, 0.1198, 0.1812, 0.1089, 0.1513, 0.1395, 0.1646, 0.1254],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,799][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.0590, 0.7413, 0.0648, 0.0118, 0.0094, 0.0406, 0.0667, 0.0063],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,800][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0346, 0.0707, 0.4890, 0.0577, 0.0643, 0.2434, 0.0336, 0.0068],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,800][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0249, 0.1885, 0.1854, 0.1015, 0.1603, 0.1048, 0.1395, 0.0951],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,805][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0230, 0.1642, 0.1447, 0.1359, 0.1270, 0.1376, 0.1380, 0.1297],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,810][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0058, 0.1874, 0.1458, 0.1560, 0.1430, 0.1278, 0.1186, 0.1155],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,811][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.8833, 0.0342, 0.0105, 0.0275, 0.0041, 0.0228, 0.0055, 0.0121],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:52,812][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([1.4139e-04, 1.1344e-01, 1.6836e-01, 1.1288e-01, 1.4272e-01, 1.1166e-01,
        1.2298e-01, 1.0057e-01, 1.2725e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,812][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0034, 0.1085, 0.1763, 0.1142, 0.1200, 0.1184, 0.1343, 0.1204, 0.1045],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,813][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([1.5722e-02, 7.9976e-01, 1.6433e-01, 4.3939e-03, 1.5406e-03, 1.0363e-02,
        2.3867e-03, 3.0860e-04, 1.1916e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,818][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0296, 0.1608, 0.1068, 0.0673, 0.0841, 0.2143, 0.1596, 0.0839, 0.0936],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,823][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([1.0374e-03, 8.6149e-01, 1.2997e-01, 1.6704e-03, 1.2973e-03, 2.8316e-03,
        1.1087e-03, 2.9436e-04, 2.9282e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,824][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0069, 0.1075, 0.1513, 0.0978, 0.1324, 0.1217, 0.1472, 0.1188, 0.1164],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,825][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.1162, 0.6315, 0.0687, 0.0141, 0.0052, 0.0605, 0.0738, 0.0138, 0.0163],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,825][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0215, 0.1039, 0.4881, 0.0794, 0.1187, 0.1520, 0.0085, 0.0100, 0.0178],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,826][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0229, 0.1671, 0.1659, 0.0899, 0.1429, 0.0931, 0.1235, 0.0851, 0.1096],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,831][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0201, 0.1453, 0.1285, 0.1197, 0.1137, 0.1227, 0.1201, 0.1150, 0.1150],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,836][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0056, 0.1662, 0.1294, 0.1382, 0.1270, 0.1137, 0.1055, 0.1033, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,837][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.8706, 0.0412, 0.0200, 0.0196, 0.0040, 0.0164, 0.0061, 0.0040, 0.0180],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:52,837][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.2095e-04, 1.0061e-01, 1.4932e-01, 9.8974e-02, 1.2688e-01, 1.0355e-01,
        1.1604e-01, 9.1337e-02, 1.1837e-01, 9.4792e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,838][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0031, 0.0843, 0.1537, 0.0819, 0.1221, 0.1200, 0.1198, 0.1021, 0.1133,
        0.0996], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,839][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2077, 0.6041, 0.1371, 0.0081, 0.0051, 0.0244, 0.0040, 0.0017, 0.0049,
        0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,844][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0504, 0.1771, 0.2120, 0.0438, 0.0970, 0.1226, 0.0996, 0.0586, 0.1025,
        0.0364], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,849][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0202, 0.8149, 0.1416, 0.0037, 0.0020, 0.0074, 0.0052, 0.0009, 0.0017,
        0.0024], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,850][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0065, 0.0928, 0.1346, 0.0831, 0.1249, 0.1100, 0.1287, 0.1040, 0.1205,
        0.0948], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,850][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.6973, 0.1869, 0.0153, 0.0043, 0.0028, 0.0170, 0.0277, 0.0046, 0.0330,
        0.0109], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,851][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0800, 0.0683, 0.3997, 0.0422, 0.1089, 0.1989, 0.0108, 0.0098, 0.0442,
        0.0372], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,852][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0230, 0.1535, 0.1501, 0.0834, 0.1306, 0.0858, 0.1124, 0.0789, 0.1018,
        0.0806], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,857][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0189, 0.1277, 0.1134, 0.1059, 0.1003, 0.1074, 0.1090, 0.1049, 0.1079,
        0.1047], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,862][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0056, 0.1479, 0.1158, 0.1230, 0.1129, 0.1020, 0.0942, 0.0920, 0.0990,
        0.1076], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,863][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.9182, 0.0256, 0.0083, 0.0119, 0.0014, 0.0063, 0.0021, 0.0029, 0.0051,
        0.0181], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:52,863][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.0303e-04, 9.6548e-02, 1.3585e-01, 9.5605e-02, 1.1656e-01, 9.4266e-02,
        1.0345e-01, 8.4881e-02, 1.0628e-01, 9.1532e-02, 7.4926e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,864][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0031, 0.0881, 0.1354, 0.0847, 0.1119, 0.1111, 0.1051, 0.0969, 0.0963,
        0.0992, 0.0682], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,865][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0455, 0.7021, 0.2028, 0.0109, 0.0058, 0.0197, 0.0034, 0.0012, 0.0036,
        0.0033, 0.0017], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,870][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0496, 0.1328, 0.2358, 0.0401, 0.1006, 0.1296, 0.1214, 0.0489, 0.0785,
        0.0371, 0.0258], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,875][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([4.5404e-03, 8.2283e-01, 1.5289e-01, 2.5783e-03, 2.0720e-03, 6.0944e-03,
        3.7017e-03, 7.2256e-04, 1.6065e-03, 2.3233e-03, 6.3841e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,876][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0065, 0.0868, 0.1197, 0.0779, 0.1129, 0.0981, 0.1157, 0.0973, 0.1061,
        0.0950, 0.0840], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,876][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2835, 0.4550, 0.0331, 0.0132, 0.0061, 0.0424, 0.0507, 0.0122, 0.0540,
        0.0426, 0.0072], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,877][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1111, 0.1065, 0.3591, 0.0629, 0.0763, 0.1596, 0.0083, 0.0117, 0.0130,
        0.0513, 0.0402], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,878][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0203, 0.1451, 0.1408, 0.0784, 0.1221, 0.0790, 0.1042, 0.0738, 0.0952,
        0.0756, 0.0654], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,883][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0167, 0.1177, 0.1026, 0.0969, 0.0910, 0.0983, 0.0980, 0.0946, 0.0975,
        0.0957, 0.0909], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,888][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0051, 0.1336, 0.1039, 0.1106, 0.1014, 0.0910, 0.0842, 0.0826, 0.0891,
        0.0972, 0.1012], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,889][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.8436, 0.0482, 0.0127, 0.0183, 0.0022, 0.0102, 0.0031, 0.0045, 0.0056,
        0.0186, 0.0331], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:52,889][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([9.5246e-05, 8.3197e-02, 1.2520e-01, 8.4339e-02, 1.0968e-01, 8.3359e-02,
        9.5685e-02, 7.6103e-02, 9.8092e-02, 8.0457e-02, 6.7251e-02, 9.6545e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,890][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0027, 0.0804, 0.1292, 0.0823, 0.1081, 0.0883, 0.0941, 0.0890, 0.0925,
        0.0918, 0.0695, 0.0721], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,891][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([1.5152e-02, 7.0019e-01, 2.4748e-01, 5.6776e-03, 7.6381e-03, 1.5974e-02,
        1.4313e-03, 6.3080e-04, 1.5722e-03, 1.8516e-03, 1.7342e-03, 6.6889e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,896][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0188, 0.1672, 0.2275, 0.0858, 0.0964, 0.1136, 0.0465, 0.0441, 0.0931,
        0.0342, 0.0449, 0.0280], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,901][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([6.9124e-04, 8.4677e-01, 1.4341e-01, 1.3623e-03, 1.2377e-03, 3.1280e-03,
        1.2310e-03, 1.9585e-04, 5.9153e-04, 8.1136e-04, 3.3699e-04, 2.3540e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,902][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0052, 0.0791, 0.1120, 0.0695, 0.1067, 0.0874, 0.1071, 0.0858, 0.0947,
        0.0837, 0.0776, 0.0911], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,903][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.1427, 0.6058, 0.0584, 0.0124, 0.0091, 0.0353, 0.0384, 0.0087, 0.0547,
        0.0251, 0.0059, 0.0035], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,903][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0232, 0.0397, 0.6242, 0.0443, 0.0506, 0.1165, 0.0082, 0.0088, 0.0153,
        0.0353, 0.0255, 0.0083], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,904][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0191, 0.1308, 0.1298, 0.0712, 0.1109, 0.0735, 0.0943, 0.0667, 0.0852,
        0.0676, 0.0606, 0.0902], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,909][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0136, 0.1071, 0.0956, 0.0892, 0.0837, 0.0922, 0.0900, 0.0892, 0.0905,
        0.0881, 0.0842, 0.0765], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,914][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0045, 0.1209, 0.0948, 0.1013, 0.0933, 0.0828, 0.0773, 0.0758, 0.0817,
        0.0885, 0.0917, 0.0876], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,915][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.8931, 0.0253, 0.0107, 0.0094, 0.0027, 0.0080, 0.0023, 0.0031, 0.0040,
        0.0131, 0.0112, 0.0171], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:52,916][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([6.9860e-05, 7.7368e-02, 1.1931e-01, 7.5890e-02, 1.0031e-01, 7.9137e-02,
        9.2472e-02, 7.2573e-02, 9.3763e-02, 7.4654e-02, 6.2634e-02, 9.1022e-02,
        6.0796e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,916][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0020, 0.0646, 0.1299, 0.0629, 0.0997, 0.0986, 0.0990, 0.0835, 0.0895,
        0.0801, 0.0645, 0.0743, 0.0512], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,917][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([8.3172e-03, 7.8052e-01, 1.7860e-01, 2.8730e-03, 2.7113e-03, 1.4557e-02,
        3.3676e-03, 6.3151e-04, 3.0220e-03, 1.7783e-03, 2.2520e-03, 1.0209e-03,
        3.5223e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,922][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0179, 0.1157, 0.3000, 0.0337, 0.1113, 0.0804, 0.1120, 0.0584, 0.0641,
        0.0309, 0.0253, 0.0444, 0.0057], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,927][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([2.7701e-04, 8.6336e-01, 1.2727e-01, 7.4522e-04, 6.5044e-04, 2.6492e-03,
        1.6412e-03, 3.3524e-04, 9.2268e-04, 1.0167e-03, 4.4207e-04, 5.9787e-04,
        9.2583e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,928][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0046, 0.0681, 0.1052, 0.0618, 0.0967, 0.0865, 0.1002, 0.0822, 0.0936,
        0.0767, 0.0729, 0.0949, 0.0567], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,929][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.4678, 0.3758, 0.0324, 0.0059, 0.0032, 0.0174, 0.0307, 0.0106, 0.0296,
        0.0118, 0.0052, 0.0076, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,930][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0196, 0.0632, 0.6174, 0.0404, 0.0411, 0.0613, 0.0145, 0.0143, 0.0076,
        0.0386, 0.0543, 0.0127, 0.0149], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,930][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0182, 0.1257, 0.1196, 0.0665, 0.1034, 0.0678, 0.0884, 0.0637, 0.0818,
        0.0649, 0.0572, 0.0884, 0.0544], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,935][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0131, 0.1000, 0.0869, 0.0816, 0.0763, 0.0831, 0.0846, 0.0807, 0.0835,
        0.0810, 0.0756, 0.0745, 0.0790], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,940][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0041, 0.1136, 0.0890, 0.0929, 0.0856, 0.0779, 0.0721, 0.0706, 0.0757,
        0.0813, 0.0846, 0.0819, 0.0706], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,941][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.7755, 0.0478, 0.0188, 0.0204, 0.0052, 0.0118, 0.0036, 0.0054, 0.0066,
        0.0208, 0.0179, 0.0307, 0.0355], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:52,942][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0001, 0.0726, 0.1040, 0.0740, 0.0921, 0.0732, 0.0806, 0.0655, 0.0841,
        0.0698, 0.0592, 0.0835, 0.0570, 0.0845], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,943][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0028, 0.0765, 0.1066, 0.0690, 0.0762, 0.0820, 0.0876, 0.0777, 0.0745,
        0.0756, 0.0611, 0.0697, 0.0555, 0.0852], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,943][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([1.1654e-02, 7.8183e-01, 1.8817e-01, 2.6317e-03, 3.5206e-03, 5.7126e-03,
        1.6037e-03, 4.2260e-04, 1.5190e-03, 1.0380e-03, 8.6831e-04, 5.8607e-04,
        2.0505e-04, 2.3921e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,948][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0183, 0.1905, 0.1157, 0.0668, 0.0558, 0.1038, 0.0760, 0.0565, 0.1071,
        0.0755, 0.0478, 0.0412, 0.0275, 0.0177], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,953][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([3.1543e-04, 9.1288e-01, 7.7731e-02, 1.2387e-03, 3.9999e-04, 2.9184e-03,
        1.2761e-03, 2.7989e-04, 9.9429e-04, 1.0499e-03, 3.8586e-04, 4.0346e-04,
        1.0524e-04, 1.8380e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,956][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0040, 0.0692, 0.0974, 0.0580, 0.0778, 0.0774, 0.0978, 0.0755, 0.0865,
        0.0677, 0.0659, 0.0941, 0.0543, 0.0747], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,957][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.2433, 0.5954, 0.0587, 0.0080, 0.0025, 0.0209, 0.0211, 0.0055, 0.0226,
        0.0102, 0.0047, 0.0047, 0.0018, 0.0007], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,958][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0168, 0.0582, 0.4873, 0.0573, 0.0698, 0.1399, 0.0092, 0.0079, 0.0104,
        0.0356, 0.0441, 0.0157, 0.0273, 0.0206], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,959][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0141, 0.1154, 0.1126, 0.0628, 0.0974, 0.0656, 0.0831, 0.0588, 0.0760,
        0.0609, 0.0530, 0.0827, 0.0522, 0.0655], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,961][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0135, 0.0909, 0.0827, 0.0768, 0.0698, 0.0780, 0.0766, 0.0751, 0.0767,
        0.0752, 0.0722, 0.0695, 0.0746, 0.0684], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,967][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0036, 0.1066, 0.0826, 0.0874, 0.0800, 0.0725, 0.0667, 0.0649, 0.0697,
        0.0762, 0.0791, 0.0753, 0.0658, 0.0697], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,969][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.8998, 0.0161, 0.0049, 0.0136, 0.0043, 0.0081, 0.0020, 0.0049, 0.0023,
        0.0075, 0.0076, 0.0087, 0.0100, 0.0102], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:52,970][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([9.1361e-05, 6.7322e-02, 9.8730e-02, 6.8148e-02, 8.4986e-02, 6.4888e-02,
        7.5929e-02, 6.0324e-02, 7.7544e-02, 6.4233e-02, 5.4427e-02, 7.8615e-02,
        5.1708e-02, 7.6558e-02, 7.6496e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,971][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0025, 0.0659, 0.0935, 0.0677, 0.0779, 0.0678, 0.0772, 0.0703, 0.0664,
        0.0721, 0.0585, 0.0668, 0.0522, 0.0820, 0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,972][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([1.2365e-02, 7.3894e-01, 2.3057e-01, 2.3831e-03, 3.4899e-03, 5.3862e-03,
        1.4173e-03, 4.4675e-04, 1.2762e-03, 1.1838e-03, 9.5280e-04, 6.2066e-04,
        2.7915e-04, 3.1721e-04, 3.6807e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,976][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0204, 0.0954, 0.1537, 0.0461, 0.1066, 0.1009, 0.0532, 0.0460, 0.0898,
        0.0572, 0.0703, 0.0522, 0.0261, 0.0520, 0.0302], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,980][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([8.0318e-04, 8.7691e-01, 1.1121e-01, 2.1077e-03, 1.4166e-03, 2.8388e-03,
        1.6247e-03, 2.0992e-04, 8.1560e-04, 6.8386e-04, 4.3651e-04, 5.3194e-04,
        8.7425e-05, 6.3643e-05, 2.5253e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,982][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0044, 0.0619, 0.0840, 0.0580, 0.0818, 0.0697, 0.0860, 0.0693, 0.0726,
        0.0664, 0.0646, 0.0835, 0.0524, 0.0739, 0.0716], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,983][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.2260, 0.5257, 0.1147, 0.0068, 0.0074, 0.0176, 0.0268, 0.0085, 0.0256,
        0.0158, 0.0081, 0.0067, 0.0025, 0.0027, 0.0051], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,984][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0062, 0.1244, 0.2234, 0.1138, 0.0718, 0.1492, 0.0119, 0.0150, 0.0058,
        0.0829, 0.1038, 0.0173, 0.0423, 0.0270, 0.0050], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,985][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0143, 0.1059, 0.1068, 0.0585, 0.0930, 0.0593, 0.0778, 0.0539, 0.0699,
        0.0551, 0.0493, 0.0764, 0.0483, 0.0636, 0.0678], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,989][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0133, 0.0847, 0.0766, 0.0692, 0.0658, 0.0724, 0.0713, 0.0686, 0.0716,
        0.0694, 0.0662, 0.0643, 0.0691, 0.0655, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,994][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0032, 0.1014, 0.0783, 0.0824, 0.0758, 0.0682, 0.0630, 0.0613, 0.0661,
        0.0719, 0.0745, 0.0716, 0.0616, 0.0658, 0.0550], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,995][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.8431, 0.0228, 0.0051, 0.0148, 0.0028, 0.0112, 0.0035, 0.0037, 0.0063,
        0.0147, 0.0152, 0.0121, 0.0201, 0.0104, 0.0141], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:52,996][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.6822e-05, 6.1960e-02, 9.1708e-02, 6.0313e-02, 7.7705e-02, 6.3790e-02,
        7.1653e-02, 5.6551e-02, 7.3193e-02, 5.8254e-02, 5.1466e-02, 7.2749e-02,
        4.9476e-02, 7.2281e-02, 7.5861e-02, 6.2955e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,997][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0021, 0.0524, 0.0932, 0.0507, 0.0756, 0.0734, 0.0728, 0.0632, 0.0700,
        0.0610, 0.0561, 0.0593, 0.0437, 0.0777, 0.0811, 0.0675],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:52,999][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3480, 0.4484, 0.1370, 0.0078, 0.0071, 0.0213, 0.0046, 0.0017, 0.0051,
        0.0028, 0.0046, 0.0024, 0.0008, 0.0011, 0.0031, 0.0042],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,006][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0257, 0.1392, 0.1640, 0.0388, 0.0833, 0.1040, 0.0803, 0.0497, 0.0871,
        0.0309, 0.0333, 0.0562, 0.0185, 0.0325, 0.0352, 0.0213],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,007][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.5263e-02, 7.6108e-01, 1.7928e-01, 3.8047e-03, 2.4076e-03, 8.1704e-03,
        6.1623e-03, 8.1480e-04, 2.1311e-03, 2.6102e-03, 2.0973e-03, 2.1817e-03,
        4.0460e-04, 3.1960e-04, 1.3208e-03, 1.9538e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,008][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0039, 0.0568, 0.0833, 0.0515, 0.0774, 0.0675, 0.0789, 0.0638, 0.0738,
        0.0588, 0.0602, 0.0754, 0.0480, 0.0714, 0.0723, 0.0570],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,009][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.2306e-01, 9.8671e-02, 1.0247e-02, 2.4484e-03, 1.6915e-03, 8.4239e-03,
        1.3568e-02, 2.8478e-03, 1.9946e-02, 5.2399e-03, 2.4396e-03, 2.5763e-03,
        8.3389e-04, 7.2631e-04, 3.8338e-03, 3.4433e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,010][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0410, 0.0553, 0.2933, 0.0413, 0.0919, 0.1766, 0.0119, 0.0100, 0.0401,
        0.0396, 0.0744, 0.0285, 0.0310, 0.0362, 0.0088, 0.0199],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,015][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0154, 0.1010, 0.0978, 0.0567, 0.0859, 0.0572, 0.0723, 0.0523, 0.0659,
        0.0532, 0.0477, 0.0722, 0.0459, 0.0600, 0.0655, 0.0509],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,020][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0126, 0.0780, 0.0692, 0.0649, 0.0613, 0.0666, 0.0673, 0.0648, 0.0667,
        0.0646, 0.0618, 0.0598, 0.0644, 0.0613, 0.0691, 0.0677],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,021][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0034, 0.0948, 0.0739, 0.0776, 0.0715, 0.0640, 0.0588, 0.0572, 0.0620,
        0.0675, 0.0702, 0.0666, 0.0586, 0.0621, 0.0515, 0.0603],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,022][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8429, 0.0210, 0.0075, 0.0130, 0.0023, 0.0054, 0.0022, 0.0028, 0.0047,
        0.0141, 0.0109, 0.0156, 0.0152, 0.0095, 0.0112, 0.0217],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,023][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([9.5069e-05, 5.8520e-02, 8.5246e-02, 5.8831e-02, 7.4643e-02, 5.8915e-02,
        6.5777e-02, 5.3338e-02, 6.6649e-02, 5.5869e-02, 4.7993e-02, 6.6450e-02,
        4.6895e-02, 6.7061e-02, 6.8100e-02, 5.9794e-02, 6.5824e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,026][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0026, 0.0533, 0.0825, 0.0568, 0.0715, 0.0632, 0.0638, 0.0609, 0.0616,
        0.0617, 0.0522, 0.0543, 0.0489, 0.0741, 0.0673, 0.0677, 0.0574],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,033][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0929, 0.5880, 0.2616, 0.0070, 0.0071, 0.0177, 0.0043, 0.0013, 0.0028,
        0.0028, 0.0025, 0.0023, 0.0007, 0.0007, 0.0012, 0.0033, 0.0039],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,034][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0134, 0.1380, 0.1234, 0.0467, 0.0770, 0.1212, 0.0688, 0.0382, 0.0616,
        0.0515, 0.0577, 0.0338, 0.0353, 0.0327, 0.0403, 0.0387, 0.0215],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,035][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([3.8889e-03, 7.8633e-01, 1.9158e-01, 4.0846e-03, 2.4115e-03, 4.1635e-03,
        2.1858e-03, 4.0052e-04, 5.7384e-04, 1.1874e-03, 6.2250e-04, 7.9351e-04,
        1.5096e-04, 1.6981e-04, 2.7006e-04, 7.3117e-04, 4.5868e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,036][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0034, 0.0528, 0.0748, 0.0460, 0.0726, 0.0621, 0.0733, 0.0635, 0.0668,
        0.0557, 0.0554, 0.0719, 0.0462, 0.0685, 0.0694, 0.0547, 0.0628],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,038][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.2143, 0.4659, 0.0920, 0.0149, 0.0095, 0.0381, 0.0308, 0.0180, 0.0191,
        0.0279, 0.0063, 0.0072, 0.0023, 0.0031, 0.0125, 0.0172, 0.0210],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,046][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0164, 0.0657, 0.4458, 0.0476, 0.0796, 0.0855, 0.0109, 0.0103, 0.0302,
        0.0479, 0.0583, 0.0079, 0.0276, 0.0290, 0.0053, 0.0267, 0.0051],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,046][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0140, 0.0936, 0.0953, 0.0540, 0.0837, 0.0544, 0.0698, 0.0488, 0.0622,
        0.0498, 0.0440, 0.0683, 0.0433, 0.0570, 0.0613, 0.0478, 0.0528],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,047][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0123, 0.0724, 0.0640, 0.0597, 0.0569, 0.0623, 0.0632, 0.0612, 0.0617,
        0.0612, 0.0578, 0.0565, 0.0599, 0.0570, 0.0659, 0.0641, 0.0638],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,048][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0033, 0.0880, 0.0684, 0.0725, 0.0667, 0.0595, 0.0551, 0.0541, 0.0586,
        0.0635, 0.0663, 0.0630, 0.0554, 0.0591, 0.0493, 0.0573, 0.0598],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,051][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.7173, 0.0330, 0.0109, 0.0231, 0.0035, 0.0135, 0.0055, 0.0053, 0.0078,
        0.0206, 0.0232, 0.0173, 0.0307, 0.0099, 0.0197, 0.0266, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,058][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0001, 0.0561, 0.0777, 0.0556, 0.0680, 0.0552, 0.0604, 0.0507, 0.0630,
        0.0532, 0.0452, 0.0629, 0.0440, 0.0626, 0.0643, 0.0569, 0.0640, 0.0601],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,059][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0025, 0.0526, 0.0772, 0.0510, 0.0614, 0.0632, 0.0624, 0.0567, 0.0562,
        0.0583, 0.0441, 0.0532, 0.0434, 0.0651, 0.0708, 0.0641, 0.0606, 0.0574],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,060][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2096, 0.4771, 0.2240, 0.0164, 0.0100, 0.0191, 0.0040, 0.0016, 0.0036,
        0.0048, 0.0034, 0.0020, 0.0014, 0.0014, 0.0028, 0.0058, 0.0046, 0.0084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,061][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0263, 0.0894, 0.1421, 0.0348, 0.0878, 0.1155, 0.0859, 0.0482, 0.0710,
        0.0391, 0.0344, 0.0567, 0.0166, 0.0346, 0.0325, 0.0285, 0.0424, 0.0143],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,063][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.0271e-02, 7.1209e-01, 2.4757e-01, 3.8565e-03, 3.4762e-03, 5.6100e-03,
        3.7939e-03, 5.7056e-04, 1.6371e-03, 2.6611e-03, 1.0264e-03, 1.5725e-03,
        2.8609e-04, 3.9026e-04, 7.3903e-04, 1.7326e-03, 1.8221e-03, 8.9231e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,069][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0041, 0.0511, 0.0689, 0.0468, 0.0647, 0.0587, 0.0705, 0.0580, 0.0604,
        0.0556, 0.0509, 0.0660, 0.0429, 0.0594, 0.0618, 0.0542, 0.0676, 0.0584],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,071][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4684, 0.2679, 0.0236, 0.0112, 0.0051, 0.0285, 0.0245, 0.0106, 0.0384,
        0.0257, 0.0079, 0.0094, 0.0027, 0.0016, 0.0106, 0.0145, 0.0433, 0.0061],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,072][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0470, 0.1136, 0.2058, 0.0656, 0.0757, 0.1829, 0.0073, 0.0074, 0.0281,
        0.0400, 0.0439, 0.0227, 0.0340, 0.0325, 0.0089, 0.0210, 0.0552, 0.0085],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,073][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0141, 0.0916, 0.0872, 0.0525, 0.0778, 0.0517, 0.0650, 0.0471, 0.0590,
        0.0489, 0.0429, 0.0651, 0.0420, 0.0543, 0.0586, 0.0469, 0.0516, 0.0436],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,074][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0134, 0.0678, 0.0590, 0.0566, 0.0529, 0.0581, 0.0578, 0.0565, 0.0582,
        0.0570, 0.0543, 0.0524, 0.0562, 0.0530, 0.0603, 0.0597, 0.0618, 0.0651],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,079][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0035, 0.0820, 0.0645, 0.0687, 0.0634, 0.0556, 0.0518, 0.0506, 0.0549,
        0.0598, 0.0623, 0.0590, 0.0523, 0.0558, 0.0462, 0.0536, 0.0558, 0.0603],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,084][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.7092, 0.0297, 0.0128, 0.0176, 0.0027, 0.0063, 0.0034, 0.0042, 0.0046,
        0.0159, 0.0223, 0.0185, 0.0300, 0.0144, 0.0190, 0.0289, 0.0134, 0.0472],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,085][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0001, 0.0509, 0.0734, 0.0513, 0.0651, 0.0499, 0.0560, 0.0464, 0.0596,
        0.0475, 0.0422, 0.0587, 0.0405, 0.0593, 0.0584, 0.0502, 0.0574, 0.0552,
        0.0778], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,086][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0025, 0.0500, 0.0692, 0.0484, 0.0583, 0.0549, 0.0579, 0.0551, 0.0523,
        0.0523, 0.0416, 0.0488, 0.0408, 0.0616, 0.0680, 0.0567, 0.0553, 0.0563,
        0.0701], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,087][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.1036, 0.5006, 0.3301, 0.0059, 0.0112, 0.0114, 0.0024, 0.0012, 0.0026,
        0.0018, 0.0031, 0.0010, 0.0006, 0.0007, 0.0016, 0.0025, 0.0043, 0.0121,
        0.0034], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,091][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0204, 0.1379, 0.1350, 0.0564, 0.0681, 0.0928, 0.0359, 0.0392, 0.0481,
        0.0532, 0.0654, 0.0306, 0.0280, 0.0240, 0.0328, 0.0361, 0.0228, 0.0604,
        0.0130], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,095][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([2.0384e-03, 8.3182e-01, 1.5012e-01, 3.0179e-03, 1.3261e-03, 4.2840e-03,
        1.2837e-03, 1.8873e-04, 7.5177e-04, 1.2183e-03, 4.9329e-04, 2.8129e-04,
        1.0958e-04, 5.6058e-05, 3.1538e-04, 7.1476e-04, 8.3212e-04, 8.9399e-04,
        2.5740e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,097][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0036, 0.0466, 0.0639, 0.0410, 0.0610, 0.0537, 0.0657, 0.0567, 0.0569,
        0.0498, 0.0463, 0.0638, 0.0409, 0.0571, 0.0643, 0.0485, 0.0609, 0.0544,
        0.0651], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,098][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.2757, 0.4585, 0.0354, 0.0138, 0.0043, 0.0371, 0.0255, 0.0147, 0.0319,
        0.0199, 0.0062, 0.0019, 0.0019, 0.0009, 0.0074, 0.0108, 0.0335, 0.0088,
        0.0119], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,099][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0291, 0.0996, 0.3538, 0.0531, 0.0845, 0.1397, 0.0071, 0.0034, 0.0136,
        0.0315, 0.0444, 0.0133, 0.0273, 0.0302, 0.0053, 0.0160, 0.0108, 0.0195,
        0.0180], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,100][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0130, 0.0854, 0.0857, 0.0498, 0.0752, 0.0501, 0.0608, 0.0439, 0.0550,
        0.0456, 0.0407, 0.0589, 0.0399, 0.0494, 0.0538, 0.0435, 0.0479, 0.0418,
        0.0597], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,105][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0111, 0.0626, 0.0572, 0.0533, 0.0506, 0.0553, 0.0577, 0.0547, 0.0558,
        0.0543, 0.0515, 0.0491, 0.0525, 0.0502, 0.0578, 0.0566, 0.0563, 0.0609,
        0.0525], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,109][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0028, 0.0774, 0.0612, 0.0651, 0.0603, 0.0526, 0.0491, 0.0480, 0.0520,
        0.0566, 0.0586, 0.0560, 0.0491, 0.0524, 0.0436, 0.0508, 0.0531, 0.0571,
        0.0543], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,110][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.8894, 0.0175, 0.0071, 0.0104, 0.0034, 0.0050, 0.0014, 0.0038, 0.0016,
        0.0073, 0.0068, 0.0058, 0.0063, 0.0087, 0.0035, 0.0078, 0.0053, 0.0066,
        0.0025], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,111][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.4055e-05, 4.7234e-02, 6.8510e-02, 4.6185e-02, 5.9211e-02, 4.8193e-02,
        5.3982e-02, 4.3264e-02, 5.5661e-02, 4.4178e-02, 3.9886e-02, 5.5122e-02,
        3.8272e-02, 5.5209e-02, 5.7031e-02, 4.7445e-02, 5.5946e-02, 5.3882e-02,
        7.4314e-02, 5.6380e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,112][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0017, 0.0404, 0.0702, 0.0389, 0.0570, 0.0548, 0.0551, 0.0481, 0.0538,
        0.0463, 0.0425, 0.0446, 0.0337, 0.0589, 0.0611, 0.0511, 0.0546, 0.0576,
        0.0783, 0.0514], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,117][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5191, 0.2779, 0.1030, 0.0082, 0.0063, 0.0153, 0.0035, 0.0011, 0.0036,
        0.0020, 0.0035, 0.0016, 0.0006, 0.0008, 0.0020, 0.0028, 0.0078, 0.0204,
        0.0136, 0.0069], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,122][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0184, 0.1316, 0.1579, 0.0348, 0.0764, 0.1013, 0.0769, 0.0445, 0.0694,
        0.0258, 0.0299, 0.0476, 0.0149, 0.0268, 0.0298, 0.0173, 0.0320, 0.0223,
        0.0289, 0.0133], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,123][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([3.8410e-02, 7.0809e-01, 2.0666e-01, 4.9337e-03, 3.2752e-03, 7.6100e-03,
        5.2601e-03, 8.0007e-04, 1.8738e-03, 2.6854e-03, 1.9503e-03, 2.0142e-03,
        3.7281e-04, 3.7538e-04, 1.0714e-03, 1.9051e-03, 3.3558e-03, 3.3100e-03,
        2.3841e-03, 3.6574e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,124][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0030, 0.0445, 0.0637, 0.0399, 0.0593, 0.0522, 0.0620, 0.0501, 0.0571,
        0.0458, 0.0466, 0.0583, 0.0370, 0.0550, 0.0572, 0.0445, 0.0584, 0.0552,
        0.0666, 0.0436], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,125][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.3454e-01, 7.1963e-02, 8.1675e-03, 2.0475e-03, 1.3960e-03, 6.6895e-03,
        8.6814e-03, 2.2877e-03, 1.3430e-02, 3.3063e-03, 2.5961e-03, 2.1412e-03,
        6.5554e-04, 5.4869e-04, 2.3364e-03, 2.2251e-03, 1.4452e-02, 3.4086e-03,
        1.5643e-02, 3.4814e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,130][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0346, 0.0567, 0.2594, 0.0407, 0.0886, 0.1617, 0.0128, 0.0094, 0.0383,
        0.0343, 0.0650, 0.0278, 0.0293, 0.0327, 0.0086, 0.0171, 0.0242, 0.0221,
        0.0179, 0.0188], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,135][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0132, 0.0816, 0.0790, 0.0466, 0.0701, 0.0464, 0.0577, 0.0424, 0.0525,
        0.0433, 0.0390, 0.0582, 0.0375, 0.0487, 0.0517, 0.0418, 0.0461, 0.0399,
        0.0591, 0.0451], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,136][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0104, 0.0603, 0.0535, 0.0502, 0.0477, 0.0521, 0.0524, 0.0507, 0.0518,
        0.0504, 0.0483, 0.0467, 0.0495, 0.0475, 0.0538, 0.0529, 0.0548, 0.0585,
        0.0533, 0.0553], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,137][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0029, 0.0732, 0.0582, 0.0615, 0.0569, 0.0503, 0.0467, 0.0457, 0.0494,
        0.0536, 0.0557, 0.0530, 0.0468, 0.0497, 0.0414, 0.0480, 0.0499, 0.0540,
        0.0510, 0.0522], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,138][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8114, 0.0197, 0.0076, 0.0135, 0.0021, 0.0055, 0.0021, 0.0031, 0.0041,
        0.0130, 0.0110, 0.0134, 0.0145, 0.0078, 0.0088, 0.0188, 0.0077, 0.0124,
        0.0025, 0.0210], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,141][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:53,145][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3693],
        [ 337],
        [1735],
        [ 343],
        [ 374],
        [ 752],
        [ 129],
        [ 918],
        [1970],
        [1187],
        [ 356],
        [ 606],
        [ 427],
        [ 452],
        [1685],
        [ 519],
        [1276],
        [1781],
        [1349],
        [ 702]], device='cuda:0')
[2024-07-24 10:16:53,148][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4029],
        [  956],
        [22530],
        [ 2731],
        [ 5162],
        [ 5400],
        [  937],
        [ 5538],
        [12128],
        [10480],
        [ 7072],
        [ 3348],
        [ 3214],
        [ 6542],
        [ 5534],
        [ 5883],
        [ 8679],
        [13600],
        [13715],
        [ 8115]], device='cuda:0')
[2024-07-24 10:16:53,151][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[25238],
        [26530],
        [37259],
        [38163],
        [37123],
        [37900],
        [37511],
        [35774],
        [36653],
        [37025],
        [35316],
        [36604],
        [36674],
        [35897],
        [36775],
        [36928],
        [36356],
        [35213],
        [36703],
        [36243]], device='cuda:0')
[2024-07-24 10:16:53,152][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[4669],
        [5063],
        [5360],
        [5703],
        [5948],
        [6279],
        [6308],
        [6596],
        [6693],
        [7238],
        [7203],
        [7225],
        [7616],
        [7870],
        [7572],
        [8228],
        [7972],
        [8214],
        [8463],
        [8731]], device='cuda:0')
[2024-07-24 10:16:53,154][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22783],
        [14318],
        [13669],
        [14054],
        [14416],
        [14687],
        [14334],
        [14431],
        [14453],
        [14659],
        [14784],
        [14924],
        [15097],
        [15290],
        [15353],
        [15377],
        [15382],
        [15596],
        [15703],
        [15697]], device='cuda:0')
[2024-07-24 10:16:53,156][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[396],
        [257],
        [316],
        [302],
        [313],
        [328],
        [335],
        [346],
        [345],
        [349],
        [363],
        [372],
        [378],
        [383],
        [383],
        [384],
        [390],
        [403],
        [404],
        [411]], device='cuda:0')
[2024-07-24 10:16:53,160][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26092],
        [23609],
        [20338],
        [20316],
        [18750],
        [16869],
        [15476],
        [15203],
        [14392],
        [16092],
        [15184],
        [14176],
        [16121],
        [15070],
        [12962],
        [14122],
        [13468],
        [13623],
        [13444],
        [13323]], device='cuda:0')
[2024-07-24 10:16:53,163][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19080],
        [ 1909],
        [  948],
        [  829],
        [  988],
        [ 1217],
        [ 1604],
        [ 1518],
        [ 1574],
        [ 1541],
        [ 1422],
        [ 1439],
        [ 1462],
        [ 1519],
        [ 1434],
        [ 1371],
        [ 1417],
        [ 1416],
        [ 1437],
        [ 1397]], device='cuda:0')
[2024-07-24 10:16:53,165][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[10218],
        [11430],
        [ 8557],
        [ 8414],
        [ 8695],
        [ 9610],
        [ 9651],
        [10010],
        [10604],
        [10502],
        [11782],
        [12410],
        [13028],
        [12910],
        [13301],
        [13191],
        [13261],
        [13648],
        [13380],
        [13221]], device='cuda:0')
[2024-07-24 10:16:53,167][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 6676],
        [ 7094],
        [11867],
        [11436],
        [13542],
        [11152],
        [12848],
        [13298],
        [13290],
        [11516],
        [12528],
        [13041],
        [13041],
        [12776],
        [12718],
        [11237],
        [12716],
        [11683],
        [10996],
        [10043]], device='cuda:0')
[2024-07-24 10:16:53,168][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[44127],
        [45443],
        [46328],
        [45796],
        [45410],
        [45568],
        [45603],
        [45638],
        [45491],
        [45433],
        [45034],
        [45113],
        [44873],
        [44446],
        [44870],
        [44927],
        [44757],
        [44442],
        [44393],
        [44544]], device='cuda:0')
[2024-07-24 10:16:53,171][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41374],
        [41490],
        [41428],
        [42470],
        [42639],
        [42548],
        [42207],
        [41767],
        [41548],
        [41434],
        [41271],
        [41024],
        [40612],
        [41089],
        [40871],
        [40888],
        [41152],
        [40969],
        [40891],
        [40385]], device='cuda:0')
[2024-07-24 10:16:53,174][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12522],
        [13148],
        [ 7777],
        [ 9511],
        [10353],
        [ 9433],
        [10031],
        [ 9430],
        [ 9730],
        [10174],
        [ 9789],
        [10332],
        [10187],
        [10380],
        [10385],
        [10720],
        [10362],
        [10322],
        [ 9711],
        [10014]], device='cuda:0')
[2024-07-24 10:16:53,177][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[11128],
        [12097],
        [ 7614],
        [ 6207],
        [ 5067],
        [ 4695],
        [ 4373],
        [ 4249],
        [ 4138],
        [ 4277],
        [ 4138],
        [ 4185],
        [ 4252],
        [ 4137],
        [ 4159],
        [ 4225],
        [ 4216],
        [ 4229],
        [ 4215],
        [ 4330]], device='cuda:0')
[2024-07-24 10:16:53,180][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15997],
        [ 7804],
        [   94],
        [  602],
        [  307],
        [  528],
        [ 1683],
        [  815],
        [  790],
        [  626],
        [  119],
        [ 1235],
        [  598],
        [  403],
        [ 2088],
        [ 1201],
        [  325],
        [  422],
        [  208],
        [  693]], device='cuda:0')
[2024-07-24 10:16:53,181][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 266],
        [1455],
        [1792],
        [1594],
        [1582],
        [1630],
        [1660],
        [1674],
        [1659],
        [1641],
        [1642],
        [1648],
        [1679],
        [1688],
        [1766],
        [1767],
        [1814],
        [1828],
        [1810],
        [1788]], device='cuda:0')
[2024-07-24 10:16:53,183][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[  952],
        [30794],
        [33884],
        [32172],
        [30899],
        [30385],
        [30765],
        [30127],
        [29385],
        [29735],
        [30169],
        [29252],
        [29368],
        [29248],
        [29071],
        [29284],
        [29343],
        [29457],
        [29094],
        [29284]], device='cuda:0')
[2024-07-24 10:16:53,185][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[19260],
        [16244],
        [ 7589],
        [ 5576],
        [ 6790],
        [ 5778],
        [ 6017],
        [ 5373],
        [ 6672],
        [ 5475],
        [ 5768],
        [ 5434],
        [ 6452],
        [ 6386],
        [ 5834],
        [ 4113],
        [ 4607],
        [ 3921],
        [ 3728],
        [ 2679]], device='cuda:0')
[2024-07-24 10:16:53,188][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8011],
        [11269],
        [15108],
        [15721],
        [13988],
        [13593],
        [13004],
        [12829],
        [13732],
        [14054],
        [14116],
        [14195],
        [14499],
        [14492],
        [13828],
        [14300],
        [14158],
        [13676],
        [13542],
        [13582]], device='cuda:0')
[2024-07-24 10:16:53,192][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10359],
        [24610],
        [22826],
        [21336],
        [22487],
        [21116],
        [21800],
        [20814],
        [20802],
        [20699],
        [20454],
        [20564],
        [20860],
        [21816],
        [21180],
        [20004],
        [19614],
        [18385],
        [20480],
        [19364]], device='cuda:0')
[2024-07-24 10:16:53,194][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21597],
        [35919],
        [33645],
        [34857],
        [34324],
        [34137],
        [32341],
        [33110],
        [33043],
        [33325],
        [33997],
        [33798],
        [33920],
        [33854],
        [33936],
        [34105],
        [34202],
        [34661],
        [34615],
        [34743]], device='cuda:0')
[2024-07-24 10:16:53,195][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29114],
        [29621],
        [31362],
        [26357],
        [23447],
        [28409],
        [26142],
        [26246],
        [28212],
        [39049],
        [31886],
        [28383],
        [32266],
        [27269],
        [26251],
        [36951],
        [27266],
        [33800],
        [30504],
        [34271]], device='cuda:0')
[2024-07-24 10:16:53,197][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22338],
        [18762],
        [37356],
        [37492],
        [38026],
        [37560],
        [37365],
        [35812],
        [36922],
        [34568],
        [35156],
        [36900],
        [36987],
        [36118],
        [33680],
        [32601],
        [35321],
        [31128],
        [34856],
        [31503]], device='cuda:0')
[2024-07-24 10:16:53,199][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18248],
        [  764],
        [ 1070],
        [ 1196],
        [ 1253],
        [ 1281],
        [ 1392],
        [ 1436],
        [ 1479],
        [ 1485],
        [ 1514],
        [ 1556],
        [ 1576],
        [ 1602],
        [ 1617],
        [ 1632],
        [ 1673],
        [ 1658],
        [ 1642],
        [ 1614]], device='cuda:0')
[2024-07-24 10:16:53,203][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33292],
        [31202],
        [29834],
        [29497],
        [29068],
        [29380],
        [29052],
        [28726],
        [28698],
        [28648],
        [28634],
        [28791],
        [28943],
        [28932],
        [29093],
        [29071],
        [29028],
        [29047],
        [29100],
        [29107]], device='cuda:0')
[2024-07-24 10:16:53,206][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17320],
        [12585],
        [12987],
        [13099],
        [13336],
        [13410],
        [13575],
        [13792],
        [14042],
        [14194],
        [14672],
        [14631],
        [14816],
        [14990],
        [15176],
        [15274],
        [15507],
        [15775],
        [15793],
        [15909]], device='cuda:0')
[2024-07-24 10:16:53,208][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1628],
        [1806],
        [1976],
        [2757],
        [3614],
        [2410],
        [2416],
        [3905],
        [4451],
        [2735],
        [4098],
        [3035],
        [4655],
        [3512],
        [4435],
        [4047],
        [7506],
        [6344],
        [3832],
        [5011]], device='cuda:0')
[2024-07-24 10:16:53,210][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20001],
        [16632],
        [15805],
        [17025],
        [17270],
        [17294],
        [17867],
        [18073],
        [16643],
        [16049],
        [16013],
        [17245],
        [15394],
        [16514],
        [17022],
        [16436],
        [16572],
        [16370],
        [16986],
        [16992]], device='cuda:0')
[2024-07-24 10:16:53,211][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40013],
        [27320],
        [14567],
        [29281],
        [22159],
        [29494],
        [26986],
        [28302],
        [22010],
        [25004],
        [28674],
        [27715],
        [27179],
        [21808],
        [28730],
        [25860],
        [29944],
        [34253],
        [34237],
        [33072]], device='cuda:0')
[2024-07-24 10:16:53,214][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900],
        [16900]], device='cuda:0')
[2024-07-24 10:16:53,282][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:53,285][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,286][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,286][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,287][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,288][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,288][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,289][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,290][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,290][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,291][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,291][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,292][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,293][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5604, 0.4396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,293][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4942, 0.5058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,294][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1745, 0.8255], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,295][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8499, 0.1501], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,298][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7115, 0.2885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,301][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5120, 0.4880], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,303][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4979, 0.5021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,304][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2411, 0.7589], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,305][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4069, 0.5931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,305][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0316, 0.9684], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,306][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9833, 0.0167], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,307][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2077, 0.7923], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,309][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2276, 0.5088, 0.2636], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,313][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.3014, 0.2765, 0.4221], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,317][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0840, 0.4330, 0.4831], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,318][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.7187, 0.1182, 0.1632], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,319][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.5392, 0.2539, 0.2068], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,319][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.4381, 0.3399, 0.2220], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,320][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.4209, 0.3139, 0.2652], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,322][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.1320, 0.4706, 0.3975], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,325][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.1511, 0.5322, 0.3167], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,331][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0190, 0.5570, 0.4240], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,331][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.9519, 0.0456, 0.0026], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,332][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0238, 0.6416, 0.3346], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,333][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3128, 0.2795, 0.1841, 0.2236], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,333][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1185, 0.2354, 0.4934, 0.1526], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,336][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0548, 0.2964, 0.3256, 0.3232], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,339][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7094, 0.0820, 0.1157, 0.0930], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,344][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4733, 0.1839, 0.1592, 0.1836], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,345][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3335, 0.2786, 0.2018, 0.1860], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,345][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5646, 0.2112, 0.1510, 0.0731], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,346][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1007, 0.3253, 0.3135, 0.2604], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,347][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0886, 0.3450, 0.2932, 0.2732], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,349][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0112, 0.4200, 0.3236, 0.2452], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,352][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.7405e-01, 2.3977e-02, 1.2472e-03, 7.2730e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,357][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1180, 0.3906, 0.3069, 0.1845], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,360][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.1730, 0.2762, 0.1577, 0.2003, 0.1928], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,361][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.1551, 0.1814, 0.3086, 0.1737, 0.1812], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,361][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0399, 0.2167, 0.2390, 0.2398, 0.2647], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,362][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.6367, 0.0744, 0.1049, 0.0843, 0.0996], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,363][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.4125, 0.1655, 0.1456, 0.1461, 0.1303], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,366][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.2645, 0.2522, 0.1734, 0.1530, 0.1570], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,370][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.4093, 0.2174, 0.1730, 0.0701, 0.1303], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,374][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0782, 0.2671, 0.2427, 0.2088, 0.2032], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,374][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0766, 0.3053, 0.1896, 0.2395, 0.1891], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,375][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0097, 0.3192, 0.2530, 0.2068, 0.2113], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,376][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.9481, 0.0417, 0.0026, 0.0027, 0.0049], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,377][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0342, 0.3610, 0.2264, 0.1792, 0.1991], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,379][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.1992, 0.1878, 0.1261, 0.1676, 0.1681, 0.1512], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,383][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1221, 0.1824, 0.2649, 0.1451, 0.1570, 0.1286], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,388][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0333, 0.1693, 0.1891, 0.1882, 0.2090, 0.2110], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,388][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.4793, 0.0865, 0.1234, 0.0993, 0.1189, 0.0926], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,389][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.3386, 0.1450, 0.1224, 0.1317, 0.1114, 0.1509], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,390][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.2133, 0.2095, 0.1621, 0.1414, 0.1473, 0.1264], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,391][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.5390, 0.1748, 0.1150, 0.0481, 0.0798, 0.0433], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,393][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0449, 0.2334, 0.2075, 0.1839, 0.1865, 0.1437], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,397][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0403, 0.2510, 0.1818, 0.1949, 0.1909, 0.1411], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,401][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0147, 0.2730, 0.2126, 0.1686, 0.1702, 0.1609], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,402][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ were] are: tensor([9.7761e-01, 1.7141e-02, 9.8994e-04, 1.4461e-03, 2.3037e-03, 5.1379e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,403][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0800, 0.2080, 0.1806, 0.1473, 0.1947, 0.1894], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,404][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.1614, 0.1776, 0.1144, 0.1501, 0.1545, 0.1347, 0.1073],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,404][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1169, 0.1266, 0.2357, 0.1165, 0.1723, 0.1155, 0.1166],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,407][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0262, 0.1415, 0.1557, 0.1557, 0.1734, 0.1753, 0.1720],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,410][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.3252, 0.0984, 0.1375, 0.1187, 0.1470, 0.1018, 0.0715],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,415][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.2422, 0.1458, 0.1171, 0.1461, 0.0949, 0.1308, 0.1231],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,416][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.1724, 0.1981, 0.1509, 0.1298, 0.1333, 0.1154, 0.1002],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,417][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.3319, 0.1961, 0.1397, 0.0654, 0.1059, 0.0577, 0.1033],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,418][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0397, 0.2043, 0.1782, 0.1600, 0.1626, 0.1264, 0.1287],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,418][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0277, 0.2379, 0.1625, 0.1792, 0.1704, 0.1348, 0.0874],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,421][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.0074, 0.2517, 0.1895, 0.1410, 0.1530, 0.1538, 0.1036],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,426][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.8680, 0.0945, 0.0049, 0.0071, 0.0112, 0.0030, 0.0113],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,429][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0497, 0.2475, 0.1711, 0.1328, 0.1538, 0.1694, 0.0756],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,430][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.1645, 0.1483, 0.1047, 0.1398, 0.1391, 0.1203, 0.0998, 0.0835],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,431][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.1049, 0.1212, 0.2090, 0.1165, 0.1195, 0.1212, 0.1251, 0.0826],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,431][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0231, 0.1212, 0.1324, 0.1332, 0.1463, 0.1480, 0.1458, 0.1500],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,432][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.3085, 0.0931, 0.1304, 0.1093, 0.1333, 0.0980, 0.0747, 0.0527],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,437][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.2248, 0.1164, 0.0921, 0.1129, 0.0896, 0.1090, 0.1169, 0.1381],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,442][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.1643, 0.1740, 0.1381, 0.1169, 0.1199, 0.1064, 0.0943, 0.0862],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,443][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.3903, 0.1669, 0.1152, 0.0490, 0.0810, 0.0429, 0.0874, 0.0673],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,444][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0330, 0.1763, 0.1667, 0.1347, 0.1457, 0.1150, 0.1151, 0.1135],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,445][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0173, 0.1990, 0.1591, 0.1669, 0.1699, 0.1281, 0.0896, 0.0702],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,445][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0092, 0.2210, 0.1700, 0.1302, 0.1310, 0.1336, 0.0933, 0.1116],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,450][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.9163, 0.0435, 0.0033, 0.0049, 0.0096, 0.0021, 0.0073, 0.0131],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,455][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.1009, 0.1821, 0.1491, 0.1117, 0.1365, 0.1387, 0.0726, 0.1084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,456][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.1630, 0.1358, 0.0892, 0.1293, 0.1283, 0.1121, 0.0889, 0.0788, 0.0746],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,457][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0958, 0.1214, 0.1850, 0.1006, 0.1299, 0.1131, 0.1139, 0.0884, 0.0520],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,458][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0188, 0.1060, 0.1170, 0.1164, 0.1290, 0.1303, 0.1284, 0.1316, 0.1224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,459][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.2759, 0.0855, 0.1220, 0.1060, 0.1337, 0.0933, 0.0681, 0.0514, 0.0642],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,461][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.2169, 0.1031, 0.0831, 0.1006, 0.0741, 0.1006, 0.1028, 0.1201, 0.0986],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,469][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.1507, 0.1609, 0.1220, 0.1068, 0.1099, 0.0984, 0.0864, 0.0812, 0.0836],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,469][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.3407, 0.1699, 0.1100, 0.0489, 0.0787, 0.0433, 0.0838, 0.0628, 0.0619],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,470][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0328, 0.1573, 0.1487, 0.1264, 0.1306, 0.1002, 0.1022, 0.1102, 0.0916],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,471][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.0209, 0.1708, 0.1354, 0.1663, 0.1556, 0.1225, 0.0816, 0.0693, 0.0778],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,472][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.0072, 0.1948, 0.1487, 0.1127, 0.1198, 0.1204, 0.0828, 0.1005, 0.1131],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,476][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.9029, 0.0577, 0.0031, 0.0036, 0.0056, 0.0021, 0.0085, 0.0126, 0.0039],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,482][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0456, 0.1860, 0.1406, 0.1052, 0.1302, 0.1431, 0.0651, 0.1060, 0.0781],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:53,483][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1941, 0.1204, 0.0871, 0.1033, 0.1043, 0.0924, 0.0814, 0.0688, 0.0676,
        0.0805], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,483][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0721, 0.1148, 0.1859, 0.0892, 0.1140, 0.1074, 0.1183, 0.0804, 0.0589,
        0.0590], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,484][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0174, 0.0934, 0.1030, 0.1026, 0.1137, 0.1143, 0.1124, 0.1158, 0.1076,
        0.1198], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,485][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4201, 0.0557, 0.0808, 0.0783, 0.0932, 0.0661, 0.0540, 0.0393, 0.0495,
        0.0629], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,490][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1727, 0.0900, 0.0776, 0.0928, 0.0722, 0.0896, 0.0950, 0.1078, 0.0933,
        0.1092], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,495][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1400, 0.1388, 0.1147, 0.0953, 0.1017, 0.0895, 0.0807, 0.0748, 0.0778,
        0.0869], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,496][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3823, 0.1524, 0.0986, 0.0406, 0.0660, 0.0353, 0.0732, 0.0553, 0.0549,
        0.0415], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,496][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0360, 0.1375, 0.1305, 0.1149, 0.1172, 0.0914, 0.0944, 0.0958, 0.0836,
        0.0986], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,497][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0242, 0.1468, 0.1332, 0.1299, 0.1364, 0.1133, 0.0824, 0.0705, 0.0788,
        0.0845], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,498][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0056, 0.1670, 0.1321, 0.1032, 0.1050, 0.1088, 0.0743, 0.0894, 0.1010,
        0.1138], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,500][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.5382e-01, 2.4659e-02, 1.7591e-03, 1.6345e-03, 3.9995e-03, 5.8664e-04,
        4.1353e-03, 5.6674e-03, 2.3666e-03, 1.3680e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,508][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1030, 0.1181, 0.1042, 0.0751, 0.1037, 0.1081, 0.0608, 0.0941, 0.0737,
        0.1591], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:53,508][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2607, 0.0917, 0.0654, 0.0908, 0.0909, 0.0825, 0.0657, 0.0598, 0.0562,
        0.0720, 0.0643], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,509][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0827, 0.1111, 0.1693, 0.0870, 0.1022, 0.0983, 0.0968, 0.0739, 0.0597,
        0.0662, 0.0527], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,510][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0153, 0.0828, 0.0923, 0.0921, 0.1019, 0.1025, 0.1009, 0.1035, 0.0961,
        0.1070, 0.1055], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,511][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.4059, 0.0535, 0.0822, 0.0744, 0.0925, 0.0612, 0.0453, 0.0323, 0.0412,
        0.0548, 0.0568], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,516][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1807, 0.0810, 0.0679, 0.0754, 0.0606, 0.0805, 0.0874, 0.0984, 0.0830,
        0.0968, 0.0882], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,521][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1152, 0.1408, 0.1143, 0.0907, 0.0953, 0.0822, 0.0723, 0.0671, 0.0694,
        0.0782, 0.0744], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,522][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2726, 0.1561, 0.1023, 0.0493, 0.0748, 0.0431, 0.0762, 0.0614, 0.0595,
        0.0462, 0.0586], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,522][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0297, 0.1274, 0.1206, 0.1052, 0.1124, 0.0830, 0.0854, 0.0862, 0.0762,
        0.0926, 0.0813], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,523][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0141, 0.1487, 0.1149, 0.1289, 0.1249, 0.0994, 0.0714, 0.0613, 0.0688,
        0.0861, 0.0816], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,524][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0042, 0.1640, 0.1217, 0.0931, 0.0937, 0.0967, 0.0661, 0.0819, 0.0935,
        0.1090, 0.0760], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,526][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.4250e-01, 2.2998e-02, 2.0210e-03, 2.0027e-03, 5.6780e-03, 7.9013e-04,
        4.1277e-03, 8.5319e-03, 4.4334e-03, 2.6248e-03, 4.2887e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,534][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0711, 0.1253, 0.1110, 0.0742, 0.1010, 0.0993, 0.0538, 0.0824, 0.0655,
        0.1411, 0.0753], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:53,535][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1163, 0.1115, 0.0745, 0.1002, 0.0999, 0.0860, 0.0735, 0.0643, 0.0657,
        0.0744, 0.0718, 0.0619], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,535][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1060, 0.0886, 0.1716, 0.0761, 0.1016, 0.0778, 0.0792, 0.0686, 0.0552,
        0.0596, 0.0458, 0.0699], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,536][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0123, 0.0745, 0.0826, 0.0834, 0.0922, 0.0932, 0.0919, 0.0948, 0.0869,
        0.0979, 0.0958, 0.0946], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,537][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1474, 0.0743, 0.1029, 0.0949, 0.1219, 0.0876, 0.0588, 0.0476, 0.0572,
        0.0767, 0.0825, 0.0483], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,542][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1411, 0.0808, 0.0638, 0.0722, 0.0544, 0.0735, 0.0792, 0.0920, 0.0749,
        0.0876, 0.0795, 0.1010], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,547][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.1059, 0.1339, 0.1085, 0.0871, 0.0898, 0.0754, 0.0677, 0.0621, 0.0643,
        0.0714, 0.0682, 0.0655], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,548][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.2581, 0.1426, 0.0924, 0.0466, 0.0699, 0.0396, 0.0725, 0.0598, 0.0563,
        0.0459, 0.0538, 0.0624], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,548][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0217, 0.1190, 0.1101, 0.0929, 0.0980, 0.0776, 0.0768, 0.0800, 0.0735,
        0.0809, 0.0808, 0.0888], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,549][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0185, 0.1372, 0.1121, 0.1191, 0.1133, 0.0921, 0.0627, 0.0527, 0.0654,
        0.0814, 0.0826, 0.0629], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,550][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0059, 0.1455, 0.1195, 0.0915, 0.0895, 0.0912, 0.0647, 0.0779, 0.0878,
        0.0931, 0.0708, 0.0625], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,555][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.7173, 0.0980, 0.0048, 0.0109, 0.0120, 0.0045, 0.0132, 0.0205, 0.0123,
        0.0119, 0.0190, 0.0755], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,560][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0417, 0.1453, 0.0979, 0.0785, 0.0840, 0.0949, 0.0462, 0.0832, 0.0593,
        0.1474, 0.0728, 0.0488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:53,561][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1663, 0.1093, 0.0776, 0.0757, 0.0844, 0.0753, 0.0684, 0.0555, 0.0556,
        0.0609, 0.0572, 0.0569, 0.0568], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,562][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0597, 0.0891, 0.1595, 0.0647, 0.0912, 0.0857, 0.0866, 0.0667, 0.0578,
        0.0548, 0.0487, 0.0826, 0.0530], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,562][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0130, 0.0685, 0.0757, 0.0761, 0.0844, 0.0856, 0.0833, 0.0861, 0.0796,
        0.0892, 0.0878, 0.0868, 0.0839], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,563][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.4251, 0.0479, 0.0666, 0.0566, 0.0668, 0.0534, 0.0432, 0.0301, 0.0394,
        0.0452, 0.0480, 0.0377, 0.0401], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,568][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1244, 0.0717, 0.0598, 0.0722, 0.0561, 0.0647, 0.0708, 0.0850, 0.0713,
        0.0836, 0.0768, 0.0835, 0.0801], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,573][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1106, 0.1151, 0.0960, 0.0787, 0.0845, 0.0707, 0.0626, 0.0586, 0.0612,
        0.0672, 0.0643, 0.0664, 0.0641], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,574][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2568, 0.1310, 0.0929, 0.0427, 0.0664, 0.0369, 0.0674, 0.0548, 0.0524,
        0.0418, 0.0510, 0.0531, 0.0528], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,574][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0304, 0.1043, 0.0974, 0.0840, 0.0888, 0.0702, 0.0718, 0.0729, 0.0651,
        0.0760, 0.0703, 0.0783, 0.0904], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,575][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0209, 0.1257, 0.1061, 0.0965, 0.1026, 0.0894, 0.0638, 0.0564, 0.0614,
        0.0700, 0.0788, 0.0658, 0.0628], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,576][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0040, 0.1354, 0.1068, 0.0824, 0.0829, 0.0862, 0.0581, 0.0710, 0.0808,
        0.0939, 0.0668, 0.0585, 0.0732], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,578][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.4201e-01, 1.2859e-02, 9.8514e-04, 1.2097e-03, 3.3215e-03, 2.6411e-04,
        2.9193e-03, 5.7013e-03, 2.3017e-03, 1.2530e-03, 5.2598e-03, 1.9423e-02,
        2.4934e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,585][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0689, 0.1186, 0.0930, 0.0625, 0.0808, 0.0875, 0.0481, 0.0745, 0.0600,
        0.1233, 0.0658, 0.0485, 0.0685], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:53,586][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.1179, 0.0976, 0.0633, 0.0812, 0.0781, 0.0694, 0.0618, 0.0540, 0.0522,
        0.0658, 0.0618, 0.0523, 0.0602, 0.0844], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,587][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0703, 0.0834, 0.1317, 0.0783, 0.0767, 0.0739, 0.0775, 0.0593, 0.0435,
        0.0561, 0.0484, 0.0767, 0.0635, 0.0607], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,588][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0122, 0.0625, 0.0694, 0.0705, 0.0771, 0.0786, 0.0768, 0.0794, 0.0736,
        0.0825, 0.0810, 0.0800, 0.0772, 0.0793], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,589][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.3426, 0.0462, 0.0674, 0.0650, 0.0788, 0.0550, 0.0394, 0.0298, 0.0374,
        0.0529, 0.0537, 0.0345, 0.0460, 0.0513], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,594][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.1355, 0.0683, 0.0561, 0.0614, 0.0497, 0.0609, 0.0678, 0.0775, 0.0596,
        0.0754, 0.0719, 0.0835, 0.0720, 0.0604], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,598][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.1117, 0.1129, 0.0879, 0.0727, 0.0752, 0.0632, 0.0589, 0.0545, 0.0569,
        0.0623, 0.0591, 0.0583, 0.0590, 0.0673], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,599][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.2524, 0.1297, 0.0931, 0.0390, 0.0653, 0.0322, 0.0623, 0.0502, 0.0471,
        0.0373, 0.0467, 0.0492, 0.0470, 0.0484], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,600][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0266, 0.0999, 0.0901, 0.0797, 0.0780, 0.0636, 0.0624, 0.0682, 0.0580,
        0.0720, 0.0670, 0.0704, 0.0873, 0.0767], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,601][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0260, 0.1238, 0.0885, 0.1072, 0.0885, 0.0746, 0.0536, 0.0441, 0.0522,
        0.0714, 0.0728, 0.0552, 0.0744, 0.0678], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,603][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.0037, 0.1132, 0.0967, 0.0798, 0.0795, 0.0827, 0.0556, 0.0671, 0.0741,
        0.0848, 0.0624, 0.0551, 0.0685, 0.0770], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,609][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.8886, 0.0288, 0.0020, 0.0025, 0.0057, 0.0013, 0.0049, 0.0088, 0.0032,
        0.0033, 0.0082, 0.0308, 0.0053, 0.0068], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,611][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0419, 0.1084, 0.0730, 0.0623, 0.0697, 0.0872, 0.0427, 0.0745, 0.0561,
        0.1185, 0.0647, 0.0470, 0.0682, 0.0858], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:53,612][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.1051, 0.0887, 0.0573, 0.0817, 0.0824, 0.0691, 0.0578, 0.0510, 0.0501,
        0.0611, 0.0565, 0.0491, 0.0511, 0.0868, 0.0523], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,613][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0817, 0.0793, 0.1179, 0.0758, 0.0780, 0.0679, 0.0675, 0.0638, 0.0367,
        0.0521, 0.0468, 0.0664, 0.0562, 0.0624, 0.0476], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,614][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0103, 0.0582, 0.0650, 0.0649, 0.0719, 0.0729, 0.0716, 0.0735, 0.0684,
        0.0766, 0.0752, 0.0739, 0.0717, 0.0744, 0.0714], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,619][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.1372, 0.0601, 0.0868, 0.0753, 0.0966, 0.0675, 0.0513, 0.0389, 0.0513,
        0.0651, 0.0748, 0.0432, 0.0461, 0.0686, 0.0371], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,624][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.1143, 0.0697, 0.0479, 0.0595, 0.0425, 0.0558, 0.0553, 0.0743, 0.0607,
        0.0673, 0.0643, 0.0768, 0.0688, 0.0529, 0.0897], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,625][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.1018, 0.1097, 0.0833, 0.0688, 0.0718, 0.0622, 0.0566, 0.0516, 0.0537,
        0.0577, 0.0559, 0.0565, 0.0564, 0.0654, 0.0487], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,626][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.2212, 0.1256, 0.0921, 0.0369, 0.0599, 0.0336, 0.0615, 0.0517, 0.0494,
        0.0399, 0.0495, 0.0509, 0.0489, 0.0454, 0.0335], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,627][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0168, 0.0957, 0.0829, 0.0749, 0.0740, 0.0610, 0.0605, 0.0640, 0.0577,
        0.0651, 0.0653, 0.0752, 0.0773, 0.0758, 0.0539], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,629][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0153, 0.1086, 0.0897, 0.0939, 0.0984, 0.0725, 0.0547, 0.0443, 0.0537,
        0.0628, 0.0678, 0.0575, 0.0588, 0.0799, 0.0423], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,635][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.0039, 0.1266, 0.0953, 0.0689, 0.0721, 0.0743, 0.0513, 0.0622, 0.0718,
        0.0781, 0.0585, 0.0525, 0.0603, 0.0731, 0.0513], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,637][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.8730, 0.0262, 0.0017, 0.0031, 0.0042, 0.0010, 0.0045, 0.0083, 0.0042,
        0.0040, 0.0068, 0.0391, 0.0055, 0.0057, 0.0126], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,638][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0379, 0.1089, 0.0826, 0.0626, 0.0734, 0.0812, 0.0385, 0.0657, 0.0498,
        0.1179, 0.0595, 0.0409, 0.0631, 0.0809, 0.0372], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:53,639][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1444, 0.0777, 0.0570, 0.0667, 0.0699, 0.0627, 0.0546, 0.0465, 0.0460,
        0.0528, 0.0493, 0.0465, 0.0480, 0.0724, 0.0491, 0.0563],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,640][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0530, 0.0778, 0.1257, 0.0621, 0.0771, 0.0744, 0.0807, 0.0555, 0.0398,
        0.0400, 0.0413, 0.0694, 0.0500, 0.0596, 0.0555, 0.0381],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,644][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0106, 0.0559, 0.0613, 0.0609, 0.0672, 0.0676, 0.0664, 0.0682, 0.0636,
        0.0707, 0.0693, 0.0688, 0.0666, 0.0699, 0.0668, 0.0663],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,649][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2301, 0.0490, 0.0674, 0.0659, 0.0801, 0.0558, 0.0440, 0.0330, 0.0414,
        0.0537, 0.0578, 0.0364, 0.0460, 0.0568, 0.0339, 0.0487],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,650][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0990, 0.0582, 0.0475, 0.0579, 0.0439, 0.0553, 0.0536, 0.0640, 0.0560,
        0.0656, 0.0615, 0.0659, 0.0640, 0.0543, 0.0851, 0.0683],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,651][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0943, 0.0936, 0.0770, 0.0636, 0.0675, 0.0601, 0.0544, 0.0494, 0.0517,
        0.0568, 0.0548, 0.0559, 0.0552, 0.0644, 0.0485, 0.0529],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,652][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3290, 0.1203, 0.0787, 0.0296, 0.0497, 0.0248, 0.0533, 0.0420, 0.0412,
        0.0311, 0.0410, 0.0417, 0.0370, 0.0353, 0.0238, 0.0215],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,655][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0196, 0.0835, 0.0799, 0.0703, 0.0735, 0.0572, 0.0592, 0.0592, 0.0525,
        0.0608, 0.0589, 0.0658, 0.0731, 0.0723, 0.0536, 0.0604],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,662][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0162, 0.0912, 0.0888, 0.0811, 0.0896, 0.0737, 0.0545, 0.0468, 0.0535,
        0.0543, 0.0646, 0.0578, 0.0567, 0.0740, 0.0481, 0.0491],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,663][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0033, 0.1111, 0.0871, 0.0667, 0.0684, 0.0705, 0.0478, 0.0578, 0.0655,
        0.0729, 0.0533, 0.0482, 0.0588, 0.0694, 0.0479, 0.0715],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,664][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.1451e-01, 1.9901e-02, 1.5176e-03, 1.5442e-03, 4.0143e-03, 5.3514e-04,
        3.6538e-03, 5.5291e-03, 2.4431e-03, 1.3680e-03, 4.3988e-03, 2.4011e-02,
        2.2495e-03, 4.0236e-03, 8.7786e-03, 1.5242e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,665][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0695, 0.0749, 0.0670, 0.0439, 0.0656, 0.0662, 0.0380, 0.0597, 0.0477,
        0.0960, 0.0548, 0.0415, 0.0534, 0.0879, 0.0389, 0.0952],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:53,667][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0984, 0.0798, 0.0544, 0.0718, 0.0751, 0.0620, 0.0519, 0.0458, 0.0442,
        0.0540, 0.0494, 0.0451, 0.0448, 0.0771, 0.0485, 0.0567, 0.0408],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,673][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0583, 0.0734, 0.1302, 0.0599, 0.0733, 0.0662, 0.0685, 0.0495, 0.0370,
        0.0399, 0.0434, 0.0675, 0.0509, 0.0614, 0.0469, 0.0390, 0.0347],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,675][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0095, 0.0520, 0.0579, 0.0573, 0.0635, 0.0638, 0.0629, 0.0645, 0.0602,
        0.0670, 0.0658, 0.0655, 0.0630, 0.0660, 0.0630, 0.0625, 0.0556],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,676][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.1248, 0.0501, 0.0772, 0.0762, 0.0993, 0.0625, 0.0428, 0.0325, 0.0424,
        0.0604, 0.0656, 0.0374, 0.0452, 0.0675, 0.0321, 0.0529, 0.0311],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,677][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.1094, 0.0538, 0.0412, 0.0453, 0.0356, 0.0503, 0.0540, 0.0610, 0.0519,
        0.0573, 0.0553, 0.0682, 0.0611, 0.0488, 0.0885, 0.0608, 0.0574],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,678][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0834, 0.0972, 0.0779, 0.0637, 0.0658, 0.0588, 0.0516, 0.0470, 0.0489,
        0.0539, 0.0521, 0.0512, 0.0534, 0.0584, 0.0440, 0.0495, 0.0430],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,682][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.2272, 0.1227, 0.0863, 0.0345, 0.0589, 0.0291, 0.0568, 0.0466, 0.0443,
        0.0338, 0.0435, 0.0450, 0.0436, 0.0429, 0.0281, 0.0259, 0.0309],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,688][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0167, 0.0810, 0.0729, 0.0665, 0.0668, 0.0554, 0.0536, 0.0562, 0.0497,
        0.0574, 0.0553, 0.0635, 0.0696, 0.0673, 0.0512, 0.0575, 0.0594],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,689][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0111, 0.1028, 0.0810, 0.0857, 0.0862, 0.0654, 0.0469, 0.0417, 0.0463,
        0.0559, 0.0602, 0.0491, 0.0551, 0.0699, 0.0426, 0.0520, 0.0479],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,690][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0027, 0.1127, 0.0860, 0.0610, 0.0634, 0.0669, 0.0449, 0.0560, 0.0640,
        0.0709, 0.0513, 0.0459, 0.0533, 0.0663, 0.0456, 0.0708, 0.0382],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,691][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.7351, 0.0456, 0.0043, 0.0058, 0.0139, 0.0026, 0.0117, 0.0223, 0.0088,
        0.0055, 0.0150, 0.0703, 0.0075, 0.0139, 0.0232, 0.0061, 0.0084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,693][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0357, 0.0897, 0.0714, 0.0490, 0.0620, 0.0650, 0.0321, 0.0556, 0.0413,
        0.1003, 0.0511, 0.0364, 0.0531, 0.0749, 0.0333, 0.0997, 0.0493],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:53,701][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1363, 0.0690, 0.0482, 0.0637, 0.0664, 0.0597, 0.0471, 0.0424, 0.0404,
        0.0495, 0.0447, 0.0422, 0.0423, 0.0714, 0.0450, 0.0524, 0.0394, 0.0399],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,702][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0606, 0.0719, 0.1088, 0.0602, 0.0702, 0.0597, 0.0638, 0.0542, 0.0387,
        0.0428, 0.0412, 0.0608, 0.0532, 0.0563, 0.0496, 0.0413, 0.0326, 0.0342],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,702][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0108, 0.0499, 0.0545, 0.0549, 0.0601, 0.0603, 0.0591, 0.0608, 0.0565,
        0.0633, 0.0623, 0.0618, 0.0596, 0.0623, 0.0595, 0.0591, 0.0522, 0.0529],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,703][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1614, 0.0538, 0.0760, 0.0731, 0.0919, 0.0565, 0.0398, 0.0314, 0.0370,
        0.0528, 0.0578, 0.0309, 0.0431, 0.0606, 0.0289, 0.0455, 0.0293, 0.0303],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,706][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1062, 0.0498, 0.0367, 0.0442, 0.0336, 0.0492, 0.0468, 0.0551, 0.0465,
        0.0540, 0.0498, 0.0596, 0.0599, 0.0477, 0.1007, 0.0587, 0.0613, 0.0401],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,713][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0806, 0.0955, 0.0762, 0.0606, 0.0628, 0.0549, 0.0487, 0.0448, 0.0468,
        0.0515, 0.0495, 0.0484, 0.0498, 0.0565, 0.0421, 0.0472, 0.0420, 0.0421],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,714][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2821, 0.1203, 0.0804, 0.0306, 0.0526, 0.0247, 0.0516, 0.0406, 0.0399,
        0.0289, 0.0389, 0.0394, 0.0369, 0.0364, 0.0232, 0.0210, 0.0252, 0.0273],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,715][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0153, 0.0757, 0.0693, 0.0606, 0.0657, 0.0509, 0.0527, 0.0535, 0.0470,
        0.0557, 0.0509, 0.0593, 0.0653, 0.0651, 0.0494, 0.0549, 0.0592, 0.0496],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,716][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0101, 0.0942, 0.0757, 0.0790, 0.0797, 0.0640, 0.0469, 0.0410, 0.0476,
        0.0543, 0.0544, 0.0490, 0.0512, 0.0664, 0.0427, 0.0501, 0.0520, 0.0418],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,721][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0031, 0.1085, 0.0798, 0.0609, 0.0607, 0.0614, 0.0425, 0.0532, 0.0611,
        0.0680, 0.0486, 0.0435, 0.0529, 0.0626, 0.0443, 0.0675, 0.0372, 0.0443],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,726][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.8390, 0.0271, 0.0026, 0.0023, 0.0062, 0.0009, 0.0058, 0.0092, 0.0050,
        0.0027, 0.0059, 0.0485, 0.0036, 0.0066, 0.0231, 0.0030, 0.0041, 0.0045],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,727][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0419, 0.0800, 0.0655, 0.0411, 0.0590, 0.0586, 0.0310, 0.0488, 0.0397,
        0.0873, 0.0462, 0.0350, 0.0482, 0.0750, 0.0325, 0.0861, 0.0484, 0.0757],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:53,728][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0852, 0.0679, 0.0499, 0.0665, 0.0663, 0.0573, 0.0470, 0.0424, 0.0410,
        0.0482, 0.0455, 0.0418, 0.0415, 0.0698, 0.0450, 0.0514, 0.0389, 0.0429,
        0.0514], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,729][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0651, 0.0653, 0.1288, 0.0567, 0.0758, 0.0544, 0.0558, 0.0472, 0.0365,
        0.0382, 0.0342, 0.0525, 0.0415, 0.0597, 0.0408, 0.0365, 0.0335, 0.0332,
        0.0443], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,733][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0098, 0.0470, 0.0504, 0.0513, 0.0562, 0.0568, 0.0553, 0.0581, 0.0530,
        0.0606, 0.0594, 0.0589, 0.0567, 0.0591, 0.0564, 0.0568, 0.0491, 0.0505,
        0.0544], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,740][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.1200, 0.0547, 0.0737, 0.0714, 0.0890, 0.0563, 0.0394, 0.0332, 0.0370,
        0.0539, 0.0575, 0.0327, 0.0439, 0.0642, 0.0306, 0.0477, 0.0317, 0.0330,
        0.0301], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,742][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0881, 0.0539, 0.0413, 0.0471, 0.0376, 0.0465, 0.0499, 0.0536, 0.0504,
        0.0529, 0.0486, 0.0598, 0.0535, 0.0448, 0.0790, 0.0558, 0.0529, 0.0421,
        0.0420], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,743][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0905, 0.0879, 0.0681, 0.0567, 0.0580, 0.0516, 0.0450, 0.0422, 0.0442,
        0.0491, 0.0467, 0.0472, 0.0476, 0.0532, 0.0402, 0.0450, 0.0408, 0.0409,
        0.0451], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,744][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.2869, 0.1207, 0.0739, 0.0283, 0.0473, 0.0240, 0.0504, 0.0392, 0.0389,
        0.0284, 0.0380, 0.0385, 0.0353, 0.0341, 0.0225, 0.0206, 0.0259, 0.0260,
        0.0210], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,745][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0145, 0.0749, 0.0658, 0.0560, 0.0581, 0.0501, 0.0504, 0.0515, 0.0463,
        0.0493, 0.0474, 0.0564, 0.0605, 0.0566, 0.0466, 0.0491, 0.0563, 0.0455,
        0.0645], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,750][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0150, 0.0951, 0.0717, 0.0771, 0.0764, 0.0609, 0.0412, 0.0364, 0.0438,
        0.0531, 0.0549, 0.0435, 0.0518, 0.0603, 0.0354, 0.0478, 0.0448, 0.0449,
        0.0460], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,754][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0033, 0.0934, 0.0804, 0.0604, 0.0601, 0.0589, 0.0420, 0.0516, 0.0584,
        0.0637, 0.0467, 0.0427, 0.0486, 0.0610, 0.0431, 0.0626, 0.0362, 0.0431,
        0.0441], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,755][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.7684, 0.0454, 0.0022, 0.0038, 0.0076, 0.0017, 0.0080, 0.0192, 0.0036,
        0.0053, 0.0108, 0.0605, 0.0095, 0.0084, 0.0150, 0.0064, 0.0041, 0.0112,
        0.0090], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,756][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0309, 0.0694, 0.0566, 0.0443, 0.0531, 0.0555, 0.0274, 0.0513, 0.0379,
        0.0850, 0.0460, 0.0329, 0.0507, 0.0651, 0.0291, 0.0845, 0.0448, 0.0824,
        0.0530], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:53,757][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1177, 0.0655, 0.0491, 0.0556, 0.0603, 0.0558, 0.0457, 0.0393, 0.0386,
        0.0420, 0.0392, 0.0398, 0.0361, 0.0591, 0.0421, 0.0452, 0.0368, 0.0372,
        0.0481, 0.0467], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,762][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0482, 0.0653, 0.1079, 0.0533, 0.0665, 0.0640, 0.0701, 0.0490, 0.0339,
        0.0337, 0.0358, 0.0587, 0.0422, 0.0503, 0.0480, 0.0318, 0.0306, 0.0368,
        0.0428, 0.0309], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,767][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0100, 0.0449, 0.0489, 0.0488, 0.0539, 0.0537, 0.0527, 0.0542, 0.0503,
        0.0561, 0.0554, 0.0553, 0.0532, 0.0563, 0.0535, 0.0527, 0.0466, 0.0479,
        0.0519, 0.0539], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,768][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1451, 0.0502, 0.0694, 0.0646, 0.0805, 0.0525, 0.0399, 0.0307, 0.0367,
        0.0489, 0.0530, 0.0323, 0.0412, 0.0563, 0.0307, 0.0435, 0.0300, 0.0313,
        0.0313, 0.0320], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,769][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0792, 0.0487, 0.0394, 0.0477, 0.0356, 0.0459, 0.0428, 0.0504, 0.0463,
        0.0530, 0.0503, 0.0524, 0.0530, 0.0436, 0.0717, 0.0552, 0.0516, 0.0407,
        0.0378, 0.0547], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,770][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0784, 0.0833, 0.0673, 0.0540, 0.0568, 0.0499, 0.0443, 0.0406, 0.0424,
        0.0472, 0.0456, 0.0457, 0.0459, 0.0531, 0.0394, 0.0432, 0.0382, 0.0392,
        0.0439, 0.0415], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,774][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2900, 0.1207, 0.0740, 0.0284, 0.0460, 0.0233, 0.0480, 0.0376, 0.0371,
        0.0268, 0.0371, 0.0353, 0.0323, 0.0313, 0.0216, 0.0191, 0.0241, 0.0251,
        0.0198, 0.0222], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,779][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0137, 0.0668, 0.0635, 0.0555, 0.0589, 0.0463, 0.0473, 0.0476, 0.0423,
        0.0479, 0.0464, 0.0528, 0.0571, 0.0575, 0.0427, 0.0477, 0.0537, 0.0463,
        0.0600, 0.0459], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,780][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0098, 0.0784, 0.0753, 0.0663, 0.0775, 0.0606, 0.0451, 0.0382, 0.0443,
        0.0436, 0.0513, 0.0474, 0.0445, 0.0625, 0.0396, 0.0399, 0.0485, 0.0423,
        0.0505, 0.0345], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,781][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0024, 0.0930, 0.0725, 0.0550, 0.0561, 0.0588, 0.0396, 0.0491, 0.0545,
        0.0602, 0.0439, 0.0403, 0.0478, 0.0574, 0.0400, 0.0594, 0.0337, 0.0406,
        0.0420, 0.0535], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,782][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.2127e-01, 1.3699e-02, 1.1730e-03, 1.1807e-03, 2.6004e-03, 3.7080e-04,
        2.8113e-03, 4.0594e-03, 1.9073e-03, 1.0877e-03, 3.0512e-03, 2.1552e-02,
        1.6648e-03, 2.8714e-03, 8.4552e-03, 1.2828e-03, 1.6129e-03, 2.4219e-03,
        4.3491e-03, 2.5743e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,787][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0494, 0.0592, 0.0545, 0.0331, 0.0520, 0.0487, 0.0291, 0.0442, 0.0369,
        0.0727, 0.0427, 0.0328, 0.0413, 0.0698, 0.0302, 0.0716, 0.0438, 0.0691,
        0.0518, 0.0670], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:53,854][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:53,855][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,856][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,857][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,857][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,858][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,859][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,860][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,861][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,861][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,862][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,863][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,863][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:53,864][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9161, 0.0839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,867][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,872][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5832, 0.4168], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,873][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8976, 0.1024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,874][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9989e-01, 1.0829e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,875][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0673, 0.9327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,876][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9989e-01, 1.0636e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,876][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4048, 0.5952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,878][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8842, 0.1158], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,882][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.6412, 0.3588], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,887][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9977, 0.0023], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,887][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0603, 0.9397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:53,888][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.1332, 0.8096, 0.0571], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,889][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([2.5836e-04, 9.8353e-01, 1.6207e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,889][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.3947, 0.4593, 0.1459], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,891][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.6586, 0.2807, 0.0608], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,893][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([9.9844e-01, 8.7944e-04, 6.7850e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,898][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0023, 0.9553, 0.0424], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,900][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([9.9970e-01, 7.6439e-05, 2.2660e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,901][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0388, 0.8422, 0.1190], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,901][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0385, 0.9515, 0.0101], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,902][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.8258, 0.1197, 0.0545], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,903][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.9958, 0.0022, 0.0020], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,905][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0012, 0.9580, 0.0408], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:53,909][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1923, 0.5876, 0.2164, 0.0038], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,912][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.4410e-05, 9.5172e-01, 4.7836e-02, 4.2727e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,913][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2943, 0.3527, 0.2608, 0.0922], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,914][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6857, 0.1881, 0.1027, 0.0234], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,915][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9926e-01, 1.2746e-04, 2.1054e-04, 4.0644e-04], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,916][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0038, 0.8984, 0.0854, 0.0124], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,916][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9673e-01, 6.1148e-04, 5.7345e-04, 2.0832e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,919][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0432, 0.6471, 0.2873, 0.0224], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,923][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0305, 0.8550, 0.1087, 0.0057], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,927][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0083, 0.3826, 0.2128, 0.3963], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,927][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9941, 0.0019, 0.0020, 0.0020], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,928][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.0027e-04, 8.2731e-01, 1.6925e-01, 2.7332e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:53,929][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0066, 0.8580, 0.1305, 0.0036, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,929][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([9.1454e-06, 9.6122e-01, 3.7441e-02, 1.1811e-03, 1.5237e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,931][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0965, 0.5180, 0.2780, 0.0601, 0.0475], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,935][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.2683, 0.5026, 0.2002, 0.0238, 0.0051], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,938][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([9.9815e-01, 4.3018e-04, 3.7010e-04, 8.9768e-04, 1.4765e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,940][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([1.9141e-04, 9.1193e-01, 8.1721e-02, 5.2711e-03, 8.9076e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,941][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([9.9860e-01, 1.7205e-04, 3.8501e-04, 4.1043e-04, 4.2758e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,941][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0047, 0.7543, 0.2198, 0.0168, 0.0044], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,942][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([4.3959e-04, 9.6505e-01, 3.3313e-02, 1.1200e-03, 7.7891e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,943][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.1554, 0.1672, 0.0905, 0.3919, 0.1951], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,945][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.9902, 0.0025, 0.0031, 0.0019, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,948][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([2.3282e-05, 9.3882e-01, 5.9379e-02, 1.5002e-03, 2.7850e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:53,953][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0552, 0.5527, 0.3658, 0.0093, 0.0095, 0.0076], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,954][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([4.3735e-05, 9.8224e-01, 1.6184e-02, 1.1072e-03, 9.5085e-05, 3.2986e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,954][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1378, 0.2999, 0.3123, 0.0868, 0.1220, 0.0412], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,955][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.5408, 0.2590, 0.1386, 0.0340, 0.0111, 0.0165], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,956][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([9.9470e-01, 9.5597e-04, 1.4644e-03, 1.5024e-03, 5.9374e-04, 7.8850e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,958][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0031, 0.8175, 0.1595, 0.0122, 0.0033, 0.0044], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,960][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([9.9691e-01, 4.8090e-04, 5.0971e-04, 7.8762e-04, 2.6771e-04, 1.0477e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,965][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0445, 0.5802, 0.3189, 0.0306, 0.0178, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,967][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0085, 0.8956, 0.0864, 0.0053, 0.0013, 0.0030], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,968][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0101, 0.2016, 0.2053, 0.3031, 0.2301, 0.0498], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,968][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.9757, 0.0044, 0.0044, 0.0067, 0.0044, 0.0044], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,969][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0014, 0.7447, 0.2413, 0.0077, 0.0034, 0.0015], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:53,970][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0204, 0.5559, 0.4028, 0.0051, 0.0060, 0.0083, 0.0014],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,971][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([6.2673e-06, 9.4615e-01, 5.1733e-02, 1.0693e-03, 2.7210e-04, 4.3011e-04,
        3.3568e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,976][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0995, 0.2876, 0.3302, 0.0929, 0.1210, 0.0404, 0.0283],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,980][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.3813, 0.3854, 0.1691, 0.0295, 0.0077, 0.0204, 0.0065],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,981][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([9.9451e-01, 8.2570e-04, 1.7246e-03, 1.0962e-03, 4.6796e-04, 7.1904e-04,
        6.5995e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,982][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([5.7315e-04, 8.4643e-01, 1.3914e-01, 7.8085e-03, 2.4265e-03, 2.2555e-03,
        1.3652e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,982][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([9.9773e-01, 3.5812e-04, 4.5610e-04, 3.9419e-04, 2.5284e-04, 4.8782e-04,
        3.2296e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,983][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0188, 0.6168, 0.3244, 0.0183, 0.0094, 0.0070, 0.0053],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,984][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([2.3940e-03, 8.5409e-01, 1.3393e-01, 4.8341e-03, 1.4149e-03, 2.6525e-03,
        6.7989e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,988][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.1281, 0.1218, 0.1085, 0.1392, 0.2670, 0.1272, 0.1081],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,992][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.9829, 0.0020, 0.0017, 0.0020, 0.0019, 0.0022, 0.0073],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,994][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([2.2594e-04, 8.1130e-01, 1.7914e-01, 5.5192e-03, 1.7575e-03, 1.5418e-03,
        5.1511e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:53,995][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0327, 0.5620, 0.3521, 0.0127, 0.0122, 0.0205, 0.0065, 0.0013],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,996][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([4.8270e-05, 9.2928e-01, 6.3425e-02, 2.8626e-03, 3.9377e-04, 2.8432e-03,
        1.0826e-03, 6.1619e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,997][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.1429, 0.2171, 0.2545, 0.1026, 0.1445, 0.0555, 0.0560, 0.0270],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,997][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.5563, 0.2206, 0.1211, 0.0347, 0.0112, 0.0347, 0.0179, 0.0034],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:53,999][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([9.8696e-01, 2.3605e-03, 5.3076e-03, 1.8950e-03, 1.0080e-03, 1.2224e-03,
        1.0666e-03, 1.8072e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,003][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0020, 0.8041, 0.1654, 0.0117, 0.0047, 0.0065, 0.0048, 0.0009],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,006][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([9.9578e-01, 4.3606e-04, 6.0418e-04, 8.0112e-04, 3.8279e-04, 6.8045e-04,
        3.8755e-04, 9.2888e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,008][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0496, 0.3930, 0.4905, 0.0207, 0.0235, 0.0084, 0.0132, 0.0011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,009][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([6.2215e-03, 8.6097e-01, 1.1103e-01, 7.2171e-03, 3.2255e-03, 7.4498e-03,
        3.2447e-03, 6.3512e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,010][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0158, 0.2893, 0.0960, 0.2026, 0.0851, 0.0921, 0.1220, 0.0972],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,010][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.9791, 0.0016, 0.0017, 0.0021, 0.0023, 0.0027, 0.0069, 0.0036],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,011][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([5.1774e-04, 6.6053e-01, 3.2243e-01, 6.2098e-03, 4.8954e-03, 2.3371e-03,
        2.9225e-03, 1.5700e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,014][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0737, 0.6046, 0.2706, 0.0131, 0.0085, 0.0220, 0.0048, 0.0014, 0.0013],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,016][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([3.1018e-05, 9.6231e-01, 3.4305e-02, 1.4972e-03, 2.6063e-04, 1.0754e-03,
        4.2025e-04, 3.2155e-05, 6.7351e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,022][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.1234, 0.2499, 0.3079, 0.0861, 0.1063, 0.0424, 0.0330, 0.0221, 0.0289],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,023][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.4892, 0.3262, 0.1147, 0.0262, 0.0063, 0.0245, 0.0071, 0.0034, 0.0023],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,023][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([9.7766e-01, 5.7454e-03, 5.6013e-03, 4.1939e-03, 8.5730e-04, 2.5262e-03,
        2.3227e-03, 5.5060e-04, 5.4600e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,024][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([1.0840e-03, 8.1761e-01, 1.5959e-01, 8.6413e-03, 3.7351e-03, 4.4832e-03,
        3.4580e-03, 6.7517e-04, 7.2989e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,025][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([9.9618e-01, 6.1361e-04, 4.2991e-04, 6.9440e-04, 2.1622e-04, 7.9629e-04,
        3.6034e-04, 4.1948e-04, 2.8761e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,028][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0320, 0.6127, 0.2950, 0.0246, 0.0119, 0.0111, 0.0085, 0.0017, 0.0025],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,030][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([5.6009e-03, 9.0351e-01, 7.9738e-02, 4.6359e-03, 1.4543e-03, 2.8832e-03,
        1.6423e-03, 2.7671e-04, 2.6050e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,036][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0751, 0.1487, 0.0682, 0.0842, 0.1055, 0.1331, 0.1845, 0.1299, 0.0707],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,036][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.9463, 0.0032, 0.0035, 0.0031, 0.0037, 0.0037, 0.0143, 0.0073, 0.0148],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,037][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([2.0334e-04, 6.8244e-01, 3.0414e-01, 4.9584e-03, 4.3239e-03, 2.4984e-03,
        1.1938e-03, 1.0116e-04, 1.3840e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,038][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4723, 0.3132, 0.1604, 0.0106, 0.0073, 0.0213, 0.0068, 0.0023, 0.0033,
        0.0025], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,039][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8605e-04, 9.6769e-01, 2.6124e-02, 2.2699e-03, 2.6857e-04, 2.0012e-03,
        7.8533e-04, 9.1728e-05, 1.6271e-04, 3.1604e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,042][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1770, 0.1655, 0.2504, 0.0807, 0.1243, 0.0402, 0.0424, 0.0222, 0.0501,
        0.0473], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,046][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.7841, 0.0935, 0.0543, 0.0171, 0.0052, 0.0212, 0.0115, 0.0045, 0.0038,
        0.0048], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,050][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9219e-01, 1.3380e-03, 3.0113e-03, 1.0260e-03, 4.8947e-04, 8.3669e-04,
        6.1579e-04, 1.2131e-04, 2.2134e-04, 1.5302e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,050][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0140, 0.7913, 0.1541, 0.0114, 0.0042, 0.0082, 0.0076, 0.0019, 0.0029,
        0.0045], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,051][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9681e-01, 2.8187e-04, 3.9884e-04, 6.1834e-04, 2.3724e-04, 5.2376e-04,
        2.7630e-04, 4.1589e-04, 1.8609e-04, 2.5487e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,052][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1357, 0.3990, 0.3759, 0.0259, 0.0203, 0.0126, 0.0156, 0.0028, 0.0056,
        0.0066], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,053][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1648, 0.6872, 0.1016, 0.0117, 0.0047, 0.0137, 0.0061, 0.0024, 0.0036,
        0.0042], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,055][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0013, 0.2235, 0.0457, 0.1256, 0.0668, 0.1048, 0.0763, 0.0702, 0.0671,
        0.2187], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,060][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9715, 0.0015, 0.0016, 0.0017, 0.0018, 0.0015, 0.0064, 0.0027, 0.0084,
        0.0030], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,063][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.4570e-03, 7.1405e-01, 2.5009e-01, 8.2279e-03, 6.4330e-03, 4.7241e-03,
        5.2221e-03, 5.2148e-04, 1.8191e-03, 1.4580e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,064][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0783, 0.4855, 0.3786, 0.0124, 0.0136, 0.0203, 0.0052, 0.0017, 0.0023,
        0.0015, 0.0005], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,065][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.0816e-05, 9.6529e-01, 3.2575e-02, 9.2034e-04, 1.4162e-04, 6.0077e-04,
        2.1889e-04, 2.5885e-05, 7.5059e-05, 1.3422e-04, 1.0681e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,066][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1060, 0.1544, 0.3327, 0.0648, 0.1199, 0.0330, 0.0427, 0.0196, 0.0542,
        0.0414, 0.0311], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,067][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4639, 0.2674, 0.1517, 0.0317, 0.0119, 0.0322, 0.0196, 0.0059, 0.0056,
        0.0079, 0.0021], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,068][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.8180e-01, 3.3398e-03, 5.9086e-03, 3.2722e-03, 9.3548e-04, 2.2201e-03,
        1.1880e-03, 2.6276e-04, 4.7343e-04, 3.4315e-04, 2.5561e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,071][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.3412e-03, 8.2409e-01, 1.5319e-01, 5.8090e-03, 2.9398e-03, 4.3457e-03,
        3.8262e-03, 7.5208e-04, 1.2558e-03, 2.0065e-03, 4.4455e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,074][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.9257e-01, 9.1756e-04, 7.5115e-04, 1.0346e-03, 4.4359e-04, 1.1523e-03,
        6.4406e-04, 8.5086e-04, 3.8764e-04, 4.3769e-04, 8.0678e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,077][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0259, 0.4306, 0.4850, 0.0159, 0.0197, 0.0071, 0.0075, 0.0012, 0.0028,
        0.0035, 0.0010], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,078][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([7.6506e-03, 8.6560e-01, 1.0821e-01, 6.2359e-03, 2.7359e-03, 5.3875e-03,
        1.5950e-03, 6.7209e-04, 6.7700e-04, 1.1127e-03, 1.2989e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,079][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0006, 0.2305, 0.0562, 0.1272, 0.0491, 0.0352, 0.0604, 0.0536, 0.0633,
        0.2659, 0.0580], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,080][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9587, 0.0019, 0.0019, 0.0015, 0.0020, 0.0016, 0.0069, 0.0031, 0.0126,
        0.0041, 0.0056], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,081][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.4287e-04, 6.7596e-01, 3.1124e-01, 3.9367e-03, 4.4126e-03, 1.6201e-03,
        1.5277e-03, 1.6947e-04, 3.9111e-04, 4.2849e-04, 7.6188e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,082][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([2.9841e-03, 6.5141e-01, 3.2045e-01, 6.9357e-03, 6.1979e-03, 7.5882e-03,
        1.4861e-03, 5.2272e-04, 8.3515e-04, 1.0893e-03, 2.7763e-04, 2.2081e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,085][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([1.2193e-05, 9.4345e-01, 5.4617e-02, 6.6704e-04, 2.0301e-04, 5.4931e-04,
        2.1123e-04, 2.8636e-05, 4.8992e-05, 1.7626e-04, 1.8599e-05, 1.6260e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,089][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0453, 0.2041, 0.3042, 0.0866, 0.1075, 0.0318, 0.0532, 0.0300, 0.0385,
        0.0434, 0.0230, 0.0324], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,091][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.2127, 0.4573, 0.2219, 0.0369, 0.0146, 0.0292, 0.0132, 0.0039, 0.0026,
        0.0048, 0.0012, 0.0017], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,092][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([9.7164e-01, 7.4284e-03, 6.9894e-03, 3.8055e-03, 7.1768e-04, 2.2003e-03,
        3.3956e-03, 9.1157e-04, 4.8198e-04, 7.9700e-04, 5.7267e-04, 1.0601e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,093][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.6303e-04, 8.3506e-01, 1.4983e-01, 5.3575e-03, 2.7631e-03, 2.5075e-03,
        2.2601e-03, 3.4503e-04, 5.5525e-04, 8.5853e-04, 1.5652e-04, 1.4791e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,094][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([9.9131e-01, 1.0877e-03, 6.8461e-04, 1.7433e-03, 3.6341e-04, 1.1850e-03,
        4.2774e-04, 8.0409e-04, 3.3866e-04, 4.7280e-04, 4.3366e-04, 1.1459e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,095][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([4.1387e-03, 5.9642e-01, 3.7126e-01, 1.0811e-02, 7.3968e-03, 2.7846e-03,
        3.4952e-03, 2.9432e-04, 7.2018e-04, 1.2553e-03, 4.4891e-04, 9.6814e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,096][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.5907e-04, 9.0153e-01, 9.1189e-02, 3.0194e-03, 1.4033e-03, 1.2439e-03,
        7.0993e-04, 1.0664e-04, 1.9353e-04, 3.6076e-04, 6.3426e-05, 1.7913e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,100][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0931, 0.1464, 0.0539, 0.1215, 0.0254, 0.0820, 0.1187, 0.0802, 0.0757,
        0.0721, 0.0939, 0.0371], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,105][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.8941, 0.0043, 0.0034, 0.0041, 0.0033, 0.0049, 0.0175, 0.0056, 0.0210,
        0.0104, 0.0113, 0.0200], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,106][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.9148e-05, 7.5919e-01, 2.3560e-01, 2.2225e-03, 1.5574e-03, 4.3590e-04,
        5.7272e-04, 3.3863e-05, 1.2860e-04, 1.8196e-04, 2.6602e-05, 2.6603e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,107][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([4.3971e-02, 6.3285e-01, 2.9593e-01, 3.7925e-03, 5.0080e-03, 1.0616e-02,
        3.7447e-03, 1.0541e-03, 1.1251e-03, 8.8538e-04, 3.7282e-04, 4.0708e-04,
        2.4490e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,107][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([5.1524e-06, 9.7613e-01, 2.2182e-02, 4.9830e-04, 9.9526e-05, 5.7658e-04,
        2.4967e-04, 3.2902e-05, 7.9445e-05, 1.0825e-04, 1.0654e-05, 1.3713e-05,
        1.3825e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,108][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0758, 0.2003, 0.3043, 0.0814, 0.0743, 0.0416, 0.0348, 0.0178, 0.0441,
        0.0393, 0.0272, 0.0325, 0.0268], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,112][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1133, 0.5112, 0.2394, 0.0301, 0.0134, 0.0449, 0.0208, 0.0054, 0.0072,
        0.0078, 0.0026, 0.0027, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,115][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([9.3481e-01, 1.0723e-02, 1.8176e-02, 1.0090e-02, 2.8975e-03, 7.6266e-03,
        5.6618e-03, 9.3478e-04, 2.5801e-03, 1.4158e-03, 9.1984e-04, 2.0124e-03,
        2.1480e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,119][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([5.5914e-04, 8.1152e-01, 1.7296e-01, 4.9230e-03, 2.0642e-03, 2.9150e-03,
        1.8661e-03, 4.4951e-04, 7.0235e-04, 1.2064e-03, 2.2834e-04, 2.7401e-04,
        3.3512e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,119][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.8569e-01, 1.4267e-03, 2.0320e-03, 1.8931e-03, 9.8007e-04, 1.6183e-03,
        7.9344e-04, 1.0869e-03, 4.0079e-04, 6.0816e-04, 7.1021e-04, 1.0113e-03,
        1.7533e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,120][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0063, 0.4997, 0.4471, 0.0090, 0.0124, 0.0070, 0.0074, 0.0012, 0.0025,
        0.0036, 0.0011, 0.0021, 0.0006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,121][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.0339e-03, 8.1376e-01, 1.7114e-01, 3.2508e-03, 1.8546e-03, 3.8133e-03,
        1.4339e-03, 4.0549e-04, 4.4859e-04, 6.2212e-04, 1.4793e-04, 4.8648e-05,
        3.7732e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,122][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0010, 0.1577, 0.0383, 0.0555, 0.0513, 0.0668, 0.0541, 0.0607, 0.0558,
        0.1988, 0.0780, 0.0721, 0.1098], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,126][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.8575, 0.0081, 0.0075, 0.0091, 0.0084, 0.0048, 0.0150, 0.0077, 0.0287,
        0.0090, 0.0140, 0.0214, 0.0088], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,129][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.2811e-04, 7.5118e-01, 2.4251e-01, 2.1218e-03, 1.9585e-03, 8.0389e-04,
        6.7827e-04, 7.1952e-05, 2.0936e-04, 2.3244e-04, 5.1557e-05, 3.6552e-05,
        2.2997e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,132][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([2.6438e-02, 5.6101e-01, 3.7665e-01, 6.8154e-03, 9.6042e-03, 1.0477e-02,
        4.1450e-03, 9.2636e-04, 1.1901e-03, 1.0480e-03, 5.1539e-04, 5.0815e-04,
        2.9170e-04, 3.8060e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,133][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([5.4232e-05, 9.4280e-01, 5.1795e-02, 2.8802e-03, 4.2256e-04, 1.1886e-03,
        4.1077e-04, 6.8837e-05, 8.2824e-05, 1.9305e-04, 2.9579e-05, 2.8379e-05,
        3.7627e-05, 4.3163e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,134][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1339, 0.2373, 0.2436, 0.0634, 0.0663, 0.0405, 0.0309, 0.0245, 0.0262,
        0.0338, 0.0270, 0.0251, 0.0291, 0.0183], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,135][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.3267, 0.3749, 0.1821, 0.0304, 0.0098, 0.0360, 0.0173, 0.0052, 0.0044,
        0.0067, 0.0017, 0.0022, 0.0019, 0.0007], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,136][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([9.3859e-01, 1.3760e-02, 2.0875e-02, 8.1548e-03, 3.2897e-03, 4.5190e-03,
        3.6041e-03, 8.2626e-04, 7.8365e-04, 6.5557e-04, 4.3834e-04, 2.3742e-03,
        1.0059e-03, 1.1253e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,138][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([7.9333e-04, 7.1761e-01, 2.5725e-01, 7.8562e-03, 4.2822e-03, 4.6535e-03,
        3.5130e-03, 5.1470e-04, 9.7998e-04, 1.3796e-03, 2.6912e-04, 3.7563e-04,
        4.0275e-04, 1.1876e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,140][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([9.9390e-01, 2.1350e-04, 6.6995e-04, 6.1831e-04, 6.7125e-04, 5.0104e-04,
        1.5717e-04, 6.4609e-04, 9.4769e-05, 1.6154e-04, 1.7655e-04, 2.0741e-04,
        4.9990e-04, 1.4820e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,146][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0151, 0.5058, 0.4208, 0.0199, 0.0114, 0.0070, 0.0083, 0.0013, 0.0023,
        0.0032, 0.0011, 0.0021, 0.0007, 0.0009], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,149][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([3.6042e-03, 8.5949e-01, 1.2897e-01, 3.2154e-03, 1.2375e-03, 1.8665e-03,
        7.3604e-04, 2.2752e-04, 1.4778e-04, 3.7114e-04, 5.9257e-05, 3.3888e-05,
        2.6080e-05, 1.6581e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,150][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0272, 0.0555, 0.0175, 0.0666, 0.0287, 0.1685, 0.0955, 0.0575, 0.0399,
        0.1053, 0.0492, 0.1027, 0.1648, 0.0211], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,151][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.9681, 0.0015, 0.0015, 0.0015, 0.0013, 0.0015, 0.0044, 0.0023, 0.0052,
        0.0018, 0.0029, 0.0048, 0.0013, 0.0018], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,152][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([2.4514e-04, 7.9338e-01, 1.9887e-01, 2.6802e-03, 1.3987e-03, 1.5495e-03,
        1.0144e-03, 9.9867e-05, 2.7741e-04, 2.6949e-04, 7.8194e-05, 6.1357e-05,
        4.2305e-05, 3.0190e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,152][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([1.1922e-02, 5.5529e-01, 3.9700e-01, 6.8804e-03, 1.0195e-02, 9.1242e-03,
        4.1905e-03, 7.8240e-04, 1.2940e-03, 8.3098e-04, 4.1777e-04, 6.2028e-04,
        3.1308e-04, 7.1809e-04, 4.2186e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,154][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([1.5768e-04, 9.6037e-01, 3.2972e-02, 3.0779e-03, 3.7882e-04, 1.6207e-03,
        6.4616e-04, 1.4497e-04, 1.3814e-04, 2.9635e-04, 4.5480e-05, 2.9247e-05,
        6.4348e-05, 6.9082e-06, 5.3765e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,159][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0651, 0.1714, 0.2403, 0.0663, 0.1043, 0.0303, 0.0363, 0.0282, 0.0441,
        0.0490, 0.0344, 0.0458, 0.0354, 0.0280, 0.0209], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,163][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.2828, 0.3204, 0.2439, 0.0345, 0.0145, 0.0296, 0.0271, 0.0056, 0.0147,
        0.0119, 0.0043, 0.0050, 0.0025, 0.0018, 0.0015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,164][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.8519, 0.0366, 0.0499, 0.0147, 0.0060, 0.0091, 0.0104, 0.0019, 0.0020,
        0.0031, 0.0015, 0.0044, 0.0029, 0.0027, 0.0030], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,164][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([1.2730e-03, 7.4778e-01, 2.2013e-01, 8.9169e-03, 6.2495e-03, 4.7275e-03,
        4.5944e-03, 7.7529e-04, 1.1582e-03, 1.8793e-03, 5.1853e-04, 7.1570e-04,
        5.9545e-04, 2.7049e-04, 4.0987e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,165][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([9.8555e-01, 1.1728e-03, 1.1870e-03, 1.4434e-03, 5.5918e-04, 1.6088e-03,
        6.2718e-04, 1.2175e-03, 6.3549e-04, 6.5947e-04, 8.8313e-04, 9.8779e-04,
        1.6110e-03, 1.1119e-03, 7.4379e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,166][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0090, 0.4572, 0.4649, 0.0099, 0.0171, 0.0081, 0.0121, 0.0017, 0.0058,
        0.0048, 0.0016, 0.0028, 0.0010, 0.0022, 0.0016], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,168][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([3.0568e-03, 8.5143e-01, 1.3407e-01, 3.8375e-03, 2.0984e-03, 2.5449e-03,
        1.4955e-03, 4.0484e-04, 2.8575e-04, 4.6879e-04, 1.0149e-04, 5.8463e-05,
        4.0547e-05, 4.9600e-05, 6.0794e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,172][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0109, 0.0962, 0.0517, 0.0424, 0.0402, 0.0479, 0.0740, 0.0343, 0.0383,
        0.1472, 0.1046, 0.0534, 0.1368, 0.0945, 0.0277], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,176][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.9141, 0.0022, 0.0024, 0.0026, 0.0024, 0.0016, 0.0076, 0.0041, 0.0169,
        0.0063, 0.0077, 0.0142, 0.0045, 0.0055, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,177][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([4.2913e-04, 6.6944e-01, 3.1741e-01, 5.1140e-03, 3.3052e-03, 1.3657e-03,
        1.6033e-03, 1.1896e-04, 4.3033e-04, 4.2102e-04, 9.5066e-05, 9.0481e-05,
        5.0085e-05, 6.0170e-05, 7.0912e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,178][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3793, 0.3294, 0.2211, 0.0092, 0.0108, 0.0232, 0.0091, 0.0028, 0.0032,
        0.0023, 0.0012, 0.0015, 0.0007, 0.0021, 0.0024, 0.0017],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,179][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.1881e-04, 9.5379e-01, 3.8620e-02, 2.7179e-03, 3.9558e-04, 2.0364e-03,
        8.7486e-04, 1.3119e-04, 1.9625e-04, 2.8614e-04, 6.3498e-05, 8.2115e-05,
        6.2866e-05, 1.4463e-05, 1.0298e-04, 1.0469e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,180][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1604, 0.1167, 0.2425, 0.0620, 0.0961, 0.0318, 0.0389, 0.0202, 0.0432,
        0.0357, 0.0238, 0.0254, 0.0282, 0.0280, 0.0208, 0.0264],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,184][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.6641, 0.1216, 0.1034, 0.0218, 0.0093, 0.0268, 0.0196, 0.0063, 0.0062,
        0.0068, 0.0027, 0.0032, 0.0014, 0.0014, 0.0021, 0.0032],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,185][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.5257e-01, 9.3524e-03, 2.0818e-02, 3.6771e-03, 2.6032e-03, 2.6480e-03,
        2.3735e-03, 4.5135e-04, 6.4693e-04, 5.1260e-04, 2.7084e-04, 7.6955e-04,
        7.0158e-04, 1.4059e-03, 6.9574e-04, 5.0678e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,186][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.0192e-02, 7.2196e-01, 2.1591e-01, 1.2228e-02, 6.3124e-03, 8.8815e-03,
        8.2179e-03, 1.8846e-03, 3.0235e-03, 3.8254e-03, 1.0359e-03, 1.1226e-03,
        1.2997e-03, 6.8125e-04, 1.4011e-03, 2.0279e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,189][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.9093e-01, 6.9154e-04, 1.1486e-03, 1.2261e-03, 6.0045e-04, 7.0809e-04,
        3.3782e-04, 6.9749e-04, 2.7007e-04, 3.3757e-04, 3.6791e-04, 4.2441e-04,
        9.4069e-04, 7.7546e-04, 1.9832e-04, 3.5046e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,191][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0666, 0.3829, 0.4434, 0.0216, 0.0234, 0.0117, 0.0150, 0.0029, 0.0051,
        0.0060, 0.0026, 0.0050, 0.0017, 0.0058, 0.0028, 0.0037],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,192][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.0775e-01, 6.8686e-01, 1.5185e-01, 1.1496e-02, 6.9667e-03, 1.1991e-02,
        7.9595e-03, 2.4151e-03, 4.0242e-03, 3.7291e-03, 1.3274e-03, 2.5662e-04,
        3.0739e-04, 5.3000e-04, 8.7270e-04, 1.6670e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,193][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0008, 0.1921, 0.0360, 0.0698, 0.0428, 0.0705, 0.0463, 0.0439, 0.0353,
        0.1020, 0.0610, 0.0469, 0.1114, 0.0442, 0.0332, 0.0639],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,194][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9605, 0.0014, 0.0014, 0.0015, 0.0016, 0.0011, 0.0042, 0.0019, 0.0061,
        0.0022, 0.0033, 0.0067, 0.0015, 0.0021, 0.0030, 0.0015],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,195][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.3299e-03, 7.3124e-01, 2.4488e-01, 5.5895e-03, 5.3720e-03, 2.8014e-03,
        3.5443e-03, 2.9031e-04, 1.1722e-03, 8.1137e-04, 3.3960e-04, 3.2481e-04,
        1.1829e-04, 3.2872e-04, 3.8893e-04, 4.6800e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,197][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.3306e-02, 5.1868e-01, 4.2472e-01, 8.5647e-03, 1.3183e-02, 9.0256e-03,
        3.7010e-03, 9.5778e-04, 1.4130e-03, 1.6956e-03, 4.0905e-04, 6.9875e-04,
        2.3993e-04, 7.6347e-04, 7.0049e-04, 9.6699e-04, 9.7852e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,200][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([9.8930e-05, 9.2259e-01, 7.2630e-02, 1.8417e-03, 3.6447e-04, 1.3403e-03,
        6.3716e-04, 4.4336e-05, 8.3417e-05, 1.3558e-04, 4.2996e-05, 3.8747e-05,
        4.7189e-05, 7.8149e-06, 2.5208e-05, 4.5160e-05, 2.7070e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,205][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.1014, 0.1341, 0.3103, 0.0413, 0.1138, 0.0209, 0.0387, 0.0185, 0.0281,
        0.0309, 0.0236, 0.0287, 0.0260, 0.0334, 0.0144, 0.0229, 0.0132],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,206][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.6006, 0.1624, 0.1436, 0.0239, 0.0114, 0.0241, 0.0124, 0.0028, 0.0042,
        0.0041, 0.0017, 0.0024, 0.0010, 0.0012, 0.0011, 0.0020, 0.0011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,207][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([9.1352e-01, 1.6296e-02, 4.4262e-02, 5.5068e-03, 5.8418e-03, 3.0832e-03,
        3.4743e-03, 5.9898e-04, 5.8667e-04, 6.1785e-04, 3.0836e-04, 6.7808e-04,
        8.5849e-04, 2.8152e-03, 6.7271e-04, 5.9922e-04, 2.7969e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,208][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([1.5923e-03, 7.7600e-01, 1.9426e-01, 8.0001e-03, 5.0579e-03, 4.3809e-03,
        3.5972e-03, 7.3536e-04, 1.0286e-03, 1.7718e-03, 4.4841e-04, 5.0096e-04,
        5.8228e-04, 2.2625e-04, 4.5287e-04, 8.3869e-04, 5.1776e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,209][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([9.8269e-01, 1.7120e-03, 2.5661e-03, 1.5128e-03, 1.3323e-03, 1.0320e-03,
        6.3263e-04, 9.3815e-04, 4.0044e-04, 4.3802e-04, 6.4369e-04, 7.1422e-04,
        1.4285e-03, 1.7035e-03, 3.7353e-04, 4.5721e-04, 1.4236e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,212][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0145, 0.3406, 0.5901, 0.0100, 0.0185, 0.0042, 0.0053, 0.0011, 0.0017,
        0.0030, 0.0009, 0.0023, 0.0008, 0.0039, 0.0007, 0.0015, 0.0009],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,215][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([7.9859e-03, 8.0799e-01, 1.6158e-01, 6.2415e-03, 4.2029e-03, 4.9489e-03,
        2.6546e-03, 7.5311e-04, 7.1806e-04, 1.3399e-03, 2.3269e-04, 1.1814e-04,
        8.5318e-05, 1.3028e-04, 1.9643e-04, 4.6576e-04, 3.5658e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,219][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0024, 0.1633, 0.0678, 0.0415, 0.0269, 0.0849, 0.0487, 0.0669, 0.0524,
        0.0713, 0.0576, 0.0253, 0.0907, 0.0780, 0.0408, 0.0596, 0.0218],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,220][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.9437, 0.0012, 0.0017, 0.0012, 0.0016, 0.0013, 0.0067, 0.0026, 0.0112,
        0.0032, 0.0047, 0.0059, 0.0023, 0.0024, 0.0035, 0.0021, 0.0047],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,220][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([1.7004e-04, 6.5434e-01, 3.3566e-01, 3.0295e-03, 3.5440e-03, 1.1987e-03,
        8.8615e-04, 1.0738e-04, 1.8052e-04, 3.0855e-04, 7.3548e-05, 8.5186e-05,
        2.6548e-05, 8.3771e-05, 7.4912e-05, 1.7008e-04, 6.4560e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,221][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.2226e-02, 4.0715e-01, 4.9967e-01, 9.8072e-03, 1.9193e-02, 1.4455e-02,
        5.2622e-03, 1.4294e-03, 1.9691e-03, 1.4427e-03, 5.0965e-04, 9.3296e-04,
        3.9966e-04, 1.6341e-03, 1.0479e-03, 8.4697e-04, 1.5997e-03, 4.2791e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,223][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([6.4700e-05, 9.1077e-01, 8.4969e-02, 1.9482e-03, 6.1002e-04, 6.8955e-04,
        3.3154e-04, 6.4293e-05, 1.0985e-04, 1.6473e-04, 3.6506e-05, 2.7752e-05,
        4.8504e-05, 1.3247e-05, 4.0705e-05, 6.5237e-05, 2.9402e-05, 1.3302e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,226][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0857, 0.1112, 0.4122, 0.0263, 0.0997, 0.0150, 0.0271, 0.0142, 0.0331,
        0.0237, 0.0193, 0.0300, 0.0164, 0.0271, 0.0116, 0.0166, 0.0116, 0.0189],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,231][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4076, 0.2353, 0.2092, 0.0341, 0.0172, 0.0341, 0.0250, 0.0062, 0.0070,
        0.0073, 0.0025, 0.0033, 0.0017, 0.0017, 0.0021, 0.0031, 0.0019, 0.0007],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,232][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.6066e-01, 6.1278e-03, 2.0296e-02, 2.9396e-03, 2.3275e-03, 1.8306e-03,
        1.2621e-03, 3.5350e-04, 3.5263e-04, 3.6352e-04, 1.9280e-04, 4.1259e-04,
        5.8100e-04, 1.3358e-03, 3.1414e-04, 3.3499e-04, 1.5198e-04, 1.5876e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,233][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.1959e-03, 7.1937e-01, 2.5263e-01, 6.8311e-03, 4.9667e-03, 3.7982e-03,
        3.4410e-03, 7.5962e-04, 1.2340e-03, 1.6991e-03, 4.1291e-04, 4.6447e-04,
        6.2254e-04, 3.0767e-04, 4.5807e-04, 7.8160e-04, 6.9906e-04, 3.2779e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,234][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.8116e-01, 1.6019e-03, 2.0381e-03, 1.6001e-03, 1.3648e-03, 1.0088e-03,
        5.2579e-04, 1.2539e-03, 3.1787e-04, 5.0351e-04, 7.1917e-04, 8.1653e-04,
        1.9506e-03, 1.9982e-03, 3.4393e-04, 6.5761e-04, 8.4369e-04, 1.2965e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,235][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0116, 0.3420, 0.5814, 0.0109, 0.0246, 0.0045, 0.0056, 0.0011, 0.0024,
        0.0028, 0.0010, 0.0021, 0.0009, 0.0041, 0.0011, 0.0017, 0.0016, 0.0007],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,237][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.1135e-03, 7.9060e-01, 1.8495e-01, 6.4317e-03, 4.3820e-03, 3.2370e-03,
        1.8226e-03, 4.2046e-04, 5.8838e-04, 9.6397e-04, 1.3889e-04, 8.7312e-05,
        8.2204e-05, 1.2854e-04, 1.6024e-04, 3.6742e-04, 3.8399e-04, 1.4115e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,241][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0004, 0.3076, 0.0376, 0.0829, 0.0185, 0.0272, 0.0212, 0.0299, 0.0333,
        0.0995, 0.0314, 0.0226, 0.0943, 0.0246, 0.0413, 0.0670, 0.0400, 0.0207],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,246][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9465, 0.0022, 0.0014, 0.0014, 0.0017, 0.0013, 0.0050, 0.0021, 0.0066,
        0.0032, 0.0038, 0.0088, 0.0026, 0.0021, 0.0035, 0.0022, 0.0038, 0.0016],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,247][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.0553e-05, 7.1198e-01, 2.7893e-01, 2.4884e-03, 3.5151e-03, 9.6804e-04,
        8.1474e-04, 8.9039e-05, 2.2619e-04, 2.8081e-04, 4.9465e-05, 9.2819e-05,
        2.7654e-05, 1.0168e-04, 6.3239e-05, 1.4085e-04, 1.0472e-04, 5.7061e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,248][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.8897e-02, 5.3235e-01, 4.0252e-01, 1.5531e-02, 9.2069e-03, 1.1022e-02,
        2.9869e-03, 7.8319e-04, 1.2578e-03, 9.4448e-04, 6.1871e-04, 7.4441e-04,
        2.6414e-04, 3.8957e-04, 3.8749e-04, 5.3691e-04, 8.2506e-04, 3.8800e-04,
        3.5034e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,249][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([7.6963e-05, 8.7277e-01, 1.2348e-01, 1.6449e-03, 4.3305e-04, 7.5074e-04,
        3.6132e-04, 4.4222e-05, 9.8909e-05, 1.2659e-04, 2.7445e-05, 2.1297e-05,
        3.3289e-05, 4.6181e-06, 3.3448e-05, 3.7098e-05, 2.4906e-05, 8.8450e-06,
        1.4509e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,251][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0533, 0.1744, 0.2988, 0.0449, 0.1098, 0.0255, 0.0377, 0.0177, 0.0410,
        0.0290, 0.0153, 0.0308, 0.0250, 0.0206, 0.0144, 0.0202, 0.0124, 0.0198,
        0.0094], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,255][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.2518, 0.3557, 0.2713, 0.0331, 0.0193, 0.0358, 0.0130, 0.0039, 0.0027,
        0.0036, 0.0015, 0.0016, 0.0009, 0.0011, 0.0008, 0.0017, 0.0011, 0.0006,
        0.0004], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,258][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([9.5756e-01, 6.5284e-03, 1.9227e-02, 2.7639e-03, 3.6222e-03, 1.7755e-03,
        2.3259e-03, 3.0642e-04, 2.6380e-04, 2.9299e-04, 2.5388e-04, 1.1491e-03,
        3.3832e-04, 1.5922e-03, 4.0459e-04, 2.3970e-04, 2.3591e-04, 2.7782e-04,
        8.3996e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,260][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([7.9472e-04, 7.1175e-01, 2.5915e-01, 7.8535e-03, 5.9853e-03, 4.5303e-03,
        3.6482e-03, 5.7695e-04, 1.2318e-03, 1.3749e-03, 2.8841e-04, 3.8554e-04,
        4.2481e-04, 1.5140e-04, 3.5167e-04, 5.6957e-04, 4.5380e-04, 3.2138e-04,
        1.5559e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,261][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([9.8643e-01, 1.2631e-03, 1.1239e-03, 1.1460e-03, 5.7494e-04, 8.9760e-04,
        5.1574e-04, 1.0012e-03, 2.7055e-04, 3.3351e-04, 4.3627e-04, 7.0985e-04,
        1.0841e-03, 9.0783e-04, 2.7036e-04, 3.5153e-04, 8.7244e-04, 6.8496e-04,
        1.1249e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,262][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0074, 0.4274, 0.5113, 0.0090, 0.0149, 0.0038, 0.0063, 0.0010, 0.0025,
        0.0025, 0.0010, 0.0022, 0.0007, 0.0019, 0.0009, 0.0013, 0.0023, 0.0007,
        0.0032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,262][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([3.6355e-03, 7.8283e-01, 2.0043e-01, 4.0227e-03, 4.2755e-03, 1.7503e-03,
        1.2755e-03, 2.5543e-04, 2.8528e-04, 4.1217e-04, 9.1005e-05, 4.8331e-05,
        4.5901e-05, 4.4305e-05, 9.2261e-05, 1.4097e-04, 2.3175e-04, 1.1721e-04,
        1.8368e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,265][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0167, 0.0379, 0.0625, 0.0469, 0.0190, 0.0126, 0.0431, 0.0449, 0.0491,
        0.1519, 0.0433, 0.0375, 0.0669, 0.0479, 0.0574, 0.1109, 0.0490, 0.0531,
        0.0494], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,270][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.8163, 0.0052, 0.0046, 0.0052, 0.0046, 0.0042, 0.0178, 0.0070, 0.0267,
        0.0087, 0.0116, 0.0193, 0.0075, 0.0071, 0.0100, 0.0056, 0.0113, 0.0054,
        0.0217], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,273][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([2.0341e-04, 6.9647e-01, 2.9200e-01, 3.6754e-03, 4.6092e-03, 1.5878e-03,
        4.4376e-04, 6.2862e-05, 2.5754e-04, 1.9580e-04, 6.4662e-05, 3.9463e-05,
        3.2348e-05, 6.7262e-05, 5.3240e-05, 8.7105e-05, 7.1545e-05, 6.6090e-05,
        1.4932e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,274][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1457, 0.4330, 0.3572, 0.0092, 0.0151, 0.0172, 0.0070, 0.0016, 0.0021,
        0.0015, 0.0008, 0.0011, 0.0005, 0.0013, 0.0013, 0.0009, 0.0021, 0.0007,
        0.0011, 0.0006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,275][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.4642e-04, 9.2780e-01, 6.6917e-02, 2.1092e-03, 5.3573e-04, 1.3657e-03,
        4.9486e-04, 6.2458e-05, 1.0728e-04, 1.4641e-04, 3.3492e-05, 4.3263e-05,
        3.7130e-05, 1.0084e-05, 4.7327e-05, 5.0833e-05, 3.0658e-05, 1.7991e-05,
        2.0564e-05, 2.5972e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,276][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1043, 0.1268, 0.2657, 0.0514, 0.1026, 0.0265, 0.0363, 0.0175, 0.0390,
        0.0316, 0.0214, 0.0235, 0.0236, 0.0265, 0.0165, 0.0222, 0.0134, 0.0228,
        0.0079, 0.0204], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,279][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4558, 0.2191, 0.1958, 0.0285, 0.0141, 0.0302, 0.0214, 0.0053, 0.0057,
        0.0058, 0.0022, 0.0032, 0.0014, 0.0013, 0.0018, 0.0025, 0.0021, 0.0008,
        0.0013, 0.0016], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,281][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.3598e-01, 1.2036e-02, 3.0489e-02, 4.0849e-03, 3.6456e-03, 2.9286e-03,
        2.2167e-03, 4.5897e-04, 5.9848e-04, 5.2781e-04, 2.7026e-04, 7.5416e-04,
        7.4161e-04, 1.7662e-03, 6.5127e-04, 5.0250e-04, 3.0231e-04, 2.4221e-04,
        1.2520e-03, 5.5486e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,284][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.7110e-03, 7.0003e-01, 2.6200e-01, 8.4154e-03, 5.8122e-03, 5.4352e-03,
        4.8461e-03, 9.2495e-04, 1.6379e-03, 1.9435e-03, 5.4346e-04, 6.6028e-04,
        6.9810e-04, 3.4425e-04, 6.6125e-04, 9.2139e-04, 1.0096e-03, 5.5481e-04,
        2.8312e-04, 5.6820e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,287][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8324e-01, 1.1425e-03, 1.9085e-03, 1.7992e-03, 1.0255e-03, 1.0084e-03,
        4.6336e-04, 1.0965e-03, 3.7943e-04, 4.8712e-04, 5.2125e-04, 6.4171e-04,
        1.4223e-03, 1.2034e-03, 2.7120e-04, 5.4147e-04, 6.9482e-04, 6.6740e-04,
        6.8441e-04, 7.9809e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,288][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0284, 0.3422, 0.5404, 0.0159, 0.0235, 0.0067, 0.0093, 0.0016, 0.0032,
        0.0034, 0.0015, 0.0030, 0.0011, 0.0038, 0.0016, 0.0020, 0.0031, 0.0012,
        0.0062, 0.0018], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,289][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6024e-02, 7.3356e-01, 2.0683e-01, 8.9026e-03, 6.1268e-03, 6.2597e-03,
        3.6266e-03, 9.3871e-04, 1.6277e-03, 1.6961e-03, 5.6745e-04, 1.5201e-04,
        1.3433e-04, 1.9955e-04, 3.3554e-04, 6.3934e-04, 1.1225e-03, 6.0930e-04,
        2.4070e-04, 4.0722e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,290][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0003, 0.1882, 0.0333, 0.0598, 0.0290, 0.0644, 0.0393, 0.0433, 0.0276,
        0.0907, 0.0460, 0.0380, 0.0954, 0.0332, 0.0261, 0.0569, 0.0533, 0.0274,
        0.0123, 0.0355], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,293][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9354, 0.0019, 0.0014, 0.0017, 0.0019, 0.0013, 0.0048, 0.0024, 0.0066,
        0.0027, 0.0042, 0.0095, 0.0019, 0.0027, 0.0038, 0.0019, 0.0039, 0.0019,
        0.0083, 0.0018], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,295][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.3840e-04, 7.0251e-01, 2.8326e-01, 3.8012e-03, 5.1572e-03, 1.4025e-03,
        1.4507e-03, 1.0032e-04, 4.2621e-04, 3.1210e-04, 1.4361e-04, 1.3071e-04,
        5.2295e-05, 1.4010e-04, 1.1754e-04, 1.5247e-04, 1.4283e-04, 1.3702e-04,
        4.8524e-05, 8.1621e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,298][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:54,302][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3342],
        [ 133],
        [1255],
        [ 442],
        [  88],
        [ 418],
        [ 101],
        [ 341],
        [ 869],
        [ 330],
        [ 151],
        [  89],
        [  97],
        [ 115],
        [ 760],
        [  54],
        [ 281],
        [ 245],
        [ 112],
        [  70]], device='cuda:0')
[2024-07-24 10:16:54,304][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 3584],
        [  431],
        [11641],
        [  378],
        [  885],
        [  980],
        [  108],
        [  927],
        [ 1829],
        [ 1234],
        [  223],
        [  510],
        [  533],
        [  802],
        [ 1814],
        [  499],
        [ 1304],
        [ 1413],
        [ 1241],
        [  840]], device='cuda:0')
[2024-07-24 10:16:54,305][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21068],
        [14033],
        [10630],
        [10154],
        [ 8603],
        [ 8341],
        [ 8005],
        [ 7904],
        [ 7811],
        [ 8211],
        [ 8615],
        [ 7901],
        [ 8159],
        [ 7890],
        [ 7956],
        [ 8237],
        [ 8159],
        [ 8445],
        [ 8291],
        [ 8518]], device='cuda:0')
[2024-07-24 10:16:54,308][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[29125],
        [19440],
        [28705],
        [28314],
        [28391],
        [25440],
        [27260],
        [25478],
        [25059],
        [24819],
        [23952],
        [22267],
        [21507],
        [22066],
        [22635],
        [22655],
        [22651],
        [22116],
        [21867],
        [21064]], device='cuda:0')
[2024-07-24 10:16:54,311][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14036],
        [17565],
        [18894],
        [20946],
        [21142],
        [21765],
        [22743],
        [23117],
        [23269],
        [23648],
        [23595],
        [23587],
        [23703],
        [23647],
        [23898],
        [24024],
        [24103],
        [24008],
        [24014],
        [24034]], device='cuda:0')
[2024-07-24 10:16:54,314][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14783],
        [ 9060],
        [ 7730],
        [ 7387],
        [ 7176],
        [ 7861],
        [ 8055],
        [ 8270],
        [ 8147],
        [ 7531],
        [ 7299],
        [ 7732],
        [ 7925],
        [ 7871],
        [ 8047],
        [ 7999],
        [ 7923],
        [ 7782],
        [ 7683],
        [ 7546]], device='cuda:0')
[2024-07-24 10:16:54,318][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13124],
        [20675],
        [ 2919],
        [ 5844],
        [ 5108],
        [ 4777],
        [ 5415],
        [ 7507],
        [ 6132],
        [ 6733],
        [ 7576],
        [ 9074],
        [ 9697],
        [ 8850],
        [11024],
        [10992],
        [10613],
        [11444],
        [10550],
        [11338]], device='cuda:0')
[2024-07-24 10:16:54,319][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 2808],
        [20663],
        [22409],
        [23265],
        [22809],
        [24054],
        [25264],
        [25034],
        [25081],
        [25233],
        [25470],
        [25503],
        [25229],
        [24601],
        [24492],
        [24473],
        [24595],
        [24472],
        [24324],
        [24111]], device='cuda:0')
[2024-07-24 10:16:54,321][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 59],
        [381],
        [343],
        [295],
        [339],
        [274],
        [320],
        [262],
        [275],
        [254],
        [281],
        [286],
        [284],
        [279],
        [284],
        [263],
        [290],
        [279],
        [280],
        [282]], device='cuda:0')
[2024-07-24 10:16:54,323][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[3553],
        [6063],
        [3828],
        [4306],
        [4579],
        [4312],
        [4734],
        [5263],
        [5504],
        [5690],
        [5852],
        [5893],
        [6096],
        [6193],
        [6369],
        [6452],
        [6421],
        [6613],
        [6777],
        [6892]], device='cuda:0')
[2024-07-24 10:16:54,326][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[3985],
        [5835],
        [7184],
        [7853],
        [8133],
        [8427],
        [8529],
        [8534],
        [8480],
        [8396],
        [8598],
        [8525],
        [8422],
        [8439],
        [8453],
        [8404],
        [8267],
        [8353],
        [8336],
        [8362]], device='cuda:0')
[2024-07-24 10:16:54,330][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41678],
        [35193],
        [46244],
        [45631],
        [45867],
        [44941],
        [44161],
        [43397],
        [42736],
        [42194],
        [41638],
        [41326],
        [40830],
        [41233],
        [41028],
        [40893],
        [40720],
        [40493],
        [40322],
        [40124]], device='cuda:0')
[2024-07-24 10:16:54,333][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[2556],
        [2265],
        [1878],
        [2133],
        [1885],
        [2226],
        [1495],
        [1763],
        [1661],
        [2020],
        [1935],
        [1232],
        [1968],
        [1706],
        [1636],
        [1809],
        [1375],
        [1580],
        [1397],
        [1864]], device='cuda:0')
[2024-07-24 10:16:54,334][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[26799],
        [16317],
        [15944],
        [17015],
        [17307],
        [18322],
        [17593],
        [17944],
        [17837],
        [17848],
        [18268],
        [17921],
        [18496],
        [18586],
        [18452],
        [18639],
        [18552],
        [19001],
        [18914],
        [19044]], device='cuda:0')
[2024-07-24 10:16:54,336][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[15257],
        [16325],
        [ 5813],
        [14933],
        [ 4855],
        [11142],
        [14371],
        [18600],
        [18065],
        [10466],
        [15707],
        [11712],
        [11793],
        [ 6406],
        [25197],
        [ 7035],
        [14753],
        [ 9915],
        [ 7969],
        [ 5920]], device='cuda:0')
[2024-07-24 10:16:54,338][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9289],
        [11548],
        [23158],
        [18608],
        [22108],
        [15915],
        [15619],
        [15998],
        [17462],
        [13384],
        [14508],
        [17659],
        [17685],
        [15894],
        [15636],
        [12728],
        [14834],
        [12687],
        [15220],
        [13669]], device='cuda:0')
[2024-07-24 10:16:54,342][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21680],
        [27895],
        [27220],
        [25910],
        [26272],
        [27187],
        [25718],
        [25154],
        [26398],
        [26720],
        [26494],
        [25626],
        [26963],
        [25663],
        [26412],
        [26204],
        [24849],
        [24319],
        [22711],
        [25061]], device='cuda:0')
[2024-07-24 10:16:54,345][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[5150],
        [4113],
        [4301],
        [4903],
        [4113],
        [3730],
        [3934],
        [5176],
        [4693],
        [5744],
        [4729],
        [5086],
        [6014],
        [6717],
        [6514],
        [7068],
        [5145],
        [3805],
        [5591],
        [6787]], device='cuda:0')
[2024-07-24 10:16:54,348][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2428],
        [ 6883],
        [11219],
        [11796],
        [12037],
        [11196],
        [11298],
        [10456],
        [10794],
        [10346],
        [10639],
        [11326],
        [11278],
        [10966],
        [11286],
        [11091],
        [11444],
        [11307],
        [11439],
        [11363]], device='cuda:0')
[2024-07-24 10:16:54,350][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[2470],
        [2465],
        [2362],
        [2428],
        [2377],
        [2180],
        [2171],
        [1774],
        [1401],
        [2046],
        [1574],
        [1186],
        [ 326],
        [ 335],
        [  17],
        [ 548],
        [ 109],
        [ 742],
        [ 689],
        [ 280]], device='cuda:0')
[2024-07-24 10:16:54,351][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[16161],
        [20780],
        [21682],
        [22934],
        [22617],
        [24685],
        [24007],
        [24847],
        [24537],
        [24642],
        [24281],
        [24141],
        [24595],
        [26830],
        [26046],
        [26204],
        [25324],
        [26680],
        [26932],
        [27042]], device='cuda:0')
[2024-07-24 10:16:54,353][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25625],
        [25623],
        [25670],
        [25860],
        [25781],
        [25945],
        [25886],
        [26217],
        [26084],
        [26031],
        [26627],
        [26646],
        [27442],
        [26521],
        [27451],
        [26822],
        [27781],
        [27939],
        [27291],
        [27667]], device='cuda:0')
[2024-07-24 10:16:54,357][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[31363],
        [ 6628],
        [ 5536],
        [ 6610],
        [ 5945],
        [ 6947],
        [ 6667],
        [ 8011],
        [ 6552],
        [ 7952],
        [ 7810],
        [ 6850],
        [ 7298],
        [ 7199],
        [ 7430],
        [ 7758],
        [ 8290],
        [ 8234],
        [ 7729],
        [ 8075]], device='cuda:0')
[2024-07-24 10:16:54,360][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4491],
        [ 5247],
        [24125],
        [22903],
        [24029],
        [23249],
        [22652],
        [22771],
        [23323],
        [21229],
        [22847],
        [23252],
        [22137],
        [22730],
        [22617],
        [20984],
        [22071],
        [21812],
        [21697],
        [21241]], device='cuda:0')
[2024-07-24 10:16:54,363][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 8858],
        [ 7174],
        [11224],
        [ 3798],
        [ 3908],
        [ 5966],
        [ 6327],
        [ 4623],
        [ 5558],
        [ 5572],
        [ 6485],
        [ 5158],
        [ 6143],
        [ 4598],
        [ 7644],
        [ 6033],
        [ 7256],
        [ 5888],
        [ 9961],
        [ 6909]], device='cuda:0')
[2024-07-24 10:16:54,365][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 5185],
        [ 5324],
        [ 5323],
        [ 5451],
        [ 5527],
        [ 6301],
        [ 5757],
        [ 5941],
        [ 8084],
        [ 6713],
        [ 7443],
        [ 9840],
        [12931],
        [ 6281],
        [ 8288],
        [ 6522],
        [ 7847],
        [ 7432],
        [18982],
        [ 8168]], device='cuda:0')
[2024-07-24 10:16:54,366][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7749],
        [13601],
        [14603],
        [16188],
        [14821],
        [17183],
        [16303],
        [18441],
        [18190],
        [17098],
        [18275],
        [17138],
        [17247],
        [16554],
        [18368],
        [17114],
        [18737],
        [17778],
        [17997],
        [17798]], device='cuda:0')
[2024-07-24 10:16:54,369][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[33987],
        [40750],
        [25412],
        [28199],
        [28503],
        [27872],
        [29195],
        [29187],
        [28595],
        [28919],
        [28261],
        [28262],
        [27332],
        [31018],
        [30226],
        [29837],
        [29675],
        [30518],
        [23485],
        [29028]], device='cuda:0')
[2024-07-24 10:16:54,372][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32855],
        [33378],
        [39306],
        [44442],
        [38986],
        [43110],
        [40406],
        [37187],
        [38294],
        [43368],
        [40581],
        [38409],
        [35019],
        [38028],
        [33823],
        [42762],
        [40154],
        [43267],
        [40165],
        [42531]], device='cuda:0')
[2024-07-24 10:16:54,375][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071],
        [8071]], device='cuda:0')
[2024-07-24 10:16:54,452][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:54,453][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,454][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,454][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,455][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,456][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,456][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,457][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,458][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,458][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,459][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,460][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,460][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,461][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0269, 0.9731], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,462][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2291, 0.7709], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,462][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0108, 0.9892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,467][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0501, 0.9499], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,468][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0120, 0.9880], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,469][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,470][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5315, 0.4685], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,470][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3305, 0.6695], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,471][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0307, 0.9693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,474][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,478][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,481][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9428, 0.0572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,482][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([5.8904e-08, 9.9983e-01, 1.7115e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,482][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.3542, 0.3131, 0.3327], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,483][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0281, 0.6601, 0.3118], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,484][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0284, 0.5377, 0.4339], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,485][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([1.4150e-04, 9.8479e-01, 1.5067e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,488][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.9563, 0.0291, 0.0146], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,493][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.2668, 0.4025, 0.3307], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,495][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.7289, 0.1444, 0.1267], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,495][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([2.3626e-04, 9.7390e-01, 2.5866e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,496][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([4.2661e-05, 9.8984e-01, 1.0120e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,497][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0226, 0.7160, 0.2614], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,497][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.9291, 0.0464, 0.0245], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,498][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([4.4739e-07, 9.9537e-01, 4.5575e-03, 7.0559e-05], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,502][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0316, 0.5358, 0.2097, 0.2229], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,505][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.8295e-04, 5.1404e-01, 1.7632e-01, 3.0925e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,508][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0092, 0.5366, 0.3431, 0.1111], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,509][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.3917e-04, 9.6416e-01, 3.2396e-02, 3.0082e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,509][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9791, 0.0070, 0.0103, 0.0037], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,510][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1237, 0.2928, 0.2513, 0.3323], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,511][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0418, 0.1483, 0.2099, 0.6000], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,512][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.9483e-04, 9.2624e-01, 6.9964e-02, 3.5990e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,514][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.2401e-04, 8.8473e-01, 1.1321e-01, 1.9348e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,516][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.3905e-05, 7.4057e-01, 1.9015e-01, 6.9246e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,521][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4680, 0.1741, 0.2094, 0.1485], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:54,522][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ James] are: tensor([3.0136e-10, 9.9904e-01, 9.2982e-04, 3.4052e-05, 6.9374e-07],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,523][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0721, 0.2542, 0.1574, 0.3169, 0.1993], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,524][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0010, 0.3109, 0.1522, 0.2328, 0.3031], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,524][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0067, 0.3141, 0.3449, 0.2341, 0.1003], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,525][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ James] are: tensor([1.1966e-05, 9.7930e-01, 1.9212e-02, 1.4075e-03, 6.5143e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,529][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.9015, 0.0468, 0.0337, 0.0151, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,533][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.1002, 0.2344, 0.2169, 0.2393, 0.2091], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,535][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1814, 0.0657, 0.0646, 0.5787, 0.1096], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,536][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ James] are: tensor([5.6789e-06, 9.5968e-01, 3.7508e-02, 2.4496e-03, 3.5785e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,537][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ James] are: tensor([2.6056e-06, 9.8649e-01, 1.2611e-02, 8.3431e-04, 6.5346e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,537][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0004, 0.3748, 0.3369, 0.1080, 0.1799], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,538][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.3581, 0.1760, 0.1033, 0.1743, 0.1883], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:54,540][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ were] are: tensor([2.7478e-07, 9.9444e-01, 5.3324e-03, 1.9404e-04, 1.7499e-05, 1.3548e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,544][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0084, 0.4279, 0.1372, 0.1482, 0.1208, 0.1574], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,548][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0004, 0.2832, 0.1444, 0.2632, 0.2411, 0.0677], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,549][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0054, 0.2204, 0.4919, 0.1098, 0.1262, 0.0464], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,550][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ were] are: tensor([2.4784e-04, 9.5377e-01, 3.8072e-02, 6.7352e-03, 2.9468e-04, 8.7813e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,551][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.9685, 0.0082, 0.0147, 0.0060, 0.0014, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,551][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.0830, 0.1988, 0.1781, 0.2160, 0.1842, 0.1400], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,554][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0232, 0.1312, 0.1011, 0.5107, 0.1356, 0.0983], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,556][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ were] are: tensor([4.6530e-05, 8.3986e-01, 1.5064e-01, 5.6776e-03, 3.4451e-03, 3.3164e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,559][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ were] are: tensor([2.7832e-05, 9.2239e-01, 7.3691e-02, 2.5625e-03, 7.1816e-04, 6.1063e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,562][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ were] are: tensor([6.5767e-05, 7.3551e-01, 1.3790e-01, 3.7466e-02, 6.9628e-02, 1.9430e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,563][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0219, 0.1139, 0.2908, 0.1931, 0.1565, 0.2239], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:54,563][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([3.3430e-09, 9.9628e-01, 3.6318e-03, 7.3360e-05, 7.3146e-06, 6.1443e-06,
        1.5067e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,564][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0464, 0.1752, 0.1372, 0.1913, 0.1271, 0.1881, 0.1346],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,565][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0011, 0.1651, 0.1252, 0.1817, 0.2721, 0.1324, 0.1224],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,568][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0078, 0.3724, 0.1138, 0.2430, 0.0663, 0.1344, 0.0624],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,570][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([5.5842e-05, 9.3674e-01, 5.7645e-02, 4.1919e-03, 4.9082e-04, 7.2637e-04,
        1.4696e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,576][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.8837, 0.0416, 0.0350, 0.0188, 0.0033, 0.0063, 0.0112],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,579][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.0813, 0.1842, 0.1643, 0.1792, 0.1668, 0.1228, 0.1014],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,579][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.1350, 0.0643, 0.0564, 0.2861, 0.0800, 0.0884, 0.2899],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,580][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([1.2356e-05, 8.4670e-01, 1.4645e-01, 3.3045e-03, 3.1635e-03, 2.2936e-04,
        1.3641e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,581][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([8.3581e-06, 8.8086e-01, 1.1547e-01, 1.9557e-03, 8.3166e-04, 6.9704e-04,
        1.7241e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,582][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([3.9613e-04, 4.1508e-01, 1.8504e-01, 2.8587e-02, 2.3648e-01, 5.4318e-02,
        8.0099e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,584][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0461, 0.1603, 0.0951, 0.1275, 0.0975, 0.1559, 0.3176],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:54,586][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ about] are: tensor([2.6719e-08, 9.9438e-01, 5.3234e-03, 2.3202e-04, 4.4178e-05, 2.0205e-05,
        2.5633e-06, 2.6176e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,591][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0093, 0.2150, 0.1344, 0.1292, 0.1115, 0.1468, 0.1498, 0.1039],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,593][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ about] are: tensor([2.5778e-04, 2.6394e-01, 1.7821e-01, 1.7063e-01, 1.7067e-01, 8.5275e-02,
        6.8721e-02, 6.2285e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,593][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0047, 0.3113, 0.3442, 0.1623, 0.0385, 0.0766, 0.0441, 0.0183],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,594][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ about] are: tensor([2.0456e-03, 8.6438e-01, 1.0830e-01, 1.4487e-02, 2.1229e-03, 6.0825e-03,
        1.9487e-03, 6.2470e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,595][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.9048, 0.0195, 0.0460, 0.0091, 0.0032, 0.0043, 0.0111, 0.0019],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,596][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.0613, 0.1512, 0.1398, 0.1499, 0.1501, 0.1086, 0.0913, 0.1478],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,598][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0301, 0.0702, 0.0601, 0.3790, 0.0486, 0.0533, 0.2707, 0.0880],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,601][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ about] are: tensor([9.8297e-05, 8.3777e-01, 1.4842e-01, 5.9766e-03, 6.0444e-03, 7.7950e-04,
        8.3133e-04, 7.7245e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,604][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ about] are: tensor([9.1000e-05, 9.1124e-01, 7.9400e-02, 4.8147e-03, 1.5313e-03, 1.8990e-03,
        9.0890e-04, 1.1478e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,606][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ about] are: tensor([6.5198e-05, 5.0830e-01, 2.7848e-01, 3.3288e-02, 7.3700e-02, 3.2673e-02,
        5.7425e-02, 1.6065e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,607][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0388, 0.0994, 0.1035, 0.1523, 0.0945, 0.0636, 0.3691, 0.0787],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:54,608][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ going] are: tensor([4.2958e-08, 9.9003e-01, 9.6332e-03, 2.7928e-04, 3.2917e-05, 1.8193e-05,
        1.8221e-06, 2.8682e-07, 2.4348e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,609][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0097, 0.2237, 0.1201, 0.1365, 0.1006, 0.1278, 0.1157, 0.1049, 0.0609],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,609][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0008, 0.2494, 0.0971, 0.1197, 0.1652, 0.1264, 0.1063, 0.0773, 0.0578],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,612][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0013, 0.4908, 0.2757, 0.0867, 0.0298, 0.0632, 0.0236, 0.0114, 0.0175],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,615][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ going] are: tensor([7.4141e-04, 9.4189e-01, 4.3528e-02, 9.1282e-03, 7.2481e-04, 2.8754e-03,
        7.3732e-04, 1.7523e-04, 2.0349e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,620][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.9470, 0.0166, 0.0142, 0.0079, 0.0012, 0.0029, 0.0062, 0.0018, 0.0021],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,621][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0496, 0.1380, 0.1220, 0.1388, 0.1296, 0.1014, 0.0848, 0.1491, 0.0866],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,622][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0528, 0.0676, 0.0355, 0.2009, 0.0689, 0.0508, 0.1949, 0.0765, 0.2522],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,622][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ going] are: tensor([7.4474e-05, 8.5666e-01, 1.2768e-01, 8.5178e-03, 5.7795e-03, 6.4292e-04,
        5.5498e-04, 3.8523e-05, 5.8031e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,623][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ going] are: tensor([1.7210e-05, 9.1604e-01, 8.0217e-02, 1.6338e-03, 7.2568e-04, 8.5227e-04,
        3.6155e-04, 5.9249e-05, 9.7980e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,625][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ going] are: tensor([3.6460e-04, 5.5488e-01, 1.3510e-01, 2.1905e-02, 6.8582e-02, 3.8199e-02,
        7.0788e-02, 4.9154e-02, 6.1023e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,629][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0241, 0.2191, 0.1047, 0.1532, 0.0713, 0.0776, 0.1688, 0.0857, 0.0957],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:54,632][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.5053e-05, 9.8442e-01, 1.3898e-02, 1.1201e-03, 1.7039e-04, 1.7103e-04,
        5.1634e-05, 1.0520e-05, 1.5091e-05, 8.3780e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,634][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0060, 0.2301, 0.0976, 0.1107, 0.0897, 0.1240, 0.1131, 0.0885, 0.0613,
        0.0790], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,635][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.2742e-04, 2.0647e-01, 6.4091e-02, 1.0320e-01, 7.4507e-02, 8.1503e-02,
        5.5984e-02, 9.7545e-02, 3.8412e-02, 2.7806e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,636][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0049, 0.2552, 0.4139, 0.0633, 0.0623, 0.0791, 0.0548, 0.0119, 0.0381,
        0.0165], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,637][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0327, 0.8503, 0.0601, 0.0248, 0.0022, 0.0179, 0.0048, 0.0022, 0.0018,
        0.0032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,637][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.7983e-01, 3.6912e-03, 5.7349e-03, 2.1308e-03, 4.9222e-04, 1.2229e-03,
        3.5534e-03, 8.5404e-04, 1.4429e-03, 1.0494e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,641][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0427, 0.1243, 0.1135, 0.1311, 0.1205, 0.0911, 0.0748, 0.1295, 0.0776,
        0.0949], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,645][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0244, 0.0697, 0.0373, 0.1420, 0.0547, 0.0360, 0.1989, 0.0760, 0.2414,
        0.1195], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,648][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.6283e-03, 7.9485e-01, 1.7048e-01, 1.5676e-02, 1.0608e-02, 2.1120e-03,
        2.9726e-03, 4.7276e-04, 6.7740e-04, 5.2569e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,649][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.3334e-03, 8.7733e-01, 9.9889e-02, 7.5234e-03, 2.4053e-03, 4.8697e-03,
        2.8306e-03, 7.5866e-04, 7.3124e-04, 2.3268e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,649][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.1672e-05, 6.2967e-01, 1.6530e-01, 1.9927e-02, 3.7434e-02, 3.1779e-02,
        3.8211e-02, 1.6476e-02, 3.8302e-02, 2.2887e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,650][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0176, 0.1060, 0.1095, 0.0993, 0.0719, 0.0487, 0.2451, 0.0836, 0.1080,
        0.1103], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:54,651][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.1293e-08, 9.9495e-01, 4.8144e-03, 1.8318e-04, 2.8095e-05, 1.2376e-05,
        2.8753e-06, 3.2007e-07, 7.1609e-07, 6.8978e-06, 7.3682e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,654][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0046, 0.2723, 0.0990, 0.1008, 0.0758, 0.1137, 0.0921, 0.0767, 0.0514,
        0.0765, 0.0372], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,656][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.9364e-04, 2.3007e-01, 6.3043e-02, 1.5913e-01, 7.7803e-02, 3.9222e-02,
        3.5764e-02, 6.4379e-02, 3.5866e-02, 2.1429e-01, 8.0246e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,662][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0023, 0.4416, 0.2546, 0.0908, 0.0223, 0.0792, 0.0278, 0.0103, 0.0346,
        0.0317, 0.0048], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,662][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([3.1275e-04, 9.2140e-01, 6.5509e-02, 7.8546e-03, 9.6165e-04, 2.3363e-03,
        7.6001e-04, 1.8815e-04, 2.5582e-04, 3.9678e-04, 2.5269e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,663][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.0238e-01, 2.7097e-02, 3.4635e-02, 1.1950e-02, 2.0599e-03, 4.5251e-03,
        9.0710e-03, 1.6150e-03, 3.4529e-03, 2.6205e-03, 5.8873e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,664][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0383, 0.1185, 0.1040, 0.1200, 0.1079, 0.0813, 0.0677, 0.1139, 0.0673,
        0.0844, 0.0966], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,665][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0142, 0.0457, 0.0380, 0.2399, 0.0484, 0.0387, 0.1820, 0.0473, 0.2215,
        0.0857, 0.0385], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,667][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.9420e-05, 8.7193e-01, 1.2045e-01, 3.7406e-03, 3.0184e-03, 3.6455e-04,
        3.3828e-04, 3.2244e-05, 5.1541e-05, 5.0943e-05, 5.1209e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,669][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([5.4848e-06, 9.3467e-01, 6.2943e-02, 1.0469e-03, 4.3857e-04, 4.7168e-04,
        1.9323e-04, 3.3863e-05, 4.6896e-05, 1.3993e-04, 1.0607e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,672][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.5928e-05, 6.6785e-01, 1.1633e-01, 2.4323e-02, 3.3199e-02, 1.7745e-02,
        3.8857e-02, 1.6910e-02, 3.8310e-02, 2.8594e-02, 1.7862e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,676][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0052, 0.1947, 0.0682, 0.2309, 0.0363, 0.0526, 0.1224, 0.0606, 0.0750,
        0.0917, 0.0624], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:54,676][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ store] are: tensor([2.5089e-10, 9.9590e-01, 3.9377e-03, 1.3448e-04, 2.2563e-05, 2.3440e-06,
        3.2970e-07, 3.1281e-08, 9.9594e-08, 1.3641e-06, 2.2635e-08, 2.8216e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,677][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0295, 0.1020, 0.0795, 0.1452, 0.0815, 0.1437, 0.0859, 0.0770, 0.0478,
        0.0762, 0.0424, 0.0892], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,678][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0010, 0.2587, 0.0689, 0.1342, 0.0856, 0.0831, 0.0262, 0.0394, 0.0224,
        0.1277, 0.0731, 0.0797], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,679][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0010, 0.3545, 0.2128, 0.1299, 0.0706, 0.1129, 0.0165, 0.0083, 0.0281,
        0.0497, 0.0121, 0.0037], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,681][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ store] are: tensor([5.3099e-06, 9.6232e-01, 3.4814e-02, 2.1075e-03, 2.1986e-04, 3.1180e-04,
        7.7499e-05, 2.2656e-05, 3.2757e-05, 8.0959e-05, 6.6642e-06, 1.8192e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,685][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.5741, 0.1171, 0.1633, 0.0344, 0.0082, 0.0160, 0.0317, 0.0067, 0.0138,
        0.0125, 0.0030, 0.0192], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,689][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0273, 0.1139, 0.0991, 0.1058, 0.0989, 0.0739, 0.0641, 0.1075, 0.0657,
        0.0813, 0.0898, 0.0726], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,690][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0038, 0.0312, 0.0272, 0.1309, 0.0362, 0.0194, 0.0935, 0.0259, 0.0792,
        0.0472, 0.0152, 0.4904], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,691][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ store] are: tensor([1.6838e-06, 8.7920e-01, 1.1746e-01, 1.4796e-03, 1.6981e-03, 9.5478e-05,
        3.8295e-05, 4.9185e-06, 6.6470e-06, 1.3529e-05, 1.3046e-06, 9.3378e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,692][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ store] are: tensor([1.2012e-06, 9.1559e-01, 8.1869e-02, 1.1775e-03, 5.3789e-04, 5.0479e-04,
        1.6965e-04, 1.8578e-05, 3.2754e-05, 8.5470e-05, 6.7872e-06, 2.6516e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,693][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0006, 0.4186, 0.1022, 0.0247, 0.0188, 0.0383, 0.1124, 0.0517, 0.1185,
        0.0322, 0.0295, 0.0523], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,695][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0014, 0.1331, 0.1023, 0.1553, 0.0412, 0.0489, 0.1655, 0.0518, 0.0667,
        0.0762, 0.0735, 0.0843], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:54,698][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([7.1163e-09, 9.9220e-01, 7.6352e-03, 1.1362e-04, 2.9414e-05, 8.9861e-06,
        2.3145e-06, 2.7510e-07, 4.6334e-07, 4.9617e-06, 1.0965e-07, 2.6623e-08,
        2.9255e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,703][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0044, 0.2555, 0.0678, 0.0850, 0.0594, 0.1088, 0.0786, 0.0580, 0.0496,
        0.0675, 0.0365, 0.0826, 0.0463], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,704][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0002, 0.1404, 0.0557, 0.1260, 0.0681, 0.0547, 0.0396, 0.0786, 0.0362,
        0.1589, 0.1061, 0.0636, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,705][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0029, 0.1643, 0.4840, 0.0294, 0.0855, 0.0922, 0.0395, 0.0112, 0.0520,
        0.0224, 0.0088, 0.0049, 0.0029], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,706][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([8.1416e-05, 9.4044e-01, 5.4939e-02, 2.5178e-03, 4.9300e-04, 9.8824e-04,
        2.3875e-04, 6.6154e-05, 6.2187e-05, 1.3960e-04, 1.1434e-05, 7.0421e-06,
        1.2438e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,707][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.6523, 0.0939, 0.1200, 0.0329, 0.0092, 0.0177, 0.0274, 0.0066, 0.0123,
        0.0095, 0.0031, 0.0121, 0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,710][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0304, 0.1064, 0.0945, 0.1007, 0.0950, 0.0691, 0.0574, 0.0964, 0.0596,
        0.0736, 0.0837, 0.0686, 0.0646], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,715][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0119, 0.0380, 0.0247, 0.1004, 0.0353, 0.0252, 0.1108, 0.0318, 0.1037,
        0.0335, 0.0242, 0.4229, 0.0375], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,717][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([6.5310e-06, 8.5225e-01, 1.4341e-01, 1.8653e-03, 1.8891e-03, 2.6892e-04,
        2.3670e-04, 1.9243e-05, 2.0880e-05, 2.7438e-05, 3.2016e-06, 2.1176e-06,
        1.3252e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,718][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([1.1187e-05, 8.9735e-01, 1.0024e-01, 7.9522e-04, 4.9654e-04, 6.4942e-04,
        2.3316e-04, 2.9689e-05, 5.8023e-05, 1.0131e-04, 9.2917e-06, 9.5214e-06,
        1.3083e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,719][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.6926e-05, 5.9705e-01, 1.5353e-01, 1.8413e-02, 3.8921e-02, 2.0832e-02,
        2.9368e-02, 1.2692e-02, 2.6648e-02, 2.3338e-02, 1.7761e-02, 4.1422e-02,
        2.0009e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,720][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0385, 0.1410, 0.0921, 0.1355, 0.0611, 0.0518, 0.1271, 0.0460, 0.0567,
        0.0449, 0.0720, 0.0535, 0.0798], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:54,721][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ James] are: tensor([9.6576e-09, 9.7562e-01, 2.4101e-02, 1.8007e-04, 7.5711e-05, 1.1398e-05,
        3.7148e-06, 2.8514e-07, 8.1860e-07, 4.1818e-06, 1.2602e-07, 6.1742e-08,
        2.2907e-08, 2.5650e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,724][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0153, 0.1258, 0.0646, 0.1188, 0.0743, 0.1465, 0.0790, 0.0648, 0.0420,
        0.0654, 0.0350, 0.0797, 0.0477, 0.0410], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,729][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0005, 0.1443, 0.0356, 0.0846, 0.0573, 0.0679, 0.0775, 0.0902, 0.0770,
        0.1325, 0.0730, 0.0641, 0.0641, 0.0315], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,731][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0053, 0.2040, 0.2567, 0.1512, 0.0678, 0.1517, 0.0136, 0.0123, 0.0305,
        0.0335, 0.0194, 0.0083, 0.0129, 0.0329], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,732][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ James] are: tensor([1.2695e-04, 8.7345e-01, 1.1971e-01, 3.6058e-03, 1.2429e-03, 1.1299e-03,
        3.3362e-04, 1.0463e-04, 1.1444e-04, 1.3353e-04, 1.8568e-05, 1.0696e-05,
        1.2471e-05, 5.8428e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,733][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.7519, 0.0647, 0.0938, 0.0215, 0.0087, 0.0106, 0.0208, 0.0055, 0.0066,
        0.0034, 0.0020, 0.0054, 0.0022, 0.0027], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,734][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0294, 0.1004, 0.0871, 0.0948, 0.0837, 0.0688, 0.0539, 0.0932, 0.0540,
        0.0692, 0.0747, 0.0637, 0.0598, 0.0674], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,735][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0397, 0.0301, 0.0219, 0.1602, 0.0190, 0.0233, 0.1336, 0.0350, 0.1117,
        0.0392, 0.0202, 0.3049, 0.0419, 0.0194], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,736][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ James] are: tensor([3.1799e-05, 8.5446e-01, 1.3773e-01, 4.8918e-03, 2.2533e-03, 3.4225e-04,
        1.9138e-04, 2.7086e-05, 2.6691e-05, 3.5755e-05, 6.4892e-06, 2.2025e-06,
        3.1098e-06, 3.7433e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,739][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ James] are: tensor([2.9567e-05, 9.3878e-01, 5.8108e-02, 1.4376e-03, 4.2410e-04, 7.4875e-04,
        2.6159e-04, 3.9247e-05, 6.0481e-05, 7.4591e-05, 7.9988e-06, 1.4948e-05,
        1.3980e-05, 3.4764e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,742][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ James] are: tensor([1.3767e-04, 3.7146e-01, 1.2852e-01, 2.8046e-02, 3.3543e-02, 8.6205e-02,
        3.5825e-02, 3.7873e-02, 2.2667e-02, 3.4452e-02, 3.2588e-02, 1.1588e-01,
        5.7150e-02, 1.5653e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,745][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.2554, 0.0925, 0.0578, 0.0795, 0.0481, 0.0701, 0.1235, 0.0503, 0.0301,
        0.0308, 0.0489, 0.0537, 0.0398, 0.0193], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:54,746][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([1.1731e-07, 9.7492e-01, 2.4360e-02, 4.5805e-04, 1.7962e-04, 4.9091e-05,
        1.2524e-05, 1.0444e-06, 2.2890e-06, 1.6600e-05, 6.2612e-07, 1.9223e-07,
        1.1937e-07, 1.2211e-06, 2.5440e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,747][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0137, 0.1458, 0.0631, 0.1016, 0.0675, 0.1065, 0.0741, 0.0633, 0.0474,
        0.0711, 0.0429, 0.0702, 0.0547, 0.0372, 0.0409], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,748][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0003, 0.1305, 0.0399, 0.0813, 0.0634, 0.0374, 0.0605, 0.0600, 0.0534,
        0.1497, 0.1082, 0.0452, 0.0667, 0.0648, 0.0388], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,749][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0017, 0.4095, 0.2248, 0.0841, 0.0531, 0.0487, 0.0286, 0.0198, 0.0216,
        0.0465, 0.0207, 0.0037, 0.0083, 0.0174, 0.0117], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,750][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([6.2462e-04, 8.9282e-01, 9.4720e-02, 6.7240e-03, 1.3606e-03, 2.5307e-03,
        4.8599e-04, 1.6050e-04, 1.8181e-04, 2.6048e-04, 3.5462e-05, 3.0195e-05,
        3.6189e-05, 9.6560e-06, 1.7481e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,754][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.7300, 0.0789, 0.0921, 0.0276, 0.0079, 0.0061, 0.0226, 0.0040, 0.0048,
        0.0060, 0.0039, 0.0089, 0.0027, 0.0022, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,759][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0286, 0.0898, 0.0794, 0.0880, 0.0796, 0.0599, 0.0497, 0.0823, 0.0510,
        0.0641, 0.0734, 0.0616, 0.0582, 0.0727, 0.0615], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,760][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0142, 0.0327, 0.0155, 0.1193, 0.0235, 0.0196, 0.1394, 0.0299, 0.1367,
        0.0419, 0.0169, 0.3397, 0.0249, 0.0235, 0.0224], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,761][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([2.6098e-05, 8.3057e-01, 1.5995e-01, 5.2022e-03, 3.0314e-03, 5.1005e-04,
        4.6358e-04, 5.1688e-05, 5.6192e-05, 8.4405e-05, 1.0082e-05, 8.8166e-06,
        5.0700e-06, 1.5728e-05, 8.8438e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,762][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([1.3548e-05, 9.0504e-01, 9.0889e-02, 1.6391e-03, 9.0216e-04, 7.7622e-04,
        4.2380e-04, 2.8221e-05, 7.5494e-05, 1.3797e-04, 2.1376e-05, 1.3922e-05,
        2.4786e-05, 9.7877e-06, 8.6631e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,763][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([5.8794e-05, 5.9297e-01, 9.1332e-02, 1.7849e-02, 2.1096e-02, 2.2071e-02,
        3.5725e-02, 1.7365e-02, 3.8571e-02, 3.9126e-02, 3.5714e-02, 3.7000e-02,
        2.7577e-02, 1.3864e-02, 9.6838e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,766][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0330, 0.1110, 0.1075, 0.1179, 0.0556, 0.0432, 0.2031, 0.0292, 0.0578,
        0.0380, 0.0516, 0.0463, 0.0587, 0.0245, 0.0226], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:54,768][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.4554e-05, 9.8000e-01, 1.8421e-02, 9.0496e-04, 2.6463e-04, 1.8486e-04,
        6.9092e-05, 7.4494e-06, 2.0185e-05, 6.1425e-05, 2.7268e-06, 1.1503e-06,
        6.5620e-07, 9.4405e-06, 4.8452e-06, 2.7226e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,773][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0041, 0.1999, 0.0616, 0.0830, 0.0578, 0.0952, 0.0686, 0.0587, 0.0418,
        0.0587, 0.0280, 0.0743, 0.0385, 0.0276, 0.0370, 0.0654],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,774][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0002, 0.1285, 0.0399, 0.0788, 0.0590, 0.0514, 0.0319, 0.0634, 0.0219,
        0.1440, 0.0834, 0.0417, 0.0579, 0.0459, 0.0337, 0.1185],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,775][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0024, 0.2027, 0.4740, 0.0508, 0.0625, 0.0557, 0.0457, 0.0083, 0.0260,
        0.0108, 0.0108, 0.0036, 0.0046, 0.0251, 0.0111, 0.0059],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,776][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.0323e-02, 8.5649e-01, 1.0010e-01, 1.3599e-02, 2.7716e-03, 9.5702e-03,
        2.7129e-03, 1.0746e-03, 9.0012e-04, 1.3425e-03, 2.1011e-04, 1.4040e-04,
        1.3160e-04, 6.1348e-05, 1.5373e-04, 4.2419e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,777][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.1904e-01, 1.4236e-02, 3.1904e-02, 5.8448e-03, 2.8630e-03, 3.2063e-03,
        7.3473e-03, 1.4077e-03, 2.5280e-03, 1.6541e-03, 6.3198e-04, 3.6325e-03,
        6.6455e-04, 1.3023e-03, 2.3186e-03, 1.4153e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,780][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0233, 0.0839, 0.0789, 0.0846, 0.0802, 0.0570, 0.0469, 0.0778, 0.0485,
        0.0596, 0.0682, 0.0541, 0.0535, 0.0670, 0.0559, 0.0608],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,785][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0054, 0.0422, 0.0220, 0.0847, 0.0341, 0.0174, 0.0851, 0.0323, 0.0998,
        0.0454, 0.0209, 0.4123, 0.0283, 0.0308, 0.0188, 0.0206],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,787][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.1865e-04, 7.0333e-01, 2.7511e-01, 8.2781e-03, 7.8463e-03, 1.7435e-03,
        1.9121e-03, 2.0647e-04, 4.1270e-04, 2.4417e-04, 6.1819e-05, 3.2948e-05,
        2.7013e-05, 1.4160e-04, 8.5042e-05, 5.4605e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,788][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.0482e-04, 8.7422e-01, 1.1098e-01, 4.1240e-03, 2.2798e-03, 3.2479e-03,
        2.1114e-03, 3.5209e-04, 5.2444e-04, 9.1517e-04, 1.2505e-04, 1.1114e-04,
        1.2239e-04, 1.2388e-04, 8.9916e-05, 2.6433e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,788][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.4392e-06, 6.6801e-01, 1.3677e-01, 1.6945e-02, 3.1586e-02, 2.1662e-02,
        1.9121e-02, 7.9498e-03, 1.7377e-02, 9.8824e-03, 8.9923e-03, 2.4431e-02,
        1.1469e-02, 6.8806e-03, 8.2782e-03, 1.0637e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,789][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0232, 0.0881, 0.0919, 0.0895, 0.0723, 0.0428, 0.1236, 0.0437, 0.0651,
        0.0391, 0.0729, 0.0653, 0.0666, 0.0535, 0.0379, 0.0246],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:54,790][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ give] are: tensor([1.0914e-07, 9.8994e-01, 9.2588e-03, 5.8228e-04, 1.3621e-04, 4.5683e-05,
        8.4984e-06, 8.5743e-07, 1.7308e-06, 1.5102e-05, 3.1834e-07, 1.5434e-07,
        7.6484e-08, 8.4939e-07, 3.6836e-07, 5.3363e-06, 2.5593e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,794][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0054, 0.1672, 0.0647, 0.0870, 0.0771, 0.0950, 0.0588, 0.0562, 0.0330,
        0.0556, 0.0234, 0.0690, 0.0344, 0.0340, 0.0297, 0.0590, 0.0505],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,798][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0003, 0.1315, 0.0335, 0.0825, 0.0601, 0.0407, 0.0332, 0.0606, 0.0322,
        0.1446, 0.0807, 0.0263, 0.0502, 0.0449, 0.0265, 0.1224, 0.0297],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,800][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0036, 0.2049, 0.3163, 0.0969, 0.0770, 0.0825, 0.0140, 0.0168, 0.0163,
        0.0592, 0.0180, 0.0060, 0.0101, 0.0268, 0.0057, 0.0406, 0.0052],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,801][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ give] are: tensor([9.5138e-04, 8.8513e-01, 9.6454e-02, 9.3956e-03, 1.8454e-03, 3.9889e-03,
        9.6828e-04, 2.4588e-04, 2.7682e-04, 4.4842e-04, 4.6620e-05, 3.5309e-05,
        3.5129e-05, 9.1347e-06, 2.5547e-05, 8.9605e-05, 5.3057e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,802][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ give] are: tensor([7.7699e-01, 4.4964e-02, 1.3098e-01, 1.2114e-02, 9.7593e-03, 2.7976e-03,
        7.2895e-03, 1.1873e-03, 1.5352e-03, 1.5687e-03, 4.8792e-04, 3.8183e-03,
        6.5778e-04, 2.0306e-03, 1.1051e-03, 1.4300e-03, 1.2848e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,803][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0236, 0.0790, 0.0761, 0.0809, 0.0789, 0.0523, 0.0430, 0.0732, 0.0430,
        0.0540, 0.0646, 0.0506, 0.0509, 0.0655, 0.0510, 0.0557, 0.0575],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,806][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0130, 0.0141, 0.0074, 0.0932, 0.0148, 0.0107, 0.0688, 0.0223, 0.0743,
        0.0466, 0.0197, 0.4432, 0.0310, 0.0217, 0.0174, 0.0216, 0.0801],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,808][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ give] are: tensor([9.3495e-05, 7.2488e-01, 2.6189e-01, 5.3511e-03, 6.0970e-03, 7.7138e-04,
        6.5664e-04, 4.4074e-05, 6.5259e-05, 5.5538e-05, 8.1392e-06, 9.8541e-06,
        5.0098e-06, 3.2175e-05, 1.6728e-05, 1.1557e-05, 1.5191e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,811][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ give] are: tensor([3.1354e-05, 8.9859e-01, 9.5232e-02, 2.0712e-03, 1.6209e-03, 1.2099e-03,
        5.7541e-04, 5.9916e-05, 1.1264e-04, 2.8220e-04, 2.8173e-05, 1.8833e-05,
        3.9440e-05, 2.6147e-05, 1.5889e-05, 6.3774e-05, 2.4815e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,814][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ give] are: tensor([2.6583e-05, 6.5653e-01, 1.0381e-01, 2.0771e-02, 2.9372e-02, 3.5611e-02,
        1.8382e-02, 1.0378e-02, 2.4046e-02, 1.0701e-02, 1.3076e-02, 1.9664e-02,
        1.4351e-02, 1.7084e-02, 8.1866e-03, 1.0946e-02, 7.0607e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,815][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0098, 0.1601, 0.0460, 0.1338, 0.0519, 0.0372, 0.1245, 0.0243, 0.0529,
        0.0444, 0.0605, 0.0532, 0.0758, 0.0424, 0.0233, 0.0236, 0.0363],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:54,816][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.4540e-08, 9.9012e-01, 9.4603e-03, 3.0189e-04, 7.2757e-05, 2.7894e-05,
        6.4118e-06, 4.4299e-07, 1.5483e-06, 8.2286e-06, 1.8133e-07, 9.0988e-08,
        4.5492e-08, 6.0122e-07, 3.0905e-07, 2.5135e-06, 3.2214e-07, 2.1610e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,817][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0023, 0.2395, 0.0604, 0.0616, 0.0532, 0.0827, 0.0567, 0.0481, 0.0340,
        0.0483, 0.0198, 0.0637, 0.0296, 0.0252, 0.0327, 0.0562, 0.0493, 0.0370],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,818][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([5.8996e-05, 2.0527e-01, 3.0483e-02, 9.9242e-02, 3.8536e-02, 2.7371e-02,
        1.2542e-02, 3.6039e-02, 1.6317e-02, 1.2989e-01, 4.3217e-02, 2.3443e-02,
        5.1532e-02, 3.7317e-02, 3.7016e-02, 1.2427e-01, 4.0155e-02, 4.7302e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,821][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0015, 0.3164, 0.3140, 0.0791, 0.0376, 0.0701, 0.0275, 0.0093, 0.0335,
        0.0283, 0.0066, 0.0054, 0.0096, 0.0165, 0.0178, 0.0189, 0.0042, 0.0036],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,824][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.5965e-04, 8.9214e-01, 9.8954e-02, 4.9466e-03, 1.0597e-03, 1.6476e-03,
        5.0365e-04, 1.0792e-04, 1.1221e-04, 2.0304e-04, 1.7923e-05, 1.5659e-05,
        2.0093e-05, 4.6989e-06, 1.6910e-05, 4.9601e-05, 2.7127e-05, 9.6832e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,827][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([8.2705e-01, 5.1174e-02, 7.3665e-02, 1.1558e-02, 5.8217e-03, 5.8973e-03,
        7.2541e-03, 9.7739e-04, 2.7453e-03, 1.9577e-03, 5.6991e-04, 2.7523e-03,
        7.0852e-04, 1.3495e-03, 2.6723e-03, 1.5391e-03, 1.9337e-03, 3.6972e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,828][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0228, 0.0815, 0.0760, 0.0775, 0.0752, 0.0514, 0.0409, 0.0655, 0.0406,
        0.0516, 0.0586, 0.0458, 0.0472, 0.0576, 0.0469, 0.0531, 0.0541, 0.0538],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,829][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0058, 0.0572, 0.0271, 0.1044, 0.0221, 0.0155, 0.0699, 0.0278, 0.0745,
        0.0522, 0.0190, 0.3010, 0.0285, 0.0313, 0.0222, 0.0247, 0.1030, 0.0139],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,830][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.1379e-05, 7.7023e-01, 2.2448e-01, 1.9205e-03, 2.6672e-03, 3.3232e-04,
        2.4243e-04, 1.6800e-05, 3.3656e-05, 2.5834e-05, 3.8397e-06, 5.2825e-06,
        2.6096e-06, 1.0137e-05, 8.1597e-06, 4.8650e-06, 1.0368e-05, 8.5531e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,831][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.1673e-06, 9.0626e-01, 9.1447e-02, 7.9979e-04, 6.4517e-04, 4.6622e-04,
        1.8739e-04, 1.6359e-05, 3.3568e-05, 7.0658e-05, 6.8998e-06, 7.3283e-06,
        1.1355e-05, 8.6220e-06, 5.6280e-06, 1.6617e-05, 8.0793e-06, 3.1856e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,833][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.1638e-06, 7.7903e-01, 8.8932e-02, 1.8093e-02, 1.7787e-02, 1.1871e-02,
        7.9771e-03, 4.8111e-03, 1.1299e-02, 6.6914e-03, 5.2584e-03, 1.1206e-02,
        9.5597e-03, 5.3123e-03, 7.1938e-03, 6.1168e-03, 6.3252e-03, 2.5357e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,838][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0029, 0.2339, 0.0558, 0.1451, 0.0297, 0.0281, 0.0302, 0.0277, 0.0313,
        0.0418, 0.0541, 0.0325, 0.0921, 0.0300, 0.0520, 0.0398, 0.0496, 0.0233],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:54,841][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([4.8632e-09, 9.8648e-01, 1.3208e-02, 1.6762e-04, 1.2578e-04, 1.0820e-05,
        2.5809e-06, 2.1703e-07, 7.0623e-07, 4.5039e-06, 1.7390e-07, 3.2893e-08,
        2.4402e-08, 3.6511e-07, 9.3098e-08, 1.2197e-06, 1.5632e-07, 2.5071e-07,
        6.3893e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,842][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0144, 0.0917, 0.0482, 0.1100, 0.0555, 0.1194, 0.0530, 0.0527, 0.0304,
        0.0480, 0.0276, 0.0481, 0.0412, 0.0274, 0.0266, 0.0454, 0.0479, 0.0459,
        0.0666], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,843][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([1.7193e-04, 5.2627e-02, 2.1410e-02, 3.7577e-02, 3.1743e-02, 2.1644e-02,
        2.0181e-02, 4.4509e-02, 2.5791e-02, 1.9279e-01, 6.5543e-02, 3.4174e-02,
        3.4958e-02, 2.9992e-02, 2.6407e-02, 1.8648e-01, 3.5842e-02, 7.7505e-02,
        6.0647e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,844][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0017, 0.2539, 0.2775, 0.0692, 0.0598, 0.0654, 0.0327, 0.0161, 0.0283,
        0.0585, 0.0155, 0.0105, 0.0116, 0.0196, 0.0078, 0.0380, 0.0086, 0.0145,
        0.0107], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,845][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([2.8290e-05, 8.6965e-01, 1.2371e-01, 3.8867e-03, 1.1563e-03, 9.3983e-04,
        3.0158e-04, 5.6405e-05, 8.5656e-05, 1.1016e-04, 1.4213e-05, 1.1300e-05,
        9.7143e-06, 1.9509e-06, 6.3447e-06, 2.0464e-05, 1.4018e-05, 4.0833e-06,
        2.4392e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,848][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.6803, 0.0849, 0.1212, 0.0209, 0.0075, 0.0158, 0.0209, 0.0022, 0.0068,
        0.0035, 0.0018, 0.0130, 0.0019, 0.0018, 0.0034, 0.0027, 0.0045, 0.0011,
        0.0057], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,853][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.0156, 0.0791, 0.0723, 0.0702, 0.0693, 0.0471, 0.0428, 0.0658, 0.0403,
        0.0496, 0.0558, 0.0470, 0.0449, 0.0552, 0.0460, 0.0506, 0.0531, 0.0509,
        0.0444], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,855][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0103, 0.0490, 0.0416, 0.1430, 0.0223, 0.0186, 0.0912, 0.0275, 0.0787,
        0.0291, 0.0190, 0.1815, 0.0279, 0.0235, 0.0207, 0.0177, 0.0905, 0.0174,
        0.0908], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,856][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([1.6811e-05, 7.3065e-01, 2.6137e-01, 3.1791e-03, 3.9433e-03, 4.2478e-04,
        2.8650e-04, 1.7584e-05, 5.0298e-05, 2.3855e-05, 5.7623e-06, 4.9059e-06,
        2.2812e-06, 4.6190e-06, 5.3614e-06, 2.9780e-06, 1.1581e-05, 9.6210e-07,
        1.6026e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,857][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([3.6657e-06, 8.7062e-01, 1.2577e-01, 1.4578e-03, 1.0902e-03, 6.5557e-04,
        2.2522e-04, 1.4223e-05, 4.2506e-05, 6.1825e-05, 5.3540e-06, 1.0631e-05,
        9.4943e-06, 3.2148e-06, 4.4991e-06, 9.7711e-06, 8.6309e-06, 2.4376e-06,
        3.5060e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,858][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([2.2887e-04, 3.0102e-01, 1.8445e-01, 1.9755e-02, 3.4990e-02, 1.6157e-02,
        2.9562e-02, 2.1223e-02, 4.5549e-02, 3.6487e-02, 2.3809e-02, 8.3524e-02,
        2.2260e-02, 2.5572e-02, 2.4017e-02, 4.9168e-02, 2.9500e-02, 2.2278e-02,
        3.0451e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,861][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0019, 0.0955, 0.0956, 0.0819, 0.0412, 0.0197, 0.1252, 0.0392, 0.0455,
        0.0460, 0.0470, 0.0470, 0.0748, 0.0459, 0.0329, 0.0273, 0.0936, 0.0249,
        0.0151], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:54,863][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.7561e-07, 9.7882e-01, 2.0534e-02, 3.7113e-04, 1.9088e-04, 3.9998e-05,
        1.4598e-05, 9.4433e-07, 3.1772e-06, 1.2982e-05, 5.4735e-07, 1.9997e-07,
        1.1017e-07, 2.0643e-06, 6.1467e-07, 4.7590e-06, 8.2106e-07, 9.9338e-07,
        6.5872e-07, 1.9405e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,868][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0021, 0.1595, 0.0471, 0.0634, 0.0447, 0.0757, 0.0520, 0.0492, 0.0315,
        0.0473, 0.0214, 0.0565, 0.0316, 0.0206, 0.0272, 0.0520, 0.0448, 0.0406,
        0.0825, 0.0503], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,869][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([7.7844e-05, 1.1189e-01, 2.9976e-02, 6.7904e-02, 4.3782e-02, 3.9030e-02,
        2.2660e-02, 4.6274e-02, 1.5237e-02, 1.2372e-01, 5.6684e-02, 2.8876e-02,
        4.2644e-02, 3.4155e-02, 2.4103e-02, 1.0817e-01, 4.3333e-02, 6.7394e-02,
        2.0552e-02, 7.3539e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,870][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0013, 0.1810, 0.5388, 0.0420, 0.0576, 0.0454, 0.0378, 0.0059, 0.0206,
        0.0084, 0.0069, 0.0030, 0.0030, 0.0176, 0.0086, 0.0045, 0.0076, 0.0042,
        0.0030, 0.0029], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,871][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.3276e-04, 8.7187e-01, 1.1620e-01, 5.6266e-03, 1.8812e-03, 2.3126e-03,
        7.1369e-04, 1.5740e-04, 1.8398e-04, 2.2669e-04, 3.3278e-05, 2.7286e-05,
        2.4719e-05, 1.0361e-05, 2.5192e-05, 5.6983e-05, 6.8060e-05, 1.8812e-05,
        8.8380e-06, 2.3205e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,872][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([7.5940e-01, 5.3695e-02, 1.1699e-01, 1.3202e-02, 8.0485e-03, 5.3622e-03,
        1.2852e-02, 1.6873e-03, 3.9742e-03, 2.3843e-03, 8.9080e-04, 5.0069e-03,
        9.4201e-04, 2.0253e-03, 2.8771e-03, 1.7589e-03, 2.7423e-03, 6.3783e-04,
        3.8617e-03, 1.6585e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,876][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0174, 0.0718, 0.0681, 0.0695, 0.0662, 0.0459, 0.0380, 0.0615, 0.0377,
        0.0473, 0.0541, 0.0436, 0.0430, 0.0527, 0.0436, 0.0481, 0.0481, 0.0484,
        0.0456, 0.0494], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,880][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0028, 0.0557, 0.0241, 0.0813, 0.0261, 0.0140, 0.0729, 0.0287, 0.0830,
        0.0467, 0.0191, 0.2793, 0.0248, 0.0253, 0.0145, 0.0186, 0.0686, 0.0130,
        0.0792, 0.0220], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,882][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.6515e-05, 6.6350e-01, 3.2853e-01, 2.4970e-03, 4.4477e-03, 4.1365e-04,
        4.0108e-04, 2.2344e-05, 6.3151e-05, 2.7830e-05, 7.9971e-06, 5.5333e-06,
        3.8268e-06, 1.6820e-05, 1.0033e-05, 5.1019e-06, 1.6202e-05, 1.9922e-06,
        3.1022e-06, 1.3864e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,883][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.5428e-05, 8.9637e-01, 9.9812e-02, 1.2688e-03, 1.0874e-03, 6.9784e-04,
        4.0289e-04, 3.5146e-05, 7.6679e-05, 1.0611e-04, 1.3692e-05, 1.5018e-05,
        1.6021e-05, 1.2218e-05, 8.3455e-06, 2.3145e-05, 1.3383e-05, 7.2895e-06,
        7.2362e-06, 8.3171e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,884][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.1955e-06, 6.5634e-01, 1.4210e-01, 1.4419e-02, 2.8066e-02, 2.1767e-02,
        1.5437e-02, 7.3257e-03, 1.5233e-02, 9.8105e-03, 7.3418e-03, 2.2725e-02,
        9.9928e-03, 6.4052e-03, 6.5437e-03, 1.0328e-02, 1.2292e-02, 5.5700e-03,
        3.7603e-03, 4.5350e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,885][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0034, 0.1372, 0.0840, 0.1044, 0.0548, 0.0301, 0.0752, 0.0392, 0.0515,
        0.0403, 0.0533, 0.0495, 0.0610, 0.0431, 0.0411, 0.0244, 0.0538, 0.0243,
        0.0144, 0.0151], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:54,975][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:54,977][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,977][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,978][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,979][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,979][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,980][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,981][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,981][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,982][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,983][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,983][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,984][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:54,985][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0104, 0.9896], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,985][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9939, 0.0061], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,986][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0125, 0.9875], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,987][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0255, 0.9745], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,987][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0120, 0.9880], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,988][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,989][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9903e-01, 9.6790e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,990][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9501, 0.0499], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,991][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0307, 0.9693], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,991][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,992][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,993][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:54,994][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([1.0304e-05, 9.9592e-01, 4.0716e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,994][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.9852, 0.0061, 0.0087], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:54,996][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0358, 0.6160, 0.3482], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,000][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0047, 0.9583, 0.0371], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,003][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([1.4150e-04, 9.8479e-01, 1.5067e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,007][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.9563, 0.0291, 0.0146], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,007][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.9918, 0.0052, 0.0029], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,008][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.9265, 0.0412, 0.0323], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,009][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([2.3626e-04, 9.7390e-01, 2.5866e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,010][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([5.0188e-05, 9.8899e-01, 1.0962e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,011][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0226, 0.7160, 0.2614], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,014][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.9918, 0.0043, 0.0038], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,019][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0018, 0.9460, 0.0511, 0.0010], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,020][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8734, 0.0190, 0.0652, 0.0424], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,021][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([4.2296e-04, 5.1030e-01, 1.8083e-01, 3.0845e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,022][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0015, 0.9391, 0.0470, 0.0124], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,023][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.3917e-04, 9.6416e-01, 3.2396e-02, 3.0082e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,023][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9791, 0.0070, 0.0103, 0.0037], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,026][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9668, 0.0092, 0.0058, 0.0182], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,030][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2931, 0.1536, 0.2294, 0.3240], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,034][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.9483e-04, 9.2624e-01, 6.9964e-02, 3.5990e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,034][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.3491e-04, 8.8026e-01, 1.1768e-01, 1.9264e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,035][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.3905e-05, 7.4057e-01, 1.9015e-01, 6.9246e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,036][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9072, 0.0193, 0.0314, 0.0421], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,036][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([5.8948e-07, 9.8345e-01, 1.6270e-02, 2.6626e-04, 8.6898e-06],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,037][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.9231, 0.0068, 0.0208, 0.0263, 0.0230], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,041][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0012, 0.2872, 0.1556, 0.2226, 0.3333], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,044][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([3.3342e-04, 9.5545e-01, 4.0331e-02, 3.6836e-03, 2.0226e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,047][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([1.1966e-05, 9.7930e-01, 1.9212e-02, 1.4075e-03, 6.5143e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,048][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.9015, 0.0468, 0.0337, 0.0151, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,049][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.9375, 0.0160, 0.0149, 0.0250, 0.0065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,049][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.4621, 0.0906, 0.0895, 0.3370, 0.0208], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,050][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([5.6789e-06, 9.5968e-01, 3.7508e-02, 2.4496e-03, 3.5785e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,051][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([2.8988e-06, 9.8557e-01, 1.3497e-02, 8.6168e-04, 6.5024e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,054][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0004, 0.3748, 0.3369, 0.1080, 0.1799], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,059][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.8887, 0.0162, 0.0181, 0.0408, 0.0362], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,061][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([1.8614e-04, 9.3377e-01, 6.4183e-02, 1.4100e-03, 1.5895e-04, 2.8817e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,061][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.7273, 0.0357, 0.0766, 0.0690, 0.0553, 0.0361], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,062][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0004, 0.2785, 0.1419, 0.2578, 0.2417, 0.0796], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,063][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0018, 0.8882, 0.0995, 0.0071, 0.0012, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,064][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([2.4784e-04, 9.5377e-01, 3.8072e-02, 6.7352e-03, 2.9468e-04, 8.7813e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,066][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.9685, 0.0082, 0.0147, 0.0060, 0.0014, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,071][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.8829, 0.0253, 0.0195, 0.0443, 0.0101, 0.0179], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,074][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.2099, 0.1769, 0.1840, 0.3566, 0.0378, 0.0347], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,075][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([4.6530e-05, 8.3986e-01, 1.5064e-01, 5.6776e-03, 3.4451e-03, 3.3164e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,075][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([2.8161e-05, 9.1926e-01, 7.6812e-02, 2.5865e-03, 7.0607e-04, 6.0238e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,076][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([6.5767e-05, 7.3551e-01, 1.3790e-01, 3.7466e-02, 6.9628e-02, 1.9430e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,077][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.6028, 0.0320, 0.0643, 0.0886, 0.0354, 0.1769], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,078][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([5.6415e-06, 9.5023e-01, 4.8945e-02, 5.8223e-04, 7.7927e-05, 1.4737e-04,
        8.4651e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,081][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.7381, 0.0167, 0.1081, 0.0317, 0.0452, 0.0152, 0.0451],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,086][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0011, 0.1383, 0.1202, 0.1619, 0.2742, 0.1547, 0.1497],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,088][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([3.8468e-04, 9.1467e-01, 7.6954e-02, 5.0847e-03, 8.5167e-04, 1.3319e-03,
        7.2508e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,088][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([5.5842e-05, 9.3674e-01, 5.7645e-02, 4.1919e-03, 4.9082e-04, 7.2637e-04,
        1.4696e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,089][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.8837, 0.0416, 0.0350, 0.0188, 0.0033, 0.0063, 0.0112],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,090][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.8676, 0.0277, 0.0210, 0.0303, 0.0103, 0.0135, 0.0297],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,091][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.3945, 0.1197, 0.1336, 0.2453, 0.0299, 0.0408, 0.0362],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,092][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([1.2356e-05, 8.4670e-01, 1.4645e-01, 3.3045e-03, 3.1635e-03, 2.2936e-04,
        1.3641e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,095][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([8.8242e-06, 8.7454e-01, 1.2179e-01, 1.9681e-03, 8.2821e-04, 6.9241e-04,
        1.7331e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,098][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([3.9613e-04, 4.1508e-01, 1.8504e-01, 2.8587e-02, 2.3648e-01, 5.4318e-02,
        8.0099e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,101][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.6196, 0.0352, 0.0298, 0.0588, 0.0266, 0.1188, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,102][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([1.2456e-04, 9.1147e-01, 8.4043e-02, 2.5853e-03, 6.1955e-04, 9.2060e-04,
        2.0413e-04, 3.1681e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,102][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.7270, 0.0241, 0.0874, 0.0342, 0.0268, 0.0181, 0.0552, 0.0273],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,103][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([2.2132e-04, 2.6654e-01, 1.6500e-01, 1.6274e-01, 1.5378e-01, 9.5625e-02,
        7.9398e-02, 7.6691e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,104][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([1.4719e-03, 8.4167e-01, 1.4004e-01, 7.9042e-03, 1.7144e-03, 4.1529e-03,
        2.7420e-03, 3.0970e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,106][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([2.0456e-03, 8.6438e-01, 1.0830e-01, 1.4487e-02, 2.1229e-03, 6.0825e-03,
        1.9487e-03, 6.2470e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,110][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.9048, 0.0195, 0.0460, 0.0091, 0.0032, 0.0043, 0.0111, 0.0019],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,114][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.9185, 0.0132, 0.0108, 0.0142, 0.0059, 0.0091, 0.0209, 0.0075],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,115][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.2707, 0.1397, 0.1807, 0.3009, 0.0302, 0.0291, 0.0350, 0.0138],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,116][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([9.8297e-05, 8.3777e-01, 1.4842e-01, 5.9766e-03, 6.0444e-03, 7.7950e-04,
        8.3133e-04, 7.7245e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,117][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([9.3369e-05, 9.0761e-01, 8.3143e-02, 4.8061e-03, 1.4946e-03, 1.8595e-03,
        8.8828e-04, 1.0667e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,117][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([6.5198e-05, 5.0830e-01, 2.7848e-01, 3.3288e-02, 7.3700e-02, 3.2673e-02,
        5.7425e-02, 1.6065e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,120][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.7592, 0.0129, 0.0164, 0.0404, 0.0147, 0.0419, 0.0717, 0.0428],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,122][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([1.2393e-04, 9.0218e-01, 9.4859e-02, 1.9408e-03, 2.7783e-04, 5.0171e-04,
        9.3145e-05, 1.8861e-05, 6.4014e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,128][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.6225, 0.0438, 0.1199, 0.0307, 0.0382, 0.0107, 0.0576, 0.0494, 0.0271],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,129][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0008, 0.2042, 0.0913, 0.1031, 0.1660, 0.1452, 0.1255, 0.0954, 0.0685],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,129][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([6.2393e-04, 8.9756e-01, 9.2276e-02, 5.1401e-03, 8.3493e-04, 1.9899e-03,
        1.2136e-03, 1.3704e-04, 2.2509e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,130][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([7.4141e-04, 9.4189e-01, 4.3528e-02, 9.1282e-03, 7.2481e-04, 2.8754e-03,
        7.3732e-04, 1.7523e-04, 2.0349e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,131][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.9470, 0.0166, 0.0142, 0.0079, 0.0012, 0.0029, 0.0062, 0.0018, 0.0021],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,133][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.7894, 0.0297, 0.0182, 0.0348, 0.0093, 0.0228, 0.0493, 0.0273, 0.0192],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,138][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.3588, 0.1513, 0.1452, 0.2078, 0.0395, 0.0278, 0.0322, 0.0141, 0.0233],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,141][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([7.4474e-05, 8.5666e-01, 1.2768e-01, 8.5178e-03, 5.7795e-03, 6.4292e-04,
        5.5498e-04, 3.8523e-05, 5.8031e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,142][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([1.7206e-05, 9.1256e-01, 8.3757e-02, 1.6169e-03, 7.1328e-04, 8.3608e-04,
        3.5597e-04, 5.5685e-05, 9.1837e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,143][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([3.6460e-04, 5.5488e-01, 1.3510e-01, 2.1905e-02, 6.8582e-02, 3.8199e-02,
        7.0788e-02, 4.9154e-02, 6.1023e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,144][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.7083, 0.0201, 0.0128, 0.0400, 0.0118, 0.0531, 0.0515, 0.0537, 0.0487],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,144][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.8948e-02, 8.9800e-01, 7.1548e-02, 5.5935e-03, 9.1879e-04, 2.5394e-03,
        1.2102e-03, 3.8916e-04, 2.1080e-04, 6.4356e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,147][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.7258, 0.0181, 0.0719, 0.0337, 0.0331, 0.0156, 0.0346, 0.0292, 0.0263,
        0.0117], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,149][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.7948e-04, 1.7831e-01, 5.1045e-02, 8.0445e-02, 5.7327e-02, 8.2873e-02,
        5.9717e-02, 1.1195e-01, 3.9779e-02, 3.3838e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,155][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0090, 0.8488, 0.1099, 0.0126, 0.0019, 0.0076, 0.0059, 0.0010, 0.0014,
        0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,156][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0327, 0.8503, 0.0601, 0.0248, 0.0022, 0.0179, 0.0048, 0.0022, 0.0018,
        0.0032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,156][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.7983e-01, 3.6912e-03, 5.7349e-03, 2.1308e-03, 4.9222e-04, 1.2229e-03,
        3.5534e-03, 8.5404e-04, 1.4429e-03, 1.0494e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,157][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8942, 0.0123, 0.0128, 0.0185, 0.0062, 0.0106, 0.0229, 0.0102, 0.0081,
        0.0042], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,158][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.4432, 0.1176, 0.1099, 0.1712, 0.0287, 0.0198, 0.0419, 0.0155, 0.0272,
        0.0249], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,159][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.6283e-03, 7.9485e-01, 1.7048e-01, 1.5676e-02, 1.0608e-02, 2.1120e-03,
        2.9726e-03, 4.7276e-04, 6.7740e-04, 5.2569e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,162][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3924e-03, 8.7301e-01, 1.0476e-01, 7.4676e-03, 2.3397e-03, 4.7361e-03,
        2.8063e-03, 7.0147e-04, 6.8295e-04, 2.1051e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,165][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1672e-05, 6.2967e-01, 1.6530e-01, 1.9927e-02, 3.7434e-02, 3.1779e-02,
        3.8211e-02, 1.6476e-02, 3.8302e-02, 2.2887e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,168][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7408, 0.0103, 0.0120, 0.0233, 0.0093, 0.0281, 0.0564, 0.0360, 0.0432,
        0.0404], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,169][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.9072e-05, 9.4487e-01, 5.3819e-02, 7.5501e-04, 1.8764e-04, 2.2703e-04,
        7.8884e-05, 9.9572e-06, 9.1640e-06, 2.7263e-05, 7.7887e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,170][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.5495, 0.0445, 0.1464, 0.0498, 0.0474, 0.0240, 0.0422, 0.0385, 0.0307,
        0.0164, 0.0106], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,171][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.4631e-04, 2.0340e-01, 5.0879e-02, 1.3033e-01, 6.1188e-02, 4.0238e-02,
        3.8512e-02, 7.3995e-02, 3.7987e-02, 2.6290e-01, 1.0043e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,172][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.1665e-04, 9.0738e-01, 8.6003e-02, 2.8276e-03, 6.5860e-04, 1.3957e-03,
        9.3158e-04, 1.0245e-04, 1.8763e-04, 2.7106e-04, 2.1850e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,173][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([3.1275e-04, 9.2140e-01, 6.5509e-02, 7.8546e-03, 9.6165e-04, 2.3363e-03,
        7.6001e-04, 1.8815e-04, 2.5582e-04, 3.9678e-04, 2.5269e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,176][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([9.0238e-01, 2.7097e-02, 3.4635e-02, 1.1950e-02, 2.0599e-03, 4.5251e-03,
        9.0710e-03, 1.6150e-03, 3.4529e-03, 2.6205e-03, 5.8873e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,180][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8241, 0.0270, 0.0179, 0.0292, 0.0087, 0.0159, 0.0361, 0.0141, 0.0121,
        0.0070, 0.0080], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,182][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.2800, 0.1538, 0.1675, 0.2520, 0.0296, 0.0204, 0.0338, 0.0089, 0.0279,
        0.0187, 0.0075], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,183][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.9420e-05, 8.7193e-01, 1.2045e-01, 3.7406e-03, 3.0184e-03, 3.6455e-04,
        3.3828e-04, 3.2244e-05, 5.1541e-05, 5.0943e-05, 5.1209e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,184][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([5.7532e-06, 9.3100e-01, 6.6587e-02, 1.0717e-03, 4.3587e-04, 4.7561e-04,
        1.9863e-04, 3.2711e-05, 4.5658e-05, 1.3181e-04, 1.0066e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,185][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.5928e-05, 6.6785e-01, 1.1633e-01, 2.4323e-02, 3.3199e-02, 1.7745e-02,
        3.8857e-02, 1.6910e-02, 3.8310e-02, 2.8594e-02, 1.7862e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,185][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.5713, 0.0273, 0.0159, 0.0607, 0.0107, 0.0415, 0.0636, 0.0424, 0.0563,
        0.0564, 0.0541], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,187][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([9.1081e-08, 9.3921e-01, 6.0247e-02, 3.8921e-04, 1.1861e-04, 2.9526e-05,
        6.2907e-06, 6.0370e-07, 6.6483e-07, 2.3996e-06, 8.7096e-08, 2.4691e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,191][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.6446, 0.0236, 0.0588, 0.0343, 0.0319, 0.0151, 0.0664, 0.0265, 0.0306,
        0.0168, 0.0077, 0.0436], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,196][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0009, 0.2316, 0.0619, 0.1182, 0.0772, 0.0884, 0.0281, 0.0454, 0.0240,
        0.1475, 0.0863, 0.0905], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,197][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([3.3517e-05, 8.5958e-01, 1.3474e-01, 2.7489e-03, 1.1321e-03, 1.1063e-03,
        4.2067e-04, 3.0814e-05, 8.6296e-05, 1.0797e-04, 9.8841e-06, 5.4939e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,198][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([5.3099e-06, 9.6232e-01, 3.4814e-02, 2.1075e-03, 2.1986e-04, 3.1180e-04,
        7.7499e-05, 2.2656e-05, 3.2757e-05, 8.0959e-05, 6.6642e-06, 1.8192e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,198][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.5741, 0.1171, 0.1633, 0.0344, 0.0082, 0.0160, 0.0317, 0.0067, 0.0138,
        0.0125, 0.0030, 0.0192], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,199][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.7061, 0.0419, 0.0296, 0.0399, 0.0120, 0.0247, 0.0485, 0.0227, 0.0213,
        0.0113, 0.0106, 0.0315], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,202][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.1020, 0.2662, 0.2183, 0.2311, 0.0322, 0.0201, 0.0248, 0.0078, 0.0141,
        0.0217, 0.0053, 0.0565], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,204][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.6838e-06, 8.7920e-01, 1.1746e-01, 1.4796e-03, 1.6981e-03, 9.5478e-05,
        3.8295e-05, 4.9185e-06, 6.6470e-06, 1.3529e-05, 1.3046e-06, 9.3378e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,207][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([1.2965e-06, 9.1087e-01, 8.6611e-02, 1.1759e-03, 5.2934e-04, 5.0186e-04,
        1.7057e-04, 1.7685e-05, 3.1321e-05, 7.8979e-05, 6.3499e-06, 2.5327e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,210][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0006, 0.4186, 0.1022, 0.0247, 0.0188, 0.0383, 0.1124, 0.0517, 0.1185,
        0.0322, 0.0295, 0.0523], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,211][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.3899, 0.0293, 0.0402, 0.0671, 0.0221, 0.0542, 0.0845, 0.0378, 0.0560,
        0.0533, 0.0615, 0.1041], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,212][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([2.7259e-05, 9.2272e-01, 7.6470e-02, 3.9604e-04, 1.4159e-04, 1.5500e-04,
        6.1351e-05, 8.4032e-06, 5.3298e-06, 1.6970e-05, 6.8728e-07, 2.8385e-07,
        5.1973e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,213][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.5594, 0.0427, 0.0890, 0.0371, 0.0364, 0.0211, 0.0481, 0.0271, 0.0369,
        0.0118, 0.0090, 0.0593, 0.0221], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,213][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0002, 0.1185, 0.0450, 0.0992, 0.0543, 0.0552, 0.0413, 0.0886, 0.0375,
        0.1871, 0.1284, 0.0715, 0.0731], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,216][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.1958e-04, 8.8121e-01, 1.1246e-01, 2.6341e-03, 8.6531e-04, 1.3793e-03,
        8.4015e-04, 6.9063e-05, 1.7515e-04, 1.9942e-04, 1.6342e-05, 1.1254e-05,
        1.9647e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,220][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([8.1416e-05, 9.4044e-01, 5.4939e-02, 2.5178e-03, 4.9300e-04, 9.8824e-04,
        2.3875e-04, 6.6154e-05, 6.2187e-05, 1.3960e-04, 1.1434e-05, 7.0421e-06,
        1.2438e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,223][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.6523, 0.0939, 0.1200, 0.0329, 0.0092, 0.0177, 0.0274, 0.0066, 0.0123,
        0.0095, 0.0031, 0.0121, 0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,224][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6408, 0.0530, 0.0375, 0.0474, 0.0144, 0.0255, 0.0544, 0.0225, 0.0215,
        0.0128, 0.0135, 0.0361, 0.0206], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,225][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.1280, 0.2008, 0.1845, 0.2042, 0.0420, 0.0308, 0.0390, 0.0141, 0.0285,
        0.0190, 0.0106, 0.0878, 0.0109], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,226][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([6.5310e-06, 8.5225e-01, 1.4341e-01, 1.8653e-03, 1.8891e-03, 2.6892e-04,
        2.3670e-04, 1.9243e-05, 2.0880e-05, 2.7438e-05, 3.2016e-06, 2.1176e-06,
        1.3252e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,226][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.2172e-05, 8.9084e-01, 1.0672e-01, 8.2381e-04, 4.9178e-04, 6.5365e-04,
        2.4358e-04, 2.8674e-05, 5.6602e-05, 9.5923e-05, 8.8100e-06, 9.1981e-06,
        1.2692e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,229][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.6926e-05, 5.9705e-01, 1.5353e-01, 1.8413e-02, 3.8921e-02, 2.0832e-02,
        2.9368e-02, 1.2692e-02, 2.6648e-02, 2.3338e-02, 1.7761e-02, 4.1422e-02,
        2.0009e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,236][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.7476, 0.0085, 0.0106, 0.0194, 0.0091, 0.0183, 0.0350, 0.0245, 0.0237,
        0.0183, 0.0270, 0.0326, 0.0255], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,237][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([9.4562e-06, 8.0899e-01, 1.8985e-01, 5.7679e-04, 2.9805e-04, 1.6969e-04,
        8.1186e-05, 6.6158e-06, 7.9053e-06, 1.2315e-05, 7.1687e-07, 5.9829e-07,
        3.2731e-07, 3.0732e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,238][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.4851, 0.0528, 0.0744, 0.0563, 0.0440, 0.0338, 0.0536, 0.0218, 0.0167,
        0.0143, 0.0066, 0.0534, 0.0137, 0.0735], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,239][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0004, 0.1251, 0.0313, 0.0688, 0.0506, 0.0693, 0.0807, 0.1008, 0.0796,
        0.1480, 0.0818, 0.0739, 0.0609, 0.0289], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,239][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([6.0138e-04, 8.3830e-01, 1.5195e-01, 4.4367e-03, 1.0936e-03, 2.0906e-03,
        1.0400e-03, 6.5365e-05, 1.6934e-04, 1.5869e-04, 2.2168e-05, 2.4726e-05,
        3.3769e-05, 1.0823e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,242][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([1.2695e-04, 8.7345e-01, 1.1971e-01, 3.6058e-03, 1.2429e-03, 1.1299e-03,
        3.3362e-04, 1.0463e-04, 1.1444e-04, 1.3353e-04, 1.8568e-05, 1.0696e-05,
        1.2471e-05, 5.8428e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,249][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.7519, 0.0647, 0.0938, 0.0215, 0.0087, 0.0106, 0.0208, 0.0055, 0.0066,
        0.0034, 0.0020, 0.0054, 0.0022, 0.0027], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,250][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.7057, 0.0432, 0.0298, 0.0415, 0.0113, 0.0263, 0.0412, 0.0187, 0.0161,
        0.0100, 0.0081, 0.0264, 0.0160, 0.0055], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,251][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.3721, 0.1341, 0.1125, 0.2085, 0.0150, 0.0213, 0.0343, 0.0099, 0.0258,
        0.0134, 0.0056, 0.0332, 0.0076, 0.0067], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,252][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([3.1799e-05, 8.5446e-01, 1.3773e-01, 4.8918e-03, 2.2533e-03, 3.4225e-04,
        1.9138e-04, 2.7086e-05, 2.6691e-05, 3.5755e-05, 6.4892e-06, 2.2025e-06,
        3.1098e-06, 3.7433e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,252][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([3.2240e-05, 9.3376e-01, 6.3066e-02, 1.4712e-03, 4.2496e-04, 7.6754e-04,
        2.7199e-04, 3.9178e-05, 5.9735e-05, 7.1887e-05, 7.6930e-06, 1.4698e-05,
        1.3675e-05, 3.4102e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,255][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([1.3767e-04, 3.7146e-01, 1.2852e-01, 2.8046e-02, 3.3543e-02, 8.6205e-02,
        3.5825e-02, 3.7873e-02, 2.2667e-02, 3.4452e-02, 3.2588e-02, 1.1588e-01,
        5.7150e-02, 1.5653e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,262][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.8108, 0.0045, 0.0041, 0.0126, 0.0058, 0.0234, 0.0331, 0.0261, 0.0108,
        0.0102, 0.0135, 0.0209, 0.0163, 0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,263][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([1.0294e-04, 8.2411e-01, 1.7317e-01, 1.2366e-03, 5.7797e-04, 5.1588e-04,
        1.9670e-04, 1.9423e-05, 1.6783e-05, 4.4365e-05, 2.7248e-06, 1.3828e-06,
        1.2641e-06, 1.2585e-06, 1.0537e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,264][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.1629, 0.1321, 0.1930, 0.0289, 0.0593, 0.0128, 0.0604, 0.0257, 0.0627,
        0.0265, 0.0132, 0.0722, 0.0201, 0.1035, 0.0265], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,265][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0003, 0.1168, 0.0335, 0.0655, 0.0515, 0.0365, 0.0619, 0.0665, 0.0539,
        0.1719, 0.1254, 0.0518, 0.0661, 0.0616, 0.0368], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,266][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([2.1247e-04, 8.8728e-01, 1.0589e-01, 2.7028e-03, 1.3026e-03, 9.5000e-04,
        1.0129e-03, 9.3585e-05, 1.7758e-04, 2.5264e-04, 2.2039e-05, 1.9539e-05,
        3.0438e-05, 1.5353e-05, 3.7381e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,268][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([6.2462e-04, 8.9282e-01, 9.4720e-02, 6.7240e-03, 1.3606e-03, 2.5307e-03,
        4.8599e-04, 1.6050e-04, 1.8181e-04, 2.6048e-04, 3.5462e-05, 3.0195e-05,
        3.6189e-05, 9.6560e-06, 1.7481e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,275][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.7300, 0.0789, 0.0921, 0.0276, 0.0079, 0.0061, 0.0226, 0.0040, 0.0048,
        0.0060, 0.0039, 0.0089, 0.0027, 0.0022, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,276][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.6476, 0.0502, 0.0285, 0.0461, 0.0107, 0.0201, 0.0422, 0.0178, 0.0165,
        0.0114, 0.0120, 0.0401, 0.0222, 0.0097, 0.0249], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,277][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.3920, 0.1223, 0.1144, 0.1778, 0.0260, 0.0152, 0.0340, 0.0087, 0.0211,
        0.0124, 0.0057, 0.0498, 0.0068, 0.0083, 0.0056], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,278][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([2.6098e-05, 8.3057e-01, 1.5995e-01, 5.2022e-03, 3.0314e-03, 5.1005e-04,
        4.6358e-04, 5.1688e-05, 5.6192e-05, 8.4405e-05, 1.0082e-05, 8.8166e-06,
        5.0700e-06, 1.5728e-05, 8.8438e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,279][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([1.4016e-05, 8.9870e-01, 9.7217e-02, 1.6561e-03, 9.0277e-04, 7.8037e-04,
        4.2736e-04, 2.7106e-05, 7.2521e-05, 1.2769e-04, 1.9919e-05, 1.3300e-05,
        2.3621e-05, 9.3333e-06, 8.5116e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,281][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([5.8794e-05, 5.9297e-01, 9.1332e-02, 1.7849e-02, 2.1096e-02, 2.2071e-02,
        3.5725e-02, 1.7365e-02, 3.8571e-02, 3.9126e-02, 3.5714e-02, 3.7000e-02,
        2.7577e-02, 1.3864e-02, 9.6838e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,288][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.5404, 0.0161, 0.0171, 0.0383, 0.0101, 0.0345, 0.0596, 0.0276, 0.0443,
        0.0379, 0.0445, 0.0374, 0.0442, 0.0161, 0.0319], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,289][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.4646e-03, 8.5065e-01, 1.3346e-01, 3.5840e-03, 1.2554e-03, 2.3562e-03,
        1.4109e-03, 1.8649e-04, 2.0661e-04, 2.7634e-04, 2.3704e-05, 1.0235e-05,
        1.2039e-05, 2.3325e-05, 2.7035e-05, 5.6572e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,290][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3960, 0.0671, 0.1428, 0.0383, 0.0528, 0.0198, 0.0325, 0.0280, 0.0266,
        0.0135, 0.0061, 0.0393, 0.0147, 0.0859, 0.0206, 0.0160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,291][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.2534e-04, 1.1198e-01, 3.1473e-02, 6.0431e-02, 4.5140e-02, 4.9411e-02,
        3.3016e-02, 7.0738e-02, 2.2074e-02, 1.6848e-01, 1.0089e-01, 4.8171e-02,
        5.8901e-02, 4.2151e-02, 3.1408e-02, 1.2561e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,292][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.9393e-03, 7.9927e-01, 1.7730e-01, 8.6054e-03, 2.5513e-03, 3.9658e-03,
        3.5843e-03, 3.9044e-04, 7.5149e-04, 7.5972e-04, 8.2464e-05, 7.7321e-05,
        1.0450e-04, 9.1212e-05, 2.0010e-04, 3.3259e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,294][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.0323e-02, 8.5649e-01, 1.0010e-01, 1.3599e-02, 2.7716e-03, 9.5702e-03,
        2.7129e-03, 1.0746e-03, 9.0012e-04, 1.3425e-03, 2.1011e-04, 1.4040e-04,
        1.3160e-04, 6.1348e-05, 1.5373e-04, 4.2419e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,299][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.1904e-01, 1.4236e-02, 3.1904e-02, 5.8448e-03, 2.8630e-03, 3.2063e-03,
        7.3473e-03, 1.4077e-03, 2.5280e-03, 1.6541e-03, 6.3198e-04, 3.6325e-03,
        6.6455e-04, 1.3023e-03, 2.3186e-03, 1.4153e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,302][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7279, 0.0339, 0.0326, 0.0345, 0.0119, 0.0172, 0.0337, 0.0136, 0.0134,
        0.0076, 0.0089, 0.0200, 0.0137, 0.0071, 0.0164, 0.0078],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,302][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3501, 0.1364, 0.1234, 0.1648, 0.0303, 0.0152, 0.0294, 0.0101, 0.0186,
        0.0135, 0.0061, 0.0723, 0.0070, 0.0098, 0.0072, 0.0057],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,303][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([5.1865e-04, 7.0333e-01, 2.7511e-01, 8.2781e-03, 7.8463e-03, 1.7435e-03,
        1.9121e-03, 2.0647e-04, 4.1270e-04, 2.4417e-04, 6.1819e-05, 3.2948e-05,
        2.7013e-05, 1.4160e-04, 8.5042e-05, 5.4605e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,304][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.3157e-04, 8.6866e-01, 1.1680e-01, 4.1375e-03, 2.2329e-03, 3.1863e-03,
        2.1182e-03, 3.2908e-04, 4.9334e-04, 8.3537e-04, 1.1549e-04, 1.0393e-04,
        1.1556e-04, 1.1469e-04, 8.6139e-05, 2.4232e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,305][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.4392e-06, 6.6801e-01, 1.3677e-01, 1.6945e-02, 3.1586e-02, 2.1662e-02,
        1.9121e-02, 7.9498e-03, 1.7377e-02, 9.8824e-03, 8.9923e-03, 2.4431e-02,
        1.1469e-02, 6.8806e-03, 8.2782e-03, 1.0637e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,312][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7273, 0.0079, 0.0102, 0.0165, 0.0082, 0.0175, 0.0302, 0.0204, 0.0251,
        0.0157, 0.0247, 0.0310, 0.0164, 0.0194, 0.0190, 0.0107],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,314][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.9677e-05, 9.0328e-01, 9.3639e-02, 1.7501e-03, 5.8836e-04, 4.6870e-04,
        1.5885e-04, 1.6171e-05, 1.3738e-05, 4.1064e-05, 1.4507e-06, 1.2913e-06,
        9.7936e-07, 9.5351e-07, 1.4587e-06, 5.4531e-06, 1.6738e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,315][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.1400, 0.0962, 0.1973, 0.0316, 0.1486, 0.0219, 0.0192, 0.0236, 0.0182,
        0.0143, 0.0036, 0.0553, 0.0113, 0.1513, 0.0149, 0.0233, 0.0295],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,316][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0002, 0.1171, 0.0260, 0.0641, 0.0454, 0.0381, 0.0337, 0.0669, 0.0323,
        0.1683, 0.0976, 0.0297, 0.0515, 0.0412, 0.0245, 0.1286, 0.0346],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,317][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.0157e-04, 7.6959e-01, 2.2020e-01, 4.2659e-03, 2.2838e-03, 1.4627e-03,
        9.0406e-04, 1.1532e-04, 2.0970e-04, 2.5131e-04, 2.4255e-05, 2.5454e-05,
        3.3826e-05, 3.0031e-05, 3.7023e-05, 9.9776e-05, 6.1469e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,318][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([9.5138e-04, 8.8513e-01, 9.6454e-02, 9.3956e-03, 1.8454e-03, 3.9889e-03,
        9.6828e-04, 2.4588e-04, 2.7682e-04, 4.4842e-04, 4.6620e-05, 3.5309e-05,
        3.5129e-05, 9.1347e-06, 2.5547e-05, 8.9605e-05, 5.3057e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,322][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([7.7699e-01, 4.4964e-02, 1.3098e-01, 1.2114e-02, 9.7593e-03, 2.7976e-03,
        7.2895e-03, 1.1873e-03, 1.5352e-03, 1.5687e-03, 4.8792e-04, 3.8183e-03,
        6.5778e-04, 2.0306e-03, 1.1051e-03, 1.4300e-03, 1.2848e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,327][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.6191, 0.0477, 0.0472, 0.0493, 0.0219, 0.0205, 0.0357, 0.0184, 0.0132,
        0.0090, 0.0129, 0.0319, 0.0192, 0.0124, 0.0165, 0.0095, 0.0156],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,328][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.4950, 0.1047, 0.0614, 0.1710, 0.0138, 0.0103, 0.0190, 0.0071, 0.0111,
        0.0108, 0.0052, 0.0622, 0.0063, 0.0057, 0.0041, 0.0040, 0.0084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,329][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([9.3495e-05, 7.2488e-01, 2.6189e-01, 5.3511e-03, 6.0970e-03, 7.7138e-04,
        6.5664e-04, 4.4074e-05, 6.5259e-05, 5.5538e-05, 8.1392e-06, 9.8541e-06,
        5.0098e-06, 3.2175e-05, 1.6728e-05, 1.1557e-05, 1.5191e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,330][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([3.4093e-05, 8.9333e-01, 1.0052e-01, 2.0817e-03, 1.6160e-03, 1.2010e-03,
        5.8554e-04, 5.7165e-05, 1.0822e-04, 2.6278e-04, 2.6559e-05, 1.8098e-05,
        3.7868e-05, 2.5107e-05, 1.5547e-05, 5.9724e-05, 2.4004e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,331][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([2.6583e-05, 6.5653e-01, 1.0381e-01, 2.0771e-02, 2.9372e-02, 3.5611e-02,
        1.8382e-02, 1.0378e-02, 2.4046e-02, 1.0701e-02, 1.3076e-02, 1.9664e-02,
        1.4351e-02, 1.7084e-02, 8.1866e-03, 1.0946e-02, 7.0607e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,338][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.6603, 0.0210, 0.0094, 0.0274, 0.0079, 0.0224, 0.0297, 0.0142, 0.0274,
        0.0210, 0.0310, 0.0260, 0.0311, 0.0186, 0.0185, 0.0143, 0.0198],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,340][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.1615e-06, 9.0806e-01, 9.0951e-02, 5.0322e-04, 2.4045e-04, 1.6237e-04,
        6.0197e-05, 3.3962e-06, 6.2656e-06, 1.0055e-05, 4.3112e-07, 3.7087e-07,
        3.2343e-07, 4.3648e-07, 6.6177e-07, 1.3915e-06, 1.0859e-06, 9.7260e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,341][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2326, 0.0941, 0.2047, 0.0381, 0.0728, 0.0260, 0.0210, 0.0234, 0.0184,
        0.0124, 0.0049, 0.0347, 0.0142, 0.1210, 0.0186, 0.0172, 0.0356, 0.0105],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,342][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.5919e-05, 1.8990e-01, 2.4608e-02, 7.9999e-02, 3.0137e-02, 2.5808e-02,
        1.2741e-02, 3.9502e-02, 1.6332e-02, 1.4911e-01, 5.1429e-02, 2.6722e-02,
        5.2503e-02, 3.4413e-02, 3.4432e-02, 1.3252e-01, 4.7394e-02, 5.2405e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,343][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([8.1153e-05, 7.9633e-01, 1.9676e-01, 3.0772e-03, 1.1827e-03, 1.2759e-03,
        7.3125e-04, 5.5099e-05, 1.5809e-04, 1.4153e-04, 1.2737e-05, 1.8264e-05,
        2.5841e-05, 1.4944e-05, 3.1272e-05, 6.0340e-05, 3.3725e-05, 1.0119e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,344][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.5965e-04, 8.9214e-01, 9.8954e-02, 4.9466e-03, 1.0597e-03, 1.6476e-03,
        5.0365e-04, 1.0792e-04, 1.1221e-04, 2.0304e-04, 1.7923e-05, 1.5659e-05,
        2.0093e-05, 4.6989e-06, 1.6910e-05, 4.9601e-05, 2.7127e-05, 9.6832e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,348][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([8.2705e-01, 5.1174e-02, 7.3665e-02, 1.1558e-02, 5.8217e-03, 5.8973e-03,
        7.2541e-03, 9.7739e-04, 2.7453e-03, 1.9577e-03, 5.6991e-04, 2.7523e-03,
        7.0852e-04, 1.3495e-03, 2.6723e-03, 1.5391e-03, 1.9337e-03, 3.6972e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,353][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6034, 0.0676, 0.0523, 0.0474, 0.0195, 0.0231, 0.0379, 0.0133, 0.0147,
        0.0093, 0.0105, 0.0216, 0.0188, 0.0082, 0.0174, 0.0103, 0.0160, 0.0088],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,354][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2623, 0.2618, 0.1391, 0.1883, 0.0142, 0.0102, 0.0156, 0.0058, 0.0102,
        0.0116, 0.0042, 0.0362, 0.0051, 0.0063, 0.0057, 0.0051, 0.0149, 0.0034],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,355][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.1379e-05, 7.7023e-01, 2.2448e-01, 1.9205e-03, 2.6672e-03, 3.3232e-04,
        2.4243e-04, 1.6800e-05, 3.3656e-05, 2.5834e-05, 3.8397e-06, 5.2825e-06,
        2.6096e-06, 1.0137e-05, 8.1597e-06, 4.8650e-06, 1.0368e-05, 8.5531e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,356][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.3990e-06, 9.0088e-01, 9.6800e-02, 8.1977e-04, 6.4971e-04, 4.7258e-04,
        1.9540e-04, 1.6118e-05, 3.2943e-05, 6.7818e-05, 6.6421e-06, 7.1815e-06,
        1.1121e-05, 8.4069e-06, 5.6888e-06, 1.6077e-05, 8.0655e-06, 3.2077e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,357][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.1638e-06, 7.7903e-01, 8.8932e-02, 1.8093e-02, 1.7787e-02, 1.1871e-02,
        7.9771e-03, 4.8111e-03, 1.1299e-02, 6.6914e-03, 5.2584e-03, 1.1206e-02,
        9.5597e-03, 5.3123e-03, 7.1938e-03, 6.1168e-03, 6.3252e-03, 2.5357e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,364][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.4501, 0.0323, 0.0184, 0.0399, 0.0108, 0.0287, 0.0288, 0.0304, 0.0328,
        0.0331, 0.0378, 0.0462, 0.0494, 0.0290, 0.0411, 0.0257, 0.0403, 0.0251],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,366][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([7.5222e-07, 7.5952e-01, 2.3925e-01, 4.4331e-04, 6.3468e-04, 9.8669e-05,
        3.7993e-05, 2.4453e-06, 3.9836e-06, 5.8639e-06, 5.0075e-07, 2.8852e-07,
        2.4699e-07, 2.5828e-07, 2.5738e-07, 6.4403e-07, 6.6971e-07, 1.0015e-07,
        7.0515e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,367][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.3378, 0.0819, 0.1240, 0.0343, 0.0379, 0.0177, 0.0301, 0.0128, 0.0245,
        0.0112, 0.0046, 0.0376, 0.0127, 0.0774, 0.0277, 0.0219, 0.0505, 0.0144,
        0.0410], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,368][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([1.4236e-04, 4.9017e-02, 1.8005e-02, 3.1050e-02, 2.5523e-02, 2.0364e-02,
        1.9577e-02, 4.7184e-02, 2.4696e-02, 2.0635e-01, 7.1342e-02, 3.6381e-02,
        3.3725e-02, 2.7087e-02, 2.4239e-02, 1.8613e-01, 3.7364e-02, 7.8822e-02,
        6.3008e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,369][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([9.1162e-05, 7.2707e-01, 2.6614e-01, 2.8022e-03, 1.6370e-03, 1.1010e-03,
        7.0395e-04, 4.4196e-05, 1.3254e-04, 1.0981e-04, 1.3708e-05, 1.9416e-05,
        1.8136e-05, 9.1061e-06, 2.1921e-05, 3.4220e-05, 2.9487e-05, 8.2296e-06,
        1.0620e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,371][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([2.8290e-05, 8.6965e-01, 1.2371e-01, 3.8867e-03, 1.1563e-03, 9.3983e-04,
        3.0158e-04, 5.6405e-05, 8.5656e-05, 1.1016e-04, 1.4213e-05, 1.1300e-05,
        9.7143e-06, 1.9509e-06, 6.3447e-06, 2.0464e-05, 1.4018e-05, 4.0833e-06,
        2.4392e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,378][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.6803, 0.0849, 0.1212, 0.0209, 0.0075, 0.0158, 0.0209, 0.0022, 0.0068,
        0.0035, 0.0018, 0.0130, 0.0019, 0.0018, 0.0034, 0.0027, 0.0045, 0.0011,
        0.0057], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,379][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.5882, 0.0588, 0.0467, 0.0369, 0.0182, 0.0185, 0.0510, 0.0155, 0.0169,
        0.0086, 0.0103, 0.0414, 0.0167, 0.0095, 0.0164, 0.0083, 0.0165, 0.0070,
        0.0146], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,380][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.2351, 0.1769, 0.1793, 0.2312, 0.0204, 0.0204, 0.0230, 0.0081, 0.0139,
        0.0095, 0.0053, 0.0266, 0.0046, 0.0055, 0.0081, 0.0044, 0.0132, 0.0045,
        0.0101], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,381][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([1.6811e-05, 7.3065e-01, 2.6137e-01, 3.1791e-03, 3.9433e-03, 4.2478e-04,
        2.8650e-04, 1.7584e-05, 5.0298e-05, 2.3855e-05, 5.7623e-06, 4.9059e-06,
        2.2812e-06, 4.6190e-06, 5.3614e-06, 2.9780e-06, 1.1581e-05, 9.6210e-07,
        1.6026e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,382][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([3.9847e-06, 8.6273e-01, 1.3364e-01, 1.4667e-03, 1.0949e-03, 6.6101e-04,
        2.3322e-04, 1.4087e-05, 4.1328e-05, 5.9174e-05, 5.1388e-06, 1.0366e-05,
        9.2505e-06, 3.1358e-06, 4.5522e-06, 9.4601e-06, 8.7550e-06, 2.4551e-06,
        3.4881e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,385][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([2.2887e-04, 3.0102e-01, 1.8445e-01, 1.9755e-02, 3.4990e-02, 1.6157e-02,
        2.9562e-02, 2.1223e-02, 4.5549e-02, 3.6487e-02, 2.3809e-02, 8.3524e-02,
        2.2260e-02, 2.5572e-02, 2.4017e-02, 4.9168e-02, 2.9500e-02, 2.2278e-02,
        3.0451e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,392][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.2378, 0.0192, 0.0310, 0.0361, 0.0165, 0.0279, 0.0631, 0.0350, 0.0405,
        0.0477, 0.0508, 0.0597, 0.0579, 0.0393, 0.0427, 0.0322, 0.0706, 0.0417,
        0.0504], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,395][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.6370e-05, 8.1073e-01, 1.8734e-01, 7.5776e-04, 6.1952e-04, 2.7433e-04,
        1.6179e-04, 8.7164e-06, 1.4163e-05, 1.7191e-05, 1.4904e-06, 8.9777e-07,
        8.1344e-07, 1.2507e-06, 1.1663e-06, 2.4092e-06, 2.9316e-06, 3.8288e-07,
        5.0152e-07, 5.1009e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,396][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2866, 0.0736, 0.1482, 0.0376, 0.0514, 0.0204, 0.0280, 0.0266, 0.0220,
        0.0155, 0.0059, 0.0411, 0.0154, 0.0944, 0.0182, 0.0189, 0.0410, 0.0136,
        0.0250, 0.0164], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,397][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([6.0063e-05, 9.8353e-02, 2.3226e-02, 5.1670e-02, 3.2768e-02, 3.6481e-02,
        2.2831e-02, 5.0359e-02, 1.4942e-02, 1.4149e-01, 6.6925e-02, 3.2470e-02,
        4.2486e-02, 3.0463e-02, 2.1699e-02, 1.1162e-01, 4.8773e-02, 7.1459e-02,
        2.2068e-02, 7.9849e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,398][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.6376e-04, 7.8545e-01, 2.0616e-01, 3.6290e-03, 1.5586e-03, 1.3002e-03,
        1.0764e-03, 6.7428e-05, 1.7779e-04, 1.5320e-04, 1.5498e-05, 1.9866e-05,
        2.0788e-05, 1.5603e-05, 3.5162e-05, 5.3591e-05, 4.9917e-05, 1.1025e-05,
        1.6515e-05, 1.7846e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,399][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.3276e-04, 8.7187e-01, 1.1620e-01, 5.6266e-03, 1.8812e-03, 2.3126e-03,
        7.1369e-04, 1.5740e-04, 1.8398e-04, 2.2669e-04, 3.3278e-05, 2.7286e-05,
        2.4719e-05, 1.0361e-05, 2.5192e-05, 5.6983e-05, 6.8060e-05, 1.8812e-05,
        8.8380e-06, 2.3205e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,403][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.5940e-01, 5.3695e-02, 1.1699e-01, 1.3202e-02, 8.0485e-03, 5.3622e-03,
        1.2852e-02, 1.6873e-03, 3.9742e-03, 2.3843e-03, 8.9080e-04, 5.0069e-03,
        9.4201e-04, 2.0253e-03, 2.8771e-03, 1.7589e-03, 2.7423e-03, 6.3783e-04,
        3.8617e-03, 1.6585e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,408][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5849, 0.0624, 0.0542, 0.0464, 0.0162, 0.0220, 0.0422, 0.0154, 0.0156,
        0.0096, 0.0107, 0.0267, 0.0176, 0.0077, 0.0174, 0.0096, 0.0132, 0.0077,
        0.0124, 0.0081], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,409][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.2144, 0.2449, 0.1508, 0.1843, 0.0238, 0.0131, 0.0253, 0.0080, 0.0141,
        0.0123, 0.0048, 0.0512, 0.0058, 0.0063, 0.0054, 0.0046, 0.0118, 0.0045,
        0.0100, 0.0046], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,409][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.6515e-05, 6.6350e-01, 3.2853e-01, 2.4970e-03, 4.4477e-03, 4.1365e-04,
        4.0108e-04, 2.2344e-05, 6.3151e-05, 2.7830e-05, 7.9971e-06, 5.5333e-06,
        3.8268e-06, 1.6820e-05, 1.0033e-05, 5.1019e-06, 1.6202e-05, 1.9922e-06,
        3.1022e-06, 1.3864e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,410][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6814e-05, 8.9032e-01, 1.0586e-01, 1.2817e-03, 1.0869e-03, 6.9541e-04,
        4.1094e-04, 3.3605e-05, 7.3465e-05, 9.8721e-05, 1.2870e-05, 1.4359e-05,
        1.5329e-05, 1.1608e-05, 8.1488e-06, 2.1631e-05, 1.2884e-05, 7.1524e-06,
        6.9966e-06, 7.8517e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,412][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.1955e-06, 6.5634e-01, 1.4210e-01, 1.4419e-02, 2.8066e-02, 2.1767e-02,
        1.5437e-02, 7.3257e-03, 1.5233e-02, 9.8105e-03, 7.3418e-03, 2.2725e-02,
        9.9928e-03, 6.4052e-03, 6.5437e-03, 1.0328e-02, 1.2292e-02, 5.5700e-03,
        3.7603e-03, 4.5350e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,419][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.5375, 0.0168, 0.0154, 0.0245, 0.0113, 0.0232, 0.0393, 0.0263, 0.0283,
        0.0217, 0.0299, 0.0401, 0.0261, 0.0265, 0.0250, 0.0150, 0.0350, 0.0197,
        0.0228, 0.0156], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,422][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:55,424][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2074],
        [  22],
        [ 526],
        [  25],
        [ 135],
        [ 114],
        [   5],
        [   5],
        [ 238],
        [   2],
        [  56],
        [ 130],
        [   9],
        [  23],
        [  32],
        [   2],
        [  44],
        [ 122],
        [  20],
        [   5]], device='cuda:0')
[2024-07-24 10:16:55,426][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2384],
        [ 378],
        [5216],
        [ 355],
        [ 367],
        [ 223],
        [  53],
        [ 208],
        [ 612],
        [ 272],
        [  58],
        [ 220],
        [ 147],
        [  81],
        [ 610],
        [  93],
        [ 280],
        [ 251],
        [  88],
        [ 140]], device='cuda:0')
[2024-07-24 10:16:55,429][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[43510],
        [30705],
        [30482],
        [30571],
        [30500],
        [30586],
        [30555],
        [30586],
        [30664],
        [30729],
        [30576],
        [30562],
        [30627],
        [30915],
        [30922],
        [30814],
        [30652],
        [30659],
        [30721],
        [30849]], device='cuda:0')
[2024-07-24 10:16:55,433][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35087],
        [ 2655],
        [ 5871],
        [ 2650],
        [ 1424],
        [ 1934],
        [ 1744],
        [ 1591],
        [ 1481],
        [ 1388],
        [ 1478],
        [ 1116],
        [ 1130],
        [ 1040],
        [  967],
        [  986],
        [  945],
        [ 1036],
        [  960],
        [  890]], device='cuda:0')
[2024-07-24 10:16:55,436][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11041],
        [11597],
        [45509],
        [28467],
        [31886],
        [30741],
        [29688],
        [35439],
        [24377],
        [17296],
        [15010],
        [17245],
        [13966],
        [12991],
        [13158],
        [15159],
        [14384],
        [14480],
        [13612],
        [16179]], device='cuda:0')
[2024-07-24 10:16:55,437][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 9428],
        [11240],
        [  154],
        [  672],
        [  962],
        [  128],
        [11439],
        [  953],
        [ 1434],
        [  296],
        [ 1978],
        [ 3539],
        [  134],
        [ 2653],
        [ 2766],
        [  149],
        [ 1036],
        [ 1064],
        [ 1598],
        [   68]], device='cuda:0')
[2024-07-24 10:16:55,439][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31541],
        [11387],
        [11447],
        [11536],
        [11476],
        [11565],
        [11645],
        [11930],
        [11595],
        [11843],
        [11676],
        [11540],
        [11625],
        [11951],
        [11826],
        [11937],
        [11841],
        [11838],
        [11977],
        [11933]], device='cuda:0')
[2024-07-24 10:16:55,441][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16789],
        [17318],
        [24486],
        [20004],
        [31584],
        [21304],
        [31772],
        [30524],
        [23260],
        [18919],
        [29765],
        [46702],
        [45047],
        [42689],
        [43093],
        [27188],
        [44280],
        [39619],
        [45081],
        [43722]], device='cuda:0')
[2024-07-24 10:16:55,445][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[612],
        [486],
        [384],
        [424],
        [401],
        [420],
        [397],
        [385],
        [388],
        [388],
        [408],
        [410],
        [414],
        [406],
        [412],
        [407],
        [406],
        [419],
        [434],
        [435]], device='cuda:0')
[2024-07-24 10:16:55,448][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[36743],
        [11493],
        [28533],
        [28965],
        [31360],
        [30665],
        [27766],
        [25724],
        [22931],
        [21589],
        [22602],
        [20637],
        [20395],
        [21581],
        [21257],
        [21390],
        [20996],
        [22013],
        [23286],
        [21985]], device='cuda:0')
[2024-07-24 10:16:55,451][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[10970],
        [11775],
        [12218],
        [12829],
        [12369],
        [14127],
        [14074],
        [14144],
        [13769],
        [14609],
        [13692],
        [13664],
        [14041],
        [13934],
        [14333],
        [16730],
        [16391],
        [15621],
        [16364],
        [17848]], device='cuda:0')
[2024-07-24 10:16:55,453][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[10770],
        [32286],
        [32069],
        [29511],
        [32025],
        [30520],
        [29424],
        [30332],
        [30343],
        [29649],
        [30759],
        [30309],
        [29841],
        [30858],
        [30054],
        [29432],
        [29936],
        [30056],
        [29121],
        [29846]], device='cuda:0')
[2024-07-24 10:16:55,454][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[33871],
        [44485],
        [49984],
        [49679],
        [50230],
        [49445],
        [50086],
        [50142],
        [49724],
        [49756],
        [49285],
        [49496],
        [49674],
        [49671],
        [49055],
        [49475],
        [49199],
        [48608],
        [50086],
        [49549]], device='cuda:0')
[2024-07-24 10:16:55,456][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24378],
        [15125],
        [26619],
        [36989],
        [36357],
        [44413],
        [20012],
        [17883],
        [15691],
        [17055],
        [11157],
        [15149],
        [17529],
        [17985],
        [19367],
        [22035],
        [13884],
        [12156],
        [19313],
        [18381]], device='cuda:0')
[2024-07-24 10:16:55,460][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7755],
        [ 5033],
        [ 4729],
        [ 2888],
        [ 6896],
        [10521],
        [ 2252],
        [ 1495],
        [16578],
        [ 4618],
        [11639],
        [18133],
        [ 3625],
        [ 8791],
        [ 5087],
        [ 5786],
        [16174],
        [15142],
        [ 9091],
        [ 8998]], device='cuda:0')
[2024-07-24 10:16:55,463][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 1565],
        [17600],
        [17664],
        [17712],
        [17681],
        [17736],
        [17718],
        [17784],
        [17782],
        [17750],
        [17736],
        [17732],
        [17761],
        [17701],
        [17720],
        [17839],
        [17787],
        [17760],
        [17605],
        [17702]], device='cuda:0')
[2024-07-24 10:16:55,466][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15282],
        [14909],
        [13733],
        [ 5021],
        [ 6990],
        [ 4640],
        [ 3374],
        [ 3893],
        [ 5503],
        [ 4169],
        [ 6306],
        [ 7241],
        [ 9190],
        [ 9306],
        [10765],
        [ 9673],
        [10336],
        [ 9836],
        [ 9821],
        [ 9645]], device='cuda:0')
[2024-07-24 10:16:55,468][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[24063],
        [27365],
        [25023],
        [24520],
        [14898],
        [17900],
        [14916],
        [19660],
        [18746],
        [18147],
        [19347],
        [22174],
        [20465],
        [20085],
        [19656],
        [17187],
        [17901],
        [18856],
        [18636],
        [17718]], device='cuda:0')
[2024-07-24 10:16:55,469][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4744],
        [7039],
        [7406],
        [7631],
        [7457],
        [8252],
        [7969],
        [8798],
        [8155],
        [8609],
        [8050],
        [8616],
        [8363],
        [8860],
        [8290],
        [9282],
        [9602],
        [9329],
        [9967],
        [9454]], device='cuda:0')
[2024-07-24 10:16:55,472][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[8749],
        [5281],
        [5316],
        [5333],
        [5318],
        [5324],
        [5368],
        [5352],
        [5306],
        [5134],
        [5340],
        [5347],
        [5376],
        [5476],
        [5399],
        [5302],
        [5373],
        [5429],
        [5478],
        [5451]], device='cuda:0')
[2024-07-24 10:16:55,475][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28069],
        [27195],
        [19217],
        [25026],
        [12328],
        [23781],
        [11637],
        [15757],
        [19949],
        [25351],
        [14132],
        [ 3072],
        [ 3363],
        [ 5624],
        [ 4674],
        [17296],
        [ 8281],
        [ 8127],
        [ 3852],
        [ 6712]], device='cuda:0')
[2024-07-24 10:16:55,478][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 3115],
        [ 3118],
        [ 3202],
        [ 3030],
        [ 3540],
        [ 3745],
        [ 5898],
        [ 4837],
        [ 9328],
        [ 5897],
        [ 7984],
        [12213],
        [13608],
        [11799],
        [13394],
        [11919],
        [14328],
        [13982],
        [14828],
        [14251]], device='cuda:0')
[2024-07-24 10:16:55,481][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21968],
        [28059],
        [26250],
        [ 9695],
        [12389],
        [10247],
        [11783],
        [10453],
        [10973],
        [11850],
        [10244],
        [ 9320],
        [ 9366],
        [11203],
        [11045],
        [10487],
        [12574],
        [10481],
        [ 9829],
        [ 9908]], device='cuda:0')
[2024-07-24 10:16:55,483][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[29432],
        [11714],
        [11318],
        [11047],
        [11203],
        [10470],
        [10540],
        [10453],
        [10582],
        [10125],
        [10698],
        [10756],
        [10579],
        [10585],
        [10399],
        [ 9471],
        [ 9669],
        [10022],
        [ 9716],
        [ 9197]], device='cuda:0')
[2024-07-24 10:16:55,485][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[42669],
        [ 6923],
        [ 6943],
        [ 7213],
        [ 6944],
        [ 7071],
        [ 7230],
        [ 7085],
        [ 7097],
        [ 7130],
        [ 7050],
        [ 7106],
        [ 7177],
        [ 7036],
        [ 7136],
        [ 7195],
        [ 7143],
        [ 7133],
        [ 7272],
        [ 7168]], device='cuda:0')
[2024-07-24 10:16:55,487][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[25898],
        [10761],
        [14829],
        [12791],
        [13831],
        [12402],
        [13447],
        [14529],
        [12522],
        [13178],
        [12518],
        [12936],
        [13452],
        [14174],
        [12811],
        [13121],
        [12635],
        [12147],
        [17955],
        [13473]], device='cuda:0')
[2024-07-24 10:16:55,490][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[6296],
        [6282],
        [6256],
        [5372],
        [5723],
        [3054],
        [3096],
        [3620],
        [3702],
        [4509],
        [3915],
        [3344],
        [4240],
        [4513],
        [3534],
        [4710],
        [4230],
        [3728],
        [3472],
        [3912]], device='cuda:0')
[2024-07-24 10:16:55,494][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[22482],
        [34903],
        [35627],
        [39964],
        [39688],
        [40186],
        [41158],
        [40168],
        [38951],
        [38962],
        [39446],
        [41025],
        [40837],
        [39472],
        [39142],
        [37250],
        [37477],
        [39107],
        [39165],
        [39771]], device='cuda:0')
[2024-07-24 10:16:55,497][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33589],
        [25388],
        [ 8550],
        [41996],
        [42691],
        [42821],
        [46268],
        [46751],
        [40745],
        [41962],
        [44772],
        [44049],
        [41610],
        [40632],
        [44909],
        [40862],
        [40795],
        [43129],
        [41771],
        [39521]], device='cuda:0')
[2024-07-24 10:16:55,498][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529],
        [4529]], device='cuda:0')
[2024-07-24 10:16:55,585][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:55,587][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,588][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,589][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,589][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,590][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,590][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,592][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,592][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,593][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,594][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,594][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,595][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:55,596][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9980e-01, 2.0277e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,598][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1827, 0.8173], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,603][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9791, 0.0209], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,605][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3138, 0.6862], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,606][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([2.0142e-04, 9.9980e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,607][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1109, 0.8891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,607][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9967, 0.0033], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,608][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([7.8744e-04, 9.9921e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,609][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0294, 0.9706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,612][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9065, 0.0935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,616][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0090, 0.9910], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,619][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2416, 0.7584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:55,619][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([9.9876e-01, 9.1399e-04, 3.2382e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,620][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1621, 0.6649, 0.1729], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,621][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.9318, 0.0509, 0.0173], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,621][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0703, 0.7431, 0.1866], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,622][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([1.7144e-06, 9.9731e-01, 2.6860e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,624][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([3.7970e-04, 9.8998e-01, 9.6421e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,629][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.9873, 0.0061, 0.0066], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,632][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([2.9803e-07, 9.9953e-01, 4.7184e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,633][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0157, 0.9384, 0.0459], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,633][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.5494, 0.2743, 0.1764], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,634][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0017, 0.9598, 0.0385], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,635][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.1412, 0.4683, 0.3906], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:55,635][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.1943e-01, 1.1829e-03, 8.6633e-04, 7.8526e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,638][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0007, 0.5234, 0.3822, 0.0936], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,643][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8168, 0.0862, 0.0623, 0.0346], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,645][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0991, 0.3836, 0.3323, 0.1849], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,646][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([1.7780e-05, 9.8535e-01, 1.0607e-02, 4.0206e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,647][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0186, 0.9008, 0.0561, 0.0245], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,648][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5069, 0.1792, 0.2812, 0.0328], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,648][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.7905e-04, 9.8980e-01, 4.0211e-03, 5.9964e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,650][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0530, 0.7616, 0.1051, 0.0803], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,654][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4229, 0.2403, 0.2626, 0.0742], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,659][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0019, 0.8747, 0.0477, 0.0756], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,659][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1084, 0.3195, 0.2772, 0.2949], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:55,660][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.9016, 0.0022, 0.0013, 0.0916, 0.0034], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,661][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0184, 0.5766, 0.2284, 0.1363, 0.0402], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,662][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.7976, 0.0969, 0.0375, 0.0292, 0.0388], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,664][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0274, 0.4588, 0.3400, 0.1100, 0.0638], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,666][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ James] are: tensor([7.9341e-08, 9.9230e-01, 6.9503e-03, 7.2382e-04, 2.5545e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,669][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ James] are: tensor([6.6032e-05, 9.7977e-01, 1.3741e-02, 6.2182e-03, 2.0245e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,672][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.9600, 0.0112, 0.0132, 0.0124, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,673][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ James] are: tensor([2.8936e-08, 9.9785e-01, 1.8213e-03, 3.3077e-04, 2.7051e-06],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,674][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0095, 0.8925, 0.0738, 0.0209, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,674][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.2038, 0.3744, 0.3110, 0.0965, 0.0144], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,675][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ James] are: tensor([5.1002e-04, 9.2572e-01, 4.5862e-02, 2.4905e-02, 3.0041e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,677][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0757, 0.2660, 0.2325, 0.2340, 0.1917], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:55,681][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.7766, 0.0028, 0.0013, 0.2115, 0.0069, 0.0009], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,685][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0043, 0.4889, 0.3953, 0.0652, 0.0429, 0.0034], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,686][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.5090, 0.1353, 0.1182, 0.0591, 0.1533, 0.0251], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,687][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0166, 0.4094, 0.3546, 0.1096, 0.0879, 0.0220], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,688][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ were] are: tensor([6.8823e-06, 9.7690e-01, 1.8462e-02, 4.3908e-03, 1.3194e-04, 1.0622e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,688][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0017, 0.9032, 0.0587, 0.0296, 0.0038, 0.0031], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,691][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.8224, 0.0731, 0.0502, 0.0236, 0.0174, 0.0134], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,693][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ were] are: tensor([6.4450e-06, 9.9016e-01, 7.7035e-03, 2.0606e-03, 4.6389e-05, 2.6881e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,699][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0129, 0.8271, 0.0995, 0.0462, 0.0056, 0.0087], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,699][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2403, 0.3097, 0.3097, 0.0959, 0.0174, 0.0270], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,700][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0012, 0.8706, 0.0657, 0.0514, 0.0056, 0.0054], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,701][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0601, 0.2197, 0.1958, 0.2062, 0.1689, 0.1495], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:55,702][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.8238, 0.0042, 0.0015, 0.1254, 0.0072, 0.0011, 0.0369],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,704][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0068, 0.7343, 0.1663, 0.0375, 0.0272, 0.0193, 0.0085],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,709][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.3114, 0.2235, 0.1024, 0.0781, 0.1247, 0.0675, 0.0923],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,712][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0112, 0.2450, 0.5484, 0.0363, 0.1076, 0.0213, 0.0302],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,713][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([6.2956e-07, 9.7400e-01, 2.2290e-02, 3.3105e-03, 2.0346e-04, 1.6185e-04,
        3.1740e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,714][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([2.2186e-04, 9.2857e-01, 5.3412e-02, 1.2354e-02, 2.3491e-03, 2.3562e-03,
        7.3932e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,714][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.5764, 0.0955, 0.0727, 0.0506, 0.0161, 0.0339, 0.1548],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,715][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([4.2795e-07, 9.8908e-01, 9.1502e-03, 1.6867e-03, 4.3364e-05, 3.0124e-05,
        4.4903e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,718][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.0025, 0.8743, 0.0921, 0.0171, 0.0027, 0.0055, 0.0057],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,722][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.2727, 0.2848, 0.3255, 0.0672, 0.0132, 0.0195, 0.0170],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,726][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0009, 0.8540, 0.1001, 0.0289, 0.0063, 0.0057, 0.0041],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,726][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0538, 0.1992, 0.1807, 0.1809, 0.1533, 0.1312, 0.1009],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:55,727][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ about] are: tensor([6.7876e-01, 1.2095e-03, 1.2551e-03, 4.7566e-02, 3.1528e-03, 6.4005e-04,
        3.2269e-02, 2.3515e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,728][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0016, 0.6212, 0.2646, 0.0541, 0.0407, 0.0080, 0.0087, 0.0011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,729][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.7430, 0.0549, 0.0394, 0.0288, 0.0511, 0.0172, 0.0496, 0.0160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,731][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0229, 0.3173, 0.4189, 0.0836, 0.0856, 0.0212, 0.0376, 0.0129],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,733][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ about] are: tensor([8.8069e-05, 9.3610e-01, 5.0506e-02, 1.0984e-02, 8.8143e-04, 7.2795e-04,
        5.4787e-04, 1.6632e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,739][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0345, 0.7019, 0.1555, 0.0524, 0.0145, 0.0206, 0.0148, 0.0059],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,740][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.7379, 0.0437, 0.0594, 0.0201, 0.0102, 0.0148, 0.0984, 0.0154],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,740][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ about] are: tensor([8.8361e-05, 9.7158e-01, 1.8618e-02, 8.8065e-03, 4.0075e-04, 3.1674e-04,
        1.3710e-04, 5.3327e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,741][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0245, 0.6562, 0.2378, 0.0310, 0.0106, 0.0139, 0.0229, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,742][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.3864, 0.1793, 0.2953, 0.0603, 0.0164, 0.0250, 0.0184, 0.0189],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,745][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0054, 0.8070, 0.1060, 0.0503, 0.0089, 0.0091, 0.0106, 0.0027],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,749][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0491, 0.1772, 0.1607, 0.1676, 0.1397, 0.1206, 0.0934, 0.0917],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:55,752][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.5330, 0.0021, 0.0015, 0.0738, 0.0043, 0.0009, 0.0370, 0.2983, 0.0491],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,753][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0064, 0.6758, 0.2115, 0.0497, 0.0198, 0.0154, 0.0109, 0.0020, 0.0086],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,754][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.4277, 0.1366, 0.0582, 0.0449, 0.0715, 0.0566, 0.1127, 0.0424, 0.0494],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,755][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0356, 0.2650, 0.5098, 0.0468, 0.0642, 0.0145, 0.0320, 0.0113, 0.0206],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,755][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ going] are: tensor([1.5652e-05, 9.1608e-01, 7.1446e-02, 9.7320e-03, 1.4632e-03, 8.7024e-04,
        2.8755e-04, 5.9178e-05, 4.6803e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,757][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ going] are: tensor([5.5875e-03, 8.4077e-01, 1.0705e-01, 2.4437e-02, 9.8123e-03, 6.4228e-03,
        3.2330e-03, 1.8493e-03, 8.3859e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,761][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.5326, 0.1396, 0.0705, 0.0294, 0.0097, 0.0207, 0.1339, 0.0399, 0.0236],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,764][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ going] are: tensor([5.4446e-05, 9.7109e-01, 1.9440e-02, 8.8217e-03, 3.1232e-04, 1.8048e-04,
        7.2340e-05, 1.3641e-05, 9.9687e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,766][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.0201, 0.7653, 0.1382, 0.0297, 0.0077, 0.0125, 0.0205, 0.0029, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,767][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.3265, 0.2311, 0.2664, 0.0771, 0.0128, 0.0306, 0.0209, 0.0180, 0.0166],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,767][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0030, 0.8449, 0.0847, 0.0411, 0.0057, 0.0075, 0.0080, 0.0019, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,768][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0457, 0.1620, 0.1460, 0.1511, 0.1259, 0.1096, 0.0853, 0.0831, 0.0914],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:55,769][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.1051e-01, 6.7282e-04, 6.0041e-04, 4.1483e-02, 2.4045e-03, 3.4834e-04,
        2.5690e-02, 1.6441e-01, 2.6622e-02, 1.2725e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,773][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0011, 0.5621, 0.3659, 0.0314, 0.0197, 0.0049, 0.0069, 0.0009, 0.0063,
        0.0008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,778][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.7375, 0.0837, 0.0402, 0.0148, 0.0390, 0.0133, 0.0380, 0.0101, 0.0189,
        0.0044], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,780][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0330, 0.3551, 0.3426, 0.0711, 0.0634, 0.0195, 0.0482, 0.0161, 0.0296,
        0.0213], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,780][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.4537e-03, 9.2894e-01, 3.8956e-02, 2.1393e-02, 1.4513e-03, 2.4656e-03,
        2.1759e-03, 9.7147e-04, 5.3527e-04, 1.6572e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,781][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.3517, 0.3766, 0.0893, 0.0697, 0.0188, 0.0334, 0.0245, 0.0185, 0.0097,
        0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,782][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7946, 0.0394, 0.0330, 0.0071, 0.0059, 0.0065, 0.0835, 0.0099, 0.0116,
        0.0086], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,783][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.2748e-02, 9.0961e-01, 2.1554e-02, 3.6619e-02, 1.6044e-03, 2.1369e-03,
        2.0854e-03, 9.0008e-04, 6.6465e-04, 2.0771e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,786][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0613, 0.6126, 0.1532, 0.0502, 0.0104, 0.0227, 0.0533, 0.0088, 0.0198,
        0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,791][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.5596, 0.1373, 0.1800, 0.0382, 0.0084, 0.0165, 0.0139, 0.0150, 0.0152,
        0.0160], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,793][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0181, 0.7616, 0.0995, 0.0653, 0.0084, 0.0128, 0.0170, 0.0041, 0.0061,
        0.0072], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,794][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0446, 0.1435, 0.1289, 0.1358, 0.1121, 0.0969, 0.0760, 0.0744, 0.0810,
        0.1066], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:55,795][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([4.1658e-02, 1.9818e-04, 1.3852e-04, 7.5233e-03, 3.6628e-04, 7.2275e-05,
        3.8644e-03, 2.6414e-02, 3.7857e-03, 1.8914e-02, 8.9706e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,796][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.4380e-04, 7.1845e-01, 2.1535e-01, 3.9329e-02, 1.3532e-02, 3.3229e-03,
        4.4665e-03, 6.9662e-04, 3.2052e-03, 5.5672e-04, 1.4912e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,796][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3551, 0.2220, 0.0837, 0.0453, 0.0891, 0.0428, 0.0786, 0.0223, 0.0427,
        0.0114, 0.0070], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,800][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0047, 0.4898, 0.3749, 0.0374, 0.0429, 0.0094, 0.0132, 0.0052, 0.0096,
        0.0088, 0.0040], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,804][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.2343e-06, 9.6590e-01, 3.2096e-02, 1.6040e-03, 1.8223e-04, 1.0945e-04,
        4.4265e-05, 1.7117e-05, 1.1572e-05, 3.5991e-05, 2.5535e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,807][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.7207e-03, 8.5249e-01, 1.1591e-01, 1.3237e-02, 4.8630e-03, 7.3833e-03,
        2.6098e-03, 7.9823e-04, 4.4188e-04, 4.9304e-04, 5.4754e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,810][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.7752, 0.0575, 0.0520, 0.0174, 0.0088, 0.0108, 0.0493, 0.0086, 0.0107,
        0.0069, 0.0029], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,810][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([2.1743e-06, 9.8978e-01, 8.9807e-03, 1.1010e-03, 6.2699e-05, 4.0379e-05,
        1.6484e-05, 2.9636e-06, 3.7222e-06, 7.1391e-06, 1.8013e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,811][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([3.3635e-03, 8.3809e-01, 1.2486e-01, 1.4587e-02, 3.3449e-03, 4.9105e-03,
        7.7993e-03, 7.3917e-04, 1.4944e-03, 7.4121e-04, 6.9214e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,812][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3027, 0.2600, 0.2825, 0.0516, 0.0117, 0.0219, 0.0156, 0.0143, 0.0166,
        0.0176, 0.0055], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,813][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.2511e-03, 8.8053e-01, 8.2034e-02, 2.0299e-02, 3.4307e-03, 3.8635e-03,
        4.4473e-03, 7.3531e-04, 1.4790e-03, 1.5812e-03, 3.4877e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,815][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0363, 0.1355, 0.1226, 0.1255, 0.1054, 0.0893, 0.0691, 0.0665, 0.0723,
        0.0961, 0.0813], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:55,818][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ store] are: tensor([4.9066e-02, 6.1441e-04, 3.4695e-04, 1.2574e-02, 9.9153e-04, 9.1315e-05,
        4.8855e-03, 4.0046e-02, 4.9857e-03, 1.9897e-02, 8.6515e-01, 1.3469e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,821][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ store] are: tensor([1.0750e-03, 8.0979e-01, 1.4593e-01, 2.0618e-02, 1.2324e-02, 2.2477e-03,
        2.4377e-03, 3.2158e-04, 2.0515e-03, 6.5169e-04, 2.3938e-04, 2.3059e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,823][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.4433, 0.1731, 0.0746, 0.0458, 0.0829, 0.0510, 0.0496, 0.0180, 0.0252,
        0.0099, 0.0070, 0.0196], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,824][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0151, 0.2656, 0.5355, 0.0333, 0.0688, 0.0160, 0.0267, 0.0087, 0.0104,
        0.0084, 0.0037, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,825][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ store] are: tensor([1.0285e-07, 9.7486e-01, 2.4145e-02, 8.3974e-04, 9.8193e-05, 3.2204e-05,
        1.1430e-05, 2.8656e-06, 7.8289e-07, 8.4775e-06, 6.5595e-07, 9.3082e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,826][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ store] are: tensor([7.5098e-06, 9.3443e-01, 5.9330e-02, 3.7384e-03, 1.3508e-03, 6.4314e-04,
        2.9921e-04, 6.6212e-05, 5.7112e-05, 6.4429e-05, 6.1611e-06, 3.2996e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,827][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.4133, 0.1561, 0.1291, 0.0420, 0.0172, 0.0226, 0.0888, 0.0199, 0.0243,
        0.0282, 0.0124, 0.0461], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,829][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ store] are: tensor([1.3919e-08, 9.8932e-01, 1.0009e-02, 6.1887e-04, 3.8090e-05, 1.0041e-05,
        2.1471e-06, 2.7338e-07, 4.7980e-07, 1.3134e-06, 3.9010e-08, 3.0856e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,831][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ store] are: tensor([1.1945e-03, 8.2254e-01, 1.5806e-01, 7.5891e-03, 2.5829e-03, 2.3208e-03,
        3.6557e-03, 4.4574e-04, 7.2339e-04, 5.9244e-04, 8.1061e-05, 2.0642e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,836][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.3160, 0.2893, 0.2875, 0.0396, 0.0064, 0.0135, 0.0099, 0.0083, 0.0081,
        0.0101, 0.0029, 0.0084], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,837][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ store] are: tensor([3.1858e-04, 8.0531e-01, 1.6087e-01, 1.9237e-02, 5.2279e-03, 3.1959e-03,
        3.4003e-03, 4.5299e-04, 7.5008e-04, 6.2961e-04, 1.0341e-04, 4.9649e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,838][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0357, 0.1282, 0.1172, 0.1146, 0.0980, 0.0844, 0.0661, 0.0635, 0.0697,
        0.0899, 0.0767, 0.0561], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:55,839][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.2103e-01, 2.1002e-04, 2.0636e-04, 6.2660e-03, 4.3809e-04, 7.7114e-05,
        3.9243e-03, 2.6206e-02, 3.3503e-03, 1.4916e-02, 8.2129e-01, 4.8515e-04,
        1.6019e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,840][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([3.4606e-04, 6.6343e-01, 2.8133e-01, 2.9672e-02, 1.4399e-02, 2.6372e-03,
        3.0517e-03, 4.5518e-04, 2.5067e-03, 3.2261e-04, 1.5575e-04, 1.3666e-03,
        3.3439e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,841][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.5834, 0.1451, 0.0517, 0.0267, 0.0446, 0.0332, 0.0457, 0.0152, 0.0171,
        0.0064, 0.0061, 0.0161, 0.0088], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,844][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0057, 0.3621, 0.4794, 0.0341, 0.0610, 0.0086, 0.0175, 0.0042, 0.0091,
        0.0057, 0.0025, 0.0065, 0.0035], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,846][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([6.0396e-07, 9.7542e-01, 2.3621e-02, 7.6203e-04, 7.6470e-05, 6.8865e-05,
        1.5077e-05, 8.1818e-06, 2.4602e-06, 1.9198e-05, 9.9226e-07, 4.9624e-07,
        1.0463e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,849][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([8.0974e-04, 8.8041e-01, 1.0093e-01, 6.7182e-03, 3.0135e-03, 4.6809e-03,
        2.0733e-03, 6.3341e-04, 3.3021e-04, 3.3336e-04, 3.0457e-05, 1.5125e-05,
        2.6297e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,851][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.3774, 0.1899, 0.0958, 0.0216, 0.0140, 0.0212, 0.1573, 0.0207, 0.0247,
        0.0199, 0.0100, 0.0347, 0.0129], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,852][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([5.6939e-06, 9.8853e-01, 1.0478e-02, 8.7614e-04, 4.8543e-05, 3.7249e-05,
        1.6818e-05, 2.8924e-06, 2.1937e-06, 7.0648e-06, 1.5601e-07, 2.0764e-08,
        1.7738e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,853][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([3.3601e-03, 7.9367e-01, 1.6875e-01, 1.4256e-02, 5.0342e-03, 4.9564e-03,
        6.1577e-03, 1.0193e-03, 1.2523e-03, 9.1966e-04, 9.3271e-05, 3.4469e-04,
        1.8427e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,854][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0927, 0.3345, 0.4094, 0.0502, 0.0143, 0.0226, 0.0158, 0.0122, 0.0149,
        0.0158, 0.0051, 0.0084, 0.0041], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,855][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.1495e-03, 8.3954e-01, 1.2666e-01, 1.7400e-02, 4.4193e-03, 3.0798e-03,
        3.7602e-03, 4.8878e-04, 1.0711e-03, 1.0189e-03, 1.8065e-04, 6.4531e-04,
        5.8396e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,858][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0341, 0.1178, 0.1070, 0.1090, 0.0905, 0.0771, 0.0605, 0.0589, 0.0645,
        0.0840, 0.0717, 0.0527, 0.0723], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:55,860][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ James] are: tensor([1.1413e-01, 3.8086e-04, 3.0632e-04, 8.8247e-03, 5.2159e-04, 1.1448e-04,
        5.5582e-03, 3.3589e-02, 3.2017e-03, 1.7769e-02, 8.1173e-01, 9.9844e-04,
        2.5614e-03, 3.1590e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,863][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ James] are: tensor([1.9770e-03, 7.5784e-01, 1.5652e-01, 3.9191e-02, 1.4520e-02, 5.4936e-03,
        6.8384e-03, 1.1210e-03, 4.4026e-03, 1.3747e-03, 6.2104e-04, 7.5755e-03,
        1.4009e-03, 1.1228e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,865][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.4107, 0.2141, 0.0870, 0.0280, 0.0836, 0.0298, 0.0522, 0.0147, 0.0157,
        0.0058, 0.0061, 0.0294, 0.0080, 0.0148], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,866][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0244, 0.3326, 0.3762, 0.0544, 0.0650, 0.0179, 0.0494, 0.0143, 0.0222,
        0.0097, 0.0057, 0.0124, 0.0061, 0.0096], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,867][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ James] are: tensor([2.1246e-06, 9.1545e-01, 8.1893e-02, 1.8432e-03, 4.9972e-04, 1.7843e-04,
        5.3760e-05, 2.0652e-05, 8.0108e-06, 4.2451e-05, 4.4062e-06, 2.5419e-06,
        2.0289e-06, 1.6254e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,868][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ James] are: tensor([1.0526e-03, 7.9861e-01, 1.7561e-01, 1.0474e-02, 5.6219e-03, 4.7857e-03,
        2.3533e-03, 5.8448e-04, 3.7834e-04, 3.3920e-04, 5.0856e-05, 4.3195e-05,
        3.6446e-05, 5.5603e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,869][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.8032, 0.0374, 0.0227, 0.0112, 0.0045, 0.0043, 0.0606, 0.0164, 0.0047,
        0.0069, 0.0045, 0.0154, 0.0061, 0.0021], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,871][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ James] are: tensor([1.6963e-06, 9.5673e-01, 4.1768e-02, 1.1244e-03, 2.1076e-04, 6.3575e-05,
        7.0475e-05, 7.3341e-06, 1.0499e-05, 1.2411e-05, 6.4825e-07, 2.0359e-07,
        4.3978e-07, 1.7958e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,873][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ James] are: tensor([2.0081e-02, 7.3303e-01, 1.7874e-01, 2.1099e-02, 1.0251e-02, 1.0718e-02,
        1.7468e-02, 2.5904e-03, 2.1708e-03, 1.7275e-03, 3.0661e-04, 8.2431e-04,
        7.1754e-04, 2.8147e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,879][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.2303, 0.1846, 0.3859, 0.0560, 0.0223, 0.0204, 0.0184, 0.0169, 0.0162,
        0.0172, 0.0060, 0.0134, 0.0054, 0.0071], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,880][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ James] are: tensor([3.0931e-03, 8.0720e-01, 1.3301e-01, 2.7993e-02, 7.8403e-03, 4.8248e-03,
        9.3825e-03, 8.5447e-04, 2.0598e-03, 1.0685e-03, 2.8268e-04, 1.2634e-03,
        7.9345e-04, 3.2843e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,881][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0331, 0.1107, 0.1004, 0.1036, 0.0870, 0.0728, 0.0567, 0.0547, 0.0604,
        0.0787, 0.0681, 0.0491, 0.0685, 0.0562], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:55,882][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([2.6219e-02, 3.4439e-04, 1.8830e-04, 1.1362e-02, 5.3342e-04, 1.0615e-04,
        7.0021e-03, 2.4236e-02, 4.1228e-03, 2.1952e-02, 8.9914e-01, 7.8375e-04,
        2.1661e-03, 2.5269e-04, 1.5939e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,882][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([3.6359e-04, 7.5162e-01, 2.1540e-01, 1.6663e-02, 9.0842e-03, 9.3754e-04,
        1.7859e-03, 2.1827e-04, 1.3431e-03, 2.5182e-04, 1.2501e-04, 1.1984e-03,
        2.4734e-04, 4.6257e-04, 3.0086e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,886][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.2522, 0.1944, 0.1108, 0.0502, 0.1467, 0.0381, 0.0564, 0.0250, 0.0219,
        0.0092, 0.0086, 0.0200, 0.0115, 0.0275, 0.0273], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,890][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0032, 0.3284, 0.5236, 0.0170, 0.0608, 0.0061, 0.0159, 0.0033, 0.0079,
        0.0037, 0.0021, 0.0129, 0.0038, 0.0089, 0.0026], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,893][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([8.8611e-06, 9.2910e-01, 6.6238e-02, 3.2079e-03, 6.9328e-04, 3.1453e-04,
        1.8649e-04, 5.4377e-05, 2.7141e-05, 1.2790e-04, 1.5669e-05, 4.4915e-06,
        8.4023e-06, 3.0238e-06, 5.2904e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,894][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([2.0707e-03, 7.6399e-01, 1.9745e-01, 1.7130e-02, 9.0201e-03, 5.8621e-03,
        2.7378e-03, 5.0911e-04, 5.2024e-04, 3.2014e-04, 6.1224e-05, 6.7402e-05,
        5.3463e-05, 1.2366e-04, 8.7434e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,895][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.6236, 0.1098, 0.0624, 0.0209, 0.0216, 0.0101, 0.0793, 0.0138, 0.0080,
        0.0078, 0.0051, 0.0189, 0.0065, 0.0085, 0.0036], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,896][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([2.1203e-05, 9.7083e-01, 2.6133e-02, 2.5256e-03, 2.5765e-04, 9.5308e-05,
        8.6845e-05, 9.4527e-06, 1.2059e-05, 2.2832e-05, 8.5037e-07, 2.9308e-07,
        8.3138e-07, 3.4845e-07, 1.0201e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,896][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([1.9085e-03, 7.8721e-01, 1.7961e-01, 8.0575e-03, 4.1398e-03, 4.8001e-03,
        8.8364e-03, 9.4553e-04, 1.8515e-03, 9.1839e-04, 1.0814e-04, 4.4814e-04,
        2.3553e-04, 9.7839e-05, 8.3361e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,900][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.1090, 0.3168, 0.3471, 0.0519, 0.0148, 0.0270, 0.0238, 0.0182, 0.0179,
        0.0221, 0.0083, 0.0204, 0.0070, 0.0058, 0.0099], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,902][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([1.3470e-03, 8.2624e-01, 1.1992e-01, 2.5516e-02, 7.6155e-03, 4.9288e-03,
        5.9411e-03, 1.1354e-03, 2.0172e-03, 1.4965e-03, 3.7010e-04, 1.2003e-03,
        9.6801e-04, 5.2568e-04, 7.8725e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,907][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0279, 0.1033, 0.0931, 0.0980, 0.0817, 0.0698, 0.0549, 0.0529, 0.0589,
        0.0763, 0.0658, 0.0475, 0.0640, 0.0553, 0.0506], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:55,908][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.7872e-02, 2.3288e-04, 1.6098e-04, 9.8211e-03, 4.5725e-04, 8.6854e-05,
        4.7114e-03, 2.9433e-02, 5.9244e-03, 2.4181e-02, 8.1185e-01, 7.8000e-04,
        2.3498e-03, 1.7564e-04, 1.4373e-03, 2.0531e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,909][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.7304e-04, 7.1348e-01, 2.5366e-01, 1.6047e-02, 1.0640e-02, 1.3494e-03,
        1.9876e-03, 1.3397e-04, 1.1794e-03, 1.5252e-04, 6.3358e-05, 5.2941e-04,
        1.0839e-04, 2.8081e-04, 1.5504e-04, 6.1178e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,909][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.4932, 0.1894, 0.0822, 0.0268, 0.0626, 0.0176, 0.0381, 0.0123, 0.0203,
        0.0050, 0.0022, 0.0095, 0.0059, 0.0117, 0.0188, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,910][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0035, 0.3555, 0.4465, 0.0458, 0.0609, 0.0110, 0.0233, 0.0048, 0.0097,
        0.0068, 0.0026, 0.0067, 0.0039, 0.0092, 0.0038, 0.0060],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,912][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.4649e-04, 9.2953e-01, 5.7232e-02, 8.0425e-03, 9.2865e-04, 1.5265e-03,
        1.2868e-03, 2.9345e-04, 2.4684e-04, 4.5558e-04, 7.9540e-05, 2.8299e-05,
        3.8817e-05, 1.9793e-05, 6.7885e-05, 7.3852e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,915][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.5989e-02, 5.7505e-01, 2.1824e-01, 4.6886e-02, 2.7606e-02, 2.4500e-02,
        2.0465e-02, 7.0452e-03, 5.6997e-03, 2.7553e-03, 5.2258e-04, 3.9052e-04,
        3.3053e-04, 2.2894e-03, 1.2410e-03, 9.8520e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,919][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.7393, 0.0629, 0.0515, 0.0093, 0.0096, 0.0066, 0.0642, 0.0076, 0.0078,
        0.0063, 0.0039, 0.0146, 0.0040, 0.0043, 0.0032, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,921][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.3959e-03, 9.4880e-01, 3.3935e-02, 1.1260e-02, 1.0302e-03, 1.0996e-03,
        1.3033e-03, 2.3475e-04, 3.6031e-04, 3.9631e-04, 1.7870e-05, 3.9527e-06,
        1.1934e-05, 1.6531e-05, 2.9064e-05, 1.0630e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,922][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.6169e-02, 6.7332e-01, 2.0459e-01, 3.0599e-02, 1.0910e-02, 1.1315e-02,
        2.8759e-02, 3.3442e-03, 9.6532e-03, 2.7338e-03, 3.0681e-04, 1.8826e-03,
        8.8899e-04, 6.5784e-04, 3.4392e-03, 1.4319e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,923][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3622, 0.1942, 0.2719, 0.0375, 0.0116, 0.0172, 0.0177, 0.0137, 0.0155,
        0.0149, 0.0046, 0.0137, 0.0041, 0.0051, 0.0070, 0.0092],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,924][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.0770e-03, 7.7204e-01, 1.3291e-01, 4.2986e-02, 9.1962e-03, 8.8878e-03,
        1.1079e-02, 2.0501e-03, 3.5512e-03, 2.6493e-03, 5.3086e-04, 1.7701e-03,
        1.3781e-03, 8.0921e-04, 1.4734e-03, 1.6074e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,926][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0288, 0.0974, 0.0879, 0.0924, 0.0766, 0.0653, 0.0509, 0.0496, 0.0541,
        0.0715, 0.0610, 0.0441, 0.0614, 0.0511, 0.0473, 0.0605],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:55,929][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ give] are: tensor([5.4652e-02, 4.0662e-04, 3.6140e-04, 9.9426e-03, 1.2840e-03, 1.3078e-04,
        7.3822e-03, 3.4185e-02, 5.1891e-03, 2.5570e-02, 8.0073e-01, 1.1024e-03,
        2.7488e-03, 3.6732e-04, 1.9212e-03, 2.3807e-02, 3.0219e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,932][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ give] are: tensor([2.8911e-03, 7.7259e-01, 1.7137e-01, 3.4922e-02, 1.1242e-02, 1.5314e-03,
        2.8015e-03, 1.5999e-04, 7.9833e-04, 1.4221e-04, 5.2766e-05, 7.4833e-04,
        1.6289e-04, 3.5816e-04, 9.2991e-05, 6.8465e-05, 7.4785e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,935][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.3567, 0.1303, 0.0774, 0.0317, 0.0796, 0.0289, 0.0792, 0.0238, 0.0310,
        0.0091, 0.0038, 0.0389, 0.0098, 0.0246, 0.0309, 0.0087, 0.0356],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,936][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0020, 0.2564, 0.6178, 0.0140, 0.0636, 0.0060, 0.0094, 0.0017, 0.0037,
        0.0024, 0.0009, 0.0023, 0.0017, 0.0103, 0.0013, 0.0031, 0.0035],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,936][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ give] are: tensor([2.8052e-05, 9.3062e-01, 6.2161e-02, 5.7028e-03, 7.5149e-04, 3.3577e-04,
        2.0987e-04, 4.8583e-05, 1.9352e-05, 7.6287e-05, 8.9191e-06, 5.4074e-06,
        6.3535e-06, 3.0449e-06, 4.6191e-06, 1.0461e-05, 5.4117e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,937][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ give] are: tensor([3.0296e-03, 7.7055e-01, 1.8499e-01, 1.5740e-02, 1.0477e-02, 7.2342e-03,
        4.5965e-03, 1.0572e-03, 9.0831e-04, 5.8748e-04, 8.2342e-05, 7.7198e-05,
        5.8583e-05, 1.8542e-04, 1.3662e-04, 1.5603e-04, 1.2875e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,938][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ give] are: tensor([8.8874e-01, 2.6599e-02, 3.1872e-02, 6.8541e-03, 7.7620e-03, 2.6880e-03,
        1.5404e-02, 1.8964e-03, 1.5001e-03, 1.6231e-03, 9.5064e-04, 4.6639e-03,
        1.3923e-03, 2.6492e-03, 8.5483e-04, 1.2916e-03, 3.2617e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,940][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ give] are: tensor([1.3686e-05, 9.6500e-01, 3.1654e-02, 2.8683e-03, 2.7604e-04, 8.3690e-05,
        5.8310e-05, 9.1589e-06, 1.1952e-05, 1.6598e-05, 5.5395e-07, 2.7813e-07,
        5.5750e-07, 3.9791e-07, 1.1213e-06, 2.8155e-06, 1.6814e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,943][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ give] are: tensor([3.9150e-03, 7.8558e-01, 1.8220e-01, 9.0895e-03, 4.2403e-03, 3.5014e-03,
        6.3709e-03, 6.2727e-04, 1.5441e-03, 6.5698e-04, 5.9009e-05, 4.4795e-04,
        1.9542e-04, 1.3848e-04, 3.7919e-04, 3.4099e-04, 7.1185e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,947][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.1917, 0.2989, 0.3505, 0.0415, 0.0131, 0.0161, 0.0133, 0.0097, 0.0107,
        0.0109, 0.0033, 0.0099, 0.0033, 0.0052, 0.0053, 0.0074, 0.0095],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,947][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ give] are: tensor([1.4971e-03, 7.6472e-01, 1.8232e-01, 2.4778e-02, 9.7846e-03, 5.0958e-03,
        4.8002e-03, 7.4422e-04, 9.7279e-04, 1.1469e-03, 2.2589e-04, 8.9766e-04,
        7.0242e-04, 5.0434e-04, 4.0236e-04, 7.0507e-04, 7.0036e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,950][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0225, 0.0927, 0.0853, 0.0892, 0.0752, 0.0631, 0.0486, 0.0471, 0.0517,
        0.0691, 0.0589, 0.0417, 0.0583, 0.0500, 0.0445, 0.0585, 0.0434],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:55,951][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.6340e-02, 1.3064e-04, 1.0367e-04, 3.4333e-03, 2.7136e-04, 3.0262e-05,
        1.1106e-03, 8.9705e-03, 2.1116e-03, 9.1928e-03, 3.4171e-01, 2.4988e-04,
        7.4385e-04, 6.6486e-05, 4.8026e-04, 7.0314e-03, 5.9589e-03, 6.0207e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,951][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.1149e-04, 8.7841e-01, 1.0370e-01, 1.1820e-02, 3.6955e-03, 6.1263e-04,
        5.7343e-04, 9.0616e-05, 2.7206e-04, 1.2626e-04, 3.0975e-05, 1.2956e-04,
        6.9493e-05, 1.5640e-04, 6.7390e-05, 4.2867e-05, 7.3803e-05, 1.7260e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,952][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1558, 0.2710, 0.1172, 0.0610, 0.0899, 0.0441, 0.0731, 0.0232, 0.0369,
        0.0098, 0.0026, 0.0250, 0.0127, 0.0133, 0.0311, 0.0084, 0.0194, 0.0055],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,954][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0008, 0.3785, 0.5317, 0.0151, 0.0459, 0.0054, 0.0049, 0.0012, 0.0019,
        0.0019, 0.0008, 0.0021, 0.0012, 0.0039, 0.0009, 0.0017, 0.0017, 0.0006],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,957][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.9981e-07, 9.6410e-01, 3.4682e-02, 9.0711e-04, 1.0724e-04, 1.1129e-04,
        5.6846e-05, 6.7910e-06, 5.8251e-06, 1.0358e-05, 1.2860e-06, 8.4211e-07,
        1.2094e-06, 2.7659e-07, 1.6417e-06, 1.5767e-06, 1.4621e-06, 1.7235e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,960][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.2563e-04, 8.0311e-01, 1.8308e-01, 5.4633e-03, 3.3268e-03, 2.8531e-03,
        1.3384e-03, 1.5792e-04, 2.4832e-04, 1.1421e-04, 1.3149e-05, 1.5431e-05,
        1.2386e-05, 3.0585e-05, 3.3742e-05, 3.3234e-05, 3.9298e-05, 2.6825e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,963][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.7315, 0.0933, 0.0590, 0.0161, 0.0094, 0.0113, 0.0298, 0.0067, 0.0050,
        0.0052, 0.0022, 0.0087, 0.0039, 0.0028, 0.0024, 0.0035, 0.0064, 0.0028],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,964][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([2.0249e-07, 9.7076e-01, 2.8556e-02, 5.5074e-04, 7.5220e-05, 3.0404e-05,
        1.6923e-05, 1.1919e-06, 2.6325e-06, 2.6479e-06, 7.8454e-08, 5.3825e-08,
        7.4247e-08, 8.8389e-08, 2.2342e-07, 4.9933e-07, 5.6852e-07, 4.0273e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,965][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.7937e-03, 7.9655e-01, 1.8016e-01, 8.6587e-03, 3.0841e-03, 2.3245e-03,
        4.2157e-03, 3.1283e-04, 9.7996e-04, 3.4191e-04, 3.2317e-05, 3.9983e-04,
        1.1917e-04, 7.5162e-05, 3.4834e-04, 2.0155e-04, 3.5696e-04, 4.2151e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,966][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1755, 0.3035, 0.3565, 0.0415, 0.0110, 0.0159, 0.0138, 0.0107, 0.0135,
        0.0133, 0.0040, 0.0090, 0.0033, 0.0037, 0.0048, 0.0076, 0.0098, 0.0027],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,967][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.2866e-04, 8.6045e-01, 1.0841e-01, 1.7551e-02, 4.1441e-03, 3.4097e-03,
        2.1940e-03, 3.4653e-04, 5.5344e-04, 5.6129e-04, 1.0877e-04, 3.7339e-04,
        3.3126e-04, 1.4271e-04, 2.3080e-04, 3.0515e-04, 2.7452e-04, 8.3158e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,971][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0219, 0.0903, 0.0827, 0.0855, 0.0714, 0.0598, 0.0459, 0.0448, 0.0488,
        0.0659, 0.0560, 0.0395, 0.0558, 0.0464, 0.0421, 0.0553, 0.0412, 0.0466],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:55,974][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([1.5722e-02, 1.9870e-04, 2.0814e-04, 3.5088e-03, 4.3818e-04, 4.4677e-05,
        2.5691e-03, 1.1710e-02, 3.2784e-03, 1.0178e-02, 3.3923e-01, 3.2810e-04,
        1.1666e-03, 1.2700e-04, 6.0724e-04, 8.8388e-03, 1.0600e-02, 5.9110e-01,
        1.5388e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,977][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([3.4668e-04, 6.3463e-01, 3.2566e-01, 1.4507e-02, 1.2252e-02, 1.4466e-03,
        2.8181e-03, 3.9294e-04, 1.9954e-03, 5.4595e-04, 2.2211e-04, 1.6261e-03,
        4.2511e-04, 1.1031e-03, 5.7916e-04, 3.8964e-04, 4.1603e-04, 1.7401e-04,
        4.6649e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,978][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.3034, 0.1762, 0.1084, 0.0357, 0.0953, 0.0417, 0.0634, 0.0089, 0.0221,
        0.0052, 0.0033, 0.0251, 0.0066, 0.0141, 0.0212, 0.0047, 0.0243, 0.0096,
        0.0308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,979][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0019, 0.2928, 0.5814, 0.0145, 0.0681, 0.0052, 0.0108, 0.0011, 0.0027,
        0.0018, 0.0010, 0.0028, 0.0014, 0.0062, 0.0012, 0.0018, 0.0025, 0.0008,
        0.0021], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,980][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([4.5226e-07, 9.1127e-01, 8.7019e-02, 9.5772e-04, 5.4032e-04, 1.3258e-04,
        4.9874e-05, 6.2829e-06, 3.3986e-06, 1.2021e-05, 2.1631e-06, 1.2866e-06,
        1.4357e-06, 3.8106e-07, 3.0417e-07, 1.1268e-06, 9.9810e-07, 1.9301e-07,
        1.0442e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,981][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([4.8718e-05, 7.7837e-01, 2.0710e-01, 6.2537e-03, 4.9213e-03, 1.8690e-03,
        1.0558e-03, 7.7473e-05, 1.5408e-04, 5.7579e-05, 1.2130e-05, 1.5811e-05,
        9.3064e-06, 8.4185e-06, 1.2712e-05, 9.8529e-06, 1.5041e-05, 1.5556e-06,
        6.6608e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,985][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.5371, 0.1086, 0.0950, 0.0312, 0.0242, 0.0210, 0.0717, 0.0120, 0.0106,
        0.0114, 0.0063, 0.0161, 0.0086, 0.0052, 0.0045, 0.0060, 0.0136, 0.0081,
        0.0089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,988][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([1.4512e-07, 8.9455e-01, 1.0444e-01, 6.6596e-04, 2.9242e-04, 3.2211e-05,
        1.2899e-05, 4.9800e-07, 1.6572e-06, 9.1250e-07, 7.3138e-08, 3.9034e-08,
        5.1036e-08, 2.5877e-08, 7.8158e-08, 1.0927e-07, 1.1810e-07, 1.6605e-08,
        1.0796e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,991][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([1.5543e-03, 7.3982e-01, 2.2142e-01, 1.0704e-02, 5.0611e-03, 5.5075e-03,
        9.2025e-03, 7.4041e-04, 1.7722e-03, 6.4934e-04, 1.2669e-04, 8.7098e-04,
        3.1452e-04, 1.1284e-04, 6.7053e-04, 3.8496e-04, 7.2853e-04, 1.5815e-04,
        1.9934e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,992][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.2692, 0.2763, 0.2947, 0.0347, 0.0086, 0.0170, 0.0144, 0.0111, 0.0116,
        0.0114, 0.0038, 0.0093, 0.0027, 0.0033, 0.0059, 0.0053, 0.0106, 0.0023,
        0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,993][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([4.0142e-04, 7.5047e-01, 2.1212e-01, 1.9106e-02, 7.2478e-03, 2.8932e-03,
        3.5520e-03, 3.5069e-04, 9.9162e-04, 5.3958e-04, 1.1670e-04, 6.9646e-04,
        3.1384e-04, 1.6991e-04, 2.7677e-04, 2.3360e-04, 3.2812e-04, 7.4534e-05,
        1.2423e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,994][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0233, 0.0863, 0.0798, 0.0798, 0.0677, 0.0577, 0.0448, 0.0430, 0.0471,
        0.0622, 0.0535, 0.0388, 0.0530, 0.0455, 0.0407, 0.0529, 0.0404, 0.0448,
        0.0389], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:55,995][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.4536e-02, 2.4035e-04, 1.6834e-04, 5.4567e-03, 3.3886e-04, 5.0951e-05,
        2.2592e-03, 1.4020e-02, 3.0248e-03, 1.2473e-02, 3.3986e-01, 4.1597e-04,
        1.1552e-03, 9.1880e-05, 7.2251e-04, 9.7982e-03, 8.3773e-03, 5.7081e-01,
        1.2609e-04, 6.0742e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:55,997][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([6.1866e-05, 7.9634e-01, 1.8611e-01, 8.9146e-03, 5.7870e-03, 7.8005e-04,
        8.6213e-04, 5.6003e-05, 4.1456e-04, 7.6613e-05, 2.4755e-05, 2.1071e-04,
        4.9581e-05, 1.0401e-04, 5.2413e-05, 2.8727e-05, 5.2983e-05, 1.5010e-05,
        4.9669e-05, 1.3476e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,001][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2409, 0.3372, 0.1197, 0.0369, 0.0790, 0.0227, 0.0431, 0.0124, 0.0192,
        0.0056, 0.0019, 0.0118, 0.0068, 0.0096, 0.0154, 0.0047, 0.0110, 0.0046,
        0.0129, 0.0044], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,005][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0005, 0.4343, 0.4612, 0.0253, 0.0425, 0.0050, 0.0088, 0.0014, 0.0032,
        0.0023, 0.0009, 0.0021, 0.0014, 0.0029, 0.0011, 0.0019, 0.0019, 0.0006,
        0.0013, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,006][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.1188e-06, 9.3535e-01, 6.2563e-02, 1.3927e-03, 3.4240e-04, 1.7237e-04,
        1.1421e-04, 1.2662e-05, 1.3976e-05, 2.0200e-05, 3.5268e-06, 1.9333e-06,
        2.1274e-06, 7.5504e-07, 2.8626e-06, 2.4285e-06, 4.3826e-06, 5.4302e-07,
        2.5575e-07, 3.3183e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,007][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([5.2504e-04, 7.1767e-01, 2.5681e-01, 8.8467e-03, 9.8034e-03, 3.0438e-03,
        2.1762e-03, 2.7117e-04, 3.8811e-04, 1.3988e-04, 2.4692e-05, 2.6181e-05,
        1.7727e-05, 7.3069e-05, 4.5869e-05, 3.3793e-05, 5.5110e-05, 4.4378e-06,
        3.0233e-05, 7.5812e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,008][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4898, 0.1830, 0.1278, 0.0169, 0.0174, 0.0087, 0.0761, 0.0076, 0.0077,
        0.0066, 0.0035, 0.0160, 0.0046, 0.0047, 0.0029, 0.0048, 0.0083, 0.0042,
        0.0055, 0.0041], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,009][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.5057e-06, 9.5569e-01, 4.2806e-02, 1.0920e-03, 3.0135e-04, 4.7906e-05,
        4.6248e-05, 2.1281e-06, 5.9945e-06, 4.5870e-06, 2.2003e-07, 8.7412e-08,
        1.7448e-07, 1.8642e-07, 2.6828e-07, 7.5347e-07, 8.2100e-07, 1.1454e-07,
        8.1351e-08, 1.0392e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,012][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.5412e-03, 7.3644e-01, 2.3086e-01, 1.0219e-02, 5.4867e-03, 3.2641e-03,
        6.8892e-03, 4.8072e-04, 1.8053e-03, 4.7408e-04, 5.4991e-05, 4.3243e-04,
        1.7681e-04, 1.0470e-04, 5.3940e-04, 2.3823e-04, 6.2574e-04, 5.6637e-05,
        2.0054e-04, 1.0624e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,017][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2074, 0.2725, 0.3560, 0.0374, 0.0122, 0.0147, 0.0142, 0.0098, 0.0113,
        0.0108, 0.0034, 0.0105, 0.0029, 0.0036, 0.0043, 0.0062, 0.0092, 0.0026,
        0.0062, 0.0047], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,019][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([7.9995e-04, 8.2596e-01, 1.3753e-01, 1.8993e-02, 5.7585e-03, 3.1750e-03,
        3.4617e-03, 4.1201e-04, 8.6141e-04, 5.7678e-04, 1.2390e-04, 4.9135e-04,
        3.5817e-04, 1.6862e-04, 3.1897e-04, 3.2545e-04, 3.9346e-04, 8.5501e-05,
        9.9222e-05, 1.1125e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,019][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0224, 0.0839, 0.0764, 0.0774, 0.0654, 0.0547, 0.0423, 0.0410, 0.0446,
        0.0593, 0.0505, 0.0365, 0.0510, 0.0430, 0.0389, 0.0502, 0.0384, 0.0424,
        0.0367, 0.0450], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,107][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:56,108][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,109][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,109][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,110][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,111][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,111][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,112][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,113][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,113][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,114][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,115][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,115][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,116][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9980e-01, 2.0277e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,117][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1827, 0.8173], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,117][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9791, 0.0209], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,122][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3138, 0.6862], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,123][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([2.0142e-04, 9.9980e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,124][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1109, 0.8891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,125][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9967, 0.0033], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,125][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([7.8744e-04, 9.9921e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,126][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0294, 0.9706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,128][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2599, 0.7401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,133][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0082, 0.9918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,136][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.2840e-05, 9.9997e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,137][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([9.9876e-01, 9.1399e-04, 3.2382e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,138][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.1621, 0.6649, 0.1729], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,138][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.9318, 0.0509, 0.0173], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,139][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0703, 0.7431, 0.1866], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,140][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([1.7144e-06, 9.9731e-01, 2.6860e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,141][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([3.7970e-04, 9.8998e-01, 9.6421e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,145][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.9873, 0.0061, 0.0066], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,148][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([2.9803e-07, 9.9953e-01, 4.7184e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,150][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0157, 0.9384, 0.0459], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,151][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0916, 0.7974, 0.1110], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,152][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0016, 0.9639, 0.0345], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,152][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([1.0614e-06, 9.9081e-01, 9.1861e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,153][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([9.1943e-01, 1.1829e-03, 8.6633e-04, 7.8526e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,155][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0007, 0.5234, 0.3822, 0.0936], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,159][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8168, 0.0862, 0.0623, 0.0346], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,164][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0991, 0.3836, 0.3323, 0.1849], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,164][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.7780e-05, 9.8535e-01, 1.0607e-02, 4.0206e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,165][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0186, 0.9008, 0.0561, 0.0245], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,166][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5069, 0.1792, 0.2812, 0.0328], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,167][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.7905e-04, 9.8980e-01, 4.0211e-03, 5.9964e-03], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,167][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0530, 0.7616, 0.1051, 0.0803], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,171][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1167, 0.5094, 0.1599, 0.2140], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,175][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0017, 0.8801, 0.0423, 0.0760], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,178][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([4.5850e-05, 8.8498e-01, 7.8510e-02, 3.6467e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,178][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.9016, 0.0022, 0.0013, 0.0916, 0.0034], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,179][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0184, 0.5766, 0.2284, 0.1363, 0.0402], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,180][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.7976, 0.0969, 0.0375, 0.0292, 0.0388], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,181][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0274, 0.4588, 0.3400, 0.1100, 0.0638], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,182][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([7.9341e-08, 9.9230e-01, 6.9503e-03, 7.2382e-04, 2.5545e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,184][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([6.6032e-05, 9.7977e-01, 1.3741e-02, 6.2182e-03, 2.0245e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,188][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.9600, 0.0112, 0.0132, 0.0124, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,192][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([2.8936e-08, 9.9785e-01, 1.8213e-03, 3.3077e-04, 2.7051e-06],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,192][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0095, 0.8925, 0.0738, 0.0209, 0.0033], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,194][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0361, 0.7247, 0.1290, 0.1020, 0.0083], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,194][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([4.3213e-04, 9.3257e-01, 3.9874e-02, 2.4388e-02, 2.7408e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,195][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([3.2096e-07, 9.6387e-01, 3.3339e-02, 2.4735e-03, 3.1699e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,199][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.7766, 0.0028, 0.0013, 0.2115, 0.0069, 0.0009], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,203][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0043, 0.4889, 0.3953, 0.0652, 0.0429, 0.0034], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,206][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.5090, 0.1353, 0.1182, 0.0591, 0.1533, 0.0251], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,206][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0166, 0.4094, 0.3546, 0.1096, 0.0879, 0.0220], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,207][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([6.8823e-06, 9.7690e-01, 1.8462e-02, 4.3908e-03, 1.3194e-04, 1.0622e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,208][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0017, 0.9032, 0.0587, 0.0296, 0.0038, 0.0031], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,209][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.8224, 0.0731, 0.0502, 0.0236, 0.0174, 0.0134], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,210][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([6.4450e-06, 9.9016e-01, 7.7035e-03, 2.0606e-03, 4.6389e-05, 2.6881e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,214][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0129, 0.8271, 0.0995, 0.0462, 0.0056, 0.0087], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,219][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.0457, 0.6030, 0.1660, 0.1489, 0.0151, 0.0213], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,220][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0011, 0.8800, 0.0579, 0.0512, 0.0052, 0.0047], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,221][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([1.2845e-05, 8.7213e-01, 9.9495e-02, 2.1065e-02, 3.2205e-03, 4.0792e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,221][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.8238, 0.0042, 0.0015, 0.1254, 0.0072, 0.0011, 0.0369],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,222][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0068, 0.7343, 0.1663, 0.0375, 0.0272, 0.0193, 0.0085],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,223][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.3114, 0.2235, 0.1024, 0.0781, 0.1247, 0.0675, 0.0923],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,227][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0112, 0.2450, 0.5484, 0.0363, 0.1076, 0.0213, 0.0302],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,230][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([6.2956e-07, 9.7400e-01, 2.2290e-02, 3.3105e-03, 2.0346e-04, 1.6185e-04,
        3.1740e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,233][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([2.2186e-04, 9.2857e-01, 5.3412e-02, 1.2354e-02, 2.3491e-03, 2.3562e-03,
        7.3932e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,236][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.5764, 0.0955, 0.0727, 0.0506, 0.0161, 0.0339, 0.1548],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,237][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([4.2795e-07, 9.8908e-01, 9.1502e-03, 1.6867e-03, 4.3364e-05, 3.0124e-05,
        4.4903e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,237][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0025, 0.8743, 0.0921, 0.0171, 0.0027, 0.0055, 0.0057],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,238][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.0402, 0.5969, 0.2212, 0.0898, 0.0131, 0.0169, 0.0218],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,239][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([8.5584e-04, 8.6816e-01, 8.8942e-02, 2.8048e-02, 5.6874e-03, 4.9442e-03,
        3.3635e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,241][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([9.9028e-06, 8.1944e-01, 1.7068e-01, 4.6452e-03, 2.6730e-03, 2.3458e-03,
        2.0757e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,243][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([6.7876e-01, 1.2095e-03, 1.2551e-03, 4.7566e-02, 3.1528e-03, 6.4005e-04,
        3.2269e-02, 2.3515e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,248][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0016, 0.6212, 0.2646, 0.0541, 0.0407, 0.0080, 0.0087, 0.0011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,250][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.7430, 0.0549, 0.0394, 0.0288, 0.0511, 0.0172, 0.0496, 0.0160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,251][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0229, 0.3173, 0.4189, 0.0836, 0.0856, 0.0212, 0.0376, 0.0129],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,251][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([8.8069e-05, 9.3610e-01, 5.0506e-02, 1.0984e-02, 8.8143e-04, 7.2795e-04,
        5.4787e-04, 1.6632e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,252][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0345, 0.7019, 0.1555, 0.0524, 0.0145, 0.0206, 0.0148, 0.0059],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,253][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.7379, 0.0437, 0.0594, 0.0201, 0.0102, 0.0148, 0.0984, 0.0154],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,255][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([8.8361e-05, 9.7158e-01, 1.8618e-02, 8.8065e-03, 4.0075e-04, 3.1674e-04,
        1.3710e-04, 5.3327e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,259][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0245, 0.6562, 0.2378, 0.0310, 0.0106, 0.0139, 0.0229, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,263][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.1237, 0.3672, 0.2570, 0.1076, 0.0241, 0.0353, 0.0417, 0.0434],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,264][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0051, 0.8222, 0.0949, 0.0502, 0.0082, 0.0081, 0.0090, 0.0024],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,265][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([1.0319e-04, 7.7352e-01, 1.9206e-01, 1.6369e-02, 6.4581e-03, 9.1789e-03,
        1.4686e-03, 8.3954e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,266][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.5330, 0.0021, 0.0015, 0.0738, 0.0043, 0.0009, 0.0370, 0.2983, 0.0491],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,267][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0064, 0.6758, 0.2115, 0.0497, 0.0198, 0.0154, 0.0109, 0.0020, 0.0086],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,269][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.4277, 0.1366, 0.0582, 0.0449, 0.0715, 0.0566, 0.1127, 0.0424, 0.0494],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,274][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0356, 0.2650, 0.5098, 0.0468, 0.0642, 0.0145, 0.0320, 0.0113, 0.0206],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,277][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([1.5652e-05, 9.1608e-01, 7.1446e-02, 9.7320e-03, 1.4632e-03, 8.7024e-04,
        2.8755e-04, 5.9178e-05, 4.6803e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,278][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([5.5875e-03, 8.4077e-01, 1.0705e-01, 2.4437e-02, 9.8123e-03, 6.4228e-03,
        3.2330e-03, 1.8493e-03, 8.3859e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,279][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.5326, 0.1396, 0.0705, 0.0294, 0.0097, 0.0207, 0.1339, 0.0399, 0.0236],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,280][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([5.4446e-05, 9.7109e-01, 1.9440e-02, 8.8217e-03, 3.1232e-04, 1.8048e-04,
        7.2340e-05, 1.3641e-05, 9.9687e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,280][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0201, 0.7653, 0.1382, 0.0297, 0.0077, 0.0125, 0.0205, 0.0029, 0.0031],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,283][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0664, 0.5526, 0.1411, 0.1078, 0.0129, 0.0330, 0.0393, 0.0273, 0.0196],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,288][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0028, 0.8583, 0.0754, 0.0407, 0.0053, 0.0066, 0.0067, 0.0017, 0.0025],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,291][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([5.2736e-05, 8.4716e-01, 1.3132e-01, 1.2442e-02, 2.8571e-03, 4.8406e-03,
        5.7634e-04, 2.5541e-04, 5.0256e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,292][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.1051e-01, 6.7282e-04, 6.0041e-04, 4.1483e-02, 2.4045e-03, 3.4834e-04,
        2.5690e-02, 1.6441e-01, 2.6622e-02, 1.2725e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,293][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0011, 0.5621, 0.3659, 0.0314, 0.0197, 0.0049, 0.0069, 0.0009, 0.0063,
        0.0008], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,294][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.7375, 0.0837, 0.0402, 0.0148, 0.0390, 0.0133, 0.0380, 0.0101, 0.0189,
        0.0044], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,294][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0330, 0.3551, 0.3426, 0.0711, 0.0634, 0.0195, 0.0482, 0.0161, 0.0296,
        0.0213], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,296][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.4537e-03, 9.2894e-01, 3.8956e-02, 2.1393e-02, 1.4513e-03, 2.4656e-03,
        2.1759e-03, 9.7147e-04, 5.3527e-04, 1.6572e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,300][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.3517, 0.3766, 0.0893, 0.0697, 0.0188, 0.0334, 0.0245, 0.0185, 0.0097,
        0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,305][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7946, 0.0394, 0.0330, 0.0071, 0.0059, 0.0065, 0.0835, 0.0099, 0.0116,
        0.0086], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,306][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.2748e-02, 9.0961e-01, 2.1554e-02, 3.6619e-02, 1.6044e-03, 2.1369e-03,
        2.0854e-03, 9.0008e-04, 6.6465e-04, 2.0771e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,307][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0613, 0.6126, 0.1532, 0.0502, 0.0104, 0.0227, 0.0533, 0.0088, 0.0198,
        0.0078], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,307][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1725, 0.3968, 0.1267, 0.0980, 0.0115, 0.0270, 0.0414, 0.0444, 0.0386,
        0.0430], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,308][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0173, 0.7776, 0.0891, 0.0666, 0.0079, 0.0116, 0.0148, 0.0038, 0.0052,
        0.0063], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,310][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0494e-04, 8.2167e-01, 1.2556e-01, 2.4521e-02, 5.8328e-03, 1.2137e-02,
        2.9075e-03, 1.5852e-03, 3.6500e-03, 1.9296e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,312][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.1658e-02, 1.9818e-04, 1.3852e-04, 7.5233e-03, 3.6628e-04, 7.2275e-05,
        3.8644e-03, 2.6414e-02, 3.7857e-03, 1.8914e-02, 8.9706e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,315][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.4380e-04, 7.1845e-01, 2.1535e-01, 3.9329e-02, 1.3532e-02, 3.3229e-03,
        4.4665e-03, 6.9662e-04, 3.2052e-03, 5.5672e-04, 1.4912e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,319][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3551, 0.2220, 0.0837, 0.0453, 0.0891, 0.0428, 0.0786, 0.0223, 0.0427,
        0.0114, 0.0070], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,320][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0047, 0.4898, 0.3749, 0.0374, 0.0429, 0.0094, 0.0132, 0.0052, 0.0096,
        0.0088, 0.0040], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,320][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.2343e-06, 9.6590e-01, 3.2096e-02, 1.6040e-03, 1.8223e-04, 1.0945e-04,
        4.4265e-05, 1.7117e-05, 1.1572e-05, 3.5991e-05, 2.5535e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,321][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.7207e-03, 8.5249e-01, 1.1591e-01, 1.3237e-02, 4.8630e-03, 7.3833e-03,
        2.6098e-03, 7.9823e-04, 4.4188e-04, 4.9304e-04, 5.4754e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,322][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.7752, 0.0575, 0.0520, 0.0174, 0.0088, 0.0108, 0.0493, 0.0086, 0.0107,
        0.0069, 0.0029], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,324][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([2.1743e-06, 9.8978e-01, 8.9807e-03, 1.1010e-03, 6.2699e-05, 4.0379e-05,
        1.6484e-05, 2.9636e-06, 3.7222e-06, 7.1391e-06, 1.8013e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,327][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.3635e-03, 8.3809e-01, 1.2486e-01, 1.4587e-02, 3.3449e-03, 4.9105e-03,
        7.7993e-03, 7.3917e-04, 1.4944e-03, 7.4121e-04, 6.9214e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,332][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0391, 0.6089, 0.1839, 0.0630, 0.0118, 0.0192, 0.0195, 0.0163, 0.0162,
        0.0191, 0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,333][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.1264e-03, 8.9318e-01, 7.2475e-02, 1.9686e-02, 3.1037e-03, 3.3217e-03,
        3.6719e-03, 6.3601e-04, 1.1974e-03, 1.3007e-03, 3.0026e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,334][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([8.8438e-06, 8.5768e-01, 1.2685e-01, 7.1917e-03, 2.7586e-03, 3.8651e-03,
        6.3688e-04, 2.1028e-04, 4.1277e-04, 3.4209e-04, 5.2191e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,335][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([4.9066e-02, 6.1441e-04, 3.4695e-04, 1.2574e-02, 9.9153e-04, 9.1315e-05,
        4.8855e-03, 4.0046e-02, 4.9857e-03, 1.9897e-02, 8.6515e-01, 1.3469e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,335][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([1.0750e-03, 8.0979e-01, 1.4593e-01, 2.0618e-02, 1.2324e-02, 2.2477e-03,
        2.4377e-03, 3.2158e-04, 2.0515e-03, 6.5169e-04, 2.3938e-04, 2.3059e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,338][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.4433, 0.1731, 0.0746, 0.0458, 0.0829, 0.0510, 0.0496, 0.0180, 0.0252,
        0.0099, 0.0070, 0.0196], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,343][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0151, 0.2656, 0.5355, 0.0333, 0.0688, 0.0160, 0.0267, 0.0087, 0.0104,
        0.0084, 0.0037, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,346][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([1.0285e-07, 9.7486e-01, 2.4145e-02, 8.3974e-04, 9.8193e-05, 3.2204e-05,
        1.1430e-05, 2.8656e-06, 7.8289e-07, 8.4775e-06, 6.5595e-07, 9.3082e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,347][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([7.5098e-06, 9.3443e-01, 5.9330e-02, 3.7384e-03, 1.3508e-03, 6.4314e-04,
        2.9921e-04, 6.6212e-05, 5.7112e-05, 6.4429e-05, 6.1611e-06, 3.2996e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,348][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.4133, 0.1561, 0.1291, 0.0420, 0.0172, 0.0226, 0.0888, 0.0199, 0.0243,
        0.0282, 0.0124, 0.0461], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,349][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([1.3919e-08, 9.8932e-01, 1.0009e-02, 6.1887e-04, 3.8090e-05, 1.0041e-05,
        2.1471e-06, 2.7338e-07, 4.7980e-07, 1.3134e-06, 3.9010e-08, 3.0856e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,349][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.1945e-03, 8.2254e-01, 1.5806e-01, 7.5891e-03, 2.5829e-03, 2.3208e-03,
        3.6557e-03, 4.4574e-04, 7.2339e-04, 5.9244e-04, 8.1061e-05, 2.0642e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,352][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0171, 0.6930, 0.1939, 0.0459, 0.0055, 0.0100, 0.0097, 0.0066, 0.0051,
        0.0084, 0.0011, 0.0036], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,355][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([2.8033e-04, 8.2546e-01, 1.4322e-01, 1.8853e-02, 4.7682e-03, 2.7365e-03,
        2.7485e-03, 3.8541e-04, 5.8876e-04, 5.0202e-04, 8.6616e-05, 3.6888e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,358][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([2.9907e-06, 7.8330e-01, 2.1173e-01, 1.8562e-03, 1.6938e-03, 9.3989e-04,
        1.7719e-04, 5.6196e-05, 1.2951e-04, 7.5258e-05, 1.3834e-05, 2.1959e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,360][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.2103e-01, 2.1002e-04, 2.0636e-04, 6.2660e-03, 4.3809e-04, 7.7114e-05,
        3.9243e-03, 2.6206e-02, 3.3503e-03, 1.4916e-02, 8.2129e-01, 4.8515e-04,
        1.6019e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,361][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([3.4606e-04, 6.6343e-01, 2.8133e-01, 2.9672e-02, 1.4399e-02, 2.6372e-03,
        3.0517e-03, 4.5518e-04, 2.5067e-03, 3.2261e-04, 1.5575e-04, 1.3666e-03,
        3.3439e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,362][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.5834, 0.1451, 0.0517, 0.0267, 0.0446, 0.0332, 0.0457, 0.0152, 0.0171,
        0.0064, 0.0061, 0.0161, 0.0088], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,363][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0057, 0.3621, 0.4794, 0.0341, 0.0610, 0.0086, 0.0175, 0.0042, 0.0091,
        0.0057, 0.0025, 0.0065, 0.0035], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,364][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([6.0396e-07, 9.7542e-01, 2.3621e-02, 7.6203e-04, 7.6470e-05, 6.8865e-05,
        1.5077e-05, 8.1818e-06, 2.4602e-06, 1.9198e-05, 9.9226e-07, 4.9624e-07,
        1.0463e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,365][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([8.0974e-04, 8.8041e-01, 1.0093e-01, 6.7182e-03, 3.0135e-03, 4.6809e-03,
        2.0733e-03, 6.3341e-04, 3.3021e-04, 3.3336e-04, 3.0457e-05, 1.5125e-05,
        2.6297e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,369][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.3774, 0.1899, 0.0958, 0.0216, 0.0140, 0.0212, 0.1573, 0.0207, 0.0247,
        0.0199, 0.0100, 0.0347, 0.0129], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,372][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([5.6939e-06, 9.8853e-01, 1.0478e-02, 8.7614e-04, 4.8543e-05, 3.7249e-05,
        1.6818e-05, 2.8924e-06, 2.1937e-06, 7.0648e-06, 1.5601e-07, 2.0764e-08,
        1.7738e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,374][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([3.3601e-03, 7.9367e-01, 1.6875e-01, 1.4256e-02, 5.0342e-03, 4.9564e-03,
        6.1577e-03, 1.0193e-03, 1.2523e-03, 9.1966e-04, 9.3271e-05, 3.4469e-04,
        1.8427e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,375][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0128, 0.6460, 0.2025, 0.0528, 0.0120, 0.0142, 0.0148, 0.0108, 0.0113,
        0.0135, 0.0021, 0.0040, 0.0032], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,376][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([1.0282e-03, 8.5566e-01, 1.1331e-01, 1.6962e-02, 4.0702e-03, 2.6377e-03,
        3.1020e-03, 4.1974e-04, 8.5959e-04, 8.2908e-04, 1.5319e-04, 4.9347e-04,
        4.7922e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,377][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([6.5237e-06, 8.0278e-01, 1.8734e-01, 4.4843e-03, 2.6077e-03, 1.7784e-03,
        3.5198e-04, 1.2036e-04, 2.4926e-04, 1.6979e-04, 2.9724e-05, 4.4623e-05,
        3.7921e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,377][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([1.1413e-01, 3.8086e-04, 3.0632e-04, 8.8247e-03, 5.2159e-04, 1.1448e-04,
        5.5582e-03, 3.3589e-02, 3.2017e-03, 1.7769e-02, 8.1173e-01, 9.9844e-04,
        2.5614e-03, 3.1590e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,379][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([1.9770e-03, 7.5784e-01, 1.5652e-01, 3.9191e-02, 1.4520e-02, 5.4936e-03,
        6.8384e-03, 1.1210e-03, 4.4026e-03, 1.3747e-03, 6.2104e-04, 7.5755e-03,
        1.4009e-03, 1.1228e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,383][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.4107, 0.2141, 0.0870, 0.0280, 0.0836, 0.0298, 0.0522, 0.0147, 0.0157,
        0.0058, 0.0061, 0.0294, 0.0080, 0.0148], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,388][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0244, 0.3326, 0.3762, 0.0544, 0.0650, 0.0179, 0.0494, 0.0143, 0.0222,
        0.0097, 0.0057, 0.0124, 0.0061, 0.0096], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,388][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([2.1246e-06, 9.1545e-01, 8.1893e-02, 1.8432e-03, 4.9972e-04, 1.7843e-04,
        5.3760e-05, 2.0652e-05, 8.0108e-06, 4.2451e-05, 4.4062e-06, 2.5419e-06,
        2.0289e-06, 1.6254e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,389][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([1.0526e-03, 7.9861e-01, 1.7561e-01, 1.0474e-02, 5.6219e-03, 4.7857e-03,
        2.3533e-03, 5.8448e-04, 3.7834e-04, 3.3920e-04, 5.0856e-05, 4.3195e-05,
        3.6446e-05, 5.5603e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,390][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.8032, 0.0374, 0.0227, 0.0112, 0.0045, 0.0043, 0.0606, 0.0164, 0.0047,
        0.0069, 0.0045, 0.0154, 0.0061, 0.0021], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,391][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([1.6963e-06, 9.5673e-01, 4.1768e-02, 1.1244e-03, 2.1076e-04, 6.3575e-05,
        7.0475e-05, 7.3341e-06, 1.0499e-05, 1.2411e-05, 6.4825e-07, 2.0359e-07,
        4.3978e-07, 1.7958e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,393][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([2.0081e-02, 7.3303e-01, 1.7874e-01, 2.1099e-02, 1.0251e-02, 1.0718e-02,
        1.7468e-02, 2.5904e-03, 2.1708e-03, 1.7275e-03, 3.0661e-04, 8.2431e-04,
        7.1754e-04, 2.8147e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,396][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.0483, 0.4040, 0.3342, 0.0717, 0.0258, 0.0187, 0.0232, 0.0187, 0.0137,
        0.0193, 0.0034, 0.0085, 0.0057, 0.0048], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,399][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([2.8568e-03, 8.2474e-01, 1.1952e-01, 2.7774e-02, 7.3175e-03, 4.2410e-03,
        8.0289e-03, 7.4950e-04, 1.7076e-03, 8.8260e-04, 2.4590e-04, 1.0027e-03,
        6.6693e-04, 2.6024e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,401][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([1.7694e-05, 8.6711e-01, 1.1807e-01, 8.6245e-03, 3.0406e-03, 1.9565e-03,
        3.4332e-04, 1.4956e-04, 3.1141e-04, 1.4898e-04, 4.0247e-05, 1.0805e-04,
        5.9289e-05, 2.4914e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,402][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([2.6219e-02, 3.4439e-04, 1.8830e-04, 1.1362e-02, 5.3342e-04, 1.0615e-04,
        7.0021e-03, 2.4236e-02, 4.1228e-03, 2.1952e-02, 8.9914e-01, 7.8375e-04,
        2.1661e-03, 2.5269e-04, 1.5939e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,403][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([3.6359e-04, 7.5162e-01, 2.1540e-01, 1.6663e-02, 9.0842e-03, 9.3754e-04,
        1.7859e-03, 2.1827e-04, 1.3431e-03, 2.5182e-04, 1.2501e-04, 1.1984e-03,
        2.4734e-04, 4.6257e-04, 3.0086e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,404][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.2522, 0.1944, 0.1108, 0.0502, 0.1467, 0.0381, 0.0564, 0.0250, 0.0219,
        0.0092, 0.0086, 0.0200, 0.0115, 0.0275, 0.0273], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,406][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0032, 0.3284, 0.5236, 0.0170, 0.0608, 0.0061, 0.0159, 0.0033, 0.0079,
        0.0037, 0.0021, 0.0129, 0.0038, 0.0089, 0.0026], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,409][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([8.8611e-06, 9.2910e-01, 6.6238e-02, 3.2079e-03, 6.9328e-04, 3.1453e-04,
        1.8649e-04, 5.4377e-05, 2.7141e-05, 1.2790e-04, 1.5669e-05, 4.4915e-06,
        8.4023e-06, 3.0238e-06, 5.2904e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,411][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([2.0707e-03, 7.6399e-01, 1.9745e-01, 1.7130e-02, 9.0201e-03, 5.8621e-03,
        2.7378e-03, 5.0911e-04, 5.2024e-04, 3.2014e-04, 6.1224e-05, 6.7402e-05,
        5.3463e-05, 1.2366e-04, 8.7434e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,415][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.6236, 0.1098, 0.0624, 0.0209, 0.0216, 0.0101, 0.0793, 0.0138, 0.0080,
        0.0078, 0.0051, 0.0189, 0.0065, 0.0085, 0.0036], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,416][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([2.1203e-05, 9.7083e-01, 2.6133e-02, 2.5256e-03, 2.5765e-04, 9.5308e-05,
        8.6845e-05, 9.4527e-06, 1.2059e-05, 2.2832e-05, 8.5037e-07, 2.9308e-07,
        8.3138e-07, 3.4845e-07, 1.0201e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,417][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([1.9085e-03, 7.8721e-01, 1.7961e-01, 8.0575e-03, 4.1398e-03, 4.8001e-03,
        8.8364e-03, 9.4553e-04, 1.8515e-03, 9.1839e-04, 1.0814e-04, 4.4814e-04,
        2.3553e-04, 9.7839e-05, 8.3361e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,417][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.0134, 0.5918, 0.1955, 0.0565, 0.0146, 0.0204, 0.0254, 0.0180, 0.0137,
        0.0188, 0.0042, 0.0129, 0.0067, 0.0030, 0.0052], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,418][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([1.2541e-03, 8.4387e-01, 1.0721e-01, 2.4885e-02, 6.9393e-03, 4.2306e-03,
        4.8238e-03, 9.7052e-04, 1.5994e-03, 1.1957e-03, 3.1391e-04, 8.9602e-04,
        7.8246e-04, 4.0439e-04, 6.3097e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,420][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([9.8892e-06, 8.8937e-01, 9.9665e-02, 6.4070e-03, 1.4358e-03, 1.7883e-03,
        3.3430e-04, 1.0694e-04, 3.5979e-04, 1.9183e-04, 4.4310e-05, 1.1277e-04,
        5.9048e-05, 2.4845e-05, 8.9358e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,422][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([8.7872e-02, 2.3288e-04, 1.6098e-04, 9.8211e-03, 4.5725e-04, 8.6854e-05,
        4.7114e-03, 2.9433e-02, 5.9244e-03, 2.4181e-02, 8.1185e-01, 7.8000e-04,
        2.3498e-03, 1.7564e-04, 1.4373e-03, 2.0531e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,425][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.7304e-04, 7.1348e-01, 2.5366e-01, 1.6047e-02, 1.0640e-02, 1.3494e-03,
        1.9876e-03, 1.3397e-04, 1.1794e-03, 1.5252e-04, 6.3358e-05, 5.2941e-04,
        1.0839e-04, 2.8081e-04, 1.5504e-04, 6.1178e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,429][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4932, 0.1894, 0.0822, 0.0268, 0.0626, 0.0176, 0.0381, 0.0123, 0.0203,
        0.0050, 0.0022, 0.0095, 0.0059, 0.0117, 0.0188, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,429][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0035, 0.3555, 0.4465, 0.0458, 0.0609, 0.0110, 0.0233, 0.0048, 0.0097,
        0.0068, 0.0026, 0.0067, 0.0039, 0.0092, 0.0038, 0.0060],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,430][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.4649e-04, 9.2953e-01, 5.7232e-02, 8.0425e-03, 9.2865e-04, 1.5265e-03,
        1.2868e-03, 2.9345e-04, 2.4684e-04, 4.5558e-04, 7.9540e-05, 2.8299e-05,
        3.8817e-05, 1.9793e-05, 6.7885e-05, 7.3852e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,431][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.5989e-02, 5.7505e-01, 2.1824e-01, 4.6886e-02, 2.7606e-02, 2.4500e-02,
        2.0465e-02, 7.0452e-03, 5.6997e-03, 2.7553e-03, 5.2258e-04, 3.9052e-04,
        3.3053e-04, 2.2894e-03, 1.2410e-03, 9.8520e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,433][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7393, 0.0629, 0.0515, 0.0093, 0.0096, 0.0066, 0.0642, 0.0076, 0.0078,
        0.0063, 0.0039, 0.0146, 0.0040, 0.0043, 0.0032, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,436][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.3959e-03, 9.4880e-01, 3.3935e-02, 1.1260e-02, 1.0302e-03, 1.0996e-03,
        1.3033e-03, 2.3475e-04, 3.6031e-04, 3.9631e-04, 1.7870e-05, 3.9527e-06,
        1.1934e-05, 1.6531e-05, 2.9064e-05, 1.0630e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,439][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.6169e-02, 6.7332e-01, 2.0459e-01, 3.0599e-02, 1.0910e-02, 1.1315e-02,
        2.8759e-02, 3.3442e-03, 9.6532e-03, 2.7338e-03, 3.0681e-04, 1.8826e-03,
        8.8899e-04, 6.5784e-04, 3.4392e-03, 1.4319e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,442][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0441, 0.5303, 0.1717, 0.0754, 0.0136, 0.0194, 0.0313, 0.0220, 0.0240,
        0.0253, 0.0034, 0.0116, 0.0060, 0.0041, 0.0067, 0.0113],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,443][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.5001e-03, 7.9032e-01, 1.1958e-01, 4.3726e-02, 8.7696e-03, 8.0008e-03,
        9.5569e-03, 1.8739e-03, 3.0121e-03, 2.2664e-03, 4.7588e-04, 1.4197e-03,
        1.1805e-03, 6.5908e-04, 1.2675e-03, 1.3970e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,444][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.9132e-05, 8.2981e-01, 1.3241e-01, 1.9566e-02, 5.1202e-03, 7.5131e-03,
        1.2863e-03, 5.8474e-04, 1.5626e-03, 6.7375e-04, 1.1385e-04, 2.5088e-04,
        1.6220e-04, 9.7299e-05, 5.0002e-04, 2.9985e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:56,445][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([5.4652e-02, 4.0662e-04, 3.6140e-04, 9.9426e-03, 1.2840e-03, 1.3078e-04,
        7.3822e-03, 3.4185e-02, 5.1891e-03, 2.5570e-02, 8.0073e-01, 1.1024e-03,
        2.7488e-03, 3.6732e-04, 1.9212e-03, 2.3807e-02, 3.0219e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,445][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([2.8911e-03, 7.7259e-01, 1.7137e-01, 3.4922e-02, 1.1242e-02, 1.5314e-03,
        2.8015e-03, 1.5999e-04, 7.9833e-04, 1.4221e-04, 5.2766e-05, 7.4833e-04,
        1.6289e-04, 3.5816e-04, 9.2991e-05, 6.8465e-05, 7.4785e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,449][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.3567, 0.1303, 0.0774, 0.0317, 0.0796, 0.0289, 0.0792, 0.0238, 0.0310,
        0.0091, 0.0038, 0.0389, 0.0098, 0.0246, 0.0309, 0.0087, 0.0356],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,453][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0020, 0.2564, 0.6178, 0.0140, 0.0636, 0.0060, 0.0094, 0.0017, 0.0037,
        0.0024, 0.0009, 0.0023, 0.0017, 0.0103, 0.0013, 0.0031, 0.0035],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,456][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([2.8052e-05, 9.3062e-01, 6.2161e-02, 5.7028e-03, 7.5149e-04, 3.3577e-04,
        2.0987e-04, 4.8583e-05, 1.9352e-05, 7.6287e-05, 8.9191e-06, 5.4074e-06,
        6.3535e-06, 3.0449e-06, 4.6191e-06, 1.0461e-05, 5.4117e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,457][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([3.0296e-03, 7.7055e-01, 1.8499e-01, 1.5740e-02, 1.0477e-02, 7.2342e-03,
        4.5965e-03, 1.0572e-03, 9.0831e-04, 5.8748e-04, 8.2342e-05, 7.7198e-05,
        5.8583e-05, 1.8542e-04, 1.3662e-04, 1.5603e-04, 1.2875e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,457][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([8.8874e-01, 2.6599e-02, 3.1872e-02, 6.8541e-03, 7.7620e-03, 2.6880e-03,
        1.5404e-02, 1.8964e-03, 1.5001e-03, 1.6231e-03, 9.5064e-04, 4.6639e-03,
        1.3923e-03, 2.6492e-03, 8.5483e-04, 1.2916e-03, 3.2617e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,458][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.3686e-05, 9.6500e-01, 3.1654e-02, 2.8683e-03, 2.7604e-04, 8.3690e-05,
        5.8310e-05, 9.1589e-06, 1.1952e-05, 1.6598e-05, 5.5395e-07, 2.7813e-07,
        5.5750e-07, 3.9791e-07, 1.1213e-06, 2.8155e-06, 1.6814e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,460][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([3.9150e-03, 7.8558e-01, 1.8220e-01, 9.0895e-03, 4.2403e-03, 3.5014e-03,
        6.3709e-03, 6.2727e-04, 1.5441e-03, 6.5698e-04, 5.9009e-05, 4.4795e-04,
        1.9542e-04, 1.3848e-04, 3.7919e-04, 3.4099e-04, 7.1185e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,463][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0223, 0.6080, 0.2309, 0.0414, 0.0129, 0.0127, 0.0143, 0.0112, 0.0100,
        0.0114, 0.0016, 0.0059, 0.0029, 0.0030, 0.0029, 0.0051, 0.0036],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,466][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([1.4051e-03, 7.8552e-01, 1.6544e-01, 2.4501e-02, 9.1297e-03, 4.4422e-03,
        3.9377e-03, 6.4043e-04, 7.7007e-04, 9.2644e-04, 1.9248e-04, 6.7784e-04,
        5.7198e-04, 3.9394e-04, 3.2213e-04, 5.7679e-04, 5.5049e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,469][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([4.9622e-06, 8.1918e-01, 1.6400e-01, 7.1443e-03, 3.9206e-03, 3.7233e-03,
        4.7390e-04, 1.5498e-04, 4.2564e-04, 2.6543e-04, 3.8168e-05, 1.0115e-04,
        7.3329e-05, 5.1382e-05, 1.1537e-04, 1.5986e-04, 1.6782e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:56,470][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.6340e-02, 1.3064e-04, 1.0367e-04, 3.4333e-03, 2.7136e-04, 3.0262e-05,
        1.1106e-03, 8.9705e-03, 2.1116e-03, 9.1928e-03, 3.4171e-01, 2.4988e-04,
        7.4385e-04, 6.6486e-05, 4.8026e-04, 7.0314e-03, 5.9589e-03, 6.0207e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,471][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.1149e-04, 8.7841e-01, 1.0370e-01, 1.1820e-02, 3.6955e-03, 6.1263e-04,
        5.7343e-04, 9.0616e-05, 2.7206e-04, 1.2626e-04, 3.0975e-05, 1.2956e-04,
        6.9493e-05, 1.5640e-04, 6.7390e-05, 4.2867e-05, 7.3803e-05, 1.7260e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,472][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1558, 0.2710, 0.1172, 0.0610, 0.0899, 0.0441, 0.0731, 0.0232, 0.0369,
        0.0098, 0.0026, 0.0250, 0.0127, 0.0133, 0.0311, 0.0084, 0.0194, 0.0055],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,474][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0008, 0.3785, 0.5317, 0.0151, 0.0459, 0.0054, 0.0049, 0.0012, 0.0019,
        0.0019, 0.0008, 0.0021, 0.0012, 0.0039, 0.0009, 0.0017, 0.0017, 0.0006],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,477][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.9981e-07, 9.6410e-01, 3.4682e-02, 9.0711e-04, 1.0724e-04, 1.1129e-04,
        5.6846e-05, 6.7910e-06, 5.8251e-06, 1.0358e-05, 1.2860e-06, 8.4211e-07,
        1.2094e-06, 2.7659e-07, 1.6417e-06, 1.5767e-06, 1.4621e-06, 1.7235e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,480][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.2563e-04, 8.0311e-01, 1.8308e-01, 5.4633e-03, 3.3268e-03, 2.8531e-03,
        1.3384e-03, 1.5792e-04, 2.4832e-04, 1.1421e-04, 1.3149e-05, 1.5431e-05,
        1.2386e-05, 3.0585e-05, 3.3742e-05, 3.3234e-05, 3.9298e-05, 2.6825e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,483][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.7315, 0.0933, 0.0590, 0.0161, 0.0094, 0.0113, 0.0298, 0.0067, 0.0050,
        0.0052, 0.0022, 0.0087, 0.0039, 0.0028, 0.0024, 0.0035, 0.0064, 0.0028],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,484][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.0249e-07, 9.7076e-01, 2.8556e-02, 5.5074e-04, 7.5220e-05, 3.0404e-05,
        1.6923e-05, 1.1919e-06, 2.6325e-06, 2.6479e-06, 7.8454e-08, 5.3825e-08,
        7.4247e-08, 8.8389e-08, 2.2342e-07, 4.9933e-07, 5.6852e-07, 4.0273e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,485][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.7937e-03, 7.9655e-01, 1.8016e-01, 8.6587e-03, 3.0841e-03, 2.3245e-03,
        4.2157e-03, 3.1283e-04, 9.7996e-04, 3.4191e-04, 3.2317e-05, 3.9983e-04,
        1.1917e-04, 7.5162e-05, 3.4834e-04, 2.0155e-04, 3.5696e-04, 4.2151e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,486][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.8748e-03, 6.6336e-01, 2.2008e-01, 3.8126e-02, 8.9213e-03, 9.4807e-03,
        1.0525e-02, 7.0176e-03, 8.7891e-03, 9.8667e-03, 1.3414e-03, 3.0544e-03,
        2.0571e-03, 1.2626e-03, 1.7210e-03, 3.5449e-03, 2.3714e-03, 6.0590e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,487][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.4272e-04, 8.7592e-01, 9.5156e-02, 1.7199e-02, 3.8048e-03, 2.9723e-03,
        1.8054e-03, 2.9918e-04, 4.4522e-04, 4.6008e-04, 9.2590e-05, 2.8787e-04,
        2.7304e-04, 1.1046e-04, 1.8739e-04, 2.5217e-04, 2.1768e-04, 6.9209e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,489][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.6308e-06, 8.5622e-01, 1.3333e-01, 4.8982e-03, 2.0393e-03, 2.4162e-03,
        2.5463e-04, 9.5228e-05, 2.0897e-04, 1.6108e-04, 2.4377e-05, 4.4432e-05,
        4.1924e-05, 1.3738e-05, 7.1314e-05, 7.2933e-05, 8.8434e-05, 1.9383e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:56,491][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([1.5722e-02, 1.9870e-04, 2.0814e-04, 3.5088e-03, 4.3818e-04, 4.4677e-05,
        2.5691e-03, 1.1710e-02, 3.2784e-03, 1.0178e-02, 3.3923e-01, 3.2810e-04,
        1.1666e-03, 1.2700e-04, 6.0724e-04, 8.8388e-03, 1.0600e-02, 5.9110e-01,
        1.5388e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,494][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([3.4668e-04, 6.3463e-01, 3.2566e-01, 1.4507e-02, 1.2252e-02, 1.4466e-03,
        2.8181e-03, 3.9294e-04, 1.9954e-03, 5.4595e-04, 2.2211e-04, 1.6261e-03,
        4.2511e-04, 1.1031e-03, 5.7916e-04, 3.8964e-04, 4.1603e-04, 1.7401e-04,
        4.6649e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,497][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.3034, 0.1762, 0.1084, 0.0357, 0.0953, 0.0417, 0.0634, 0.0089, 0.0221,
        0.0052, 0.0033, 0.0251, 0.0066, 0.0141, 0.0212, 0.0047, 0.0243, 0.0096,
        0.0308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,498][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0019, 0.2928, 0.5814, 0.0145, 0.0681, 0.0052, 0.0108, 0.0011, 0.0027,
        0.0018, 0.0010, 0.0028, 0.0014, 0.0062, 0.0012, 0.0018, 0.0025, 0.0008,
        0.0021], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,498][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([4.5226e-07, 9.1127e-01, 8.7019e-02, 9.5772e-04, 5.4032e-04, 1.3258e-04,
        4.9874e-05, 6.2829e-06, 3.3986e-06, 1.2021e-05, 2.1631e-06, 1.2866e-06,
        1.4357e-06, 3.8106e-07, 3.0417e-07, 1.1268e-06, 9.9810e-07, 1.9301e-07,
        1.0442e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,499][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([4.8718e-05, 7.7837e-01, 2.0710e-01, 6.2537e-03, 4.9213e-03, 1.8690e-03,
        1.0558e-03, 7.7473e-05, 1.5408e-04, 5.7579e-05, 1.2130e-05, 1.5811e-05,
        9.3064e-06, 8.4185e-06, 1.2712e-05, 9.8529e-06, 1.5041e-05, 1.5556e-06,
        6.6608e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,502][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.5371, 0.1086, 0.0950, 0.0312, 0.0242, 0.0210, 0.0717, 0.0120, 0.0106,
        0.0114, 0.0063, 0.0161, 0.0086, 0.0052, 0.0045, 0.0060, 0.0136, 0.0081,
        0.0089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,505][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([1.4512e-07, 8.9455e-01, 1.0444e-01, 6.6596e-04, 2.9242e-04, 3.2211e-05,
        1.2899e-05, 4.9800e-07, 1.6572e-06, 9.1250e-07, 7.3138e-08, 3.9034e-08,
        5.1036e-08, 2.5877e-08, 7.8158e-08, 1.0927e-07, 1.1810e-07, 1.6605e-08,
        1.0796e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,508][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([1.5543e-03, 7.3982e-01, 2.2142e-01, 1.0704e-02, 5.0611e-03, 5.5075e-03,
        9.2025e-03, 7.4041e-04, 1.7722e-03, 6.4934e-04, 1.2669e-04, 8.7098e-04,
        3.1452e-04, 1.1284e-04, 6.7053e-04, 3.8496e-04, 7.2853e-04, 1.5815e-04,
        1.9934e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,510][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.4206e-02, 6.5283e-01, 2.3442e-01, 2.4567e-02, 6.8336e-03, 1.0647e-02,
        1.3346e-02, 8.4810e-03, 7.1041e-03, 8.5123e-03, 1.5720e-03, 3.8245e-03,
        2.0693e-03, 1.2400e-03, 2.5373e-03, 2.4578e-03, 3.2093e-03, 5.7202e-04,
        1.5666e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,511][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([3.5199e-04, 7.7445e-01, 1.9094e-01, 1.8866e-02, 6.6554e-03, 2.4868e-03,
        2.9068e-03, 2.9653e-04, 7.9061e-04, 4.3083e-04, 9.8028e-05, 5.2696e-04,
        2.5207e-04, 1.2870e-04, 2.2019e-04, 1.8621e-04, 2.5299e-04, 6.0390e-05,
        9.3848e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,512][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([3.8158e-06, 7.5440e-01, 2.3491e-01, 4.2873e-03, 2.4965e-03, 2.7086e-03,
        3.0070e-04, 7.8010e-05, 2.2379e-04, 1.1855e-04, 3.1216e-05, 1.0467e-04,
        3.4339e-05, 2.1386e-05, 4.6722e-05, 5.7866e-05, 1.2103e-04, 1.9964e-05,
        3.0964e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:56,513][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.4536e-02, 2.4035e-04, 1.6834e-04, 5.4567e-03, 3.3886e-04, 5.0951e-05,
        2.2592e-03, 1.4020e-02, 3.0248e-03, 1.2473e-02, 3.3986e-01, 4.1597e-04,
        1.1552e-03, 9.1880e-05, 7.2251e-04, 9.7982e-03, 8.3773e-03, 5.7081e-01,
        1.2609e-04, 6.0742e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,514][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([6.1866e-05, 7.9634e-01, 1.8611e-01, 8.9146e-03, 5.7870e-03, 7.8005e-04,
        8.6213e-04, 5.6003e-05, 4.1456e-04, 7.6613e-05, 2.4755e-05, 2.1071e-04,
        4.9581e-05, 1.0401e-04, 5.2413e-05, 2.8727e-05, 5.2983e-05, 1.5010e-05,
        4.9669e-05, 1.3476e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,517][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2409, 0.3372, 0.1197, 0.0369, 0.0790, 0.0227, 0.0431, 0.0124, 0.0192,
        0.0056, 0.0019, 0.0118, 0.0068, 0.0096, 0.0154, 0.0047, 0.0110, 0.0046,
        0.0129, 0.0044], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,522][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0005, 0.4343, 0.4612, 0.0253, 0.0425, 0.0050, 0.0088, 0.0014, 0.0032,
        0.0023, 0.0009, 0.0021, 0.0014, 0.0029, 0.0011, 0.0019, 0.0019, 0.0006,
        0.0013, 0.0013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,524][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.1188e-06, 9.3535e-01, 6.2563e-02, 1.3927e-03, 3.4240e-04, 1.7237e-04,
        1.1421e-04, 1.2662e-05, 1.3976e-05, 2.0200e-05, 3.5268e-06, 1.9333e-06,
        2.1274e-06, 7.5504e-07, 2.8626e-06, 2.4285e-06, 4.3826e-06, 5.4302e-07,
        2.5575e-07, 3.3183e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,525][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.2504e-04, 7.1767e-01, 2.5681e-01, 8.8467e-03, 9.8034e-03, 3.0438e-03,
        2.1762e-03, 2.7117e-04, 3.8811e-04, 1.3988e-04, 2.4692e-05, 2.6181e-05,
        1.7727e-05, 7.3069e-05, 4.5869e-05, 3.3793e-05, 5.5110e-05, 4.4378e-06,
        3.0233e-05, 7.5812e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,526][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4898, 0.1830, 0.1278, 0.0169, 0.0174, 0.0087, 0.0761, 0.0076, 0.0077,
        0.0066, 0.0035, 0.0160, 0.0046, 0.0047, 0.0029, 0.0048, 0.0083, 0.0042,
        0.0055, 0.0041], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,527][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.5057e-06, 9.5569e-01, 4.2806e-02, 1.0920e-03, 3.0135e-04, 4.7906e-05,
        4.6248e-05, 2.1281e-06, 5.9945e-06, 4.5870e-06, 2.2003e-07, 8.7412e-08,
        1.7448e-07, 1.8642e-07, 2.6828e-07, 7.5347e-07, 8.2100e-07, 1.1454e-07,
        8.1351e-08, 1.0392e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,528][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.5412e-03, 7.3644e-01, 2.3086e-01, 1.0219e-02, 5.4867e-03, 3.2641e-03,
        6.8892e-03, 4.8072e-04, 1.8053e-03, 4.7408e-04, 5.4991e-05, 4.3243e-04,
        1.7681e-04, 1.0470e-04, 5.3940e-04, 2.3823e-04, 6.2574e-04, 5.6637e-05,
        2.0054e-04, 1.0624e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,531][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.7498e-03, 6.9061e-01, 1.9492e-01, 3.9363e-02, 9.2727e-03, 8.7261e-03,
        1.1675e-02, 6.1534e-03, 7.1552e-03, 7.7660e-03, 1.0200e-03, 3.8620e-03,
        1.9583e-03, 1.1412e-03, 1.5270e-03, 3.0392e-03, 2.1479e-03, 5.7247e-04,
        1.0691e-03, 1.2785e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,534][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.8045e-04, 8.4419e-01, 1.2175e-01, 1.8853e-02, 5.3469e-03, 2.7701e-03,
        2.8923e-03, 3.5811e-04, 7.0027e-04, 4.7280e-04, 1.0627e-04, 3.8037e-04,
        2.9543e-04, 1.3054e-04, 2.6125e-04, 2.6906e-04, 3.1258e-04, 7.0840e-05,
        7.6485e-05, 8.7005e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,537][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.4325e-06, 8.5893e-01, 1.2764e-01, 6.8551e-03, 2.9053e-03, 2.3989e-03,
        3.1659e-04, 9.4408e-05, 2.9486e-04, 1.3114e-04, 2.2360e-05, 5.4197e-05,
        3.5979e-05, 1.7679e-05, 8.3994e-05, 5.4155e-05, 1.0276e-04, 1.8193e-05,
        2.5131e-05, 1.6035e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:56,541][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:56,543][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4050],
        [ 371],
        [1217],
        [ 130],
        [ 433],
        [ 276],
        [  81],
        [  63],
        [ 667],
        [ 110],
        [ 220],
        [ 456],
        [  54],
        [ 134],
        [ 271],
        [  72],
        [ 211],
        [ 385],
        [  42],
        [  76]], device='cuda:0')
[2024-07-24 10:16:56,546][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[4171],
        [ 487],
        [3179],
        [  98],
        [ 781],
        [ 203],
        [  72],
        [  56],
        [ 487],
        [  94],
        [ 115],
        [ 387],
        [  41],
        [ 157],
        [ 146],
        [  65],
        [ 181],
        [ 166],
        [  43],
        [  80]], device='cuda:0')
[2024-07-24 10:16:56,550][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20743],
        [20765],
        [20929],
        [26161],
        [27308],
        [32710],
        [32796],
        [37332],
        [40239],
        [36869],
        [33751],
        [33981],
        [33650],
        [33822],
        [33895],
        [33907],
        [34542],
        [31823],
        [32020],
        [32060]], device='cuda:0')
[2024-07-24 10:16:56,553][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[17414],
        [15424],
        [31684],
        [44523],
        [38089],
        [45848],
        [30614],
        [39099],
        [34060],
        [43668],
        [33925],
        [27771],
        [38710],
        [28950],
        [33444],
        [36465],
        [30138],
        [23635],
        [41181],
        [30750]], device='cuda:0')
[2024-07-24 10:16:56,554][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5572],
        [ 4684],
        [ 4530],
        [ 8158],
        [ 8270],
        [14838],
        [16283],
        [13134],
        [18323],
        [11832],
        [16083],
        [15500],
        [13859],
        [14951],
        [16456],
        [13586],
        [16664],
        [16115],
        [15080],
        [13712]], device='cuda:0')
[2024-07-24 10:16:56,556][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14492],
        [38243],
        [40304],
        [43659],
        [43056],
        [43540],
        [43707],
        [44207],
        [43498],
        [43834],
        [42563],
        [43309],
        [42962],
        [43748],
        [42659],
        [43159],
        [42638],
        [42426],
        [42693],
        [42496]], device='cuda:0')
[2024-07-24 10:16:56,558][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[44006],
        [ 9998],
        [ 9994],
        [10010],
        [ 9994],
        [ 9990],
        [ 9981],
        [10016],
        [ 9980],
        [10153],
        [ 9955],
        [ 9967],
        [ 9968],
        [ 9879],
        [ 9915],
        [ 9994],
        [ 9940],
        [ 9953],
        [ 9865],
        [ 9904]], device='cuda:0')
[2024-07-24 10:16:56,561][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1120],
        [7250],
        [7875],
        [7765],
        [7865],
        [7829],
        [7904],
        [7878],
        [7981],
        [5941],
        [8082],
        [7960],
        [8058],
        [8265],
        [8259],
        [8045],
        [8230],
        [8318],
        [8370],
        [8506]], device='cuda:0')
[2024-07-24 10:16:56,565][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[14011],
        [13808],
        [15896],
        [47001],
        [18591],
        [30179],
        [37383],
        [37859],
        [32771],
        [31177],
        [32777],
        [34627],
        [32158],
        [24985],
        [33372],
        [32607],
        [27458],
        [30537],
        [36380],
        [37385]], device='cuda:0')
[2024-07-24 10:16:56,568][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20013],
        [40449],
        [40454],
        [40404],
        [40455],
        [40468],
        [40482],
        [40447],
        [40455],
        [40032],
        [40491],
        [40506],
        [40502],
        [40627],
        [40562],
        [40454],
        [40580],
        [40592],
        [40908],
        [40633]], device='cuda:0')
[2024-07-24 10:16:56,569][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11595],
        [ 1968],
        [ 2073],
        [ 2521],
        [ 2257],
        [ 2454],
        [ 2350],
        [ 3345],
        [ 2689],
        [ 3340],
        [ 2475],
        [ 2552],
        [ 2651],
        [ 2859],
        [ 2687],
        [ 3229],
        [ 2693],
        [ 2657],
        [ 2938],
        [ 2969]], device='cuda:0')
[2024-07-24 10:16:56,571][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[19951],
        [17527],
        [15172],
        [15172],
        [14845],
        [14897],
        [15340],
        [16089],
        [16206],
        [17273],
        [16346],
        [15851],
        [16051],
        [16885],
        [16845],
        [17291],
        [16174],
        [16252],
        [16504],
        [16423]], device='cuda:0')
[2024-07-24 10:16:56,573][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[35442],
        [40207],
        [38912],
        [37116],
        [38178],
        [36776],
        [35666],
        [34730],
        [35918],
        [34341],
        [36644],
        [33090],
        [34760],
        [34006],
        [34755],
        [33510],
        [31703],
        [35597],
        [30318],
        [34215]], device='cuda:0')
[2024-07-24 10:16:56,576][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 9135],
        [24098],
        [47876],
        [42073],
        [37264],
        [35451],
        [35286],
        [35386],
        [34895],
        [34330],
        [34145],
        [33263],
        [32778],
        [31660],
        [30585],
        [30867],
        [30512],
        [30953],
        [30565],
        [30715]], device='cuda:0')
[2024-07-24 10:16:56,580][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 7087],
        [ 4743],
        [  200],
        [ 6811],
        [ 1378],
        [ 7485],
        [ 2431],
        [ 1292],
        [ 7317],
        [ 2920],
        [ 9682],
        [ 5843],
        [ 2717],
        [ 1650],
        [10571],
        [ 2997],
        [ 6253],
        [15091],
        [ 5864],
        [ 3001]], device='cuda:0')
[2024-07-24 10:16:56,583][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23626],
        [23608],
        [23509],
        [33728],
        [35186],
        [41432],
        [37922],
        [22302],
        [22571],
        [29021],
        [42309],
        [42348],
        [42327],
        [42348],
        [42370],
        [42437],
        [42446],
        [45575],
        [45552],
        [45509]], device='cuda:0')
[2024-07-24 10:16:56,584][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[5690],
        [3506],
        [3350],
        [3520],
        [3033],
        [3465],
        [3427],
        [3303],
        [3405],
        [3615],
        [3315],
        [3356],
        [3393],
        [3384],
        [3334],
        [3363],
        [3281],
        [3383],
        [3519],
        [3342]], device='cuda:0')
[2024-07-24 10:16:56,586][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[28360],
        [25725],
        [18010],
        [ 5004],
        [ 5154],
        [ 2333],
        [  824],
        [ 1393],
        [  330],
        [ 1222],
        [  509],
        [  482],
        [  483],
        [  453],
        [  452],
        [  590],
        [  199],
        [  319],
        [  323],
        [  507]], device='cuda:0')
[2024-07-24 10:16:56,588][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18158],
        [ 9978],
        [10556],
        [11444],
        [11518],
        [11436],
        [10376],
        [11289],
        [10514],
        [11819],
        [11086],
        [10470],
        [10818],
        [11648],
        [10549],
        [11109],
        [ 9874],
        [10297],
        [10110],
        [10725]], device='cuda:0')
[2024-07-24 10:16:56,591][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3309],
        [27038],
        [27070],
        [27165],
        [27126],
        [27250],
        [27295],
        [27675],
        [27918],
        [27471],
        [27417],
        [27329],
        [27325],
        [28064],
        [27861],
        [27752],
        [27818],
        [27458],
        [28126],
        [27826]], device='cuda:0')
[2024-07-24 10:16:56,595][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[35145],
        [14470],
        [13644],
        [13641],
        [13588],
        [13402],
        [13611],
        [13361],
        [13606],
        [15471],
        [13741],
        [13752],
        [13777],
        [14102],
        [14148],
        [13917],
        [14046],
        [14206],
        [14388],
        [14678]], device='cuda:0')
[2024-07-24 10:16:56,598][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[8604],
        [8555],
        [7882],
        [2453],
        [6703],
        [2996],
        [3387],
        [3239],
        [3661],
        [3635],
        [3206],
        [3343],
        [3211],
        [4692],
        [3427],
        [3308],
        [4400],
        [3235],
        [3719],
        [3114]], device='cuda:0')
[2024-07-24 10:16:56,599][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[4051],
        [ 592],
        [ 594],
        [ 601],
        [ 596],
        [ 601],
        [ 603],
        [ 615],
        [ 616],
        [ 591],
        [ 602],
        [ 604],
        [ 604],
        [ 630],
        [ 621],
        [ 625],
        [ 628],
        [ 623],
        [ 689],
        [ 632]], device='cuda:0')
[2024-07-24 10:16:56,601][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4484],
        [12845],
        [13049],
        [13914],
        [13399],
        [13784],
        [13465],
        [14645],
        [13919],
        [14323],
        [13647],
        [13778],
        [13944],
        [14151],
        [13975],
        [14531],
        [13992],
        [13940],
        [14292],
        [14348]], device='cuda:0')
[2024-07-24 10:16:56,603][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[30550],
        [14774],
        [16398],
        [19428],
        [16896],
        [18770],
        [20191],
        [24590],
        [19717],
        [22224],
        [19738],
        [18807],
        [19535],
        [24948],
        [20229],
        [20824],
        [20646],
        [19691],
        [20145],
        [18984]], device='cuda:0')
[2024-07-24 10:16:56,606][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1563],
        [3132],
        [3477],
        [4088],
        [3717],
        [4202],
        [4476],
        [4815],
        [4419],
        [4939],
        [4167],
        [5218],
        [4722],
        [4999],
        [4785],
        [5237],
        [5777],
        [4452],
        [6129],
        [4899]], device='cuda:0')
[2024-07-24 10:16:56,610][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[  992],
        [14493],
        [14282],
        [12552],
        [13660],
        [12004],
        [10370],
        [ 9928],
        [11160],
        [11191],
        [11275],
        [ 9576],
        [10044],
        [11520],
        [11955],
        [11105],
        [10468],
        [11131],
        [ 9174],
        [11268]], device='cuda:0')
[2024-07-24 10:16:56,613][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[39267],
        [39287],
        [40694],
        [42312],
        [42813],
        [43899],
        [44214],
        [43251],
        [44927],
        [43171],
        [44995],
        [44965],
        [45048],
        [43079],
        [44648],
        [44374],
        [45364],
        [44982],
        [44553],
        [44341]], device='cuda:0')
[2024-07-24 10:16:56,614][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39052],
        [44661],
        [45162],
        [44508],
        [45880],
        [44887],
        [47969],
        [49240],
        [47821],
        [47800],
        [43018],
        [44225],
        [45821],
        [45632],
        [44424],
        [46438],
        [43206],
        [40632],
        [42490],
        [45819]], device='cuda:0')
[2024-07-24 10:16:56,616][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628],
        [2628]], device='cuda:0')
[2024-07-24 10:16:56,713][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:56,714][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,714][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,715][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,716][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,717][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,718][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,719][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,719][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,720][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,720][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,721][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,722][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:56,722][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8844, 0.1156], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,723][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7419, 0.2581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,724][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9928, 0.0072], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,724][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5420, 0.4580], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,725][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5944, 0.4056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,726][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,727][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0068, 0.9932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,727][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([5.6796e-05, 9.9994e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,729][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9618, 0.0382], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,734][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,736][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.6306e-05, 9.9990e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,736][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9738, 0.0262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:56,737][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.5019, 0.4802, 0.0179], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,738][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.5016, 0.2324, 0.2661], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,739][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.9555, 0.0369, 0.0076], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,740][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([1.2836e-03, 9.9826e-01, 4.6094e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,743][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.9136, 0.0830, 0.0034], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,747][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.9190, 0.0787, 0.0023], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,749][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0014, 0.7635, 0.2351], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,750][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([2.1088e-05, 9.9687e-01, 3.1058e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,751][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.6970, 0.1780, 0.1250], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,751][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([4.6951e-04, 3.1735e-01, 6.8218e-01], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,752][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([1.3726e-07, 9.9757e-01, 2.4269e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,754][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.8852, 0.0784, 0.0363], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:56,758][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4112, 0.3332, 0.0480, 0.2076], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,762][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0283, 0.1470, 0.8087, 0.0160], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,763][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7604, 0.0768, 0.0259, 0.1370], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,764][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3477, 0.4417, 0.0019, 0.2087], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,764][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4068, 0.2418, 0.0323, 0.3191], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,765][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8676, 0.0992, 0.0022, 0.0310], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,766][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([1.0823e-04, 2.1586e-01, 7.0067e-01, 8.3362e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,769][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0009, 0.9341, 0.0472, 0.0178], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,774][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7523, 0.0789, 0.0841, 0.0847], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,776][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.9221e-04, 1.9340e-01, 4.3335e-01, 3.7296e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,777][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([5.4800e-05, 9.4640e-01, 1.1581e-02, 4.1962e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,778][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6964, 0.0870, 0.1481, 0.0684], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:56,778][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.3652, 0.4173, 0.0904, 0.1019, 0.0253], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,779][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0923, 0.2385, 0.3961, 0.0071, 0.2661], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,780][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.5381, 0.3282, 0.0526, 0.0751, 0.0060], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,781][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ James] are: tensor([1.0481e-03, 9.6950e-01, 1.3714e-03, 2.8044e-02, 3.1208e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,785][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.9065, 0.0348, 0.0104, 0.0345, 0.0138], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,790][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.8036, 0.1640, 0.0074, 0.0185, 0.0065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,791][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ James] are: tensor([3.3627e-04, 5.8458e-01, 2.8368e-01, 6.2528e-02, 6.8871e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,791][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ James] are: tensor([2.3772e-05, 9.7908e-01, 1.1123e-02, 9.5619e-03, 2.1272e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,792][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.5316, 0.1552, 0.1241, 0.1156, 0.0735], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,793][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ James] are: tensor([2.0165e-04, 1.4930e-01, 3.3668e-01, 2.9530e-01, 2.1853e-01],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,794][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ James] are: tensor([1.0517e-07, 9.9076e-01, 3.8050e-03, 5.3968e-03, 3.4481e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,797][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.7564, 0.0806, 0.0566, 0.0536, 0.0528], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:56,801][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0882, 0.6287, 0.0840, 0.1028, 0.0260, 0.0704], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,804][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.1128, 0.2036, 0.4935, 0.0125, 0.1679, 0.0097], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,805][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.1393, 0.4447, 0.1825, 0.1509, 0.0287, 0.0539], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,805][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ were] are: tensor([2.2844e-02, 7.5248e-01, 1.0149e-02, 2.0901e-01, 4.7336e-04, 5.0488e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,806][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0797, 0.4215, 0.0286, 0.2984, 0.0582, 0.1135], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,807][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.7575, 0.1717, 0.0049, 0.0311, 0.0020, 0.0328], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,808][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ were] are: tensor([9.8036e-05, 3.7904e-01, 5.0273e-01, 3.5315e-02, 6.7148e-02, 1.5665e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,810][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ were] are: tensor([4.2323e-04, 8.9660e-01, 6.3945e-02, 3.1426e-02, 1.5579e-03, 6.0521e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,814][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.5728, 0.1024, 0.0991, 0.0942, 0.0692, 0.0623], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,818][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.0003, 0.1265, 0.2630, 0.2170, 0.1732, 0.2201], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,818][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ were] are: tensor([1.3026e-06, 9.7855e-01, 1.1117e-02, 1.0079e-02, 1.3591e-04, 1.1938e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,819][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.7921, 0.0375, 0.0550, 0.0354, 0.0461, 0.0339], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:56,820][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0797, 0.4975, 0.1558, 0.0430, 0.0226, 0.0471, 0.1542],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,821][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.1419, 0.2475, 0.4421, 0.0096, 0.1418, 0.0107, 0.0065],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,823][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.2456, 0.3677, 0.2060, 0.0823, 0.0152, 0.0225, 0.0607],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,825][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([3.1719e-03, 8.8318e-01, 1.6780e-02, 8.5436e-02, 7.9360e-04, 7.7608e-03,
        2.8802e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,830][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.2461, 0.2580, 0.0905, 0.1695, 0.0550, 0.1115, 0.0695],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,832][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.4470, 0.3435, 0.0132, 0.0373, 0.0067, 0.0440, 0.1084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,833][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([4.3623e-05, 1.6432e-01, 6.9966e-01, 2.6301e-02, 8.6051e-02, 1.4310e-02,
        9.3143e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,833][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([2.9244e-04, 8.2897e-01, 1.3149e-01, 1.8875e-02, 2.1386e-03, 1.7353e-02,
        8.8025e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,834][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.4086, 0.1330, 0.1329, 0.0957, 0.0780, 0.0761, 0.0757],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,835][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([1.0840e-04, 1.0131e-01, 2.5948e-01, 2.0768e-01, 1.6433e-01, 2.0948e-01,
        5.7601e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,836][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([2.6633e-07, 9.5691e-01, 3.1545e-02, 1.0676e-02, 3.9008e-04, 3.9643e-04,
        8.4219e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,841][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.8156, 0.0280, 0.0482, 0.0235, 0.0360, 0.0215, 0.0272],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:56,845][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.2708, 0.3890, 0.0948, 0.0519, 0.0156, 0.0213, 0.1145, 0.0420],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,846][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.3971, 0.1077, 0.3524, 0.0086, 0.1054, 0.0087, 0.0176, 0.0026],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,847][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.2033, 0.5335, 0.1484, 0.0467, 0.0069, 0.0130, 0.0387, 0.0095],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,848][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ about] are: tensor([9.1457e-01, 2.3027e-02, 1.0953e-03, 2.8065e-02, 4.4291e-04, 5.3962e-03,
        1.0264e-02, 1.7141e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,848][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.2750, 0.1773, 0.0216, 0.2488, 0.0406, 0.0742, 0.1135, 0.0490],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,851][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.9068, 0.0286, 0.0019, 0.0050, 0.0010, 0.0061, 0.0234, 0.0270],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,853][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ about] are: tensor([1.3562e-04, 2.3330e-01, 5.9232e-01, 3.8985e-02, 1.0101e-01, 1.0835e-02,
        1.5912e-02, 7.5120e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,858][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0233, 0.6054, 0.1968, 0.0777, 0.0091, 0.0754, 0.0100, 0.0023],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,859][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.4883, 0.1290, 0.1116, 0.0742, 0.0591, 0.0479, 0.0527, 0.0373],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,860][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ about] are: tensor([1.5116e-04, 1.0332e-01, 2.4014e-01, 1.9186e-01, 1.4901e-01, 1.7303e-01,
        5.1687e-02, 9.0807e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,861][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ about] are: tensor([4.5527e-04, 8.3385e-01, 7.2409e-02, 6.7444e-02, 4.0865e-03, 1.2557e-02,
        3.6457e-03, 5.5492e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,862][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.8178, 0.0245, 0.0360, 0.0292, 0.0309, 0.0221, 0.0237, 0.0157],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:56,862][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.1324, 0.4806, 0.0494, 0.0474, 0.0106, 0.0465, 0.0988, 0.0776, 0.0568],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,865][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.5625, 0.1881, 0.1435, 0.0096, 0.0643, 0.0080, 0.0159, 0.0026, 0.0054],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,870][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.1514, 0.5334, 0.0843, 0.0670, 0.0152, 0.0291, 0.0730, 0.0136, 0.0330],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,873][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.1987, 0.3871, 0.0276, 0.2493, 0.0072, 0.0272, 0.0399, 0.0544, 0.0083],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,874][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.4524, 0.1910, 0.0253, 0.0970, 0.0156, 0.0868, 0.0380, 0.0252, 0.0687],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,875][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.6694, 0.1366, 0.0026, 0.0274, 0.0028, 0.0151, 0.0721, 0.0604, 0.0137],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,875][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ going] are: tensor([3.0908e-04, 3.8560e-01, 4.4142e-01, 4.2410e-02, 5.2560e-02, 1.1127e-02,
        3.3614e-02, 1.1257e-02, 2.1696e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,876][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ going] are: tensor([2.1503e-03, 8.2216e-01, 1.1070e-01, 3.0461e-02, 4.9886e-03, 2.4290e-02,
        3.5973e-03, 4.8212e-04, 1.1700e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,879][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.5247, 0.0876, 0.0793, 0.0719, 0.0461, 0.0609, 0.0528, 0.0431, 0.0334],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,881][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ going] are: tensor([1.4390e-04, 9.7332e-02, 2.0100e-01, 1.7347e-01, 1.3283e-01, 1.6967e-01,
        5.2008e-02, 9.3699e-02, 7.9839e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,884][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ going] are: tensor([2.0986e-05, 8.5369e-01, 8.5539e-02, 5.2160e-02, 3.9416e-03, 2.7582e-03,
        9.2148e-04, 8.4218e-04, 1.2576e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,887][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.7817, 0.0296, 0.0379, 0.0274, 0.0316, 0.0240, 0.0286, 0.0167, 0.0225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:56,888][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1593, 0.4528, 0.0662, 0.0338, 0.0202, 0.0187, 0.0844, 0.0681, 0.0569,
        0.0395], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,889][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2693, 0.2886, 0.3159, 0.0076, 0.0862, 0.0071, 0.0150, 0.0026, 0.0064,
        0.0015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,889][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2398, 0.4894, 0.1088, 0.0426, 0.0076, 0.0168, 0.0523, 0.0111, 0.0255,
        0.0062], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,890][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.5871e-01, 2.6205e-03, 1.3730e-04, 9.1024e-03, 1.2983e-04, 2.0246e-03,
        5.5922e-03, 1.5208e-02, 1.9345e-03, 4.5401e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,893][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4266, 0.1661, 0.0220, 0.1469, 0.0195, 0.0636, 0.0552, 0.0301, 0.0504,
        0.0196], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,895][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.0585e-01, 2.1856e-02, 7.8126e-04, 4.6163e-03, 5.9288e-04, 7.5779e-03,
        2.7147e-02, 2.2995e-02, 5.1477e-03, 3.4374e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,898][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.4807e-04, 3.3573e-01, 5.5625e-01, 2.2287e-02, 4.5604e-02, 5.6564e-03,
        1.5931e-02, 2.9079e-03, 7.5698e-03, 7.9070e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,901][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0136, 0.7586, 0.1243, 0.0426, 0.0090, 0.0396, 0.0064, 0.0015, 0.0027,
        0.0017], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,902][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6728, 0.0672, 0.0664, 0.0410, 0.0343, 0.0265, 0.0345, 0.0232, 0.0181,
        0.0161], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,903][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1428e-04, 8.7393e-02, 2.0086e-01, 1.5541e-01, 1.2506e-01, 1.5171e-01,
        4.2923e-02, 7.6929e-02, 6.2786e-02, 9.6823e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,903][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0174, 0.6474, 0.0813, 0.1525, 0.0092, 0.0219, 0.0173, 0.0332, 0.0040,
        0.0158], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,904][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.8679, 0.0190, 0.0267, 0.0139, 0.0189, 0.0119, 0.0167, 0.0081, 0.0117,
        0.0052], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:56,906][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.0667e-02, 8.6071e-01, 5.8116e-02, 1.6718e-02, 5.4211e-03, 4.9781e-03,
        1.4616e-02, 7.5593e-03, 1.1843e-02, 8.5958e-03, 7.7702e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,908][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.3762e-01, 4.2757e-01, 3.4925e-01, 8.5508e-03, 5.9427e-02, 3.5333e-03,
        8.5812e-03, 1.2563e-03, 2.9683e-03, 9.4289e-04, 3.0190e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,911][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.4425e-02, 8.6075e-01, 7.9746e-02, 1.5737e-02, 4.3064e-03, 3.8722e-03,
        9.2396e-03, 2.1199e-03, 7.2189e-03, 1.9658e-03, 6.2077e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,915][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.4057e-02, 9.2482e-01, 1.7759e-02, 3.1204e-02, 6.5422e-04, 4.4583e-03,
        3.5202e-03, 2.1457e-03, 2.4239e-04, 1.0506e-03, 8.3823e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,915][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2492, 0.4497, 0.0172, 0.0650, 0.0102, 0.0497, 0.0373, 0.0273, 0.0475,
        0.0343, 0.0125], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,916][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.7823, 0.1011, 0.0043, 0.0115, 0.0012, 0.0118, 0.0454, 0.0294, 0.0073,
        0.0043, 0.0014], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,917][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([2.7223e-05, 4.8414e-01, 4.5420e-01, 1.2573e-02, 3.0198e-02, 2.1728e-03,
        4.2152e-03, 1.5686e-03, 3.3305e-03, 6.6481e-03, 9.2477e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,918][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([4.5551e-04, 8.8010e-01, 9.7873e-02, 9.6740e-03, 2.2340e-03, 8.3224e-03,
        6.9817e-04, 1.1750e-04, 2.9981e-04, 2.1264e-04, 1.7799e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,921][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.4943, 0.1322, 0.0898, 0.0551, 0.0418, 0.0406, 0.0431, 0.0304, 0.0267,
        0.0239, 0.0221], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,923][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([8.1333e-05, 8.1858e-02, 1.8283e-01, 1.4443e-01, 1.1912e-01, 1.4471e-01,
        3.9002e-02, 7.1994e-02, 5.8974e-02, 9.3430e-02, 6.3566e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,926][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.4838e-06, 9.6911e-01, 2.7896e-02, 2.3536e-03, 2.2569e-04, 3.0452e-04,
        4.3283e-05, 3.3791e-05, 3.6095e-06, 2.4635e-05, 9.8217e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,929][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.7901, 0.0327, 0.0397, 0.0221, 0.0248, 0.0168, 0.0238, 0.0116, 0.0187,
        0.0080, 0.0118], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:56,929][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ store] are: tensor([1.2130e-02, 8.1835e-01, 7.6785e-02, 1.8559e-02, 6.5945e-03, 4.6187e-03,
        1.9522e-02, 1.5610e-02, 1.4515e-02, 8.0339e-03, 6.9026e-04, 4.5931e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,930][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ store] are: tensor([3.0282e-02, 2.2603e-01, 5.1288e-01, 5.0112e-03, 2.0593e-01, 4.5396e-03,
        4.1919e-03, 6.6498e-04, 2.8251e-03, 1.0889e-03, 1.8323e-04, 6.3625e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,931][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ store] are: tensor([2.2792e-03, 8.4637e-01, 1.0646e-01, 1.2949e-02, 3.1787e-03, 3.0968e-03,
        1.1484e-02, 2.6234e-03, 7.8317e-03, 2.0071e-03, 4.8590e-04, 1.2324e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,932][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ store] are: tensor([3.7686e-05, 9.7512e-01, 1.3193e-02, 9.5949e-03, 4.3084e-04, 5.3969e-04,
        3.7406e-04, 3.7421e-04, 3.6174e-05, 2.4702e-04, 4.3853e-05, 4.3211e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,934][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1886, 0.1404, 0.0885, 0.2019, 0.0291, 0.1548, 0.0183, 0.0303, 0.0796,
        0.0194, 0.0107, 0.0384], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,939][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.1457, 0.6179, 0.0099, 0.0359, 0.0046, 0.0280, 0.0643, 0.0455, 0.0119,
        0.0093, 0.0016, 0.0255], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,942][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ store] are: tensor([9.0214e-06, 2.4645e-01, 6.8425e-01, 1.4617e-02, 2.8940e-02, 6.7639e-03,
        7.0649e-03, 1.6564e-03, 3.0568e-03, 3.8488e-03, 5.3367e-04, 2.8104e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,943][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ store] are: tensor([2.6414e-05, 8.8316e-01, 8.9344e-02, 1.6576e-02, 1.1057e-03, 8.7889e-03,
        7.0595e-04, 2.9756e-05, 1.4135e-04, 9.1214e-05, 1.1722e-05, 1.7413e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,944][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.3767, 0.1556, 0.0921, 0.0691, 0.0477, 0.0573, 0.0465, 0.0337, 0.0323,
        0.0324, 0.0256, 0.0311], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,945][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ store] are: tensor([9.6452e-05, 6.8129e-02, 1.6886e-01, 1.3661e-01, 1.0915e-01, 1.4126e-01,
        4.2188e-02, 7.5125e-02, 5.9751e-02, 9.2142e-02, 6.3519e-02, 4.3169e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,946][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ store] are: tensor([4.9040e-09, 9.6604e-01, 3.3160e-02, 5.8243e-04, 1.5840e-04, 3.1143e-05,
        1.5517e-05, 5.1698e-06, 6.2457e-07, 7.8358e-06, 3.7290e-07, 5.4610e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,948][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.7166, 0.0366, 0.0495, 0.0325, 0.0338, 0.0217, 0.0216, 0.0149, 0.0206,
        0.0101, 0.0201, 0.0220], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:56,953][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0279, 0.7063, 0.1414, 0.0235, 0.0182, 0.0099, 0.0217, 0.0169, 0.0140,
        0.0123, 0.0013, 0.0044, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,956][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([1.0577e-01, 3.8656e-01, 4.1506e-01, 4.3357e-03, 6.7525e-02, 3.4562e-03,
        5.5719e-03, 6.5929e-04, 1.9191e-03, 5.1662e-04, 1.5044e-04, 7.9346e-03,
        5.3682e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,957][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([4.7290e-02, 7.3058e-01, 1.5442e-01, 2.6511e-02, 4.1866e-03, 7.4317e-03,
        1.5420e-02, 2.6217e-03, 7.2771e-03, 1.3320e-03, 1.0114e-03, 1.2187e-03,
        7.0032e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,958][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([1.5375e-02, 9.0635e-01, 3.1931e-02, 3.5098e-02, 6.9649e-04, 4.7845e-03,
        2.8110e-03, 1.6342e-03, 2.1800e-04, 8.7044e-04, 6.2036e-05, 8.2117e-06,
        1.6115e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,959][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.2228, 0.3643, 0.0483, 0.1175, 0.0260, 0.0473, 0.0302, 0.0231, 0.0238,
        0.0146, 0.0155, 0.0297, 0.0368], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,960][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([7.4093e-01, 1.4696e-01, 3.3538e-03, 1.5238e-02, 1.4341e-03, 1.7577e-02,
        3.2729e-02, 2.5749e-02, 5.9082e-03, 4.9977e-03, 1.2250e-03, 3.5249e-03,
        3.7575e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,961][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([2.7803e-05, 2.4109e-01, 6.8662e-01, 9.2102e-03, 4.4797e-02, 2.2520e-03,
        4.2745e-03, 8.7972e-04, 1.9681e-03, 2.4447e-03, 6.9154e-04, 1.7530e-03,
        3.9906e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,964][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([8.8899e-05, 8.4647e-01, 1.3438e-01, 7.7070e-03, 2.1089e-03, 8.1069e-03,
        6.6470e-04, 7.1196e-05, 1.8881e-04, 1.0994e-04, 1.2338e-05, 3.3309e-05,
        5.0827e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,968][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.4677, 0.1291, 0.0943, 0.0505, 0.0441, 0.0341, 0.0404, 0.0260, 0.0242,
        0.0212, 0.0181, 0.0261, 0.0243], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,970][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([9.7998e-05, 7.4591e-02, 1.7143e-01, 1.2995e-01, 1.0517e-01, 1.2393e-01,
        3.5541e-02, 6.2793e-02, 5.2174e-02, 8.0478e-02, 5.6587e-02, 3.9223e-02,
        6.8031e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,971][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([3.5015e-06, 9.5013e-01, 4.6235e-02, 2.9058e-03, 1.7959e-04, 4.0471e-04,
        8.0134e-05, 3.4651e-05, 3.3844e-06, 1.8638e-05, 7.7662e-07, 2.1230e-07,
        2.7893e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,972][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.7812, 0.0305, 0.0483, 0.0171, 0.0270, 0.0141, 0.0181, 0.0103, 0.0131,
        0.0060, 0.0109, 0.0145, 0.0090], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:56,973][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0108, 0.7360, 0.1624, 0.0197, 0.0128, 0.0051, 0.0170, 0.0122, 0.0113,
        0.0063, 0.0010, 0.0030, 0.0011, 0.0011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,973][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ James] are: tensor([2.3577e-01, 4.4344e-01, 1.8611e-01, 5.4509e-03, 8.0876e-02, 3.4114e-03,
        2.1539e-03, 9.0103e-04, 1.3214e-03, 1.0231e-03, 1.5845e-04, 1.4121e-02,
        4.2177e-04, 2.4834e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,975][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ James] are: tensor([4.7193e-02, 7.7758e-01, 1.2639e-01, 2.0444e-02, 5.2340e-03, 3.4609e-03,
        9.3881e-03, 3.1660e-03, 4.1235e-03, 9.1018e-04, 4.8267e-04, 1.1186e-03,
        3.0480e-04, 2.0027e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,977][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ James] are: tensor([1.7510e-02, 7.9044e-01, 1.3985e-01, 2.7455e-02, 3.3726e-03, 7.0699e-03,
        8.8149e-03, 2.9286e-03, 7.8947e-04, 1.0284e-03, 2.8316e-04, 1.0236e-04,
        3.0033e-04, 5.4610e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,982][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.8647, 0.0479, 0.0107, 0.0152, 0.0086, 0.0067, 0.0045, 0.0046, 0.0050,
        0.0012, 0.0025, 0.0150, 0.0056, 0.0077], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,984][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ James] are: tensor([7.7031e-01, 1.0910e-01, 1.2474e-02, 1.5432e-02, 9.5503e-03, 1.0452e-02,
        3.0302e-02, 2.4052e-02, 8.2650e-03, 2.1052e-03, 6.4540e-04, 6.4090e-03,
        2.8879e-04, 6.0705e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,985][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ James] are: tensor([1.2651e-04, 6.2837e-01, 2.6343e-01, 3.3733e-02, 2.8512e-02, 8.1868e-03,
        3.5693e-03, 1.8874e-03, 2.3677e-03, 5.5785e-03, 1.1413e-03, 3.3986e-03,
        8.9403e-03, 1.0760e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,985][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ James] are: tensor([3.0787e-03, 8.0879e-01, 1.0540e-01, 4.7939e-02, 6.3318e-03, 2.2107e-02,
        3.6236e-03, 1.0625e-03, 3.7859e-04, 3.6152e-04, 1.2066e-04, 2.7049e-04,
        3.7173e-04, 1.7344e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,986][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.4035, 0.1486, 0.0878, 0.0639, 0.0392, 0.0435, 0.0385, 0.0278, 0.0279,
        0.0256, 0.0217, 0.0290, 0.0274, 0.0156], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,987][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ James] are: tensor([1.0423e-04, 7.0990e-02, 1.5016e-01, 1.2418e-01, 9.0628e-02, 1.2537e-01,
        3.2432e-02, 6.3440e-02, 4.8368e-02, 8.0553e-02, 5.3763e-02, 3.6755e-02,
        6.4983e-02, 5.8279e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,989][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ James] are: tensor([2.6653e-06, 8.6987e-01, 1.2081e-01, 6.9247e-03, 1.1927e-03, 8.2836e-04,
        2.3239e-04, 8.8256e-05, 8.6645e-06, 3.0284e-05, 2.9264e-06, 1.8794e-06,
        3.7214e-06, 4.6474e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,993][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.6917, 0.0622, 0.0377, 0.0292, 0.0261, 0.0199, 0.0167, 0.0137, 0.0165,
        0.0098, 0.0165, 0.0242, 0.0147, 0.0211], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:56,996][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([8.1890e-03, 7.7114e-01, 9.7736e-02, 2.1592e-02, 9.3862e-03, 1.2895e-02,
        2.3092e-02, 1.6837e-02, 1.9882e-02, 7.5773e-03, 1.0749e-03, 5.4507e-03,
        1.0701e-03, 5.0610e-04, 3.5675e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,997][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([2.8048e-01, 2.9996e-01, 2.8881e-01, 8.1742e-03, 7.2060e-02, 3.1412e-03,
        5.9561e-03, 1.0254e-03, 2.7564e-03, 8.3572e-04, 2.8557e-04, 1.2206e-02,
        8.7292e-04, 1.9834e-02, 3.6076e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,998][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([2.5901e-03, 8.5884e-01, 9.3842e-02, 1.5035e-02, 5.4203e-03, 3.4406e-03,
        9.0677e-03, 2.1565e-03, 5.2710e-03, 1.6914e-03, 4.0295e-04, 1.0884e-03,
        4.2687e-04, 1.8970e-04, 5.4179e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:56,999][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([1.2435e-02, 8.7529e-01, 3.8778e-02, 4.8063e-02, 1.6864e-03, 9.0258e-03,
        6.3740e-03, 3.9871e-03, 8.4184e-04, 2.0765e-03, 3.3502e-04, 7.2223e-05,
        5.6761e-04, 5.9656e-05, 4.0573e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,000][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.2231, 0.1887, 0.0226, 0.0426, 0.0201, 0.0459, 0.0252, 0.0209, 0.1251,
        0.0211, 0.0266, 0.1313, 0.0520, 0.0211, 0.0337], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,001][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([3.5733e-01, 4.4000e-01, 1.1424e-02, 2.9723e-02, 4.7342e-03, 2.4419e-02,
        6.4944e-02, 3.3430e-02, 1.0636e-02, 6.1441e-03, 1.8266e-03, 9.7553e-03,
        5.5895e-04, 2.7516e-04, 4.8003e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,003][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([2.5021e-05, 2.5137e-01, 6.4907e-01, 1.0581e-02, 3.5357e-02, 4.8736e-03,
        5.1379e-03, 1.7081e-03, 4.1388e-03, 4.1300e-03, 1.3092e-03, 4.2903e-03,
        6.1371e-03, 1.5911e-02, 5.9533e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,005][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([5.2825e-04, 7.6998e-01, 1.7606e-01, 2.4454e-02, 4.3226e-03, 2.1583e-02,
        1.5917e-03, 1.2812e-04, 4.9717e-04, 3.2399e-04, 3.7837e-05, 1.6227e-04,
        1.7595e-04, 7.6930e-05, 7.9247e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,011][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.4576, 0.1265, 0.0769, 0.0501, 0.0358, 0.0409, 0.0376, 0.0218, 0.0266,
        0.0210, 0.0215, 0.0272, 0.0233, 0.0136, 0.0195], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,012][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([4.8625e-05, 6.5318e-02, 1.4491e-01, 1.2011e-01, 8.9498e-02, 1.0918e-01,
        3.3958e-02, 6.0427e-02, 4.9610e-02, 7.8215e-02, 5.5003e-02, 3.5057e-02,
        6.4159e-02, 5.6604e-02, 3.7903e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,012][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([4.5988e-06, 9.0651e-01, 8.1482e-02, 1.0061e-02, 8.4213e-04, 6.6152e-04,
        2.4407e-04, 9.1107e-05, 1.5923e-05, 6.2880e-05, 3.6743e-06, 1.6311e-06,
        8.0918e-06, 7.9107e-07, 9.3220e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,013][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.8274, 0.0203, 0.0259, 0.0157, 0.0169, 0.0110, 0.0117, 0.0078, 0.0099,
        0.0051, 0.0093, 0.0094, 0.0071, 0.0145, 0.0081], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,014][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0269, 0.5937, 0.1581, 0.0238, 0.0347, 0.0128, 0.0571, 0.0363, 0.0243,
        0.0127, 0.0013, 0.0056, 0.0018, 0.0014, 0.0058, 0.0038],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,016][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3651e-01, 4.3050e-01, 3.0981e-01, 5.8143e-03, 8.4716e-02, 3.4311e-03,
        5.9650e-03, 1.0036e-03, 2.2489e-03, 4.8049e-04, 1.0171e-04, 6.0528e-03,
        2.9376e-04, 1.0062e-02, 2.0317e-03, 9.7017e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,018][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.0937e-02, 7.4627e-01, 1.6141e-01, 2.3552e-02, 6.4417e-03, 6.3342e-03,
        1.9365e-02, 3.2768e-03, 7.3181e-03, 1.3844e-03, 7.0597e-04, 1.2423e-03,
        5.6722e-04, 2.4556e-04, 5.5895e-04, 3.9259e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,021][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.4186e-01, 1.5782e-01, 1.3750e-02, 5.4511e-02, 2.4238e-03, 1.6970e-02,
        4.9942e-02, 2.9886e-02, 1.0250e-02, 6.8182e-03, 1.6372e-03, 2.7257e-04,
        2.8441e-03, 1.3894e-03, 6.6733e-03, 2.9486e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,025][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2175, 0.2526, 0.0409, 0.1372, 0.0269, 0.0784, 0.0363, 0.0293, 0.0367,
        0.0128, 0.0081, 0.0520, 0.0210, 0.0093, 0.0193, 0.0217],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,025][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.5582e-01, 1.2546e-01, 3.2083e-03, 1.4836e-02, 1.8937e-03, 2.2954e-02,
        8.2424e-02, 5.9994e-02, 9.7770e-03, 8.4429e-03, 1.9950e-03, 5.3793e-03,
        6.6011e-04, 3.3381e-04, 2.2480e-03, 4.5777e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,026][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.6045e-05, 3.8156e-01, 5.6091e-01, 1.2181e-02, 2.7655e-02, 2.1410e-03,
        5.0476e-03, 5.5186e-04, 1.5275e-03, 1.2233e-03, 1.9595e-04, 8.3229e-04,
        1.5619e-03, 2.5545e-03, 1.1922e-03, 8.4231e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,027][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([1.5293e-03, 7.3069e-01, 1.9518e-01, 2.8945e-02, 7.7708e-03, 2.9473e-02,
        2.6631e-03, 3.1684e-04, 1.1383e-03, 5.3593e-04, 6.1998e-05, 4.0531e-04,
        3.4025e-04, 3.0458e-04, 2.9374e-04, 3.5557e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,028][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.6430, 0.0827, 0.0727, 0.0332, 0.0272, 0.0209, 0.0241, 0.0128, 0.0125,
        0.0104, 0.0102, 0.0149, 0.0122, 0.0082, 0.0091, 0.0058],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,030][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.8939e-05, 6.5362e-02, 1.5095e-01, 1.1316e-01, 8.9434e-02, 1.0793e-01,
        2.9755e-02, 5.4495e-02, 4.2032e-02, 6.9722e-02, 4.7617e-02, 3.0743e-02,
        5.6180e-02, 5.1368e-02, 3.2331e-02, 5.8863e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,032][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.5093e-04, 8.1962e-01, 1.2602e-01, 3.2692e-02, 5.0331e-03, 7.0706e-03,
        4.2824e-03, 2.3646e-03, 6.7055e-04, 9.2865e-04, 7.5998e-05, 3.4254e-05,
        1.3767e-04, 6.7127e-05, 4.1262e-04, 3.3702e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,036][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.8153, 0.0200, 0.0301, 0.0147, 0.0184, 0.0113, 0.0151, 0.0079, 0.0107,
        0.0047, 0.0086, 0.0102, 0.0069, 0.0133, 0.0082, 0.0046],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,038][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ give] are: tensor([2.4828e-02, 6.9685e-01, 1.5030e-01, 3.0072e-02, 2.4020e-02, 6.4767e-03,
        1.7243e-02, 1.2160e-02, 1.1666e-02, 5.0964e-03, 4.5227e-04, 7.1534e-03,
        1.1617e-03, 2.0215e-03, 4.7163e-03, 2.2499e-03, 3.5324e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,039][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ give] are: tensor([1.5421e-01, 3.7073e-01, 3.6538e-01, 5.1998e-03, 6.6367e-02, 3.4822e-03,
        3.9538e-03, 6.2553e-04, 1.4365e-03, 8.8252e-04, 1.5102e-04, 4.9675e-03,
        6.2980e-04, 1.4967e-02, 1.8133e-03, 1.5402e-03, 3.6658e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,040][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ give] are: tensor([3.9227e-03, 8.2283e-01, 1.5722e-01, 6.6769e-03, 4.1456e-03, 1.0473e-03,
        1.7815e-03, 5.5043e-04, 7.8950e-04, 1.6579e-04, 4.5322e-05, 3.2052e-04,
        7.1270e-05, 7.9294e-05, 6.8011e-05, 6.5063e-05, 2.1357e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,041][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ give] are: tensor([4.8514e-02, 7.7083e-01, 6.1635e-02, 7.8487e-02, 2.4920e-03, 1.4548e-02,
        9.4461e-03, 6.7283e-03, 1.1182e-03, 2.1780e-03, 4.3189e-04, 1.0487e-04,
        1.0130e-03, 1.3814e-04, 1.1593e-03, 6.5712e-04, 5.2046e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,043][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.2219, 0.1790, 0.0197, 0.0860, 0.0188, 0.0609, 0.0559, 0.0221, 0.0672,
        0.0161, 0.0097, 0.0641, 0.0339, 0.0134, 0.0450, 0.0377, 0.0487],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,046][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ give] are: tensor([5.5279e-01, 2.5784e-01, 8.6232e-03, 2.4282e-02, 2.8244e-03, 2.2637e-02,
        5.7613e-02, 3.6243e-02, 8.5481e-03, 6.7298e-03, 1.3577e-03, 7.1353e-03,
        5.6348e-04, 2.0429e-04, 2.5907e-03, 3.1623e-03, 6.8605e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,049][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ give] are: tensor([1.6010e-05, 3.0407e-01, 6.3952e-01, 4.0568e-03, 3.4198e-02, 1.4509e-03,
        7.8053e-04, 4.3383e-04, 4.8399e-04, 1.3240e-03, 1.6012e-04, 7.4572e-04,
        1.2719e-03, 8.2145e-03, 7.7811e-04, 1.7444e-03, 7.4459e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,052][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ give] are: tensor([1.7212e-04, 7.6849e-01, 2.0131e-01, 1.0296e-02, 4.8419e-03, 1.2724e-02,
        7.0618e-04, 9.5939e-05, 3.2532e-04, 2.9171e-04, 2.1514e-05, 1.0360e-04,
        1.1360e-04, 1.0295e-04, 6.8141e-05, 1.8906e-04, 1.5482e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,053][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.4389, 0.1388, 0.0986, 0.0414, 0.0353, 0.0380, 0.0339, 0.0207, 0.0219,
        0.0181, 0.0185, 0.0223, 0.0183, 0.0119, 0.0140, 0.0101, 0.0191],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,054][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ give] are: tensor([3.3528e-05, 5.6818e-02, 1.3623e-01, 1.1348e-01, 8.7098e-02, 1.1207e-01,
        2.7791e-02, 5.4690e-02, 3.9682e-02, 6.9281e-02, 4.6357e-02, 2.9826e-02,
        5.5189e-02, 5.3281e-02, 3.1239e-02, 6.1025e-02, 2.5913e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,054][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ give] are: tensor([1.1274e-05, 8.6448e-01, 1.2062e-01, 1.1330e-02, 1.9621e-03, 9.5947e-04,
        2.9475e-04, 1.2427e-04, 2.1555e-05, 1.0035e-04, 4.1559e-06, 1.4668e-06,
        9.6658e-06, 3.3877e-06, 3.3141e-05, 3.1019e-05, 9.7430e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,055][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.7381, 0.0210, 0.0316, 0.0217, 0.0209, 0.0134, 0.0160, 0.0121, 0.0164,
        0.0074, 0.0158, 0.0148, 0.0111, 0.0239, 0.0126, 0.0071, 0.0160],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,057][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([4.8862e-03, 7.8313e-01, 1.5053e-01, 1.8600e-02, 1.1100e-02, 2.7654e-03,
        1.0994e-02, 4.1192e-03, 4.4464e-03, 2.5226e-03, 2.7671e-04, 1.8170e-03,
        5.3359e-04, 2.4002e-04, 1.3939e-03, 6.8019e-04, 1.8026e-03, 1.6199e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,060][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.1834e-02, 7.5199e-01, 1.8592e-01, 5.0902e-03, 2.9214e-02, 2.0688e-03,
        2.7204e-03, 3.8158e-04, 1.0554e-03, 4.1824e-04, 5.3460e-05, 3.0973e-03,
        2.5064e-04, 2.5023e-03, 1.3137e-03, 5.6694e-04, 1.3836e-03, 1.3454e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,063][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.2652e-03, 8.6286e-01, 1.2544e-01, 4.6393e-03, 1.6552e-03, 6.0564e-04,
        1.8120e-03, 3.3648e-04, 5.8739e-04, 1.9045e-04, 4.7031e-05, 1.7114e-04,
        7.1073e-05, 2.5892e-05, 6.6194e-05, 4.3509e-05, 1.6028e-04, 2.6381e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,066][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([5.8881e-05, 9.7259e-01, 2.4163e-02, 2.1497e-03, 9.9496e-05, 4.5331e-04,
        3.1934e-04, 5.7777e-05, 1.9835e-05, 3.3551e-05, 2.2213e-06, 5.7708e-07,
        1.1072e-05, 1.0296e-06, 1.3130e-05, 9.8348e-06, 1.2804e-05, 4.5615e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,068][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2002, 0.4589, 0.0236, 0.0745, 0.0154, 0.0480, 0.0137, 0.0184, 0.0106,
        0.0104, 0.0087, 0.0365, 0.0205, 0.0083, 0.0128, 0.0188, 0.0145, 0.0064],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,069][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.2124e-01, 4.5675e-01, 1.1703e-02, 2.3750e-02, 2.8458e-03, 3.0211e-02,
        7.9415e-02, 4.1421e-02, 7.3030e-03, 7.1574e-03, 1.1812e-03, 4.2621e-03,
        3.9118e-04, 1.2573e-04, 1.4895e-03, 3.2768e-03, 4.9488e-03, 2.5335e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,070][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.1855e-06, 7.2353e-01, 2.5372e-01, 5.7707e-03, 1.1334e-02, 9.5528e-04,
        7.1887e-04, 1.7204e-04, 2.8829e-04, 5.0101e-04, 5.5681e-05, 2.9592e-04,
        5.5483e-04, 6.5953e-04, 6.2721e-04, 3.6166e-04, 4.1533e-04, 3.4390e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,071][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([8.8607e-06, 8.6411e-01, 1.2427e-01, 5.1729e-03, 2.5647e-03, 3.4201e-03,
        1.6313e-04, 1.5166e-05, 5.6084e-05, 3.7338e-05, 2.9249e-06, 3.1881e-05,
        2.4595e-05, 1.7760e-05, 3.1941e-05, 3.1852e-05, 3.5737e-05, 9.5583e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,074][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4820, 0.1452, 0.0928, 0.0457, 0.0320, 0.0310, 0.0317, 0.0168, 0.0166,
        0.0147, 0.0130, 0.0157, 0.0143, 0.0085, 0.0102, 0.0072, 0.0127, 0.0098],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,076][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.6941e-05, 6.0458e-02, 1.4117e-01, 1.2106e-01, 8.3737e-02, 1.1364e-01,
        2.5553e-02, 5.0653e-02, 3.7207e-02, 6.7581e-02, 4.3149e-02, 2.6554e-02,
        5.2949e-02, 4.4444e-02, 2.7531e-02, 5.6523e-02, 2.1893e-02, 2.5888e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,079][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.6876e-09, 9.7143e-01, 2.8208e-02, 2.8024e-04, 4.5723e-05, 2.8206e-05,
        5.9293e-06, 8.3240e-07, 2.8383e-07, 8.3637e-07, 2.9200e-08, 9.5564e-09,
        1.1006e-07, 1.5442e-08, 2.8762e-07, 2.1316e-07, 1.5488e-07, 5.3627e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,082][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.6106, 0.0472, 0.0624, 0.0282, 0.0331, 0.0222, 0.0270, 0.0141, 0.0192,
        0.0089, 0.0153, 0.0200, 0.0148, 0.0255, 0.0147, 0.0082, 0.0165, 0.0121],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,083][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([2.7189e-02, 6.9245e-01, 1.2461e-01, 2.9582e-02, 1.2503e-02, 3.4105e-03,
        4.5658e-02, 1.4718e-02, 1.4233e-02, 5.9529e-03, 1.4573e-03, 6.1478e-03,
        1.5915e-03, 7.0994e-04, 6.9120e-03, 1.8837e-03, 8.4884e-03, 6.8118e-04,
        1.8207e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,083][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([3.8044e-02, 5.3288e-01, 3.0505e-01, 4.2722e-03, 7.5204e-02, 4.8454e-03,
        1.9092e-03, 3.8755e-04, 9.1079e-04, 1.1278e-03, 1.2091e-04, 5.2401e-03,
        4.5089e-04, 1.7650e-02, 1.7533e-03, 2.1901e-03, 4.5478e-03, 6.0365e-04,
        2.8209e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,084][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([1.5895e-03, 8.9611e-01, 8.7570e-02, 6.4213e-03, 2.0905e-03, 9.4607e-04,
        2.3878e-03, 5.3600e-04, 1.0420e-03, 3.0040e-04, 1.0261e-04, 2.3116e-04,
        1.0511e-04, 3.7580e-05, 8.4722e-05, 7.6287e-05, 2.6808e-04, 5.7521e-05,
        4.3737e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,086][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([6.7044e-05, 8.5497e-01, 1.3313e-01, 8.3234e-03, 1.9222e-03, 8.1512e-04,
        5.1697e-04, 8.0082e-05, 4.6051e-05, 3.6338e-05, 1.4306e-05, 9.4843e-06,
        2.4638e-05, 1.1379e-06, 9.6447e-06, 5.6740e-06, 1.8760e-05, 1.3219e-06,
        3.2461e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,089][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.2192, 0.1786, 0.0592, 0.0965, 0.0250, 0.0862, 0.0244, 0.0180, 0.0274,
        0.0189, 0.0117, 0.0588, 0.0279, 0.0167, 0.0205, 0.0314, 0.0359, 0.0203,
        0.0235], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,092][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([2.1719e-01, 5.6343e-01, 1.4722e-02, 3.0188e-02, 4.8710e-03, 3.2167e-02,
        6.8246e-02, 2.8205e-02, 8.3171e-03, 7.3839e-03, 1.9846e-03, 7.6209e-03,
        9.0440e-04, 2.2386e-04, 1.4132e-03, 2.5730e-03, 3.5209e-03, 3.5697e-03,
        3.4647e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,095][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([3.9618e-06, 4.4122e-01, 4.9849e-01, 9.7082e-03, 2.3321e-02, 4.2125e-03,
        1.5423e-03, 8.9584e-04, 7.7563e-04, 2.9273e-03, 3.2755e-04, 1.4950e-03,
        3.6147e-03, 5.3753e-03, 1.3721e-03, 2.9511e-03, 1.2261e-03, 2.5583e-04,
        2.9283e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,096][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([3.2090e-05, 7.0958e-01, 2.5546e-01, 1.6613e-02, 6.7855e-03, 9.6942e-03,
        9.6992e-04, 5.8561e-05, 2.0237e-04, 1.0050e-04, 3.1393e-05, 7.2639e-05,
        8.8678e-05, 4.5394e-05, 4.4820e-05, 5.0442e-05, 1.1952e-04, 3.2156e-05,
        1.5951e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,097][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.3167, 0.1606, 0.0994, 0.0582, 0.0419, 0.0489, 0.0378, 0.0237, 0.0289,
        0.0237, 0.0174, 0.0286, 0.0204, 0.0122, 0.0150, 0.0126, 0.0237, 0.0164,
        0.0140], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,098][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.7567e-05, 4.7325e-02, 1.2302e-01, 1.0406e-01, 7.5545e-02, 1.1262e-01,
        2.6424e-02, 5.5453e-02, 4.2502e-02, 7.4463e-02, 4.7527e-02, 2.7555e-02,
        5.4499e-02, 4.9641e-02, 2.8499e-02, 6.2694e-02, 2.3120e-02, 2.7374e-02,
        1.7662e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,099][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([1.0726e-08, 7.2780e-01, 2.7058e-01, 8.9227e-04, 5.9223e-04, 9.7970e-05,
        3.1960e-05, 1.8560e-06, 7.9211e-07, 1.5906e-06, 3.2635e-07, 1.2400e-07,
        4.8609e-07, 2.1298e-08, 6.1344e-07, 2.7365e-07, 2.4589e-07, 2.2760e-08,
        2.1847e-09], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,102][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.5455, 0.0506, 0.0750, 0.0328, 0.0355, 0.0265, 0.0220, 0.0140, 0.0198,
        0.0108, 0.0225, 0.0188, 0.0172, 0.0266, 0.0160, 0.0096, 0.0203, 0.0155,
        0.0211], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,105][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.8376e-03, 7.1913e-01, 1.9771e-01, 1.1825e-02, 2.3346e-02, 4.2055e-03,
        1.5820e-02, 7.1794e-03, 6.3991e-03, 3.1419e-03, 2.9132e-04, 1.5868e-03,
        5.1794e-04, 3.9275e-04, 1.4817e-03, 8.6327e-04, 2.2758e-03, 1.8765e-04,
        4.8173e-04, 3.2233e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,109][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.3232e-02, 6.9600e-01, 2.2390e-01, 3.6537e-03, 3.9869e-02, 2.1447e-03,
        2.0160e-03, 3.7179e-04, 6.4381e-04, 2.4010e-04, 3.6747e-05, 2.1195e-03,
        1.3647e-04, 2.6288e-03, 8.0232e-04, 4.6243e-04, 8.8384e-04, 9.9082e-05,
        5.1359e-04, 2.3873e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,110][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.2526e-04, 8.6179e-01, 1.2406e-01, 4.9940e-03, 2.2049e-03, 9.6191e-04,
        2.7203e-03, 3.8082e-04, 9.0293e-04, 1.8789e-04, 6.6158e-05, 1.8567e-04,
        8.0935e-05, 2.6695e-05, 9.1148e-05, 5.2329e-05, 2.7937e-04, 3.6241e-05,
        4.3013e-05, 1.7822e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,111][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.4811e-04, 9.1472e-01, 7.5267e-02, 5.9990e-03, 1.0109e-03, 7.7389e-04,
        1.4873e-03, 1.2988e-04, 8.8587e-05, 4.9058e-05, 9.8870e-06, 2.4815e-06,
        2.8148e-05, 4.6943e-06, 3.3498e-05, 1.1496e-05, 3.3777e-05, 1.4333e-06,
        6.2886e-07, 1.3481e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,111][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0763, 0.4007, 0.0396, 0.0887, 0.0226, 0.0678, 0.0248, 0.0229, 0.0300,
        0.0117, 0.0057, 0.0456, 0.0193, 0.0077, 0.0206, 0.0214, 0.0420, 0.0083,
        0.0264, 0.0179], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,113][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.9777e-01, 4.1684e-01, 1.0477e-02, 2.3083e-02, 3.3101e-03, 3.3476e-02,
        1.0642e-01, 5.6219e-02, 1.0730e-02, 9.9131e-03, 2.0847e-03, 6.2191e-03,
        7.6449e-04, 2.9136e-04, 2.3745e-03, 5.0998e-03, 6.6528e-03, 3.4509e-03,
        1.8393e-03, 2.9842e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,114][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([3.8224e-06, 5.0759e-01, 4.6400e-01, 5.4820e-03, 1.6113e-02, 9.3572e-04,
        1.2768e-03, 1.7623e-04, 4.2874e-04, 5.3611e-04, 5.8186e-05, 2.5238e-04,
        5.8231e-04, 8.6720e-04, 4.1077e-04, 4.0307e-04, 5.9095e-04, 3.1761e-05,
        1.2548e-04, 1.3478e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,117][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.2384e-05, 7.5659e-01, 2.2767e-01, 6.2141e-03, 3.2880e-03, 5.4621e-03,
        3.8623e-04, 1.8220e-05, 9.1998e-05, 4.1604e-05, 4.3886e-06, 3.4033e-05,
        2.8201e-05, 1.9916e-05, 2.2774e-05, 2.6253e-05, 4.7758e-05, 8.5640e-06,
        9.4072e-06, 1.4472e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,122][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5232, 0.1286, 0.1061, 0.0388, 0.0322, 0.0239, 0.0251, 0.0122, 0.0127,
        0.0105, 0.0099, 0.0138, 0.0113, 0.0075, 0.0082, 0.0055, 0.0118, 0.0074,
        0.0061, 0.0053], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,123][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.5951e-05, 5.7444e-02, 1.4149e-01, 1.0898e-01, 8.2231e-02, 1.0300e-01,
        2.4272e-02, 4.7050e-02, 3.5252e-02, 6.2558e-02, 4.0601e-02, 2.5005e-02,
        4.9304e-02, 4.4640e-02, 2.6245e-02, 5.2690e-02, 2.1409e-02, 2.4642e-02,
        1.5631e-02, 3.7537e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,124][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.6135e-08, 8.5768e-01, 1.4048e-01, 1.1397e-03, 5.2031e-04, 1.3329e-04,
        4.1595e-05, 3.6659e-06, 2.0778e-06, 2.2445e-06, 1.6393e-07, 1.0561e-07,
        4.0586e-07, 8.4425e-08, 8.9581e-07, 4.9491e-07, 4.4882e-07, 2.0356e-08,
        7.8131e-09, 2.7703e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,125][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.7075, 0.0360, 0.0453, 0.0202, 0.0225, 0.0147, 0.0172, 0.0098, 0.0130,
        0.0061, 0.0109, 0.0135, 0.0093, 0.0170, 0.0096, 0.0059, 0.0127, 0.0081,
        0.0139, 0.0068], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,208][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:57,208][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,210][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,210][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,211][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,212][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,212][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,213][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,214][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,214][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,215][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,216][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,216][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,217][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8844, 0.1156], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,218][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.7419, 0.2581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,218][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9928, 0.0072], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,221][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5420, 0.4580], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,226][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5944, 0.4056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,228][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,228][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0068, 0.9932], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,229][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([5.6796e-05, 9.9994e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,230][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9877, 0.0123], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,230][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,231][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.6306e-05, 9.9990e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,235][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5084, 0.4916], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,239][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.5019, 0.4802, 0.0179], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,241][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.5016, 0.2324, 0.2661], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,242][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.9555, 0.0369, 0.0076], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,242][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([1.2836e-03, 9.9826e-01, 4.6094e-04], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,243][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.9136, 0.0830, 0.0034], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,244][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.9190, 0.0787, 0.0023], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,246][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0014, 0.7635, 0.2351], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,248][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([2.1088e-05, 9.9687e-01, 3.1058e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,253][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.3745, 0.5584, 0.0671], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,254][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0011, 0.2722, 0.7267], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,255][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([1.3726e-07, 9.9757e-01, 2.4269e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,256][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.2681, 0.6748, 0.0572], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,256][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4112, 0.3332, 0.0480, 0.2076], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,257][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0283, 0.1470, 0.8087, 0.0160], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,260][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7604, 0.0768, 0.0259, 0.1370], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,264][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3477, 0.4417, 0.0019, 0.2087], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,268][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4068, 0.2418, 0.0323, 0.3191], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,268][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8676, 0.0992, 0.0022, 0.0310], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,269][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.0823e-04, 2.1586e-01, 7.0067e-01, 8.3362e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,270][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0009, 0.9341, 0.0472, 0.0178], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,271][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8420, 0.0898, 0.0307, 0.0375], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,272][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([3.5950e-05, 3.4200e-02, 8.8995e-01, 7.5818e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,275][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([5.4800e-05, 9.4640e-01, 1.1581e-02, 4.1962e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,279][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0404, 0.3546, 0.4438, 0.1612], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,281][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.3652, 0.4173, 0.0904, 0.1019, 0.0253], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,282][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0923, 0.2385, 0.3961, 0.0071, 0.2661], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,283][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.5381, 0.3282, 0.0526, 0.0751, 0.0060], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,283][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([1.0481e-03, 9.6950e-01, 1.3714e-03, 2.8044e-02, 3.1208e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,284][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.9065, 0.0348, 0.0104, 0.0345, 0.0138], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,286][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.8036, 0.1640, 0.0074, 0.0185, 0.0065], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,289][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([3.3627e-04, 5.8458e-01, 2.8368e-01, 6.2528e-02, 6.8871e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,292][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([2.3772e-05, 9.7908e-01, 1.1123e-02, 9.5619e-03, 2.1272e-04],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,294][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.1770, 0.6380, 0.1145, 0.0603, 0.0102], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,295][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([4.0629e-05, 8.8146e-02, 7.7029e-01, 4.7811e-02, 9.3711e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,296][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([1.0517e-07, 9.9076e-01, 3.8050e-03, 5.3968e-03, 3.4481e-05],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,296][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0344, 0.5104, 0.0742, 0.1903, 0.1906], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,297][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0882, 0.6287, 0.0840, 0.1028, 0.0260, 0.0704], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,299][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.1128, 0.2036, 0.4935, 0.0125, 0.1679, 0.0097], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,303][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.1393, 0.4447, 0.1825, 0.1509, 0.0287, 0.0539], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,306][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([2.2844e-02, 7.5248e-01, 1.0149e-02, 2.0901e-01, 4.7336e-04, 5.0488e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,308][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0797, 0.4215, 0.0286, 0.2984, 0.0582, 0.1135], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,309][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.7575, 0.1717, 0.0049, 0.0311, 0.0020, 0.0328], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,309][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([9.8036e-05, 3.7904e-01, 5.0273e-01, 3.5315e-02, 6.7148e-02, 1.5665e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,310][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([4.2323e-04, 8.9660e-01, 6.3945e-02, 3.1426e-02, 1.5579e-03, 6.0521e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,311][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.1023, 0.5029, 0.2388, 0.0669, 0.0678, 0.0212], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,312][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([5.6202e-05, 9.1037e-02, 6.6288e-01, 4.4341e-02, 1.3210e-01, 6.9593e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,315][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([1.3026e-06, 9.7855e-01, 1.1117e-02, 1.0079e-02, 1.3591e-04, 1.1938e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,319][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0424, 0.2288, 0.1580, 0.1406, 0.2557, 0.1745], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,321][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0797, 0.4975, 0.1558, 0.0430, 0.0226, 0.0471, 0.1542],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,322][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.1419, 0.2475, 0.4421, 0.0096, 0.1418, 0.0107, 0.0065],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,323][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.2456, 0.3677, 0.2060, 0.0823, 0.0152, 0.0225, 0.0607],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,323][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([3.1719e-03, 8.8318e-01, 1.6780e-02, 8.5436e-02, 7.9360e-04, 7.7608e-03,
        2.8802e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,324][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.2461, 0.2580, 0.0905, 0.1695, 0.0550, 0.1115, 0.0695],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,327][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.4470, 0.3435, 0.0132, 0.0373, 0.0067, 0.0440, 0.1084],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,329][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([4.3623e-05, 1.6432e-01, 6.9966e-01, 2.6301e-02, 8.6051e-02, 1.4310e-02,
        9.3143e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,332][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([2.9244e-04, 8.2897e-01, 1.3149e-01, 1.8875e-02, 2.1386e-03, 1.7353e-02,
        8.8025e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,334][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0881, 0.4241, 0.3283, 0.0420, 0.0615, 0.0320, 0.0239],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,335][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([8.2648e-05, 3.6248e-02, 7.4240e-01, 2.4241e-02, 1.1022e-01, 5.7127e-02,
        2.9687e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,336][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([2.6633e-07, 9.5691e-01, 3.1545e-02, 1.0676e-02, 3.9008e-04, 3.9643e-04,
        8.4219e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,337][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0932, 0.1484, 0.1640, 0.0746, 0.2232, 0.0956, 0.2011],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,337][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.2708, 0.3890, 0.0948, 0.0519, 0.0156, 0.0213, 0.1145, 0.0420],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,340][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.3971, 0.1077, 0.3524, 0.0086, 0.1054, 0.0087, 0.0176, 0.0026],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,344][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.2033, 0.5335, 0.1484, 0.0467, 0.0069, 0.0130, 0.0387, 0.0095],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,348][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([9.1457e-01, 2.3027e-02, 1.0953e-03, 2.8065e-02, 4.4291e-04, 5.3962e-03,
        1.0264e-02, 1.7141e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,348][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.2750, 0.1773, 0.0216, 0.2488, 0.0406, 0.0742, 0.1135, 0.0490],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,349][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.9068, 0.0286, 0.0019, 0.0050, 0.0010, 0.0061, 0.0234, 0.0270],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,350][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([1.3562e-04, 2.3330e-01, 5.9232e-01, 3.8985e-02, 1.0101e-01, 1.0835e-02,
        1.5912e-02, 7.5120e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,351][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0233, 0.6054, 0.1968, 0.0777, 0.0091, 0.0754, 0.0100, 0.0023],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,353][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.2278, 0.4754, 0.2020, 0.0419, 0.0202, 0.0105, 0.0085, 0.0136],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,356][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([3.0902e-05, 5.0863e-02, 8.2499e-01, 2.1064e-02, 7.3817e-02, 1.4135e-02,
        1.2300e-02, 2.8025e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,359][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([4.5527e-04, 8.3385e-01, 7.2409e-02, 6.7444e-02, 4.0865e-03, 1.2557e-02,
        3.6457e-03, 5.5492e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,361][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.1442, 0.1146, 0.0895, 0.1486, 0.1490, 0.0954, 0.1419, 0.1170],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,362][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.1324, 0.4806, 0.0494, 0.0474, 0.0106, 0.0465, 0.0988, 0.0776, 0.0568],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,363][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.5625, 0.1881, 0.1435, 0.0096, 0.0643, 0.0080, 0.0159, 0.0026, 0.0054],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,363][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.1514, 0.5334, 0.0843, 0.0670, 0.0152, 0.0291, 0.0730, 0.0136, 0.0330],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,364][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.1987, 0.3871, 0.0276, 0.2493, 0.0072, 0.0272, 0.0399, 0.0544, 0.0083],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,367][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.4524, 0.1910, 0.0253, 0.0970, 0.0156, 0.0868, 0.0380, 0.0252, 0.0687],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,371][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.6694, 0.1366, 0.0026, 0.0274, 0.0028, 0.0151, 0.0721, 0.0604, 0.0137],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,375][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([3.0908e-04, 3.8560e-01, 4.4142e-01, 4.2410e-02, 5.2560e-02, 1.1127e-02,
        3.3614e-02, 1.1257e-02, 2.1696e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,375][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([2.1503e-03, 8.2216e-01, 1.1070e-01, 3.0461e-02, 4.9886e-03, 2.4290e-02,
        3.5973e-03, 4.8212e-04, 1.1700e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,376][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.2185, 0.3878, 0.1748, 0.0622, 0.0288, 0.0455, 0.0267, 0.0470, 0.0086],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,377][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.0021, 0.1191, 0.4810, 0.0606, 0.1296, 0.0459, 0.0460, 0.0178, 0.0979],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,378][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([2.0986e-05, 8.5369e-01, 8.5539e-02, 5.2160e-02, 3.9416e-03, 2.7582e-03,
        9.2148e-04, 8.4218e-04, 1.2576e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,380][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0248, 0.1297, 0.0593, 0.0838, 0.1266, 0.0856, 0.1754, 0.1132, 0.2016],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,385][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1593, 0.4528, 0.0662, 0.0338, 0.0202, 0.0187, 0.0844, 0.0681, 0.0569,
        0.0395], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,388][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2693, 0.2886, 0.3159, 0.0076, 0.0862, 0.0071, 0.0150, 0.0026, 0.0064,
        0.0015], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,389][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2398, 0.4894, 0.1088, 0.0426, 0.0076, 0.0168, 0.0523, 0.0111, 0.0255,
        0.0062], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,390][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.5871e-01, 2.6205e-03, 1.3730e-04, 9.1024e-03, 1.2983e-04, 2.0246e-03,
        5.5922e-03, 1.5208e-02, 1.9345e-03, 4.5401e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,391][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4266, 0.1661, 0.0220, 0.1469, 0.0195, 0.0636, 0.0552, 0.0301, 0.0504,
        0.0196], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,391][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.0585e-01, 2.1856e-02, 7.8126e-04, 4.6163e-03, 5.9288e-04, 7.5779e-03,
        2.7147e-02, 2.2995e-02, 5.1477e-03, 3.4374e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,393][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4807e-04, 3.3573e-01, 5.5625e-01, 2.2287e-02, 4.5604e-02, 5.6564e-03,
        1.5931e-02, 2.9079e-03, 7.5698e-03, 7.9070e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,397][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0136, 0.7586, 0.1243, 0.0426, 0.0090, 0.0396, 0.0064, 0.0015, 0.0027,
        0.0017], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,402][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3479, 0.4164, 0.1615, 0.0226, 0.0160, 0.0089, 0.0101, 0.0102, 0.0027,
        0.0038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,402][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([3.2771e-05, 7.2654e-02, 7.8428e-01, 1.8403e-02, 7.3198e-02, 1.7736e-02,
        1.2537e-02, 3.2489e-03, 1.2975e-02, 4.9396e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,403][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0174, 0.6474, 0.0813, 0.1525, 0.0092, 0.0219, 0.0173, 0.0332, 0.0040,
        0.0158], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,404][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0822, 0.1722, 0.1121, 0.0562, 0.1243, 0.0518, 0.1520, 0.0619, 0.1426,
        0.0446], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,405][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([1.0667e-02, 8.6071e-01, 5.8116e-02, 1.6718e-02, 5.4211e-03, 4.9781e-03,
        1.4616e-02, 7.5593e-03, 1.1843e-02, 8.5958e-03, 7.7702e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,406][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.3762e-01, 4.2757e-01, 3.4925e-01, 8.5508e-03, 5.9427e-02, 3.5333e-03,
        8.5812e-03, 1.2563e-03, 2.9683e-03, 9.4289e-04, 3.0190e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,409][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.4425e-02, 8.6075e-01, 7.9746e-02, 1.5737e-02, 4.3064e-03, 3.8722e-03,
        9.2396e-03, 2.1199e-03, 7.2189e-03, 1.9658e-03, 6.2077e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,412][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.4057e-02, 9.2482e-01, 1.7759e-02, 3.1204e-02, 6.5422e-04, 4.4583e-03,
        3.5202e-03, 2.1457e-03, 2.4239e-04, 1.0506e-03, 8.3823e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,415][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2492, 0.4497, 0.0172, 0.0650, 0.0102, 0.0497, 0.0373, 0.0273, 0.0475,
        0.0343, 0.0125], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,416][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.7823, 0.1011, 0.0043, 0.0115, 0.0012, 0.0118, 0.0454, 0.0294, 0.0073,
        0.0043, 0.0014], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,417][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.7223e-05, 4.8414e-01, 4.5420e-01, 1.2573e-02, 3.0198e-02, 2.1728e-03,
        4.2152e-03, 1.5686e-03, 3.3305e-03, 6.6481e-03, 9.2477e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,418][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([4.5551e-04, 8.8010e-01, 9.7873e-02, 9.6740e-03, 2.2340e-03, 8.3224e-03,
        6.9817e-04, 1.1750e-04, 2.9981e-04, 2.1264e-04, 1.7799e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,418][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0201, 0.7521, 0.1851, 0.0123, 0.0132, 0.0053, 0.0037, 0.0039, 0.0016,
        0.0017, 0.0010], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,420][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.2660e-05, 1.4972e-01, 6.7536e-01, 1.3306e-02, 1.0926e-01, 1.6403e-02,
        1.0199e-02, 2.8381e-03, 1.2762e-02, 7.3597e-03, 2.7795e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,422][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([2.4838e-06, 9.6911e-01, 2.7896e-02, 2.3536e-03, 2.2569e-04, 3.0452e-04,
        4.3283e-05, 3.3791e-05, 3.6095e-06, 2.4635e-05, 9.8217e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,427][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1186, 0.2042, 0.0872, 0.0655, 0.0793, 0.0441, 0.1289, 0.0521, 0.1612,
        0.0431, 0.0159], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:57,429][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([1.2130e-02, 8.1835e-01, 7.6785e-02, 1.8559e-02, 6.5945e-03, 4.6187e-03,
        1.9522e-02, 1.5610e-02, 1.4515e-02, 8.0339e-03, 6.9026e-04, 4.5931e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,430][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([3.0282e-02, 2.2603e-01, 5.1288e-01, 5.0112e-03, 2.0593e-01, 4.5396e-03,
        4.1919e-03, 6.6498e-04, 2.8251e-03, 1.0889e-03, 1.8323e-04, 6.3625e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,430][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([2.2792e-03, 8.4637e-01, 1.0646e-01, 1.2949e-02, 3.1787e-03, 3.0968e-03,
        1.1484e-02, 2.6234e-03, 7.8317e-03, 2.0071e-03, 4.8590e-04, 1.2324e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,431][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([3.7686e-05, 9.7512e-01, 1.3193e-02, 9.5949e-03, 4.3084e-04, 5.3969e-04,
        3.7406e-04, 3.7421e-04, 3.6174e-05, 2.4702e-04, 4.3853e-05, 4.3211e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,432][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1886, 0.1404, 0.0885, 0.2019, 0.0291, 0.1548, 0.0183, 0.0303, 0.0796,
        0.0194, 0.0107, 0.0384], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,435][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.1457, 0.6179, 0.0099, 0.0359, 0.0046, 0.0280, 0.0643, 0.0455, 0.0119,
        0.0093, 0.0016, 0.0255], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,438][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([9.0214e-06, 2.4645e-01, 6.8425e-01, 1.4617e-02, 2.8940e-02, 6.7639e-03,
        7.0649e-03, 1.6564e-03, 3.0568e-03, 3.8488e-03, 5.3367e-04, 2.8104e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,441][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([2.6414e-05, 8.8316e-01, 8.9344e-02, 1.6576e-02, 1.1057e-03, 8.7889e-03,
        7.0595e-04, 2.9756e-05, 1.4135e-04, 9.1214e-05, 1.1722e-05, 1.7413e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,443][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.7399e-02, 7.9229e-01, 1.3953e-01, 1.8728e-02, 1.0290e-02, 7.7838e-03,
        2.5982e-03, 3.1798e-03, 1.2425e-03, 3.4472e-03, 6.0861e-04, 2.9075e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,443][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([6.1239e-05, 4.3753e-02, 7.7930e-01, 2.3629e-02, 6.4263e-02, 2.4799e-02,
        3.2555e-02, 4.5749e-03, 1.3694e-02, 4.9854e-03, 1.8548e-03, 6.5254e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,444][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([4.9040e-09, 9.6604e-01, 3.3160e-02, 5.8243e-04, 1.5840e-04, 3.1143e-05,
        1.5517e-05, 5.1698e-06, 6.2457e-07, 7.8358e-06, 3.7290e-07, 5.4610e-08],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,445][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0236, 0.0734, 0.0383, 0.0656, 0.0717, 0.0286, 0.0409, 0.0456, 0.0885,
        0.0292, 0.0248, 0.4700], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:57,446][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0279, 0.7063, 0.1414, 0.0235, 0.0182, 0.0099, 0.0217, 0.0169, 0.0140,
        0.0123, 0.0013, 0.0044, 0.0022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,448][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.0577e-01, 3.8656e-01, 4.1506e-01, 4.3357e-03, 6.7525e-02, 3.4562e-03,
        5.5719e-03, 6.5929e-04, 1.9191e-03, 5.1662e-04, 1.5044e-04, 7.9346e-03,
        5.3682e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,450][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([4.7290e-02, 7.3058e-01, 1.5442e-01, 2.6511e-02, 4.1866e-03, 7.4317e-03,
        1.5420e-02, 2.6217e-03, 7.2771e-03, 1.3320e-03, 1.0114e-03, 1.2187e-03,
        7.0032e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,453][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([1.5375e-02, 9.0635e-01, 3.1931e-02, 3.5098e-02, 6.9649e-04, 4.7845e-03,
        2.8110e-03, 1.6342e-03, 2.1800e-04, 8.7044e-04, 6.2036e-05, 8.2117e-06,
        1.6115e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,456][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.2228, 0.3643, 0.0483, 0.1175, 0.0260, 0.0473, 0.0302, 0.0231, 0.0238,
        0.0146, 0.0155, 0.0297, 0.0368], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,457][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([7.4093e-01, 1.4696e-01, 3.3538e-03, 1.5238e-02, 1.4341e-03, 1.7577e-02,
        3.2729e-02, 2.5749e-02, 5.9082e-03, 4.9977e-03, 1.2250e-03, 3.5249e-03,
        3.7575e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,458][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([2.7803e-05, 2.4109e-01, 6.8662e-01, 9.2102e-03, 4.4797e-02, 2.2520e-03,
        4.2745e-03, 8.7972e-04, 1.9681e-03, 2.4447e-03, 6.9154e-04, 1.7530e-03,
        3.9906e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,458][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([8.8899e-05, 8.4647e-01, 1.3438e-01, 7.7070e-03, 2.1089e-03, 8.1069e-03,
        6.6470e-04, 7.1196e-05, 1.8881e-04, 1.0994e-04, 1.2338e-05, 3.3309e-05,
        5.0827e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,459][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0875, 0.6322, 0.2139, 0.0140, 0.0225, 0.0051, 0.0043, 0.0053, 0.0017,
        0.0022, 0.0008, 0.0075, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,461][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.1872e-05, 3.8219e-02, 8.4247e-01, 9.0232e-03, 7.8862e-02, 9.6477e-03,
        6.0690e-03, 1.1374e-03, 5.8624e-03, 2.6797e-03, 1.0991e-03, 2.5564e-03,
        2.3656e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,463][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([3.5015e-06, 9.5013e-01, 4.6235e-02, 2.9058e-03, 1.7959e-04, 4.0471e-04,
        8.0134e-05, 3.4651e-05, 3.3844e-06, 1.8638e-05, 7.7662e-07, 2.1230e-07,
        2.7893e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,469][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0757, 0.1285, 0.1178, 0.0302, 0.1048, 0.0237, 0.0686, 0.0363, 0.0624,
        0.0168, 0.0101, 0.3066, 0.0186], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:57,472][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0108, 0.7360, 0.1624, 0.0197, 0.0128, 0.0051, 0.0170, 0.0122, 0.0113,
        0.0063, 0.0010, 0.0030, 0.0011, 0.0011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,473][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([2.3577e-01, 4.4344e-01, 1.8611e-01, 5.4509e-03, 8.0876e-02, 3.4114e-03,
        2.1539e-03, 9.0103e-04, 1.3214e-03, 1.0231e-03, 1.5845e-04, 1.4121e-02,
        4.2177e-04, 2.4834e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,474][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([4.7193e-02, 7.7758e-01, 1.2639e-01, 2.0444e-02, 5.2340e-03, 3.4609e-03,
        9.3881e-03, 3.1660e-03, 4.1235e-03, 9.1018e-04, 4.8267e-04, 1.1186e-03,
        3.0480e-04, 2.0027e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,475][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([1.7510e-02, 7.9044e-01, 1.3985e-01, 2.7455e-02, 3.3726e-03, 7.0699e-03,
        8.8149e-03, 2.9286e-03, 7.8947e-04, 1.0284e-03, 2.8316e-04, 1.0236e-04,
        3.0033e-04, 5.4610e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,476][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.8647, 0.0479, 0.0107, 0.0152, 0.0086, 0.0067, 0.0045, 0.0046, 0.0050,
        0.0012, 0.0025, 0.0150, 0.0056, 0.0077], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,477][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([7.7031e-01, 1.0910e-01, 1.2474e-02, 1.5432e-02, 9.5503e-03, 1.0452e-02,
        3.0302e-02, 2.4052e-02, 8.2650e-03, 2.1052e-03, 6.4540e-04, 6.4090e-03,
        2.8879e-04, 6.0705e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,480][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([1.2651e-04, 6.2837e-01, 2.6343e-01, 3.3733e-02, 2.8512e-02, 8.1868e-03,
        3.5693e-03, 1.8874e-03, 2.3677e-03, 5.5785e-03, 1.1413e-03, 3.3986e-03,
        8.9403e-03, 1.0760e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,483][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([3.0787e-03, 8.0879e-01, 1.0540e-01, 4.7939e-02, 6.3318e-03, 2.2107e-02,
        3.6236e-03, 1.0625e-03, 3.7859e-04, 3.6152e-04, 1.2066e-04, 2.7049e-04,
        3.7173e-04, 1.7344e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,486][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0112, 0.7419, 0.1940, 0.0184, 0.0091, 0.0055, 0.0018, 0.0025, 0.0013,
        0.0016, 0.0009, 0.0047, 0.0023, 0.0049], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,487][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([4.1278e-05, 2.4192e-01, 5.9757e-01, 2.9774e-02, 4.7540e-02, 3.9868e-02,
        4.1848e-03, 2.4973e-03, 6.3166e-03, 7.5046e-03, 1.7411e-03, 5.7942e-03,
        4.9755e-03, 1.0276e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,488][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([2.6653e-06, 8.6987e-01, 1.2081e-01, 6.9247e-03, 1.1927e-03, 8.2836e-04,
        2.3239e-04, 8.8256e-05, 8.6645e-06, 3.0284e-05, 2.9264e-06, 1.8794e-06,
        3.7214e-06, 4.6474e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,488][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0269, 0.2494, 0.0214, 0.0480, 0.0389, 0.0194, 0.0195, 0.0291, 0.0378,
        0.0224, 0.0125, 0.4011, 0.0323, 0.0414], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:57,489][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([8.1890e-03, 7.7114e-01, 9.7736e-02, 2.1592e-02, 9.3862e-03, 1.2895e-02,
        2.3092e-02, 1.6837e-02, 1.9882e-02, 7.5773e-03, 1.0749e-03, 5.4507e-03,
        1.0701e-03, 5.0610e-04, 3.5675e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,491][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([2.8048e-01, 2.9996e-01, 2.8881e-01, 8.1742e-03, 7.2060e-02, 3.1412e-03,
        5.9561e-03, 1.0254e-03, 2.7564e-03, 8.3572e-04, 2.8557e-04, 1.2206e-02,
        8.7292e-04, 1.9834e-02, 3.6076e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,493][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([2.5901e-03, 8.5884e-01, 9.3842e-02, 1.5035e-02, 5.4203e-03, 3.4406e-03,
        9.0677e-03, 2.1565e-03, 5.2710e-03, 1.6914e-03, 4.0295e-04, 1.0884e-03,
        4.2687e-04, 1.8970e-04, 5.4179e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,496][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([1.2435e-02, 8.7529e-01, 3.8778e-02, 4.8063e-02, 1.6864e-03, 9.0258e-03,
        6.3740e-03, 3.9871e-03, 8.4184e-04, 2.0765e-03, 3.3502e-04, 7.2223e-05,
        5.6761e-04, 5.9656e-05, 4.0573e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,500][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.2231, 0.1887, 0.0226, 0.0426, 0.0201, 0.0459, 0.0252, 0.0209, 0.1251,
        0.0211, 0.0266, 0.1313, 0.0520, 0.0211, 0.0337], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,500][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([3.5733e-01, 4.4000e-01, 1.1424e-02, 2.9723e-02, 4.7342e-03, 2.4419e-02,
        6.4944e-02, 3.3430e-02, 1.0636e-02, 6.1441e-03, 1.8266e-03, 9.7553e-03,
        5.5895e-04, 2.7516e-04, 4.8003e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,501][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([2.5021e-05, 2.5137e-01, 6.4907e-01, 1.0581e-02, 3.5357e-02, 4.8736e-03,
        5.1379e-03, 1.7081e-03, 4.1388e-03, 4.1300e-03, 1.3092e-03, 4.2903e-03,
        6.1371e-03, 1.5911e-02, 5.9533e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,502][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([5.2825e-04, 7.6998e-01, 1.7606e-01, 2.4454e-02, 4.3226e-03, 2.1583e-02,
        1.5917e-03, 1.2812e-04, 4.9717e-04, 3.2399e-04, 3.7837e-05, 1.6227e-04,
        1.7595e-04, 7.6930e-05, 7.9247e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,503][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0243, 0.6516, 0.2394, 0.0173, 0.0184, 0.0107, 0.0071, 0.0036, 0.0029,
        0.0021, 0.0030, 0.0087, 0.0028, 0.0046, 0.0034], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,505][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([1.7596e-05, 1.2971e-01, 7.5200e-01, 1.1316e-02, 5.2905e-02, 7.8711e-03,
        8.4573e-03, 1.2643e-03, 7.7899e-03, 3.8683e-03, 1.9343e-03, 4.7696e-03,
        4.1425e-03, 1.1985e-02, 1.9649e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,507][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([4.5988e-06, 9.0651e-01, 8.1482e-02, 1.0061e-02, 8.4213e-04, 6.6152e-04,
        2.4407e-04, 9.1107e-05, 1.5923e-05, 6.2880e-05, 3.6743e-06, 1.6311e-06,
        8.0918e-06, 7.9107e-07, 9.3220e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,512][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0705, 0.0772, 0.0397, 0.0463, 0.0695, 0.0304, 0.0555, 0.0474, 0.0776,
        0.0301, 0.0174, 0.2213, 0.0268, 0.1065, 0.0836], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:57,513][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0269, 0.5937, 0.1581, 0.0238, 0.0347, 0.0128, 0.0571, 0.0363, 0.0243,
        0.0127, 0.0013, 0.0056, 0.0018, 0.0014, 0.0058, 0.0038],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,514][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3651e-01, 4.3050e-01, 3.0981e-01, 5.8143e-03, 8.4716e-02, 3.4311e-03,
        5.9650e-03, 1.0036e-03, 2.2489e-03, 4.8049e-04, 1.0171e-04, 6.0528e-03,
        2.9376e-04, 1.0062e-02, 2.0317e-03, 9.7017e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,515][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.0937e-02, 7.4627e-01, 1.6141e-01, 2.3552e-02, 6.4417e-03, 6.3342e-03,
        1.9365e-02, 3.2768e-03, 7.3181e-03, 1.3844e-03, 7.0597e-04, 1.2423e-03,
        5.6722e-04, 2.4556e-04, 5.5895e-04, 3.9259e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,516][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.4186e-01, 1.5782e-01, 1.3750e-02, 5.4511e-02, 2.4238e-03, 1.6970e-02,
        4.9942e-02, 2.9886e-02, 1.0250e-02, 6.8182e-03, 1.6372e-03, 2.7257e-04,
        2.8441e-03, 1.3894e-03, 6.6733e-03, 2.9486e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,518][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2175, 0.2526, 0.0409, 0.1372, 0.0269, 0.0784, 0.0363, 0.0293, 0.0367,
        0.0128, 0.0081, 0.0520, 0.0210, 0.0093, 0.0193, 0.0217],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,521][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.5582e-01, 1.2546e-01, 3.2083e-03, 1.4836e-02, 1.8937e-03, 2.2954e-02,
        8.2424e-02, 5.9994e-02, 9.7770e-03, 8.4429e-03, 1.9950e-03, 5.3793e-03,
        6.6011e-04, 3.3381e-04, 2.2480e-03, 4.5777e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,524][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.6045e-05, 3.8156e-01, 5.6091e-01, 1.2181e-02, 2.7655e-02, 2.1410e-03,
        5.0476e-03, 5.5186e-04, 1.5275e-03, 1.2233e-03, 1.9595e-04, 8.3229e-04,
        1.5619e-03, 2.5545e-03, 1.1922e-03, 8.4231e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,527][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.5293e-03, 7.3069e-01, 1.9518e-01, 2.8945e-02, 7.7708e-03, 2.9473e-02,
        2.6631e-03, 3.1684e-04, 1.1383e-03, 5.3593e-04, 6.1998e-05, 4.0531e-04,
        3.4025e-04, 3.0458e-04, 2.9374e-04, 3.5557e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,528][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.3006e-02, 6.2524e-01, 2.5636e-01, 1.3154e-02, 1.0398e-02, 4.2512e-03,
        3.9169e-03, 1.8849e-03, 1.0253e-03, 9.4550e-04, 8.4269e-04, 3.2492e-03,
        1.3818e-03, 2.4665e-03, 1.3607e-03, 5.1456e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,529][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.8199e-06, 9.0783e-02, 8.5838e-01, 6.4075e-03, 3.1903e-02, 3.9876e-03,
        2.2374e-03, 3.7351e-04, 1.0326e-03, 8.7133e-04, 2.2893e-04, 4.7197e-04,
        5.5804e-04, 1.6131e-03, 3.0889e-04, 8.4298e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,529][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.5093e-04, 8.1962e-01, 1.2602e-01, 3.2692e-02, 5.0331e-03, 7.0706e-03,
        4.2824e-03, 2.3646e-03, 6.7055e-04, 9.2865e-04, 7.5998e-05, 3.4254e-05,
        1.3767e-04, 6.7127e-05, 4.1262e-04, 3.3702e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,530][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0648, 0.0995, 0.0844, 0.0419, 0.0854, 0.0276, 0.0830, 0.0392, 0.0710,
        0.0208, 0.0107, 0.2215, 0.0192, 0.0550, 0.0536, 0.0225],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:57,532][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([2.4828e-02, 6.9685e-01, 1.5030e-01, 3.0072e-02, 2.4020e-02, 6.4767e-03,
        1.7243e-02, 1.2160e-02, 1.1666e-02, 5.0964e-03, 4.5227e-04, 7.1534e-03,
        1.1617e-03, 2.0215e-03, 4.7163e-03, 2.2499e-03, 3.5324e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,534][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([1.5421e-01, 3.7073e-01, 3.6538e-01, 5.1998e-03, 6.6367e-02, 3.4822e-03,
        3.9538e-03, 6.2553e-04, 1.4365e-03, 8.8252e-04, 1.5102e-04, 4.9675e-03,
        6.2980e-04, 1.4967e-02, 1.8133e-03, 1.5402e-03, 3.6658e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,537][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([3.9227e-03, 8.2283e-01, 1.5722e-01, 6.6769e-03, 4.1456e-03, 1.0473e-03,
        1.7815e-03, 5.5043e-04, 7.8950e-04, 1.6579e-04, 4.5322e-05, 3.2052e-04,
        7.1270e-05, 7.9294e-05, 6.8011e-05, 6.5063e-05, 2.1357e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,541][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([4.8514e-02, 7.7083e-01, 6.1635e-02, 7.8487e-02, 2.4920e-03, 1.4548e-02,
        9.4461e-03, 6.7283e-03, 1.1182e-03, 2.1780e-03, 4.3189e-04, 1.0487e-04,
        1.0130e-03, 1.3814e-04, 1.1593e-03, 6.5712e-04, 5.2046e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,541][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.2219, 0.1790, 0.0197, 0.0860, 0.0188, 0.0609, 0.0559, 0.0221, 0.0672,
        0.0161, 0.0097, 0.0641, 0.0339, 0.0134, 0.0450, 0.0377, 0.0487],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,542][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([5.5279e-01, 2.5784e-01, 8.6232e-03, 2.4282e-02, 2.8244e-03, 2.2637e-02,
        5.7613e-02, 3.6243e-02, 8.5481e-03, 6.7298e-03, 1.3577e-03, 7.1353e-03,
        5.6348e-04, 2.0429e-04, 2.5907e-03, 3.1623e-03, 6.8605e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,543][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([1.6010e-05, 3.0407e-01, 6.3952e-01, 4.0568e-03, 3.4198e-02, 1.4509e-03,
        7.8053e-04, 4.3383e-04, 4.8399e-04, 1.3240e-03, 1.6012e-04, 7.4572e-04,
        1.2719e-03, 8.2145e-03, 7.7811e-04, 1.7444e-03, 7.4459e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,544][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([1.7212e-04, 7.6849e-01, 2.0131e-01, 1.0296e-02, 4.8419e-03, 1.2724e-02,
        7.0618e-04, 9.5939e-05, 3.2532e-04, 2.9171e-04, 2.1514e-05, 1.0360e-04,
        1.1360e-04, 1.0295e-04, 6.8141e-05, 1.8906e-04, 1.5482e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,546][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([1.5594e-02, 5.3385e-01, 4.1355e-01, 5.9579e-03, 9.0025e-03, 5.8298e-03,
        2.4530e-03, 1.7710e-03, 1.0461e-03, 9.3326e-04, 1.1159e-03, 2.3475e-03,
        8.3280e-04, 1.8811e-03, 8.2294e-04, 5.0058e-04, 2.5111e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,548][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.0196e-05, 1.0523e-01, 7.9625e-01, 6.3571e-03, 5.6199e-02, 1.2344e-02,
        2.6542e-03, 5.7748e-04, 1.2794e-03, 1.7163e-03, 5.1151e-04, 1.6172e-03,
        1.1159e-03, 8.7213e-03, 5.2751e-04, 2.4611e-03, 2.4312e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,551][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([1.1274e-05, 8.6448e-01, 1.2062e-01, 1.1330e-02, 1.9621e-03, 9.5947e-04,
        2.9475e-04, 1.2427e-04, 2.1555e-05, 1.0035e-04, 4.1559e-06, 1.4668e-06,
        9.6658e-06, 3.3877e-06, 3.3141e-05, 3.1019e-05, 9.7430e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,554][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0318, 0.0247, 0.0217, 0.0338, 0.0342, 0.0154, 0.0394, 0.0546, 0.0918,
        0.0278, 0.0238, 0.2318, 0.0290, 0.1289, 0.0904, 0.0336, 0.0874],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:57,555][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([4.8862e-03, 7.8313e-01, 1.5053e-01, 1.8600e-02, 1.1100e-02, 2.7654e-03,
        1.0994e-02, 4.1192e-03, 4.4464e-03, 2.5226e-03, 2.7671e-04, 1.8170e-03,
        5.3359e-04, 2.4002e-04, 1.3939e-03, 6.8019e-04, 1.8026e-03, 1.6199e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,556][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.1834e-02, 7.5199e-01, 1.8592e-01, 5.0902e-03, 2.9214e-02, 2.0688e-03,
        2.7204e-03, 3.8158e-04, 1.0554e-03, 4.1824e-04, 5.3460e-05, 3.0973e-03,
        2.5064e-04, 2.5023e-03, 1.3137e-03, 5.6694e-04, 1.3836e-03, 1.3454e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,557][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.2652e-03, 8.6286e-01, 1.2544e-01, 4.6393e-03, 1.6552e-03, 6.0564e-04,
        1.8120e-03, 3.3648e-04, 5.8739e-04, 1.9045e-04, 4.7031e-05, 1.7114e-04,
        7.1073e-05, 2.5892e-05, 6.6194e-05, 4.3509e-05, 1.6028e-04, 2.6381e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,558][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.8881e-05, 9.7259e-01, 2.4163e-02, 2.1497e-03, 9.9496e-05, 4.5331e-04,
        3.1934e-04, 5.7777e-05, 1.9835e-05, 3.3551e-05, 2.2213e-06, 5.7708e-07,
        1.1072e-05, 1.0296e-06, 1.3130e-05, 9.8348e-06, 1.2804e-05, 4.5615e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,561][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2002, 0.4589, 0.0236, 0.0745, 0.0154, 0.0480, 0.0137, 0.0184, 0.0106,
        0.0104, 0.0087, 0.0365, 0.0205, 0.0083, 0.0128, 0.0188, 0.0145, 0.0064],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,563][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.2124e-01, 4.5675e-01, 1.1703e-02, 2.3750e-02, 2.8458e-03, 3.0211e-02,
        7.9415e-02, 4.1421e-02, 7.3030e-03, 7.1574e-03, 1.1812e-03, 4.2621e-03,
        3.9118e-04, 1.2573e-04, 1.4895e-03, 3.2768e-03, 4.9488e-03, 2.5335e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,566][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.1855e-06, 7.2353e-01, 2.5372e-01, 5.7707e-03, 1.1334e-02, 9.5528e-04,
        7.1887e-04, 1.7204e-04, 2.8829e-04, 5.0101e-04, 5.5681e-05, 2.9592e-04,
        5.5483e-04, 6.5953e-04, 6.2721e-04, 3.6166e-04, 4.1533e-04, 3.4390e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,568][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([8.8607e-06, 8.6411e-01, 1.2427e-01, 5.1729e-03, 2.5647e-03, 3.4201e-03,
        1.6313e-04, 1.5166e-05, 5.6084e-05, 3.7338e-05, 2.9249e-06, 3.1881e-05,
        2.4595e-05, 1.7760e-05, 3.1941e-05, 3.1852e-05, 3.5737e-05, 9.5583e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,569][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.5571e-03, 8.1145e-01, 1.7008e-01, 4.7885e-03, 3.8943e-03, 1.3720e-03,
        1.0678e-03, 4.0792e-04, 3.3672e-04, 2.6311e-04, 1.6969e-04, 6.5785e-04,
        4.0204e-04, 3.9915e-04, 3.1303e-04, 1.2147e-04, 4.7488e-04, 2.3811e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,570][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.0921e-07, 3.3830e-01, 6.2252e-01, 5.0095e-03, 2.5709e-02, 3.3833e-03,
        7.8299e-04, 1.7974e-04, 3.6575e-04, 7.1010e-04, 1.2429e-04, 3.2365e-04,
        4.4084e-04, 5.9556e-04, 1.2858e-04, 7.2638e-04, 5.0346e-04, 1.9952e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,571][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([6.6876e-09, 9.7143e-01, 2.8208e-02, 2.8024e-04, 4.5723e-05, 2.8206e-05,
        5.9293e-06, 8.3240e-07, 2.8383e-07, 8.3637e-07, 2.9200e-08, 9.5564e-09,
        1.1006e-07, 1.5442e-08, 2.8762e-07, 2.1316e-07, 1.5488e-07, 5.3627e-09],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,573][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0143, 0.1268, 0.0708, 0.0410, 0.0736, 0.0316, 0.0761, 0.0353, 0.0654,
        0.0206, 0.0099, 0.2128, 0.0283, 0.0713, 0.0523, 0.0202, 0.0404, 0.0094],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:57,576][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([2.7189e-02, 6.9245e-01, 1.2461e-01, 2.9582e-02, 1.2503e-02, 3.4105e-03,
        4.5658e-02, 1.4718e-02, 1.4233e-02, 5.9529e-03, 1.4573e-03, 6.1478e-03,
        1.5915e-03, 7.0994e-04, 6.9120e-03, 1.8837e-03, 8.4884e-03, 6.8118e-04,
        1.8207e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,579][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([3.8044e-02, 5.3288e-01, 3.0505e-01, 4.2722e-03, 7.5204e-02, 4.8454e-03,
        1.9092e-03, 3.8755e-04, 9.1079e-04, 1.1278e-03, 1.2091e-04, 5.2401e-03,
        4.5089e-04, 1.7650e-02, 1.7533e-03, 2.1901e-03, 4.5478e-03, 6.0365e-04,
        2.8209e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,581][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([1.5895e-03, 8.9611e-01, 8.7570e-02, 6.4213e-03, 2.0905e-03, 9.4607e-04,
        2.3878e-03, 5.3600e-04, 1.0420e-03, 3.0040e-04, 1.0261e-04, 2.3116e-04,
        1.0511e-04, 3.7580e-05, 8.4722e-05, 7.6287e-05, 2.6808e-04, 5.7521e-05,
        4.3737e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,582][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([6.7044e-05, 8.5497e-01, 1.3313e-01, 8.3234e-03, 1.9222e-03, 8.1512e-04,
        5.1697e-04, 8.0082e-05, 4.6051e-05, 3.6338e-05, 1.4306e-05, 9.4843e-06,
        2.4638e-05, 1.1379e-06, 9.6447e-06, 5.6740e-06, 1.8760e-05, 1.3219e-06,
        3.2461e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,583][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.2192, 0.1786, 0.0592, 0.0965, 0.0250, 0.0862, 0.0244, 0.0180, 0.0274,
        0.0189, 0.0117, 0.0588, 0.0279, 0.0167, 0.0205, 0.0314, 0.0359, 0.0203,
        0.0235], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,584][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([2.1719e-01, 5.6343e-01, 1.4722e-02, 3.0188e-02, 4.8710e-03, 3.2167e-02,
        6.8246e-02, 2.8205e-02, 8.3171e-03, 7.3839e-03, 1.9846e-03, 7.6209e-03,
        9.0440e-04, 2.2386e-04, 1.4132e-03, 2.5730e-03, 3.5209e-03, 3.5697e-03,
        3.4647e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,586][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([3.9618e-06, 4.4122e-01, 4.9849e-01, 9.7082e-03, 2.3321e-02, 4.2125e-03,
        1.5423e-03, 8.9584e-04, 7.7563e-04, 2.9273e-03, 3.2755e-04, 1.4950e-03,
        3.6147e-03, 5.3753e-03, 1.3721e-03, 2.9511e-03, 1.2261e-03, 2.5583e-04,
        2.9283e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,588][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([3.2090e-05, 7.0958e-01, 2.5546e-01, 1.6613e-02, 6.7855e-03, 9.6942e-03,
        9.6992e-04, 5.8561e-05, 2.0237e-04, 1.0050e-04, 3.1393e-05, 7.2639e-05,
        8.8678e-05, 4.5394e-05, 4.4820e-05, 5.0442e-05, 1.1952e-04, 3.2156e-05,
        1.5951e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,591][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([6.7563e-03, 5.3621e-01, 3.9290e-01, 1.7681e-02, 1.8827e-02, 8.1256e-03,
        2.7185e-03, 1.6249e-03, 1.4835e-03, 1.1718e-03, 3.5524e-04, 3.9380e-03,
        7.9451e-04, 1.5496e-03, 7.9396e-04, 5.2076e-04, 3.2899e-03, 7.7136e-04,
        4.9301e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,595][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.4306e-05, 1.5814e-01, 7.1695e-01, 1.0979e-02, 2.7496e-02, 1.6163e-02,
        7.4772e-03, 2.4654e-03, 9.8269e-03, 8.9497e-03, 2.3535e-03, 4.6021e-03,
        4.5107e-03, 7.7169e-03, 2.0248e-03, 9.8714e-03, 6.0251e-03, 2.0037e-03,
        2.4342e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,595][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([1.0726e-08, 7.2780e-01, 2.7058e-01, 8.9227e-04, 5.9223e-04, 9.7970e-05,
        3.1960e-05, 1.8560e-06, 7.9211e-07, 1.5906e-06, 3.2635e-07, 1.2400e-07,
        4.8609e-07, 2.1298e-08, 6.1344e-07, 2.7365e-07, 2.4589e-07, 2.2760e-08,
        2.1847e-09], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,596][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0114, 0.0772, 0.0709, 0.0415, 0.0656, 0.0338, 0.0343, 0.0299, 0.0529,
        0.0252, 0.0235, 0.1903, 0.0443, 0.0776, 0.0629, 0.0261, 0.0714, 0.0163,
        0.0448], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:57,597][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.8376e-03, 7.1913e-01, 1.9771e-01, 1.1825e-02, 2.3346e-02, 4.2055e-03,
        1.5820e-02, 7.1794e-03, 6.3991e-03, 3.1419e-03, 2.9132e-04, 1.5868e-03,
        5.1794e-04, 3.9275e-04, 1.4817e-03, 8.6327e-04, 2.2758e-03, 1.8765e-04,
        4.8173e-04, 3.2233e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,598][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.3232e-02, 6.9600e-01, 2.2390e-01, 3.6537e-03, 3.9869e-02, 2.1447e-03,
        2.0160e-03, 3.7179e-04, 6.4381e-04, 2.4010e-04, 3.6747e-05, 2.1195e-03,
        1.3647e-04, 2.6288e-03, 8.0232e-04, 4.6243e-04, 8.8384e-04, 9.9082e-05,
        5.1359e-04, 2.3873e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,600][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.2526e-04, 8.6179e-01, 1.2406e-01, 4.9940e-03, 2.2049e-03, 9.6191e-04,
        2.7203e-03, 3.8082e-04, 9.0293e-04, 1.8789e-04, 6.6158e-05, 1.8567e-04,
        8.0935e-05, 2.6695e-05, 9.1148e-05, 5.2329e-05, 2.7937e-04, 3.6241e-05,
        4.3013e-05, 1.7822e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,602][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.4811e-04, 9.1472e-01, 7.5267e-02, 5.9990e-03, 1.0109e-03, 7.7389e-04,
        1.4873e-03, 1.2988e-04, 8.8587e-05, 4.9058e-05, 9.8870e-06, 2.4815e-06,
        2.8148e-05, 4.6943e-06, 3.3498e-05, 1.1496e-05, 3.3777e-05, 1.4333e-06,
        6.2886e-07, 1.3481e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,608][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0763, 0.4007, 0.0396, 0.0887, 0.0226, 0.0678, 0.0248, 0.0229, 0.0300,
        0.0117, 0.0057, 0.0456, 0.0193, 0.0077, 0.0206, 0.0214, 0.0420, 0.0083,
        0.0264, 0.0179], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,609][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.9777e-01, 4.1684e-01, 1.0477e-02, 2.3083e-02, 3.3101e-03, 3.3476e-02,
        1.0642e-01, 5.6219e-02, 1.0730e-02, 9.9131e-03, 2.0847e-03, 6.2191e-03,
        7.6449e-04, 2.9136e-04, 2.3745e-03, 5.0998e-03, 6.6528e-03, 3.4509e-03,
        1.8393e-03, 2.9842e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,610][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.8224e-06, 5.0759e-01, 4.6400e-01, 5.4820e-03, 1.6113e-02, 9.3572e-04,
        1.2768e-03, 1.7623e-04, 4.2874e-04, 5.3611e-04, 5.8186e-05, 2.5238e-04,
        5.8231e-04, 8.6720e-04, 4.1077e-04, 4.0307e-04, 5.9095e-04, 3.1761e-05,
        1.2548e-04, 1.3478e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,611][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.2384e-05, 7.5659e-01, 2.2767e-01, 6.2141e-03, 3.2880e-03, 5.4621e-03,
        3.8623e-04, 1.8220e-05, 9.1998e-05, 4.1604e-05, 4.3886e-06, 3.4033e-05,
        2.8201e-05, 1.9916e-05, 2.2774e-05, 2.6253e-05, 4.7758e-05, 8.5640e-06,
        9.4072e-06, 1.4472e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,612][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.4585e-03, 6.7936e-01, 2.9895e-01, 5.2800e-03, 5.8717e-03, 1.4068e-03,
        9.9830e-04, 3.5684e-04, 2.3230e-04, 2.2181e-04, 1.7540e-04, 6.4673e-04,
        3.0956e-04, 5.0745e-04, 2.4505e-04, 1.0962e-04, 5.7799e-04, 1.7259e-04,
        6.1831e-05, 5.6838e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,614][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.6796e-07, 1.2463e-01, 8.4778e-01, 2.7145e-03, 1.9575e-02, 1.8608e-03,
        6.5191e-04, 1.1537e-04, 2.7598e-04, 3.3958e-04, 6.4384e-05, 1.4289e-04,
        1.9654e-04, 5.4160e-04, 1.0618e-04, 3.5545e-04, 3.3118e-04, 8.8054e-05,
        5.9450e-05, 1.6757e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,616][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.6135e-08, 8.5768e-01, 1.4048e-01, 1.1397e-03, 5.2031e-04, 1.3329e-04,
        4.1595e-05, 3.6659e-06, 2.0778e-06, 2.2445e-06, 1.6393e-07, 1.0561e-07,
        4.0586e-07, 8.4425e-08, 8.9581e-07, 4.9491e-07, 4.4882e-07, 2.0356e-08,
        7.8131e-09, 2.7703e-08], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,621][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0272, 0.1637, 0.0925, 0.0420, 0.0681, 0.0226, 0.0549, 0.0325, 0.0546,
        0.0178, 0.0083, 0.2005, 0.0179, 0.0487, 0.0357, 0.0197, 0.0427, 0.0066,
        0.0308, 0.0132], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:57,625][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:57,627][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2769],
        [ 215],
        [ 175],
        [  14],
        [  46],
        [  43],
        [  12],
        [  15],
        [  22],
        [   2],
        [  18],
        [  37],
        [  17],
        [   4],
        [  34],
        [   1],
        [   2],
        [   2],
        [   5],
        [   1]], device='cuda:0')
[2024-07-24 10:16:57,630][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2550],
        [ 189],
        [ 138],
        [   7],
        [  39],
        [  22],
        [   6],
        [   5],
        [  12],
        [   2],
        [   7],
        [  19],
        [   6],
        [   4],
        [  17],
        [   1],
        [   1],
        [   1],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:16:57,634][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3848],
        [40635],
        [49441],
        [49349],
        [49442],
        [49539],
        [49328],
        [49282],
        [49418],
        [49395],
        [49663],
        [49626],
        [49545],
        [49545],
        [49598],
        [49475],
        [49538],
        [49570],
        [49538],
        [49524]], device='cuda:0')
[2024-07-24 10:16:57,637][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[22420],
        [ 7136],
        [ 4018],
        [ 3618],
        [ 3997],
        [ 3715],
        [ 3680],
        [ 3751],
        [ 4273],
        [ 3815],
        [ 3850],
        [ 3678],
        [ 3681],
        [ 4188],
        [ 3777],
        [ 3881],
        [ 3774],
        [ 4611],
        [ 4006],
        [ 4422]], device='cuda:0')
[2024-07-24 10:16:57,638][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18258],
        [17859],
        [19071],
        [14033],
        [17799],
        [23636],
        [29352],
        [24135],
        [19325],
        [21880],
        [17856],
        [19305],
        [22264],
        [20542],
        [18533],
        [22501],
        [21914],
        [20251],
        [18208],
        [20184]], device='cuda:0')
[2024-07-24 10:16:57,640][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[30482],
        [28683],
        [26918],
        [24257],
        [26566],
        [24164],
        [25845],
        [29490],
        [23626],
        [30388],
        [26658],
        [26888],
        [26686],
        [27504],
        [26552],
        [28381],
        [26378],
        [27057],
        [27701],
        [27331]], device='cuda:0')
[2024-07-24 10:16:57,642][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6093],
        [46421],
        [24715],
        [45556],
        [19311],
        [45923],
        [44545],
        [45119],
        [44274],
        [44042],
        [45977],
        [42798],
        [45310],
        [24256],
        [40954],
        [44096],
        [42484],
        [45912],
        [42346],
        [44943]], device='cuda:0')
[2024-07-24 10:16:57,645][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31936],
        [29767],
        [18233],
        [15596],
        [11126],
        [11697],
        [ 7691],
        [17498],
        [ 8342],
        [18365],
        [10449],
        [ 5977],
        [ 9690],
        [10169],
        [ 6473],
        [ 8036],
        [ 7076],
        [ 6125],
        [ 6085],
        [ 5946]], device='cuda:0')
[2024-07-24 10:16:57,649][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[31930],
        [47842],
        [49768],
        [50235],
        [49891],
        [50181],
        [50227],
        [50206],
        [50145],
        [50204],
        [50166],
        [50233],
        [50232],
        [49868],
        [50223],
        [50207],
        [50226],
        [49821],
        [50183],
        [50170]], device='cuda:0')
[2024-07-24 10:16:57,652][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 2945],
        [31490],
        [31557],
        [32263],
        [31650],
        [32540],
        [33892],
        [35142],
        [33558],
        [33914],
        [33349],
        [33142],
        [34004],
        [33393],
        [34828],
        [35244],
        [35307],
        [33814],
        [36228],
        [35734]], device='cuda:0')
[2024-07-24 10:16:57,653][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7506],
        [ 6035],
        [26677],
        [21644],
        [27792],
        [26604],
        [28902],
        [26400],
        [23630],
        [22170],
        [21462],
        [20128],
        [21282],
        [19486],
        [18990],
        [20925],
        [21511],
        [20413],
        [19879],
        [23472]], device='cuda:0')
[2024-07-24 10:16:57,655][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 3155],
        [ 5223],
        [38212],
        [15688],
        [12418],
        [ 8032],
        [ 7664],
        [ 7121],
        [ 5544],
        [ 5572],
        [ 5185],
        [ 4777],
        [ 4774],
        [ 4234],
        [ 3871],
        [ 4149],
        [ 3660],
        [ 3785],
        [ 3371],
        [ 3831]], device='cuda:0')
[2024-07-24 10:16:57,657][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17732],
        [18631],
        [18642],
        [18359],
        [18602],
        [18612],
        [18727],
        [18338],
        [18641],
        [17320],
        [18769],
        [18815],
        [18885],
        [19251],
        [19000],
        [18928],
        [19195],
        [18789],
        [20278],
        [19435]], device='cuda:0')
[2024-07-24 10:16:57,660][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21362],
        [21064],
        [26158],
        [36107],
        [32532],
        [33259],
        [31995],
        [29657],
        [29031],
        [27569],
        [28545],
        [29131],
        [29544],
        [28152],
        [27897],
        [28282],
        [28260],
        [30354],
        [30501],
        [28945]], device='cuda:0')
[2024-07-24 10:16:57,663][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19764],
        [ 2771],
        [ 6379],
        [ 3417],
        [ 5955],
        [ 4945],
        [ 5159],
        [ 3178],
        [ 4990],
        [ 3568],
        [ 4607],
        [ 5381],
        [ 6042],
        [ 4876],
        [ 1553],
        [ 3782],
        [ 2016],
        [ 5150],
        [ 5120],
        [ 4688]], device='cuda:0')
[2024-07-24 10:16:57,667][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18341],
        [ 9455],
        [14585],
        [13751],
        [14617],
        [14222],
        [15086],
        [15264],
        [14665],
        [14726],
        [14621],
        [14644],
        [14701],
        [14702],
        [14650],
        [14849],
        [14744],
        [14685],
        [14856],
        [14671]], device='cuda:0')
[2024-07-24 10:16:57,668][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 7634],
        [16385],
        [ 5547],
        [ 4102],
        [ 8679],
        [ 6373],
        [ 6540],
        [ 5692],
        [ 8483],
        [ 7200],
        [ 7742],
        [ 6685],
        [ 6676],
        [11613],
        [ 7855],
        [ 8790],
        [ 7385],
        [13004],
        [ 9851],
        [11953]], device='cuda:0')
[2024-07-24 10:16:57,670][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 8659],
        [ 9789],
        [16428],
        [24684],
        [27542],
        [27039],
        [26339],
        [26820],
        [26501],
        [26674],
        [26326],
        [26270],
        [26386],
        [26402],
        [26285],
        [26277],
        [26260],
        [26306],
        [26299],
        [26300]], device='cuda:0')
[2024-07-24 10:16:57,672][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[276],
        [ 13],
        [ 59],
        [ 18],
        [ 55],
        [ 58],
        [ 56],
        [ 89],
        [ 42],
        [168],
        [ 53],
        [ 59],
        [ 53],
        [ 52],
        [ 55],
        [ 13],
        [ 49],
        [ 59],
        [ 54],
        [ 57]], device='cuda:0')
[2024-07-24 10:16:57,675][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 6159],
        [11722],
        [ 6988],
        [15455],
        [ 7606],
        [14304],
        [11929],
        [12865],
        [11867],
        [12185],
        [12403],
        [11742],
        [12279],
        [ 7455],
        [10162],
        [11567],
        [10004],
        [11791],
        [ 9578],
        [11051]], device='cuda:0')
[2024-07-24 10:16:57,678][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 2168],
        [ 2439],
        [ 5508],
        [ 7172],
        [10601],
        [ 9842],
        [ 8906],
        [ 2031],
        [ 3083],
        [ 1820],
        [ 3266],
        [10298],
        [ 4859],
        [ 3756],
        [ 9274],
        [ 2621],
        [ 6015],
        [ 8793],
        [10413],
        [ 7011]], device='cuda:0')
[2024-07-24 10:16:57,681][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7054],
        [ 269],
        [ 690],
        [7038],
        [ 725],
        [2486],
        [5558],
        [3662],
        [2342],
        [3703],
        [2150],
        [6145],
        [5832],
        [ 787],
        [5314],
        [3649],
        [4828],
        [ 727],
        [2777],
        [2241]], device='cuda:0')
[2024-07-24 10:16:57,683][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[2235],
        [6272],
        [6269],
        [6234],
        [6294],
        [6222],
        [5826],
        [5628],
        [5988],
        [5945],
        [5998],
        [6038],
        [5834],
        [6131],
        [5681],
        [5638],
        [5572],
        [5908],
        [5376],
        [5462]], device='cuda:0')
[2024-07-24 10:16:57,685][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8840],
        [ 7190],
        [18611],
        [10979],
        [19730],
        [21054],
        [21521],
        [20495],
        [20976],
        [19950],
        [20361],
        [20122],
        [20527],
        [20465],
        [20796],
        [20682],
        [21311],
        [20223],
        [21350],
        [20797]], device='cuda:0')
[2024-07-24 10:16:57,687][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[19941],
        [18335],
        [41763],
        [42323],
        [40706],
        [38896],
        [40184],
        [41567],
        [37366],
        [41537],
        [40218],
        [41437],
        [41897],
        [39385],
        [41305],
        [42455],
        [41669],
        [40308],
        [41472],
        [42540]], device='cuda:0')
[2024-07-24 10:16:57,690][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[3006],
        [5937],
        [5932],
        [5967],
        [5938],
        [5928],
        [5911],
        [5891],
        [5892],
        [5868],
        [5916],
        [5915],
        [5896],
        [5772],
        [5851],
        [5769],
        [5787],
        [5922],
        [5467],
        [5745]], device='cuda:0')
[2024-07-24 10:16:57,693][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[2079],
        [1861],
        [1955],
        [ 917],
        [1479],
        [ 974],
        [ 652],
        [1678],
        [2658],
        [1855],
        [2343],
        [3135],
        [2905],
        [2826],
        [3164],
        [2795],
        [3722],
        [2985],
        [3374],
        [2903]], device='cuda:0')
[2024-07-24 10:16:57,696][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49206],
        [49843],
        [48068],
        [45938],
        [44912],
        [44402],
        [43674],
        [45901],
        [45918],
        [45403],
        [45622],
        [42839],
        [44047],
        [46705],
        [43669],
        [46639],
        [44678],
        [43987],
        [43750],
        [44144]], device='cuda:0')
[2024-07-24 10:16:57,698][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29295],
        [47597],
        [46627],
        [47338],
        [47770],
        [40111],
        [45372],
        [44906],
        [42694],
        [44111],
        [42901],
        [41731],
        [39538],
        [45310],
        [44624],
        [41242],
        [44724],
        [44910],
        [42512],
        [42402]], device='cuda:0')
[2024-07-24 10:16:57,699][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383],
        [4383]], device='cuda:0')
[2024-07-24 10:16:57,793][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:57,793][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,794][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,795][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,795][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,797][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,797][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,798][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,799][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,799][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,800][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,801][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,801][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:57,802][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9777, 0.0223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,803][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9092, 0.0908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,806][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7592, 0.2408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,810][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9469, 0.0531], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,812][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5281, 0.4719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,813][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,813][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2348, 0.7652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,814][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7021, 0.2979], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,815][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7743, 0.2257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,817][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0019, 0.9981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,822][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0283, 0.9717], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,825][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6945, 0.3055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:57,826][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1328, 0.3328, 0.5343], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,826][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1648, 0.0728, 0.7624], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,827][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.7954, 0.1945, 0.0101], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,828][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.8486, 0.0495, 0.1019], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,830][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.2875, 0.5577, 0.1548], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,832][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([7.0704e-05, 9.7243e-01, 2.7502e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,836][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0230, 0.3450, 0.6320], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,838][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.2473, 0.2063, 0.5464], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,839][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.7190, 0.2302, 0.0508], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,840][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([3.0067e-05, 9.9455e-01, 5.4224e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,840][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0034, 0.9923, 0.0043], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,841][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0014, 0.7134, 0.2852], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:57,843][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2134, 0.1396, 0.6011, 0.0459], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,847][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0136, 0.0330, 0.9256, 0.0278], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,851][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1318, 0.2972, 0.1142, 0.4569], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,852][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3669, 0.2291, 0.2543, 0.1497], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,853][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0395, 0.6291, 0.0639, 0.2675], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,853][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0074, 0.6235, 0.0345, 0.3345], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,854][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0126, 0.2527, 0.5114, 0.2233], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,856][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0600, 0.4287, 0.4791, 0.0321], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,860][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1603, 0.2960, 0.2101, 0.3336], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,863][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([5.7793e-04, 7.1483e-01, 1.1573e-02, 2.7302e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,865][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0044, 0.7004, 0.0093, 0.2860], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,865][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0032, 0.3770, 0.5601, 0.0597], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:57,866][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0211, 0.1669, 0.6113, 0.0432, 0.1576], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,867][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0283, 0.0406, 0.8694, 0.0168, 0.0450], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,868][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.1861, 0.3841, 0.0315, 0.2859, 0.1124], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,870][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.3029, 0.1686, 0.2397, 0.0620, 0.2268], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,874][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0885, 0.3838, 0.2523, 0.1899, 0.0855], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,877][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ James] are: tensor([4.9253e-05, 7.9510e-01, 2.2011e-02, 1.8137e-01, 1.4650e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,881][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.0019, 0.2629, 0.4922, 0.1205, 0.1226], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,881][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0482, 0.3140, 0.4591, 0.0333, 0.1455], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,882][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.2603, 0.2138, 0.0924, 0.1597, 0.2739], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,883][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ James] are: tensor([2.5664e-05, 7.9465e-01, 9.8766e-03, 1.9304e-01, 2.4070e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,883][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0017, 0.7623, 0.0082, 0.2235, 0.0042], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,884][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ James] are: tensor([3.9520e-04, 4.8502e-01, 4.4052e-01, 5.4906e-02, 1.9158e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:57,888][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0016, 0.2777, 0.5935, 0.0187, 0.0673, 0.0411], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,892][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0184, 0.0656, 0.8657, 0.0131, 0.0301, 0.0070], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,894][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0418, 0.4305, 0.0602, 0.2321, 0.1840, 0.0514], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,895][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0445, 0.2653, 0.3231, 0.0458, 0.0880, 0.2333], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,895][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0127, 0.6224, 0.0503, 0.1992, 0.0122, 0.1032], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,896][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ were] are: tensor([2.5218e-04, 7.4733e-01, 2.5536e-02, 2.1745e-01, 2.5416e-03, 6.8907e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,897][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ were] are: tensor([4.3844e-04, 2.0083e-01, 5.9155e-01, 5.4509e-02, 9.3457e-02, 5.9207e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,899][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0036, 0.5342, 0.3979, 0.0173, 0.0328, 0.0142], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,904][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ were] are: tensor([0.0856, 0.2955, 0.0688, 0.1017, 0.1848, 0.2636], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,907][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ were] are: tensor([8.2752e-06, 9.0113e-01, 3.3204e-02, 4.3000e-02, 4.9536e-03, 1.7700e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,908][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ were] are: tensor([4.0799e-04, 8.0140e-01, 2.3300e-03, 1.8872e-01, 2.1517e-03, 4.9815e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,908][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ were] are: tensor([5.9289e-05, 4.8246e-01, 3.9152e-01, 3.3969e-02, 1.0724e-02, 8.1274e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:57,909][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0034, 0.0511, 0.8025, 0.0066, 0.0898, 0.0341, 0.0125],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,910][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0258, 0.0243, 0.8778, 0.0042, 0.0244, 0.0044, 0.0390],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,912][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0779, 0.3893, 0.1322, 0.1229, 0.1791, 0.0590, 0.0396],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,915][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0180, 0.1268, 0.4792, 0.0425, 0.1004, 0.1233, 0.1099],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,920][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0079, 0.5133, 0.1535, 0.0971, 0.0474, 0.0811, 0.0997],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,921][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([1.2959e-04, 6.9507e-01, 5.9536e-02, 2.1733e-01, 8.9698e-03, 1.1823e-02,
        7.1424e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,921][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([3.7474e-04, 1.0684e-01, 6.6996e-01, 4.4364e-02, 6.5742e-02, 8.3265e-02,
        2.9455e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,922][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0029, 0.2595, 0.6436, 0.0075, 0.0454, 0.0056, 0.0356],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,923][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([0.1053, 0.2361, 0.0965, 0.1063, 0.2558, 0.1463, 0.0537],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,925][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([2.5029e-06, 8.5432e-01, 6.3336e-02, 5.8230e-02, 3.7119e-03, 1.9199e-02,
        1.1974e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,929][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0019, 0.7729, 0.0059, 0.1997, 0.0040, 0.0140, 0.0016],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,931][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([1.7549e-05, 2.9095e-01, 3.7492e-01, 2.0649e-02, 5.7468e-03, 1.7977e-01,
        1.2794e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:57,933][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0059, 0.1080, 0.7085, 0.0097, 0.1101, 0.0199, 0.0106, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,934][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0345, 0.0522, 0.8223, 0.0075, 0.0491, 0.0034, 0.0253, 0.0057],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,935][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0761, 0.3703, 0.0697, 0.1264, 0.1465, 0.0391, 0.0722, 0.0997],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,936][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0707, 0.1199, 0.3165, 0.0262, 0.1804, 0.0637, 0.1493, 0.0734],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,936][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0357, 0.1187, 0.1680, 0.0742, 0.1629, 0.0677, 0.2746, 0.0982],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,939][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0220, 0.4011, 0.0472, 0.3367, 0.0214, 0.0439, 0.0490, 0.0788],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,941][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ about] are: tensor([3.0643e-04, 1.8802e-01, 4.3353e-01, 5.0108e-02, 8.6601e-02, 4.5711e-02,
        1.9640e-02, 1.7608e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,946][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0060, 0.1862, 0.7219, 0.0057, 0.0452, 0.0044, 0.0166, 0.0140],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,947][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.2304, 0.1993, 0.0529, 0.0563, 0.1675, 0.0746, 0.0486, 0.1704],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,948][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.0019, 0.2768, 0.0635, 0.0934, 0.0303, 0.1506, 0.0163, 0.3672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,949][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0048, 0.8347, 0.0088, 0.1287, 0.0049, 0.0109, 0.0019, 0.0053],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,949][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0009, 0.2010, 0.3509, 0.0269, 0.0165, 0.0411, 0.0496, 0.3130],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:57,952][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0039, 0.2095, 0.5350, 0.0198, 0.0446, 0.0647, 0.0319, 0.0708, 0.0196],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,956][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0861, 0.0847, 0.5238, 0.0104, 0.0328, 0.0107, 0.1233, 0.0316, 0.0966],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,960][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0873, 0.5070, 0.0299, 0.1158, 0.0482, 0.0328, 0.0738, 0.0746, 0.0306],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,960][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0323, 0.1547, 0.1236, 0.0485, 0.0670, 0.1174, 0.2330, 0.1153, 0.1082],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,961][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0107, 0.2236, 0.0747, 0.0694, 0.0434, 0.0640, 0.1970, 0.1284, 0.1889],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,962][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0007, 0.5472, 0.0451, 0.3032, 0.0126, 0.0236, 0.0191, 0.0277, 0.0207],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,963][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.0005, 0.2245, 0.2504, 0.0437, 0.0218, 0.0482, 0.0278, 0.3388, 0.0445],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,965][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0050, 0.6392, 0.2203, 0.0171, 0.0407, 0.0118, 0.0267, 0.0179, 0.0214],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,970][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ going] are: tensor([0.1401, 0.1533, 0.0372, 0.0697, 0.1463, 0.0832, 0.0562, 0.1529, 0.1613],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,973][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ going] are: tensor([1.2899e-04, 4.2027e-01, 6.0131e-02, 9.3248e-02, 2.6143e-02, 7.8131e-02,
        8.3297e-03, 2.5290e-01, 6.0711e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,974][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ going] are: tensor([7.7402e-04, 8.1315e-01, 2.7391e-03, 1.7137e-01, 2.1470e-03, 5.8025e-03,
        6.6959e-04, 2.3683e-03, 9.8710e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,974][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ going] are: tensor([1.0168e-04, 2.5690e-01, 2.5608e-01, 1.8547e-02, 2.8225e-03, 1.3291e-01,
        4.2315e-02, 2.4770e-01, 4.2615e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:57,975][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0052, 0.2285, 0.6173, 0.0065, 0.0561, 0.0249, 0.0118, 0.0238, 0.0086,
        0.0173], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,976][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0239, 0.0533, 0.8184, 0.0056, 0.0273, 0.0026, 0.0332, 0.0052, 0.0245,
        0.0059], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,978][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1478, 0.3394, 0.0670, 0.0941, 0.0926, 0.0282, 0.0802, 0.0649, 0.0369,
        0.0488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,983][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0355, 0.0890, 0.2576, 0.0192, 0.0924, 0.0783, 0.1325, 0.0571, 0.0788,
        0.1595], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,986][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0178, 0.1671, 0.0558, 0.0472, 0.0235, 0.0492, 0.1818, 0.0694, 0.1268,
        0.2613], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,987][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0315, 0.2131, 0.0243, 0.1551, 0.0097, 0.0296, 0.0264, 0.0731, 0.0403,
        0.3968], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,988][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.0421e-04, 2.4433e-01, 3.3679e-01, 3.2049e-02, 3.7452e-02, 3.3072e-02,
        2.4304e-02, 1.4767e-01, 3.0281e-02, 1.1385e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,988][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0104, 0.3957, 0.4286, 0.0099, 0.0537, 0.0074, 0.0359, 0.0171, 0.0207,
        0.0207], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,989][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0868, 0.2666, 0.0542, 0.0395, 0.1632, 0.0555, 0.0368, 0.1220, 0.1017,
        0.0737], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,992][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0023, 0.0787, 0.0053, 0.0183, 0.0039, 0.0349, 0.0033, 0.2679, 0.0257,
        0.5596], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,994][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0015, 0.8074, 0.0050, 0.1512, 0.0045, 0.0073, 0.0011, 0.0029, 0.0022,
        0.0169], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,995][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0033, 0.2723, 0.3286, 0.0216, 0.0106, 0.0336, 0.0575, 0.0910, 0.0165,
        0.1650], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:57,997][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([5.4674e-04, 3.1340e-01, 6.1769e-01, 2.7654e-03, 4.8401e-02, 5.3361e-03,
        2.1803e-03, 4.5642e-03, 1.4539e-03, 3.4633e-03, 1.9983e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,001][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0101, 0.0846, 0.8395, 0.0025, 0.0190, 0.0013, 0.0134, 0.0029, 0.0143,
        0.0050, 0.0073], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,001][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1280, 0.6077, 0.0444, 0.0532, 0.0574, 0.0125, 0.0248, 0.0317, 0.0104,
        0.0271, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,002][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0069, 0.1371, 0.3247, 0.0187, 0.0639, 0.0607, 0.1010, 0.0755, 0.0404,
        0.1228, 0.0484], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,003][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0016, 0.4150, 0.0864, 0.0325, 0.0238, 0.0364, 0.1289, 0.0271, 0.0716,
        0.1459, 0.0308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,004][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([3.0939e-04, 9.1870e-01, 3.2511e-02, 3.4061e-02, 2.2261e-03, 4.2499e-03,
        8.9897e-04, 9.6571e-04, 6.1719e-04, 5.0317e-03, 4.2994e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,006][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.2624e-05, 3.4753e-01, 4.3288e-01, 1.8391e-02, 2.3360e-02, 1.2997e-02,
        5.1332e-03, 5.5461e-02, 7.8073e-03, 6.6463e-02, 2.9959e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,009][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0010, 0.3872, 0.5311, 0.0059, 0.0318, 0.0032, 0.0137, 0.0079, 0.0063,
        0.0072, 0.0046], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,014][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1327, 0.3258, 0.0500, 0.0348, 0.1618, 0.0337, 0.0236, 0.1129, 0.0554,
        0.0499, 0.0194], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,015][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([4.4172e-06, 9.3794e-01, 3.1058e-02, 5.1389e-03, 2.0937e-03, 4.4718e-03,
        2.6324e-04, 5.6761e-03, 5.4387e-04, 1.2002e-02, 8.0863e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,015][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([1.5837e-03, 8.5063e-01, 5.3492e-03, 1.0965e-01, 3.1396e-03, 4.1130e-03,
        7.9398e-04, 1.8363e-03, 9.5626e-04, 1.0426e-02, 1.1521e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,016][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.8671e-05, 3.4771e-01, 2.3708e-01, 7.3526e-03, 2.5341e-03, 1.9593e-02,
        1.1496e-02, 8.9979e-02, 7.0371e-03, 1.3853e-01, 1.3867e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,017][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ store] are: tensor([1.4774e-04, 2.5623e-01, 6.4329e-01, 1.0502e-02, 3.2440e-02, 1.3522e-02,
        8.3252e-03, 9.8825e-03, 2.7660e-03, 1.6580e-02, 6.7250e-04, 5.6474e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,020][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0037, 0.0569, 0.7580, 0.0063, 0.0151, 0.0082, 0.0374, 0.0145, 0.0276,
        0.0170, 0.0215, 0.0336], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,024][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0023, 0.3760, 0.1003, 0.1476, 0.0803, 0.0445, 0.0386, 0.0909, 0.0200,
        0.0721, 0.0126, 0.0147], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,027][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0028, 0.2173, 0.2549, 0.0361, 0.0746, 0.1041, 0.0522, 0.0407, 0.0284,
        0.1338, 0.0373, 0.0178], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,028][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0010, 0.4844, 0.1246, 0.0607, 0.0234, 0.0403, 0.0328, 0.0278, 0.0251,
        0.1447, 0.0176, 0.0178], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,029][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ store] are: tensor([2.4389e-06, 8.8285e-01, 7.3389e-02, 2.2774e-02, 3.5124e-03, 1.8155e-03,
        8.3772e-04, 7.9933e-04, 3.5555e-04, 1.2278e-02, 1.3386e-03, 4.8814e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,030][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ store] are: tensor([1.7730e-05, 9.7729e-02, 4.9413e-01, 2.0769e-02, 3.0107e-02, 3.1663e-02,
        1.5936e-02, 1.1335e-01, 1.5136e-02, 1.3116e-01, 4.4821e-02, 5.1750e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,030][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ store] are: tensor([2.9005e-04, 4.1414e-01, 5.0298e-01, 7.8842e-03, 2.5348e-02, 5.5904e-03,
        1.0028e-02, 6.3127e-03, 4.1359e-03, 8.6102e-03, 2.8609e-03, 1.1822e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,034][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0081, 0.3386, 0.0488, 0.0790, 0.0864, 0.0586, 0.0173, 0.0784, 0.0488,
        0.0680, 0.0973, 0.0706], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,036][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ store] are: tensor([1.2698e-07, 9.3622e-01, 2.9685e-02, 1.2194e-02, 1.6044e-03, 2.0437e-03,
        1.5246e-04, 1.8921e-03, 1.7028e-04, 1.4322e-02, 1.5730e-03, 1.4400e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,039][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ store] are: tensor([1.8413e-04, 8.0366e-01, 3.4226e-03, 1.5787e-01, 2.2524e-03, 6.2793e-03,
        3.5420e-04, 1.1893e-03, 8.5305e-04, 1.0244e-02, 1.3198e-02, 4.9629e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,041][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ store] are: tensor([6.1895e-08, 7.4655e-02, 8.9091e-02, 1.5686e-03, 6.3585e-04, 7.8766e-03,
        1.1271e-02, 1.7281e-01, 1.0084e-02, 1.4708e-01, 4.8473e-01, 1.9999e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,041][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([1.6577e-03, 1.1929e-01, 7.7242e-01, 3.6801e-03, 5.9751e-02, 1.2436e-02,
        4.7726e-03, 6.9790e-03, 2.8705e-03, 4.9055e-03, 5.4455e-04, 8.1691e-03,
        2.5250e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,042][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0058, 0.0368, 0.8479, 0.0031, 0.0227, 0.0021, 0.0207, 0.0035, 0.0146,
        0.0044, 0.0078, 0.0217, 0.0089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,043][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0750, 0.4472, 0.0793, 0.0758, 0.0935, 0.0217, 0.0537, 0.0447, 0.0224,
        0.0338, 0.0054, 0.0133, 0.0342], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,044][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0108, 0.1146, 0.3145, 0.0218, 0.0806, 0.0688, 0.1005, 0.0410, 0.0486,
        0.1051, 0.0404, 0.0176, 0.0356], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,047][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0096, 0.4249, 0.0770, 0.0250, 0.0164, 0.0317, 0.0923, 0.0419, 0.0530,
        0.1466, 0.0354, 0.0272, 0.0189], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,049][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([9.6647e-05, 8.8322e-01, 5.9208e-02, 3.8493e-02, 2.0013e-03, 4.5375e-03,
        1.3846e-03, 1.0786e-03, 7.0071e-04, 7.6289e-03, 4.8538e-04, 5.7542e-05,
        1.1039e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,052][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([7.6257e-05, 2.5059e-01, 4.1266e-01, 2.1494e-02, 3.2905e-02, 2.3906e-02,
        1.3129e-02, 8.4102e-02, 1.5403e-02, 6.6863e-02, 3.6469e-02, 5.3503e-03,
        3.7053e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,054][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0019, 0.3337, 0.5719, 0.0053, 0.0304, 0.0036, 0.0139, 0.0065, 0.0054,
        0.0073, 0.0051, 0.0110, 0.0040], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,055][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0518, 0.2633, 0.0805, 0.0310, 0.1653, 0.0376, 0.0255, 0.0827, 0.0767,
        0.0406, 0.0530, 0.0706, 0.0215], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,056][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([3.9937e-06, 9.4887e-01, 2.7910e-02, 5.1840e-03, 7.5773e-04, 2.9749e-03,
        1.6133e-04, 2.7070e-03, 3.1663e-04, 9.3551e-03, 2.7095e-04, 9.6882e-05,
        1.3912e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,056][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([1.1077e-03, 8.2071e-01, 4.2856e-03, 1.3058e-01, 2.8371e-03, 4.6348e-03,
        8.3694e-04, 2.0638e-03, 1.6455e-03, 1.3851e-02, 1.5228e-02, 7.8176e-04,
        1.4405e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,059][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0005, 0.3023, 0.2925, 0.0077, 0.0081, 0.0176, 0.0182, 0.0457, 0.0057,
        0.0896, 0.1854, 0.0011, 0.0257], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,061][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ James] are: tensor([2.4197e-04, 1.9494e-01, 6.5281e-01, 1.3366e-02, 5.1543e-02, 2.5277e-02,
        5.3063e-03, 1.2355e-02, 2.4357e-03, 1.0495e-02, 1.0473e-03, 5.7203e-03,
        3.6215e-03, 2.0832e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,065][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0048, 0.0645, 0.6505, 0.0082, 0.0512, 0.0068, 0.0261, 0.0071, 0.0151,
        0.0101, 0.0118, 0.0284, 0.0162, 0.0993], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,067][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0288, 0.3485, 0.0155, 0.0949, 0.0374, 0.0482, 0.0403, 0.1103, 0.0289,
        0.0478, 0.0078, 0.0428, 0.0466, 0.1022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,068][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0055, 0.1243, 0.1894, 0.0320, 0.0891, 0.0742, 0.0702, 0.0422, 0.0253,
        0.0554, 0.0347, 0.0095, 0.0265, 0.2216], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,069][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0069, 0.2148, 0.3074, 0.0261, 0.0767, 0.0375, 0.0693, 0.0251, 0.0483,
        0.0903, 0.0191, 0.0528, 0.0160, 0.0096], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,070][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ James] are: tensor([5.7704e-05, 5.8711e-01, 2.4449e-01, 7.5309e-02, 1.3594e-02, 7.5107e-03,
        1.5766e-02, 8.3127e-03, 6.8511e-03, 3.1422e-02, 3.0480e-03, 7.9494e-04,
        4.9951e-03, 7.4321e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,071][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ James] are: tensor([2.6230e-05, 2.4883e-01, 3.5516e-01, 3.4287e-02, 3.9035e-02, 3.6595e-02,
        7.4904e-03, 9.7015e-02, 1.1676e-02, 6.3186e-02, 2.2988e-02, 4.6850e-03,
        2.0701e-02, 5.8322e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,074][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0033, 0.4109, 0.3833, 0.0145, 0.0802, 0.0083, 0.0143, 0.0075, 0.0069,
        0.0086, 0.0065, 0.0149, 0.0060, 0.0348], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,078][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ James] are: tensor([0.0227, 0.2215, 0.0737, 0.0486, 0.1452, 0.0362, 0.0257, 0.0677, 0.0343,
        0.0314, 0.0258, 0.0979, 0.0252, 0.1442], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,080][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ James] are: tensor([2.8864e-05, 8.0223e-01, 1.0285e-01, 4.2434e-02, 1.0237e-02, 8.4008e-03,
        1.4363e-03, 8.1048e-03, 2.0830e-03, 1.5740e-02, 2.1395e-03, 1.6978e-03,
        1.7452e-03, 8.7106e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,081][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ James] are: tensor([7.8291e-04, 8.0023e-01, 5.7027e-03, 1.5403e-01, 2.3345e-03, 6.0140e-03,
        1.1874e-03, 2.0691e-03, 1.5177e-03, 9.4324e-03, 1.3873e-02, 1.2163e-03,
        8.9046e-04, 7.1770e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,082][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ James] are: tensor([4.9444e-06, 1.5352e-01, 2.6251e-01, 2.4703e-03, 4.7086e-03, 3.9162e-02,
        8.0055e-03, 7.1393e-02, 5.9765e-03, 8.3540e-02, 3.5912e-01, 7.3030e-04,
        7.5634e-03, 1.3033e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,083][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([5.1129e-05, 1.5061e-01, 7.2446e-01, 4.8901e-03, 4.0198e-02, 1.4513e-02,
        6.8148e-03, 9.6846e-03, 2.8946e-03, 1.2635e-02, 9.9016e-04, 5.4584e-03,
        3.9369e-03, 2.1007e-02, 1.8509e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,084][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0033, 0.0548, 0.7029, 0.0032, 0.0280, 0.0028, 0.0345, 0.0058, 0.0216,
        0.0075, 0.0115, 0.0416, 0.0116, 0.0582, 0.0127], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,087][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0103, 0.3567, 0.0476, 0.0985, 0.0468, 0.0288, 0.0451, 0.0643, 0.0282,
        0.0538, 0.0116, 0.0138, 0.0370, 0.0773, 0.0802], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,091][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0020, 0.1956, 0.1527, 0.0241, 0.0473, 0.0543, 0.0644, 0.0275, 0.0404,
        0.1181, 0.0397, 0.0181, 0.0260, 0.1389, 0.0510], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,094][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0024, 0.3048, 0.0927, 0.0448, 0.0175, 0.0366, 0.1066, 0.0379, 0.0766,
        0.1496, 0.0249, 0.0417, 0.0144, 0.0030, 0.0464], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,095][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([2.6810e-04, 8.2977e-01, 3.8282e-02, 7.3467e-02, 5.0364e-03, 7.5073e-03,
        3.5269e-03, 2.8046e-03, 2.2940e-03, 2.7739e-02, 2.0953e-03, 3.3998e-04,
        4.7557e-03, 3.7607e-04, 1.7399e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,095][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([1.2863e-05, 2.1450e-01, 3.6557e-01, 2.3318e-02, 3.3163e-02, 2.2848e-02,
        1.3023e-02, 9.0393e-02, 2.2847e-02, 9.2284e-02, 4.5322e-02, 5.1752e-03,
        2.1933e-02, 4.6596e-02, 3.0139e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,096][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0008, 0.3283, 0.5453, 0.0069, 0.0273, 0.0055, 0.0120, 0.0117, 0.0086,
        0.0113, 0.0079, 0.0162, 0.0037, 0.0104, 0.0040], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,097][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([0.0187, 0.2071, 0.0933, 0.0293, 0.1270, 0.0255, 0.0325, 0.0813, 0.0528,
        0.0322, 0.0610, 0.0465, 0.0156, 0.1050, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,099][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([3.5406e-06, 8.2730e-01, 7.2338e-02, 1.4591e-02, 3.2288e-03, 1.4589e-02,
        8.8387e-04, 8.7218e-03, 2.9883e-03, 4.1614e-02, 4.0909e-03, 1.0212e-03,
        5.8119e-03, 9.1241e-04, 1.9092e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,102][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([6.0900e-04, 7.7352e-01, 3.2651e-03, 1.8035e-01, 3.1651e-03, 4.7090e-03,
        8.0006e-04, 2.0212e-03, 1.1891e-03, 9.2400e-03, 1.7514e-02, 9.1694e-04,
        8.6425e-04, 7.8936e-04, 1.0418e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,104][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([9.1365e-06, 2.4994e-01, 2.3209e-01, 4.0633e-03, 3.0438e-03, 2.0287e-02,
        1.4195e-02, 7.5072e-02, 1.0634e-02, 1.0877e-01, 2.4982e-01, 1.0387e-03,
        1.2915e-02, 5.6680e-04, 1.7552e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,107][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.2922e-04, 2.9214e-01, 6.1061e-01, 4.3298e-03, 3.8260e-02, 1.0868e-02,
        6.3729e-03, 5.8257e-03, 2.6888e-03, 5.3467e-03, 4.1848e-04, 5.8984e-03,
        1.7592e-03, 1.0558e-02, 2.2420e-03, 2.3511e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,108][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0019, 0.0856, 0.7771, 0.0068, 0.0258, 0.0026, 0.0220, 0.0037, 0.0124,
        0.0043, 0.0038, 0.0149, 0.0054, 0.0174, 0.0051, 0.0111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,109][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0155, 0.3617, 0.0820, 0.0931, 0.0933, 0.0243, 0.0530, 0.0432, 0.0179,
        0.0281, 0.0032, 0.0095, 0.0174, 0.0608, 0.0605, 0.0366],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,110][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0039, 0.1008, 0.2291, 0.0146, 0.0857, 0.0567, 0.0583, 0.0184, 0.0346,
        0.0757, 0.0173, 0.0133, 0.0140, 0.1571, 0.0375, 0.0830],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,112][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0029, 0.2570, 0.0978, 0.0435, 0.0210, 0.0438, 0.1132, 0.0385, 0.0777,
        0.1542, 0.0209, 0.0274, 0.0117, 0.0025, 0.0386, 0.0493],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,116][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0015, 0.6251, 0.0774, 0.0810, 0.0083, 0.0203, 0.0164, 0.0166, 0.0108,
        0.0781, 0.0077, 0.0011, 0.0121, 0.0021, 0.0078, 0.0338],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,118][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.8225e-05, 2.6909e-01, 4.2611e-01, 2.0192e-02, 3.7216e-02, 2.0099e-02,
        1.3138e-02, 5.8519e-02, 1.4494e-02, 4.7037e-02, 1.6848e-02, 3.7045e-03,
        1.8080e-02, 3.1063e-02, 2.2866e-03, 2.2109e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,120][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0019, 0.3491, 0.5064, 0.0079, 0.0377, 0.0047, 0.0154, 0.0092, 0.0079,
        0.0117, 0.0064, 0.0129, 0.0049, 0.0135, 0.0025, 0.0077],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,121][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0176, 0.3128, 0.0531, 0.0378, 0.1380, 0.0439, 0.0206, 0.0723, 0.0435,
        0.0295, 0.0364, 0.0468, 0.0171, 0.0572, 0.0416, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,122][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.6724e-05, 6.9014e-01, 4.0603e-02, 1.7379e-02, 5.1994e-03, 2.8278e-02,
        2.0237e-03, 4.2370e-02, 9.6528e-03, 9.3392e-02, 4.8778e-03, 5.0083e-03,
        1.6359e-02, 7.5970e-03, 8.2488e-03, 2.8808e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,123][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.1466e-04, 8.3040e-01, 2.9074e-03, 1.3565e-01, 2.6360e-03, 3.3502e-03,
        3.5685e-04, 7.9420e-04, 6.2561e-04, 6.8743e-03, 8.8095e-03, 2.6173e-04,
        6.3592e-04, 6.0996e-04, 5.9029e-04, 5.1837e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,124][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.6284e-04, 2.7609e-01, 4.1829e-01, 5.8793e-03, 6.1248e-03, 2.2365e-02,
        2.2468e-02, 4.5092e-02, 6.2215e-03, 6.1720e-02, 9.4947e-02, 9.1550e-04,
        1.1980e-02, 8.5525e-04, 9.0236e-03, 1.7868e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,126][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ give] are: tensor([1.2496e-04, 9.4717e-02, 7.9392e-01, 2.9489e-03, 5.2874e-02, 7.7358e-03,
        3.5372e-03, 4.5390e-03, 1.0386e-03, 5.4763e-03, 2.9194e-04, 3.3596e-03,
        1.3934e-03, 2.1839e-02, 1.1974e-03, 3.1298e-03, 1.8784e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,130][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0031, 0.0832, 0.6766, 0.0032, 0.0489, 0.0055, 0.0160, 0.0061, 0.0088,
        0.0096, 0.0065, 0.0123, 0.0090, 0.0614, 0.0078, 0.0305, 0.0115],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,133][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0114, 0.2347, 0.0785, 0.0646, 0.1279, 0.0246, 0.0217, 0.0462, 0.0139,
        0.0489, 0.0045, 0.0092, 0.0220, 0.1623, 0.0427, 0.0644, 0.0227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,134][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0013, 0.0926, 0.2370, 0.0114, 0.0837, 0.0326, 0.0271, 0.0142, 0.0113,
        0.0580, 0.0096, 0.0121, 0.0142, 0.2679, 0.0193, 0.0780, 0.0296],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,135][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0040, 0.2514, 0.1894, 0.0494, 0.0366, 0.0338, 0.0539, 0.0304, 0.0356,
        0.1214, 0.0228, 0.0195, 0.0169, 0.0078, 0.0218, 0.0670, 0.0383],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,136][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ give] are: tensor([2.0001e-04, 6.6215e-01, 1.3426e-01, 7.7157e-02, 9.9069e-03, 1.7515e-02,
        6.3440e-03, 7.0265e-03, 4.8262e-03, 3.8938e-02, 4.6513e-03, 1.1534e-03,
        6.9919e-03, 9.8843e-04, 6.2085e-03, 1.7335e-02, 4.3477e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,137][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ give] are: tensor([7.6751e-06, 1.5047e-01, 5.3447e-01, 9.7822e-03, 5.4793e-02, 1.6618e-02,
        7.3857e-03, 4.7739e-02, 1.0937e-02, 5.4300e-02, 1.4205e-02, 3.0611e-03,
        1.3276e-02, 5.4488e-02, 1.6069e-03, 2.5313e-02, 1.5548e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,140][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0008, 0.1078, 0.7393, 0.0046, 0.0491, 0.0041, 0.0085, 0.0066, 0.0047,
        0.0073, 0.0049, 0.0134, 0.0029, 0.0304, 0.0035, 0.0059, 0.0060],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,145][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ give] are: tensor([0.0127, 0.1767, 0.0688, 0.0300, 0.1567, 0.0308, 0.0196, 0.0576, 0.0334,
        0.0467, 0.0370, 0.0479, 0.0209, 0.1214, 0.0355, 0.0381, 0.0661],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,147][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ give] are: tensor([1.8383e-06, 7.5077e-01, 8.3939e-02, 2.8131e-02, 2.7052e-03, 1.3594e-02,
        1.6720e-03, 1.0492e-02, 4.9869e-03, 6.4279e-02, 5.4759e-03, 1.6724e-03,
        9.2345e-03, 1.3358e-03, 4.0838e-03, 1.5669e-02, 1.9563e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,148][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ give] are: tensor([1.5831e-04, 8.8155e-01, 1.7831e-03, 9.6053e-02, 1.3689e-03, 2.7873e-03,
        1.7029e-04, 5.4095e-04, 2.6797e-04, 4.8686e-03, 5.6177e-03, 1.3850e-04,
        2.8489e-04, 2.7901e-04, 3.2255e-04, 3.5462e-03, 2.6178e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,149][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ give] are: tensor([1.3453e-05, 3.2612e-01, 3.4975e-01, 7.5219e-03, 1.4511e-02, 2.0477e-02,
        5.9705e-03, 3.7175e-02, 3.8801e-03, 8.2209e-02, 8.7178e-02, 7.7100e-04,
        1.5558e-02, 1.8562e-03, 6.2776e-03, 2.9947e-02, 1.0788e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,149][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([1.3350e-05, 3.2811e-01, 6.3944e-01, 1.5521e-03, 2.1847e-02, 2.1931e-03,
        1.0337e-03, 7.2883e-04, 2.7200e-04, 7.5775e-04, 4.4921e-05, 7.6509e-04,
        2.4069e-04, 1.8892e-03, 3.6153e-04, 2.7332e-04, 4.2283e-04, 5.4937e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,151][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.7138e-04, 1.7744e-01, 7.6391e-01, 4.0825e-03, 1.1283e-02, 2.2173e-03,
        5.2087e-03, 1.2889e-03, 2.8787e-03, 2.5999e-03, 1.6812e-03, 5.1319e-03,
        2.2225e-03, 4.7101e-03, 2.1675e-03, 4.8569e-03, 2.0513e-03, 5.9960e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,154][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0016, 0.7272, 0.0448, 0.0519, 0.0408, 0.0131, 0.0179, 0.0162, 0.0042,
        0.0145, 0.0009, 0.0026, 0.0065, 0.0185, 0.0201, 0.0112, 0.0059, 0.0020],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,158][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0006, 0.3732, 0.2967, 0.0218, 0.0269, 0.0367, 0.0307, 0.0114, 0.0115,
        0.0467, 0.0097, 0.0044, 0.0111, 0.0276, 0.0165, 0.0419, 0.0189, 0.0136],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,160][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.5973e-04, 5.8873e-01, 1.5565e-01, 3.5346e-02, 1.6057e-02, 2.6228e-02,
        3.6940e-02, 7.5873e-03, 2.5194e-02, 5.4242e-02, 6.0331e-03, 6.5780e-03,
        4.2084e-03, 4.5913e-04, 8.7841e-03, 1.3921e-02, 1.1629e-02, 2.2518e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,161][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([6.3119e-07, 9.5897e-01, 3.2506e-02, 6.2172e-03, 5.0978e-04, 6.5483e-04,
        2.1061e-04, 6.0706e-05, 6.0357e-05, 3.7833e-04, 2.3109e-05, 5.6388e-06,
        1.2239e-04, 6.7577e-06, 6.7383e-05, 1.5283e-04, 4.1161e-05, 9.5410e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,162][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.1842e-07, 3.6103e-01, 5.6288e-01, 8.9357e-03, 1.9010e-02, 6.2045e-03,
        1.8475e-03, 8.5718e-03, 1.8561e-03, 1.1351e-02, 2.7902e-03, 8.9516e-04,
        3.1447e-03, 5.3937e-03, 5.7522e-04, 3.5092e-03, 2.1576e-04, 1.7887e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,163][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0006, 0.4138, 0.4948, 0.0084, 0.0240, 0.0042, 0.0079, 0.0063, 0.0038,
        0.0061, 0.0041, 0.0074, 0.0024, 0.0049, 0.0014, 0.0033, 0.0019, 0.0048],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,165][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0153, 0.4914, 0.0707, 0.0495, 0.0797, 0.0376, 0.0151, 0.0330, 0.0150,
        0.0200, 0.0085, 0.0255, 0.0089, 0.0211, 0.0288, 0.0188, 0.0397, 0.0213],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,168][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.7574e-09, 9.7786e-01, 2.1161e-02, 2.8459e-04, 1.6623e-04, 2.3188e-04,
        7.3626e-06, 4.1972e-05, 9.6305e-06, 1.4014e-04, 2.9921e-06, 2.2333e-06,
        2.5259e-05, 5.3973e-06, 1.4108e-05, 3.9727e-05, 8.8548e-06, 1.0375e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,171][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.1391e-04, 8.9035e-01, 1.8494e-03, 8.5750e-02, 1.0167e-03, 1.7443e-03,
        1.3369e-04, 2.9663e-04, 1.3006e-04, 2.5084e-03, 2.6489e-03, 8.4827e-05,
        2.5783e-04, 1.1727e-04, 1.2323e-04, 1.6735e-03, 1.5649e-04, 1.1046e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,173][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.8652e-07, 5.0109e-01, 3.3944e-01, 2.5788e-03, 2.4405e-03, 7.2530e-03,
        3.4477e-03, 3.3487e-02, 1.4533e-03, 4.7323e-02, 3.7627e-02, 3.8664e-04,
        4.3814e-03, 2.2744e-04, 3.1860e-03, 7.5143e-03, 4.1266e-03, 4.0417e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,174][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([7.2655e-05, 2.4033e-01, 6.3894e-01, 8.3291e-03, 2.6616e-02, 1.6664e-02,
        7.3409e-03, 8.6894e-03, 3.2766e-03, 1.2497e-02, 1.2335e-03, 5.0936e-03,
        3.6209e-03, 1.4006e-02, 2.7518e-03, 4.6116e-03, 3.2442e-03, 1.2504e-03,
        1.4303e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,175][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0011, 0.0836, 0.5574, 0.0041, 0.0193, 0.0083, 0.0223, 0.0089, 0.0169,
        0.0139, 0.0163, 0.0227, 0.0131, 0.0344, 0.0099, 0.0307, 0.0121, 0.0526,
        0.0725], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,176][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0026, 0.2185, 0.0413, 0.0717, 0.0358, 0.0443, 0.0212, 0.0726, 0.0200,
        0.0630, 0.0095, 0.0097, 0.0424, 0.0836, 0.0751, 0.1013, 0.0208, 0.0275,
        0.0392], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,178][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0004, 0.1593, 0.1754, 0.0209, 0.0428, 0.0681, 0.0422, 0.0185, 0.0176,
        0.0866, 0.0189, 0.0098, 0.0189, 0.1010, 0.0315, 0.0923, 0.0352, 0.0306,
        0.0298], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,182][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0016, 0.4024, 0.2707, 0.0427, 0.0255, 0.0387, 0.0262, 0.0084, 0.0207,
        0.0456, 0.0126, 0.0111, 0.0138, 0.0022, 0.0235, 0.0242, 0.0223, 0.0047,
        0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,185][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([3.0092e-07, 7.6629e-01, 2.0055e-01, 1.8694e-02, 4.4215e-03, 2.3639e-03,
        7.4387e-04, 3.0988e-04, 3.4651e-04, 3.3869e-03, 7.5942e-04, 9.0033e-05,
        7.0929e-04, 2.0950e-05, 2.3910e-04, 7.3879e-04, 1.8399e-04, 1.4358e-04,
        7.3791e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,186][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([9.0151e-06, 1.4089e-01, 4.0810e-01, 2.4303e-02, 3.3753e-02, 2.4868e-02,
        1.0303e-02, 7.2977e-02, 1.3764e-02, 8.6690e-02, 2.8491e-02, 4.5043e-03,
        2.2640e-02, 5.6252e-02, 3.4733e-03, 4.4100e-02, 2.0093e-03, 2.0984e-02,
        1.8830e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,187][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0006, 0.3497, 0.4972, 0.0107, 0.0350, 0.0079, 0.0149, 0.0105, 0.0061,
        0.0122, 0.0069, 0.0136, 0.0040, 0.0096, 0.0027, 0.0058, 0.0042, 0.0048,
        0.0037], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,188][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([0.0112, 0.2849, 0.0541, 0.0329, 0.0529, 0.0311, 0.0239, 0.0478, 0.0261,
        0.0424, 0.0457, 0.0323, 0.0282, 0.0629, 0.0587, 0.0413, 0.0488, 0.0624,
        0.0125], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,189][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([1.1698e-08, 8.7755e-01, 1.0913e-01, 7.4618e-03, 1.6235e-03, 1.2777e-03,
        9.8774e-05, 2.4356e-04, 9.8691e-05, 1.3717e-03, 2.8200e-04, 1.4081e-04,
        2.9463e-04, 1.5475e-05, 1.2461e-04, 1.7830e-04, 7.8888e-05, 1.9503e-05,
        8.9103e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,191][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([1.7588e-04, 8.2365e-01, 2.9823e-03, 1.1918e-01, 1.8762e-03, 3.1588e-03,
        2.6201e-04, 8.6451e-04, 4.9455e-04, 5.7708e-03, 6.6896e-03, 2.2469e-04,
        4.9608e-04, 3.1989e-04, 4.0932e-04, 3.4646e-03, 4.4540e-04, 2.8809e-02,
        7.3331e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,193][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([3.9399e-07, 1.7517e-01, 1.9088e-01, 3.9885e-03, 2.8861e-03, 1.6546e-02,
        8.1687e-03, 7.2133e-02, 6.3964e-03, 8.4178e-02, 3.5046e-01, 3.5193e-04,
        1.5473e-02, 3.5777e-04, 4.5936e-03, 2.5083e-02, 9.8564e-03, 3.3049e-02,
        4.3036e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,196][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.3226e-05, 3.2035e-01, 6.4118e-01, 1.6489e-03, 2.2547e-02, 2.9081e-03,
        1.5969e-03, 1.0043e-03, 5.5339e-04, 1.1886e-03, 7.5103e-05, 1.0871e-03,
        4.1995e-04, 3.0024e-03, 5.4718e-04, 5.1669e-04, 7.1720e-04, 1.0450e-04,
        3.2242e-04, 2.0891e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,199][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.8895e-04, 1.2527e-01, 7.9402e-01, 3.6476e-03, 1.7343e-02, 1.1708e-03,
        7.9801e-03, 1.1396e-03, 4.3449e-03, 1.8923e-03, 1.1884e-03, 4.7853e-03,
        1.9293e-03, 6.8007e-03, 1.6678e-03, 4.4814e-03, 4.2827e-03, 4.2527e-03,
        9.1513e-03, 4.1688e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,200][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0057, 0.4963, 0.0975, 0.0614, 0.0847, 0.0158, 0.0305, 0.0241, 0.0110,
        0.0180, 0.0015, 0.0056, 0.0105, 0.0386, 0.0327, 0.0229, 0.0149, 0.0032,
        0.0155, 0.0097], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,201][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0012, 0.1947, 0.3559, 0.0159, 0.0701, 0.0396, 0.0364, 0.0087, 0.0167,
        0.0445, 0.0081, 0.0066, 0.0093, 0.0657, 0.0186, 0.0464, 0.0246, 0.0095,
        0.0125, 0.0148], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,202][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([4.0894e-04, 5.3263e-01, 1.7317e-01, 3.0571e-02, 1.7012e-02, 2.5485e-02,
        5.4397e-02, 1.1655e-02, 2.6877e-02, 5.6686e-02, 6.5478e-03, 9.9462e-03,
        4.3043e-03, 6.0951e-04, 1.2340e-02, 1.3129e-02, 1.5850e-02, 1.8051e-03,
        1.3657e-03, 5.2041e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,203][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.3306e-06, 9.0169e-01, 8.6390e-02, 8.4305e-03, 1.0140e-03, 8.0024e-04,
        3.2564e-04, 7.6687e-05, 7.2512e-05, 6.0455e-04, 5.3028e-05, 8.9543e-06,
        1.4461e-04, 8.7592e-06, 6.1300e-05, 2.1698e-04, 6.3319e-05, 1.4792e-05,
        1.3287e-06, 2.6208e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,205][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.1413e-06, 3.8917e-01, 4.7241e-01, 1.2735e-02, 2.8917e-02, 8.4748e-03,
        4.7154e-03, 1.6973e-02, 5.5046e-03, 1.9189e-02, 4.7940e-03, 1.4706e-03,
        6.6767e-03, 1.1436e-02, 8.6913e-04, 7.7084e-03, 6.3167e-04, 3.9339e-03,
        5.9342e-04, 3.8035e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,207][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.5658e-04, 3.9223e-01, 5.3352e-01, 5.4390e-03, 2.3094e-02, 2.4930e-03,
        7.7200e-03, 3.1709e-03, 3.0140e-03, 5.3527e-03, 2.5958e-03, 4.7262e-03,
        1.9852e-03, 4.8377e-03, 9.2500e-04, 3.0064e-03, 1.3712e-03, 2.1065e-03,
        1.0650e-03, 1.0966e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,212][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0089, 0.4593, 0.0599, 0.0296, 0.1069, 0.0294, 0.0124, 0.0383, 0.0248,
        0.0207, 0.0174, 0.0291, 0.0119, 0.0301, 0.0241, 0.0210, 0.0310, 0.0255,
        0.0052, 0.0144], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,213][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.0852e-09, 9.6917e-01, 2.9154e-02, 7.8123e-04, 2.4828e-04, 3.3207e-04,
        1.1212e-05, 3.4954e-05, 1.4062e-05, 1.4360e-04, 6.1602e-06, 7.1976e-06,
        3.7488e-05, 5.5718e-06, 1.1130e-05, 3.2638e-05, 7.1248e-06, 1.1852e-06,
        7.4517e-07, 4.6764e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,214][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.7749e-05, 8.7523e-01, 1.8305e-03, 8.4442e-02, 1.3903e-03, 1.7492e-03,
        1.3900e-04, 3.3142e-04, 2.4140e-04, 3.6515e-03, 3.7760e-03, 9.5631e-05,
        3.1685e-04, 2.3581e-04, 2.2928e-04, 2.7113e-03, 2.0519e-04, 1.9865e-02,
        5.0425e-04, 2.9577e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,215][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.5747e-05, 4.1605e-01, 4.6622e-01, 3.4464e-03, 4.4729e-03, 8.5326e-03,
        6.6660e-03, 1.4587e-02, 1.8305e-03, 2.5352e-02, 2.8326e-02, 3.3853e-04,
        4.9368e-03, 3.9664e-04, 2.9937e-03, 6.7198e-03, 3.3051e-03, 2.6306e-03,
        2.8038e-04, 2.8892e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,308][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:58,309][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,310][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,310][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,311][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,311][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,312][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,313][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,313][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,314][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,315][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,315][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,316][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,317][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9777, 0.0223], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,317][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9092, 0.0908], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,318][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7592, 0.2408], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,320][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9469, 0.0531], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,321][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5281, 0.4719], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,322][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,322][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2348, 0.7652], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,323][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9433, 0.0567], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,324][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7743, 0.2257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,327][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0019, 0.9981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,330][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9927e-01, 7.2526e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,333][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6945, 0.3055], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,334][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.1328, 0.3328, 0.5343], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,335][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.1648, 0.0728, 0.7624], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,335][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.7954, 0.1945, 0.0101], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,336][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.8486, 0.0495, 0.1019], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,338][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.2875, 0.5577, 0.1548], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,340][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([7.0704e-05, 9.7243e-01, 2.7502e-02], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,345][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0230, 0.3450, 0.6320], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,346][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.7378, 0.0867, 0.1756], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,347][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.7190, 0.2302, 0.0508], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,348][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([3.0067e-05, 9.9455e-01, 5.4224e-03], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,348][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([9.9952e-01, 4.4382e-04, 3.8502e-05], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,349][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0014, 0.7134, 0.2852], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,351][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2134, 0.1396, 0.6011, 0.0459], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,355][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0136, 0.0330, 0.9256, 0.0278], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,360][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1318, 0.2972, 0.1142, 0.4569], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,360][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3669, 0.2291, 0.2543, 0.1497], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,361][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0395, 0.6291, 0.0639, 0.2675], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,362][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0074, 0.6235, 0.0345, 0.3345], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,362][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0126, 0.2527, 0.5114, 0.2233], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,363][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3848, 0.2616, 0.3094, 0.0443], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,367][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1603, 0.2960, 0.2101, 0.3336], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,370][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.7793e-04, 7.1483e-01, 1.1573e-02, 2.7302e-01], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,373][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9852e-01, 1.2466e-03, 2.2495e-04, 6.9697e-06], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,374][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0032, 0.3770, 0.5601, 0.0597], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,374][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0211, 0.1669, 0.6113, 0.0432, 0.1576], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,375][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0283, 0.0406, 0.8694, 0.0168, 0.0450], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,376][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.1861, 0.3841, 0.0315, 0.2859, 0.1124], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,378][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.3029, 0.1686, 0.2397, 0.0620, 0.2268], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,382][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0885, 0.3838, 0.2523, 0.1899, 0.0855], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,384][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([4.9253e-05, 7.9510e-01, 2.2011e-02, 1.8137e-01, 1.4650e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,386][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.0019, 0.2629, 0.4922, 0.1205, 0.1226], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,387][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.2291, 0.2744, 0.3162, 0.0464, 0.1339], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,388][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.2603, 0.2138, 0.0924, 0.1597, 0.2739], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,388][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([2.5664e-05, 7.9465e-01, 9.8766e-03, 1.9304e-01, 2.4070e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,389][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([9.8941e-01, 3.0177e-03, 9.0980e-04, 1.5879e-05, 6.6450e-03],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,391][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([3.9520e-04, 4.8502e-01, 4.4052e-01, 5.4906e-02, 1.9158e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,395][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0016, 0.2777, 0.5935, 0.0187, 0.0673, 0.0411], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,399][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0184, 0.0656, 0.8657, 0.0131, 0.0301, 0.0070], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,400][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0418, 0.4305, 0.0602, 0.2321, 0.1840, 0.0514], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,401][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0445, 0.2653, 0.3231, 0.0458, 0.0880, 0.2333], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,401][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0127, 0.6224, 0.0503, 0.1992, 0.0122, 0.1032], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,402][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([2.5218e-04, 7.4733e-01, 2.5536e-02, 2.1745e-01, 2.5416e-03, 6.8907e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,403][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([4.3844e-04, 2.0083e-01, 5.9155e-01, 5.4509e-02, 9.3457e-02, 5.9207e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,406][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0188, 0.5010, 0.3840, 0.0311, 0.0409, 0.0242], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,411][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0856, 0.2955, 0.0688, 0.1017, 0.1848, 0.2636], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,413][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([8.2752e-06, 9.0113e-01, 3.3204e-02, 4.3000e-02, 4.9536e-03, 1.7700e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,413][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([9.8477e-01, 7.4406e-03, 6.3952e-04, 1.6974e-05, 7.1313e-03, 7.0926e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,414][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([5.9289e-05, 4.8246e-01, 3.9152e-01, 3.3969e-02, 1.0724e-02, 8.1274e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:58,415][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0034, 0.0511, 0.8025, 0.0066, 0.0898, 0.0341, 0.0125],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,416][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0258, 0.0243, 0.8778, 0.0042, 0.0244, 0.0044, 0.0390],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,418][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0779, 0.3893, 0.1322, 0.1229, 0.1791, 0.0590, 0.0396],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,423][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0180, 0.1268, 0.4792, 0.0425, 0.1004, 0.1233, 0.1099],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,426][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0079, 0.5133, 0.1535, 0.0971, 0.0474, 0.0811, 0.0997],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,427][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([1.2959e-04, 6.9507e-01, 5.9536e-02, 2.1733e-01, 8.9698e-03, 1.1823e-02,
        7.1424e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,427][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([3.7474e-04, 1.0684e-01, 6.6996e-01, 4.4364e-02, 6.5742e-02, 8.3265e-02,
        2.9455e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,428][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0145, 0.1910, 0.6518, 0.0105, 0.0520, 0.0076, 0.0726],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,429][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.1053, 0.2361, 0.0965, 0.1063, 0.2558, 0.1463, 0.0537],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,430][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([2.5029e-06, 8.5432e-01, 6.3336e-02, 5.8230e-02, 3.7119e-03, 1.9199e-02,
        1.1974e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,433][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([9.8512e-01, 2.8726e-03, 2.0093e-03, 1.2625e-05, 9.9598e-03, 1.7588e-06,
        2.3941e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,436][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([1.7549e-05, 2.9095e-01, 3.7492e-01, 2.0649e-02, 5.7468e-03, 1.7977e-01,
        1.2794e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:58,439][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0059, 0.1080, 0.7085, 0.0097, 0.1101, 0.0199, 0.0106, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,440][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0345, 0.0522, 0.8223, 0.0075, 0.0491, 0.0034, 0.0253, 0.0057],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,441][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0761, 0.3703, 0.0697, 0.1264, 0.1465, 0.0391, 0.0722, 0.0997],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,441][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0707, 0.1199, 0.3165, 0.0262, 0.1804, 0.0637, 0.1493, 0.0734],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,442][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0357, 0.1187, 0.1680, 0.0742, 0.1629, 0.0677, 0.2746, 0.0982],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,445][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0220, 0.4011, 0.0472, 0.3367, 0.0214, 0.0439, 0.0490, 0.0788],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,447][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([3.0643e-04, 1.8802e-01, 4.3353e-01, 5.0108e-02, 8.6601e-02, 4.5711e-02,
        1.9640e-02, 1.7608e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,452][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0344, 0.1414, 0.6973, 0.0089, 0.0510, 0.0065, 0.0372, 0.0233],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,453][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.2304, 0.1993, 0.0529, 0.0563, 0.1675, 0.0746, 0.0486, 0.1704],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,454][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.0019, 0.2768, 0.0635, 0.0934, 0.0303, 0.1506, 0.0163, 0.3672],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,454][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([9.8971e-01, 3.7536e-03, 9.6630e-04, 1.5257e-05, 5.5421e-03, 7.7228e-07,
        1.1388e-05, 3.1678e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,455][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0009, 0.2010, 0.3509, 0.0269, 0.0165, 0.0411, 0.0496, 0.3130],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:58,458][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0039, 0.2095, 0.5350, 0.0198, 0.0446, 0.0647, 0.0319, 0.0708, 0.0196],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,462][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0861, 0.0847, 0.5238, 0.0104, 0.0328, 0.0107, 0.1233, 0.0316, 0.0966],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,466][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0873, 0.5070, 0.0299, 0.1158, 0.0482, 0.0328, 0.0738, 0.0746, 0.0306],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,466][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0323, 0.1547, 0.1236, 0.0485, 0.0670, 0.1174, 0.2330, 0.1153, 0.1082],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,467][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0107, 0.2236, 0.0747, 0.0694, 0.0434, 0.0640, 0.1970, 0.1284, 0.1889],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,468][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0007, 0.5472, 0.0451, 0.3032, 0.0126, 0.0236, 0.0191, 0.0277, 0.0207],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,469][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.0005, 0.2245, 0.2504, 0.0437, 0.0218, 0.0482, 0.0278, 0.3388, 0.0445],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,471][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0231, 0.5372, 0.2116, 0.0273, 0.0494, 0.0194, 0.0581, 0.0318, 0.0421],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,476][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.1401, 0.1533, 0.0372, 0.0697, 0.1463, 0.0832, 0.0562, 0.1529, 0.1613],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,479][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([1.2899e-04, 4.2027e-01, 6.0131e-02, 9.3248e-02, 2.6143e-02, 7.8131e-02,
        8.3297e-03, 2.5290e-01, 6.0711e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,480][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([9.9100e-01, 6.1769e-03, 5.1878e-04, 2.5909e-05, 2.1632e-03, 2.6309e-06,
        5.0043e-05, 1.0913e-05, 5.3889e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,480][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([1.0168e-04, 2.5690e-01, 2.5608e-01, 1.8547e-02, 2.8225e-03, 1.3291e-01,
        4.2315e-02, 2.4770e-01, 4.2615e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:58,481][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0052, 0.2285, 0.6173, 0.0065, 0.0561, 0.0249, 0.0118, 0.0238, 0.0086,
        0.0173], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,482][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0239, 0.0533, 0.8184, 0.0056, 0.0273, 0.0026, 0.0332, 0.0052, 0.0245,
        0.0059], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,484][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1478, 0.3394, 0.0670, 0.0941, 0.0926, 0.0282, 0.0802, 0.0649, 0.0369,
        0.0488], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,489][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0355, 0.0890, 0.2576, 0.0192, 0.0924, 0.0783, 0.1325, 0.0571, 0.0788,
        0.1595], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,492][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0178, 0.1671, 0.0558, 0.0472, 0.0235, 0.0492, 0.1818, 0.0694, 0.1268,
        0.2613], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,493][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0315, 0.2131, 0.0243, 0.1551, 0.0097, 0.0296, 0.0264, 0.0731, 0.0403,
        0.3968], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,494][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.0421e-04, 2.4433e-01, 3.3679e-01, 3.2049e-02, 3.7452e-02, 3.3072e-02,
        2.4304e-02, 1.4767e-01, 3.0281e-02, 1.1385e-01], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,494][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0534, 0.3324, 0.3662, 0.0152, 0.0557, 0.0104, 0.0792, 0.0270, 0.0314,
        0.0292], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,495][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0868, 0.2666, 0.0542, 0.0395, 0.1632, 0.0555, 0.0368, 0.1220, 0.1017,
        0.0737], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,498][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0023, 0.0787, 0.0053, 0.0183, 0.0039, 0.0349, 0.0033, 0.2679, 0.0257,
        0.5596], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,500][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9607e-01, 2.0767e-03, 2.3170e-04, 3.7976e-06, 1.6021e-03, 1.6809e-07,
        6.1946e-06, 7.3658e-07, 4.5744e-06, 9.3249e-07], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,505][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0033, 0.2723, 0.3286, 0.0216, 0.0106, 0.0336, 0.0575, 0.0910, 0.0165,
        0.1650], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:58,506][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([5.4674e-04, 3.1340e-01, 6.1769e-01, 2.7654e-03, 4.8401e-02, 5.3361e-03,
        2.1803e-03, 4.5642e-03, 1.4539e-03, 3.4633e-03, 1.9983e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,507][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0101, 0.0846, 0.8395, 0.0025, 0.0190, 0.0013, 0.0134, 0.0029, 0.0143,
        0.0050, 0.0073], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,508][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1280, 0.6077, 0.0444, 0.0532, 0.0574, 0.0125, 0.0248, 0.0317, 0.0104,
        0.0271, 0.0028], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,509][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0069, 0.1371, 0.3247, 0.0187, 0.0639, 0.0607, 0.1010, 0.0755, 0.0404,
        0.1228, 0.0484], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,511][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0016, 0.4150, 0.0864, 0.0325, 0.0238, 0.0364, 0.1289, 0.0271, 0.0716,
        0.1459, 0.0308], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,513][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.0939e-04, 9.1870e-01, 3.2511e-02, 3.4061e-02, 2.2261e-03, 4.2499e-03,
        8.9897e-04, 9.6571e-04, 6.1719e-04, 5.0317e-03, 4.2994e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,516][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.2624e-05, 3.4753e-01, 4.3288e-01, 1.8391e-02, 2.3360e-02, 1.2997e-02,
        5.1332e-03, 5.5461e-02, 7.8073e-03, 6.6463e-02, 2.9959e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,519][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0041, 0.3258, 0.5577, 0.0083, 0.0371, 0.0041, 0.0253, 0.0119, 0.0087,
        0.0099, 0.0072], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,520][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1327, 0.3258, 0.0500, 0.0348, 0.1618, 0.0337, 0.0236, 0.1129, 0.0554,
        0.0499, 0.0194], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,521][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([4.4172e-06, 9.3794e-01, 3.1058e-02, 5.1389e-03, 2.0937e-03, 4.4718e-03,
        2.6324e-04, 5.6761e-03, 5.4387e-04, 1.2002e-02, 8.0863e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,521][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.8524e-01, 1.0540e-02, 6.2110e-04, 4.1868e-06, 3.5872e-03, 1.0960e-07,
        3.9094e-06, 6.2699e-07, 3.2869e-06, 1.0347e-06, 1.7692e-07],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,522][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.8671e-05, 3.4771e-01, 2.3708e-01, 7.3526e-03, 2.5341e-03, 1.9593e-02,
        1.1496e-02, 8.9979e-02, 7.0371e-03, 1.3853e-01, 1.3867e-01],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:58,524][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([1.4774e-04, 2.5623e-01, 6.4329e-01, 1.0502e-02, 3.2440e-02, 1.3522e-02,
        8.3252e-03, 9.8825e-03, 2.7660e-03, 1.6580e-02, 6.7250e-04, 5.6474e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,528][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0037, 0.0569, 0.7580, 0.0063, 0.0151, 0.0082, 0.0374, 0.0145, 0.0276,
        0.0170, 0.0215, 0.0336], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,532][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0023, 0.3760, 0.1003, 0.1476, 0.0803, 0.0445, 0.0386, 0.0909, 0.0200,
        0.0721, 0.0126, 0.0147], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,533][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0028, 0.2173, 0.2549, 0.0361, 0.0746, 0.1041, 0.0522, 0.0407, 0.0284,
        0.1338, 0.0373, 0.0178], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,534][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0010, 0.4844, 0.1246, 0.0607, 0.0234, 0.0403, 0.0328, 0.0278, 0.0251,
        0.1447, 0.0176, 0.0178], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,535][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.4389e-06, 8.8285e-01, 7.3389e-02, 2.2774e-02, 3.5124e-03, 1.8155e-03,
        8.3772e-04, 7.9933e-04, 3.5555e-04, 1.2278e-02, 1.3386e-03, 4.8814e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,535][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([1.7730e-05, 9.7729e-02, 4.9413e-01, 2.0769e-02, 3.0107e-02, 3.1663e-02,
        1.5936e-02, 1.1335e-01, 1.5136e-02, 1.3116e-01, 4.4821e-02, 5.1750e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,539][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0010, 0.3260, 0.5402, 0.0134, 0.0309, 0.0092, 0.0236, 0.0120, 0.0080,
        0.0146, 0.0052, 0.0159], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,543][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0081, 0.3386, 0.0488, 0.0790, 0.0864, 0.0586, 0.0173, 0.0784, 0.0488,
        0.0680, 0.0973, 0.0706], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,545][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([1.2698e-07, 9.3622e-01, 2.9685e-02, 1.2194e-02, 1.6044e-03, 2.0437e-03,
        1.5246e-04, 1.8921e-03, 1.7028e-04, 1.4322e-02, 1.5730e-03, 1.4400e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,546][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([9.2330e-01, 2.7407e-02, 1.1643e-02, 5.6546e-05, 3.6751e-02, 6.3256e-06,
        1.0599e-04, 2.3301e-05, 8.9258e-05, 2.8931e-05, 8.0516e-06, 5.7685e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,547][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([6.1895e-08, 7.4655e-02, 8.9091e-02, 1.5686e-03, 6.3585e-04, 7.8766e-03,
        1.1271e-02, 1.7281e-01, 1.0084e-02, 1.4708e-01, 4.8473e-01, 1.9999e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:58,548][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([1.6577e-03, 1.1929e-01, 7.7242e-01, 3.6801e-03, 5.9751e-02, 1.2436e-02,
        4.7726e-03, 6.9790e-03, 2.8705e-03, 4.9055e-03, 5.4455e-04, 8.1691e-03,
        2.5250e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,549][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0058, 0.0368, 0.8479, 0.0031, 0.0227, 0.0021, 0.0207, 0.0035, 0.0146,
        0.0044, 0.0078, 0.0217, 0.0089], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,552][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0750, 0.4472, 0.0793, 0.0758, 0.0935, 0.0217, 0.0537, 0.0447, 0.0224,
        0.0338, 0.0054, 0.0133, 0.0342], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,556][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0108, 0.1146, 0.3145, 0.0218, 0.0806, 0.0688, 0.1005, 0.0410, 0.0486,
        0.1051, 0.0404, 0.0176, 0.0356], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,559][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0096, 0.4249, 0.0770, 0.0250, 0.0164, 0.0317, 0.0923, 0.0419, 0.0530,
        0.1466, 0.0354, 0.0272, 0.0189], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,560][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([9.6647e-05, 8.8322e-01, 5.9208e-02, 3.8493e-02, 2.0013e-03, 4.5375e-03,
        1.3846e-03, 1.0786e-03, 7.0071e-04, 7.6289e-03, 4.8538e-04, 5.7542e-05,
        1.1039e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,560][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([7.6257e-05, 2.5059e-01, 4.1266e-01, 2.1494e-02, 3.2905e-02, 2.3906e-02,
        1.3129e-02, 8.4102e-02, 1.5403e-02, 6.6863e-02, 3.6469e-02, 5.3503e-03,
        3.7053e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,561][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0101, 0.2496, 0.5930, 0.0085, 0.0359, 0.0055, 0.0326, 0.0118, 0.0104,
        0.0113, 0.0100, 0.0132, 0.0079], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,562][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0518, 0.2633, 0.0805, 0.0310, 0.1653, 0.0376, 0.0255, 0.0827, 0.0767,
        0.0406, 0.0530, 0.0706, 0.0215], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,564][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.9937e-06, 9.4887e-01, 2.7910e-02, 5.1840e-03, 7.5773e-04, 2.9749e-03,
        1.6133e-04, 2.7070e-03, 3.1663e-04, 9.3551e-03, 2.7095e-04, 9.6882e-05,
        1.3912e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,566][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([9.9316e-01, 3.1912e-03, 4.6616e-04, 3.3244e-06, 3.1435e-03, 1.9058e-07,
        6.5030e-06, 5.4751e-07, 4.8211e-06, 9.6639e-07, 2.2472e-07, 2.1403e-05,
        1.5312e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,570][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0005, 0.3023, 0.2925, 0.0077, 0.0081, 0.0176, 0.0182, 0.0457, 0.0057,
        0.0896, 0.1854, 0.0011, 0.0257], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:58,572][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([2.4197e-04, 1.9494e-01, 6.5281e-01, 1.3366e-02, 5.1543e-02, 2.5277e-02,
        5.3063e-03, 1.2355e-02, 2.4357e-03, 1.0495e-02, 1.0473e-03, 5.7203e-03,
        3.6215e-03, 2.0832e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,573][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0048, 0.0645, 0.6505, 0.0082, 0.0512, 0.0068, 0.0261, 0.0071, 0.0151,
        0.0101, 0.0118, 0.0284, 0.0162, 0.0993], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,574][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0288, 0.3485, 0.0155, 0.0949, 0.0374, 0.0482, 0.0403, 0.1103, 0.0289,
        0.0478, 0.0078, 0.0428, 0.0466, 0.1022], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,575][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0055, 0.1243, 0.1894, 0.0320, 0.0891, 0.0742, 0.0702, 0.0422, 0.0253,
        0.0554, 0.0347, 0.0095, 0.0265, 0.2216], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,577][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0069, 0.2148, 0.3074, 0.0261, 0.0767, 0.0375, 0.0693, 0.0251, 0.0483,
        0.0903, 0.0191, 0.0528, 0.0160, 0.0096], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,579][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([5.7704e-05, 5.8711e-01, 2.4449e-01, 7.5309e-02, 1.3594e-02, 7.5107e-03,
        1.5766e-02, 8.3127e-03, 6.8511e-03, 3.1422e-02, 3.0480e-03, 7.9494e-04,
        4.9951e-03, 7.4321e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,582][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([2.6230e-05, 2.4883e-01, 3.5516e-01, 3.4287e-02, 3.9035e-02, 3.6595e-02,
        7.4904e-03, 9.7015e-02, 1.1676e-02, 6.3186e-02, 2.2988e-02, 4.6850e-03,
        2.0701e-02, 5.8322e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,585][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0123, 0.3471, 0.3674, 0.0203, 0.0920, 0.0106, 0.0255, 0.0101, 0.0091,
        0.0107, 0.0099, 0.0153, 0.0085, 0.0613], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,586][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0227, 0.2215, 0.0737, 0.0486, 0.1452, 0.0362, 0.0257, 0.0677, 0.0343,
        0.0314, 0.0258, 0.0979, 0.0252, 0.1442], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,587][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([2.8864e-05, 8.0223e-01, 1.0285e-01, 4.2434e-02, 1.0237e-02, 8.4008e-03,
        1.4363e-03, 8.1048e-03, 2.0830e-03, 1.5740e-02, 2.1395e-03, 1.6978e-03,
        1.7452e-03, 8.7106e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,587][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([9.7486e-01, 1.1838e-02, 1.2091e-03, 2.4266e-05, 6.9201e-03, 1.8339e-06,
        2.4069e-05, 4.5753e-06, 2.2057e-05, 6.7568e-06, 1.8005e-06, 1.1085e-04,
        1.3216e-05, 4.9663e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,588][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([4.9444e-06, 1.5352e-01, 2.6251e-01, 2.4703e-03, 4.7086e-03, 3.9162e-02,
        8.0055e-03, 7.1393e-02, 5.9765e-03, 8.3540e-02, 3.5912e-01, 7.3030e-04,
        7.5634e-03, 1.3033e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:58,590][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([5.1129e-05, 1.5061e-01, 7.2446e-01, 4.8901e-03, 4.0198e-02, 1.4513e-02,
        6.8148e-03, 9.6846e-03, 2.8946e-03, 1.2635e-02, 9.9016e-04, 5.4584e-03,
        3.9369e-03, 2.1007e-02, 1.8509e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,594][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0033, 0.0548, 0.7029, 0.0032, 0.0280, 0.0028, 0.0345, 0.0058, 0.0216,
        0.0075, 0.0115, 0.0416, 0.0116, 0.0582, 0.0127], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,598][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0103, 0.3567, 0.0476, 0.0985, 0.0468, 0.0288, 0.0451, 0.0643, 0.0282,
        0.0538, 0.0116, 0.0138, 0.0370, 0.0773, 0.0802], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,599][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0020, 0.1956, 0.1527, 0.0241, 0.0473, 0.0543, 0.0644, 0.0275, 0.0404,
        0.1181, 0.0397, 0.0181, 0.0260, 0.1389, 0.0510], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,600][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0024, 0.3048, 0.0927, 0.0448, 0.0175, 0.0366, 0.1066, 0.0379, 0.0766,
        0.1496, 0.0249, 0.0417, 0.0144, 0.0030, 0.0464], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,601][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([2.6810e-04, 8.2977e-01, 3.8282e-02, 7.3467e-02, 5.0364e-03, 7.5073e-03,
        3.5269e-03, 2.8046e-03, 2.2940e-03, 2.7739e-02, 2.0953e-03, 3.3998e-04,
        4.7557e-03, 3.7607e-04, 1.7399e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,602][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([1.2863e-05, 2.1450e-01, 3.6557e-01, 2.3318e-02, 3.3163e-02, 2.2848e-02,
        1.3023e-02, 9.0393e-02, 2.2847e-02, 9.2284e-02, 4.5322e-02, 5.1752e-03,
        2.1933e-02, 4.6596e-02, 3.0139e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,605][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0031, 0.2489, 0.5694, 0.0095, 0.0306, 0.0070, 0.0225, 0.0184, 0.0139,
        0.0151, 0.0127, 0.0175, 0.0058, 0.0193, 0.0063], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,609][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0187, 0.2071, 0.0933, 0.0293, 0.1270, 0.0255, 0.0325, 0.0813, 0.0528,
        0.0322, 0.0610, 0.0465, 0.0156, 0.1050, 0.0719], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,611][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([3.5406e-06, 8.2730e-01, 7.2338e-02, 1.4591e-02, 3.2288e-03, 1.4589e-02,
        8.8387e-04, 8.7218e-03, 2.9883e-03, 4.1614e-02, 4.0909e-03, 1.0212e-03,
        5.8119e-03, 9.1241e-04, 1.9092e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,612][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([9.2062e-01, 4.2707e-02, 4.0426e-03, 3.7737e-05, 2.1673e-02, 3.0232e-06,
        1.1517e-04, 1.0030e-05, 9.6326e-05, 1.5604e-05, 4.4659e-06, 2.8809e-04,
        1.9658e-05, 1.0313e-02, 5.2255e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,613][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([9.1365e-06, 2.4994e-01, 2.3209e-01, 4.0633e-03, 3.0438e-03, 2.0287e-02,
        1.4195e-02, 7.5072e-02, 1.0634e-02, 1.0877e-01, 2.4982e-01, 1.0387e-03,
        1.2915e-02, 5.6680e-04, 1.7552e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:58,614][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([3.2922e-04, 2.9214e-01, 6.1061e-01, 4.3298e-03, 3.8260e-02, 1.0868e-02,
        6.3729e-03, 5.8257e-03, 2.6888e-03, 5.3467e-03, 4.1848e-04, 5.8984e-03,
        1.7592e-03, 1.0558e-02, 2.2420e-03, 2.3511e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,615][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0019, 0.0856, 0.7771, 0.0068, 0.0258, 0.0026, 0.0220, 0.0037, 0.0124,
        0.0043, 0.0038, 0.0149, 0.0054, 0.0174, 0.0051, 0.0111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,618][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0155, 0.3617, 0.0820, 0.0931, 0.0933, 0.0243, 0.0530, 0.0432, 0.0179,
        0.0281, 0.0032, 0.0095, 0.0174, 0.0608, 0.0605, 0.0366],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,622][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0039, 0.1008, 0.2291, 0.0146, 0.0857, 0.0567, 0.0583, 0.0184, 0.0346,
        0.0757, 0.0173, 0.0133, 0.0140, 0.1571, 0.0375, 0.0830],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,625][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0029, 0.2570, 0.0978, 0.0435, 0.0210, 0.0438, 0.1132, 0.0385, 0.0777,
        0.1542, 0.0209, 0.0274, 0.0117, 0.0025, 0.0386, 0.0493],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,626][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0015, 0.6251, 0.0774, 0.0810, 0.0083, 0.0203, 0.0164, 0.0166, 0.0108,
        0.0781, 0.0077, 0.0011, 0.0121, 0.0021, 0.0078, 0.0338],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,626][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.8225e-05, 2.6909e-01, 4.2611e-01, 2.0192e-02, 3.7216e-02, 2.0099e-02,
        1.3138e-02, 5.8519e-02, 1.4494e-02, 4.7037e-02, 1.6848e-02, 3.7045e-03,
        1.8080e-02, 3.1063e-02, 2.2866e-03, 2.2109e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,627][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0078, 0.2883, 0.5099, 0.0111, 0.0416, 0.0058, 0.0288, 0.0132, 0.0113,
        0.0151, 0.0097, 0.0131, 0.0074, 0.0228, 0.0032, 0.0110],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,630][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0176, 0.3128, 0.0531, 0.0378, 0.1380, 0.0439, 0.0206, 0.0723, 0.0435,
        0.0295, 0.0364, 0.0468, 0.0171, 0.0572, 0.0416, 0.0319],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,632][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.6724e-05, 6.9014e-01, 4.0603e-02, 1.7379e-02, 5.1994e-03, 2.8278e-02,
        2.0237e-03, 4.2370e-02, 9.6528e-03, 9.3392e-02, 4.8778e-03, 5.0083e-03,
        1.6359e-02, 7.5970e-03, 8.2488e-03, 2.8808e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,635][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.7181e-01, 1.6993e-02, 1.2104e-03, 1.8470e-05, 8.3933e-03, 6.6551e-07,
        2.1216e-05, 1.5775e-06, 1.0113e-05, 2.1617e-06, 3.1936e-07, 2.8270e-05,
        2.5900e-06, 1.4961e-03, 7.1115e-06, 4.2184e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,638][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.6284e-04, 2.7609e-01, 4.1829e-01, 5.8793e-03, 6.1248e-03, 2.2365e-02,
        2.2468e-02, 4.5092e-02, 6.2215e-03, 6.1720e-02, 9.4947e-02, 9.1550e-04,
        1.1980e-02, 8.5525e-04, 9.0236e-03, 1.7868e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:58,639][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([1.2496e-04, 9.4717e-02, 7.9392e-01, 2.9489e-03, 5.2874e-02, 7.7358e-03,
        3.5372e-03, 4.5390e-03, 1.0386e-03, 5.4763e-03, 2.9194e-04, 3.3596e-03,
        1.3934e-03, 2.1839e-02, 1.1974e-03, 3.1298e-03, 1.8784e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,640][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0031, 0.0832, 0.6766, 0.0032, 0.0489, 0.0055, 0.0160, 0.0061, 0.0088,
        0.0096, 0.0065, 0.0123, 0.0090, 0.0614, 0.0078, 0.0305, 0.0115],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,640][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0114, 0.2347, 0.0785, 0.0646, 0.1279, 0.0246, 0.0217, 0.0462, 0.0139,
        0.0489, 0.0045, 0.0092, 0.0220, 0.1623, 0.0427, 0.0644, 0.0227],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,643][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0013, 0.0926, 0.2370, 0.0114, 0.0837, 0.0326, 0.0271, 0.0142, 0.0113,
        0.0580, 0.0096, 0.0121, 0.0142, 0.2679, 0.0193, 0.0780, 0.0296],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,646][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0040, 0.2514, 0.1894, 0.0494, 0.0366, 0.0338, 0.0539, 0.0304, 0.0356,
        0.1214, 0.0228, 0.0195, 0.0169, 0.0078, 0.0218, 0.0670, 0.0383],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,649][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([2.0001e-04, 6.6215e-01, 1.3426e-01, 7.7157e-02, 9.9069e-03, 1.7515e-02,
        6.3440e-03, 7.0265e-03, 4.8262e-03, 3.8938e-02, 4.6513e-03, 1.1534e-03,
        6.9919e-03, 9.8843e-04, 6.2085e-03, 1.7335e-02, 4.3477e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,651][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([7.6751e-06, 1.5047e-01, 5.3447e-01, 9.7822e-03, 5.4793e-02, 1.6618e-02,
        7.3857e-03, 4.7739e-02, 1.0937e-02, 5.4300e-02, 1.4205e-02, 3.0611e-03,
        1.3276e-02, 5.4488e-02, 1.6069e-03, 2.5313e-02, 1.5548e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,652][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0019, 0.0846, 0.7449, 0.0053, 0.0490, 0.0042, 0.0119, 0.0077, 0.0045,
        0.0079, 0.0057, 0.0117, 0.0031, 0.0404, 0.0034, 0.0069, 0.0070],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,653][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0127, 0.1767, 0.0688, 0.0300, 0.1567, 0.0308, 0.0196, 0.0576, 0.0334,
        0.0467, 0.0370, 0.0479, 0.0209, 0.1214, 0.0355, 0.0381, 0.0661],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,654][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([1.8383e-06, 7.5077e-01, 8.3939e-02, 2.8131e-02, 2.7052e-03, 1.3594e-02,
        1.6720e-03, 1.0492e-02, 4.9869e-03, 6.4279e-02, 5.4759e-03, 1.6724e-03,
        9.2345e-03, 1.3358e-03, 4.0838e-03, 1.5669e-02, 1.9563e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,655][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([9.1358e-01, 2.6862e-02, 7.8420e-03, 3.6403e-05, 3.6694e-02, 4.4667e-06,
        6.0409e-05, 7.8532e-06, 3.4393e-05, 1.4709e-05, 1.8480e-06, 1.7623e-04,
        1.0467e-05, 1.4427e-02, 3.1150e-05, 3.8166e-05, 1.7675e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,657][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([1.3453e-05, 3.2612e-01, 3.4975e-01, 7.5219e-03, 1.4511e-02, 2.0477e-02,
        5.9705e-03, 3.7175e-02, 3.8801e-03, 8.2209e-02, 8.7178e-02, 7.7100e-04,
        1.5558e-02, 1.8562e-03, 6.2776e-03, 2.9947e-02, 1.0788e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:58,659][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.3350e-05, 3.2811e-01, 6.3944e-01, 1.5521e-03, 2.1847e-02, 2.1931e-03,
        1.0337e-03, 7.2883e-04, 2.7200e-04, 7.5775e-04, 4.4921e-05, 7.6509e-04,
        2.4069e-04, 1.8892e-03, 3.6153e-04, 2.7332e-04, 4.2283e-04, 5.4937e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,662][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.7138e-04, 1.7744e-01, 7.6391e-01, 4.0825e-03, 1.1283e-02, 2.2173e-03,
        5.2087e-03, 1.2889e-03, 2.8787e-03, 2.5999e-03, 1.6812e-03, 5.1319e-03,
        2.2225e-03, 4.7101e-03, 2.1675e-03, 4.8569e-03, 2.0513e-03, 5.9960e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,667][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0016, 0.7272, 0.0448, 0.0519, 0.0408, 0.0131, 0.0179, 0.0162, 0.0042,
        0.0145, 0.0009, 0.0026, 0.0065, 0.0185, 0.0201, 0.0112, 0.0059, 0.0020],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,668][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0006, 0.3732, 0.2967, 0.0218, 0.0269, 0.0367, 0.0307, 0.0114, 0.0115,
        0.0467, 0.0097, 0.0044, 0.0111, 0.0276, 0.0165, 0.0419, 0.0189, 0.0136],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,668][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.5973e-04, 5.8873e-01, 1.5565e-01, 3.5346e-02, 1.6057e-02, 2.6228e-02,
        3.6940e-02, 7.5873e-03, 2.5194e-02, 5.4242e-02, 6.0331e-03, 6.5780e-03,
        4.2084e-03, 4.5913e-04, 8.7841e-03, 1.3921e-02, 1.1629e-02, 2.2518e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,669][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([6.3119e-07, 9.5897e-01, 3.2506e-02, 6.2172e-03, 5.0978e-04, 6.5483e-04,
        2.1061e-04, 6.0706e-05, 6.0357e-05, 3.7833e-04, 2.3109e-05, 5.6388e-06,
        1.2239e-04, 6.7577e-06, 6.7383e-05, 1.5283e-04, 4.1161e-05, 9.5410e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,670][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.1842e-07, 3.6103e-01, 5.6288e-01, 8.9357e-03, 1.9010e-02, 6.2045e-03,
        1.8475e-03, 8.5718e-03, 1.8561e-03, 1.1351e-02, 2.7902e-03, 8.9516e-04,
        3.1447e-03, 5.3937e-03, 5.7522e-04, 3.5092e-03, 2.1576e-04, 1.7887e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,673][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0018, 0.3410, 0.5289, 0.0124, 0.0276, 0.0056, 0.0146, 0.0096, 0.0056,
        0.0085, 0.0066, 0.0078, 0.0037, 0.0089, 0.0019, 0.0050, 0.0028, 0.0075],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,678][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0153, 0.4914, 0.0707, 0.0495, 0.0797, 0.0376, 0.0151, 0.0330, 0.0150,
        0.0200, 0.0085, 0.0255, 0.0089, 0.0211, 0.0288, 0.0188, 0.0397, 0.0213],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,680][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.7574e-09, 9.7786e-01, 2.1161e-02, 2.8459e-04, 1.6623e-04, 2.3188e-04,
        7.3626e-06, 4.1972e-05, 9.6305e-06, 1.4014e-04, 2.9921e-06, 2.2333e-06,
        2.5259e-05, 5.3973e-06, 1.4108e-05, 3.9727e-05, 8.8548e-06, 1.0375e-06],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,681][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([7.9070e-01, 1.7260e-01, 8.8938e-03, 4.3967e-05, 2.5068e-02, 9.9330e-07,
        2.2395e-05, 1.9666e-06, 6.9340e-06, 3.0727e-06, 3.5774e-07, 3.9738e-05,
        3.6680e-06, 2.5176e-03, 7.9689e-06, 5.5563e-06, 5.8405e-05, 2.7946e-05],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,682][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.8652e-07, 5.0109e-01, 3.3944e-01, 2.5788e-03, 2.4405e-03, 7.2530e-03,
        3.4477e-03, 3.3487e-02, 1.4533e-03, 4.7323e-02, 3.7627e-02, 3.8664e-04,
        4.3814e-03, 2.2744e-04, 3.1860e-03, 7.5143e-03, 4.1266e-03, 4.0417e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:58,683][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([7.2655e-05, 2.4033e-01, 6.3894e-01, 8.3291e-03, 2.6616e-02, 1.6664e-02,
        7.3409e-03, 8.6894e-03, 3.2766e-03, 1.2497e-02, 1.2335e-03, 5.0936e-03,
        3.6209e-03, 1.4006e-02, 2.7518e-03, 4.6116e-03, 3.2442e-03, 1.2504e-03,
        1.4303e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,685][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0011, 0.0836, 0.5574, 0.0041, 0.0193, 0.0083, 0.0223, 0.0089, 0.0169,
        0.0139, 0.0163, 0.0227, 0.0131, 0.0344, 0.0099, 0.0307, 0.0121, 0.0526,
        0.0725], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,689][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0026, 0.2185, 0.0413, 0.0717, 0.0358, 0.0443, 0.0212, 0.0726, 0.0200,
        0.0630, 0.0095, 0.0097, 0.0424, 0.0836, 0.0751, 0.1013, 0.0208, 0.0275,
        0.0392], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,693][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0004, 0.1593, 0.1754, 0.0209, 0.0428, 0.0681, 0.0422, 0.0185, 0.0176,
        0.0866, 0.0189, 0.0098, 0.0189, 0.1010, 0.0315, 0.0923, 0.0352, 0.0306,
        0.0298], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,694][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0016, 0.4024, 0.2707, 0.0427, 0.0255, 0.0387, 0.0262, 0.0084, 0.0207,
        0.0456, 0.0126, 0.0111, 0.0138, 0.0022, 0.0235, 0.0242, 0.0223, 0.0047,
        0.0031], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,695][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([3.0092e-07, 7.6629e-01, 2.0055e-01, 1.8694e-02, 4.4215e-03, 2.3639e-03,
        7.4387e-04, 3.0988e-04, 3.4651e-04, 3.3869e-03, 7.5942e-04, 9.0033e-05,
        7.0929e-04, 2.0950e-05, 2.3910e-04, 7.3879e-04, 1.8399e-04, 1.4358e-04,
        7.3791e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,696][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([9.0151e-06, 1.4089e-01, 4.0810e-01, 2.4303e-02, 3.3753e-02, 2.4868e-02,
        1.0303e-02, 7.2977e-02, 1.3764e-02, 8.6690e-02, 2.8491e-02, 4.5043e-03,
        2.2640e-02, 5.6252e-02, 3.4733e-03, 4.4100e-02, 2.0093e-03, 2.0984e-02,
        1.8830e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,698][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0021, 0.2547, 0.5043, 0.0167, 0.0419, 0.0119, 0.0315, 0.0178, 0.0105,
        0.0185, 0.0120, 0.0164, 0.0072, 0.0195, 0.0045, 0.0096, 0.0067, 0.0073,
        0.0069], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,702][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0112, 0.2849, 0.0541, 0.0329, 0.0529, 0.0311, 0.0239, 0.0478, 0.0261,
        0.0424, 0.0457, 0.0323, 0.0282, 0.0629, 0.0587, 0.0413, 0.0488, 0.0624,
        0.0125], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,705][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([1.1698e-08, 8.7755e-01, 1.0913e-01, 7.4618e-03, 1.6235e-03, 1.2777e-03,
        9.8774e-05, 2.4356e-04, 9.8691e-05, 1.3717e-03, 2.8200e-04, 1.4081e-04,
        2.9463e-04, 1.5475e-05, 1.2461e-04, 1.7830e-04, 7.8888e-05, 1.9503e-05,
        8.9103e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,707][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([9.0349e-01, 3.8011e-02, 7.7523e-03, 6.1456e-05, 3.1233e-02, 5.3210e-06,
        1.0309e-04, 2.1422e-05, 7.3894e-05, 2.5922e-05, 3.8077e-06, 3.1955e-04,
        2.2863e-05, 1.3865e-02, 4.9497e-05, 4.9573e-05, 3.2447e-04, 1.8461e-04,
        4.4018e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,708][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([3.9399e-07, 1.7517e-01, 1.9088e-01, 3.9885e-03, 2.8861e-03, 1.6546e-02,
        8.1687e-03, 7.2133e-02, 6.3964e-03, 8.4178e-02, 3.5046e-01, 3.5193e-04,
        1.5473e-02, 3.5777e-04, 4.5936e-03, 2.5083e-02, 9.8564e-03, 3.3049e-02,
        4.3036e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:58,708][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.3226e-05, 3.2035e-01, 6.4118e-01, 1.6489e-03, 2.2547e-02, 2.9081e-03,
        1.5969e-03, 1.0043e-03, 5.5339e-04, 1.1886e-03, 7.5103e-05, 1.0871e-03,
        4.1995e-04, 3.0024e-03, 5.4718e-04, 5.1669e-04, 7.1720e-04, 1.0450e-04,
        3.2242e-04, 2.0891e-04], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,709][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.8895e-04, 1.2527e-01, 7.9402e-01, 3.6476e-03, 1.7343e-02, 1.1708e-03,
        7.9801e-03, 1.1396e-03, 4.3449e-03, 1.8923e-03, 1.1884e-03, 4.7853e-03,
        1.9293e-03, 6.8007e-03, 1.6678e-03, 4.4814e-03, 4.2827e-03, 4.2527e-03,
        9.1513e-03, 4.1688e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,712][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0057, 0.4963, 0.0975, 0.0614, 0.0847, 0.0158, 0.0305, 0.0241, 0.0110,
        0.0180, 0.0015, 0.0056, 0.0105, 0.0386, 0.0327, 0.0229, 0.0149, 0.0032,
        0.0155, 0.0097], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,716][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0012, 0.1947, 0.3559, 0.0159, 0.0701, 0.0396, 0.0364, 0.0087, 0.0167,
        0.0445, 0.0081, 0.0066, 0.0093, 0.0657, 0.0186, 0.0464, 0.0246, 0.0095,
        0.0125, 0.0148], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,720][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.0894e-04, 5.3263e-01, 1.7317e-01, 3.0571e-02, 1.7012e-02, 2.5485e-02,
        5.4397e-02, 1.1655e-02, 2.6877e-02, 5.6686e-02, 6.5478e-03, 9.9462e-03,
        4.3043e-03, 6.0951e-04, 1.2340e-02, 1.3129e-02, 1.5850e-02, 1.8051e-03,
        1.3657e-03, 5.2041e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,721][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3306e-06, 9.0169e-01, 8.6390e-02, 8.4305e-03, 1.0140e-03, 8.0024e-04,
        3.2564e-04, 7.6687e-05, 7.2512e-05, 6.0455e-04, 5.3028e-05, 8.9543e-06,
        1.4461e-04, 8.7592e-06, 6.1300e-05, 2.1698e-04, 6.3319e-05, 1.4792e-05,
        1.3287e-06, 2.6208e-05], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,721][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.1413e-06, 3.8917e-01, 4.7241e-01, 1.2735e-02, 2.8917e-02, 8.4748e-03,
        4.7154e-03, 1.6973e-02, 5.5046e-03, 1.9189e-02, 4.7940e-03, 1.4706e-03,
        6.6767e-03, 1.1436e-02, 8.6913e-04, 7.7084e-03, 6.3167e-04, 3.9339e-03,
        5.9342e-04, 3.8035e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,722][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0011, 0.3091, 0.5864, 0.0075, 0.0270, 0.0032, 0.0144, 0.0045, 0.0046,
        0.0070, 0.0040, 0.0046, 0.0030, 0.0094, 0.0014, 0.0045, 0.0021, 0.0029,
        0.0017, 0.0017], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,725][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0089, 0.4593, 0.0599, 0.0296, 0.1069, 0.0294, 0.0124, 0.0383, 0.0248,
        0.0207, 0.0174, 0.0291, 0.0119, 0.0301, 0.0241, 0.0210, 0.0310, 0.0255,
        0.0052, 0.0144], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,727][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.0852e-09, 9.6917e-01, 2.9154e-02, 7.8123e-04, 2.4828e-04, 3.3207e-04,
        1.1212e-05, 3.4954e-05, 1.4062e-05, 1.4360e-04, 6.1602e-06, 7.1976e-06,
        3.7488e-05, 5.5718e-06, 1.1130e-05, 3.2638e-05, 7.1248e-06, 1.1852e-06,
        7.4517e-07, 4.6764e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,730][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.7976e-01, 8.8687e-02, 4.8746e-03, 3.4868e-05, 2.3102e-02, 1.0285e-06,
        2.8330e-05, 1.8282e-06, 1.1163e-05, 3.1891e-06, 3.0777e-07, 3.4212e-05,
        3.3483e-06, 2.5538e-03, 7.5528e-06, 6.1570e-06, 5.3377e-05, 2.3305e-05,
        8.0739e-04, 6.9297e-06], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,733][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.5747e-05, 4.1605e-01, 4.6622e-01, 3.4464e-03, 4.4729e-03, 8.5326e-03,
        6.6660e-03, 1.4587e-02, 1.8305e-03, 2.5352e-02, 2.8326e-02, 3.3853e-04,
        4.9368e-03, 3.9664e-04, 2.9937e-03, 6.7198e-03, 3.3051e-03, 2.6306e-03,
        2.8038e-04, 2.8892e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:58,736][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:58,738][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1551],
        [  96],
        [   3],
        [  17],
        [  51],
        [   3],
        [  26],
        [  10],
        [  28],
        [   2],
        [  21],
        [  32],
        [  16],
        [  22],
        [ 113],
        [   2],
        [   6],
        [   2],
        [  28],
        [   1]], device='cuda:0')
[2024-07-24 10:16:58,742][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1434],
        [  79],
        [   3],
        [  12],
        [  35],
        [   3],
        [  12],
        [   5],
        [  26],
        [   2],
        [  15],
        [  16],
        [   8],
        [  18],
        [  79],
        [   1],
        [   3],
        [   1],
        [  14],
        [   1]], device='cuda:0')
[2024-07-24 10:16:58,745][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11624],
        [ 9129],
        [48676],
        [49754],
        [49364],
        [48948],
        [49992],
        [49779],
        [48513],
        [49204],
        [49005],
        [49261],
        [49886],
        [49443],
        [49751],
        [48986],
        [49944],
        [49082],
        [49250],
        [49113]], device='cuda:0')
[2024-07-24 10:16:58,748][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[11901],
        [20534],
        [40377],
        [40573],
        [40495],
        [40470],
        [40626],
        [40469],
        [39966],
        [40592],
        [40529],
        [40539],
        [40702],
        [40982],
        [41115],
        [40685],
        [40693],
        [40350],
        [40239],
        [40529]], device='cuda:0')
[2024-07-24 10:16:58,749][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[12043],
        [15509],
        [17681],
        [21899],
        [20272],
        [25840],
        [33867],
        [22088],
        [16236],
        [19514],
        [22076],
        [20143],
        [21734],
        [11192],
        [13818],
        [20333],
        [22130],
        [21800],
        [ 9594],
        [24730]], device='cuda:0')
[2024-07-24 10:16:58,751][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[16763],
        [18882],
        [37446],
        [37941],
        [42572],
        [42032],
        [43219],
        [42451],
        [36300],
        [40110],
        [40988],
        [40087],
        [41251],
        [44778],
        [41789],
        [44247],
        [45963],
        [39599],
        [42310],
        [43189]], device='cuda:0')
[2024-07-24 10:16:58,753][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22278],
        [37033],
        [37242],
        [38639],
        [38317],
        [38710],
        [39556],
        [41399],
        [40802],
        [38807],
        [39034],
        [38027],
        [38578],
        [37866],
        [38364],
        [38190],
        [37653],
        [38067],
        [37586],
        [38194]], device='cuda:0')
[2024-07-24 10:16:58,756][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1687],
        [2143],
        [2092],
        [1781],
        [1896],
        [1839],
        [1718],
        [1343],
        [1511],
        [1083],
        [2009],
        [1930],
        [1941],
        [1413],
        [1839],
        [1387],
        [1483],
        [2075],
        [1706],
        [1956]], device='cuda:0')
[2024-07-24 10:16:58,760][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12129],
        [34447],
        [41670],
        [36021],
        [37154],
        [38903],
        [39428],
        [39294],
        [38681],
        [37825],
        [39626],
        [38710],
        [38662],
        [38011],
        [37822],
        [38919],
        [39390],
        [40794],
        [37436],
        [40085]], device='cuda:0')
[2024-07-24 10:16:58,763][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[19388],
        [45702],
        [ 4787],
        [15420],
        [15318],
        [23524],
        [ 7143],
        [ 4447],
        [38073],
        [19354],
        [12637],
        [14709],
        [10281],
        [22583],
        [11545],
        [13759],
        [ 3895],
        [15062],
        [14340],
        [12525]], device='cuda:0')
[2024-07-24 10:16:58,764][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[26540],
        [14512],
        [14078],
        [13440],
        [12385],
        [13517],
        [12335],
        [12533],
        [ 9497],
        [10388],
        [10890],
        [11287],
        [10295],
        [10306],
        [ 9545],
        [10136],
        [ 9642],
        [10339],
        [ 9806],
        [10128]], device='cuda:0')
[2024-07-24 10:16:58,766][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35810],
        [49375],
        [49387],
        [49085],
        [49192],
        [49392],
        [49429],
        [48745],
        [49062],
        [48251],
        [49416],
        [49415],
        [49415],
        [49499],
        [49479],
        [49355],
        [49473],
        [49404],
        [49530],
        [49418]], device='cuda:0')
[2024-07-24 10:16:58,768][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21423],
        [  851],
        [  824],
        [  641],
        [  675],
        [  718],
        [  688],
        [  714],
        [  722],
        [  699],
        [  731],
        [  703],
        [  705],
        [  690],
        [  682],
        [  722],
        [  758],
        [  763],
        [  716],
        [  755]], device='cuda:0')
[2024-07-24 10:16:58,771][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[29575],
        [17962],
        [12425],
        [12038],
        [11752],
        [11441],
        [11520],
        [14547],
        [13470],
        [12029],
        [12528],
        [14509],
        [12550],
        [13216],
        [13014],
        [12528],
        [12252],
        [12411],
        [13535],
        [12379]], device='cuda:0')
[2024-07-24 10:16:58,774][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12490],
        [14334],
        [ 4722],
        [14025],
        [ 7566],
        [11186],
        [13002],
        [14605],
        [ 9854],
        [ 8491],
        [ 6340],
        [ 8648],
        [ 7544],
        [ 3698],
        [ 9495],
        [ 6676],
        [11557],
        [ 8472],
        [ 5591],
        [ 6941]], device='cuda:0')
[2024-07-24 10:16:58,777][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 6065],
        [ 6632],
        [14720],
        [16502],
        [17172],
        [15760],
        [19433],
        [18427],
        [16027],
        [16327],
        [15584],
        [15864],
        [18212],
        [16525],
        [17422],
        [15491],
        [18634],
        [15414],
        [15914],
        [15483]], device='cuda:0')
[2024-07-24 10:16:58,779][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12087],
        [ 5475],
        [11421],
        [11988],
        [11446],
        [11437],
        [11920],
        [11274],
        [ 9420],
        [11313],
        [11305],
        [11141],
        [11594],
        [ 9183],
        [10179],
        [10792],
        [ 9660],
        [10682],
        [ 8683],
        [10829]], device='cuda:0')
[2024-07-24 10:16:58,780][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[34241],
        [22206],
        [22894],
        [16362],
        [15623],
        [14387],
        [13851],
        [13010],
        [13201],
        [12701],
        [12701],
        [11944],
        [12399],
        [11831],
        [11070],
        [10957],
        [10078],
        [11920],
        [ 8554],
        [10614]], device='cuda:0')
[2024-07-24 10:16:58,782][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[16644],
        [ 8657],
        [ 3727],
        [ 2418],
        [ 2429],
        [ 2130],
        [ 1947],
        [ 2100],
        [ 2071],
        [ 1910],
        [ 2095],
        [ 2201],
        [ 1921],
        [ 1793],
        [ 1952],
        [ 1819],
        [ 1821],
        [ 2411],
        [ 2170],
        [ 2098]], device='cuda:0')
[2024-07-24 10:16:58,785][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[5724],
        [6001],
        [7063],
        [5676],
        [7073],
        [5349],
        [5985],
        [6036],
        [5523],
        [6813],
        [6371],
        [6287],
        [6197],
        [7101],
        [6216],
        [6572],
        [7127],
        [6505],
        [7192],
        [6597]], device='cuda:0')
[2024-07-24 10:16:58,789][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15039],
        [ 3556],
        [ 3524],
        [ 3981],
        [ 3740],
        [ 3851],
        [ 3946],
        [ 5314],
        [ 4422],
        [ 4863],
        [ 3593],
        [ 3534],
        [ 3584],
        [ 3829],
        [ 3720],
        [ 4266],
        [ 4013],
        [ 3531],
        [ 3435],
        [ 3470]], device='cuda:0')
[2024-07-24 10:16:58,792][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14064],
        [ 5727],
        [12700],
        [12592],
        [12486],
        [14303],
        [15920],
        [13573],
        [12397],
        [12503],
        [12112],
        [14981],
        [12760],
        [12456],
        [12928],
        [12555],
        [13826],
        [12437],
        [13597],
        [11861]], device='cuda:0')
[2024-07-24 10:16:58,793][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7654],
        [ 7730],
        [ 7851],
        [ 8191],
        [ 9584],
        [ 8578],
        [ 8776],
        [ 9184],
        [ 7751],
        [ 8230],
        [ 8806],
        [ 8979],
        [ 9165],
        [10578],
        [ 9579],
        [ 9535],
        [10531],
        [ 9104],
        [ 9721],
        [ 9165]], device='cuda:0')
[2024-07-24 10:16:58,795][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 7455],
        [10163],
        [10461],
        [14182],
        [ 9604],
        [10008],
        [ 9442],
        [11650],
        [11358],
        [10812],
        [11145],
        [12287],
        [10910],
        [ 9343],
        [ 9911],
        [10304],
        [ 8676],
        [11143],
        [10813],
        [10782]], device='cuda:0')
[2024-07-24 10:16:58,797][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[41688],
        [ 3268],
        [ 3251],
        [ 3628],
        [ 3506],
        [ 3205],
        [ 3159],
        [ 4473],
        [ 3999],
        [ 6696],
        [ 3214],
        [ 3218],
        [ 3211],
        [ 3117],
        [ 3165],
        [ 3479],
        [ 3278],
        [ 3212],
        [ 3048],
        [ 3202]], device='cuda:0')
[2024-07-24 10:16:58,800][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19628],
        [19703],
        [19684],
        [19815],
        [20521],
        [21052],
        [20841],
        [20566],
        [20635],
        [20034],
        [21250],
        [24302],
        [20308],
        [22036],
        [24942],
        [22514],
        [24264],
        [25944],
        [25019],
        [25840]], device='cuda:0')
[2024-07-24 10:16:58,803][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10399],
        [13475],
        [13972],
        [14112],
        [13997],
        [13380],
        [12453],
        [13755],
        [13067],
        [12919],
        [13325],
        [11446],
        [13295],
        [12790],
        [12836],
        [13427],
        [13243],
        [13660],
        [12210],
        [13569]], device='cuda:0')
[2024-07-24 10:16:58,806][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[11544],
        [26933],
        [26162],
        [28756],
        [28842],
        [30292],
        [29663],
        [28589],
        [30598],
        [29430],
        [29806],
        [29106],
        [29540],
        [30524],
        [29587],
        [30124],
        [29599],
        [29588],
        [30820],
        [30489]], device='cuda:0')
[2024-07-24 10:16:58,808][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[18629],
        [41795],
        [33775],
        [28750],
        [34901],
        [28801],
        [26830],
        [27242],
        [29574],
        [28276],
        [37187],
        [36084],
        [35031],
        [40776],
        [32103],
        [36967],
        [29534],
        [38148],
        [38648],
        [40107]], device='cuda:0')
[2024-07-24 10:16:58,809][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636],
        [7636]], device='cuda:0')
[2024-07-24 10:16:58,911][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:58,913][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,914][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,915][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,915][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,916][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,917][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,918][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,919][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,919][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,920][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,921][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,921][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:58,922][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2415, 0.7585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,925][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3061, 0.6939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,929][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3343, 0.6657], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,931][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2607, 0.7393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,932][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1531, 0.8469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,932][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1735, 0.8265], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,933][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3584, 0.6416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,934][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2609, 0.7391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,934][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([6.1996e-04, 9.9938e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,938][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4565, 0.5435], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,942][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7236, 0.2764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,944][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2782, 0.7218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:58,945][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1858, 0.3991, 0.4151], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,945][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.2848, 0.4020, 0.3132], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,946][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.1779, 0.1698, 0.6524], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,947][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1156, 0.3895, 0.4949], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,949][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0374, 0.0876, 0.8750], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,952][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0698, 0.2965, 0.6337], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,957][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.5887, 0.1765, 0.2348], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,957][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.3093, 0.3359, 0.3549], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,958][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0012, 0.7253, 0.2736], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,959][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.2750, 0.2182, 0.5068], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,959][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.5452, 0.1086, 0.3461], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,962][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.2469, 0.3308, 0.4224], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:58,965][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1260, 0.1967, 0.3691, 0.3081], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,970][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1582, 0.2062, 0.2724, 0.3632], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,970][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1485, 0.1084, 0.6322, 0.1110], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,971][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0324, 0.2869, 0.3525, 0.3281], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,972][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0185, 0.0395, 0.8406, 0.1014], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,972][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0366, 0.2241, 0.5321, 0.2072], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,975][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4125, 0.2652, 0.2232, 0.0991], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,978][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1388, 0.2148, 0.2277, 0.4187], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,981][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.8645e-05, 8.1491e-01, 1.5647e-01, 2.8600e-02], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,983][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4851, 0.1531, 0.2901, 0.0716], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,983][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1893, 0.1358, 0.4082, 0.2666], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,984][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2364, 0.2801, 0.3622, 0.1213], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:58,985][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0872, 0.1617, 0.2144, 0.2023, 0.3346], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,986][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.1148, 0.2041, 0.2133, 0.2582, 0.2097], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,988][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0697, 0.1096, 0.3812, 0.0943, 0.3452], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,992][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0112, 0.1838, 0.2230, 0.2616, 0.3204], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,996][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0178, 0.0396, 0.5130, 0.0537, 0.3759], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,996][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0315, 0.1867, 0.4235, 0.1621, 0.1962], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,997][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.3081, 0.1737, 0.2737, 0.0868, 0.1577], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,998][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.1196, 0.1760, 0.1791, 0.2297, 0.2956], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:58,999][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ James] are: tensor([2.0395e-04, 6.5728e-01, 2.8601e-01, 2.2068e-02, 3.4434e-02],
       device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,001][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.1879, 0.1337, 0.3983, 0.0884, 0.1918], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,004][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.1802, 0.1135, 0.3302, 0.1703, 0.2058], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,008][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0937, 0.2808, 0.3581, 0.1211, 0.1463], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,009][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ were] are: tensor([0.0423, 0.1637, 0.2118, 0.1846, 0.3247, 0.0728], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,010][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ were] are: tensor([0.0765, 0.1472, 0.2088, 0.1946, 0.1782, 0.1946], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,011][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ were] are: tensor([0.0302, 0.0742, 0.3592, 0.0770, 0.3192, 0.1402], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,011][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ were] are: tensor([0.0060, 0.1605, 0.0959, 0.2203, 0.1316, 0.3857], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,012][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ were] are: tensor([0.0047, 0.0287, 0.4366, 0.0496, 0.3245, 0.1559], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,015][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ were] are: tensor([0.0287, 0.1301, 0.4417, 0.1166, 0.1696, 0.1132], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,019][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ were] are: tensor([0.1970, 0.2122, 0.2610, 0.0926, 0.1524, 0.0847], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,022][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ were] are: tensor([0.0315, 0.1497, 0.0972, 0.2128, 0.1209, 0.3879], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,023][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ were] are: tensor([1.2650e-04, 7.3986e-01, 1.6352e-01, 4.8619e-02, 2.9586e-02, 1.8290e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,023][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ were] are: tensor([0.2089, 0.1364, 0.3113, 0.0700, 0.1413, 0.1321], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,024][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ were] are: tensor([0.0327, 0.1075, 0.3362, 0.1806, 0.1306, 0.2123], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,025][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ were] are: tensor([0.0319, 0.1828, 0.1857, 0.1482, 0.0865, 0.3649], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,027][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ thinking] are: tensor([0.0413, 0.1196, 0.1554, 0.1705, 0.2585, 0.0677, 0.1871],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,031][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ thinking] are: tensor([0.0410, 0.0827, 0.1341, 0.1573, 0.1293, 0.1628, 0.2928],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,035][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ thinking] are: tensor([0.0313, 0.0390, 0.3565, 0.0566, 0.2762, 0.1366, 0.1038],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,036][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ thinking] are: tensor([0.0037, 0.0751, 0.1019, 0.1432, 0.1773, 0.2725, 0.2263],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,036][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ thinking] are: tensor([0.0067, 0.0187, 0.4367, 0.0379, 0.2935, 0.1244, 0.0821],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,037][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ thinking] are: tensor([0.0177, 0.0966, 0.3671, 0.1015, 0.1540, 0.1143, 0.1489],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,038][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ thinking] are: tensor([0.2973, 0.1170, 0.2408, 0.0528, 0.1412, 0.0567, 0.0943],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,040][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ thinking] are: tensor([0.0321, 0.0542, 0.0730, 0.1293, 0.1079, 0.4077, 0.1959],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,042][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ thinking] are: tensor([8.4942e-05, 6.8006e-01, 1.9618e-01, 5.7906e-02, 3.3685e-02, 1.7299e-02,
        1.4793e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,047][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ thinking] are: tensor([0.1176, 0.0672, 0.4069, 0.0452, 0.1608, 0.1050, 0.0973],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,048][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ thinking] are: tensor([0.0271, 0.0698, 0.3707, 0.1150, 0.1453, 0.1100, 0.1621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,049][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ thinking] are: tensor([0.0370, 0.1596, 0.2324, 0.0875, 0.0876, 0.2319, 0.1639],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,050][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ about] are: tensor([0.0487, 0.0668, 0.1283, 0.0890, 0.1954, 0.0383, 0.1604, 0.2731],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,050][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ about] are: tensor([0.0561, 0.0679, 0.0968, 0.1032, 0.1088, 0.0851, 0.1553, 0.3268],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,051][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ about] are: tensor([0.0375, 0.0382, 0.2615, 0.0475, 0.2750, 0.0884, 0.0759, 0.1760],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,054][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ about] are: tensor([0.0051, 0.0741, 0.0879, 0.1032, 0.1452, 0.2479, 0.1904, 0.1462],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,059][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ about] are: tensor([0.0114, 0.0222, 0.3645, 0.0441, 0.2761, 0.1086, 0.0753, 0.0979],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,063][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ about] are: tensor([0.0351, 0.0931, 0.3393, 0.0848, 0.1279, 0.0632, 0.1146, 0.1420],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,064][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ about] are: tensor([0.3064, 0.1181, 0.1883, 0.0497, 0.1254, 0.0397, 0.0633, 0.1091],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,065][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ about] are: tensor([0.0318, 0.0499, 0.0580, 0.0926, 0.0909, 0.2239, 0.1617, 0.2912],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,066][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ about] are: tensor([0.0006, 0.5739, 0.2178, 0.0674, 0.0569, 0.0171, 0.0178, 0.0485],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,066][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ about] are: tensor([0.2016, 0.0787, 0.3141, 0.0452, 0.1318, 0.0892, 0.0883, 0.0511],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,069][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ about] are: tensor([0.0601, 0.0637, 0.2913, 0.1069, 0.1102, 0.1098, 0.1344, 0.1236],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,073][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ about] are: tensor([0.0091, 0.1098, 0.1995, 0.0763, 0.0880, 0.2088, 0.1404, 0.1681],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,076][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ going] are: tensor([0.0305, 0.0753, 0.1226, 0.1050, 0.1818, 0.0422, 0.1225, 0.2089, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,077][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ going] are: tensor([0.0326, 0.0566, 0.0947, 0.0770, 0.0777, 0.1128, 0.1516, 0.2470, 0.1501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,078][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ going] are: tensor([0.0192, 0.0428, 0.2383, 0.0553, 0.1833, 0.1381, 0.0930, 0.1295, 0.1006],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,079][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ going] are: tensor([0.0043, 0.0604, 0.0625, 0.0785, 0.1115, 0.2425, 0.1519, 0.1718, 0.1166],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,079][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ going] are: tensor([0.0046, 0.0194, 0.3297, 0.0395, 0.2376, 0.1428, 0.0708, 0.0756, 0.0800],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,082][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ going] are: tensor([0.0239, 0.0967, 0.2578, 0.0879, 0.0999, 0.1089, 0.1243, 0.1440, 0.0565],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,085][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ going] are: tensor([0.1766, 0.1162, 0.1960, 0.0609, 0.1073, 0.0627, 0.0898, 0.0998, 0.0906],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,090][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ going] are: tensor([0.0255, 0.0456, 0.0552, 0.0877, 0.0817, 0.2221, 0.1189, 0.2322, 0.1311],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,090][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ going] are: tensor([1.8463e-04, 6.0873e-01, 2.2864e-01, 4.2483e-02, 4.6278e-02, 1.2904e-02,
        1.2964e-02, 2.8416e-02, 1.9397e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,091][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ going] are: tensor([0.1772, 0.0820, 0.2498, 0.0468, 0.1022, 0.1084, 0.0930, 0.0543, 0.0863],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,092][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ going] are: tensor([0.0143, 0.0631, 0.2062, 0.1165, 0.0839, 0.1455, 0.1375, 0.1011, 0.1320],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,093][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ going] are: tensor([0.0110, 0.1224, 0.1133, 0.0809, 0.0560, 0.2612, 0.1032, 0.1373, 0.1146],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,095][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0311, 0.0540, 0.1191, 0.0737, 0.1774, 0.0262, 0.1103, 0.1747, 0.0769,
        0.1565], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,099][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0422, 0.0541, 0.0697, 0.0837, 0.0612, 0.0705, 0.1195, 0.2123, 0.1080,
        0.1789], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,103][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0324, 0.0450, 0.2648, 0.0364, 0.1979, 0.0769, 0.0686, 0.1042, 0.0626,
        0.1113], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,103][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0039, 0.0672, 0.0704, 0.0642, 0.1013, 0.2124, 0.1329, 0.1209, 0.0948,
        0.1320], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,104][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0078, 0.0158, 0.4030, 0.0277, 0.2292, 0.0897, 0.0466, 0.0502, 0.0480,
        0.0821], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,105][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0242, 0.0941, 0.3156, 0.0714, 0.0901, 0.0680, 0.1087, 0.0978, 0.0509,
        0.0792], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,106][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2876, 0.1406, 0.1521, 0.0554, 0.0875, 0.0376, 0.0560, 0.0757, 0.0570,
        0.0507], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,109][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0491, 0.0757, 0.0533, 0.0777, 0.0747, 0.1437, 0.1316, 0.1751, 0.0982,
        0.1211], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,111][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.6511e-05, 6.3039e-01, 1.5781e-01, 3.3233e-02, 2.5503e-02, 1.0034e-02,
        7.5603e-03, 2.4178e-02, 1.2348e-02, 9.8899e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,116][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3161, 0.0875, 0.2111, 0.0355, 0.0793, 0.0626, 0.0720, 0.0389, 0.0616,
        0.0354], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,116][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0683, 0.0773, 0.1922, 0.1079, 0.0614, 0.1018, 0.0937, 0.0716, 0.0767,
        0.1491], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,117][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0136, 0.1399, 0.1489, 0.0749, 0.0535, 0.2034, 0.0781, 0.0923, 0.0904,
        0.1051], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,118][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0260, 0.0395, 0.0738, 0.0503, 0.1253, 0.0219, 0.0880, 0.1459, 0.0610,
        0.1213, 0.2471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,119][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0573, 0.0706, 0.0674, 0.0574, 0.0481, 0.0552, 0.0916, 0.2139, 0.0935,
        0.1411, 0.1038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,122][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0260, 0.0416, 0.2610, 0.0275, 0.1867, 0.0589, 0.0442, 0.1057, 0.0491,
        0.0849, 0.1146], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,126][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0011, 0.0599, 0.0521, 0.0587, 0.1000, 0.2444, 0.1164, 0.0932, 0.0845,
        0.0969, 0.0926], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,129][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0043, 0.0156, 0.3437, 0.0269, 0.2146, 0.0754, 0.0512, 0.0522, 0.0496,
        0.0759, 0.0906], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,129][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0443, 0.1010, 0.3543, 0.0550, 0.0960, 0.0335, 0.0714, 0.0839, 0.0330,
        0.0591, 0.0683], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,130][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2790, 0.1624, 0.1636, 0.0401, 0.0824, 0.0329, 0.0455, 0.0646, 0.0460,
        0.0401, 0.0432], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,131][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0389, 0.0458, 0.0338, 0.0659, 0.0520, 0.1655, 0.1035, 0.2055, 0.0777,
        0.0838, 0.1275], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,132][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.5643e-04, 6.2576e-01, 1.2158e-01, 6.0436e-02, 2.2979e-02, 1.2002e-02,
        5.2745e-03, 2.5826e-02, 6.9874e-03, 1.1249e-01, 6.5086e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,135][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2176, 0.1432, 0.2265, 0.0379, 0.0766, 0.0752, 0.0687, 0.0367, 0.0546,
        0.0328, 0.0302], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,139][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0452, 0.0584, 0.2026, 0.0817, 0.0602, 0.1127, 0.0815, 0.0820, 0.0701,
        0.1186, 0.0869], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,142][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0087, 0.1317, 0.1235, 0.0427, 0.0504, 0.2850, 0.0560, 0.0733, 0.0726,
        0.0672, 0.0888], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,142][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0144, 0.0450, 0.0686, 0.0722, 0.0935, 0.0249, 0.0633, 0.1371, 0.0564,
        0.1542, 0.2201, 0.0505], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,143][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0155, 0.0418, 0.0573, 0.0591, 0.0509, 0.0806, 0.0895, 0.1664, 0.0819,
        0.1438, 0.1143, 0.0990], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,144][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0096, 0.0233, 0.2177, 0.0347, 0.1583, 0.0816, 0.0605, 0.0898, 0.0687,
        0.0995, 0.1007, 0.0557], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,145][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0074, 0.0524, 0.0685, 0.0841, 0.0898, 0.1375, 0.1136, 0.1174, 0.0606,
        0.1292, 0.0991, 0.0404], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,148][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0043, 0.0218, 0.2564, 0.0301, 0.1468, 0.0989, 0.0523, 0.0522, 0.0595,
        0.0949, 0.0875, 0.0952], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,151][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0098, 0.0667, 0.1903, 0.0750, 0.0707, 0.0801, 0.0781, 0.1092, 0.0362,
        0.0959, 0.1187, 0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,155][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1275, 0.0883, 0.1540, 0.0424, 0.0745, 0.0551, 0.0714, 0.1028, 0.0607,
        0.0609, 0.0537, 0.1087], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,156][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0119, 0.0217, 0.0382, 0.0514, 0.0501, 0.1682, 0.0848, 0.1479, 0.0722,
        0.1048, 0.1490, 0.0997], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,156][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ store] are: tensor([4.4628e-05, 5.2413e-01, 1.6269e-01, 5.9820e-02, 3.3364e-02, 1.0828e-02,
        8.9448e-03, 2.1255e-02, 8.5216e-03, 1.2878e-01, 5.6451e-03, 3.5972e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,157][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0881, 0.0383, 0.2492, 0.0359, 0.1043, 0.0942, 0.0771, 0.0581, 0.0715,
        0.0510, 0.0457, 0.0866], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,158][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0213, 0.0535, 0.2233, 0.0960, 0.0766, 0.0858, 0.0959, 0.0684, 0.0602,
        0.1059, 0.0610, 0.0521], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,161][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0129, 0.1061, 0.1327, 0.0743, 0.0455, 0.1653, 0.0809, 0.1012, 0.0593,
        0.0903, 0.0785, 0.0531], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,164][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0130, 0.0408, 0.0684, 0.0576, 0.1105, 0.0175, 0.0695, 0.1211, 0.0539,
        0.1112, 0.2056, 0.0399, 0.0910], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,168][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0570, 0.0439, 0.0634, 0.0501, 0.0476, 0.0504, 0.0839, 0.1476, 0.0733,
        0.1185, 0.0805, 0.0805, 0.1035], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,169][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0342, 0.0273, 0.2223, 0.0225, 0.1740, 0.0622, 0.0565, 0.0842, 0.0552,
        0.0795, 0.0817, 0.0597, 0.0410], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,170][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0067, 0.0616, 0.0828, 0.0544, 0.1156, 0.1581, 0.1140, 0.0972, 0.0700,
        0.1086, 0.0492, 0.0452, 0.0367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,170][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0063, 0.0131, 0.2814, 0.0262, 0.1525, 0.0850, 0.0472, 0.0477, 0.0453,
        0.0802, 0.0904, 0.0692, 0.0555], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,171][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0272, 0.0794, 0.2396, 0.0596, 0.0726, 0.0445, 0.0824, 0.0792, 0.0353,
        0.0598, 0.0824, 0.0617, 0.0763], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,175][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2513, 0.0915, 0.1114, 0.0342, 0.0616, 0.0319, 0.0492, 0.0599, 0.0445,
        0.0419, 0.0445, 0.0830, 0.0953], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,179][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0200, 0.0389, 0.0300, 0.0515, 0.0386, 0.1304, 0.0937, 0.1404, 0.0578,
        0.0974, 0.1227, 0.0780, 0.1006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,181][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([2.9919e-04, 5.5332e-01, 1.5390e-01, 7.5957e-02, 3.4972e-02, 7.7142e-03,
        6.6668e-03, 2.4366e-02, 6.6359e-03, 9.9852e-02, 3.6546e-03, 1.5249e-02,
        1.7414e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,182][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1885, 0.0889, 0.2226, 0.0305, 0.0709, 0.0643, 0.0735, 0.0342, 0.0573,
        0.0360, 0.0361, 0.0526, 0.0446], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,182][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1197, 0.0599, 0.1826, 0.0733, 0.0495, 0.0621, 0.0733, 0.0578, 0.0525,
        0.1134, 0.0422, 0.0355, 0.0782], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,183][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0423, 0.1161, 0.1224, 0.0598, 0.0510, 0.1515, 0.0691, 0.0973, 0.0571,
        0.0974, 0.0479, 0.0588, 0.0295], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,185][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ James] are: tensor([0.0188, 0.0433, 0.0744, 0.0537, 0.1104, 0.0185, 0.0615, 0.0996, 0.0502,
        0.0879, 0.1938, 0.0465, 0.0852, 0.0564], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,189][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ James] are: tensor([0.0383, 0.0493, 0.0550, 0.0518, 0.0458, 0.0627, 0.0706, 0.1395, 0.0659,
        0.0971, 0.0583, 0.0812, 0.0858, 0.0987], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,193][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ James] are: tensor([0.0205, 0.0297, 0.1630, 0.0221, 0.1394, 0.0433, 0.0360, 0.0662, 0.0389,
        0.0691, 0.0543, 0.0464, 0.0341, 0.2371], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,194][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ James] are: tensor([0.0026, 0.0425, 0.0727, 0.0547, 0.1008, 0.1334, 0.0977, 0.0976, 0.0695,
        0.1078, 0.0723, 0.0449, 0.0417, 0.0619], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,195][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ James] are: tensor([0.0074, 0.0132, 0.2595, 0.0166, 0.1467, 0.0477, 0.0324, 0.0360, 0.0329,
        0.0507, 0.0359, 0.0641, 0.0316, 0.2253], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,196][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ James] are: tensor([0.0143, 0.0681, 0.1982, 0.0597, 0.0742, 0.0439, 0.0512, 0.0762, 0.0251,
        0.0596, 0.0718, 0.0543, 0.0637, 0.1398], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,198][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ James] are: tensor([0.1976, 0.0680, 0.1280, 0.0315, 0.0716, 0.0272, 0.0308, 0.0661, 0.0341,
        0.0361, 0.0236, 0.0908, 0.0557, 0.1388], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,202][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ James] are: tensor([0.0261, 0.0382, 0.0447, 0.0493, 0.0588, 0.0972, 0.0659, 0.1191, 0.0425,
        0.0671, 0.0695, 0.1011, 0.0737, 0.1468], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,204][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ James] are: tensor([2.3671e-04, 4.6618e-01, 2.3428e-01, 2.7207e-02, 3.9655e-02, 8.3003e-03,
        1.3705e-02, 2.7476e-02, 1.3847e-02, 7.4123e-02, 9.3523e-03, 2.5475e-02,
        3.0482e-02, 2.9679e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,206][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ James] are: tensor([0.1409, 0.0703, 0.1940, 0.0350, 0.0799, 0.0469, 0.0484, 0.0322, 0.0360,
        0.0336, 0.0245, 0.0512, 0.0408, 0.1661], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,207][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ James] are: tensor([0.0406, 0.0412, 0.1405, 0.0721, 0.0645, 0.0665, 0.0668, 0.0551, 0.0521,
        0.1221, 0.0686, 0.0400, 0.0686, 0.1013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,208][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ James] are: tensor([0.0321, 0.1124, 0.1696, 0.0605, 0.0616, 0.1373, 0.0658, 0.0755, 0.0559,
        0.0816, 0.0582, 0.0434, 0.0246, 0.0215], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,209][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ wanted] are: tensor([0.0102, 0.0416, 0.0680, 0.0498, 0.0877, 0.0215, 0.0583, 0.1205, 0.0460,
        0.1128, 0.1827, 0.0403, 0.0830, 0.0414, 0.0363], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,211][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ wanted] are: tensor([0.0243, 0.0347, 0.0595, 0.0440, 0.0507, 0.0536, 0.0827, 0.1257, 0.0647,
        0.0938, 0.0759, 0.0753, 0.0749, 0.0940, 0.0461], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,214][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ wanted] are: tensor([0.0114, 0.0238, 0.1552, 0.0259, 0.1386, 0.0563, 0.0474, 0.0670, 0.0457,
        0.0684, 0.0653, 0.0402, 0.0307, 0.1895, 0.0346], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,219][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ wanted] are: tensor([0.0027, 0.0530, 0.0656, 0.0537, 0.0935, 0.1541, 0.0988, 0.0931, 0.0718,
        0.0825, 0.0688, 0.0394, 0.0423, 0.0392, 0.0414], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,220][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ wanted] are: tensor([0.0030, 0.0108, 0.2073, 0.0206, 0.1386, 0.0630, 0.0419, 0.0348, 0.0354,
        0.0564, 0.0625, 0.0596, 0.0349, 0.2012, 0.0300], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,220][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ wanted] are: tensor([0.0143, 0.0617, 0.1891, 0.0562, 0.0725, 0.0387, 0.0665, 0.0719, 0.0291,
        0.0568, 0.0718, 0.0496, 0.0630, 0.1119, 0.0468], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,221][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ wanted] are: tensor([0.0692, 0.0779, 0.1128, 0.0347, 0.0634, 0.0432, 0.0582, 0.0775, 0.0522,
        0.0457, 0.0430, 0.0953, 0.0727, 0.1085, 0.0457], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,222][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ wanted] are: tensor([0.0109, 0.0238, 0.0256, 0.0513, 0.0371, 0.1388, 0.0616, 0.1124, 0.0548,
        0.0693, 0.1019, 0.0591, 0.0855, 0.0843, 0.0835], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,224][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ wanted] are: tensor([1.7663e-04, 4.8953e-01, 1.9783e-01, 4.4372e-02, 4.2113e-02, 9.5040e-03,
        1.0716e-02, 2.5250e-02, 1.1861e-02, 8.8007e-02, 5.1196e-03, 2.1936e-02,
        2.1335e-02, 2.0631e-02, 1.1621e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,227][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ wanted] are: tensor([0.1147, 0.0522, 0.2125, 0.0331, 0.0849, 0.0531, 0.0683, 0.0311, 0.0466,
        0.0273, 0.0249, 0.0609, 0.0311, 0.1261, 0.0333], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,232][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ wanted] are: tensor([0.0257, 0.0412, 0.1784, 0.0769, 0.0479, 0.0885, 0.0768, 0.0630, 0.0529,
        0.0938, 0.0480, 0.0325, 0.0549, 0.0454, 0.0741], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,233][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ wanted] are: tensor([0.0164, 0.0882, 0.1328, 0.0644, 0.0454, 0.1472, 0.0845, 0.0846, 0.0582,
        0.0867, 0.0537, 0.0483, 0.0203, 0.0110, 0.0583], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,233][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0094, 0.0335, 0.0738, 0.0415, 0.0952, 0.0154, 0.0624, 0.0989, 0.0396,
        0.0886, 0.2185, 0.0378, 0.0601, 0.0446, 0.0340, 0.0468],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,234][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0180, 0.0366, 0.0433, 0.0566, 0.0383, 0.0498, 0.0674, 0.1115, 0.0620,
        0.1056, 0.0655, 0.0712, 0.0931, 0.0725, 0.0369, 0.0717],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,235][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0107, 0.0306, 0.1787, 0.0245, 0.1396, 0.0507, 0.0442, 0.0575, 0.0373,
        0.0636, 0.0510, 0.0443, 0.0277, 0.1607, 0.0282, 0.0508],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,238][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0041, 0.0646, 0.0838, 0.0537, 0.0895, 0.1539, 0.0982, 0.0746, 0.0630,
        0.0868, 0.0473, 0.0358, 0.0367, 0.0425, 0.0269, 0.0387],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,241][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0047, 0.0101, 0.2524, 0.0176, 0.1393, 0.0506, 0.0284, 0.0254, 0.0287,
        0.0478, 0.0465, 0.0517, 0.0326, 0.1863, 0.0285, 0.0495],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,245][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0112, 0.0630, 0.2151, 0.0556, 0.0654, 0.0431, 0.0623, 0.0627, 0.0288,
        0.0485, 0.0591, 0.0493, 0.0545, 0.0956, 0.0394, 0.0463],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,246][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1199, 0.0873, 0.0961, 0.0412, 0.0613, 0.0283, 0.0393, 0.0556, 0.0402,
        0.0396, 0.0364, 0.0945, 0.0830, 0.1062, 0.0304, 0.0407],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,247][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0201, 0.0389, 0.0319, 0.0419, 0.0462, 0.0904, 0.0688, 0.0967, 0.0514,
        0.0660, 0.0774, 0.0829, 0.0655, 0.0908, 0.0588, 0.0723],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,248][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.4218e-05, 5.5560e-01, 1.6545e-01, 2.8214e-02, 2.8290e-02, 8.8394e-03,
        9.0239e-03, 2.3726e-02, 1.3550e-02, 7.3709e-02, 5.3647e-03, 1.8079e-02,
        2.1549e-02, 1.9051e-02, 8.5083e-03, 2.1002e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,250][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1635, 0.0696, 0.1649, 0.0320, 0.0644, 0.0486, 0.0645, 0.0344, 0.0499,
        0.0328, 0.0283, 0.0613, 0.0358, 0.0962, 0.0265, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,253][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0190, 0.0536, 0.1487, 0.0797, 0.0398, 0.0691, 0.0702, 0.0493, 0.0512,
        0.1172, 0.0394, 0.0280, 0.0561, 0.0438, 0.0505, 0.0843],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,258][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0082, 0.0975, 0.1169, 0.0698, 0.0413, 0.1459, 0.0607, 0.0629, 0.0672,
        0.0906, 0.0487, 0.0505, 0.0277, 0.0141, 0.0463, 0.0517],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,259][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ give] are: tensor([0.0082, 0.0340, 0.0653, 0.0408, 0.0813, 0.0176, 0.0556, 0.0955, 0.0421,
        0.0935, 0.1779, 0.0391, 0.0634, 0.0453, 0.0361, 0.0515, 0.0527],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,260][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ give] are: tensor([0.0133, 0.0274, 0.0429, 0.0308, 0.0408, 0.0318, 0.0483, 0.1084, 0.0594,
        0.1063, 0.0823, 0.0654, 0.0667, 0.1067, 0.0395, 0.0738, 0.0560],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,261][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ give] are: tensor([0.0078, 0.0173, 0.1195, 0.0188, 0.1048, 0.0400, 0.0318, 0.0605, 0.0309,
        0.0676, 0.0544, 0.0384, 0.0287, 0.2261, 0.0309, 0.0649, 0.0576],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,261][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ give] are: tensor([0.0027, 0.0358, 0.0537, 0.0496, 0.0918, 0.1076, 0.0778, 0.0876, 0.0538,
        0.0832, 0.0798, 0.0428, 0.0433, 0.0603, 0.0339, 0.0460, 0.0504],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,264][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ give] are: tensor([0.0039, 0.0095, 0.1694, 0.0157, 0.1181, 0.0464, 0.0305, 0.0346, 0.0324,
        0.0600, 0.0533, 0.0529, 0.0355, 0.1952, 0.0331, 0.0686, 0.0408],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,268][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ give] are: tensor([0.0107, 0.0387, 0.1448, 0.0408, 0.0619, 0.0342, 0.0400, 0.0720, 0.0220,
        0.0616, 0.0640, 0.0471, 0.0577, 0.1329, 0.0405, 0.0636, 0.0676],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,271][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ give] are: tensor([0.0823, 0.0523, 0.0948, 0.0275, 0.0533, 0.0287, 0.0336, 0.0735, 0.0343,
        0.0527, 0.0364, 0.0779, 0.0757, 0.1224, 0.0354, 0.0584, 0.0606],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,272][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ give] are: tensor([0.0060, 0.0146, 0.0217, 0.0418, 0.0362, 0.0869, 0.0471, 0.1032, 0.0448,
        0.0769, 0.1117, 0.0607, 0.0658, 0.0895, 0.0571, 0.0739, 0.0621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,273][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ give] are: tensor([2.3118e-04, 4.5214e-01, 1.3355e-01, 6.6961e-02, 4.0947e-02, 9.3070e-03,
        1.1454e-02, 2.7116e-02, 9.9266e-03, 8.4021e-02, 5.4496e-03, 2.2476e-02,
        1.9860e-02, 1.5883e-02, 8.8263e-03, 2.0815e-02, 7.1027e-02],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,274][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ give] are: tensor([0.0656, 0.0430, 0.1405, 0.0254, 0.0724, 0.0516, 0.0498, 0.0466, 0.0423,
        0.0449, 0.0328, 0.0604, 0.0455, 0.1485, 0.0326, 0.0522, 0.0459],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,276][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ give] are: tensor([0.0192, 0.0295, 0.1531, 0.0461, 0.0490, 0.0525, 0.0467, 0.0477, 0.0424,
        0.0863, 0.0553, 0.0313, 0.0549, 0.0727, 0.0572, 0.0802, 0.0759],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,280][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ give] are: tensor([0.0045, 0.0785, 0.0944, 0.0517, 0.0434, 0.1207, 0.0497, 0.0610, 0.0550,
        0.0776, 0.0738, 0.0439, 0.0288, 0.0223, 0.0531, 0.0524, 0.0891],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,284][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0102, 0.0328, 0.0534, 0.0389, 0.0731, 0.0178, 0.0479, 0.0932, 0.0356,
        0.0866, 0.1915, 0.0276, 0.0579, 0.0312, 0.0243, 0.0438, 0.0405, 0.0938],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,285][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0174, 0.0301, 0.0395, 0.0327, 0.0315, 0.0402, 0.0542, 0.1046, 0.0619,
        0.0789, 0.0693, 0.0649, 0.0696, 0.0652, 0.0380, 0.0534, 0.0437, 0.1049],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,286][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0077, 0.0195, 0.1353, 0.0196, 0.1200, 0.0449, 0.0295, 0.0538, 0.0306,
        0.0485, 0.0581, 0.0390, 0.0279, 0.1622, 0.0297, 0.0453, 0.0543, 0.0741],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,287][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0020, 0.0621, 0.0570, 0.0656, 0.0921, 0.1404, 0.0902, 0.0644, 0.0486,
        0.0751, 0.0606, 0.0265, 0.0439, 0.0380, 0.0293, 0.0290, 0.0362, 0.0387],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,288][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0025, 0.0098, 0.2037, 0.0151, 0.1321, 0.0476, 0.0239, 0.0271, 0.0249,
        0.0426, 0.0392, 0.0484, 0.0290, 0.1544, 0.0284, 0.0504, 0.0322, 0.0886],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,291][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0137, 0.0570, 0.2067, 0.0394, 0.0619, 0.0294, 0.0379, 0.0531, 0.0181,
        0.0371, 0.0437, 0.0493, 0.0430, 0.0923, 0.0316, 0.0364, 0.0517, 0.0976],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,293][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1345, 0.0682, 0.0884, 0.0269, 0.0513, 0.0250, 0.0330, 0.0526, 0.0311,
        0.0290, 0.0322, 0.0954, 0.0715, 0.0942, 0.0327, 0.0335, 0.0504, 0.0501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,298][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0120, 0.0213, 0.0199, 0.0431, 0.0340, 0.0829, 0.0535, 0.1083, 0.0401,
        0.0488, 0.0733, 0.0767, 0.0569, 0.0604, 0.0533, 0.0520, 0.0553, 0.1080],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,298][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([2.3483e-04, 5.1209e-01, 1.4969e-01, 5.7150e-02, 5.1861e-02, 9.3419e-03,
        7.7149e-03, 3.1287e-02, 7.8314e-03, 8.4035e-02, 3.9748e-03, 8.4979e-03,
        1.3099e-02, 9.8924e-03, 5.1076e-03, 1.3223e-02, 3.3967e-02, 1.0008e-03],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,299][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2111, 0.0788, 0.1229, 0.0244, 0.0512, 0.0473, 0.0445, 0.0241, 0.0357,
        0.0225, 0.0184, 0.0589, 0.0333, 0.0779, 0.0239, 0.0207, 0.0354, 0.0689],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,300][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0190, 0.0289, 0.1322, 0.0631, 0.0344, 0.0845, 0.0636, 0.0501, 0.0468,
        0.0791, 0.0480, 0.0210, 0.0547, 0.0340, 0.0507, 0.0593, 0.0481, 0.0824],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,303][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0036, 0.0841, 0.0915, 0.0451, 0.0371, 0.2003, 0.0389, 0.0517, 0.0587,
        0.0525, 0.0633, 0.0342, 0.0212, 0.0099, 0.0562, 0.0276, 0.0680, 0.0560],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,307][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ ring] are: tensor([0.0128, 0.0487, 0.0568, 0.0494, 0.0663, 0.0185, 0.0483, 0.0880, 0.0368,
        0.0762, 0.1577, 0.0355, 0.0647, 0.0380, 0.0298, 0.0419, 0.0438, 0.0713,
        0.0154], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,310][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ ring] are: tensor([0.0189, 0.0230, 0.0358, 0.0320, 0.0313, 0.0384, 0.0519, 0.0892, 0.0568,
        0.0827, 0.0656, 0.0543, 0.0598, 0.0747, 0.0352, 0.0591, 0.0475, 0.1037,
        0.0399], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,311][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ ring] are: tensor([0.0086, 0.0160, 0.1019, 0.0199, 0.0931, 0.0458, 0.0374, 0.0600, 0.0414,
        0.0588, 0.0530, 0.0359, 0.0294, 0.1370, 0.0314, 0.0556, 0.0565, 0.0883,
        0.0298], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,312][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ ring] are: tensor([0.0043, 0.0457, 0.0585, 0.0546, 0.0736, 0.0773, 0.0728, 0.0598, 0.0458,
        0.0823, 0.0564, 0.0444, 0.0472, 0.0533, 0.0320, 0.0514, 0.0524, 0.0613,
        0.0267], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,313][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ ring] are: tensor([0.0038, 0.0129, 0.1617, 0.0150, 0.0885, 0.0524, 0.0261, 0.0250, 0.0300,
        0.0510, 0.0382, 0.0481, 0.0286, 0.1265, 0.0219, 0.0550, 0.0282, 0.0861,
        0.1011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,316][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ ring] are: tensor([0.0108, 0.0386, 0.0997, 0.0413, 0.0495, 0.0400, 0.0349, 0.0648, 0.0225,
        0.0499, 0.0718, 0.0438, 0.0524, 0.0781, 0.0339, 0.0434, 0.0558, 0.1137,
        0.0552], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,319][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ ring] are: tensor([0.1195, 0.0462, 0.0794, 0.0262, 0.0396, 0.0339, 0.0377, 0.0717, 0.0381,
        0.0452, 0.0311, 0.0714, 0.0486, 0.0651, 0.0361, 0.0430, 0.0626, 0.0529,
        0.0518], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,323][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ ring] are: tensor([0.0132, 0.0136, 0.0221, 0.0316, 0.0299, 0.0754, 0.0523, 0.0811, 0.0389,
        0.0576, 0.0866, 0.0560, 0.0631, 0.0708, 0.0534, 0.0575, 0.0531, 0.1030,
        0.0407], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,324][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ ring] are: tensor([1.0145e-04, 4.6320e-01, 1.5126e-01, 3.5325e-02, 3.1493e-02, 1.1554e-02,
        1.1148e-02, 1.7671e-02, 1.1462e-02, 7.2296e-02, 4.7504e-03, 3.4409e-02,
        2.0565e-02, 1.7010e-02, 1.1293e-02, 2.3355e-02, 6.6898e-02, 3.0661e-03,
        1.3141e-02], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,325][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ ring] are: tensor([0.0781, 0.0330, 0.0927, 0.0240, 0.0528, 0.0585, 0.0392, 0.0398, 0.0476,
        0.0354, 0.0372, 0.0602, 0.0375, 0.0919, 0.0276, 0.0369, 0.0430, 0.0953,
        0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,326][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ ring] are: tensor([0.0187, 0.0283, 0.1353, 0.0584, 0.0437, 0.0501, 0.0648, 0.0413, 0.0456,
        0.0811, 0.0441, 0.0277, 0.0479, 0.0493, 0.0502, 0.0634, 0.0546, 0.0719,
        0.0237], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,327][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ ring] are: tensor([0.0080, 0.0726, 0.0872, 0.0639, 0.0389, 0.1064, 0.0539, 0.0485, 0.0582,
        0.0742, 0.0457, 0.0382, 0.0287, 0.0146, 0.0479, 0.0482, 0.0775, 0.0632,
        0.0243], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,330][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0076, 0.0277, 0.0601, 0.0370, 0.0782, 0.0144, 0.0505, 0.0907, 0.0303,
        0.0719, 0.1779, 0.0298, 0.0510, 0.0316, 0.0268, 0.0382, 0.0395, 0.0930,
        0.0115, 0.0323], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,334][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0286, 0.0355, 0.0346, 0.0394, 0.0298, 0.0326, 0.0506, 0.0878, 0.0499,
        0.0774, 0.0504, 0.0547, 0.0757, 0.0529, 0.0282, 0.0586, 0.0404, 0.0753,
        0.0281, 0.0695], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,337][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0099, 0.0262, 0.1321, 0.0186, 0.1254, 0.0423, 0.0358, 0.0474, 0.0326,
        0.0492, 0.0427, 0.0375, 0.0274, 0.1376, 0.0242, 0.0413, 0.0570, 0.0534,
        0.0200, 0.0395], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,337][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0028, 0.0599, 0.0843, 0.0480, 0.0923, 0.1364, 0.0867, 0.0567, 0.0470,
        0.0660, 0.0377, 0.0344, 0.0354, 0.0361, 0.0257, 0.0290, 0.0388, 0.0365,
        0.0160, 0.0304], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,338][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0038, 0.0084, 0.2044, 0.0135, 0.1136, 0.0394, 0.0209, 0.0188, 0.0205,
        0.0367, 0.0352, 0.0376, 0.0233, 0.1396, 0.0200, 0.0399, 0.0227, 0.0726,
        0.0741, 0.0551], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,339][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0116, 0.0551, 0.1738, 0.0480, 0.0579, 0.0267, 0.0518, 0.0449, 0.0244,
        0.0327, 0.0400, 0.0416, 0.0457, 0.0753, 0.0309, 0.0328, 0.0542, 0.0672,
        0.0423, 0.0432], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,342][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1227, 0.0766, 0.0705, 0.0292, 0.0446, 0.0210, 0.0320, 0.0433, 0.0343,
        0.0308, 0.0290, 0.0793, 0.0767, 0.0832, 0.0271, 0.0354, 0.0508, 0.0421,
        0.0405, 0.0309], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,345][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0169, 0.0292, 0.0214, 0.0340, 0.0338, 0.0648, 0.0630, 0.0763, 0.0428,
        0.0480, 0.0566, 0.0683, 0.0565, 0.0666, 0.0541, 0.0576, 0.0520, 0.0686,
        0.0295, 0.0601], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,347][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([3.2867e-05, 5.3065e-01, 1.5462e-01, 3.7496e-02, 2.6849e-02, 8.4546e-03,
        8.2053e-03, 2.0772e-02, 1.0748e-02, 6.8080e-02, 4.5197e-03, 1.2189e-02,
        1.5756e-02, 1.3464e-02, 7.2150e-03, 1.8092e-02, 5.0683e-02, 3.3884e-03,
        3.8414e-03, 4.9444e-03], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,350][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1819, 0.0601, 0.1150, 0.0235, 0.0526, 0.0352, 0.0488, 0.0249, 0.0400,
        0.0229, 0.0216, 0.0522, 0.0304, 0.0813, 0.0222, 0.0218, 0.0399, 0.0542,
        0.0470, 0.0246], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,351][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0164, 0.0380, 0.1330, 0.0653, 0.0325, 0.0584, 0.0632, 0.0400, 0.0401,
        0.0938, 0.0299, 0.0215, 0.0519, 0.0386, 0.0511, 0.0750, 0.0468, 0.0475,
        0.0114, 0.0453], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,352][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0043, 0.0832, 0.1007, 0.0636, 0.0382, 0.1255, 0.0496, 0.0471, 0.0526,
        0.0672, 0.0449, 0.0454, 0.0249, 0.0136, 0.0413, 0.0395, 0.0726, 0.0432,
        0.0188, 0.0237], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,452][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:16:59,454][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,454][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,455][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,456][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,456][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,457][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,457][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,458][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,459][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,459][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,460][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,461][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:16:59,461][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2415, 0.7585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,462][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3061, 0.6939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,463][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3343, 0.6657], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,465][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2607, 0.7393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,469][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1531, 0.8469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,469][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1735, 0.8265], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,470][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3584, 0.6416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,471][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2609, 0.7391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,471][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0089, 0.9911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,473][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4565, 0.5435], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,476][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7236, 0.2764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,481][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2782, 0.7218], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:16:59,482][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.1858, 0.3991, 0.4151], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,482][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.2848, 0.4020, 0.3132], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,483][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.1779, 0.1698, 0.6524], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,484][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1156, 0.3895, 0.4949], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,485][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0374, 0.0876, 0.8750], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,487][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0698, 0.2965, 0.6337], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,490][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.5887, 0.1765, 0.2348], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,494][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.3093, 0.3359, 0.3549], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,495][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0099, 0.6397, 0.3503], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,496][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.2750, 0.2182, 0.5068], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,496][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.5452, 0.1086, 0.3461], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,497][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.2469, 0.3308, 0.4224], device='cuda:0') for source tokens [Then, Sarah]
[2024-07-24 10:16:59,498][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1260, 0.1967, 0.3691, 0.3081], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,500][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1582, 0.2062, 0.2724, 0.3632], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,503][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1485, 0.1084, 0.6322, 0.1110], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,507][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0324, 0.2869, 0.3525, 0.3281], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,508][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0185, 0.0395, 0.8406, 0.1014], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,509][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0366, 0.2241, 0.5321, 0.2072], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,509][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4125, 0.2652, 0.2232, 0.0991], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,510][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1388, 0.2148, 0.2277, 0.4187], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,511][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0021, 0.6987, 0.2023, 0.0969], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,513][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4851, 0.1531, 0.2901, 0.0716], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,516][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1893, 0.1358, 0.4082, 0.2666], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,520][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2364, 0.2801, 0.3622, 0.1213], device='cuda:0') for source tokens [Then, Sarah and]
[2024-07-24 10:16:59,521][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0872, 0.1617, 0.2144, 0.2023, 0.3346], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,522][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.1148, 0.2041, 0.2133, 0.2582, 0.2097], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,522][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0697, 0.1096, 0.3812, 0.0943, 0.3452], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,523][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0112, 0.1838, 0.2230, 0.2616, 0.3204], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,524][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0178, 0.0396, 0.5130, 0.0537, 0.3759], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,527][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0315, 0.1867, 0.4235, 0.1621, 0.1962], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,529][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.3081, 0.1737, 0.2737, 0.0868, 0.1577], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,533][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.1196, 0.1760, 0.1791, 0.2297, 0.2956], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,534][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0039, 0.5172, 0.3046, 0.0652, 0.1090], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,535][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.1879, 0.1337, 0.3983, 0.0884, 0.1918], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,536][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.1802, 0.1135, 0.3302, 0.1703, 0.2058], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,536][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0937, 0.2808, 0.3581, 0.1211, 0.1463], device='cuda:0') for source tokens [Then, Sarah and James]
[2024-07-24 10:16:59,537][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ were] are: tensor([0.0423, 0.1637, 0.2118, 0.1846, 0.3247, 0.0728], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,540][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ were] are: tensor([0.0765, 0.1472, 0.2088, 0.1946, 0.1782, 0.1946], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,542][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ were] are: tensor([0.0302, 0.0742, 0.3592, 0.0770, 0.3192, 0.1402], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,547][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ were] are: tensor([0.0060, 0.1605, 0.0959, 0.2203, 0.1316, 0.3857], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,548][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ were] are: tensor([0.0047, 0.0287, 0.4366, 0.0496, 0.3245, 0.1559], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,548][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ were] are: tensor([0.0287, 0.1301, 0.4417, 0.1166, 0.1696, 0.1132], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,549][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ were] are: tensor([0.1970, 0.2122, 0.2610, 0.0926, 0.1524, 0.0847], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,550][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ were] are: tensor([0.0315, 0.1497, 0.0972, 0.2128, 0.1209, 0.3879], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,552][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ were] are: tensor([0.0029, 0.6079, 0.2109, 0.0778, 0.0758, 0.0246], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,555][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ were] are: tensor([0.2089, 0.1364, 0.3113, 0.0700, 0.1413, 0.1321], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,559][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ were] are: tensor([0.0327, 0.1075, 0.3362, 0.1806, 0.1306, 0.2123], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,560][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ were] are: tensor([0.0319, 0.1828, 0.1857, 0.1482, 0.0865, 0.3649], device='cuda:0') for source tokens [Then, Sarah and James were]
[2024-07-24 10:16:59,561][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ thinking] are: tensor([0.0413, 0.1196, 0.1554, 0.1705, 0.2585, 0.0677, 0.1871],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,562][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ thinking] are: tensor([0.0410, 0.0827, 0.1341, 0.1573, 0.1293, 0.1628, 0.2928],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,562][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ thinking] are: tensor([0.0313, 0.0390, 0.3565, 0.0566, 0.2762, 0.1366, 0.1038],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,563][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ thinking] are: tensor([0.0037, 0.0751, 0.1019, 0.1432, 0.1773, 0.2725, 0.2263],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,566][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ thinking] are: tensor([0.0067, 0.0187, 0.4367, 0.0379, 0.2935, 0.1244, 0.0821],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,570][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ thinking] are: tensor([0.0177, 0.0966, 0.3671, 0.1015, 0.1540, 0.1143, 0.1489],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,573][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ thinking] are: tensor([0.2973, 0.1170, 0.2408, 0.0528, 0.1412, 0.0567, 0.0943],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,574][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ thinking] are: tensor([0.0321, 0.0542, 0.0730, 0.1293, 0.1079, 0.4077, 0.1959],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,574][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ thinking] are: tensor([0.0014, 0.5548, 0.2451, 0.0778, 0.0718, 0.0206, 0.0285],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,575][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ thinking] are: tensor([0.1176, 0.0672, 0.4069, 0.0452, 0.1608, 0.1050, 0.0973],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,576][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ thinking] are: tensor([0.0271, 0.0698, 0.3707, 0.1150, 0.1453, 0.1100, 0.1621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,578][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ thinking] are: tensor([0.0370, 0.1596, 0.2324, 0.0875, 0.0876, 0.2319, 0.1639],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking]
[2024-07-24 10:16:59,582][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ about] are: tensor([0.0487, 0.0668, 0.1283, 0.0890, 0.1954, 0.0383, 0.1604, 0.2731],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,586][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ about] are: tensor([0.0561, 0.0679, 0.0968, 0.1032, 0.1088, 0.0851, 0.1553, 0.3268],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,586][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ about] are: tensor([0.0375, 0.0382, 0.2615, 0.0475, 0.2750, 0.0884, 0.0759, 0.1760],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,587][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ about] are: tensor([0.0051, 0.0741, 0.0879, 0.1032, 0.1452, 0.2479, 0.1904, 0.1462],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,588][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ about] are: tensor([0.0114, 0.0222, 0.3645, 0.0441, 0.2761, 0.1086, 0.0753, 0.0979],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,589][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ about] are: tensor([0.0351, 0.0931, 0.3393, 0.0848, 0.1279, 0.0632, 0.1146, 0.1420],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,591][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ about] are: tensor([0.3064, 0.1181, 0.1883, 0.0497, 0.1254, 0.0397, 0.0633, 0.1091],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,594][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ about] are: tensor([0.0318, 0.0499, 0.0580, 0.0926, 0.0909, 0.2239, 0.1617, 0.2912],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,599][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ about] are: tensor([0.0095, 0.4264, 0.2436, 0.0712, 0.1046, 0.0211, 0.0352, 0.0884],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,600][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ about] are: tensor([0.2016, 0.0787, 0.3141, 0.0452, 0.1318, 0.0892, 0.0883, 0.0511],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,600][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ about] are: tensor([0.0601, 0.0637, 0.2913, 0.1069, 0.1102, 0.1098, 0.1344, 0.1236],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,601][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ about] are: tensor([0.0091, 0.1098, 0.1995, 0.0763, 0.0880, 0.2088, 0.1404, 0.1681],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about]
[2024-07-24 10:16:59,602][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ going] are: tensor([0.0305, 0.0753, 0.1226, 0.1050, 0.1818, 0.0422, 0.1225, 0.2089, 0.1111],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,604][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ going] are: tensor([0.0326, 0.0566, 0.0947, 0.0770, 0.0777, 0.1128, 0.1516, 0.2470, 0.1501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,608][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ going] are: tensor([0.0192, 0.0428, 0.2383, 0.0553, 0.1833, 0.1381, 0.0930, 0.1295, 0.1006],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,612][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ going] are: tensor([0.0043, 0.0604, 0.0625, 0.0785, 0.1115, 0.2425, 0.1519, 0.1718, 0.1166],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,613][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ going] are: tensor([0.0046, 0.0194, 0.3297, 0.0395, 0.2376, 0.1428, 0.0708, 0.0756, 0.0800],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,613][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ going] are: tensor([0.0239, 0.0967, 0.2578, 0.0879, 0.0999, 0.1089, 0.1243, 0.1440, 0.0565],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,614][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ going] are: tensor([0.1766, 0.1162, 0.1960, 0.0609, 0.1073, 0.0627, 0.0898, 0.0998, 0.0906],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,615][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ going] are: tensor([0.0255, 0.0456, 0.0552, 0.0877, 0.0817, 0.2221, 0.1189, 0.2322, 0.1311],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,618][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ going] are: tensor([0.0024, 0.4813, 0.2706, 0.0535, 0.0895, 0.0149, 0.0237, 0.0463, 0.0178],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,621][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ going] are: tensor([0.1772, 0.0820, 0.2498, 0.0468, 0.1022, 0.1084, 0.0930, 0.0543, 0.0863],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,625][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ going] are: tensor([0.0143, 0.0631, 0.2062, 0.1165, 0.0839, 0.1455, 0.1375, 0.1011, 0.1320],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,626][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ going] are: tensor([0.0110, 0.1224, 0.1133, 0.0809, 0.0560, 0.2612, 0.1032, 0.1373, 0.1146],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going]
[2024-07-24 10:16:59,626][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0311, 0.0540, 0.1191, 0.0737, 0.1774, 0.0262, 0.1103, 0.1747, 0.0769,
        0.1565], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,627][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0422, 0.0541, 0.0697, 0.0837, 0.0612, 0.0705, 0.1195, 0.2123, 0.1080,
        0.1789], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,628][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0324, 0.0450, 0.2648, 0.0364, 0.1979, 0.0769, 0.0686, 0.1042, 0.0626,
        0.1113], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,631][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0039, 0.0672, 0.0704, 0.0642, 0.1013, 0.2124, 0.1329, 0.1209, 0.0948,
        0.1320], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,634][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0078, 0.0158, 0.4030, 0.0277, 0.2292, 0.0897, 0.0466, 0.0502, 0.0480,
        0.0821], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,638][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0242, 0.0941, 0.3156, 0.0714, 0.0901, 0.0680, 0.1087, 0.0978, 0.0509,
        0.0792], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,639][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.2876, 0.1406, 0.1521, 0.0554, 0.0875, 0.0376, 0.0560, 0.0757, 0.0570,
        0.0507], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,639][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0491, 0.0757, 0.0533, 0.0777, 0.0747, 0.1437, 0.1316, 0.1751, 0.0982,
        0.1211], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,640][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0020, 0.5029, 0.1916, 0.0572, 0.0667, 0.0142, 0.0181, 0.0540, 0.0131,
        0.0801], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,641][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3161, 0.0875, 0.2111, 0.0355, 0.0793, 0.0626, 0.0720, 0.0389, 0.0616,
        0.0354], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,644][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0683, 0.0773, 0.1922, 0.1079, 0.0614, 0.1018, 0.0937, 0.0716, 0.0767,
        0.1491], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,648][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0136, 0.1399, 0.1489, 0.0749, 0.0535, 0.2034, 0.0781, 0.0923, 0.0904,
        0.1051], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to]
[2024-07-24 10:16:59,651][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0260, 0.0395, 0.0738, 0.0503, 0.1253, 0.0219, 0.0880, 0.1459, 0.0610,
        0.1213, 0.2471], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,652][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0573, 0.0706, 0.0674, 0.0574, 0.0481, 0.0552, 0.0916, 0.2139, 0.0935,
        0.1411, 0.1038], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,653][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0260, 0.0416, 0.2610, 0.0275, 0.1867, 0.0589, 0.0442, 0.1057, 0.0491,
        0.0849, 0.1146], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,653][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0011, 0.0599, 0.0521, 0.0587, 0.1000, 0.2444, 0.1164, 0.0932, 0.0845,
        0.0969, 0.0926], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,654][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0043, 0.0156, 0.3437, 0.0269, 0.2146, 0.0754, 0.0512, 0.0522, 0.0496,
        0.0759, 0.0906], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,657][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0443, 0.1010, 0.3543, 0.0550, 0.0960, 0.0335, 0.0714, 0.0839, 0.0330,
        0.0591, 0.0683], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,661][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2790, 0.1624, 0.1636, 0.0401, 0.0824, 0.0329, 0.0455, 0.0646, 0.0460,
        0.0401, 0.0432], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,664][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0389, 0.0458, 0.0338, 0.0659, 0.0520, 0.1655, 0.1035, 0.2055, 0.0777,
        0.0838, 0.1275], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,665][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0082, 0.5264, 0.1750, 0.0618, 0.0527, 0.0164, 0.0136, 0.0578, 0.0081,
        0.0757, 0.0042], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,666][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.2176, 0.1432, 0.2265, 0.0379, 0.0766, 0.0752, 0.0687, 0.0367, 0.0546,
        0.0328, 0.0302], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,666][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0452, 0.0584, 0.2026, 0.0817, 0.0602, 0.1127, 0.0815, 0.0820, 0.0701,
        0.1186, 0.0869], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,667][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0087, 0.1317, 0.1235, 0.0427, 0.0504, 0.2850, 0.0560, 0.0733, 0.0726,
        0.0672, 0.0888], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the]
[2024-07-24 10:16:59,670][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0144, 0.0450, 0.0686, 0.0722, 0.0935, 0.0249, 0.0633, 0.1371, 0.0564,
        0.1542, 0.2201, 0.0505], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,673][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0155, 0.0418, 0.0573, 0.0591, 0.0509, 0.0806, 0.0895, 0.1664, 0.0819,
        0.1438, 0.1143, 0.0990], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,674][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0096, 0.0233, 0.2177, 0.0347, 0.1583, 0.0816, 0.0605, 0.0898, 0.0687,
        0.0995, 0.1007, 0.0557], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,678][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0074, 0.0524, 0.0685, 0.0841, 0.0898, 0.1375, 0.1136, 0.1174, 0.0606,
        0.1292, 0.0991, 0.0404], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,679][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0043, 0.0218, 0.2564, 0.0301, 0.1468, 0.0989, 0.0523, 0.0522, 0.0595,
        0.0949, 0.0875, 0.0952], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,680][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0098, 0.0667, 0.1903, 0.0750, 0.0707, 0.0801, 0.0781, 0.1092, 0.0362,
        0.0959, 0.1187, 0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,681][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.1275, 0.0883, 0.1540, 0.0424, 0.0745, 0.0551, 0.0714, 0.1028, 0.0607,
        0.0609, 0.0537, 0.1087], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,682][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0119, 0.0217, 0.0382, 0.0514, 0.0501, 0.1682, 0.0848, 0.1479, 0.0722,
        0.1048, 0.1490, 0.0997], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,684][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0014, 0.4226, 0.2170, 0.0635, 0.0673, 0.0124, 0.0181, 0.0366, 0.0090,
        0.0847, 0.0034, 0.0640], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,687][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0881, 0.0383, 0.2492, 0.0359, 0.1043, 0.0942, 0.0771, 0.0581, 0.0715,
        0.0510, 0.0457, 0.0866], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,692][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0213, 0.0535, 0.2233, 0.0960, 0.0766, 0.0858, 0.0959, 0.0684, 0.0602,
        0.1059, 0.0610, 0.0521], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,693][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0129, 0.1061, 0.1327, 0.0743, 0.0455, 0.1653, 0.0809, 0.1012, 0.0593,
        0.0903, 0.0785, 0.0531], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store]
[2024-07-24 10:16:59,693][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0130, 0.0408, 0.0684, 0.0576, 0.1105, 0.0175, 0.0695, 0.1211, 0.0539,
        0.1112, 0.2056, 0.0399, 0.0910], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,694][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0570, 0.0439, 0.0634, 0.0501, 0.0476, 0.0504, 0.0839, 0.1476, 0.0733,
        0.1185, 0.0805, 0.0805, 0.1035], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,695][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0342, 0.0273, 0.2223, 0.0225, 0.1740, 0.0622, 0.0565, 0.0842, 0.0552,
        0.0795, 0.0817, 0.0597, 0.0410], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,698][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0067, 0.0616, 0.0828, 0.0544, 0.1156, 0.1581, 0.1140, 0.0972, 0.0700,
        0.1086, 0.0492, 0.0452, 0.0367], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,701][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0063, 0.0131, 0.2814, 0.0262, 0.1525, 0.0850, 0.0472, 0.0477, 0.0453,
        0.0802, 0.0904, 0.0692, 0.0555], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,705][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0272, 0.0794, 0.2396, 0.0596, 0.0726, 0.0445, 0.0824, 0.0792, 0.0353,
        0.0598, 0.0824, 0.0617, 0.0763], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,706][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2513, 0.0915, 0.1114, 0.0342, 0.0616, 0.0319, 0.0492, 0.0599, 0.0445,
        0.0419, 0.0445, 0.0830, 0.0953], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,707][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0200, 0.0389, 0.0300, 0.0515, 0.0386, 0.1304, 0.0937, 0.1404, 0.0578,
        0.0974, 0.1227, 0.0780, 0.1006], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,707][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0079, 0.4574, 0.2135, 0.0621, 0.0624, 0.0099, 0.0145, 0.0448, 0.0076,
        0.0665, 0.0024, 0.0301, 0.0209], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,709][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1885, 0.0889, 0.2226, 0.0305, 0.0709, 0.0643, 0.0735, 0.0342, 0.0573,
        0.0360, 0.0361, 0.0526, 0.0446], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,712][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1197, 0.0599, 0.1826, 0.0733, 0.0495, 0.0621, 0.0733, 0.0578, 0.0525,
        0.1134, 0.0422, 0.0355, 0.0782], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,716][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0423, 0.1161, 0.1224, 0.0598, 0.0510, 0.1515, 0.0691, 0.0973, 0.0571,
        0.0974, 0.0479, 0.0588, 0.0295], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store.]
[2024-07-24 10:16:59,718][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ James] are: tensor([0.0188, 0.0433, 0.0744, 0.0537, 0.1104, 0.0185, 0.0615, 0.0996, 0.0502,
        0.0879, 0.1938, 0.0465, 0.0852, 0.0564], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,719][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ James] are: tensor([0.0383, 0.0493, 0.0550, 0.0518, 0.0458, 0.0627, 0.0706, 0.1395, 0.0659,
        0.0971, 0.0583, 0.0812, 0.0858, 0.0987], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,720][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ James] are: tensor([0.0205, 0.0297, 0.1630, 0.0221, 0.1394, 0.0433, 0.0360, 0.0662, 0.0389,
        0.0691, 0.0543, 0.0464, 0.0341, 0.2371], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,720][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ James] are: tensor([0.0026, 0.0425, 0.0727, 0.0547, 0.1008, 0.1334, 0.0977, 0.0976, 0.0695,
        0.1078, 0.0723, 0.0449, 0.0417, 0.0619], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,723][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ James] are: tensor([0.0074, 0.0132, 0.2595, 0.0166, 0.1467, 0.0477, 0.0324, 0.0360, 0.0329,
        0.0507, 0.0359, 0.0641, 0.0316, 0.2253], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,726][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ James] are: tensor([0.0143, 0.0681, 0.1982, 0.0597, 0.0742, 0.0439, 0.0512, 0.0762, 0.0251,
        0.0596, 0.0718, 0.0543, 0.0637, 0.1398], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,731][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ James] are: tensor([0.1976, 0.0680, 0.1280, 0.0315, 0.0716, 0.0272, 0.0308, 0.0661, 0.0341,
        0.0361, 0.0236, 0.0908, 0.0557, 0.1388], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,731][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ James] are: tensor([0.0261, 0.0382, 0.0447, 0.0493, 0.0588, 0.0972, 0.0659, 0.1191, 0.0425,
        0.0671, 0.0695, 0.1011, 0.0737, 0.1468], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,732][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ James] are: tensor([0.0039, 0.3586, 0.2560, 0.0442, 0.0892, 0.0104, 0.0251, 0.0488, 0.0125,
        0.0619, 0.0069, 0.0367, 0.0255, 0.0203], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,733][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ James] are: tensor([0.1409, 0.0703, 0.1940, 0.0350, 0.0799, 0.0469, 0.0484, 0.0322, 0.0360,
        0.0336, 0.0245, 0.0512, 0.0408, 0.1661], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,735][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ James] are: tensor([0.0406, 0.0412, 0.1405, 0.0721, 0.0645, 0.0665, 0.0668, 0.0551, 0.0521,
        0.1221, 0.0686, 0.0400, 0.0686, 0.1013], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,738][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ James] are: tensor([0.0321, 0.1124, 0.1696, 0.0605, 0.0616, 0.1373, 0.0658, 0.0755, 0.0559,
        0.0816, 0.0582, 0.0434, 0.0246, 0.0215], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James]
[2024-07-24 10:16:59,743][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ wanted] are: tensor([0.0102, 0.0416, 0.0680, 0.0498, 0.0877, 0.0215, 0.0583, 0.1205, 0.0460,
        0.1128, 0.1827, 0.0403, 0.0830, 0.0414, 0.0363], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,744][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ wanted] are: tensor([0.0243, 0.0347, 0.0595, 0.0440, 0.0507, 0.0536, 0.0827, 0.1257, 0.0647,
        0.0938, 0.0759, 0.0753, 0.0749, 0.0940, 0.0461], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,745][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ wanted] are: tensor([0.0114, 0.0238, 0.1552, 0.0259, 0.1386, 0.0563, 0.0474, 0.0670, 0.0457,
        0.0684, 0.0653, 0.0402, 0.0307, 0.1895, 0.0346], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,746][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ wanted] are: tensor([0.0027, 0.0530, 0.0656, 0.0537, 0.0935, 0.1541, 0.0988, 0.0931, 0.0718,
        0.0825, 0.0688, 0.0394, 0.0423, 0.0392, 0.0414], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,747][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ wanted] are: tensor([0.0030, 0.0108, 0.2073, 0.0206, 0.1386, 0.0630, 0.0419, 0.0348, 0.0354,
        0.0564, 0.0625, 0.0596, 0.0349, 0.2012, 0.0300], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,750][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ wanted] are: tensor([0.0143, 0.0617, 0.1891, 0.0562, 0.0725, 0.0387, 0.0665, 0.0719, 0.0291,
        0.0568, 0.0718, 0.0496, 0.0630, 0.1119, 0.0468], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,753][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ wanted] are: tensor([0.0692, 0.0779, 0.1128, 0.0347, 0.0634, 0.0432, 0.0582, 0.0775, 0.0522,
        0.0457, 0.0430, 0.0953, 0.0727, 0.1085, 0.0457], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,757][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ wanted] are: tensor([0.0109, 0.0238, 0.0256, 0.0513, 0.0371, 0.1388, 0.0616, 0.1124, 0.0548,
        0.0693, 0.1019, 0.0591, 0.0855, 0.0843, 0.0835], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,757][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ wanted] are: tensor([0.0032, 0.3859, 0.2510, 0.0464, 0.0806, 0.0102, 0.0198, 0.0406, 0.0110,
        0.0594, 0.0029, 0.0365, 0.0209, 0.0146, 0.0169], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,758][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ wanted] are: tensor([0.1147, 0.0522, 0.2125, 0.0331, 0.0849, 0.0531, 0.0683, 0.0311, 0.0466,
        0.0273, 0.0249, 0.0609, 0.0311, 0.1261, 0.0333], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,759][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ wanted] are: tensor([0.0257, 0.0412, 0.1784, 0.0769, 0.0479, 0.0885, 0.0768, 0.0630, 0.0529,
        0.0938, 0.0480, 0.0325, 0.0549, 0.0454, 0.0741], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,761][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ wanted] are: tensor([0.0164, 0.0882, 0.1328, 0.0644, 0.0454, 0.1472, 0.0845, 0.0846, 0.0582,
        0.0867, 0.0537, 0.0483, 0.0203, 0.0110, 0.0583], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted]
[2024-07-24 10:16:59,765][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0094, 0.0335, 0.0738, 0.0415, 0.0952, 0.0154, 0.0624, 0.0989, 0.0396,
        0.0886, 0.2185, 0.0378, 0.0601, 0.0446, 0.0340, 0.0468],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,769][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0180, 0.0366, 0.0433, 0.0566, 0.0383, 0.0498, 0.0674, 0.1115, 0.0620,
        0.1056, 0.0655, 0.0712, 0.0931, 0.0725, 0.0369, 0.0717],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,770][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0107, 0.0306, 0.1787, 0.0245, 0.1396, 0.0507, 0.0442, 0.0575, 0.0373,
        0.0636, 0.0510, 0.0443, 0.0277, 0.1607, 0.0282, 0.0508],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,771][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0041, 0.0646, 0.0838, 0.0537, 0.0895, 0.1539, 0.0982, 0.0746, 0.0630,
        0.0868, 0.0473, 0.0358, 0.0367, 0.0425, 0.0269, 0.0387],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,772][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0047, 0.0101, 0.2524, 0.0176, 0.1393, 0.0506, 0.0284, 0.0254, 0.0287,
        0.0478, 0.0465, 0.0517, 0.0326, 0.1863, 0.0285, 0.0495],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,774][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0112, 0.0630, 0.2151, 0.0556, 0.0654, 0.0431, 0.0623, 0.0627, 0.0288,
        0.0485, 0.0591, 0.0493, 0.0545, 0.0956, 0.0394, 0.0463],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,778][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1199, 0.0873, 0.0961, 0.0412, 0.0613, 0.0283, 0.0393, 0.0556, 0.0402,
        0.0396, 0.0364, 0.0945, 0.0830, 0.1062, 0.0304, 0.0407],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,782][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0201, 0.0389, 0.0319, 0.0419, 0.0462, 0.0904, 0.0688, 0.0967, 0.0514,
        0.0660, 0.0774, 0.0829, 0.0655, 0.0908, 0.0588, 0.0723],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,783][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0019, 0.4281, 0.1938, 0.0491, 0.0765, 0.0110, 0.0195, 0.0496, 0.0130,
        0.0619, 0.0038, 0.0301, 0.0194, 0.0134, 0.0131, 0.0157],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,784][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1635, 0.0696, 0.1649, 0.0320, 0.0644, 0.0486, 0.0645, 0.0344, 0.0499,
        0.0328, 0.0283, 0.0613, 0.0358, 0.0962, 0.0265, 0.0274],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,785][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0190, 0.0536, 0.1487, 0.0797, 0.0398, 0.0691, 0.0702, 0.0493, 0.0512,
        0.1172, 0.0394, 0.0280, 0.0561, 0.0438, 0.0505, 0.0843],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,787][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0082, 0.0975, 0.1169, 0.0698, 0.0413, 0.1459, 0.0607, 0.0629, 0.0672,
        0.0906, 0.0487, 0.0505, 0.0277, 0.0141, 0.0463, 0.0517],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to]
[2024-07-24 10:16:59,790][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ give] are: tensor([0.0082, 0.0340, 0.0653, 0.0408, 0.0813, 0.0176, 0.0556, 0.0955, 0.0421,
        0.0935, 0.1779, 0.0391, 0.0634, 0.0453, 0.0361, 0.0515, 0.0527],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,795][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ give] are: tensor([0.0133, 0.0274, 0.0429, 0.0308, 0.0408, 0.0318, 0.0483, 0.1084, 0.0594,
        0.1063, 0.0823, 0.0654, 0.0667, 0.1067, 0.0395, 0.0738, 0.0560],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,796][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ give] are: tensor([0.0078, 0.0173, 0.1195, 0.0188, 0.1048, 0.0400, 0.0318, 0.0605, 0.0309,
        0.0676, 0.0544, 0.0384, 0.0287, 0.2261, 0.0309, 0.0649, 0.0576],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,797][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ give] are: tensor([0.0027, 0.0358, 0.0537, 0.0496, 0.0918, 0.1076, 0.0778, 0.0876, 0.0538,
        0.0832, 0.0798, 0.0428, 0.0433, 0.0603, 0.0339, 0.0460, 0.0504],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,798][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ give] are: tensor([0.0039, 0.0095, 0.1694, 0.0157, 0.1181, 0.0464, 0.0305, 0.0346, 0.0324,
        0.0600, 0.0533, 0.0529, 0.0355, 0.1952, 0.0331, 0.0686, 0.0408],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,798][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ give] are: tensor([0.0107, 0.0387, 0.1448, 0.0408, 0.0619, 0.0342, 0.0400, 0.0720, 0.0220,
        0.0616, 0.0640, 0.0471, 0.0577, 0.1329, 0.0405, 0.0636, 0.0676],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,802][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ give] are: tensor([0.0823, 0.0523, 0.0948, 0.0275, 0.0533, 0.0287, 0.0336, 0.0735, 0.0343,
        0.0527, 0.0364, 0.0779, 0.0757, 0.1224, 0.0354, 0.0584, 0.0606],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,804][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ give] are: tensor([0.0060, 0.0146, 0.0217, 0.0418, 0.0362, 0.0869, 0.0471, 0.1032, 0.0448,
        0.0769, 0.1117, 0.0607, 0.0658, 0.0895, 0.0571, 0.0739, 0.0621],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,809][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ give] are: tensor([0.0038, 0.3717, 0.1792, 0.0552, 0.0692, 0.0104, 0.0221, 0.0431, 0.0107,
        0.0549, 0.0032, 0.0395, 0.0220, 0.0123, 0.0143, 0.0148, 0.0736],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,809][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ give] are: tensor([0.0656, 0.0430, 0.1405, 0.0254, 0.0724, 0.0516, 0.0498, 0.0466, 0.0423,
        0.0449, 0.0328, 0.0604, 0.0455, 0.1485, 0.0326, 0.0522, 0.0459],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,810][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ give] are: tensor([0.0192, 0.0295, 0.1531, 0.0461, 0.0490, 0.0525, 0.0467, 0.0477, 0.0424,
        0.0863, 0.0553, 0.0313, 0.0549, 0.0727, 0.0572, 0.0802, 0.0759],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,811][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ give] are: tensor([0.0045, 0.0785, 0.0944, 0.0517, 0.0434, 0.1207, 0.0497, 0.0610, 0.0550,
        0.0776, 0.0738, 0.0439, 0.0288, 0.0223, 0.0531, 0.0524, 0.0891],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give]
[2024-07-24 10:16:59,813][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0102, 0.0328, 0.0534, 0.0389, 0.0731, 0.0178, 0.0479, 0.0932, 0.0356,
        0.0866, 0.1915, 0.0276, 0.0579, 0.0312, 0.0243, 0.0438, 0.0405, 0.0938],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,817][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0174, 0.0301, 0.0395, 0.0327, 0.0315, 0.0402, 0.0542, 0.1046, 0.0619,
        0.0789, 0.0693, 0.0649, 0.0696, 0.0652, 0.0380, 0.0534, 0.0437, 0.1049],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,821][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0077, 0.0195, 0.1353, 0.0196, 0.1200, 0.0449, 0.0295, 0.0538, 0.0306,
        0.0485, 0.0581, 0.0390, 0.0279, 0.1622, 0.0297, 0.0453, 0.0543, 0.0741],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,822][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0020, 0.0621, 0.0570, 0.0656, 0.0921, 0.1404, 0.0902, 0.0644, 0.0486,
        0.0751, 0.0606, 0.0265, 0.0439, 0.0380, 0.0293, 0.0290, 0.0362, 0.0387],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,823][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0025, 0.0098, 0.2037, 0.0151, 0.1321, 0.0476, 0.0239, 0.0271, 0.0249,
        0.0426, 0.0392, 0.0484, 0.0290, 0.1544, 0.0284, 0.0504, 0.0322, 0.0886],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,824][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0137, 0.0570, 0.2067, 0.0394, 0.0619, 0.0294, 0.0379, 0.0531, 0.0181,
        0.0371, 0.0437, 0.0493, 0.0430, 0.0923, 0.0316, 0.0364, 0.0517, 0.0976],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,825][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1345, 0.0682, 0.0884, 0.0269, 0.0513, 0.0250, 0.0330, 0.0526, 0.0311,
        0.0290, 0.0322, 0.0954, 0.0715, 0.0942, 0.0327, 0.0335, 0.0504, 0.0501],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,828][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0120, 0.0213, 0.0199, 0.0431, 0.0340, 0.0829, 0.0535, 0.1083, 0.0401,
        0.0488, 0.0733, 0.0767, 0.0569, 0.0604, 0.0533, 0.0520, 0.0553, 0.1080],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,830][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.0940e-03, 4.1450e-01, 2.0588e-01, 4.4362e-02, 9.5316e-02, 1.0589e-02,
        1.5721e-02, 5.5732e-02, 8.1193e-03, 5.1709e-02, 2.1881e-03, 1.4841e-02,
        1.3849e-02, 7.0315e-03, 8.0166e-03, 8.0649e-03, 3.4660e-02, 3.2352e-04],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,835][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2111, 0.0788, 0.1229, 0.0244, 0.0512, 0.0473, 0.0445, 0.0241, 0.0357,
        0.0225, 0.0184, 0.0589, 0.0333, 0.0779, 0.0239, 0.0207, 0.0354, 0.0689],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,837][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0190, 0.0289, 0.1322, 0.0631, 0.0344, 0.0845, 0.0636, 0.0501, 0.0468,
        0.0791, 0.0480, 0.0210, 0.0547, 0.0340, 0.0507, 0.0593, 0.0481, 0.0824],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,838][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0036, 0.0841, 0.0915, 0.0451, 0.0371, 0.2003, 0.0389, 0.0517, 0.0587,
        0.0525, 0.0633, 0.0342, 0.0212, 0.0099, 0.0562, 0.0276, 0.0680, 0.0560],
       device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a]
[2024-07-24 10:16:59,839][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ ring] are: tensor([0.0128, 0.0487, 0.0568, 0.0494, 0.0663, 0.0185, 0.0483, 0.0880, 0.0368,
        0.0762, 0.1577, 0.0355, 0.0647, 0.0380, 0.0298, 0.0419, 0.0438, 0.0713,
        0.0154], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,840][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ ring] are: tensor([0.0189, 0.0230, 0.0358, 0.0320, 0.0313, 0.0384, 0.0519, 0.0892, 0.0568,
        0.0827, 0.0656, 0.0543, 0.0598, 0.0747, 0.0352, 0.0591, 0.0475, 0.1037,
        0.0399], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,843][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ ring] are: tensor([0.0086, 0.0160, 0.1019, 0.0199, 0.0931, 0.0458, 0.0374, 0.0600, 0.0414,
        0.0588, 0.0530, 0.0359, 0.0294, 0.1370, 0.0314, 0.0556, 0.0565, 0.0883,
        0.0298], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,846][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ ring] are: tensor([0.0043, 0.0457, 0.0585, 0.0546, 0.0736, 0.0773, 0.0728, 0.0598, 0.0458,
        0.0823, 0.0564, 0.0444, 0.0472, 0.0533, 0.0320, 0.0514, 0.0524, 0.0613,
        0.0267], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,850][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ ring] are: tensor([0.0038, 0.0129, 0.1617, 0.0150, 0.0885, 0.0524, 0.0261, 0.0250, 0.0300,
        0.0510, 0.0382, 0.0481, 0.0286, 0.1265, 0.0219, 0.0550, 0.0282, 0.0861,
        0.1011], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,851][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ ring] are: tensor([0.0108, 0.0386, 0.0997, 0.0413, 0.0495, 0.0400, 0.0349, 0.0648, 0.0225,
        0.0499, 0.0718, 0.0438, 0.0524, 0.0781, 0.0339, 0.0434, 0.0558, 0.1137,
        0.0552], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,852][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ ring] are: tensor([0.1195, 0.0462, 0.0794, 0.0262, 0.0396, 0.0339, 0.0377, 0.0717, 0.0381,
        0.0452, 0.0311, 0.0714, 0.0486, 0.0651, 0.0361, 0.0430, 0.0626, 0.0529,
        0.0518], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,853][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ ring] are: tensor([0.0132, 0.0136, 0.0221, 0.0316, 0.0299, 0.0754, 0.0523, 0.0811, 0.0389,
        0.0576, 0.0866, 0.0560, 0.0631, 0.0708, 0.0534, 0.0575, 0.0531, 0.1030,
        0.0407], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,854][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ ring] are: tensor([0.0070, 0.3549, 0.1974, 0.0376, 0.0752, 0.0121, 0.0216, 0.0340, 0.0106,
        0.0528, 0.0029, 0.0536, 0.0207, 0.0137, 0.0155, 0.0152, 0.0628, 0.0008,
        0.0116], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,857][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ ring] are: tensor([0.0781, 0.0330, 0.0927, 0.0240, 0.0528, 0.0585, 0.0392, 0.0398, 0.0476,
        0.0354, 0.0372, 0.0602, 0.0375, 0.0919, 0.0276, 0.0369, 0.0430, 0.0953,
        0.0693], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,860][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ ring] are: tensor([0.0187, 0.0283, 0.1353, 0.0584, 0.0437, 0.0501, 0.0648, 0.0413, 0.0456,
        0.0811, 0.0441, 0.0277, 0.0479, 0.0493, 0.0502, 0.0634, 0.0546, 0.0719,
        0.0237], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,864][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ ring] are: tensor([0.0080, 0.0726, 0.0872, 0.0639, 0.0389, 0.1064, 0.0539, 0.0485, 0.0582,
        0.0742, 0.0457, 0.0382, 0.0287, 0.0146, 0.0479, 0.0482, 0.0775, 0.0632,
        0.0243], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring]
[2024-07-24 10:16:59,865][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0076, 0.0277, 0.0601, 0.0370, 0.0782, 0.0144, 0.0505, 0.0907, 0.0303,
        0.0719, 0.1779, 0.0298, 0.0510, 0.0316, 0.0268, 0.0382, 0.0395, 0.0930,
        0.0115, 0.0323], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,866][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0286, 0.0355, 0.0346, 0.0394, 0.0298, 0.0326, 0.0506, 0.0878, 0.0499,
        0.0774, 0.0504, 0.0547, 0.0757, 0.0529, 0.0282, 0.0586, 0.0404, 0.0753,
        0.0281, 0.0695], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,867][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0099, 0.0262, 0.1321, 0.0186, 0.1254, 0.0423, 0.0358, 0.0474, 0.0326,
        0.0492, 0.0427, 0.0375, 0.0274, 0.1376, 0.0242, 0.0413, 0.0570, 0.0534,
        0.0200, 0.0395], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,869][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0028, 0.0599, 0.0843, 0.0480, 0.0923, 0.1364, 0.0867, 0.0567, 0.0470,
        0.0660, 0.0377, 0.0344, 0.0354, 0.0361, 0.0257, 0.0290, 0.0388, 0.0365,
        0.0160, 0.0304], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,872][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0038, 0.0084, 0.2044, 0.0135, 0.1136, 0.0394, 0.0209, 0.0188, 0.0205,
        0.0367, 0.0352, 0.0376, 0.0233, 0.1396, 0.0200, 0.0399, 0.0227, 0.0726,
        0.0741, 0.0551], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,877][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0116, 0.0551, 0.1738, 0.0480, 0.0579, 0.0267, 0.0518, 0.0449, 0.0244,
        0.0327, 0.0400, 0.0416, 0.0457, 0.0753, 0.0309, 0.0328, 0.0542, 0.0672,
        0.0423, 0.0432], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,878][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1227, 0.0766, 0.0705, 0.0292, 0.0446, 0.0210, 0.0320, 0.0433, 0.0343,
        0.0308, 0.0290, 0.0793, 0.0767, 0.0832, 0.0271, 0.0354, 0.0508, 0.0421,
        0.0405, 0.0309], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,879][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0169, 0.0292, 0.0214, 0.0340, 0.0338, 0.0648, 0.0630, 0.0763, 0.0428,
        0.0480, 0.0566, 0.0683, 0.0565, 0.0666, 0.0541, 0.0576, 0.0520, 0.0686,
        0.0295, 0.0601], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,879][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0046, 0.3927, 0.1991, 0.0511, 0.0812, 0.0097, 0.0191, 0.0479, 0.0104,
        0.0541, 0.0029, 0.0216, 0.0159, 0.0104, 0.0113, 0.0123, 0.0470, 0.0007,
        0.0033, 0.0047], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,882][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1819, 0.0601, 0.1150, 0.0235, 0.0526, 0.0352, 0.0488, 0.0249, 0.0400,
        0.0229, 0.0216, 0.0522, 0.0304, 0.0813, 0.0222, 0.0218, 0.0399, 0.0542,
        0.0470, 0.0246], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,885][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0164, 0.0380, 0.1330, 0.0653, 0.0325, 0.0584, 0.0632, 0.0400, 0.0401,
        0.0938, 0.0299, 0.0215, 0.0519, 0.0386, 0.0511, 0.0750, 0.0468, 0.0475,
        0.0114, 0.0453], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,890][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0043, 0.0832, 0.1007, 0.0636, 0.0382, 0.1255, 0.0496, 0.0471, 0.0526,
        0.0672, 0.0449, 0.0454, 0.0249, 0.0136, 0.0413, 0.0395, 0.0726, 0.0432,
        0.0188, 0.0237], device='cuda:0') for source tokens [Then, Sarah and James were thinking about going to the store. James wanted to give a ring to]
[2024-07-24 10:16:59,893][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:16:59,895][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1238],
        [  38],
        [   1],
        [   9],
        [  35],
        [   1],
        [  16],
        [   8],
        [  49],
        [   2],
        [  28],
        [  32],
        [   6],
        [  28],
        [ 114],
        [   2],
        [   8],
        [   4],
        [  49],
        [   1]], device='cuda:0')
[2024-07-24 10:16:59,898][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[1258],
        [  40],
        [   1],
        [   9],
        [  32],
        [   1],
        [  16],
        [   8],
        [  54],
        [   2],
        [  26],
        [  30],
        [   5],
        [  27],
        [ 108],
        [   2],
        [   6],
        [   5],
        [  52],
        [   1]], device='cuda:0')
[2024-07-24 10:16:59,902][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7219],
        [5862],
        [3998],
        [7515],
        [6333],
        [6743],
        [6962],
        [7887],
        [8267],
        [8578],
        [7655],
        [8102],
        [8367],
        [7742],
        [8256],
        [7659],
        [7803],
        [7305],
        [7316],
        [7016]], device='cuda:0')
[2024-07-24 10:16:59,904][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 605],
        [1666],
        [1796],
        [1313],
        [1056],
        [ 779],
        [ 887],
        [ 649],
        [ 542],
        [ 483],
        [ 486],
        [ 329],
        [ 310],
        [ 308],
        [ 306],
        [ 293],
        [ 267],
        [ 269],
        [ 255],
        [ 253]], device='cuda:0')
[2024-07-24 10:16:59,906][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[41551],
        [40902],
        [49651],
        [49548],
        [48768],
        [47975],
        [47421],
        [45001],
        [43068],
        [44511],
        [44010],
        [41645],
        [41970],
        [42041],
        [40449],
        [41663],
        [39466],
        [39843],
        [37206],
        [39905]], device='cuda:0')
[2024-07-24 10:16:59,907][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[25639],
        [ 8501],
        [ 6745],
        [ 7726],
        [ 9715],
        [11455],
        [11211],
        [11031],
        [10345],
        [10467],
        [ 9859],
        [ 9371],
        [ 9756],
        [ 9870],
        [ 9495],
        [ 9628],
        [ 9154],
        [ 9105],
        [ 8405],
        [ 8955]], device='cuda:0')
[2024-07-24 10:16:59,909][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[10783],
        [34471],
        [16415],
        [17723],
        [24578],
        [26576],
        [25961],
        [26263],
        [27244],
        [24985],
        [27780],
        [28640],
        [29213],
        [29665],
        [31098],
        [29571],
        [29939],
        [30838],
        [31115],
        [30348]], device='cuda:0')
[2024-07-24 10:16:59,913][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[35501],
        [46380],
        [47578],
        [47328],
        [47586],
        [47576],
        [47603],
        [47497],
        [47357],
        [47423],
        [47506],
        [47275],
        [47329],
        [47438],
        [47356],
        [47378],
        [47398],
        [47614],
        [47501],
        [47556]], device='cuda:0')
[2024-07-24 10:16:59,916][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 4620],
        [ 9050],
        [10268],
        [11681],
        [14278],
        [15862],
        [14922],
        [13783],
        [15169],
        [12682],
        [13033],
        [12943],
        [10264],
        [10857],
        [11583],
        [10606],
        [10302],
        [ 9530],
        [ 9571],
        [ 8984]], device='cuda:0')
[2024-07-24 10:16:59,919][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[44897],
        [27485],
        [23124],
        [26849],
        [25750],
        [26535],
        [28693],
        [32880],
        [33330],
        [34529],
        [35838],
        [36704],
        [37508],
        [37152],
        [37953],
        [38044],
        [39221],
        [38705],
        [39245],
        [39415]], device='cuda:0')
[2024-07-24 10:16:59,920][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[4783],
        [3782],
        [3732],
        [3966],
        [4094],
        [4458],
        [4622],
        [5209],
        [4633],
        [4877],
        [5407],
        [5832],
        [5860],
        [5114],
        [5422],
        [5038],
        [5375],
        [5411],
        [4892],
        [4761]], device='cuda:0')
[2024-07-24 10:16:59,922][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24359],
        [15790],
        [12306],
        [13770],
        [11467],
        [12012],
        [11846],
        [12231],
        [12545],
        [13166],
        [13127],
        [13170],
        [13716],
        [12528],
        [12683],
        [13328],
        [13129],
        [13971],
        [14368],
        [14405]], device='cuda:0')
[2024-07-24 10:16:59,924][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[45980],
        [48597],
        [41679],
        [42020],
        [42186],
        [43704],
        [43326],
        [45905],
        [46808],
        [47204],
        [47304],
        [47061],
        [47690],
        [47835],
        [47970],
        [48118],
        [48201],
        [48263],
        [48179],
        [48319]], device='cuda:0')
[2024-07-24 10:16:59,927][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7872],
        [ 9750],
        [18046],
        [17856],
        [19043],
        [21912],
        [23459],
        [23061],
        [22212],
        [21301],
        [21736],
        [20789],
        [20074],
        [20640],
        [20494],
        [19582],
        [19115],
        [20284],
        [19466],
        [19355]], device='cuda:0')
[2024-07-24 10:16:59,930][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4699],
        [ 5147],
        [ 4221],
        [ 6532],
        [ 3682],
        [ 6336],
        [ 4329],
        [ 3164],
        [ 4176],
        [ 4201],
        [ 6555],
        [ 3761],
        [ 3039],
        [ 4011],
        [ 6281],
        [ 4350],
        [10066],
        [ 7557],
        [ 6094],
        [ 4796]], device='cuda:0')
[2024-07-24 10:16:59,933][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 8662],
        [13503],
        [21836],
        [20625],
        [21677],
        [21623],
        [22565],
        [25998],
        [25366],
        [23761],
        [22324],
        [21678],
        [21438],
        [21224],
        [21124],
        [20761],
        [20767],
        [19857],
        [19985],
        [19632]], device='cuda:0')
[2024-07-24 10:16:59,935][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8328],
        [11476],
        [10203],
        [11390],
        [10361],
        [10773],
        [12025],
        [15281],
        [16024],
        [17225],
        [17402],
        [19130],
        [19678],
        [19298],
        [19443],
        [20250],
        [21147],
        [20808],
        [20932],
        [21213]], device='cuda:0')
[2024-07-24 10:16:59,936][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[31400],
        [40446],
        [37802],
        [37996],
        [38634],
        [39330],
        [39599],
        [40609],
        [41074],
        [41073],
        [40880],
        [40969],
        [40923],
        [40279],
        [40696],
        [40777],
        [40906],
        [41074],
        [41234],
        [41192]], device='cuda:0')
[2024-07-24 10:16:59,938][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 6528],
        [13494],
        [16848],
        [17881],
        [18137],
        [19079],
        [18475],
        [18155],
        [18591],
        [18319],
        [18173],
        [17438],
        [17865],
        [17309],
        [17661],
        [17711],
        [16890],
        [17208],
        [16657],
        [17398]], device='cuda:0')
[2024-07-24 10:16:59,941][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13195],
        [ 3988],
        [17373],
        [15176],
        [13762],
        [13893],
        [14404],
        [14619],
        [14553],
        [14742],
        [14858],
        [14537],
        [14223],
        [12310],
        [12426],
        [12572],
        [12832],
        [13751],
        [14078],
        [14115]], device='cuda:0')
[2024-07-24 10:16:59,945][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 973],
        [1926],
        [3343],
        [3523],
        [3303],
        [3573],
        [3829],
        [3593],
        [3728],
        [3659],
        [3493],
        [3431],
        [3325],
        [3071],
        [3070],
        [3159],
        [2893],
        [3079],
        [2911],
        [3015]], device='cuda:0')
[2024-07-24 10:16:59,948][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 5618],
        [27001],
        [21545],
        [28125],
        [27534],
        [28780],
        [24996],
        [24001],
        [24481],
        [25003],
        [25281],
        [24173],
        [25160],
        [24879],
        [25668],
        [26218],
        [25273],
        [25403],
        [24909],
        [26127]], device='cuda:0')
[2024-07-24 10:16:59,949][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12203],
        [ 1072],
        [ 1752],
        [ 1881],
        [ 2316],
        [ 2428],
        [ 2389],
        [ 2381],
        [ 2324],
        [ 2122],
        [ 2476],
        [ 2584],
        [ 2253],
        [ 2474],
        [ 2481],
        [ 2448],
        [ 2688],
        [ 2586],
        [ 2613],
        [ 2561]], device='cuda:0')
[2024-07-24 10:16:59,951][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[12564],
        [ 8033],
        [ 8019],
        [ 7991],
        [ 7990],
        [ 7998],
        [ 7989],
        [ 8030],
        [ 8025],
        [ 8065],
        [ 8065],
        [ 8123],
        [ 8087],
        [ 8104],
        [ 8097],
        [ 8104],
        [ 8125],
        [ 8085],
        [ 8138],
        [ 8097]], device='cuda:0')
[2024-07-24 10:16:59,952][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 9513],
        [ 8173],
        [13201],
        [13383],
        [14328],
        [14176],
        [15201],
        [14950],
        [15405],
        [15281],
        [14629],
        [16176],
        [16085],
        [18821],
        [18989],
        [18216],
        [19271],
        [18766],
        [20309],
        [19866]], device='cuda:0')
[2024-07-24 10:16:59,956][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 8184],
        [10345],
        [ 7061],
        [ 5826],
        [ 4830],
        [ 5462],
        [ 4946],
        [ 5319],
        [ 5254],
        [ 5202],
        [ 5502],
        [ 5134],
        [ 5426],
        [ 5152],
        [ 5061],
        [ 5037],
        [ 4924],
        [ 5270],
        [ 5109],
        [ 5073]], device='cuda:0')
[2024-07-24 10:16:59,959][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[7347],
        [2820],
        [2188],
        [2177],
        [2189],
        [2108],
        [1927],
        [1901],
        [1961],
        [1988],
        [2132],
        [2164],
        [2166],
        [2159],
        [2182],
        [2264],
        [2442],
        [2434],
        [2478],
        [2460]], device='cuda:0')
[2024-07-24 10:16:59,962][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[23395],
        [19960],
        [16636],
        [15731],
        [15971],
        [15025],
        [15482],
        [14970],
        [14198],
        [13923],
        [13970],
        [13540],
        [13261],
        [13310],
        [13062],
        [12743],
        [12575],
        [12579],
        [12236],
        [12034]], device='cuda:0')
[2024-07-24 10:16:59,963][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[33115],
        [29925],
        [32261],
        [30502],
        [35382],
        [30899],
        [33943],
        [35308],
        [35506],
        [33853],
        [30440],
        [32331],
        [30750],
        [33984],
        [30402],
        [33378],
        [26058],
        [28989],
        [29515],
        [32415]], device='cuda:0')
[2024-07-24 10:16:59,965][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007],
        [4007]], device='cuda:0')
