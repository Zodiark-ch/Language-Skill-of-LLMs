[2024-07-24 10:17:00,364][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Brittany and Sarah had a long argument, and afterwards Sarah said to
[2024-07-24 10:17:00,364][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Brittany
[2024-07-24 10:17:00,364][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:17:00,364][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,365][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:17:00,366][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,367][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:17:00,368][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit23']
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,369][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,370][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,371][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:17:00,372][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:17:00,373][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,374][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit15']
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:17:00,375][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,376][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,377][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit8']
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,378][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6']
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11']
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,379][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:17:00,380][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,381][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:17:00,382][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,383][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,384][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,385][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit24']
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit26']
[2024-07-24 10:17:00,386][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,387][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit26']
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,388][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit20']
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,389][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:17:00,390][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:17:00,391][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:17:00,392][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit27']
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,393][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,394][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:17:00,395][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,396][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit26']
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,397][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,398][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:17:00,399][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,400][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:17:00,401][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,402][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit22']
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit22', 'circuit25']
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:17:00,403][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,404][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:17:00,405][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit25']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit2', 'circuit5', 'circuit7', 'circuit8', 'circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit14', 'circuit19', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,406][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:17:00,407][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,408][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:17:00,409][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,410][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:17:00,411][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit27']
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,412][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:17:00,413][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit26']
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,414][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,415][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,416][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,417][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,418][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,419][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit21']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,420][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,421][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:17:00,422][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,423][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit28']
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:17:00,424][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:17:00,425][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit21', 'circuit25']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,426][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:17:00,427][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit25']
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,428][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,429][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,430][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,431][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6']
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12', 'circuit14']
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,432][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:17:00,433][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,434][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19']
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:17:00,435][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,436][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit25']
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,437][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,438][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:17:00,439][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,440][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,441][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,442][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20']
[2024-07-24 10:17:00,443][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21']
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,444][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,445][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,446][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14']
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,447][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit18', 'circuit20']
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:17:00,448][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit15', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19']
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:17:00,449][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit19', 'circuit20']
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:17:00,450][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit27']
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5']
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:17:00,451][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:17:00,452][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:17:00,453][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit13']
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,454][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:17:00,455][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit10', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,456][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,457][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit9', 'circuit10', 'circuit28']
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit11', 'circuit13']
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,458][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit15']
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18']
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,459][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit25']
[2024-07-24 10:17:00,460][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:17:00,461][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,462][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,463][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,464][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit23']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:17:00,465][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit11', 'circuit13']
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit26']
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3']
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,466][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,467][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,468][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,469][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,470][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,471][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,472][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:17:00,473][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,474][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,475][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,476][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit12']
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,477][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,478][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,479][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,480][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,481][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit25']
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,482][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,483][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,484][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,485][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25', 'circuit27']
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:17:00,486][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit27']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit22']
[2024-07-24 10:17:00,487][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit3', 'circuit4', 'circuit7', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,488][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,489][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,490][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19']
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,491][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,492][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1']
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:17:00,493][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,494][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22']
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,495][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16']
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,496][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,497][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,498][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,499][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:17:00,500][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:17:00,501][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,502][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:17:00,503][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit22', 'circuit25']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit28']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-24 10:17:00,504][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit27']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit24']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,505][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:17:00,506][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit25']
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:17:00,507][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit20']
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,508][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,509][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,510][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit10', 'circuit27']
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,511][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit19', 'circuit20']
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,512][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,513][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19']
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15']
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,514][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit26']
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,515][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:17:00,516][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,517][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,518][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,519][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,520][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,521][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,522][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,523][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,524][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,525][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:17:00,526][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,527][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,528][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,529][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,530][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,531][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,532][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,533][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,534][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,535][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,536][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,537][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,538][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,539][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,540][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,541][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,542][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,543][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,544][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,545][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,546][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit24']
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,547][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,548][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,549][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:17:00,550][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,551][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19']
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,552][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,553][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit1', 'circuit10', 'circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:17:00,554][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,555][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,556][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,557][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:17:00,558][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,559][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,560][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,561][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,562][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,563][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,564][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,565][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,566][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,567][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,568][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,569][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,570][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,571][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,572][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,573][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,574][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,575][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,576][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:17:00,577][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,578][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,579][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,580][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,581][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,582][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,583][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,584][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,585][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,586][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,587][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,588][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,589][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:17:00,590][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,591][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,592][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:17:00,593][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,594][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,595][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,596][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,597][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,598][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,599][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,600][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,601][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,602][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,603][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,604][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,605][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:17:00,606][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,607][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,608][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,609][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,610][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,611][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,612][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,613][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,614][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,615][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,616][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,617][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit18']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit25']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit7', 'circuit23']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:17:00,618][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,619][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,620][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,621][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,622][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit22']
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,623][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,624][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,625][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,626][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,627][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,628][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit14', 'circuit18']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:17:00,629][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,630][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:17:00,631][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,632][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,633][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit10']
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit1', 'circuit2', 'circuit12', 'circuit24', 'circuit27']
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,634][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,635][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,636][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,637][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit18']
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit18', 'circuit21']
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit25']
[2024-07-24 10:17:00,638][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,639][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,640][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,641][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,642][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,643][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,644][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,645][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,646][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,647][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,648][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,649][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,650][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:17:00,651][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,652][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,653][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,654][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,655][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:17:00,656][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:17:00,657][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,658][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:17:00,659][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,660][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,661][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:00,662][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:17:01,971][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:01,972][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,973][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,974][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,975][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,975][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,976][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,977][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,978][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,979][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,980][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,981][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,981][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:01,982][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,984][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,985][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,986][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,988][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,990][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,992][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,994][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,996][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,997][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,998][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:01,999][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,000][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.5234, 0.3854, 0.0911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,000][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([1.6624e-05, 1.2859e-04, 9.9985e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,001][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5514, 0.3139, 0.1348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,002][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([3.0511e-02, 6.7522e-04, 9.6881e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,003][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([1.2213e-02, 7.7023e-04, 9.8702e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,004][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([1.3095e-02, 4.4606e-06, 9.8690e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,006][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.4239, 0.3498, 0.2263], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,008][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.5606, 0.3651, 0.0743], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,009][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.5531, 0.3567, 0.0902], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,011][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.6031, 0.3494, 0.0475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,013][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.3949, 0.2391, 0.3660], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,015][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2970, 0.4791, 0.2239], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,017][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5786, 0.0656, 0.3047, 0.0511], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,018][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3024e-03, 3.9245e-02, 5.3311e-04, 9.5792e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,020][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2337, 0.1750, 0.0528, 0.5385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,021][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1154, 0.3943, 0.0081, 0.4823], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,022][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3519, 0.1594, 0.1999, 0.2888], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,023][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1228, 0.1966, 0.0093, 0.6714], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,023][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6692, 0.0320, 0.2745, 0.0243], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,024][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2281, 0.1734, 0.3374, 0.2611], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,025][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0670, 0.4691, 0.0240, 0.4399], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,027][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4254, 0.2375, 0.1165, 0.2207], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,029][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4210, 0.3135, 0.0586, 0.2069], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,030][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4331, 0.1892, 0.1305, 0.2472], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,032][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2096, 0.2803, 0.1287, 0.2404, 0.1411], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,033][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([6.5079e-05, 1.2850e-04, 3.1871e-04, 9.3662e-05, 9.9939e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,035][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.4564, 0.2241, 0.0391, 0.1096, 0.1708], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,036][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([1.6549e-02, 1.4408e-04, 7.9807e-03, 4.0794e-04, 9.7492e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,038][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0129, 0.0021, 0.0255, 0.0015, 0.9579], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,040][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([5.2152e-03, 2.0626e-06, 9.6589e-06, 2.8942e-07, 9.9477e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,042][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.2428, 0.1689, 0.2715, 0.0917, 0.2251], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,043][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.2209, 0.1765, 0.0434, 0.3890, 0.1702], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,044][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.2824, 0.2500, 0.1000, 0.1839, 0.1838], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,045][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.3973, 0.2192, 0.1734, 0.1898, 0.0202], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,046][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.2437, 0.2270, 0.0850, 0.1400, 0.3042], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,047][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.2818, 0.1813, 0.2148, 0.2138, 0.1082], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,047][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3541, 0.0311, 0.1545, 0.0310, 0.1566, 0.2727], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,048][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2184e-04, 1.6737e-03, 4.2321e-04, 2.8589e-03, 1.0257e-03, 9.9370e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,050][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4809, 0.1226, 0.0497, 0.1451, 0.0580, 0.1437], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,051][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9262e-03, 5.4142e-03, 2.4555e-04, 1.1457e-02, 4.8133e-03, 9.7314e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,053][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2253, 0.0641, 0.0438, 0.1160, 0.0726, 0.4783], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,054][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9811e-02, 1.8578e-03, 2.4579e-04, 1.2916e-03, 4.0013e-04, 9.5639e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,055][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3398, 0.0254, 0.1934, 0.0238, 0.3835, 0.0341], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,057][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1174, 0.0914, 0.0631, 0.2122, 0.2520, 0.2639], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,059][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0916, 0.2573, 0.0310, 0.3380, 0.0730, 0.2091], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,061][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3002, 0.1810, 0.1181, 0.1865, 0.0882, 0.1260], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,063][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2559, 0.1973, 0.0442, 0.1445, 0.0443, 0.3138], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,065][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4332, 0.1447, 0.1097, 0.1804, 0.0408, 0.0912], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,066][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4400, 0.0507, 0.2757, 0.0383, 0.0983, 0.0631, 0.0340],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,067][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5607e-04, 4.3023e-03, 6.6887e-04, 4.3002e-03, 7.3645e-04, 4.6855e-04,
        9.8867e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,068][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3051, 0.1892, 0.0651, 0.2232, 0.0439, 0.1263, 0.0472],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,069][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0282, 0.0173, 0.0032, 0.0318, 0.0579, 0.1721, 0.6895],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,070][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1371, 0.0302, 0.0730, 0.0425, 0.0813, 0.4286, 0.2074],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,070][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0558, 0.1294, 0.0022, 0.0968, 0.0063, 0.0447, 0.6649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,071][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3545, 0.0118, 0.3130, 0.0100, 0.2470, 0.0521, 0.0115],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,073][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0939, 0.0565, 0.0684, 0.1262, 0.1519, 0.2117, 0.2914],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,075][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0240, 0.1306, 0.0090, 0.1940, 0.0106, 0.1418, 0.4901],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,077][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2639, 0.1689, 0.0802, 0.1715, 0.0740, 0.1063, 0.1352],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,078][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2261, 0.1928, 0.0466, 0.1634, 0.0614, 0.0837, 0.2260],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,080][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3331, 0.1335, 0.1399, 0.1434, 0.0536, 0.0861, 0.1104],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,082][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2421, 0.0579, 0.3056, 0.0537, 0.0944, 0.0997, 0.0760, 0.0705],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,083][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8402e-04, 9.8721e-04, 1.9350e-03, 1.4083e-03, 1.2280e-03, 3.2457e-03,
        9.3657e-04, 9.8998e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,085][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3134, 0.1615, 0.0565, 0.1633, 0.0692, 0.1140, 0.0816, 0.0406],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,087][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5136e-03, 4.5964e-04, 6.0004e-05, 8.0287e-04, 1.3127e-03, 9.0988e-03,
        7.2485e-03, 9.7450e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,089][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0984, 0.0224, 0.0340, 0.0294, 0.0593, 0.1469, 0.0778, 0.5319],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,090][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4041e-03, 1.8790e-04, 8.1718e-05, 1.0305e-04, 8.8147e-05, 1.9184e-04,
        8.2370e-05, 9.9386e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,091][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2845, 0.0306, 0.3322, 0.0213, 0.1799, 0.0471, 0.0220, 0.0824],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,092][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1016, 0.0442, 0.0443, 0.0926, 0.0770, 0.1862, 0.3438, 0.1104],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,092][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1147, 0.1149, 0.0411, 0.1460, 0.1124, 0.1413, 0.2871, 0.0425],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,093][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2426, 0.1587, 0.0866, 0.1535, 0.0642, 0.0937, 0.1346, 0.0660],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,094][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2228, 0.1578, 0.0467, 0.1105, 0.0426, 0.0766, 0.0866, 0.2564],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,095][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3828, 0.1030, 0.0922, 0.1282, 0.0540, 0.0635, 0.0649, 0.1113],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,097][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3351, 0.0802, 0.2105, 0.0632, 0.0655, 0.0684, 0.0538, 0.0683, 0.0551],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,098][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8546e-03, 3.0731e-04, 2.1425e-03, 2.0888e-04, 1.1376e-03, 3.4838e-04,
        1.9497e-04, 3.4297e-05, 9.9377e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,100][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.3218, 0.1094, 0.0491, 0.0802, 0.0491, 0.1054, 0.1234, 0.1020, 0.0597],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,101][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3868e-03, 4.0904e-05, 5.5543e-05, 9.1314e-05, 8.2198e-04, 2.4705e-04,
        6.2988e-04, 4.3076e-03, 9.9042e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,103][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1310, 0.0059, 0.0033, 0.0051, 0.0298, 0.0159, 0.0134, 0.1756, 0.6200],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,104][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2026e-02, 1.5132e-05, 8.4045e-06, 4.1244e-06, 1.8542e-04, 2.0251e-06,
        1.5987e-06, 6.3669e-07, 9.8776e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,106][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1914, 0.0497, 0.2163, 0.0435, 0.1610, 0.0328, 0.0352, 0.0790, 0.1911],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,108][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0897, 0.0514, 0.0106, 0.0957, 0.0535, 0.1320, 0.2106, 0.2534, 0.1031],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,110][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2469, 0.0954, 0.0747, 0.1117, 0.0474, 0.2329, 0.1192, 0.0643, 0.0075],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,112][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2283, 0.1329, 0.0984, 0.1245, 0.0752, 0.1082, 0.1114, 0.0803, 0.0408],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,113][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2137, 0.1331, 0.0483, 0.1125, 0.0502, 0.0768, 0.0742, 0.0389, 0.2524],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,114][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3290, 0.1459, 0.0791, 0.1056, 0.0532, 0.0418, 0.0403, 0.0891, 0.1161],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,115][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3938, 0.0135, 0.2314, 0.0157, 0.0711, 0.0697, 0.0302, 0.0560, 0.1072,
        0.0114], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,116][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8442e-03, 4.4350e-01, 1.5915e-04, 1.1169e-02, 1.8482e-04, 3.9666e-04,
        1.7959e-04, 5.1698e-05, 7.8238e-06, 5.4250e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,117][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1971, 0.3102, 0.0322, 0.0759, 0.0158, 0.0361, 0.0074, 0.0101, 0.0099,
        0.3051], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,118][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([3.3158e-02, 7.7015e-03, 6.9239e-04, 7.7464e-03, 5.2023e-03, 6.0590e-02,
        4.9740e-02, 5.5118e-02, 8.6413e-02, 6.9364e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,120][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2727, 0.0264, 0.0198, 0.0228, 0.0611, 0.1317, 0.0322, 0.1126, 0.0472,
        0.2735], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,121][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0968, 0.3421, 0.0104, 0.1234, 0.0139, 0.0687, 0.1016, 0.0299, 0.0101,
        0.2032], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,123][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3265, 0.0096, 0.1909, 0.0093, 0.1838, 0.0306, 0.0119, 0.0788, 0.1522,
        0.0064], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,124][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0372, 0.0140, 0.0237, 0.0381, 0.0632, 0.0697, 0.1111, 0.1457, 0.1392,
        0.3582], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,127][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0191, 0.1646, 0.0084, 0.1849, 0.0051, 0.0641, 0.1658, 0.0291, 0.0075,
        0.3512], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,128][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2143, 0.1225, 0.0690, 0.1273, 0.0568, 0.0859, 0.0936, 0.0699, 0.0565,
        0.1043], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,130][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1721, 0.1584, 0.0649, 0.1455, 0.0638, 0.0942, 0.0912, 0.0585, 0.0417,
        0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,133][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2480, 0.0959, 0.1022, 0.1088, 0.0404, 0.0692, 0.0659, 0.0805, 0.0749,
        0.1140], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,134][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3165, 0.0258, 0.2027, 0.0222, 0.0833, 0.0622, 0.0375, 0.0827, 0.1149,
        0.0253, 0.0270], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,135][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0615e-03, 1.2476e-02, 6.6029e-05, 5.1186e-01, 1.0487e-04, 6.9044e-04,
        2.3420e-04, 1.8327e-04, 8.4970e-06, 7.4679e-03, 4.6584e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,136][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0822, 0.0615, 0.0281, 0.3079, 0.0222, 0.0428, 0.0172, 0.0147, 0.0230,
        0.0546, 0.3457], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,137][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0819e-02, 6.0635e-03, 5.4860e-05, 3.9874e-03, 8.7088e-04, 7.8452e-03,
        1.3921e-02, 1.5635e-02, 7.4078e-03, 4.9293e-01, 4.4047e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,138][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0356, 0.0130, 0.0066, 0.0247, 0.0147, 0.1626, 0.0660, 0.1203, 0.1784,
        0.1221, 0.2560], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,139][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0325, 0.0871, 0.0059, 0.3871, 0.0025, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2501], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,140][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2644, 0.0107, 0.1922, 0.0102, 0.1849, 0.0335, 0.0123, 0.0935, 0.1789,
        0.0081, 0.0113], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,142][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0331, 0.0120, 0.0203, 0.0200, 0.0324, 0.0423, 0.0636, 0.0795, 0.0979,
        0.2449, 0.3541], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,144][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.0999, 0.0052, 0.1173, 0.0070, 0.0608, 0.1995, 0.0255, 0.0108,
        0.2620, 0.2005], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,145][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1752, 0.1093, 0.0628, 0.1103, 0.0529, 0.0764, 0.0877, 0.0589, 0.0576,
        0.0966, 0.1124], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,147][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1438, 0.1303, 0.0506, 0.1385, 0.0487, 0.0973, 0.0983, 0.0522, 0.0351,
        0.0945, 0.1106], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,149][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2206, 0.0899, 0.0791, 0.1036, 0.0341, 0.0538, 0.0477, 0.0618, 0.0789,
        0.1137, 0.1168], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,151][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2322, 0.0423, 0.0752, 0.0468, 0.1398, 0.1233, 0.0481, 0.0337, 0.1482,
        0.0367, 0.0559, 0.0179], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,152][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7291e-03, 4.1472e-04, 3.6607e-03, 1.5492e-04, 5.3264e-03, 1.7258e-04,
        8.9580e-05, 1.4245e-04, 6.0189e-04, 9.1728e-05, 7.0288e-05, 9.8755e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,154][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2250, 0.0736, 0.1791, 0.0698, 0.0514, 0.1420, 0.0583, 0.0514, 0.0297,
        0.0467, 0.0562, 0.0169], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,156][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2691e-02, 5.1798e-05, 2.3421e-05, 7.2009e-05, 4.8890e-04, 1.1419e-03,
        2.1222e-04, 3.4362e-03, 1.4249e-03, 2.2495e-03, 4.8161e-03, 9.7339e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,158][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0117, 0.0070, 0.0053, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0126, 0.0435, 0.8084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,159][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2430e-02, 4.3730e-06, 2.0822e-04, 1.6929e-06, 2.7300e-04, 4.4295e-06,
        4.7539e-07, 4.6472e-06, 5.0036e-06, 9.8410e-08, 2.7236e-07, 9.0707e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,161][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1424, 0.0596, 0.1521, 0.0443, 0.1208, 0.0371, 0.0632, 0.0555, 0.1279,
        0.0526, 0.0488, 0.0958], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,163][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0522, 0.0187, 0.0055, 0.0289, 0.0316, 0.0332, 0.0705, 0.0484, 0.0273,
        0.1901, 0.3870, 0.1068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,164][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0975, 0.1102, 0.0168, 0.1395, 0.0283, 0.0394, 0.1218, 0.0365, 0.0998,
        0.1299, 0.1674, 0.0129], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,165][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1729, 0.0977, 0.0711, 0.0898, 0.0749, 0.0744, 0.0655, 0.0561, 0.0849,
        0.0829, 0.0901, 0.0397], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,166][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1870, 0.0909, 0.0557, 0.0870, 0.0569, 0.0814, 0.0540, 0.0505, 0.0378,
        0.0648, 0.0673, 0.1667], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,167][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1849, 0.1466, 0.0675, 0.0972, 0.0231, 0.0334, 0.0427, 0.0431, 0.0393,
        0.1675, 0.1043, 0.0503], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,167][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1206, 0.1270, 0.0779, 0.1166, 0.0766, 0.0143, 0.0418, 0.0227, 0.0631,
        0.1086, 0.1286, 0.0183, 0.0837], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,169][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([3.0855e-05, 3.2389e-05, 5.6776e-05, 2.7793e-05, 5.4116e-01, 6.4177e-05,
        1.4582e-05, 1.3141e-05, 1.0620e-05, 5.0014e-06, 1.0901e-05, 1.6948e-04,
        4.5840e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,170][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.2267, 0.0966, 0.0234, 0.0602, 0.1052, 0.0661, 0.0714, 0.0283, 0.0622,
        0.0551, 0.0483, 0.0592, 0.0974], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,171][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([1.4389e-03, 1.3402e-06, 7.2384e-05, 1.6573e-06, 5.6961e-03, 1.3968e-05,
        1.8501e-05, 1.1598e-04, 3.7106e-04, 6.2271e-05, 1.1469e-04, 1.8686e-03,
        9.9022e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,173][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([2.0745e-03, 2.0969e-04, 1.6353e-03, 1.2125e-04, 7.2014e-02, 2.8464e-04,
        2.9380e-04, 2.4108e-03, 3.3426e-04, 6.6263e-04, 7.9743e-04, 9.0717e-04,
        9.1825e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,174][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([1.2610e-03, 4.0852e-07, 3.5434e-06, 5.8970e-08, 5.8526e-01, 2.1498e-07,
        1.9855e-08, 2.8202e-07, 1.4938e-06, 9.0853e-09, 9.6726e-09, 1.7174e-06,
        4.1348e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,176][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.1222, 0.0761, 0.1933, 0.0470, 0.1694, 0.0149, 0.0463, 0.0199, 0.0292,
        0.0463, 0.0394, 0.0247, 0.1713], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,178][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0500, 0.0147, 0.0033, 0.0267, 0.0133, 0.0318, 0.0574, 0.0439, 0.0228,
        0.1517, 0.3142, 0.0861, 0.1841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,180][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.1307, 0.1061, 0.0505, 0.0906, 0.1005, 0.0261, 0.0855, 0.0389, 0.0529,
        0.0922, 0.0875, 0.0286, 0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,182][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1920, 0.1084, 0.1037, 0.0994, 0.0115, 0.0589, 0.0776, 0.0472, 0.0403,
        0.0891, 0.0975, 0.0632, 0.0111], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,184][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0770, 0.0758, 0.0540, 0.0674, 0.2507, 0.0357, 0.0531, 0.0251, 0.0200,
        0.0515, 0.0505, 0.0239, 0.2152], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,186][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.1111, 0.0696, 0.1003, 0.0708, 0.0458, 0.0627, 0.0592, 0.0785, 0.0728,
        0.0709, 0.0868, 0.1132, 0.0585], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,187][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3337, 0.0289, 0.0981, 0.0167, 0.0579, 0.0608, 0.0178, 0.0441, 0.0425,
        0.0284, 0.0177, 0.0967, 0.0823, 0.0743], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,188][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4446e-03, 3.5510e-03, 2.4833e-04, 1.2008e-03, 1.1132e-03, 8.4896e-03,
        1.4045e-03, 4.5777e-05, 1.5918e-03, 1.5506e-03, 7.2214e-04, 1.1237e-04,
        7.8743e-04, 9.7774e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,189][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2327, 0.0520, 0.0242, 0.0449, 0.0133, 0.1070, 0.0353, 0.0259, 0.0509,
        0.0430, 0.0419, 0.0421, 0.0127, 0.2742], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,189][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.0010e-03, 7.4010e-05, 1.0830e-05, 5.5094e-05, 3.1030e-05, 3.1015e-04,
        4.3089e-04, 4.8981e-04, 1.2627e-03, 2.5569e-03, 3.5743e-03, 1.3264e-03,
        3.2086e-03, 9.8467e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,190][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0849, 0.0130, 0.0025, 0.0185, 0.0059, 0.0264, 0.0215, 0.0249, 0.0423,
        0.0557, 0.1184, 0.0239, 0.0472, 0.5151], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,191][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2064e-02, 2.4319e-03, 1.6743e-04, 8.8968e-04, 9.0761e-04, 8.6889e-03,
        2.0741e-04, 2.9448e-05, 6.7182e-04, 2.4859e-04, 2.8093e-04, 6.1953e-06,
        3.5560e-04, 9.7305e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,193][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.2001, 0.0098, 0.1772, 0.0099, 0.1213, 0.0131, 0.0080, 0.0358, 0.0944,
        0.0074, 0.0097, 0.1371, 0.1569, 0.0194], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,195][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0374, 0.0071, 0.0040, 0.0119, 0.0061, 0.0161, 0.0340, 0.0147, 0.0233,
        0.1236, 0.1932, 0.1991, 0.1338, 0.1955], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,197][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0521, 0.1078, 0.0158, 0.1058, 0.0154, 0.1030, 0.1394, 0.0317, 0.0281,
        0.1784, 0.1396, 0.0253, 0.0197, 0.0378], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,199][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1460, 0.0785, 0.0605, 0.0806, 0.0500, 0.0645, 0.0614, 0.0456, 0.0536,
        0.0730, 0.0835, 0.0542, 0.0552, 0.0934], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,201][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0998, 0.0719, 0.0305, 0.0758, 0.0521, 0.0781, 0.0586, 0.0245, 0.0469,
        0.0608, 0.0654, 0.0280, 0.0450, 0.2625], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,203][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2542, 0.0605, 0.0698, 0.0808, 0.0318, 0.0386, 0.0324, 0.0584, 0.0693,
        0.0642, 0.0821, 0.0851, 0.0321, 0.0407], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,205][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2652, 0.0257, 0.1209, 0.0215, 0.0411, 0.0692, 0.0231, 0.0374, 0.0738,
        0.0257, 0.0263, 0.0855, 0.0576, 0.1101, 0.0170], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,206][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1215e-03, 1.1780e-02, 5.1474e-05, 3.4318e-02, 1.3844e-04, 3.0536e-04,
        1.4493e-03, 1.7848e-04, 5.7935e-05, 8.2849e-03, 3.0208e-02, 2.4506e-04,
        9.1128e-05, 1.4516e-04, 9.0863e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,208][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1629, 0.0716, 0.0245, 0.0983, 0.0190, 0.0598, 0.0257, 0.0384, 0.0313,
        0.0611, 0.0968, 0.0398, 0.0187, 0.0761, 0.1760], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,209][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9402e-03, 2.6542e-04, 1.9826e-05, 1.8189e-04, 4.9108e-05, 7.2802e-04,
        1.2041e-03, 2.4214e-04, 1.1463e-03, 7.1891e-03, 1.1921e-02, 1.6549e-02,
        5.2584e-03, 2.9293e-01, 6.5937e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,210][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0360, 0.0023, 0.0028, 0.0038, 0.0010, 0.0340, 0.0104, 0.0264, 0.0575,
        0.0124, 0.0318, 0.0736, 0.0109, 0.4180, 0.2791], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,211][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0433, 0.0612, 0.0023, 0.0784, 0.0016, 0.0312, 0.2265, 0.0344, 0.0048,
        0.0212, 0.0413, 0.0007, 0.0007, 0.0326, 0.4198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,212][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1292, 0.0062, 0.0775, 0.0054, 0.0610, 0.0181, 0.0051, 0.0335, 0.0577,
        0.0046, 0.0067, 0.1176, 0.0998, 0.0347, 0.3429], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,213][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0206, 0.0039, 0.0037, 0.0064, 0.0093, 0.0083, 0.0111, 0.0171, 0.0250,
        0.0458, 0.0741, 0.0869, 0.1930, 0.2403, 0.2544], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,214][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0595, 0.0042, 0.1036, 0.0042, 0.0466, 0.1311, 0.0198, 0.0089,
        0.1508, 0.1815, 0.0048, 0.0063, 0.0338, 0.2369], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,216][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1203, 0.0745, 0.0463, 0.0820, 0.0362, 0.0547, 0.0698, 0.0479, 0.0431,
        0.0704, 0.0860, 0.0462, 0.0400, 0.0836, 0.0992], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,218][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1013, 0.0832, 0.0350, 0.0997, 0.0357, 0.0739, 0.0849, 0.0499, 0.0331,
        0.0756, 0.0920, 0.0273, 0.0320, 0.0637, 0.1126], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,220][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1815, 0.0717, 0.0755, 0.0736, 0.0305, 0.0511, 0.0464, 0.0545, 0.0547,
        0.0738, 0.0700, 0.0754, 0.0298, 0.0375, 0.0740], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,236][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:02,237][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,238][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,239][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,239][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,240][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,241][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,241][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,242][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,243][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,244][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,246][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,247][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,248][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,249][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,250][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,250][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,251][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,252][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,253][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,255][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,257][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,258][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,260][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,262][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,263][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.5234, 0.3854, 0.0911], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,265][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([1.6624e-05, 1.2859e-04, 9.9985e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,267][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.5514, 0.3139, 0.1348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,268][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([3.0511e-02, 6.7522e-04, 9.6881e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,269][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([1.2213e-02, 7.7023e-04, 9.8702e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,270][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([1.3095e-02, 4.4606e-06, 9.8690e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,271][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.4239, 0.3498, 0.2263], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,272][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.5606, 0.3651, 0.0743], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,273][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.5531, 0.3567, 0.0902], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,273][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.6031, 0.3494, 0.0475], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,274][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.3949, 0.2391, 0.3660], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,275][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.2970, 0.4791, 0.2239], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,277][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5786, 0.0656, 0.3047, 0.0511], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,278][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3024e-03, 3.9245e-02, 5.3311e-04, 9.5792e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,279][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2337, 0.1750, 0.0528, 0.5385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,281][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1154, 0.3943, 0.0081, 0.4823], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,283][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3519, 0.1594, 0.1999, 0.2888], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,285][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1228, 0.1966, 0.0093, 0.6714], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,286][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6692, 0.0320, 0.2745, 0.0243], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,288][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2281, 0.1734, 0.3374, 0.2611], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,290][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0670, 0.4691, 0.0240, 0.4399], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,292][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4254, 0.2375, 0.1165, 0.2207], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,294][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4210, 0.3135, 0.0586, 0.2069], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,294][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4331, 0.1892, 0.1305, 0.2472], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,295][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.2096, 0.2803, 0.1287, 0.2404, 0.1411], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,296][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([6.5079e-05, 1.2850e-04, 3.1871e-04, 9.3662e-05, 9.9939e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,296][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.4564, 0.2241, 0.0391, 0.1096, 0.1708], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,297][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([1.6549e-02, 1.4408e-04, 7.9807e-03, 4.0794e-04, 9.7492e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,298][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0129, 0.0021, 0.0255, 0.0015, 0.9579], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,299][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([5.2152e-03, 2.0626e-06, 9.6589e-06, 2.8942e-07, 9.9477e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,300][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.2428, 0.1689, 0.2715, 0.0917, 0.2251], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,302][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.2209, 0.1765, 0.0434, 0.3890, 0.1702], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,304][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.2824, 0.2500, 0.1000, 0.1839, 0.1838], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,305][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.3973, 0.2192, 0.1734, 0.1898, 0.0202], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,307][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.2437, 0.2270, 0.0850, 0.1400, 0.3042], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,309][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.2818, 0.1813, 0.2148, 0.2138, 0.1082], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,311][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3541, 0.0311, 0.1545, 0.0310, 0.1566, 0.2727], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,312][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2184e-04, 1.6737e-03, 4.2321e-04, 2.8589e-03, 1.0257e-03, 9.9370e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,314][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4809, 0.1226, 0.0497, 0.1451, 0.0580, 0.1437], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,316][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9262e-03, 5.4142e-03, 2.4555e-04, 1.1457e-02, 4.8133e-03, 9.7314e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,317][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2253, 0.0641, 0.0438, 0.1160, 0.0726, 0.4783], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,318][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9811e-02, 1.8578e-03, 2.4579e-04, 1.2916e-03, 4.0013e-04, 9.5639e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,318][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3398, 0.0254, 0.1934, 0.0238, 0.3835, 0.0341], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,319][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1174, 0.0914, 0.0631, 0.2122, 0.2520, 0.2639], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,320][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0916, 0.2573, 0.0310, 0.3380, 0.0730, 0.2091], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,321][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3002, 0.1810, 0.1181, 0.1865, 0.0882, 0.1260], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,323][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2559, 0.1973, 0.0442, 0.1445, 0.0443, 0.3138], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,325][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4332, 0.1447, 0.1097, 0.1804, 0.0408, 0.0912], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,326][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4400, 0.0507, 0.2757, 0.0383, 0.0983, 0.0631, 0.0340],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,327][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5607e-04, 4.3023e-03, 6.6887e-04, 4.3002e-03, 7.3645e-04, 4.6855e-04,
        9.8867e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,329][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3051, 0.1892, 0.0651, 0.2232, 0.0439, 0.1263, 0.0472],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,331][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0282, 0.0173, 0.0032, 0.0318, 0.0579, 0.1721, 0.6895],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,333][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1371, 0.0302, 0.0730, 0.0425, 0.0813, 0.4286, 0.2074],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,335][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0558, 0.1294, 0.0022, 0.0968, 0.0063, 0.0447, 0.6649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,337][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3545, 0.0118, 0.3130, 0.0100, 0.2470, 0.0521, 0.0115],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,339][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0939, 0.0565, 0.0684, 0.1262, 0.1519, 0.2117, 0.2914],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,340][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0240, 0.1306, 0.0090, 0.1940, 0.0106, 0.1418, 0.4901],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,341][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2639, 0.1689, 0.0802, 0.1715, 0.0740, 0.1063, 0.1352],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,342][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2261, 0.1928, 0.0466, 0.1634, 0.0614, 0.0837, 0.2260],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,343][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3331, 0.1335, 0.1399, 0.1434, 0.0536, 0.0861, 0.1104],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,343][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2421, 0.0579, 0.3056, 0.0537, 0.0944, 0.0997, 0.0760, 0.0705],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,344][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8402e-04, 9.8721e-04, 1.9350e-03, 1.4083e-03, 1.2280e-03, 3.2457e-03,
        9.3657e-04, 9.8998e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,346][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.3134, 0.1615, 0.0565, 0.1633, 0.0692, 0.1140, 0.0816, 0.0406],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,348][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5136e-03, 4.5964e-04, 6.0004e-05, 8.0287e-04, 1.3127e-03, 9.0988e-03,
        7.2485e-03, 9.7450e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,349][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0984, 0.0224, 0.0340, 0.0294, 0.0593, 0.1469, 0.0778, 0.5319],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,350][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4041e-03, 1.8790e-04, 8.1718e-05, 1.0305e-04, 8.8147e-05, 1.9184e-04,
        8.2370e-05, 9.9386e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,352][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2845, 0.0306, 0.3322, 0.0213, 0.1799, 0.0471, 0.0220, 0.0824],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,354][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1016, 0.0442, 0.0443, 0.0926, 0.0770, 0.1862, 0.3438, 0.1104],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,356][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1147, 0.1149, 0.0411, 0.1460, 0.1124, 0.1413, 0.2871, 0.0425],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,357][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2426, 0.1587, 0.0866, 0.1535, 0.0642, 0.0937, 0.1346, 0.0660],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,360][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2228, 0.1578, 0.0467, 0.1105, 0.0426, 0.0766, 0.0866, 0.2564],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,362][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3828, 0.1030, 0.0922, 0.1282, 0.0540, 0.0635, 0.0649, 0.1113],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,363][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3351, 0.0802, 0.2105, 0.0632, 0.0655, 0.0684, 0.0538, 0.0683, 0.0551],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,364][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8546e-03, 3.0731e-04, 2.1425e-03, 2.0888e-04, 1.1376e-03, 3.4838e-04,
        1.9497e-04, 3.4297e-05, 9.9377e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,365][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3218, 0.1094, 0.0491, 0.0802, 0.0491, 0.1054, 0.1234, 0.1020, 0.0597],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,366][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3868e-03, 4.0904e-05, 5.5543e-05, 9.1314e-05, 8.2198e-04, 2.4705e-04,
        6.2988e-04, 4.3076e-03, 9.9042e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,366][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1310, 0.0059, 0.0033, 0.0051, 0.0298, 0.0159, 0.0134, 0.1756, 0.6200],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,367][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2026e-02, 1.5132e-05, 8.4045e-06, 4.1244e-06, 1.8542e-04, 2.0251e-06,
        1.5987e-06, 6.3669e-07, 9.8776e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,368][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1914, 0.0497, 0.2163, 0.0435, 0.1610, 0.0328, 0.0352, 0.0790, 0.1911],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,370][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0897, 0.0514, 0.0106, 0.0957, 0.0535, 0.1320, 0.2106, 0.2534, 0.1031],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,372][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2469, 0.0954, 0.0747, 0.1117, 0.0474, 0.2329, 0.1192, 0.0643, 0.0075],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,373][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2283, 0.1329, 0.0984, 0.1245, 0.0752, 0.1082, 0.1114, 0.0803, 0.0408],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,375][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2137, 0.1331, 0.0483, 0.1125, 0.0502, 0.0768, 0.0742, 0.0389, 0.2524],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,377][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3290, 0.1459, 0.0791, 0.1056, 0.0532, 0.0418, 0.0403, 0.0891, 0.1161],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,378][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3938, 0.0135, 0.2314, 0.0157, 0.0711, 0.0697, 0.0302, 0.0560, 0.1072,
        0.0114], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,380][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8442e-03, 4.4350e-01, 1.5915e-04, 1.1169e-02, 1.8482e-04, 3.9666e-04,
        1.7959e-04, 5.1698e-05, 7.8238e-06, 5.4250e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,382][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1971, 0.3102, 0.0322, 0.0759, 0.0158, 0.0361, 0.0074, 0.0101, 0.0099,
        0.3051], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,383][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.3158e-02, 7.7015e-03, 6.9239e-04, 7.7464e-03, 5.2023e-03, 6.0590e-02,
        4.9740e-02, 5.5118e-02, 8.6413e-02, 6.9364e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,385][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2727, 0.0264, 0.0198, 0.0228, 0.0611, 0.1317, 0.0322, 0.1126, 0.0472,
        0.2735], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,387][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0968, 0.3421, 0.0104, 0.1234, 0.0139, 0.0687, 0.1016, 0.0299, 0.0101,
        0.2032], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,388][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3265, 0.0096, 0.1909, 0.0093, 0.1838, 0.0306, 0.0119, 0.0788, 0.1522,
        0.0064], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,388][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0372, 0.0140, 0.0237, 0.0381, 0.0632, 0.0697, 0.1111, 0.1457, 0.1392,
        0.3582], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,389][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0191, 0.1646, 0.0084, 0.1849, 0.0051, 0.0641, 0.1658, 0.0291, 0.0075,
        0.3512], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,390][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2143, 0.1225, 0.0690, 0.1273, 0.0568, 0.0859, 0.0936, 0.0699, 0.0565,
        0.1043], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,391][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1721, 0.1584, 0.0649, 0.1455, 0.0638, 0.0942, 0.0912, 0.0585, 0.0417,
        0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,393][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2480, 0.0959, 0.1022, 0.1088, 0.0404, 0.0692, 0.0659, 0.0805, 0.0749,
        0.1140], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,395][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3165, 0.0258, 0.2027, 0.0222, 0.0833, 0.0622, 0.0375, 0.0827, 0.1149,
        0.0253, 0.0270], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,396][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0615e-03, 1.2476e-02, 6.6029e-05, 5.1186e-01, 1.0487e-04, 6.9044e-04,
        2.3420e-04, 1.8327e-04, 8.4970e-06, 7.4679e-03, 4.6584e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,398][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0822, 0.0615, 0.0281, 0.3079, 0.0222, 0.0428, 0.0172, 0.0147, 0.0230,
        0.0546, 0.3457], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,399][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0819e-02, 6.0635e-03, 5.4860e-05, 3.9874e-03, 8.7088e-04, 7.8452e-03,
        1.3921e-02, 1.5635e-02, 7.4078e-03, 4.9293e-01, 4.4047e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,401][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0356, 0.0130, 0.0066, 0.0247, 0.0147, 0.1626, 0.0660, 0.1203, 0.1784,
        0.1221, 0.2560], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,403][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0325, 0.0871, 0.0059, 0.3871, 0.0025, 0.0542, 0.1209, 0.0254, 0.0037,
        0.0306, 0.2501], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,405][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2644, 0.0107, 0.1922, 0.0102, 0.1849, 0.0335, 0.0123, 0.0935, 0.1789,
        0.0081, 0.0113], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,407][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0331, 0.0120, 0.0203, 0.0200, 0.0324, 0.0423, 0.0636, 0.0795, 0.0979,
        0.2449, 0.3541], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,409][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.0999, 0.0052, 0.1173, 0.0070, 0.0608, 0.1995, 0.0255, 0.0108,
        0.2620, 0.2005], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,410][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1752, 0.1093, 0.0628, 0.1103, 0.0529, 0.0764, 0.0877, 0.0589, 0.0576,
        0.0966, 0.1124], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,410][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1438, 0.1303, 0.0506, 0.1385, 0.0487, 0.0973, 0.0983, 0.0522, 0.0351,
        0.0945, 0.1106], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,411][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2206, 0.0899, 0.0791, 0.1036, 0.0341, 0.0538, 0.0477, 0.0618, 0.0789,
        0.1137, 0.1168], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,412][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2322, 0.0423, 0.0752, 0.0468, 0.1398, 0.1233, 0.0481, 0.0337, 0.1482,
        0.0367, 0.0559, 0.0179], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,413][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7291e-03, 4.1472e-04, 3.6607e-03, 1.5492e-04, 5.3264e-03, 1.7258e-04,
        8.9580e-05, 1.4245e-04, 6.0189e-04, 9.1728e-05, 7.0288e-05, 9.8755e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,415][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2250, 0.0736, 0.1791, 0.0698, 0.0514, 0.1420, 0.0583, 0.0514, 0.0297,
        0.0467, 0.0562, 0.0169], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,416][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2691e-02, 5.1798e-05, 2.3421e-05, 7.2009e-05, 4.8890e-04, 1.1419e-03,
        2.1222e-04, 3.4362e-03, 1.4249e-03, 2.2495e-03, 4.8161e-03, 9.7339e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,418][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0417, 0.0033, 0.0117, 0.0070, 0.0053, 0.0113, 0.0108, 0.0292, 0.0152,
        0.0126, 0.0435, 0.8084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,419][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2430e-02, 4.3730e-06, 2.0822e-04, 1.6929e-06, 2.7300e-04, 4.4295e-06,
        4.7539e-07, 4.6472e-06, 5.0036e-06, 9.8410e-08, 2.7236e-07, 9.0707e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,421][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1424, 0.0596, 0.1521, 0.0443, 0.1208, 0.0371, 0.0632, 0.0555, 0.1279,
        0.0526, 0.0488, 0.0958], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,423][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0522, 0.0187, 0.0055, 0.0289, 0.0316, 0.0332, 0.0705, 0.0484, 0.0273,
        0.1901, 0.3870, 0.1068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,425][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0975, 0.1102, 0.0168, 0.1395, 0.0283, 0.0394, 0.1218, 0.0365, 0.0998,
        0.1299, 0.1674, 0.0129], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,427][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1729, 0.0977, 0.0711, 0.0898, 0.0749, 0.0744, 0.0655, 0.0561, 0.0849,
        0.0829, 0.0901, 0.0397], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,429][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1870, 0.0909, 0.0557, 0.0870, 0.0569, 0.0814, 0.0540, 0.0505, 0.0378,
        0.0648, 0.0673, 0.1667], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,431][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1849, 0.1466, 0.0675, 0.0972, 0.0231, 0.0334, 0.0427, 0.0431, 0.0393,
        0.1675, 0.1043, 0.0503], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,432][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.1206, 0.1270, 0.0779, 0.1166, 0.0766, 0.0143, 0.0418, 0.0227, 0.0631,
        0.1086, 0.1286, 0.0183, 0.0837], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,433][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([3.0855e-05, 3.2389e-05, 5.6776e-05, 2.7793e-05, 5.4116e-01, 6.4177e-05,
        1.4582e-05, 1.3141e-05, 1.0620e-05, 5.0014e-06, 1.0901e-05, 1.6948e-04,
        4.5840e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,434][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.2267, 0.0966, 0.0234, 0.0602, 0.1052, 0.0661, 0.0714, 0.0283, 0.0622,
        0.0551, 0.0483, 0.0592, 0.0974], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,435][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([1.4389e-03, 1.3402e-06, 7.2384e-05, 1.6573e-06, 5.6961e-03, 1.3968e-05,
        1.8501e-05, 1.1598e-04, 3.7106e-04, 6.2271e-05, 1.1469e-04, 1.8686e-03,
        9.9022e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,436][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([2.0745e-03, 2.0969e-04, 1.6353e-03, 1.2125e-04, 7.2014e-02, 2.8464e-04,
        2.9380e-04, 2.4108e-03, 3.3426e-04, 6.6263e-04, 7.9743e-04, 9.0717e-04,
        9.1825e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,437][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([1.2610e-03, 4.0852e-07, 3.5434e-06, 5.8970e-08, 5.8526e-01, 2.1498e-07,
        1.9855e-08, 2.8202e-07, 1.4938e-06, 9.0853e-09, 9.6726e-09, 1.7174e-06,
        4.1348e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,439][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.1222, 0.0761, 0.1933, 0.0470, 0.1694, 0.0149, 0.0463, 0.0199, 0.0292,
        0.0463, 0.0394, 0.0247, 0.1713], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,440][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0500, 0.0147, 0.0033, 0.0267, 0.0133, 0.0318, 0.0574, 0.0439, 0.0228,
        0.1517, 0.3142, 0.0861, 0.1841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,442][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.1307, 0.1061, 0.0505, 0.0906, 0.1005, 0.0261, 0.0855, 0.0389, 0.0529,
        0.0922, 0.0875, 0.0286, 0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,444][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.1920, 0.1084, 0.1037, 0.0994, 0.0115, 0.0589, 0.0776, 0.0472, 0.0403,
        0.0891, 0.0975, 0.0632, 0.0111], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,446][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0770, 0.0758, 0.0540, 0.0674, 0.2507, 0.0357, 0.0531, 0.0251, 0.0200,
        0.0515, 0.0505, 0.0239, 0.2152], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,448][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1111, 0.0696, 0.1003, 0.0708, 0.0458, 0.0627, 0.0592, 0.0785, 0.0728,
        0.0709, 0.0868, 0.1132, 0.0585], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,450][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3337, 0.0289, 0.0981, 0.0167, 0.0579, 0.0608, 0.0178, 0.0441, 0.0425,
        0.0284, 0.0177, 0.0967, 0.0823, 0.0743], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,451][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4446e-03, 3.5510e-03, 2.4833e-04, 1.2008e-03, 1.1132e-03, 8.4896e-03,
        1.4045e-03, 4.5777e-05, 1.5918e-03, 1.5506e-03, 7.2214e-04, 1.1237e-04,
        7.8743e-04, 9.7774e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,453][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2327, 0.0520, 0.0242, 0.0449, 0.0133, 0.1070, 0.0353, 0.0259, 0.0509,
        0.0430, 0.0419, 0.0421, 0.0127, 0.2742], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,454][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([2.0010e-03, 7.4010e-05, 1.0830e-05, 5.5094e-05, 3.1030e-05, 3.1015e-04,
        4.3089e-04, 4.8981e-04, 1.2627e-03, 2.5569e-03, 3.5743e-03, 1.3264e-03,
        3.2086e-03, 9.8467e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,455][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0849, 0.0130, 0.0025, 0.0185, 0.0059, 0.0264, 0.0215, 0.0249, 0.0423,
        0.0557, 0.1184, 0.0239, 0.0472, 0.5151], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,456][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2064e-02, 2.4319e-03, 1.6743e-04, 8.8968e-04, 9.0761e-04, 8.6889e-03,
        2.0741e-04, 2.9448e-05, 6.7182e-04, 2.4859e-04, 2.8093e-04, 6.1953e-06,
        3.5560e-04, 9.7305e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,457][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2001, 0.0098, 0.1772, 0.0099, 0.1213, 0.0131, 0.0080, 0.0358, 0.0944,
        0.0074, 0.0097, 0.1371, 0.1569, 0.0194], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,458][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0374, 0.0071, 0.0040, 0.0119, 0.0061, 0.0161, 0.0340, 0.0147, 0.0233,
        0.1236, 0.1932, 0.1991, 0.1338, 0.1955], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,459][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0521, 0.1078, 0.0158, 0.1058, 0.0154, 0.1030, 0.1394, 0.0317, 0.0281,
        0.1784, 0.1396, 0.0253, 0.0197, 0.0378], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,460][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1460, 0.0785, 0.0605, 0.0806, 0.0500, 0.0645, 0.0614, 0.0456, 0.0536,
        0.0730, 0.0835, 0.0542, 0.0552, 0.0934], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,462][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0998, 0.0719, 0.0305, 0.0758, 0.0521, 0.0781, 0.0586, 0.0245, 0.0469,
        0.0608, 0.0654, 0.0280, 0.0450, 0.2625], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,464][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2542, 0.0605, 0.0698, 0.0808, 0.0318, 0.0386, 0.0324, 0.0584, 0.0693,
        0.0642, 0.0821, 0.0851, 0.0321, 0.0407], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,465][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2652, 0.0257, 0.1209, 0.0215, 0.0411, 0.0692, 0.0231, 0.0374, 0.0738,
        0.0257, 0.0263, 0.0855, 0.0576, 0.1101, 0.0170], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,466][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1215e-03, 1.1780e-02, 5.1474e-05, 3.4318e-02, 1.3844e-04, 3.0536e-04,
        1.4493e-03, 1.7848e-04, 5.7935e-05, 8.2849e-03, 3.0208e-02, 2.4506e-04,
        9.1128e-05, 1.4516e-04, 9.0863e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,469][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1629, 0.0716, 0.0245, 0.0983, 0.0190, 0.0598, 0.0257, 0.0384, 0.0313,
        0.0611, 0.0968, 0.0398, 0.0187, 0.0761, 0.1760], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,470][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9402e-03, 2.6542e-04, 1.9826e-05, 1.8189e-04, 4.9108e-05, 7.2802e-04,
        1.2041e-03, 2.4214e-04, 1.1463e-03, 7.1891e-03, 1.1921e-02, 1.6549e-02,
        5.2584e-03, 2.9293e-01, 6.5937e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,472][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0360, 0.0023, 0.0028, 0.0038, 0.0010, 0.0340, 0.0104, 0.0264, 0.0575,
        0.0124, 0.0318, 0.0736, 0.0109, 0.4180, 0.2791], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,474][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0433, 0.0612, 0.0023, 0.0784, 0.0016, 0.0312, 0.2265, 0.0344, 0.0048,
        0.0212, 0.0413, 0.0007, 0.0007, 0.0326, 0.4198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,476][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1292, 0.0062, 0.0775, 0.0054, 0.0610, 0.0181, 0.0051, 0.0335, 0.0577,
        0.0046, 0.0067, 0.1176, 0.0998, 0.0347, 0.3429], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,478][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0206, 0.0039, 0.0037, 0.0064, 0.0093, 0.0083, 0.0111, 0.0171, 0.0250,
        0.0458, 0.0741, 0.0869, 0.1930, 0.2403, 0.2544], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,479][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0595, 0.0042, 0.1036, 0.0042, 0.0466, 0.1311, 0.0198, 0.0089,
        0.1508, 0.1815, 0.0048, 0.0063, 0.0338, 0.2369], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,480][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1203, 0.0745, 0.0463, 0.0820, 0.0362, 0.0547, 0.0698, 0.0479, 0.0431,
        0.0704, 0.0860, 0.0462, 0.0400, 0.0836, 0.0992], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,481][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1013, 0.0832, 0.0350, 0.0997, 0.0357, 0.0739, 0.0849, 0.0499, 0.0331,
        0.0756, 0.0920, 0.0273, 0.0320, 0.0637, 0.1126], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,482][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1815, 0.0717, 0.0755, 0.0736, 0.0305, 0.0511, 0.0464, 0.0545, 0.0547,
        0.0738, 0.0700, 0.0754, 0.0298, 0.0375, 0.0740], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,485][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:02,487][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[29545],
        [26044],
        [    1],
        [26172],
        [29753],
        [27457],
        [41649],
        [20234],
        [39457],
        [32569],
        [36372],
        [30166],
        [35186],
        [29382],
        [34449]], device='cuda:0')
[2024-07-24 10:17:02,489][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[34830],
        [34000],
        [    1],
        [20124],
        [  475],
        [24941],
        [11336],
        [22968],
        [31951],
        [18659],
        [10291],
        [15845],
        [  342],
        [11081],
        [11117]], device='cuda:0')
[2024-07-24 10:17:02,491][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 2887],
        [ 3027],
        [ 8089],
        [ 3873],
        [13132],
        [ 1277],
        [ 3819],
        [ 6373],
        [ 6310],
        [ 4709],
        [ 7008],
        [ 8642],
        [15782],
        [ 6613],
        [ 8238]], device='cuda:0')
[2024-07-24 10:17:02,492][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 5826],
        [12057],
        [32650],
        [ 9720],
        [39875],
        [46637],
        [48305],
        [17635],
        [33989],
        [ 9400],
        [ 8469],
        [23087],
        [39217],
        [48866],
        [15951]], device='cuda:0')
[2024-07-24 10:17:02,494][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4020],
        [ 5991],
        [ 4435],
        [29731],
        [ 9452],
        [12978],
        [16318],
        [12890],
        [10337],
        [13149],
        [36222],
        [13351],
        [12788],
        [15065],
        [16394]], device='cuda:0')
[2024-07-24 10:17:02,496][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[40495],
        [42067],
        [ 5054],
        [40456],
        [ 6263],
        [ 3239],
        [11179],
        [ 3602],
        [ 7432],
        [34450],
        [41354],
        [38100],
        [ 8581],
        [ 1520],
        [28008]], device='cuda:0')
[2024-07-24 10:17:02,498][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 4537],
        [ 4352],
        [  935],
        [  859],
        [29011],
        [ 1739],
        [ 1339],
        [ 7103],
        [40177],
        [ 3629],
        [ 8567],
        [19049],
        [32151],
        [14783],
        [14103]], device='cuda:0')
[2024-07-24 10:17:02,500][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19613],
        [29653],
        [ 3293],
        [34952],
        [39354],
        [48588],
        [29118],
        [20343],
        [43818],
        [33529],
        [36647],
        [37445],
        [39807],
        [44879],
        [34840]], device='cuda:0')
[2024-07-24 10:17:02,502][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23345],
        [23918],
        [ 9663],
        [  728],
        [ 1530],
        [ 1043],
        [  166],
        [  156],
        [ 1352],
        [ 1024],
        [ 1184],
        [14132],
        [ 3462],
        [ 2984],
        [18920]], device='cuda:0')
[2024-07-24 10:17:02,503][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38884],
        [38523],
        [34005],
        [25839],
        [40126],
        [38551],
        [44462],
        [45018],
        [44527],
        [37963],
        [41335],
        [41134],
        [41018],
        [33968],
        [24183]], device='cuda:0')
[2024-07-24 10:17:02,504][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[41835],
        [37812],
        [42602],
        [31117],
        [37670],
        [40244],
        [42563],
        [44891],
        [47319],
        [34411],
        [33939],
        [36093],
        [36173],
        [38688],
        [34550]], device='cuda:0')
[2024-07-24 10:17:02,506][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41965],
        [44764],
        [44382],
        [42970],
        [40666],
        [41382],
        [40633],
        [40630],
        [40437],
        [42768],
        [43136],
        [42362],
        [41339],
        [41746],
        [42187]], device='cuda:0')
[2024-07-24 10:17:02,508][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13094],
        [17455],
        [42691],
        [19072],
        [40646],
        [14030],
        [37353],
        [23778],
        [10070],
        [22867],
        [19570],
        [22373],
        [44667],
        [11315],
        [18452]], device='cuda:0')
[2024-07-24 10:17:02,510][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[18238],
        [28995],
        [43108],
        [40222],
        [46264],
        [42351],
        [46822],
        [45602],
        [45618],
        [47033],
        [46577],
        [46433],
        [48788],
        [47075],
        [47632]], device='cuda:0')
[2024-07-24 10:17:02,511][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9814],
        [ 1369],
        [    1],
        [ 2595],
        [ 5389],
        [ 7059],
        [25525],
        [ 9779],
        [ 6131],
        [ 1931],
        [ 3191],
        [23241],
        [ 5528],
        [ 8884],
        [15841]], device='cuda:0')
[2024-07-24 10:17:02,513][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[6108],
        [5846],
        [6179],
        [6782],
        [6803],
        [6688],
        [6073],
        [7173],
        [6170],
        [5174],
        [5399],
        [5353],
        [6824],
        [5323],
        [6237]], device='cuda:0')
[2024-07-24 10:17:02,515][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38842],
        [20070],
        [ 8989],
        [14867],
        [29015],
        [ 8914],
        [13075],
        [27718],
        [26869],
        [22176],
        [15400],
        [30110],
        [29657],
        [16463],
        [16306]], device='cuda:0')
[2024-07-24 10:17:02,517][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[27070],
        [27183],
        [21524],
        [36048],
        [16557],
        [24548],
        [23450],
        [19200],
        [15869],
        [18575],
        [38905],
        [14171],
        [11047],
        [15240],
        [14002]], device='cuda:0')
[2024-07-24 10:17:02,519][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22179],
        [25219],
        [24128],
        [15578],
        [36654],
        [27938],
        [19808],
        [30139],
        [28805],
        [14702],
        [11207],
        [28808],
        [33795],
        [32696],
        [20298]], device='cuda:0')
[2024-07-24 10:17:02,520][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31121],
        [31303],
        [23094],
        [33577],
        [31288],
        [41913],
        [37202],
        [41837],
        [44846],
        [36057],
        [37575],
        [12542],
        [28784],
        [41791],
        [33224]], device='cuda:0')
[2024-07-24 10:17:02,522][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[44003],
        [30011],
        [26609],
        [18112],
        [25352],
        [ 4967],
        [19399],
        [21562],
        [14953],
        [20407],
        [13611],
        [20211],
        [23999],
        [14436],
        [14533]], device='cuda:0')
[2024-07-24 10:17:02,524][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[27633],
        [27281],
        [ 4412],
        [ 4075],
        [ 4096],
        [ 8743],
        [ 2860],
        [ 1646],
        [ 5418],
        [ 6970],
        [ 7215],
        [ 6269],
        [ 9630],
        [ 7637],
        [19336]], device='cuda:0')
[2024-07-24 10:17:02,526][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[3639],
        [4092],
        [4836],
        [1414],
        [ 607],
        [ 479],
        [ 806],
        [ 854],
        [ 490],
        [1235],
        [1383],
        [1665],
        [ 362],
        [ 597],
        [ 622]], device='cuda:0')
[2024-07-24 10:17:02,527][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[38759],
        [10672],
        [21931],
        [ 8248],
        [13478],
        [ 8452],
        [ 9162],
        [ 8591],
        [14542],
        [ 9384],
        [ 9298],
        [ 7599],
        [10524],
        [ 7901],
        [10081]], device='cuda:0')
[2024-07-24 10:17:02,529][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[5436],
        [3951],
        [3641],
        [4299],
        [3975],
        [3978],
        [5900],
        [6077],
        [5256],
        [4416],
        [4639],
        [4131],
        [4816],
        [4345],
        [4798]], device='cuda:0')
[2024-07-24 10:17:02,530][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17546],
        [25597],
        [18307],
        [28693],
        [21741],
        [28952],
        [26066],
        [24178],
        [20695],
        [25785],
        [28137],
        [25067],
        [18541],
        [25552],
        [29327]], device='cuda:0')
[2024-07-24 10:17:02,532][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[45746],
        [36104],
        [15525],
        [ 6680],
        [ 9752],
        [ 8143],
        [ 7158],
        [ 4275],
        [ 6344],
        [ 6970],
        [ 5790],
        [ 6648],
        [ 7111],
        [ 7941],
        [ 7513]], device='cuda:0')
[2024-07-24 10:17:02,534][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[26006],
        [31929],
        [38614],
        [39579],
        [38278],
        [42219],
        [42959],
        [40230],
        [39706],
        [41610],
        [40967],
        [39159],
        [40314],
        [41236],
        [40535]], device='cuda:0')
[2024-07-24 10:17:02,536][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37705],
        [47684],
        [50257],
        [46285],
        [43323],
        [40809],
        [22826],
        [37856],
        [42807],
        [47076],
        [45727],
        [24640],
        [43238],
        [40514],
        [32071]], device='cuda:0')
[2024-07-24 10:17:02,537][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060],
        [46060]], device='cuda:0')
[2024-07-24 10:17:02,560][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:02,561][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,563][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,564][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,565][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,566][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,567][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,569][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,570][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,571][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,573][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,574][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,575][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,577][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9855, 0.0145], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,577][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9355, 0.0645], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,577][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.8547, 0.1453], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,578][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2076, 0.7924], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,578][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9372, 0.0628], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,578][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7997, 0.2003], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,579][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2373, 0.7627], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,579][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6267, 0.3733], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,579][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9466, 0.0534], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,580][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9898, 0.0102], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,580][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([6.9387e-05, 9.9993e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,580][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7999, 0.2001], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,581][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0138, 0.1687, 0.8175], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,582][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.3700, 0.5810, 0.0491], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,583][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5465, 0.2256, 0.2279], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,585][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.4108, 0.3467, 0.2425], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,586][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.7284, 0.1342, 0.1375], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,588][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.4972, 0.4679, 0.0349], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,589][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.4133, 0.5374, 0.0494], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,591][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0274, 0.1191, 0.8535], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,593][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.7042, 0.2713, 0.0245], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,594][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.8936, 0.0103, 0.0961], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,595][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([2.6653e-04, 4.4067e-01, 5.5906e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,597][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0423, 0.0360, 0.9217], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,599][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0018, 0.0104, 0.9864, 0.0014], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,600][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8131, 0.0903, 0.0652, 0.0314], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,600][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4273, 0.1271, 0.2168, 0.2288], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,600][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3483, 0.2298, 0.2282, 0.1936], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,601][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6664, 0.0725, 0.1496, 0.1116], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,601][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4054, 0.4294, 0.0062, 0.1591], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,601][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3390, 0.5367, 0.0837, 0.0405], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,602][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0468, 0.0620, 0.8567, 0.0345], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,602][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7485, 0.0700, 0.0650, 0.1165], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,602][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4416, 0.0086, 0.1765, 0.3732], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,603][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.4438e-04, 2.5438e-01, 4.5225e-01, 2.9302e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,603][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2938, 0.1941, 0.0027, 0.5094], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,603][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0064, 0.0272, 0.8444, 0.0155, 0.1065], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,604][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.3025, 0.2417, 0.0428, 0.3971, 0.0159], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,606][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.3235, 0.1584, 0.1556, 0.2358, 0.1267], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,607][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.3686, 0.1792, 0.1542, 0.1505, 0.1475], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,609][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.5023, 0.1120, 0.1357, 0.1254, 0.1246], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,610][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.2878, 0.1028, 0.5399, 0.0308, 0.0387], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,612][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0478, 0.8094, 0.0182, 0.0670, 0.0576], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,614][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0066, 0.0209, 0.8732, 0.0163, 0.0829], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,615][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.6600, 0.1116, 0.0303, 0.1508, 0.0473], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,616][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.5193, 0.0105, 0.1126, 0.2388, 0.1188], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,618][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0004, 0.1882, 0.3101, 0.2281, 0.2732], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,620][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0533, 0.0561, 0.0090, 0.0321, 0.8495], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,622][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1618, 0.0718, 0.1353, 0.1025, 0.4239, 0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,623][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4651, 0.2126, 0.0307, 0.2279, 0.0161, 0.0476], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,623][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2584, 0.1396, 0.1639, 0.1667, 0.1289, 0.1425], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,624][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.3045, 0.1611, 0.1418, 0.1206, 0.1343, 0.1377], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,624][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4648, 0.0774, 0.1162, 0.0897, 0.1166, 0.1353], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,624][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2789, 0.5723, 0.0190, 0.0547, 0.0085, 0.0666], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,625][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0908, 0.7965, 0.0302, 0.0279, 0.0463, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,625][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0099, 0.0139, 0.7143, 0.0171, 0.1558, 0.0890], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,625][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5323, 0.1326, 0.0739, 0.0776, 0.0702, 0.1134], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,626][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2372, 0.0055, 0.1415, 0.0876, 0.3518, 0.1764], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,626][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0004, 0.1278, 0.2253, 0.1571, 0.2147, 0.2748], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,626][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0230, 0.0557, 0.0018, 0.0298, 0.0013, 0.8884], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,627][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.0268e-04, 1.2882e-03, 1.3950e-01, 1.1419e-03, 9.8996e-03, 8.4504e-01,
        2.9266e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,629][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.7063, 0.1246, 0.0300, 0.0840, 0.0114, 0.0312, 0.0126],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,630][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2666, 0.1054, 0.1361, 0.1530, 0.1076, 0.0988, 0.1325],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,632][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3159, 0.1273, 0.1185, 0.1021, 0.1177, 0.1180, 0.1004],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,633][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4115, 0.0662, 0.0928, 0.0843, 0.1094, 0.1180, 0.1177],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,635][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2906, 0.4746, 0.0579, 0.0569, 0.0220, 0.0314, 0.0667],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,637][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1778, 0.5530, 0.0846, 0.0376, 0.0744, 0.0058, 0.0668],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,638][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0180, 0.0080, 0.7191, 0.0086, 0.0881, 0.1368, 0.0214],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,640][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4925, 0.0827, 0.0565, 0.0608, 0.0604, 0.0620, 0.1851],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,642][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0596, 0.0011, 0.0186, 0.0291, 0.0344, 0.0204, 0.8368],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,643][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0004, 0.0964, 0.1892, 0.1272, 0.1823, 0.2216, 0.1830],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,644][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.0205e-02, 2.7260e-02, 1.4643e-03, 1.5210e-02, 8.3154e-04, 2.8318e-03,
        9.0220e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,645][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([7.0894e-05, 3.2998e-04, 1.8986e-03, 3.5363e-04, 6.1869e-02, 4.3090e-01,
        5.0327e-01, 1.3035e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,646][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.3407, 0.1896, 0.0701, 0.1721, 0.0413, 0.0792, 0.0766, 0.0303],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,646][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2367, 0.1026, 0.1289, 0.1283, 0.1072, 0.0946, 0.1009, 0.1008],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,647][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.3320, 0.1058, 0.1041, 0.0965, 0.1065, 0.1064, 0.0818, 0.0669],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,647][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.3341, 0.0764, 0.1005, 0.0801, 0.1049, 0.1105, 0.0944, 0.0991],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,648][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([1.6830e-01, 5.6597e-01, 6.2190e-04, 5.5081e-02, 4.1221e-04, 8.9735e-03,
        9.9748e-02, 1.0090e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,648][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1092, 0.5670, 0.0402, 0.0491, 0.0897, 0.0104, 0.1178, 0.0166],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,648][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0225, 0.0131, 0.4293, 0.0135, 0.1389, 0.3046, 0.0696, 0.0086],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,649][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4231, 0.0316, 0.0463, 0.0594, 0.0580, 0.0781, 0.1843, 0.1192],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,649][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([1.6212e-02, 4.7960e-04, 1.4684e-02, 1.3883e-02, 1.5475e-02, 6.2111e-03,
        2.7791e-01, 6.5514e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,649][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0003, 0.0780, 0.1690, 0.1051, 0.1571, 0.1820, 0.1523, 0.1562],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,650][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([4.8223e-02, 4.5534e-02, 3.8880e-04, 2.2424e-02, 5.4460e-04, 7.0454e-03,
        6.5836e-03, 8.6926e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,651][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([5.6341e-05, 4.7818e-04, 6.6405e-02, 2.1050e-03, 2.4663e-02, 5.6129e-01,
        2.0826e-01, 1.3613e-01, 6.0451e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,652][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.2757, 0.1048, 0.0413, 0.2022, 0.0388, 0.1147, 0.1226, 0.0551, 0.0450],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,654][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2019, 0.0953, 0.1240, 0.1200, 0.0834, 0.0870, 0.0918, 0.0829, 0.1138],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,656][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.3101, 0.1003, 0.0987, 0.0888, 0.0946, 0.0981, 0.0729, 0.0614, 0.0752],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,657][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.3084, 0.0666, 0.0955, 0.0722, 0.0947, 0.1051, 0.0831, 0.0825, 0.0917],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,659][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.2737, 0.1856, 0.1757, 0.0754, 0.0296, 0.0277, 0.1634, 0.0230, 0.0460],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,660][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0467, 0.5905, 0.0367, 0.0734, 0.0538, 0.0207, 0.0537, 0.0435, 0.0810],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,662][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0076, 0.0066, 0.2683, 0.0101, 0.1397, 0.3806, 0.0149, 0.1209, 0.0514],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,663][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4001, 0.0604, 0.0396, 0.0471, 0.0504, 0.1098, 0.1798, 0.0672, 0.0455],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,665][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.1397e-02, 3.2801e-04, 1.0004e-02, 5.6956e-03, 2.3914e-02, 7.7478e-03,
        3.1335e-01, 6.2626e-01, 1.3103e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,666][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0004, 0.0660, 0.1331, 0.0879, 0.1283, 0.1517, 0.1195, 0.1263, 0.1868],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,668][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0714, 0.0370, 0.0025, 0.0293, 0.0012, 0.0014, 0.0146, 0.0011, 0.8414],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,669][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([1.4138e-02, 3.8342e-04, 1.7024e-01, 2.6925e-03, 9.0410e-02, 1.0980e-02,
        1.1928e-01, 3.3125e-02, 5.5852e-01, 2.3687e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,669][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5203, 0.0721, 0.0683, 0.1049, 0.0253, 0.0651, 0.0383, 0.0184, 0.0268,
        0.0605], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,670][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1707, 0.0646, 0.1052, 0.0934, 0.0860, 0.0781, 0.0805, 0.0826, 0.1201,
        0.1187], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,670][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3414, 0.0846, 0.0798, 0.0734, 0.0824, 0.0843, 0.0619, 0.0523, 0.0662,
        0.0736], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,671][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2595, 0.0518, 0.0816, 0.0640, 0.0860, 0.0909, 0.0710, 0.0758, 0.0943,
        0.1251], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,671][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0350, 0.2291, 0.0008, 0.0046, 0.0019, 0.0050, 0.0262, 0.0033, 0.0044,
        0.6895], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,671][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2762, 0.4194, 0.0429, 0.0532, 0.0365, 0.0123, 0.0504, 0.0377, 0.0474,
        0.0239], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,672][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0107, 0.0149, 0.4343, 0.0165, 0.0798, 0.1114, 0.0297, 0.0644, 0.2184,
        0.0198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,672][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4086, 0.0626, 0.0461, 0.0500, 0.0434, 0.0431, 0.1451, 0.0632, 0.0671,
        0.0709], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,673][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.4809e-02, 2.4226e-04, 4.4771e-03, 9.2998e-03, 7.3634e-03, 2.9429e-03,
        1.8062e-01, 7.7538e-01, 7.9372e-04, 4.0654e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,673][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0006, 0.0491, 0.1099, 0.0715, 0.1062, 0.1374, 0.1009, 0.1049, 0.1585,
        0.1609], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,675][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1769, 0.1665, 0.0229, 0.1500, 0.0179, 0.0777, 0.0862, 0.0476, 0.0711,
        0.1831], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,676][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([2.6246e-04, 1.9307e-03, 1.2090e-01, 1.8268e-04, 3.6684e-01, 8.6230e-03,
        1.6626e-01, 1.2757e-01, 2.0582e-01, 1.5295e-03, 8.0748e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,678][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5914, 0.0873, 0.0786, 0.0291, 0.0265, 0.0438, 0.0239, 0.0144, 0.0232,
        0.0579, 0.0239], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,679][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1475, 0.0550, 0.0986, 0.0946, 0.0731, 0.0681, 0.0702, 0.0663, 0.1107,
        0.1026, 0.1133], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,681][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3577, 0.0711, 0.0674, 0.0660, 0.0708, 0.0750, 0.0548, 0.0472, 0.0607,
        0.0677, 0.0616], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,683][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2210, 0.0448, 0.0778, 0.0559, 0.0779, 0.0813, 0.0642, 0.0670, 0.0829,
        0.1127, 0.1146], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,684][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0941, 0.1083, 0.0025, 0.0511, 0.0017, 0.0030, 0.0417, 0.0085, 0.0086,
        0.6163, 0.0642], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,686][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1850, 0.3630, 0.0623, 0.0683, 0.0642, 0.0184, 0.0635, 0.0534, 0.0728,
        0.0318, 0.0175], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,688][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0220, 0.0279, 0.2748, 0.0167, 0.0677, 0.2149, 0.0342, 0.0619, 0.2240,
        0.0378, 0.0180], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,690][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3858, 0.0472, 0.0477, 0.0393, 0.0375, 0.0361, 0.1516, 0.0756, 0.0878,
        0.0509, 0.0405], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,691][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.2459e-02, 2.0213e-04, 5.2995e-03, 8.9110e-03, 7.7944e-03, 2.4212e-03,
        2.1236e-01, 7.3497e-01, 8.6222e-04, 3.4677e-03, 1.1251e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,692][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0006, 0.0436, 0.0939, 0.0627, 0.0904, 0.1181, 0.0846, 0.0871, 0.1328,
        0.1333, 0.1528], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,692][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1347, 0.1430, 0.0016, 0.2606, 0.0009, 0.0673, 0.0111, 0.0069, 0.0113,
        0.1296, 0.2329], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,693][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([2.6768e-04, 4.5663e-03, 1.4566e-02, 7.6773e-03, 4.2787e-03, 3.2091e-01,
        9.2932e-03, 5.9114e-01, 2.0599e-02, 9.3096e-03, 4.1438e-03, 1.3249e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,693][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0278, 0.0574, 0.0185, 0.1582, 0.0203, 0.0421, 0.0441, 0.0332, 0.0218,
        0.2555, 0.3126, 0.0084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,694][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1686, 0.0709, 0.0805, 0.0851, 0.0559, 0.0601, 0.0671, 0.0650, 0.0899,
        0.1005, 0.0931, 0.0631], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,694][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.2986, 0.0744, 0.0711, 0.0651, 0.0690, 0.0726, 0.0573, 0.0480, 0.0558,
        0.0711, 0.0617, 0.0554], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,694][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.2092, 0.0527, 0.0590, 0.0535, 0.0658, 0.0657, 0.0628, 0.0630, 0.0681,
        0.1176, 0.0924, 0.0901], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,695][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3069, 0.1360, 0.0009, 0.0473, 0.0007, 0.0564, 0.0675, 0.0958, 0.0170,
        0.1417, 0.0418, 0.0879], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,695][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0438, 0.4283, 0.0058, 0.0746, 0.0102, 0.0741, 0.0546, 0.2579, 0.0362,
        0.0088, 0.0052, 0.0005], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,696][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0048, 0.0082, 0.2427, 0.0068, 0.0418, 0.2236, 0.0125, 0.0217, 0.3841,
        0.0086, 0.0062, 0.0389], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,697][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.3093, 0.0612, 0.0248, 0.0264, 0.0362, 0.1109, 0.1694, 0.0367, 0.0378,
        0.1216, 0.0352, 0.0306], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,698][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.0918e-02, 1.6022e-04, 5.6246e-03, 3.8596e-03, 8.4946e-03, 1.2425e-02,
        3.6562e-01, 5.8390e-01, 7.6925e-04, 3.0325e-03, 4.9316e-03, 2.6374e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,700][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0007, 0.0364, 0.0806, 0.0522, 0.0748, 0.0918, 0.0731, 0.0803, 0.1157,
        0.1142, 0.1292, 0.1512], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,701][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([4.2411e-02, 2.6455e-02, 1.3001e-03, 1.7988e-02, 6.8042e-04, 2.6711e-03,
        1.4263e-03, 1.0225e-02, 5.8013e-03, 2.0021e-02, 1.2604e-02, 8.5842e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,702][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0036, 0.0143, 0.2058, 0.0081, 0.0384, 0.0255, 0.1537, 0.0381, 0.1909,
        0.0048, 0.0020, 0.2878, 0.0271], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,703][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0841, 0.0928, 0.0233, 0.1446, 0.0063, 0.0462, 0.0669, 0.0253, 0.0251,
        0.2316, 0.2292, 0.0165, 0.0081], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,705][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.1187, 0.0687, 0.0678, 0.0958, 0.0560, 0.0631, 0.0665, 0.0564, 0.0798,
        0.0980, 0.1037, 0.0662, 0.0593], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,706][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.3540, 0.0651, 0.0522, 0.0557, 0.0541, 0.0682, 0.0504, 0.0380, 0.0517,
        0.0599, 0.0532, 0.0495, 0.0480], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,708][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1653, 0.0579, 0.0660, 0.0556, 0.0582, 0.0753, 0.0681, 0.0467, 0.0613,
        0.1079, 0.0869, 0.0698, 0.0810], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,709][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0785, 0.0324, 0.3229, 0.0203, 0.0428, 0.0061, 0.0460, 0.0036, 0.0213,
        0.2646, 0.0595, 0.0160, 0.0862], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,711][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0336, 0.3499, 0.0267, 0.1488, 0.0543, 0.0499, 0.0683, 0.1645, 0.0634,
        0.0198, 0.0145, 0.0020, 0.0042], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,713][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0022, 0.0090, 0.3856, 0.0069, 0.0355, 0.1850, 0.0287, 0.0179, 0.2496,
        0.0093, 0.0060, 0.0281, 0.0364], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,714][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.2649, 0.0730, 0.0133, 0.0304, 0.0194, 0.0696, 0.2370, 0.0459, 0.0442,
        0.1107, 0.0396, 0.0278, 0.0241], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,715][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([9.6295e-03, 1.9302e-04, 2.5853e-03, 4.1018e-03, 2.7509e-03, 5.6505e-03,
        2.9925e-01, 6.6258e-01, 1.1602e-03, 2.7395e-03, 4.6115e-03, 2.1510e-04,
        4.5309e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,716][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0008, 0.0306, 0.0632, 0.0447, 0.0604, 0.0873, 0.0637, 0.0631, 0.0926,
        0.0986, 0.1120, 0.1404, 0.1425], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,716][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0069, 0.0247, 0.0084, 0.0028, 0.5857, 0.0020, 0.0014, 0.0007, 0.0014,
        0.0620, 0.0045, 0.0020, 0.2975], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,717][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0026, 0.0017, 0.3177, 0.0081, 0.1627, 0.2882, 0.0318, 0.0571, 0.0008,
        0.0068, 0.0058, 0.0155, 0.0995, 0.0018], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,717][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.2474, 0.1450, 0.0226, 0.0849, 0.0164, 0.0391, 0.0374, 0.0140, 0.0172,
        0.1955, 0.1132, 0.0394, 0.0201, 0.0078], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,717][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1200, 0.0553, 0.0728, 0.0647, 0.0636, 0.0555, 0.0574, 0.0504, 0.0823,
        0.0872, 0.0736, 0.0568, 0.0697, 0.0908], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,718][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.3248, 0.0626, 0.0568, 0.0537, 0.0561, 0.0591, 0.0435, 0.0374, 0.0454,
        0.0544, 0.0474, 0.0479, 0.0447, 0.0661], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,718][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1675, 0.0433, 0.0538, 0.0447, 0.0610, 0.0519, 0.0478, 0.0412, 0.0471,
        0.0948, 0.0765, 0.0722, 0.0946, 0.1037], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,719][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0850, 0.1473, 0.0105, 0.0435, 0.0141, 0.0337, 0.0983, 0.0180, 0.0449,
        0.2522, 0.0389, 0.0159, 0.0069, 0.1909], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,719][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1397, 0.4678, 0.0448, 0.0627, 0.0369, 0.0147, 0.0467, 0.0440, 0.0778,
        0.0250, 0.0121, 0.0132, 0.0090, 0.0054], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,721][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0030, 0.0034, 0.6089, 0.0037, 0.0377, 0.0639, 0.0026, 0.0177, 0.0493,
        0.0026, 0.0038, 0.0625, 0.0410, 0.1001], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,723][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.3509, 0.0460, 0.0284, 0.0189, 0.0424, 0.0661, 0.1477, 0.0450, 0.0459,
        0.0747, 0.0215, 0.0190, 0.0466, 0.0471], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,724][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.8330e-02, 1.2104e-04, 6.1650e-03, 2.6300e-03, 1.4089e-02, 6.6309e-03,
        1.8727e-01, 7.3417e-01, 2.7458e-03, 1.7806e-03, 3.0793e-03, 2.7373e-04,
        2.2454e-02, 2.5696e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,726][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0007, 0.0266, 0.0541, 0.0376, 0.0543, 0.0689, 0.0497, 0.0497, 0.0734,
        0.0783, 0.0892, 0.1078, 0.1173, 0.1924], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,726][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([1.9284e-02, 2.3717e-02, 3.3695e-04, 1.5011e-02, 2.8374e-04, 1.4022e-03,
        4.5103e-03, 4.8467e-04, 1.2010e-02, 3.3732e-02, 1.1161e-02, 2.1561e-03,
        9.4172e-05, 8.7582e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,728][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([3.1290e-04, 6.8645e-04, 5.7771e-04, 9.6978e-05, 6.8642e-03, 5.0764e-01,
        8.6403e-03, 1.3210e-02, 2.2367e-02, 3.4633e-04, 5.7298e-05, 7.7853e-03,
        8.0549e-03, 4.2336e-01, 1.4973e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,730][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4985, 0.0876, 0.0464, 0.0662, 0.0153, 0.0369, 0.0239, 0.0125, 0.0195,
        0.0697, 0.0578, 0.0272, 0.0103, 0.0151, 0.0131], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,731][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1042, 0.0447, 0.0696, 0.0574, 0.0568, 0.0517, 0.0564, 0.0598, 0.0831,
        0.0777, 0.0667, 0.0661, 0.0632, 0.0789, 0.0637], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,733][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3588, 0.0569, 0.0471, 0.0443, 0.0498, 0.0560, 0.0413, 0.0326, 0.0414,
        0.0487, 0.0401, 0.0395, 0.0414, 0.0617, 0.0405], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,735][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1330, 0.0304, 0.0461, 0.0327, 0.0472, 0.0476, 0.0437, 0.0399, 0.0478,
        0.0757, 0.0636, 0.0698, 0.0801, 0.1060, 0.1364], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,736][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1060, 0.0161, 0.0254, 0.0111, 0.0057, 0.0061, 0.0629, 0.0131, 0.0144,
        0.0385, 0.0091, 0.0098, 0.0024, 0.0186, 0.6607], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,738][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1240, 0.4409, 0.0228, 0.1045, 0.0378, 0.0206, 0.0563, 0.0609, 0.0621,
        0.0240, 0.0149, 0.0067, 0.0088, 0.0060, 0.0097], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,738][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0082, 0.0140, 0.1708, 0.0106, 0.0640, 0.1051, 0.0133, 0.0232, 0.2445,
        0.0180, 0.0106, 0.0744, 0.0636, 0.1714, 0.0084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,739][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3244, 0.0359, 0.0461, 0.0199, 0.0442, 0.0443, 0.1459, 0.0587, 0.0613,
        0.0326, 0.0217, 0.0292, 0.0392, 0.0524, 0.0442], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,739][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.5363e-03, 1.0908e-04, 2.4572e-03, 4.2583e-03, 4.3396e-03, 2.0550e-03,
        2.1493e-01, 7.1525e-01, 4.0806e-04, 2.3267e-03, 5.7354e-03, 2.0626e-04,
        7.6923e-03, 5.1608e-05, 3.1646e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,740][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0008, 0.0201, 0.0435, 0.0293, 0.0433, 0.0581, 0.0425, 0.0402, 0.0626,
        0.0664, 0.0747, 0.0945, 0.1019, 0.1809, 0.1412], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,740][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1851e-01, 8.4181e-02, 7.4071e-04, 6.7486e-02, 4.1055e-04, 6.4376e-03,
        1.7048e-02, 2.0556e-03, 5.7052e-03, 8.6608e-02, 4.1693e-02, 7.1408e-03,
        1.5796e-04, 3.4679e-02, 5.2715e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,763][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:02,763][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,763][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,764][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,764][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,766][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,766][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,766][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,766][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,767][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,767][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,767][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,768][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:02,769][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8286, 0.1714], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,771][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8379, 0.1621], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,772][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6408, 0.3592], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,773][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5182, 0.4818], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,775][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9172, 0.0828], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,777][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8464, 0.1536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,778][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8265, 0.1735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,780][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3837, 0.6163], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,782][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9626, 0.0374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,783][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1838, 0.8162], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,784][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.3686e-04, 9.9956e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,786][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1329, 0.8671], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:02,786][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0221, 0.1077, 0.8702], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,786][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.1738, 0.4430, 0.3832], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,787][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.4409, 0.2804, 0.2786], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,787][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.3761, 0.3420, 0.2819], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,787][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.5778, 0.2439, 0.1783], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,788][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.4574, 0.4596, 0.0830], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,788][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.1648, 0.0079, 0.8273], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,788][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1378, 0.3859, 0.4763], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,789][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.5862, 0.0854, 0.3284], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,789][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0387, 0.2047, 0.7566], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,789][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0008, 0.4380, 0.5612], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,790][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([1.8631e-06, 8.4727e-05, 9.9991e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:02,792][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0083, 0.0204, 0.9631, 0.0082], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,793][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0613, 0.1024, 0.8278, 0.0085], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,795][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3326, 0.1968, 0.2331, 0.2375], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,796][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2728, 0.2387, 0.2405, 0.2479], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,797][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5395, 0.0615, 0.1979, 0.2011], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,799][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4165, 0.4093, 0.0210, 0.1532], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,801][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0937, 0.0168, 0.7282, 0.1613], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,802][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1268, 0.2339, 0.4352, 0.2040], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,804][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9479, 0.0302, 0.0154, 0.0065], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,806][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0533, 0.2047, 0.4920, 0.2500], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,807][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0005, 0.2726, 0.4022, 0.3247], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,808][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.1648e-03, 5.7860e-03, 2.7748e-07, 9.8805e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:02,809][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0094, 0.0189, 0.8545, 0.0161, 0.1011], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,809][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0340, 0.0847, 0.4618, 0.2456, 0.1739], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,809][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.2773, 0.1773, 0.1749, 0.2005, 0.1700], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,810][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.2304, 0.2044, 0.1756, 0.2148, 0.1748], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,810][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.3628, 0.1593, 0.1373, 0.2320, 0.1087], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,810][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.2723, 0.1470, 0.4537, 0.0524, 0.0746], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,811][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.1111, 0.0082, 0.6057, 0.0891, 0.1859], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,811][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0637, 0.1798, 0.4449, 0.1299, 0.1817], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,811][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.4839, 0.0910, 0.3247, 0.0274, 0.0730], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,812][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0278, 0.1214, 0.4517, 0.2335, 0.1655], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,812][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0007, 0.2364, 0.2954, 0.2622, 0.2053], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,813][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([8.6114e-06, 8.1728e-05, 5.7103e-06, 1.9723e-04, 9.9971e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:02,814][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1072, 0.0467, 0.4473, 0.0602, 0.2282, 0.1103], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,816][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0705, 0.1740, 0.2388, 0.2701, 0.2067, 0.0398], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,818][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2177, 0.1479, 0.1618, 0.1623, 0.1557, 0.1547], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,819][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1815, 0.1646, 0.1608, 0.1672, 0.1540, 0.1718], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,821][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3527, 0.0792, 0.1273, 0.1480, 0.1124, 0.1803], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,822][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3889, 0.4008, 0.0385, 0.0637, 0.0265, 0.0816], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,824][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0363, 0.0137, 0.6350, 0.1419, 0.1646, 0.0085], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,825][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0734, 0.1283, 0.3151, 0.1273, 0.1821, 0.1737], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,827][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.4699, 0.1531, 0.1487, 0.0260, 0.0581, 0.1443], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,829][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0301, 0.1275, 0.3271, 0.1600, 0.1217, 0.2336], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,831][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0005, 0.1406, 0.2096, 0.1646, 0.1657, 0.3189], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,832][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.3455e-04, 1.4611e-02, 2.6744e-05, 5.3775e-02, 1.8576e-05, 9.3143e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:02,832][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0041, 0.0102, 0.6366, 0.0104, 0.0516, 0.2437, 0.0435],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,832][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0849, 0.0944, 0.2961, 0.0925, 0.2175, 0.1938, 0.0208],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,833][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1999, 0.1239, 0.1367, 0.1432, 0.1322, 0.1260, 0.1381],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,833][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1582, 0.1392, 0.1382, 0.1429, 0.1323, 0.1460, 0.1433],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,833][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3646, 0.0553, 0.0816, 0.1305, 0.0928, 0.1308, 0.1444],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,834][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2662, 0.3352, 0.0955, 0.0698, 0.0486, 0.0400, 0.1446],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,834][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0203, 0.0111, 0.5294, 0.1432, 0.2743, 0.0095, 0.0123],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,834][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0688, 0.1023, 0.2569, 0.0988, 0.1334, 0.1530, 0.1868],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,835][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9317, 0.0275, 0.0148, 0.0072, 0.0064, 0.0111, 0.0014],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,835][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0265, 0.1156, 0.2769, 0.1325, 0.1022, 0.2061, 0.1402],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,836][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0005, 0.1128, 0.1832, 0.1396, 0.1417, 0.2659, 0.1562],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,837][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.5854e-05, 4.8912e-04, 3.7916e-06, 3.5810e-03, 1.1795e-06, 1.2515e-06,
        9.9589e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:02,839][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0044, 0.0045, 0.1010, 0.0067, 0.1651, 0.2887, 0.4110, 0.0187],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,840][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0169, 0.0388, 0.2686, 0.0593, 0.3407, 0.0817, 0.1839, 0.0102],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,842][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1824, 0.1127, 0.1188, 0.1229, 0.1164, 0.1116, 0.1144, 0.1207],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,844][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1418, 0.1254, 0.1141, 0.1295, 0.1132, 0.1318, 0.1257, 0.1185],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,845][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.2798, 0.0890, 0.0992, 0.1321, 0.0880, 0.1231, 0.1099, 0.0789],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,847][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2119, 0.3281, 0.0025, 0.0751, 0.0025, 0.0162, 0.2485, 0.1153],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,848][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0224, 0.0078, 0.5906, 0.1310, 0.2155, 0.0077, 0.0119, 0.0131],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,850][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0484, 0.0772, 0.1900, 0.0773, 0.1335, 0.1667, 0.1926, 0.1143],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,852][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2926, 0.1488, 0.1077, 0.0333, 0.0560, 0.1002, 0.0228, 0.2386],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,853][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0200, 0.0942, 0.2887, 0.1341, 0.1078, 0.1719, 0.1055, 0.0778],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,855][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0007, 0.0986, 0.1770, 0.1184, 0.1399, 0.2154, 0.1411, 0.1089],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,857][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([7.2543e-05, 1.8773e-04, 4.5965e-08, 9.4385e-04, 6.8894e-07, 2.5592e-05,
        4.4817e-07, 9.9877e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:02,858][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0015, 0.0077, 0.4560, 0.0116, 0.0509, 0.1644, 0.1752, 0.1173, 0.0155],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,859][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0541, 0.0784, 0.2085, 0.1056, 0.1914, 0.1552, 0.1291, 0.0565, 0.0213],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,860][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1661, 0.0993, 0.1071, 0.1074, 0.0990, 0.0958, 0.0999, 0.1049, 0.1204],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,860][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1229, 0.1100, 0.0996, 0.1142, 0.0968, 0.1153, 0.1124, 0.1062, 0.1226],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,861][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.2845, 0.0673, 0.0949, 0.1050, 0.0885, 0.1236, 0.0989, 0.0708, 0.0667],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,861][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.2411, 0.1371, 0.1565, 0.0602, 0.0419, 0.0257, 0.2336, 0.0348, 0.0689],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,862][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0364, 0.0063, 0.6142, 0.0874, 0.1861, 0.0059, 0.0081, 0.0103, 0.0453],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,862][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0402, 0.0684, 0.1614, 0.0575, 0.1047, 0.1567, 0.1146, 0.1505, 0.1460],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,862][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2216, 0.0448, 0.2028, 0.0109, 0.0621, 0.1023, 0.0156, 0.1836, 0.1563],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,863][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0160, 0.0723, 0.2710, 0.1325, 0.1035, 0.1710, 0.0972, 0.0705, 0.0660],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,863][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0005, 0.0894, 0.1370, 0.1098, 0.1083, 0.1830, 0.1120, 0.0994, 0.1607],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,863][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([6.3812e-05, 6.0445e-05, 2.2217e-05, 3.7263e-04, 9.3119e-08, 4.7616e-08,
        2.1856e-07, 5.5557e-10, 9.9948e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:02,865][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0151, 0.0056, 0.4077, 0.0101, 0.0905, 0.0306, 0.1316, 0.0464, 0.2509,
        0.0116], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,866][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0402, 0.0104, 0.1930, 0.0825, 0.1973, 0.2738, 0.0385, 0.0898, 0.0624,
        0.0122], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,868][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1372, 0.0826, 0.0964, 0.0950, 0.0935, 0.0882, 0.0914, 0.0963, 0.1111,
        0.1085], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,869][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1099, 0.0949, 0.0947, 0.0987, 0.0914, 0.0999, 0.0961, 0.0949, 0.1109,
        0.1086], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,871][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2192, 0.0397, 0.0746, 0.0923, 0.0740, 0.0948, 0.0733, 0.0557, 0.0683,
        0.2082], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,872][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0655, 0.1365, 0.0051, 0.0103, 0.0120, 0.0119, 0.0876, 0.0137, 0.0284,
        0.6288], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,874][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0545, 0.0103, 0.5108, 0.0961, 0.2274, 0.0103, 0.0102, 0.0124, 0.0372,
        0.0309], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,876][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0354, 0.0640, 0.1429, 0.0652, 0.0920, 0.0946, 0.1272, 0.1208, 0.1478,
        0.1101], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,877][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7167, 0.0214, 0.0306, 0.0029, 0.0133, 0.0325, 0.0027, 0.1401, 0.0379,
        0.0017], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,879][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0230, 0.0915, 0.2209, 0.1047, 0.0824, 0.1514, 0.1019, 0.0759, 0.0490,
        0.0992], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,881][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0004, 0.0797, 0.1220, 0.0979, 0.0929, 0.1812, 0.0941, 0.0735, 0.1531,
        0.1052], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,882][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([2.7398e-02, 7.4794e-02, 3.0583e-04, 7.5495e-01, 4.4285e-05, 7.2302e-04,
        1.6668e-04, 3.0368e-05, 3.1006e-05, 1.4156e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:02,883][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0025, 0.0077, 0.4276, 0.0031, 0.1733, 0.0246, 0.1285, 0.0823, 0.1344,
        0.0137, 0.0022], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,883][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0257, 0.0399, 0.3937, 0.0018, 0.2335, 0.1515, 0.0370, 0.0523, 0.0273,
        0.0359, 0.0013], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,884][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1214, 0.0734, 0.0885, 0.0881, 0.0836, 0.0799, 0.0826, 0.0857, 0.1015,
        0.0979, 0.0973], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,884][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1002, 0.0858, 0.0880, 0.0900, 0.0832, 0.0899, 0.0863, 0.0865, 0.1016,
        0.0985, 0.0900], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,885][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1899, 0.0333, 0.0708, 0.0780, 0.0637, 0.0774, 0.0582, 0.0452, 0.0514,
        0.1678, 0.1642], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,885][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0681, 0.0829, 0.0065, 0.0335, 0.0073, 0.0074, 0.0915, 0.0203, 0.0333,
        0.5695, 0.0796], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,886][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0393, 0.0111, 0.4418, 0.1023, 0.2523, 0.0112, 0.0099, 0.0132, 0.0307,
        0.0265, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,886][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0387, 0.0632, 0.1121, 0.0603, 0.0778, 0.0951, 0.1274, 0.1071, 0.1308,
        0.1152, 0.0723], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,886][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7506, 0.0306, 0.0179, 0.0068, 0.0072, 0.0211, 0.0016, 0.1305, 0.0236,
        0.0024, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,887][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0206, 0.0823, 0.1917, 0.0918, 0.0731, 0.1334, 0.0909, 0.0692, 0.0441,
        0.0882, 0.1146], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,888][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0004, 0.0692, 0.1081, 0.0878, 0.0851, 0.1626, 0.0852, 0.0652, 0.1365,
        0.0942, 0.1055], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,889][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.7325e-03, 2.0208e-03, 9.4927e-08, 3.9940e-01, 1.6099e-08, 5.2192e-05,
        6.5943e-07, 1.8614e-07, 9.1395e-08, 4.1200e-03, 5.9167e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:02,891][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0031, 0.0122, 0.1632, 0.0167, 0.0266, 0.2054, 0.0481, 0.3623, 0.0758,
        0.0331, 0.0112, 0.0424], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,892][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0221, 0.0697, 0.0360, 0.1842, 0.1985, 0.0510, 0.0264, 0.0461, 0.0466,
        0.1082, 0.2028, 0.0082], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,894][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.1284, 0.0744, 0.0769, 0.0797, 0.0709, 0.0715, 0.0751, 0.0780, 0.0898,
        0.0907, 0.0858, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,895][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0914, 0.0826, 0.0708, 0.0856, 0.0706, 0.0863, 0.0836, 0.0775, 0.0904,
        0.0961, 0.0854, 0.0798], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,897][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.1646, 0.0609, 0.0573, 0.0789, 0.0583, 0.0709, 0.0651, 0.0503, 0.0474,
        0.1728, 0.1116, 0.0620], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,899][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2191, 0.0648, 0.0022, 0.0376, 0.0019, 0.0477, 0.0896, 0.1002, 0.0373,
        0.1521, 0.0515, 0.1960], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,900][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0485, 0.0106, 0.4267, 0.0856, 0.1717, 0.0097, 0.0095, 0.0140, 0.0347,
        0.0257, 0.0523, 0.1110], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,902][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0271, 0.0537, 0.1214, 0.0448, 0.0764, 0.1230, 0.1014, 0.0932, 0.1609,
        0.0839, 0.0485, 0.0656], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,904][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1402, 0.0207, 0.1127, 0.0035, 0.0279, 0.0152, 0.0023, 0.3856, 0.1965,
        0.0017, 0.0050, 0.0886], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,905][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0144, 0.0617, 0.1918, 0.0960, 0.0719, 0.1237, 0.0722, 0.0518, 0.0439,
        0.0865, 0.1297, 0.0563], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,906][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.0681, 0.1080, 0.0780, 0.0781, 0.1383, 0.0869, 0.0660, 0.1330,
        0.0876, 0.0905, 0.0648], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,907][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.6109e-01, 9.1504e-03, 5.0864e-05, 8.8168e-02, 3.8050e-06, 4.8198e-06,
        1.9642e-07, 2.3392e-05, 1.1330e-06, 2.2514e-02, 1.6515e-01, 4.5384e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:02,907][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0046, 0.0106, 0.4095, 0.0093, 0.0520, 0.0342, 0.1170, 0.0416, 0.1041,
        0.0217, 0.0065, 0.1477, 0.0411], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,908][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0084, 0.0201, 0.1354, 0.0523, 0.0512, 0.0678, 0.0761, 0.0410, 0.0365,
        0.0732, 0.0760, 0.3040, 0.0580], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,908][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.1100, 0.0701, 0.0695, 0.0776, 0.0670, 0.0666, 0.0699, 0.0699, 0.0830,
        0.0852, 0.0834, 0.0759, 0.0720], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,908][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0863, 0.0756, 0.0659, 0.0800, 0.0655, 0.0801, 0.0773, 0.0721, 0.0857,
        0.0895, 0.0802, 0.0771, 0.0647], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,909][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.1285, 0.0844, 0.0554, 0.0937, 0.0419, 0.0846, 0.0796, 0.0326, 0.0379,
        0.1752, 0.1088, 0.0411, 0.0363], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,909][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0273, 0.0255, 0.1082, 0.0147, 0.0362, 0.0080, 0.0767, 0.0066, 0.0252,
        0.3495, 0.0811, 0.0222, 0.2191], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,910][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0256, 0.0067, 0.4056, 0.0834, 0.1439, 0.0077, 0.0085, 0.0111, 0.0432,
        0.0298, 0.0605, 0.1081, 0.0660], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,910][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0200, 0.0569, 0.1449, 0.0418, 0.0571, 0.1233, 0.0912, 0.0828, 0.1308,
        0.0795, 0.0464, 0.0632, 0.0620], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,912][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.1339, 0.0400, 0.1369, 0.0119, 0.0275, 0.0156, 0.0041, 0.2913, 0.1753,
        0.0038, 0.0174, 0.1040, 0.0384], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,914][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0097, 0.0476, 0.1848, 0.0923, 0.0691, 0.1156, 0.0620, 0.0415, 0.0442,
        0.0834, 0.1395, 0.0516, 0.0587], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,916][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0007, 0.0702, 0.0915, 0.0804, 0.0650, 0.1426, 0.0799, 0.0548, 0.1193,
        0.0867, 0.0917, 0.0637, 0.0536], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,917][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([3.3650e-06, 4.0480e-05, 3.2099e-06, 8.4196e-05, 5.6223e-01, 2.8380e-07,
        1.6455e-07, 2.9735e-08, 3.6835e-08, 1.9288e-04, 1.7090e-04, 1.3881e-07,
        4.3727e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:02,918][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0082, 0.0095, 0.5291, 0.0126, 0.1080, 0.0874, 0.0510, 0.0350, 0.0113,
        0.0173, 0.0090, 0.0345, 0.0764, 0.0108], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,920][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0330, 0.1558, 0.0526, 0.0591, 0.1291, 0.0291, 0.0194, 0.0425, 0.0065,
        0.2089, 0.0619, 0.0818, 0.1145, 0.0057], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,922][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0989, 0.0614, 0.0671, 0.0662, 0.0663, 0.0621, 0.0635, 0.0657, 0.0780,
        0.0765, 0.0717, 0.0695, 0.0708, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,923][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0777, 0.0686, 0.0664, 0.0710, 0.0629, 0.0722, 0.0689, 0.0664, 0.0782,
        0.0795, 0.0717, 0.0718, 0.0622, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,925][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.1385, 0.0494, 0.0470, 0.0719, 0.0568, 0.0569, 0.0551, 0.0339, 0.0284,
        0.1543, 0.0998, 0.0537, 0.0578, 0.0964], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,927][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0815, 0.0970, 0.0139, 0.0230, 0.0241, 0.0344, 0.1312, 0.0269, 0.0829,
        0.2680, 0.0357, 0.0290, 0.0308, 0.1213], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,928][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0272, 0.0053, 0.4102, 0.0705, 0.1543, 0.0085, 0.0077, 0.0112, 0.0452,
        0.0261, 0.0550, 0.0953, 0.0656, 0.0178], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,929][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0263, 0.0462, 0.1390, 0.0407, 0.0653, 0.0760, 0.0686, 0.0900, 0.0963,
        0.0684, 0.0447, 0.0677, 0.0664, 0.1044], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,930][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.4706, 0.0256, 0.0545, 0.0055, 0.0184, 0.0461, 0.0049, 0.1265, 0.0696,
        0.0026, 0.0080, 0.0465, 0.0274, 0.0938], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,930][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0103, 0.0484, 0.1375, 0.0702, 0.0529, 0.0929, 0.0577, 0.0438, 0.0321,
        0.0646, 0.0909, 0.0411, 0.0463, 0.2112], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,931][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0006, 0.0559, 0.0857, 0.0685, 0.0675, 0.1238, 0.0710, 0.0480, 0.1035,
        0.0780, 0.0822, 0.0573, 0.0566, 0.1013], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,931][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([3.0737e-06, 5.9685e-06, 2.8885e-07, 1.4958e-05, 4.5588e-08, 6.7148e-08,
        4.5320e-07, 2.7010e-10, 1.5660e-05, 2.0294e-05, 3.8882e-05, 1.4660e-08,
        4.4653e-08, 9.9990e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:02,932][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0054, 0.0079, 0.1076, 0.0046, 0.0624, 0.2446, 0.0837, 0.0742, 0.1210,
        0.0175, 0.0034, 0.0534, 0.0465, 0.1674, 0.0004], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,932][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0318, 0.0243, 0.0760, 0.0433, 0.1742, 0.0846, 0.0446, 0.0273, 0.0148,
        0.0327, 0.0435, 0.0989, 0.1577, 0.1450, 0.0013], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,932][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0892, 0.0552, 0.0631, 0.0616, 0.0609, 0.0585, 0.0611, 0.0644, 0.0742,
        0.0719, 0.0675, 0.0671, 0.0658, 0.0758, 0.0638], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,933][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0726, 0.0634, 0.0634, 0.0649, 0.0611, 0.0668, 0.0643, 0.0623, 0.0752,
        0.0734, 0.0654, 0.0674, 0.0608, 0.0758, 0.0632], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,934][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1466, 0.0274, 0.0394, 0.0477, 0.0390, 0.0527, 0.0463, 0.0323, 0.0311,
        0.1284, 0.0814, 0.0482, 0.0437, 0.0969, 0.1389], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,936][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0329, 0.0079, 0.0204, 0.0063, 0.0079, 0.0044, 0.0546, 0.0081, 0.0145,
        0.0435, 0.0111, 0.0125, 0.0120, 0.0171, 0.7467], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,937][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0198, 0.0073, 0.3366, 0.0888, 0.1758, 0.0096, 0.0103, 0.0119, 0.0396,
        0.0305, 0.0639, 0.0979, 0.0723, 0.0230, 0.0126], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,939][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0275, 0.0469, 0.0819, 0.0460, 0.0637, 0.0623, 0.0860, 0.0690, 0.1050,
        0.0830, 0.0520, 0.0532, 0.0645, 0.0907, 0.0683], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,940][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5010, 0.0180, 0.0323, 0.0029, 0.0138, 0.0227, 0.0021, 0.2004, 0.0402,
        0.0014, 0.0035, 0.0702, 0.0200, 0.0402, 0.0313], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,942][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0128, 0.0581, 0.1314, 0.0633, 0.0503, 0.0929, 0.0625, 0.0465, 0.0273,
        0.0590, 0.0757, 0.0404, 0.0457, 0.1885, 0.0456], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,944][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0006, 0.0514, 0.0779, 0.0649, 0.0601, 0.1183, 0.0663, 0.0429, 0.0974,
        0.0711, 0.0756, 0.0551, 0.0484, 0.0903, 0.0797], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,945][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([7.2036e-06, 1.8259e-04, 6.0660e-08, 4.4395e-03, 8.2349e-10, 2.2854e-07,
        4.6711e-07, 1.7832e-09, 1.8330e-08, 6.6070e-04, 6.6624e-03, 1.9501e-08,
        5.9850e-10, 6.1769e-08, 9.8805e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:02,946][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:02,949][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[28458],
        [21017],
        [  636],
        [ 8349],
        [26305],
        [17959],
        [20081],
        [14359],
        [22213],
        [13816],
        [19452],
        [27208],
        [42006],
        [20984],
        [31908]], device='cuda:0')
[2024-07-24 10:17:02,950][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[28835],
        [21754],
        [    1],
        [31029],
        [35742],
        [24132],
        [45109],
        [24626],
        [34786],
        [41679],
        [34381],
        [23177],
        [40698],
        [26362],
        [38924]], device='cuda:0')
[2024-07-24 10:17:02,952][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[28308],
        [28459],
        [37083],
        [36363],
        [35065],
        [13766],
        [  596],
        [  280],
        [  308],
        [ 9270],
        [ 7143],
        [ 3029],
        [12012],
        [ 4127],
        [  674]], device='cuda:0')
[2024-07-24 10:17:02,953][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[34992],
        [37280],
        [44580],
        [37176],
        [40073],
        [42182],
        [40585],
        [42466],
        [43312],
        [41289],
        [40017],
        [40924],
        [42042],
        [41579],
        [39992]], device='cuda:0')
[2024-07-24 10:17:02,954][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18377],
        [19278],
        [22505],
        [23972],
        [25003],
        [26718],
        [29205],
        [29524],
        [30180],
        [30990],
        [30498],
        [30075],
        [30494],
        [29910],
        [30455]], device='cuda:0')
[2024-07-24 10:17:02,955][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[27820],
        [42412],
        [41612],
        [39543],
        [38498],
        [37010],
        [36921],
        [37320],
        [37088],
        [37068],
        [36955],
        [35883],
        [35835],
        [35797],
        [36263]], device='cuda:0')
[2024-07-24 10:17:02,956][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30513],
        [30981],
        [26658],
        [26107],
        [25375],
        [19398],
        [18598],
        [18345],
        [19092],
        [20035],
        [20728],
        [22397],
        [22613],
        [20718],
        [20134]], device='cuda:0')
[2024-07-24 10:17:02,957][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16394],
        [15453],
        [18332],
        [19538],
        [43582],
        [17296],
        [20332],
        [15014],
        [26457],
        [18264],
        [19302],
        [12771],
        [36905],
        [12291],
        [23258]], device='cuda:0')
[2024-07-24 10:17:02,959][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13046],
        [10952],
        [ 8559],
        [ 7008],
        [ 9268],
        [ 9075],
        [ 6171],
        [ 7450],
        [ 8063],
        [ 7512],
        [ 6973],
        [10604],
        [ 8883],
        [ 8050],
        [ 8603]], device='cuda:0')
[2024-07-24 10:17:02,960][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39992],
        [38460],
        [  128],
        [  150],
        [  119],
        [  158],
        [  156],
        [ 1185],
        [ 4042],
        [ 2531],
        [10257],
        [17283],
        [ 3885],
        [  393],
        [20874]], device='cuda:0')
[2024-07-24 10:17:02,962][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14536],
        [14979],
        [20855],
        [22717],
        [21797],
        [31346],
        [25723],
        [24779],
        [23927],
        [22964],
        [21277],
        [20205],
        [16721],
        [14674],
        [13966]], device='cuda:0')
[2024-07-24 10:17:02,963][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40112],
        [40143],
        [39108],
        [39270],
        [38233],
        [32885],
        [45331],
        [45774],
        [45797],
        [45710],
        [45737],
        [46015],
        [45940],
        [45466],
        [45724]], device='cuda:0')
[2024-07-24 10:17:02,964][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13807],
        [ 6471],
        [13359],
        [14910],
        [18820],
        [18786],
        [19942],
        [20167],
        [21349],
        [20435],
        [20607],
        [21405],
        [23686],
        [22394],
        [23183]], device='cuda:0')
[2024-07-24 10:17:02,966][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[30555],
        [27362],
        [47874],
        [30014],
        [48760],
        [46632],
        [40742],
        [33134],
        [43899],
        [30829],
        [28219],
        [44984],
        [48017],
        [45218],
        [33849]], device='cuda:0')
[2024-07-24 10:17:02,968][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[19332],
        [35824],
        [30159],
        [38673],
        [43737],
        [45596],
        [47970],
        [38348],
        [32582],
        [44058],
        [40751],
        [34429],
        [42794],
        [48547],
        [45981]], device='cuda:0')
[2024-07-24 10:17:02,969][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12096],
        [ 5848],
        [  328],
        [  477],
        [  595],
        [ 2372],
        [ 1202],
        [ 5462],
        [ 2409],
        [ 1742],
        [ 2343],
        [17582],
        [ 2335],
        [ 2058],
        [ 8917]], device='cuda:0')
[2024-07-24 10:17:02,971][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13990],
        [12027],
        [ 8757],
        [17797],
        [15939],
        [14528],
        [11371],
        [13111],
        [10984],
        [ 9597],
        [11560],
        [13497],
        [14233],
        [14746],
        [17305]], device='cuda:0')
[2024-07-24 10:17:02,973][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[41378],
        [39706],
        [37432],
        [35655],
        [35219],
        [33905],
        [33189],
        [33003],
        [33183],
        [32603],
        [32136],
        [32705],
        [32542],
        [32399],
        [32193]], device='cuda:0')
[2024-07-24 10:17:02,974][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18044],
        [18774],
        [18487],
        [18807],
        [18992],
        [19197],
        [19272],
        [18900],
        [18886],
        [18969],
        [19077],
        [19060],
        [19120],
        [19149],
        [19206]], device='cuda:0')
[2024-07-24 10:17:02,976][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[40520],
        [39094],
        [36751],
        [38328],
        [38225],
        [38183],
        [38119],
        [38635],
        [37888],
        [33609],
        [33169],
        [31323],
        [31430],
        [29064],
        [28272]], device='cuda:0')
[2024-07-24 10:17:02,977][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[43993],
        [43450],
        [29798],
        [20275],
        [24663],
        [19667],
        [11255],
        [ 8968],
        [ 6892],
        [24328],
        [21041],
        [16264],
        [14112],
        [ 6341],
        [45505]], device='cuda:0')
[2024-07-24 10:17:02,978][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26961],
        [20475],
        [16304],
        [13793],
        [14333],
        [14291],
        [14089],
        [14607],
        [15476],
        [14585],
        [14265],
        [15800],
        [16707],
        [16808],
        [16400]], device='cuda:0')
[2024-07-24 10:17:02,979][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[43202],
        [39670],
        [44358],
        [43126],
        [45679],
        [46551],
        [46161],
        [46054],
        [44998],
        [43724],
        [42596],
        [43676],
        [44467],
        [44719],
        [43488]], device='cuda:0')
[2024-07-24 10:17:02,980][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[41784],
        [42764],
        [48787],
        [43162],
        [48561],
        [47352],
        [43331],
        [47752],
        [48879],
        [47142],
        [46672],
        [48497],
        [48486],
        [48457],
        [47812]], device='cuda:0')
[2024-07-24 10:17:02,981][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11541],
        [17029],
        [21970],
        [23844],
        [24697],
        [24799],
        [25341],
        [24798],
        [24847],
        [25435],
        [27362],
        [27667],
        [27905],
        [28902],
        [28620]], device='cuda:0')
[2024-07-24 10:17:02,983][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[27898],
        [29291],
        [25110],
        [25918],
        [25222],
        [24055],
        [23857],
        [23850],
        [25440],
        [25727],
        [25715],
        [25228],
        [24897],
        [24224],
        [23943]], device='cuda:0')
[2024-07-24 10:17:02,984][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[  179],
        [  180],
        [28463],
        [  109],
        [41237],
        [35206],
        [14935],
        [34837],
        [43461],
        [  131],
        [  122],
        [  337],
        [41732],
        [41730],
        [   67]], device='cuda:0')
[2024-07-24 10:17:02,986][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7278],
        [25265],
        [15379],
        [38888],
        [12034],
        [12516],
        [19152],
        [13134],
        [15453],
        [38536],
        [40167],
        [15639],
        [15345],
        [19238],
        [14552]], device='cuda:0')
[2024-07-24 10:17:02,987][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23197],
        [41941],
        [43817],
        [36026],
        [10096],
        [ 9711],
        [ 5906],
        [21717],
        [18272],
        [22191],
        [30107],
        [20169],
        [ 6550],
        [ 1408],
        [ 6717]], device='cuda:0')
[2024-07-24 10:17:02,988][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562],
        [28562]], device='cuda:0')
[2024-07-24 10:17:03,018][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:03,020][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,021][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,022][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,022][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,022][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,023][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,023][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,023][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,024][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,024][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,024][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,024][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,025][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4212, 0.5788], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,025][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5063, 0.4937], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,025][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7509, 0.2491], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,026][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3553, 0.6447], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,028][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6316, 0.3684], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,030][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8989, 0.1011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,031][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3482, 0.6518], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,032][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2861, 0.7139], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,034][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5160, 0.4840], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,036][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6865, 0.3135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,037][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3082, 0.6918], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,039][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1931, 0.8069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,041][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.2593, 0.3878, 0.3529], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,043][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.3229, 0.3151, 0.3620], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,044][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5456, 0.2802, 0.1742], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,045][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0922, 0.3081, 0.5996], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,045][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.5120, 0.3293, 0.1587], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,046][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.7183, 0.0978, 0.1839], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,046][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1655, 0.2997, 0.5348], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,046][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0167, 0.0087, 0.9746], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,047][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.3757, 0.5070, 0.1173], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,047][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.6235, 0.2385, 0.1380], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,047][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.2441, 0.3534, 0.4025], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,048][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0762, 0.2834, 0.6404], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,048][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1795, 0.3035, 0.2855, 0.2315], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,048][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2496, 0.2315, 0.2750, 0.2439], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,049][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3036, 0.0988, 0.4396, 0.1580], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,049][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0772, 0.1998, 0.5032, 0.2198], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,051][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.2707, 0.2931, 0.1458, 0.2904], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,053][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.6291, 0.0213, 0.0580, 0.2916], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,054][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1423, 0.2537, 0.3889, 0.2151], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,055][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0342, 0.0253, 0.8646, 0.0760], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,056][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2211, 0.2581, 0.2886, 0.2322], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,058][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2690, 0.1507, 0.4013, 0.1790], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,060][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1406, 0.2554, 0.3241, 0.2798], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,061][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0363, 0.1597, 0.3881, 0.4159], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,063][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1514, 0.2338, 0.2203, 0.2536, 0.1409], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,065][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.2062, 0.1936, 0.2203, 0.2033, 0.1766], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,067][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.2497, 0.0891, 0.2796, 0.3220, 0.0595], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,068][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0312, 0.1094, 0.3447, 0.1582, 0.3565], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,068][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.2124, 0.1690, 0.1143, 0.3291, 0.1752], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,069][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.3374, 0.0188, 0.0483, 0.4482, 0.1473], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,069][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0713, 0.1291, 0.2569, 0.1100, 0.4326], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,069][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0141, 0.0061, 0.5105, 0.0152, 0.4541], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,070][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.1977, 0.2016, 0.2108, 0.3216, 0.0682], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,070][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.2134, 0.1261, 0.3193, 0.2807, 0.0607], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,070][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.1271, 0.1970, 0.2146, 0.2190, 0.2422], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,071][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0313, 0.1090, 0.2548, 0.2809, 0.3239], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,071][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1166, 0.2175, 0.2156, 0.1930, 0.1653, 0.0920], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,072][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1734, 0.1618, 0.1869, 0.1702, 0.1479, 0.1598], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,072][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1248, 0.0727, 0.2229, 0.3025, 0.1698, 0.1075], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,074][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0677, 0.1129, 0.2741, 0.1456, 0.3118, 0.0879], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,075][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2031, 0.1568, 0.0600, 0.2966, 0.1050, 0.1785], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,077][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1238, 0.0176, 0.0627, 0.3580, 0.2002, 0.2378], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,078][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0701, 0.1235, 0.2082, 0.0948, 0.3306, 0.1728], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,079][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0067, 0.0024, 0.4385, 0.0051, 0.3265, 0.2208], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,081][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1401, 0.2467, 0.1450, 0.1916, 0.1384, 0.1381], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,082][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2121, 0.1259, 0.1662, 0.2157, 0.1808, 0.0993], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,084][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1156, 0.1617, 0.1714, 0.1797, 0.1946, 0.1770], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,085][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0211, 0.0890, 0.1750, 0.1607, 0.2772, 0.2770], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,088][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0996, 0.1649, 0.1495, 0.2088, 0.1480, 0.1079, 0.1213],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,089][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1408, 0.1324, 0.1630, 0.1442, 0.1273, 0.1342, 0.1582],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,091][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1308, 0.0532, 0.1181, 0.1962, 0.0971, 0.3741, 0.0307],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,091][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0358, 0.0925, 0.2219, 0.1464, 0.2435, 0.1134, 0.1464],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,092][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1481, 0.1147, 0.1039, 0.2108, 0.1102, 0.1604, 0.1519],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,092][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0697, 0.0037, 0.0155, 0.1053, 0.0563, 0.1193, 0.6302],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,092][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0652, 0.1134, 0.1705, 0.0960, 0.2881, 0.1673, 0.0995],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,093][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0064, 0.0012, 0.2068, 0.0039, 0.1973, 0.1407, 0.4436],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,093][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1055, 0.1083, 0.1291, 0.1741, 0.0732, 0.3613, 0.0485],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,093][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1435, 0.0903, 0.1616, 0.1689, 0.1495, 0.2194, 0.0669],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,094][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0999, 0.1351, 0.1403, 0.1514, 0.1628, 0.1470, 0.1635],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,094][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0168, 0.0522, 0.0973, 0.1196, 0.1717, 0.1892, 0.3532],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,094][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1094, 0.1524, 0.1167, 0.1510, 0.1023, 0.0796, 0.1332, 0.1554],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,095][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1294, 0.1173, 0.1384, 0.1273, 0.1119, 0.1212, 0.1267, 0.1279],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,096][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0606, 0.0250, 0.1154, 0.0833, 0.1722, 0.3531, 0.1291, 0.0612],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,098][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0228, 0.0557, 0.1729, 0.0916, 0.1815, 0.1045, 0.1959, 0.1751],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,099][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1235, 0.1029, 0.0360, 0.2129, 0.0654, 0.1385, 0.2030, 0.1179],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,101][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0668, 0.0077, 0.0221, 0.1020, 0.0614, 0.0959, 0.5561, 0.0880],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,102][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0465, 0.0867, 0.1488, 0.0742, 0.2536, 0.1563, 0.0818, 0.1521],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,104][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0042, 0.0014, 0.1747, 0.0040, 0.1673, 0.1219, 0.4070, 0.1195],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,105][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0867, 0.1251, 0.0732, 0.1291, 0.1220, 0.3171, 0.0940, 0.0527],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,107][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0980, 0.0710, 0.0921, 0.2358, 0.0687, 0.2664, 0.1143, 0.0538],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,108][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0787, 0.1159, 0.1234, 0.1278, 0.1406, 0.1291, 0.1455, 0.1391],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,111][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0201, 0.0425, 0.0636, 0.0784, 0.1109, 0.1103, 0.2043, 0.3699],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,112][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0818, 0.1369, 0.1350, 0.1216, 0.0769, 0.0865, 0.0895, 0.1893, 0.0825],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,114][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1127, 0.1032, 0.1220, 0.1132, 0.0985, 0.1069, 0.1155, 0.1141, 0.1139],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,114][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0816, 0.0327, 0.1364, 0.0876, 0.1182, 0.2915, 0.0794, 0.1287, 0.0439],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,115][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0146, 0.0395, 0.1196, 0.0659, 0.1654, 0.0926, 0.1488, 0.2252, 0.1282],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,115][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0927, 0.0827, 0.0405, 0.1445, 0.0971, 0.1491, 0.1617, 0.1292, 0.1025],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,115][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0730, 0.0090, 0.0233, 0.1007, 0.0500, 0.0797, 0.3539, 0.1088, 0.2017],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,116][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0386, 0.0668, 0.1333, 0.0570, 0.2191, 0.1182, 0.0682, 0.1338, 0.1649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,116][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0042, 0.0010, 0.1861, 0.0031, 0.1598, 0.1089, 0.3543, 0.1069, 0.0757],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,116][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0655, 0.0967, 0.1131, 0.1279, 0.0596, 0.3209, 0.1068, 0.0738, 0.0357],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,117][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1091, 0.0843, 0.0982, 0.1726, 0.0808, 0.2376, 0.0920, 0.0878, 0.0376],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,117][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0716, 0.1030, 0.1098, 0.1148, 0.1240, 0.1131, 0.1266, 0.1226, 0.1145],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,118][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0121, 0.0329, 0.0389, 0.0666, 0.0573, 0.0860, 0.1776, 0.2651, 0.2635],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,119][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0691, 0.0920, 0.1023, 0.1121, 0.0980, 0.0721, 0.0933, 0.1507, 0.1051,
        0.1052], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,120][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1061, 0.0946, 0.1112, 0.0995, 0.0851, 0.0944, 0.1051, 0.0998, 0.0994,
        0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,122][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1022, 0.0200, 0.1109, 0.0945, 0.0837, 0.2193, 0.0909, 0.1368, 0.1156,
        0.0263], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,124][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0189, 0.0360, 0.0989, 0.0644, 0.1239, 0.0961, 0.1213, 0.2260, 0.1688,
        0.0456], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,125][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0933, 0.0703, 0.0560, 0.1076, 0.0786, 0.0865, 0.1541, 0.1075, 0.1102,
        0.1358], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,126][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([7.4332e-03, 6.6477e-05, 3.2266e-04, 2.0310e-03, 1.0368e-03, 1.7800e-03,
        9.3059e-03, 3.0072e-03, 6.6675e-03, 9.6835e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,128][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0366, 0.0646, 0.1019, 0.0634, 0.1847, 0.1086, 0.0679, 0.1176, 0.1476,
        0.1069], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,129][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0078, 0.0012, 0.1376, 0.0069, 0.1584, 0.1243, 0.3543, 0.1223, 0.0765,
        0.0107], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,131][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0934, 0.0609, 0.0706, 0.1151, 0.0443, 0.2377, 0.1034, 0.0957, 0.1257,
        0.0532], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,133][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0931, 0.0364, 0.0767, 0.1132, 0.0675, 0.1570, 0.1452, 0.0996, 0.1759,
        0.0353], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,135][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0614, 0.0905, 0.1007, 0.0998, 0.1121, 0.1018, 0.1132, 0.1092, 0.1040,
        0.1073], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,136][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0076, 0.0169, 0.0268, 0.0360, 0.0418, 0.0478, 0.0976, 0.1798, 0.1687,
        0.3771], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,137][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0629, 0.1046, 0.0945, 0.0786, 0.0983, 0.0566, 0.0888, 0.1356, 0.0944,
        0.1160, 0.0697], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,137][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0972, 0.0860, 0.0995, 0.0901, 0.0766, 0.0859, 0.0958, 0.0908, 0.0899,
        0.0942, 0.0938], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,138][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1145, 0.0320, 0.1276, 0.0412, 0.1617, 0.1560, 0.0912, 0.1106, 0.0924,
        0.0443, 0.0285], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,138][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0160, 0.0409, 0.1045, 0.0437, 0.1467, 0.0706, 0.1245, 0.1951, 0.1659,
        0.0525, 0.0396], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,139][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0696, 0.0871, 0.0440, 0.0848, 0.0930, 0.0695, 0.1368, 0.0744, 0.0584,
        0.1768, 0.1055], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,139][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.8939e-03, 1.2121e-04, 4.0614e-04, 1.5698e-03, 1.1979e-03, 1.6681e-03,
        7.4235e-03, 2.4952e-03, 5.6103e-03, 5.4141e-01, 4.2820e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,139][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0351, 0.0648, 0.0955, 0.0575, 0.1808, 0.1026, 0.0654, 0.1082, 0.1270,
        0.1046, 0.0584], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,140][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0104, 0.0023, 0.1363, 0.0114, 0.1530, 0.1325, 0.3231, 0.1247, 0.0761,
        0.0156, 0.0145], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,140][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0780, 0.0789, 0.0886, 0.0626, 0.0682, 0.2022, 0.0994, 0.0993, 0.1011,
        0.0791, 0.0427], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,141][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0818, 0.0466, 0.0830, 0.0553, 0.0770, 0.1826, 0.1111, 0.1171, 0.1607,
        0.0516, 0.0331], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,142][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0547, 0.0818, 0.0937, 0.0893, 0.1027, 0.0933, 0.1034, 0.0995, 0.0958,
        0.0960, 0.0899], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,143][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0096, 0.0168, 0.0238, 0.0228, 0.0352, 0.0403, 0.0708, 0.1248, 0.1247,
        0.3160, 0.2152], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,145][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0449, 0.0849, 0.0794, 0.0974, 0.0580, 0.0502, 0.0640, 0.1134, 0.0831,
        0.1200, 0.1018, 0.1029], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,147][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0837, 0.0755, 0.0902, 0.0835, 0.0739, 0.0805, 0.0863, 0.0864, 0.0857,
        0.0882, 0.0873, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,148][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1043, 0.0322, 0.0597, 0.1442, 0.0828, 0.1562, 0.0775, 0.0712, 0.0924,
        0.0467, 0.0865, 0.0464], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,150][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0088, 0.0304, 0.0993, 0.0452, 0.1438, 0.0634, 0.1304, 0.1524, 0.1677,
        0.0406, 0.0408, 0.0772], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,151][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0612, 0.0632, 0.0212, 0.1047, 0.0205, 0.0849, 0.0645, 0.2016, 0.0494,
        0.1405, 0.1164, 0.0720], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,152][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([1.0584e-03, 1.1295e-04, 3.5191e-04, 1.2963e-03, 9.1205e-04, 1.6431e-03,
        6.2940e-03, 1.8394e-03, 5.9160e-03, 5.4683e-01, 3.1771e-01, 1.1603e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,154][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0291, 0.0514, 0.0899, 0.0416, 0.1726, 0.0989, 0.0461, 0.0991, 0.1248,
        0.0803, 0.0416, 0.1246], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,156][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0052, 0.0008, 0.1324, 0.0035, 0.1530, 0.1056, 0.3663, 0.1131, 0.0604,
        0.0045, 0.0038, 0.0515], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,158][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0444, 0.0831, 0.0448, 0.1103, 0.0367, 0.2640, 0.0531, 0.0919, 0.1145,
        0.0711, 0.0628, 0.0232], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,159][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0741, 0.0540, 0.0562, 0.1159, 0.0647, 0.1913, 0.0879, 0.0834, 0.1453,
        0.0435, 0.0519, 0.0318], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,160][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0610, 0.0752, 0.0799, 0.0866, 0.0926, 0.0853, 0.0935, 0.0911, 0.0831,
        0.0906, 0.0880, 0.0731], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,160][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0112, 0.0196, 0.0293, 0.0257, 0.0331, 0.0375, 0.0647, 0.1210, 0.1223,
        0.2748, 0.1860, 0.0750], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,161][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0497, 0.0780, 0.0694, 0.0839, 0.0466, 0.0508, 0.0746, 0.1178, 0.0647,
        0.0993, 0.0867, 0.1319, 0.0467], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,161][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0787, 0.0715, 0.0843, 0.0783, 0.0683, 0.0746, 0.0790, 0.0788, 0.0774,
        0.0834, 0.0823, 0.0734, 0.0702], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,162][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0671, 0.0203, 0.0619, 0.0703, 0.0125, 0.2245, 0.0665, 0.1127, 0.1056,
        0.0305, 0.0448, 0.1757, 0.0077], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,162][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0063, 0.0245, 0.0796, 0.0354, 0.0841, 0.0552, 0.1065, 0.1487, 0.1484,
        0.0310, 0.0329, 0.1376, 0.1100], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,162][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0493, 0.0432, 0.0258, 0.0803, 0.0406, 0.0759, 0.0950, 0.0728, 0.0860,
        0.1279, 0.1047, 0.1458, 0.0526], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,163][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([4.2682e-03, 5.7482e-05, 1.9213e-04, 1.6397e-03, 6.2234e-04, 9.8662e-04,
        4.4554e-03, 1.4576e-03, 3.3295e-03, 3.8994e-01, 4.2107e-01, 1.5256e-01,
        1.9428e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,163][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0222, 0.0412, 0.0781, 0.0357, 0.1377, 0.0854, 0.0349, 0.0831, 0.1162,
        0.0681, 0.0370, 0.1233, 0.1371], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,164][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0069, 0.0009, 0.0909, 0.0047, 0.1084, 0.1008, 0.2717, 0.0918, 0.0577,
        0.0063, 0.0057, 0.0668, 0.1875], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,166][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0621, 0.0540, 0.0569, 0.0816, 0.0185, 0.2301, 0.0579, 0.0721, 0.1383,
        0.0522, 0.0565, 0.1037, 0.0163], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,168][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0661, 0.0377, 0.0617, 0.0845, 0.0149, 0.1785, 0.0907, 0.1070, 0.1951,
        0.0399, 0.0439, 0.0718, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,169][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0564, 0.0721, 0.0732, 0.0814, 0.0844, 0.0772, 0.0860, 0.0832, 0.0773,
        0.0864, 0.0840, 0.0670, 0.0715], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,170][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0081, 0.0127, 0.0219, 0.0213, 0.0222, 0.0285, 0.0479, 0.0972, 0.0759,
        0.1612, 0.1497, 0.0615, 0.2920], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,172][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0413, 0.0717, 0.0780, 0.0696, 0.0608, 0.0534, 0.0517, 0.0947, 0.0833,
        0.0802, 0.0694, 0.1228, 0.0606, 0.0624], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,174][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0708, 0.0680, 0.0790, 0.0728, 0.0633, 0.0683, 0.0723, 0.0716, 0.0712,
        0.0774, 0.0761, 0.0662, 0.0635, 0.0796], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,176][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0841, 0.0312, 0.0553, 0.1097, 0.0513, 0.2180, 0.0426, 0.0821, 0.0557,
        0.0414, 0.0740, 0.0865, 0.0327, 0.0353], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,177][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0186, 0.0317, 0.0654, 0.0521, 0.0928, 0.0375, 0.0728, 0.1409, 0.1192,
        0.0449, 0.0533, 0.1144, 0.1180, 0.0384], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,179][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0847, 0.0539, 0.0212, 0.0879, 0.0322, 0.0713, 0.0884, 0.0836, 0.0442,
        0.1290, 0.1141, 0.1003, 0.0385, 0.0507], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,180][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.2062e-04, 6.1513e-05, 2.1005e-04, 6.4288e-04, 4.2301e-04, 7.0014e-04,
        2.6931e-03, 9.5573e-04, 2.7986e-03, 4.4491e-01, 2.4847e-01, 1.1206e-01,
        2.2127e-02, 1.6303e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,182][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0236, 0.0400, 0.0740, 0.0345, 0.1252, 0.0687, 0.0408, 0.0785, 0.0897,
        0.0621, 0.0364, 0.1054, 0.1234, 0.0974], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,183][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0029, 0.0004, 0.0961, 0.0017, 0.0973, 0.0804, 0.2573, 0.0789, 0.0494,
        0.0025, 0.0021, 0.0503, 0.1922, 0.0886], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,183][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0640, 0.1107, 0.0913, 0.0964, 0.0687, 0.0911, 0.0455, 0.0761, 0.0615,
        0.0909, 0.0539, 0.0580, 0.0513, 0.0407], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,184][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0635, 0.0489, 0.0843, 0.1286, 0.0541, 0.1215, 0.0685, 0.0682, 0.1124,
        0.0591, 0.0707, 0.0575, 0.0299, 0.0328], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,184][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0559, 0.0663, 0.0680, 0.0755, 0.0780, 0.0713, 0.0779, 0.0762, 0.0708,
        0.0795, 0.0775, 0.0627, 0.0664, 0.0738], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,185][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0088, 0.0147, 0.0192, 0.0164, 0.0189, 0.0246, 0.0417, 0.0719, 0.0555,
        0.1806, 0.1052, 0.0523, 0.2277, 0.1625], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,185][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0445, 0.0679, 0.0561, 0.0727, 0.0550, 0.0438, 0.0508, 0.0871, 0.0718,
        0.0792, 0.0724, 0.1200, 0.0541, 0.0587, 0.0658], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,186][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0672, 0.0624, 0.0728, 0.0667, 0.0589, 0.0637, 0.0674, 0.0671, 0.0666,
        0.0710, 0.0704, 0.0627, 0.0600, 0.0752, 0.0678], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,186][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0741, 0.0203, 0.0405, 0.0674, 0.0476, 0.1824, 0.0591, 0.1163, 0.0936,
        0.0328, 0.0432, 0.1002, 0.0269, 0.0830, 0.0124], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,186][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0145, 0.0309, 0.0678, 0.0475, 0.0795, 0.0434, 0.0910, 0.1346, 0.1110,
        0.0388, 0.0427, 0.0981, 0.0932, 0.0814, 0.0255], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,187][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0518, 0.0465, 0.0239, 0.0760, 0.0619, 0.0678, 0.0676, 0.0640, 0.0900,
        0.0953, 0.0858, 0.0629, 0.0650, 0.0720, 0.0696], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,188][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.0706e-04, 1.6973e-06, 7.3021e-06, 2.8445e-05, 1.7431e-05, 3.2793e-05,
        1.2044e-04, 3.5570e-05, 1.6374e-04, 3.0400e-02, 2.6771e-02, 1.4977e-02,
        1.4077e-03, 3.2619e-02, 8.9321e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,190][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0237, 0.0390, 0.0618, 0.0395, 0.1095, 0.0649, 0.0426, 0.0671, 0.0932,
        0.0694, 0.0398, 0.0960, 0.1117, 0.1045, 0.0372], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,192][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0063, 0.0002, 0.0766, 0.0015, 0.0853, 0.0713, 0.1978, 0.0666, 0.0371,
        0.0018, 0.0018, 0.0463, 0.1683, 0.0813, 0.1579], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,193][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0573, 0.0576, 0.0559, 0.0724, 0.0336, 0.1684, 0.0529, 0.0404, 0.0732,
        0.0496, 0.0458, 0.0437, 0.0251, 0.2111, 0.0131], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,195][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1095, 0.0518, 0.0443, 0.0876, 0.0501, 0.1054, 0.0897, 0.0806, 0.0903,
        0.0423, 0.0443, 0.0429, 0.0230, 0.1212, 0.0171], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,197][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0647, 0.0628, 0.0607, 0.0717, 0.0714, 0.0668, 0.0710, 0.0703, 0.0639,
        0.0735, 0.0737, 0.0575, 0.0610, 0.0684, 0.0626], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,199][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0087, 0.0084, 0.0107, 0.0109, 0.0109, 0.0139, 0.0243, 0.0416, 0.0367,
        0.0970, 0.0809, 0.0316, 0.1397, 0.1238, 0.3609], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,227][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:03,228][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,230][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,230][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,230][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,231][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,231][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,231][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,232][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,232][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,232][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,232][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,233][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,233][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4001, 0.5999], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,233][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8826, 0.1174], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,234][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1262, 0.8738], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,234][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,234][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0455, 0.9545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,235][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5223, 0.4777], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,235][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,235][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1452, 0.8548], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,236][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,237][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,239][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2425, 0.7575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,240][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,241][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.2376, 0.3965, 0.3660], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,242][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.4549, 0.1695, 0.3757], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,242][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([3.2429e-04, 7.9152e-02, 9.2052e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,242][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0010, 0.1512, 0.8478], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,243][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0027, 0.0851, 0.9122], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,243][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.2671, 0.3320, 0.4009], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,243][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0915, 0.1700, 0.7385], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,244][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0108, 0.1183, 0.8709], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,244][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0024, 0.2025, 0.7950], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,244][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([7.8426e-05, 2.2763e-01, 7.7229e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,245][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0781, 0.4147, 0.5073], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,245][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0242, 0.5192, 0.4566], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,246][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1490, 0.2939, 0.2973, 0.2598], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,247][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4709, 0.1074, 0.1355, 0.2862], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,248][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.9171e-05, 1.1610e-03, 9.8438e-01, 1.4443e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,249][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.2127e-04, 3.5528e-02, 5.4973e-01, 4.1432e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,251][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0030, 0.0527, 0.6620, 0.2824], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,252][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2187, 0.2324, 0.2843, 0.2647], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,254][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0598, 0.0746, 0.3605, 0.5051], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,256][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0077, 0.0656, 0.5785, 0.3483], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,257][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0015, 0.0898, 0.4364, 0.4723], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,258][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.1914e-05, 2.3880e-02, 4.5578e-01, 5.2033e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,260][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0438, 0.2381, 0.3230, 0.3951], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,262][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0184, 0.3889, 0.3260, 0.2667], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,263][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.1235, 0.2256, 0.2173, 0.2917, 0.1418], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,264][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.4594, 0.1095, 0.1749, 0.2020, 0.0542], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,265][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([1.7911e-05, 1.2358e-03, 4.4695e-01, 1.7425e-01, 3.7755e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,265][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([7.1869e-05, 7.8004e-03, 1.5618e-01, 2.4517e-01, 5.9077e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,265][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([5.9656e-04, 2.4647e-02, 2.0955e-01, 1.3618e-01, 6.2902e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,266][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.1436, 0.1840, 0.2222, 0.2197, 0.2305], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,266][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0268, 0.0584, 0.1548, 0.3860, 0.3741], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,266][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0047, 0.0450, 0.2722, 0.1567, 0.5214], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,267][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([2.5471e-04, 2.4074e-02, 2.5893e-01, 3.2533e-01, 3.9141e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,267][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([5.0752e-06, 1.7609e-02, 2.0451e-01, 5.7050e-01, 2.0738e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,267][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0240, 0.1507, 0.2274, 0.3141, 0.2838], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,268][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0138, 0.2563, 0.2389, 0.2504, 0.2406], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,268][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0968, 0.2033, 0.2284, 0.2127, 0.1784, 0.0804], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,269][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5101, 0.0547, 0.0949, 0.2097, 0.0498, 0.0808], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,270][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.8682e-06, 2.8850e-04, 2.6595e-01, 4.8301e-02, 6.7347e-01, 1.1987e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,271][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([6.7326e-05, 7.3401e-03, 7.8496e-02, 1.4012e-01, 6.4394e-01, 1.3004e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,273][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0009, 0.0163, 0.1908, 0.0884, 0.5712, 0.1325], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,274][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1371, 0.1495, 0.1824, 0.1740, 0.1893, 0.1675], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,275][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0238, 0.0500, 0.1495, 0.2769, 0.2581, 0.2416], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,277][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0025, 0.0263, 0.1914, 0.1027, 0.3820, 0.2950], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,278][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.6160e-04, 2.0254e-02, 8.9766e-02, 2.1958e-01, 3.2325e-01, 3.4699e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,279][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.0741e-06, 4.5989e-03, 5.0777e-02, 1.7431e-01, 4.2038e-01, 3.4994e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,281][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0178, 0.1105, 0.1599, 0.2159, 0.2211, 0.2749], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,282][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0108, 0.2274, 0.1872, 0.1455, 0.2063, 0.2228], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,284][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0812, 0.1482, 0.1411, 0.2456, 0.1607, 0.1032, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,286][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3236, 0.0612, 0.1177, 0.1698, 0.0600, 0.1127, 0.1550],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,287][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.0924e-06, 2.0608e-04, 1.2064e-01, 6.6079e-02, 5.6858e-01, 2.2271e-01,
        2.1782e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,287][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.3317e-05, 3.0777e-03, 5.2392e-02, 8.1677e-02, 3.0510e-01, 1.6849e-01,
        3.8920e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,288][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0006, 0.0148, 0.1642, 0.0765, 0.5014, 0.1287, 0.1137],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,288][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1123, 0.1292, 0.1556, 0.1510, 0.1628, 0.1496, 0.1396],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,289][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0141, 0.0222, 0.1061, 0.1457, 0.2041, 0.1462, 0.3617],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,289][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0022, 0.0198, 0.1364, 0.0816, 0.2811, 0.2227, 0.2562],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,289][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.5669e-05, 3.3346e-03, 2.9831e-02, 6.6284e-02, 9.7465e-02, 6.0546e-01,
        1.9757e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,290][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.9396e-07, 1.3960e-03, 2.1595e-02, 4.8171e-02, 1.5560e-01, 3.3597e-01,
        4.3726e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,290][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0163, 0.0815, 0.1193, 0.1612, 0.1495, 0.1787, 0.2935],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,290][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0106, 0.1610, 0.1288, 0.1238, 0.1490, 0.1713, 0.2556],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,291][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0917, 0.1399, 0.1129, 0.1723, 0.1085, 0.0741, 0.1437, 0.1570],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,291][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2794, 0.0148, 0.0308, 0.2111, 0.0256, 0.0363, 0.3522, 0.0497],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,292][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([1.6442e-06, 2.6439e-05, 1.1779e-01, 5.4186e-03, 3.9135e-01, 9.1463e-02,
        2.0547e-01, 1.8848e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,293][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([4.5810e-06, 2.9060e-04, 8.8372e-03, 1.1161e-02, 5.7056e-02, 3.1366e-02,
        3.9426e-01, 4.9703e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,294][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([3.5419e-04, 1.0261e-02, 8.3412e-02, 5.1927e-02, 2.2174e-01, 8.5671e-02,
        8.6665e-02, 4.5997e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,295][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0955, 0.1136, 0.1364, 0.1330, 0.1437, 0.1328, 0.1258, 0.1193],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,297][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0112, 0.0166, 0.0380, 0.0813, 0.0977, 0.0943, 0.2258, 0.4351],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,298][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0021, 0.0189, 0.1037, 0.0620, 0.2066, 0.1575, 0.1814, 0.2677],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,299][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([1.9509e-05, 9.2520e-04, 5.4698e-03, 1.0684e-02, 5.8045e-02, 1.0991e-01,
        1.5219e-01, 6.6275e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,300][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.3483e-07, 1.0844e-04, 2.7225e-03, 4.8862e-03, 1.1929e-02, 4.9754e-02,
        1.4476e-01, 7.8584e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,302][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0079, 0.0485, 0.0647, 0.0986, 0.0854, 0.1068, 0.1709, 0.4173],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,304][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0092, 0.1099, 0.0837, 0.0781, 0.0968, 0.0978, 0.1478, 0.3765],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,305][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0654, 0.1248, 0.1370, 0.1372, 0.0797, 0.0852, 0.0907, 0.2112, 0.0688],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,307][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0906, 0.0083, 0.0392, 0.1584, 0.0301, 0.0595, 0.4559, 0.0475, 0.1107],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,308][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([2.9169e-07, 1.0860e-05, 5.3121e-02, 2.4766e-03, 1.1075e-01, 1.1295e-02,
        4.2773e-02, 6.2582e-01, 1.5375e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,309][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.0275e-06, 2.3111e-04, 4.9125e-03, 6.8587e-03, 3.2282e-02, 3.1216e-02,
        1.2205e-01, 5.1523e-01, 2.8722e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,310][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([1.6201e-04, 5.4936e-03, 4.4711e-02, 3.1641e-02, 1.2557e-01, 5.3629e-02,
        5.7502e-02, 3.1285e-01, 3.6845e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,311][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0861, 0.1015, 0.1213, 0.1187, 0.1269, 0.1176, 0.1122, 0.1086, 0.1071],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,311][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0080, 0.0088, 0.0321, 0.0551, 0.0635, 0.0527, 0.1692, 0.3621, 0.2487],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,311][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0016, 0.0139, 0.0789, 0.0475, 0.1595, 0.1215, 0.1406, 0.2072, 0.2293],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,312][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.5034e-06, 5.2346e-04, 6.3930e-03, 8.6397e-03, 1.3951e-02, 1.1493e-01,
        1.0379e-01, 5.3202e-01, 2.1975e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,312][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.0582e-08, 5.0144e-05, 1.5380e-03, 1.9578e-03, 5.8742e-03, 1.5364e-02,
        3.3409e-02, 7.2795e-01, 2.1386e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,312][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0069, 0.0358, 0.0403, 0.0845, 0.0574, 0.0747, 0.1500, 0.2676, 0.2827],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,313][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0065, 0.0871, 0.0557, 0.0701, 0.0552, 0.0809, 0.1342, 0.2680, 0.2422],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,313][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0585, 0.0795, 0.1010, 0.1273, 0.1091, 0.0712, 0.0985, 0.1616, 0.0954,
        0.0979], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,314][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1591, 0.0266, 0.0442, 0.1300, 0.0335, 0.0606, 0.2208, 0.0709, 0.1528,
        0.1016], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,314][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.6090e-06, 1.1047e-06, 2.6086e-02, 5.6697e-03, 8.7823e-02, 1.4663e-02,
        2.8315e-02, 4.0316e-01, 2.8114e-01, 1.5314e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,315][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.5896e-06, 3.0499e-05, 1.2726e-03, 1.9510e-03, 8.4101e-03, 9.3603e-03,
        5.0974e-02, 1.8648e-01, 1.8729e-01, 5.5423e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,316][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([1.9276e-04, 4.3264e-03, 4.4179e-02, 2.4056e-02, 1.2935e-01, 3.7896e-02,
        3.6902e-02, 2.4148e-01, 3.8535e-01, 9.6272e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,318][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0820, 0.0906, 0.1088, 0.1081, 0.1143, 0.1074, 0.1024, 0.0981, 0.0990,
        0.0892], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,319][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0056, 0.0059, 0.0247, 0.0552, 0.0618, 0.0571, 0.1192, 0.2614, 0.1990,
        0.2101], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,320][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0018, 0.0125, 0.0641, 0.0415, 0.1262, 0.1002, 0.1125, 0.1608, 0.1767,
        0.2036], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,321][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([8.3323e-06, 7.7137e-05, 7.5882e-04, 3.1385e-03, 2.7718e-03, 3.0523e-02,
        4.0481e-02, 1.4442e-01, 3.0184e-01, 4.7599e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,322][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.3768e-08, 3.9200e-06, 2.4928e-04, 5.0025e-04, 1.8924e-03, 3.9881e-03,
        1.8580e-02, 1.1627e-01, 2.8102e-01, 5.7749e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,324][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0062, 0.0296, 0.0365, 0.0563, 0.0451, 0.0598, 0.0851, 0.1747, 0.1791,
        0.3277], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,326][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0057, 0.0595, 0.0484, 0.0476, 0.0507, 0.0589, 0.0913, 0.2248, 0.2017,
        0.2115], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,327][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0499, 0.0927, 0.0927, 0.0825, 0.1141, 0.0527, 0.0956, 0.1467, 0.0858,
        0.1159, 0.0716], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,330][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1464, 0.0252, 0.0374, 0.0912, 0.0291, 0.0500, 0.1581, 0.0378, 0.2011,
        0.0878, 0.1358], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,331][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.6616e-06, 3.7698e-06, 1.2982e-02, 1.0037e-04, 7.8417e-02, 2.3958e-03,
        9.4902e-03, 5.7314e-02, 5.3707e-02, 3.7482e-01, 4.1077e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,332][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0823e-06, 1.2439e-05, 3.4997e-04, 1.5364e-04, 2.6189e-03, 1.7147e-03,
        1.2081e-02, 3.9202e-02, 5.2095e-02, 2.2609e-01, 6.6568e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,332][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.7550e-04, 3.6020e-03, 4.1301e-02, 1.9531e-02, 1.2514e-01, 3.2219e-02,
        3.1246e-02, 2.0561e-01, 3.5179e-01, 8.1797e-02, 1.0759e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,334][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0740, 0.0840, 0.0987, 0.0958, 0.1041, 0.0986, 0.0947, 0.0904, 0.0916,
        0.0841, 0.0840], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,334][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0042, 0.0047, 0.0180, 0.0257, 0.0366, 0.0333, 0.0654, 0.1190, 0.1082,
        0.1261, 0.4588], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,334][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0019, 0.0119, 0.0522, 0.0361, 0.1000, 0.0812, 0.0908, 0.1255, 0.1377,
        0.1609, 0.2018], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,335][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.0862e-06, 4.1499e-05, 2.2301e-04, 2.3249e-04, 7.3696e-04, 7.8413e-03,
        9.5730e-03, 3.5480e-02, 5.6727e-02, 2.6959e-01, 6.1955e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,335][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.3065e-09, 1.6013e-06, 5.3362e-05, 3.4584e-05, 3.3129e-04, 9.2838e-04,
        3.0232e-03, 2.3164e-02, 4.9868e-02, 2.4767e-01, 6.7492e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,335][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0041, 0.0238, 0.0294, 0.0370, 0.0362, 0.0431, 0.0601, 0.1089, 0.1278,
        0.2417, 0.2878], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,336][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0063, 0.0624, 0.0456, 0.0333, 0.0471, 0.0545, 0.0745, 0.1795, 0.1658,
        0.2009, 0.1301], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,336][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0365, 0.0794, 0.0779, 0.1128, 0.0589, 0.0474, 0.0628, 0.1177, 0.0750,
        0.1241, 0.1177, 0.0899], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,337][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.1076, 0.0144, 0.0158, 0.2006, 0.0111, 0.0484, 0.1665, 0.0263, 0.0438,
        0.0704, 0.2710, 0.0239], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,337][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([2.8757e-07, 3.0226e-07, 2.1623e-04, 9.3824e-05, 1.6342e-03, 1.1407e-04,
        1.2071e-03, 1.7670e-03, 6.7969e-03, 5.6443e-02, 6.7471e-01, 2.5702e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,338][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([3.2464e-07, 7.2876e-06, 1.4610e-04, 1.1222e-04, 8.7448e-04, 7.1997e-04,
        4.0967e-03, 9.1211e-03, 1.6407e-02, 1.1299e-01, 4.5454e-01, 4.0098e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,339][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([1.2842e-04, 3.7222e-03, 2.5744e-02, 1.7147e-02, 7.5996e-02, 2.6861e-02,
        2.7146e-02, 1.7903e-01, 2.2908e-01, 7.2742e-02, 9.0611e-02, 2.5179e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,341][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0638, 0.0765, 0.0908, 0.0897, 0.0963, 0.0901, 0.0864, 0.0829, 0.0842,
        0.0780, 0.0798, 0.0815], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,342][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.0028, 0.0085, 0.0180, 0.0220, 0.0254, 0.0493, 0.0827, 0.0778,
        0.0968, 0.3319, 0.2828], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,344][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0016, 0.0106, 0.0412, 0.0284, 0.0785, 0.0620, 0.0705, 0.0985, 0.1075,
        0.1280, 0.1622, 0.2110], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,344][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([8.2274e-07, 2.4172e-05, 8.9220e-05, 2.1776e-04, 3.9212e-04, 1.5749e-03,
        2.9918e-03, 1.1899e-02, 2.1420e-02, 1.2038e-01, 5.8118e-01, 2.5983e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,346][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([2.5911e-09, 8.9602e-07, 1.2375e-05, 2.5140e-05, 8.8687e-05, 2.2600e-04,
        8.8087e-04, 7.5419e-03, 1.4391e-02, 9.2723e-02, 4.7695e-01, 4.0716e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,347][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0024, 0.0159, 0.0197, 0.0261, 0.0248, 0.0318, 0.0451, 0.0856, 0.1064,
        0.2159, 0.2339, 0.1924], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,349][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0060, 0.0590, 0.0419, 0.0321, 0.0377, 0.0485, 0.0657, 0.1626, 0.1536,
        0.1798, 0.1151, 0.0980], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,350][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0399, 0.0734, 0.0671, 0.0950, 0.0465, 0.0492, 0.0778, 0.1248, 0.0564,
        0.1002, 0.0971, 0.1260, 0.0466], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,353][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.1616, 0.0365, 0.0671, 0.0756, 0.0207, 0.0759, 0.0767, 0.0278, 0.0809,
        0.0766, 0.0884, 0.1881, 0.0243], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,354][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([4.6403e-09, 5.4185e-09, 7.8581e-06, 1.3598e-06, 5.5518e-06, 4.8080e-06,
        1.2446e-05, 1.7232e-04, 2.2300e-04, 1.3192e-03, 1.7530e-02, 2.5024e-01,
        7.3049e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,355][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([5.9697e-08, 8.2467e-07, 2.2009e-05, 2.1358e-05, 7.3656e-05, 1.5351e-04,
        7.8170e-04, 2.8961e-03, 5.4089e-03, 2.2351e-02, 1.0347e-01, 2.6328e-01,
        6.0154e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,356][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([4.6091e-05, 2.2915e-03, 1.6809e-02, 1.2444e-02, 5.4822e-02, 1.9208e-02,
        1.9816e-02, 1.3468e-01, 1.8419e-01, 5.3239e-02, 7.3172e-02, 2.1895e-01,
        2.1034e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,357][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0554, 0.0702, 0.0818, 0.0830, 0.0859, 0.0840, 0.0811, 0.0789, 0.0793,
        0.0731, 0.0751, 0.0797, 0.0724], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,357][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0012, 0.0024, 0.0051, 0.0145, 0.0123, 0.0196, 0.0296, 0.0510, 0.0522,
        0.0774, 0.2541, 0.2631, 0.2175], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,357][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0013, 0.0094, 0.0336, 0.0228, 0.0627, 0.0484, 0.0557, 0.0780, 0.0847,
        0.1014, 0.1311, 0.1726, 0.1982], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,358][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([4.9929e-07, 5.4087e-06, 7.1677e-05, 6.6913e-05, 6.7412e-05, 9.4147e-04,
        1.4644e-03, 6.6532e-03, 1.4583e-02, 3.2335e-02, 1.4931e-01, 5.7248e-01,
        2.2202e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,358][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([1.8229e-09, 3.4747e-07, 5.8360e-06, 1.0162e-05, 5.5954e-06, 1.3300e-04,
        4.1146e-04, 2.4575e-03, 4.6961e-03, 3.2210e-02, 1.8523e-01, 5.4748e-01,
        2.2735e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,359][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0015, 0.0115, 0.0164, 0.0228, 0.0183, 0.0267, 0.0372, 0.0677, 0.0822,
        0.1473, 0.2087, 0.1785, 0.1811], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,359][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0037, 0.0362, 0.0298, 0.0277, 0.0259, 0.0383, 0.0526, 0.1421, 0.1115,
        0.1256, 0.1095, 0.0923, 0.2049], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,360][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0341, 0.0644, 0.0775, 0.0777, 0.0655, 0.0546, 0.0511, 0.0997, 0.0777,
        0.0778, 0.0765, 0.1189, 0.0652, 0.0593], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,360][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1783, 0.0201, 0.0312, 0.0944, 0.0136, 0.0221, 0.0675, 0.0423, 0.0968,
        0.0616, 0.1368, 0.1009, 0.0156, 0.1187], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,361][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([2.6157e-09, 4.4705e-09, 3.4901e-06, 1.0467e-06, 1.1088e-05, 8.4432e-06,
        6.0101e-06, 1.2836e-05, 4.4809e-05, 7.8303e-04, 8.6177e-03, 7.5468e-02,
        9.1450e-01, 5.4609e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,362][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.3905e-07, 1.5478e-06, 1.2976e-05, 3.4339e-05, 7.6445e-05, 2.3035e-05,
        3.8218e-04, 1.9524e-03, 2.5872e-03, 2.3514e-02, 1.4531e-01, 2.2908e-01,
        4.6551e-01, 1.3152e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,363][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([1.0796e-04, 2.3079e-03, 1.8207e-02, 1.1418e-02, 5.1861e-02, 1.8191e-02,
        1.8085e-02, 1.1714e-01, 1.5564e-01, 4.2378e-02, 5.3875e-02, 1.7365e-01,
        2.1228e-01, 1.2487e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,365][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0636, 0.0688, 0.0794, 0.0791, 0.0823, 0.0775, 0.0749, 0.0723, 0.0713,
        0.0675, 0.0685, 0.0707, 0.0661, 0.0581], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,366][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0015, 0.0017, 0.0063, 0.0110, 0.0126, 0.0129, 0.0268, 0.0446, 0.0360,
        0.0517, 0.1964, 0.2654, 0.2133, 0.1197], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,367][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0011, 0.0073, 0.0277, 0.0184, 0.0527, 0.0403, 0.0458, 0.0654, 0.0708,
        0.0847, 0.1091, 0.1450, 0.1673, 0.1645], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,369][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([9.0624e-07, 9.2218e-06, 4.2948e-05, 7.3334e-05, 9.2581e-05, 3.6930e-04,
        6.8648e-04, 4.4650e-03, 4.1130e-03, 5.0624e-02, 1.5053e-01, 2.1191e-01,
        2.3342e-01, 3.4366e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,370][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.0222e-09, 1.5843e-07, 4.5511e-06, 5.7356e-06, 1.7489e-05, 1.9951e-05,
        1.0531e-04, 6.8728e-04, 1.8245e-03, 2.2256e-02, 1.0727e-01, 1.6506e-01,
        5.6962e-01, 1.3313e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,372][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0016, 0.0109, 0.0134, 0.0199, 0.0146, 0.0202, 0.0325, 0.0542, 0.0584,
        0.1291, 0.1600, 0.1296, 0.1421, 0.2134], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,373][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0058, 0.0495, 0.0319, 0.0246, 0.0250, 0.0353, 0.0487, 0.1185, 0.0910,
        0.1289, 0.0801, 0.0833, 0.1563, 0.1210], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,375][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0377, 0.0602, 0.0523, 0.0845, 0.0602, 0.0424, 0.0506, 0.0916, 0.0654,
        0.0772, 0.0829, 0.1161, 0.0589, 0.0554, 0.0646], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,377][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0747, 0.0173, 0.0327, 0.0943, 0.0292, 0.0256, 0.1499, 0.0268, 0.1280,
        0.0796, 0.1214, 0.0555, 0.0273, 0.0778, 0.0599], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,378][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.7064e-08, 7.5829e-09, 4.0671e-06, 1.3986e-06, 1.8280e-05, 1.0619e-05,
        1.1514e-05, 6.7727e-05, 1.8412e-04, 5.8181e-04, 6.0187e-03, 2.6041e-02,
        9.4958e-01, 1.5318e-02, 2.1580e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,379][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.3192e-08, 3.1191e-07, 6.0464e-06, 4.3055e-06, 2.1700e-05, 9.3026e-06,
        1.2893e-04, 3.9635e-04, 5.6155e-04, 4.7481e-03, 1.8908e-02, 4.7459e-02,
        1.5946e-01, 3.1159e-01, 4.5671e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,380][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.5344e-05, 2.0953e-03, 1.7402e-02, 9.4044e-03, 5.1236e-02, 1.5783e-02,
        1.3878e-02, 9.8106e-02, 1.4850e-01, 3.5394e-02, 4.5479e-02, 1.4595e-01,
        2.2901e-01, 1.2326e-01, 6.4412e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,380][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0628, 0.0647, 0.0754, 0.0745, 0.0776, 0.0738, 0.0699, 0.0675, 0.0675,
        0.0628, 0.0640, 0.0667, 0.0621, 0.0560, 0.0545], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,381][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0014, 0.0014, 0.0045, 0.0067, 0.0085, 0.0080, 0.0188, 0.0234, 0.0264,
        0.0388, 0.1122, 0.1266, 0.1266, 0.1238, 0.3728], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,381][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0010, 0.0065, 0.0237, 0.0165, 0.0452, 0.0352, 0.0397, 0.0557, 0.0601,
        0.0726, 0.0939, 0.1226, 0.1406, 0.1407, 0.1460], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,381][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.1393e-07, 1.2106e-06, 6.0731e-06, 8.0998e-06, 1.3592e-05, 9.3097e-05,
        8.0660e-05, 1.1719e-04, 7.7826e-04, 6.0769e-03, 2.4688e-02, 3.7564e-02,
        4.2620e-02, 6.1773e-01, 2.7023e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,382][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.3100e-10, 2.7184e-08, 6.1320e-07, 6.2912e-07, 3.0769e-06, 2.9962e-06,
        1.6770e-05, 1.7882e-04, 3.2820e-04, 2.8529e-03, 1.2680e-02, 4.4221e-02,
        1.0787e-01, 1.4102e-01, 6.9082e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,382][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0015, 0.0077, 0.0099, 0.0128, 0.0106, 0.0150, 0.0197, 0.0377, 0.0416,
        0.0790, 0.1002, 0.0946, 0.0964, 0.1709, 0.3024], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,383][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0057, 0.0344, 0.0240, 0.0208, 0.0200, 0.0276, 0.0375, 0.0878, 0.0719,
        0.0935, 0.0722, 0.0661, 0.1316, 0.1152, 0.1916], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,384][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:03,386][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[19950],
        [ 7255],
        [ 1292],
        [ 1253],
        [13157],
        [10476],
        [14595],
        [16329],
        [14673],
        [10208],
        [ 8586],
        [16553],
        [32116],
        [15081],
        [20622]], device='cuda:0')
[2024-07-24 10:17:03,388][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[30484],
        [24703],
        [ 9940],
        [ 7015],
        [27860],
        [28272],
        [40755],
        [32417],
        [34977],
        [22633],
        [24912],
        [37024],
        [46924],
        [34879],
        [45944]], device='cuda:0')
[2024-07-24 10:17:03,389][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40739],
        [42577],
        [38840],
        [40714],
        [41685],
        [40586],
        [41657],
        [42063],
        [40457],
        [41493],
        [42191],
        [42421],
        [42461],
        [41526],
        [41944]], device='cuda:0')
[2024-07-24 10:17:03,391][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32340],
        [28623],
        [33515],
        [33857],
        [34636],
        [34489],
        [33729],
        [32090],
        [30438],
        [29211],
        [28899],
        [29537],
        [29641],
        [29834],
        [30047]], device='cuda:0')
[2024-07-24 10:17:03,392][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24808],
        [21689],
        [30328],
        [39291],
        [32032],
        [29075],
        [18583],
        [22211],
        [23324],
        [23393],
        [27403],
        [21116],
        [23725],
        [20906],
        [22512]], device='cuda:0')
[2024-07-24 10:17:03,394][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[2873],
        [3509],
        [5286],
        [4092],
        [6558],
        [6286],
        [7129],
        [9003],
        [9586],
        [8612],
        [8056],
        [6957],
        [6629],
        [5958],
        [6232]], device='cuda:0')
[2024-07-24 10:17:03,395][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14316],
        [17038],
        [17064],
        [20585],
        [19778],
        [21051],
        [19817],
        [19988],
        [17353],
        [18023],
        [20850],
        [20020],
        [16772],
        [18229],
        [17667]], device='cuda:0')
[2024-07-24 10:17:03,397][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[19658],
        [21306],
        [17653],
        [19479],
        [19831],
        [19850],
        [27939],
        [28423],
        [29441],
        [37944],
        [32701],
        [32499],
        [30246],
        [31693],
        [28953]], device='cuda:0')
[2024-07-24 10:17:03,399][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7873],
        [ 5106],
        [ 8529],
        [ 6885],
        [ 9882],
        [ 9700],
        [ 8776],
        [ 9698],
        [11260],
        [10458],
        [10041],
        [10729],
        [10866],
        [10134],
        [ 9659]], device='cuda:0')
[2024-07-24 10:17:03,400][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 6263],
        [ 9935],
        [14934],
        [13323],
        [12059],
        [10831],
        [10309],
        [10013],
        [ 9875],
        [ 9502],
        [ 9279],
        [ 9436],
        [ 9063],
        [ 8987],
        [ 8490]], device='cuda:0')
[2024-07-24 10:17:03,402][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19520],
        [16368],
        [17416],
        [20025],
        [19302],
        [18405],
        [19493],
        [19914],
        [20612],
        [19715],
        [19876],
        [18243],
        [19384],
        [19272],
        [18224]], device='cuda:0')
[2024-07-24 10:17:03,403][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[46454],
        [46617],
        [45004],
        [41510],
        [43735],
        [45007],
        [44362],
        [45744],
        [45473],
        [45560],
        [45534],
        [46621],
        [46609],
        [46661],
        [46927]], device='cuda:0')
[2024-07-24 10:17:03,404][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14040],
        [22312],
        [21832],
        [24038],
        [22771],
        [23064],
        [24380],
        [25594],
        [25871],
        [25258],
        [25226],
        [24685],
        [24019],
        [24215],
        [24208]], device='cuda:0')
[2024-07-24 10:17:03,405][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14078],
        [ 2093],
        [ 1299],
        [ 1239],
        [ 1791],
        [ 1650],
        [ 2153],
        [ 2875],
        [ 3933],
        [ 4242],
        [ 4334],
        [ 3978],
        [ 4905],
        [ 4595],
        [ 6009]], device='cuda:0')
[2024-07-24 10:17:03,406][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17330],
        [35122],
        [12625],
        [24454],
        [33007],
        [45716],
        [32099],
        [42395],
        [45556],
        [43842],
        [45213],
        [35317],
        [37406],
        [39770],
        [29988]], device='cuda:0')
[2024-07-24 10:17:03,407][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[26399],
        [26746],
        [27414],
        [28335],
        [29554],
        [30192],
        [30923],
        [31219],
        [31308],
        [30637],
        [30249],
        [30127],
        [30600],
        [31775],
        [31583]], device='cuda:0')
[2024-07-24 10:17:03,408][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26232],
        [27218],
        [46027],
        [32421],
        [37303],
        [31411],
        [32991],
        [23877],
        [26396],
        [27349],
        [26429],
        [20351],
        [23001],
        [22557],
        [23481]], device='cuda:0')
[2024-07-24 10:17:03,410][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 9917],
        [ 7654],
        [20102],
        [21391],
        [27919],
        [30581],
        [27718],
        [18485],
        [13848],
        [16682],
        [10741],
        [26537],
        [38631],
        [38975],
        [38971]], device='cuda:0')
[2024-07-24 10:17:03,412][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[29450],
        [23952],
        [29163],
        [32846],
        [29403],
        [26443],
        [26187],
        [22355],
        [21450],
        [23419],
        [28270],
        [27183],
        [29393],
        [30589],
        [27225]], device='cuda:0')
[2024-07-24 10:17:03,413][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[47762],
        [46366],
        [45277],
        [45206],
        [44966],
        [45192],
        [45188],
        [45248],
        [44467],
        [44378],
        [44283],
        [44702],
        [44668],
        [44837],
        [44809]], device='cuda:0')
[2024-07-24 10:17:03,414][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17997],
        [17573],
        [17300],
        [17219],
        [16963],
        [16912],
        [16883],
        [16768],
        [16842],
        [16923],
        [16922],
        [16811],
        [16745],
        [16727],
        [16722]], device='cuda:0')
[2024-07-24 10:17:03,416][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[ 1660],
        [ 2126],
        [16637],
        [19330],
        [15753],
        [14195],
        [13867],
        [18038],
        [17633],
        [17037],
        [25192],
        [27069],
        [23001],
        [25296],
        [26566]], device='cuda:0')
[2024-07-24 10:17:03,418][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22743],
        [27761],
        [24370],
        [23696],
        [23007],
        [22635],
        [22459],
        [22312],
        [22132],
        [22017],
        [21787],
        [21643],
        [21532],
        [21345],
        [21150]], device='cuda:0')
[2024-07-24 10:17:03,419][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22224],
        [27891],
        [35255],
        [27259],
        [34643],
        [21426],
        [10313],
        [26339],
        [26561],
        [27840],
        [25739],
        [22975],
        [24990],
        [25409],
        [20146]], device='cuda:0')
[2024-07-24 10:17:03,421][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17945],
        [15636],
        [17474],
        [18432],
        [17283],
        [16296],
        [17356],
        [17141],
        [18180],
        [15369],
        [16799],
        [19170],
        [20298],
        [17027],
        [20102]], device='cuda:0')
[2024-07-24 10:17:03,422][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18315],
        [12194],
        [18990],
        [21887],
        [24292],
        [24627],
        [22030],
        [22835],
        [21534],
        [17847],
        [19456],
        [20523],
        [22311],
        [22028],
        [20416]], device='cuda:0')
[2024-07-24 10:17:03,424][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[34460],
        [16764],
        [18888],
        [19894],
        [21328],
        [22662],
        [22257],
        [21971],
        [16633],
        [16625],
        [16184],
        [15023],
        [15261],
        [15424],
        [15020]], device='cuda:0')
[2024-07-24 10:17:03,426][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[25802],
        [28193],
        [13088],
        [16567],
        [14661],
        [17941],
        [20409],
        [20598],
        [21309],
        [21675],
        [20739],
        [18357],
        [15155],
        [15459],
        [16166]], device='cuda:0')
[2024-07-24 10:17:03,427][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[27413],
        [23503],
        [ 7027],
        [17821],
        [11349],
        [ 7207],
        [10247],
        [17836],
        [12694],
        [18816],
        [15877],
        [24826],
        [19870],
        [20360],
        [20105]], device='cuda:0')
[2024-07-24 10:17:03,428][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423],
        [19423]], device='cuda:0')
[2024-07-24 10:17:03,459][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:03,459][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,460][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,460][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,460][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,460][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,461][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,461][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,461][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,462][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,462][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,462][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,462][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,463][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8694, 0.1306], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,463][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0824, 0.9176], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,463][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2481, 0.7519], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,464][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5736, 0.4264], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,464][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4298, 0.5702], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,464][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5324, 0.4676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,465][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9136, 0.0864], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,465][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4494, 0.5506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,465][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2829, 0.7171], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,466][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5507, 0.4493], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,466][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5217, 0.4783], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,466][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3438, 0.6562], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,467][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.8392, 0.0726, 0.0882], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,467][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0107, 0.1489, 0.8403], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,467][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.2163, 0.7342, 0.0495], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,468][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.2882, 0.2034, 0.5084], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,469][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.2633, 0.3417, 0.3951], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,470][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.3509, 0.3115, 0.3375], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,471][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.2250, 0.0778, 0.6971], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,473][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.3306, 0.3891, 0.2803], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,474][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2631, 0.5533, 0.1836], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,476][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.3650, 0.0873, 0.5477], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,476][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.3438, 0.3187, 0.3375], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,477][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.2839, 0.5240, 0.1921], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,477][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7667, 0.0959, 0.0547, 0.0827], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,477][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0328, 0.0782, 0.3815, 0.5075], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,479][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1605, 0.5967, 0.1212, 0.1215], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,480][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1971, 0.1601, 0.4057, 0.2371], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,482][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1689, 0.2428, 0.2809, 0.3074], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,484][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2611, 0.2312, 0.2640, 0.2436], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,486][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0556, 0.0105, 0.9321, 0.0018], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,487][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2332, 0.2768, 0.2833, 0.2067], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,487][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1625, 0.3935, 0.2275, 0.2166], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,488][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0264, 0.0936, 0.8074, 0.0726], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,488][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2569, 0.2386, 0.2507, 0.2538], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,488][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1496, 0.4099, 0.2755, 0.1649], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,489][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.7151, 0.0715, 0.0394, 0.0574, 0.1166], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,489][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0107, 0.0421, 0.1627, 0.2946, 0.4899], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,489][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.1819, 0.5017, 0.0743, 0.1911, 0.0510], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,489][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1589, 0.1108, 0.2548, 0.1544, 0.3210], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,490][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1365, 0.1819, 0.2145, 0.2388, 0.2284], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,490][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.2118, 0.1871, 0.2042, 0.1984, 0.1986], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,490][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.1342, 0.0147, 0.6641, 0.0205, 0.1664], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,491][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.2002, 0.2273, 0.2219, 0.1826, 0.1680], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,491][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.1536, 0.3442, 0.1407, 0.2622, 0.0993], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,492][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0814, 0.0759, 0.6065, 0.0521, 0.1841], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,493][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.2074, 0.1908, 0.2008, 0.2044, 0.1966], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,495][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.1734, 0.3425, 0.1760, 0.2229, 0.0852], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,496][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.6195, 0.0884, 0.0452, 0.0715, 0.0688, 0.1066], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,498][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0070, 0.0133, 0.0402, 0.0995, 0.1685, 0.6715], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,499][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2314, 0.3618, 0.0952, 0.1636, 0.0802, 0.0678], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,501][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1156, 0.0887, 0.2170, 0.1286, 0.2714, 0.1787], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,502][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1014, 0.1485, 0.1674, 0.1946, 0.1856, 0.2026], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,504][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1764, 0.1554, 0.1708, 0.1657, 0.1657, 0.1659], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,505][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0099, 0.0019, 0.3685, 0.0028, 0.6156, 0.0012], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,507][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1639, 0.1968, 0.1847, 0.1548, 0.1797, 0.1201], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,509][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1257, 0.2887, 0.1241, 0.2103, 0.1105, 0.1407], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,510][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1608, 0.0733, 0.0623, 0.0141, 0.0197, 0.6699], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,511][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1730, 0.1600, 0.1687, 0.1708, 0.1657, 0.1619], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,511][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1909, 0.2783, 0.1216, 0.1772, 0.1040, 0.1279], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,511][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6344, 0.0939, 0.0533, 0.0689, 0.0551, 0.0554, 0.0390],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,511][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0037, 0.0067, 0.0180, 0.0495, 0.0819, 0.3562, 0.4841],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,512][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1081, 0.3677, 0.1190, 0.1551, 0.0689, 0.1211, 0.0601],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,512][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0918, 0.0771, 0.1794, 0.1115, 0.2285, 0.1530, 0.1587],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,512][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0872, 0.1287, 0.1427, 0.1692, 0.1589, 0.1743, 0.1390],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,513][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1490, 0.1317, 0.1469, 0.1408, 0.1432, 0.1433, 0.1451],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,513][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1177, 0.0121, 0.3338, 0.0197, 0.4956, 0.0183, 0.0029],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,513][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1399, 0.1722, 0.1657, 0.1310, 0.1521, 0.1186, 0.1204],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,514][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1026, 0.2425, 0.1376, 0.1864, 0.1193, 0.1563, 0.0552],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,514][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1301, 0.0016, 0.0100, 0.0018, 0.0030, 0.1609, 0.6926],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,515][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1475, 0.1369, 0.1441, 0.1468, 0.1415, 0.1386, 0.1447],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,516][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0801, 0.2691, 0.1722, 0.1232, 0.1557, 0.1288, 0.0708],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,518][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.7490, 0.0671, 0.0176, 0.0466, 0.0298, 0.0618, 0.0196, 0.0085],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,519][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0024, 0.0066, 0.0188, 0.0423, 0.0683, 0.2793, 0.3902, 0.1921],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,521][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1956, 0.3397, 0.0469, 0.1196, 0.0320, 0.0912, 0.1387, 0.0363],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,522][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0916, 0.0623, 0.1314, 0.0853, 0.1752, 0.1160, 0.1220, 0.2162],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,524][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0744, 0.1081, 0.1222, 0.1413, 0.1345, 0.1497, 0.1219, 0.1480],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,525][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1324, 0.1165, 0.1275, 0.1242, 0.1239, 0.1246, 0.1270, 0.1238],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,527][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1902, 0.0370, 0.2197, 0.0566, 0.2925, 0.0178, 0.0772, 0.1091],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,529][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1331, 0.1583, 0.1395, 0.1243, 0.1225, 0.1177, 0.1156, 0.0890],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,530][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0895, 0.2390, 0.0899, 0.1630, 0.0871, 0.1503, 0.0600, 0.1212],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,531][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([2.8248e-02, 2.3309e-05, 3.5755e-04, 2.8368e-05, 7.9666e-05, 3.0408e-03,
        4.0570e-02, 9.2765e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,533][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1285, 0.1189, 0.1262, 0.1287, 0.1241, 0.1221, 0.1269, 0.1245],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,533][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1001, 0.1824, 0.0859, 0.0948, 0.0895, 0.0834, 0.1442, 0.2196],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,534][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.6772, 0.0699, 0.0304, 0.0558, 0.0440, 0.0579, 0.0291, 0.0049, 0.0307],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,534][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0016, 0.0052, 0.0140, 0.0337, 0.0494, 0.2280, 0.3285, 0.1616, 0.1780],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,534][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0851, 0.3249, 0.0442, 0.1331, 0.0677, 0.0989, 0.1468, 0.0807, 0.0186],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,535][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0813, 0.0506, 0.1118, 0.0690, 0.1452, 0.0960, 0.1011, 0.1826, 0.1626],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,535][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0640, 0.0909, 0.1095, 0.1219, 0.1213, 0.1329, 0.1070, 0.1306, 0.1218],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,535][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1187, 0.1040, 0.1139, 0.1112, 0.1107, 0.1110, 0.1133, 0.1102, 0.1070],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,536][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0394, 0.0365, 0.2346, 0.0414, 0.2184, 0.0144, 0.0634, 0.3318, 0.0201],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,536][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1145, 0.1425, 0.1265, 0.1097, 0.1149, 0.1085, 0.1104, 0.0920, 0.0809],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,536][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0817, 0.1916, 0.0907, 0.1408, 0.0891, 0.1413, 0.0464, 0.1527, 0.0656],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,536][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([1.2696e-02, 1.2681e-05, 2.9067e-04, 1.7289e-05, 1.1215e-04, 1.7889e-03,
        1.4255e-02, 6.0555e-01, 3.6528e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,537][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1147, 0.1060, 0.1134, 0.1146, 0.1113, 0.1091, 0.1134, 0.1112, 0.1063],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,537][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0534, 0.1336, 0.0673, 0.0677, 0.0649, 0.0941, 0.0933, 0.3588, 0.0669],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,539][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5239, 0.0849, 0.0460, 0.0719, 0.0611, 0.0727, 0.0447, 0.0127, 0.0300,
        0.0519], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,541][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0023, 0.0033, 0.0082, 0.0218, 0.0356, 0.1418, 0.1850, 0.1054, 0.1329,
        0.3638], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,542][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0872, 0.2512, 0.0615, 0.1232, 0.0493, 0.0882, 0.1476, 0.0883, 0.0473,
        0.0561], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,544][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0598, 0.0459, 0.1071, 0.0661, 0.1340, 0.0913, 0.0968, 0.1671, 0.1499,
        0.0822], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,545][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0575, 0.0798, 0.1002, 0.1088, 0.1058, 0.1196, 0.0959, 0.1173, 0.1094,
        0.1057], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,547][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1034, 0.0915, 0.1052, 0.0972, 0.1029, 0.1030, 0.1033, 0.1018, 0.1004,
        0.0912], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,548][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([1.2760e-02, 3.6973e-04, 1.4759e-01, 2.0366e-03, 5.1224e-01, 3.7674e-03,
        4.3033e-02, 2.5993e-01, 1.6459e-02, 1.8139e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,550][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1001, 0.1171, 0.1170, 0.0908, 0.1085, 0.0884, 0.1007, 0.0861, 0.0956,
        0.0957], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,551][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0633, 0.1574, 0.0834, 0.1221, 0.0856, 0.1157, 0.0551, 0.1134, 0.0879,
        0.1163], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,552][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([6.8832e-04, 3.1251e-06, 1.6772e-04, 9.3625e-06, 6.8679e-05, 3.6374e-04,
        3.9754e-03, 7.8731e-01, 1.9830e-01, 9.1125e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,554][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1050, 0.0967, 0.1022, 0.1031, 0.0998, 0.0980, 0.1017, 0.0991, 0.0951,
        0.0993], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,555][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0469, 0.1222, 0.0777, 0.0826, 0.0562, 0.0809, 0.1175, 0.2144, 0.1312,
        0.0703], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,558][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4629, 0.0853, 0.0448, 0.0747, 0.0596, 0.0725, 0.0456, 0.0125, 0.0335,
        0.0561, 0.0526], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,559][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0027, 0.0026, 0.0083, 0.0168, 0.0354, 0.1098, 0.1532, 0.0892, 0.1220,
        0.2879, 0.1721], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,561][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0887, 0.3260, 0.0634, 0.0656, 0.0549, 0.0845, 0.1086, 0.0731, 0.0470,
        0.0637, 0.0245], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,561][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0539, 0.0411, 0.1002, 0.0599, 0.1263, 0.0842, 0.0896, 0.1560, 0.1381,
        0.0749, 0.0759], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,562][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0571, 0.0724, 0.0907, 0.0939, 0.0941, 0.1085, 0.0897, 0.1078, 0.1027,
        0.0960, 0.0871], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,562][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0942, 0.0838, 0.0965, 0.0884, 0.0947, 0.0951, 0.0950, 0.0937, 0.0925,
        0.0836, 0.0825], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,562][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([1.1621e-02, 1.6208e-03, 6.2417e-02, 1.7169e-04, 3.1975e-01, 8.5042e-03,
        1.8911e-01, 3.5815e-01, 2.9921e-02, 1.8122e-02, 6.1531e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,563][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0932, 0.1090, 0.1084, 0.0806, 0.0973, 0.0849, 0.0876, 0.0813, 0.0920,
        0.0896, 0.0761], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,563][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0572, 0.1529, 0.0839, 0.0951, 0.0844, 0.0971, 0.0503, 0.1013, 0.0827,
        0.1212, 0.0740], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,563][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.2975e-03, 4.5827e-06, 1.1377e-04, 3.9491e-06, 2.3837e-05, 4.3532e-04,
        4.2365e-03, 6.5651e-01, 2.7133e-01, 2.5938e-02, 4.0105e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,564][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0955, 0.0876, 0.0923, 0.0940, 0.0902, 0.0888, 0.0925, 0.0898, 0.0865,
        0.0905, 0.0924], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,564][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0404, 0.1471, 0.0914, 0.0517, 0.0620, 0.0621, 0.1005, 0.2082, 0.1308,
        0.0741, 0.0315], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,564][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.6029, 0.0680, 0.0359, 0.0561, 0.0530, 0.0514, 0.0224, 0.0065, 0.0244,
        0.0335, 0.0296, 0.0163], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,565][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0009, 0.0024, 0.0075, 0.0152, 0.0258, 0.1051, 0.1463, 0.0783, 0.0949,
        0.2827, 0.1684, 0.0724], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,565][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0760, 0.3700, 0.0303, 0.1261, 0.0266, 0.0560, 0.1160, 0.0500, 0.0175,
        0.0603, 0.0468, 0.0244], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,566][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0600, 0.0382, 0.0825, 0.0515, 0.1082, 0.0732, 0.0777, 0.1350, 0.1166,
        0.0655, 0.0667, 0.1249], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,568][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0527, 0.0654, 0.0798, 0.0843, 0.0839, 0.0958, 0.0809, 0.0958, 0.0916,
        0.0891, 0.0800, 0.1009], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,569][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0886, 0.0789, 0.0871, 0.0834, 0.0851, 0.0855, 0.0865, 0.0846, 0.0827,
        0.0783, 0.0773, 0.0819], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,571][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0564, 0.0401, 0.0757, 0.0167, 0.0358, 0.0632, 0.0538, 0.4160, 0.0239,
        0.1239, 0.0754, 0.0191], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,572][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0896, 0.1068, 0.0900, 0.0849, 0.0816, 0.0832, 0.0836, 0.0715, 0.0704,
        0.0890, 0.0824, 0.0669], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,574][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0536, 0.1594, 0.0553, 0.1187, 0.0547, 0.0908, 0.0352, 0.1021, 0.0595,
        0.1239, 0.0954, 0.0515], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,575][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.8904e-02, 1.0853e-05, 1.7171e-04, 7.9623e-06, 5.2437e-05, 8.5503e-04,
        3.5457e-03, 2.1221e-01, 8.2244e-02, 9.3490e-03, 1.5102e-02, 6.5755e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,577][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0873, 0.0799, 0.0847, 0.0865, 0.0832, 0.0816, 0.0851, 0.0828, 0.0794,
        0.0837, 0.0855, 0.0803], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,578][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0310, 0.0951, 0.0372, 0.0681, 0.0268, 0.0797, 0.0978, 0.2866, 0.0764,
        0.0638, 0.0412, 0.0965], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,581][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.3645, 0.0522, 0.0349, 0.0556, 0.1453, 0.0933, 0.0376, 0.0109, 0.0387,
        0.0438, 0.0416, 0.0306, 0.0509], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,582][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0005, 0.0019, 0.0051, 0.0120, 0.0185, 0.0933, 0.1352, 0.0718, 0.0864,
        0.2884, 0.1533, 0.0739, 0.0596], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,584][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0906, 0.2881, 0.0385, 0.1030, 0.0289, 0.0623, 0.1160, 0.0730, 0.0240,
        0.0554, 0.0435, 0.0509, 0.0260], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,584][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0504, 0.0342, 0.0690, 0.0451, 0.0924, 0.0636, 0.0669, 0.1193, 0.1043,
        0.0581, 0.0591, 0.1107, 0.1270], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,585][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0495, 0.0650, 0.0720, 0.0798, 0.0757, 0.0827, 0.0688, 0.0839, 0.0799,
        0.0801, 0.0768, 0.0895, 0.0963], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,585][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0831, 0.0736, 0.0798, 0.0782, 0.0776, 0.0777, 0.0793, 0.0773, 0.0754,
        0.0729, 0.0723, 0.0754, 0.0774], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,585][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.1007, 0.0116, 0.3208, 0.0154, 0.0857, 0.0228, 0.0353, 0.0861, 0.0250,
        0.0208, 0.0522, 0.0368, 0.1868], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,586][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0831, 0.0930, 0.0890, 0.0747, 0.0685, 0.0784, 0.0745, 0.0668, 0.0753,
        0.0806, 0.0724, 0.0782, 0.0653], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,586][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0633, 0.1473, 0.0554, 0.1147, 0.0413, 0.0773, 0.0376, 0.0927, 0.0542,
        0.1125, 0.0926, 0.0737, 0.0375], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,586][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([2.4325e-02, 6.6761e-06, 9.6406e-05, 4.6660e-06, 1.8818e-05, 4.7194e-04,
        3.9194e-03, 7.5243e-02, 3.7861e-02, 7.1588e-03, 1.0541e-02, 5.3528e-01,
        3.0508e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,587][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0809, 0.0745, 0.0783, 0.0797, 0.0771, 0.0754, 0.0784, 0.0766, 0.0732,
        0.0769, 0.0784, 0.0736, 0.0771], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,587][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0461, 0.1139, 0.0560, 0.0676, 0.0276, 0.0823, 0.1087, 0.1758, 0.0560,
        0.0609, 0.0391, 0.1436, 0.0224], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,588][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3355, 0.0724, 0.0651, 0.0686, 0.0792, 0.0706, 0.0548, 0.0140, 0.0347,
        0.0487, 0.0427, 0.0283, 0.0305, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,588][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0013, 0.0020, 0.0044, 0.0121, 0.0191, 0.0758, 0.1092, 0.0613, 0.0751,
        0.2282, 0.1288, 0.0583, 0.0590, 0.1654], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,589][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0851, 0.2690, 0.0416, 0.0870, 0.0435, 0.0544, 0.0937, 0.0791, 0.0344,
        0.0697, 0.0416, 0.0437, 0.0390, 0.0182], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,590][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0450, 0.0309, 0.0678, 0.0421, 0.0872, 0.0588, 0.0621, 0.1082, 0.0957,
        0.0533, 0.0545, 0.1013, 0.1179, 0.0751], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,592][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0418, 0.0580, 0.0660, 0.0771, 0.0692, 0.0760, 0.0632, 0.0767, 0.0741,
        0.0743, 0.0700, 0.0828, 0.0886, 0.0820], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,593][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0772, 0.0681, 0.0745, 0.0728, 0.0722, 0.0723, 0.0737, 0.0720, 0.0701,
        0.0675, 0.0670, 0.0701, 0.0719, 0.0706], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,595][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0226, 0.0172, 0.0616, 0.0166, 0.1419, 0.0039, 0.0623, 0.1057, 0.0087,
        0.0749, 0.0787, 0.1032, 0.3015, 0.0012], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,597][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0750, 0.0924, 0.0769, 0.0720, 0.0797, 0.0635, 0.0754, 0.0580, 0.0667,
        0.0764, 0.0698, 0.0636, 0.0755, 0.0552], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,598][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0465, 0.1183, 0.0617, 0.0990, 0.0638, 0.0839, 0.0339, 0.0949, 0.0539,
        0.0972, 0.0800, 0.0680, 0.0559, 0.0431], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,599][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.0959e-02, 4.3244e-06, 1.4922e-05, 1.5254e-06, 2.8482e-06, 1.0601e-04,
        6.8915e-04, 2.8782e-02, 1.3249e-02, 5.8747e-03, 5.7548e-03, 8.5609e-01,
        3.4315e-02, 4.4154e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,601][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0750, 0.0693, 0.0731, 0.0739, 0.0719, 0.0702, 0.0729, 0.0712, 0.0682,
        0.0713, 0.0727, 0.0686, 0.0719, 0.0699], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,603][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0412, 0.0768, 0.0346, 0.0421, 0.0527, 0.0974, 0.0557, 0.1301, 0.0802,
        0.0495, 0.0292, 0.2461, 0.0439, 0.0203], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,605][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5548, 0.0703, 0.0350, 0.0535, 0.0353, 0.0503, 0.0305, 0.0059, 0.0196,
        0.0339, 0.0306, 0.0143, 0.0128, 0.0336, 0.0196], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,606][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0018, 0.0023, 0.0055, 0.0113, 0.0200, 0.0680, 0.0921, 0.0567, 0.0748,
        0.1702, 0.1035, 0.0577, 0.0628, 0.1536, 0.1198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,608][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0860, 0.2432, 0.0553, 0.0876, 0.0593, 0.0640, 0.0934, 0.0588, 0.0377,
        0.0507, 0.0351, 0.0418, 0.0481, 0.0263, 0.0128], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,608][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0437, 0.0296, 0.0618, 0.0396, 0.0796, 0.0544, 0.0583, 0.0987, 0.0869,
        0.0500, 0.0512, 0.0934, 0.1080, 0.0688, 0.0761], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,608][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0365, 0.0521, 0.0601, 0.0714, 0.0634, 0.0709, 0.0588, 0.0728, 0.0697,
        0.0702, 0.0637, 0.0770, 0.0848, 0.0780, 0.0706], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,609][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0709, 0.0627, 0.0698, 0.0668, 0.0679, 0.0680, 0.0689, 0.0676, 0.0662,
        0.0623, 0.0617, 0.0656, 0.0675, 0.0665, 0.0674], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,609][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0056, 0.0117, 0.0223, 0.0043, 0.1462, 0.0043, 0.0206, 0.2048, 0.0198,
        0.0389, 0.0197, 0.0535, 0.3920, 0.0519, 0.0042], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,609][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0696, 0.0831, 0.0807, 0.0626, 0.0748, 0.0594, 0.0663, 0.0564, 0.0693,
        0.0688, 0.0603, 0.0617, 0.0719, 0.0628, 0.0523], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,610][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0439, 0.1296, 0.0539, 0.0956, 0.0536, 0.0866, 0.0316, 0.0774, 0.0513,
        0.0939, 0.0701, 0.0633, 0.0465, 0.0500, 0.0527], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,610][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.0337e-03, 8.7847e-07, 6.4379e-06, 7.5641e-07, 2.3144e-06, 1.3395e-04,
        9.6796e-04, 1.5620e-02, 5.1616e-02, 1.6906e-03, 3.2204e-03, 2.5996e-01,
        4.9894e-02, 4.7955e-01, 1.3230e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,610][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0700, 0.0647, 0.0678, 0.0690, 0.0668, 0.0653, 0.0680, 0.0667, 0.0637,
        0.0670, 0.0683, 0.0643, 0.0670, 0.0651, 0.0662], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,611][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0380, 0.1099, 0.0445, 0.0626, 0.0437, 0.0428, 0.0585, 0.1340, 0.1450,
        0.0646, 0.0427, 0.1191, 0.0387, 0.0267, 0.0293], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,639][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:03,639][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,640][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,640][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,640][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,641][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,641][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,641][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,641][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,642][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,642][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,643][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,644][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,646][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5302, 0.4698], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,647][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2115, 0.7885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,649][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5765, 0.4235], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,650][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5227, 0.4773], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,652][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9766, 0.0234], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,653][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5853, 0.4147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,655][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3372, 0.6628], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,657][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4161, 0.5839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,658][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1970, 0.8030], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,660][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5507, 0.4493], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,661][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2464, 0.7536], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,662][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.5367, 0.4633], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,662][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.3585, 0.3195, 0.3221], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,662][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0990, 0.5624, 0.3386], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,663][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.3908, 0.2771, 0.3321], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,663][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.3244, 0.3798, 0.2958], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,663][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.9960, 0.0018, 0.0022], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,663][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.4191, 0.2679, 0.3130], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,664][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.2033, 0.6738, 0.1229], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,664][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2908, 0.4271, 0.2821], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,664][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.1323, 0.7906, 0.0772], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,664][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.3650, 0.0873, 0.5477], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,665][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.1272, 0.4193, 0.4534], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,665][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.5479, 0.0646, 0.3875], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,665][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2684, 0.2391, 0.2433, 0.2493], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,666][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0819, 0.4210, 0.2943, 0.2028], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,668][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2788, 0.2212, 0.3070, 0.1930], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,669][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2708, 0.2609, 0.2327, 0.2356], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,671][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7804, 0.0647, 0.0863, 0.0686], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,672][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3483, 0.2104, 0.2517, 0.1896], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,673][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2387, 0.4439, 0.1255, 0.1919], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,674][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2003, 0.3022, 0.2950, 0.2025], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,676][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0914, 0.6030, 0.1279, 0.1778], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,678][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0264, 0.0936, 0.8074, 0.0726], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,679][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0940, 0.2963, 0.3173, 0.2924], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,681][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0391, 0.0987, 0.7610, 0.1012], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,683][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.2167, 0.1918, 0.1936, 0.1987, 0.1992], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,684][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0316, 0.2184, 0.1345, 0.1893, 0.4262], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,685][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.2579, 0.1620, 0.2268, 0.1638, 0.1895], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,685][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1905, 0.2170, 0.1983, 0.2097, 0.1845], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,685][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.9477, 0.0073, 0.0096, 0.0187, 0.0166], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,686][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.2741, 0.1673, 0.2074, 0.1638, 0.1874], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,686][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.1495, 0.4604, 0.0995, 0.1884, 0.1022], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,686][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.1720, 0.2416, 0.2315, 0.1828, 0.1721], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,686][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0680, 0.5167, 0.0621, 0.2822, 0.0711], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,687][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0814, 0.0759, 0.6065, 0.0521, 0.1841], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,687][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0704, 0.2265, 0.2441, 0.2247, 0.2343], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,687][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1040, 0.0333, 0.6761, 0.0408, 0.1458], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,688][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1849, 0.1620, 0.1629, 0.1678, 0.1679, 0.1545], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,688][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0724, 0.1643, 0.0959, 0.2053, 0.2798, 0.1822], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,688][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1850, 0.1391, 0.2077, 0.1398, 0.2034, 0.1249], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,689][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1690, 0.1818, 0.1630, 0.1754, 0.1511, 0.1597], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,691][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9562, 0.0050, 0.0070, 0.0127, 0.0120, 0.0071], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,692][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2428, 0.1409, 0.1726, 0.1386, 0.1574, 0.1477], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,694][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1735, 0.2715, 0.0893, 0.1340, 0.0951, 0.2366], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,695][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1424, 0.2148, 0.1883, 0.1552, 0.1773, 0.1221], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,695][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0730, 0.4759, 0.0497, 0.2355, 0.0829, 0.0831], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,697][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1608, 0.0733, 0.0623, 0.0141, 0.0197, 0.6699], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,699][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0570, 0.1838, 0.1970, 0.1818, 0.1893, 0.1910], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,700][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2614, 0.0588, 0.1392, 0.0246, 0.0313, 0.4846], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,702][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1578, 0.1391, 0.1403, 0.1445, 0.1445, 0.1327, 0.1409],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,704][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0367, 0.1409, 0.1051, 0.1153, 0.2904, 0.1608, 0.1509],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,706][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1767, 0.1230, 0.1891, 0.1205, 0.1643, 0.1248, 0.1016],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,707][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1522, 0.1569, 0.1344, 0.1433, 0.1290, 0.1485, 0.1356],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,708][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6598, 0.0385, 0.0448, 0.0678, 0.0716, 0.0494, 0.0681],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,708][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2171, 0.1242, 0.1554, 0.1228, 0.1410, 0.1350, 0.1046],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,708][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1517, 0.1993, 0.0689, 0.1071, 0.0730, 0.1868, 0.2132],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,708][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1214, 0.1891, 0.1646, 0.1328, 0.1472, 0.1232, 0.1217],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,709][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0602, 0.3803, 0.0676, 0.1904, 0.0955, 0.1593, 0.0467],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,709][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1301, 0.0016, 0.0100, 0.0018, 0.0030, 0.1609, 0.6926],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,709][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0489, 0.1544, 0.1636, 0.1522, 0.1588, 0.1606, 0.1615],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,710][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2034, 0.0026, 0.0150, 0.0017, 0.0022, 0.0613, 0.7140],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,710][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1417, 0.1249, 0.1248, 0.1294, 0.1294, 0.1189, 0.1263, 0.1047],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,710][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0249, 0.1204, 0.0462, 0.1291, 0.1648, 0.1393, 0.1581, 0.2173],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,711][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1510, 0.1038, 0.1380, 0.1041, 0.1278, 0.1122, 0.1249, 0.1381],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,711][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1242, 0.1374, 0.1152, 0.1366, 0.1190, 0.1193, 0.1423, 0.1059],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,711][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.6123, 0.0393, 0.0522, 0.0652, 0.0688, 0.0480, 0.0689, 0.0453],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,712][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1954, 0.1125, 0.1353, 0.1051, 0.1204, 0.1139, 0.0979, 0.1194],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,713][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0893, 0.2092, 0.0556, 0.1097, 0.0634, 0.1684, 0.2054, 0.0990],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,715][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1129, 0.1702, 0.1406, 0.1263, 0.1239, 0.1200, 0.1162, 0.0899],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,717][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0458, 0.3552, 0.0355, 0.1657, 0.0670, 0.1561, 0.0733, 0.1014],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,717][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([2.8248e-02, 2.3309e-05, 3.5755e-04, 2.8368e-05, 7.9666e-05, 3.0408e-03,
        4.0570e-02, 9.2765e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,718][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0409, 0.1325, 0.1427, 0.1319, 0.1371, 0.1385, 0.1388, 0.1375],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,720][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.4102e-02, 4.7907e-06, 7.6834e-05, 4.6176e-06, 8.5404e-06, 1.4872e-04,
        7.2238e-03, 9.6843e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,721][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1288, 0.1127, 0.1137, 0.1177, 0.1178, 0.1079, 0.1146, 0.0942, 0.0926],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,723][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0130, 0.0819, 0.0396, 0.0951, 0.1368, 0.1442, 0.1239, 0.2694, 0.0962],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,724][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1233, 0.0896, 0.1239, 0.0919, 0.1327, 0.1029, 0.1045, 0.1419, 0.0893],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,726][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1102, 0.1200, 0.1081, 0.1172, 0.1061, 0.1227, 0.1230, 0.1122, 0.0806],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,728][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.6866, 0.0244, 0.0354, 0.0446, 0.0472, 0.0400, 0.0461, 0.0375, 0.0383],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,730][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1654, 0.1039, 0.1226, 0.0972, 0.1080, 0.1035, 0.0856, 0.1064, 0.1073],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,731][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0781, 0.2121, 0.0447, 0.1000, 0.0470, 0.1625, 0.2000, 0.0884, 0.0673],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,731][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0897, 0.1412, 0.1303, 0.1018, 0.1198, 0.1059, 0.1053, 0.0994, 0.1065],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,731][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0280, 0.2370, 0.0427, 0.1367, 0.0828, 0.1547, 0.0570, 0.2066, 0.0546],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,732][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([1.2696e-02, 1.2681e-05, 2.9067e-04, 1.7289e-05, 1.1215e-04, 1.7889e-03,
        1.4255e-02, 6.0555e-01, 3.6528e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,732][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0351, 0.1166, 0.1259, 0.1161, 0.1207, 0.1223, 0.1225, 0.1215, 0.1192],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,732][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([6.6856e-04, 7.1230e-07, 7.4326e-06, 5.5696e-07, 1.6598e-06, 1.9858e-05,
        1.0038e-03, 9.7659e-01, 2.1708e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,733][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1141, 0.1012, 0.1029, 0.1054, 0.1060, 0.0979, 0.1030, 0.0861, 0.0849,
        0.0987], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,733][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0131, 0.0667, 0.0402, 0.0755, 0.1193, 0.1211, 0.1095, 0.2012, 0.1286,
        0.1247], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,733][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1161, 0.0752, 0.1126, 0.0821, 0.1083, 0.0848, 0.0976, 0.1336, 0.0949,
        0.0949], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,733][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1060, 0.1010, 0.0954, 0.0977, 0.0897, 0.1108, 0.1114, 0.1018, 0.0725,
        0.1138], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,734][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5141, 0.0440, 0.0439, 0.0623, 0.0759, 0.0430, 0.0670, 0.0466, 0.0593,
        0.0439], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,734][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1645, 0.0967, 0.1013, 0.0778, 0.1018, 0.0995, 0.0785, 0.1118, 0.1042,
        0.0638], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,735][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1161, 0.1312, 0.0452, 0.0718, 0.0481, 0.1385, 0.1587, 0.0873, 0.0724,
        0.1308], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,737][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0856, 0.1254, 0.1216, 0.0883, 0.1057, 0.0880, 0.1000, 0.0862, 0.1063,
        0.0928], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,738][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0331, 0.1960, 0.0360, 0.1001, 0.0687, 0.1159, 0.0730, 0.1010, 0.1029,
        0.1733], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,739][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([6.8832e-04, 3.1251e-06, 1.6772e-04, 9.3625e-06, 6.8679e-05, 3.6374e-04,
        3.9754e-03, 7.8731e-01, 1.9830e-01, 9.1125e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,740][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0321, 0.1043, 0.1124, 0.1036, 0.1080, 0.1093, 0.1095, 0.1085, 0.1065,
        0.1058], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,741][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.5369e-04, 5.1524e-07, 7.1130e-06, 1.3130e-06, 2.5481e-06, 2.7711e-05,
        1.7727e-03, 9.4038e-01, 5.4854e-02, 2.7962e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,743][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1046, 0.0925, 0.0937, 0.0959, 0.0963, 0.0890, 0.0938, 0.0782, 0.0768,
        0.0895, 0.0896], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,745][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0115, 0.0741, 0.0382, 0.0299, 0.1082, 0.1265, 0.0791, 0.2131, 0.1525,
        0.1388, 0.0282], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,746][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1043, 0.0759, 0.1008, 0.0634, 0.0985, 0.0820, 0.0879, 0.1184, 0.0915,
        0.0981, 0.0792], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,748][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0972, 0.0971, 0.0839, 0.0893, 0.0844, 0.1023, 0.1010, 0.0874, 0.0677,
        0.1041, 0.0857], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,750][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2928, 0.0645, 0.0656, 0.0786, 0.0983, 0.0551, 0.0880, 0.0624, 0.0696,
        0.0520, 0.0732], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,752][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1463, 0.0901, 0.0985, 0.0736, 0.1001, 0.0979, 0.0773, 0.1080, 0.0978,
        0.0595, 0.0508], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,753][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0765, 0.1309, 0.0444, 0.0672, 0.0475, 0.1280, 0.1556, 0.0764, 0.0659,
        0.1303, 0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,754][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0777, 0.1163, 0.1131, 0.0792, 0.0970, 0.0836, 0.0866, 0.0838, 0.1036,
        0.0863, 0.0728], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,754][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0281, 0.1905, 0.0378, 0.0627, 0.0705, 0.0865, 0.0674, 0.0852, 0.1082,
        0.2035, 0.0595], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,754][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.2975e-03, 4.5827e-06, 1.1377e-04, 3.9491e-06, 2.3837e-05, 4.3532e-04,
        4.2365e-03, 6.5651e-01, 2.7133e-01, 2.5938e-02, 4.0105e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,755][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0294, 0.0947, 0.1014, 0.0936, 0.0975, 0.0988, 0.0989, 0.0982, 0.0963,
        0.0958, 0.0955], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,755][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.9677e-04, 4.3998e-07, 8.2556e-06, 5.1431e-07, 2.2117e-06, 3.4455e-05,
        1.9712e-03, 9.1055e-01, 7.1566e-02, 4.2926e-03, 1.1275e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,755][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0975, 0.0859, 0.0857, 0.0883, 0.0887, 0.0817, 0.0864, 0.0714, 0.0699,
        0.0822, 0.0825, 0.0798], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,756][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0106, 0.0593, 0.0285, 0.0588, 0.0835, 0.0946, 0.0623, 0.2681, 0.0857,
        0.1327, 0.0650, 0.0508], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,756][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0985, 0.0699, 0.0814, 0.0716, 0.0790, 0.0699, 0.0762, 0.0981, 0.0702,
        0.0891, 0.0911, 0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,756][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0752, 0.0881, 0.0734, 0.0944, 0.0750, 0.0877, 0.0950, 0.0906, 0.0577,
        0.1019, 0.0928, 0.0681], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,757][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.6466, 0.0295, 0.0288, 0.0431, 0.0425, 0.0275, 0.0365, 0.0291, 0.0385,
        0.0203, 0.0416, 0.0161], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,757][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.1219, 0.0819, 0.0998, 0.0801, 0.0885, 0.0854, 0.0757, 0.0858, 0.0840,
        0.0659, 0.0611, 0.0699], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,758][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0710, 0.1368, 0.0357, 0.0673, 0.0410, 0.1116, 0.1312, 0.0668, 0.0583,
        0.1156, 0.0776, 0.0871], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,759][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0711, 0.1113, 0.0890, 0.0833, 0.0863, 0.0811, 0.0839, 0.0767, 0.0890,
        0.0816, 0.0747, 0.0721], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,761][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0217, 0.1747, 0.0185, 0.0954, 0.0357, 0.0796, 0.0337, 0.1014, 0.0774,
        0.2197, 0.1031, 0.0391], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,762][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.8904e-02, 1.0853e-05, 1.7171e-04, 7.9623e-06, 5.2437e-05, 8.5503e-04,
        3.5457e-03, 2.1221e-01, 8.2244e-02, 9.3490e-03, 1.5102e-02, 6.5755e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,764][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0278, 0.0863, 0.0928, 0.0855, 0.0890, 0.0902, 0.0900, 0.0893, 0.0877,
        0.0872, 0.0869, 0.0873], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,764][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([7.5196e-03, 1.0453e-06, 8.3237e-06, 8.1520e-07, 2.9656e-06, 4.3354e-05,
        8.4910e-04, 2.7020e-01, 2.0325e-02, 1.7729e-03, 4.8135e-03, 6.9446e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,766][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0883, 0.0783, 0.0791, 0.0812, 0.0814, 0.0752, 0.0792, 0.0657, 0.0646,
        0.0758, 0.0758, 0.0733, 0.0821], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,768][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0060, 0.0468, 0.0269, 0.0389, 0.0952, 0.0856, 0.0598, 0.1722, 0.1132,
        0.1120, 0.0465, 0.0970, 0.0999], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,769][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0994, 0.0604, 0.0796, 0.0594, 0.0704, 0.0581, 0.0658, 0.0973, 0.0650,
        0.0722, 0.0771, 0.1118, 0.0833], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,771][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0711, 0.0818, 0.0763, 0.0797, 0.0713, 0.0805, 0.0851, 0.0852, 0.0597,
        0.0903, 0.0787, 0.0714, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,773][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.5112, 0.0181, 0.0257, 0.0534, 0.0464, 0.0293, 0.0481, 0.0451, 0.0373,
        0.0282, 0.0586, 0.0233, 0.0752], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,775][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.1218, 0.0755, 0.0917, 0.0703, 0.0824, 0.0793, 0.0628, 0.0803, 0.0785,
        0.0569, 0.0536, 0.0708, 0.0761], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,776][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0400, 0.1507, 0.0324, 0.0669, 0.0353, 0.1096, 0.1313, 0.0630, 0.0510,
        0.1207, 0.0805, 0.0871, 0.0316], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,777][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0685, 0.0970, 0.0913, 0.0727, 0.0685, 0.0793, 0.0756, 0.0705, 0.0921,
        0.0732, 0.0652, 0.0840, 0.0621], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,777][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0210, 0.1743, 0.0218, 0.1019, 0.0268, 0.0622, 0.0415, 0.0975, 0.0576,
        0.1978, 0.0979, 0.0748, 0.0248], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,777][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([2.4325e-02, 6.6761e-06, 9.6406e-05, 4.6660e-06, 1.8818e-05, 4.7194e-04,
        3.9194e-03, 7.5243e-02, 3.7861e-02, 7.1588e-03, 1.0541e-02, 5.3528e-01,
        3.0508e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,778][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0248, 0.0798, 0.0855, 0.0789, 0.0820, 0.0826, 0.0826, 0.0820, 0.0807,
        0.0805, 0.0801, 0.0806, 0.0799], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,778][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([9.4865e-03, 6.1811e-07, 1.7476e-05, 7.2706e-07, 2.3729e-06, 4.2456e-05,
        1.1814e-03, 5.5224e-02, 1.5488e-02, 1.0637e-03, 3.3375e-03, 8.5952e-01,
        5.4632e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,778][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0832, 0.0733, 0.0735, 0.0758, 0.0758, 0.0698, 0.0736, 0.0609, 0.0600,
        0.0707, 0.0708, 0.0681, 0.0762, 0.0682], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,779][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0080, 0.0457, 0.0203, 0.0530, 0.0797, 0.0458, 0.0691, 0.2225, 0.0428,
        0.1208, 0.0642, 0.0815, 0.0772, 0.0693], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,779][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0798, 0.0580, 0.0722, 0.0530, 0.0757, 0.0515, 0.0618, 0.0908, 0.0654,
        0.0744, 0.0697, 0.0998, 0.0911, 0.0565], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,779][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0696, 0.0801, 0.0689, 0.0764, 0.0685, 0.0753, 0.0767, 0.0746, 0.0479,
        0.0895, 0.0792, 0.0655, 0.0676, 0.0601], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,780][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.7335, 0.0132, 0.0139, 0.0266, 0.0294, 0.0123, 0.0212, 0.0192, 0.0210,
        0.0147, 0.0308, 0.0084, 0.0463, 0.0094], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,780][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.1175, 0.0704, 0.0820, 0.0658, 0.0762, 0.0713, 0.0575, 0.0754, 0.0753,
        0.0533, 0.0494, 0.0656, 0.0701, 0.0701], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,781][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0552, 0.1209, 0.0330, 0.0615, 0.0376, 0.0931, 0.1163, 0.0577, 0.0510,
        0.1064, 0.0668, 0.0797, 0.0316, 0.0893], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,782][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0609, 0.0922, 0.0768, 0.0717, 0.0802, 0.0656, 0.0762, 0.0632, 0.0785,
        0.0711, 0.0663, 0.0677, 0.0738, 0.0558], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,784][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0158, 0.1337, 0.0234, 0.0841, 0.0549, 0.0734, 0.0382, 0.1230, 0.0593,
        0.1630, 0.0886, 0.0660, 0.0514, 0.0252], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,785][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.0959e-02, 4.3244e-06, 1.4922e-05, 1.5254e-06, 2.8482e-06, 1.0601e-04,
        6.8915e-04, 2.8782e-02, 1.3249e-02, 5.8747e-03, 5.7548e-03, 8.5609e-01,
        3.4315e-02, 4.4154e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,787][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0225, 0.0736, 0.0791, 0.0732, 0.0761, 0.0767, 0.0768, 0.0759, 0.0746,
        0.0743, 0.0741, 0.0743, 0.0739, 0.0749], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,787][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.2445e-03, 4.9168e-07, 1.6063e-06, 2.6865e-07, 2.9964e-07, 1.8043e-05,
        2.8730e-04, 8.6626e-02, 1.0485e-02, 7.2163e-04, 1.9852e-03, 8.4947e-01,
        7.7856e-03, 4.0378e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,789][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0780, 0.0684, 0.0688, 0.0707, 0.0709, 0.0654, 0.0692, 0.0572, 0.0563,
        0.0659, 0.0659, 0.0637, 0.0711, 0.0638, 0.0647], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,791][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0087, 0.0356, 0.0285, 0.0366, 0.0833, 0.0873, 0.0568, 0.1309, 0.1001,
        0.0747, 0.0409, 0.0529, 0.0810, 0.1673, 0.0151], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,793][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0719, 0.0516, 0.0692, 0.0501, 0.0720, 0.0520, 0.0576, 0.0794, 0.0623,
        0.0674, 0.0649, 0.0907, 0.0857, 0.0633, 0.0618], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,794][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0727, 0.0755, 0.0622, 0.0705, 0.0645, 0.0744, 0.0714, 0.0660, 0.0528,
        0.0803, 0.0694, 0.0574, 0.0630, 0.0628, 0.0572], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,796][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3513, 0.0258, 0.0336, 0.0529, 0.0558, 0.0399, 0.0528, 0.0585, 0.0685,
        0.0388, 0.0650, 0.0379, 0.0670, 0.0275, 0.0244], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,798][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1040, 0.0631, 0.0770, 0.0621, 0.0722, 0.0684, 0.0562, 0.0706, 0.0715,
        0.0506, 0.0475, 0.0625, 0.0672, 0.0677, 0.0593], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,799][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0901, 0.1059, 0.0329, 0.0563, 0.0362, 0.0853, 0.1059, 0.0504, 0.0456,
        0.0874, 0.0522, 0.0665, 0.0274, 0.0742, 0.0838], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,800][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0584, 0.0886, 0.0823, 0.0624, 0.0736, 0.0594, 0.0680, 0.0588, 0.0768,
        0.0668, 0.0578, 0.0625, 0.0681, 0.0624, 0.0541], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,800][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0131, 0.1554, 0.0168, 0.0825, 0.0352, 0.0920, 0.0332, 0.0707, 0.0602,
        0.1726, 0.0799, 0.0646, 0.0327, 0.0472, 0.0439], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,800][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.0337e-03, 8.7847e-07, 6.4379e-06, 7.5641e-07, 2.3144e-06, 1.3395e-04,
        9.6796e-04, 1.5620e-02, 5.1616e-02, 1.6906e-03, 3.2204e-03, 2.5996e-01,
        4.9894e-02, 4.7955e-01, 1.3230e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,801][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0225, 0.0686, 0.0731, 0.0679, 0.0707, 0.0716, 0.0718, 0.0711, 0.0696,
        0.0691, 0.0690, 0.0692, 0.0685, 0.0695, 0.0678], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,801][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.0109e-03, 2.5989e-07, 3.2511e-06, 2.3086e-07, 3.2489e-07, 1.0601e-05,
        6.9110e-04, 9.8004e-02, 1.2964e-02, 6.0213e-04, 1.8392e-03, 5.0970e-01,
        1.3628e-02, 2.0130e-01, 1.5825e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:03,802][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:03,803][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[19030],
        [15268],
        [ 7619],
        [ 2969],
        [13370],
        [16047],
        [11762],
        [19556],
        [19423],
        [17433],
        [16618],
        [18144],
        [35469],
        [18480],
        [30218]], device='cuda:0')
[2024-07-24 10:17:03,805][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[19636],
        [12934],
        [16681],
        [ 2297],
        [18800],
        [11882],
        [13209],
        [21139],
        [14050],
        [11296],
        [ 9769],
        [16199],
        [37984],
        [14951],
        [23832]], device='cuda:0')
[2024-07-24 10:17:03,806][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36464],
        [33893],
        [35947],
        [33090],
        [35390],
        [36181],
        [35731],
        [36539],
        [36754],
        [35828],
        [34768],
        [35468],
        [36781],
        [35846],
        [35779]], device='cuda:0')
[2024-07-24 10:17:03,808][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 7368],
        [18640],
        [20756],
        [21240],
        [23124],
        [25968],
        [26882],
        [28553],
        [28205],
        [25937],
        [26097],
        [25961],
        [25718],
        [26815],
        [27517]], device='cuda:0')
[2024-07-24 10:17:03,809][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[22231],
        [12732],
        [12125],
        [11116],
        [11319],
        [11285],
        [ 9634],
        [11361],
        [10551],
        [11109],
        [11006],
        [10932],
        [11253],
        [11192],
        [10708]], device='cuda:0')
[2024-07-24 10:17:03,811][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[11403],
        [11761],
        [ 5518],
        [ 4046],
        [ 3896],
        [ 3773],
        [ 3894],
        [ 3768],
        [ 3556],
        [ 3784],
        [ 3867],
        [ 4014],
        [ 3979],
        [ 4144],
        [ 4462]], device='cuda:0')
[2024-07-24 10:17:03,812][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26495],
        [40622],
        [40861],
        [40144],
        [39938],
        [40325],
        [39904],
        [40101],
        [40424],
        [41143],
        [41177],
        [41189],
        [41316],
        [41470],
        [41376]], device='cuda:0')
[2024-07-24 10:17:03,814][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[10613],
        [ 9536],
        [ 9840],
        [ 9471],
        [ 9973],
        [10477],
        [10934],
        [11170],
        [11181],
        [11156],
        [10844],
        [10646],
        [10709],
        [10702],
        [10837]], device='cuda:0')
[2024-07-24 10:17:03,815][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[47485],
        [48529],
        [ 9131],
        [ 3083],
        [ 6534],
        [14552],
        [18074],
        [33558],
        [34376],
        [30459],
        [37855],
        [46901],
        [22857],
        [40119],
        [36494]], device='cuda:0')
[2024-07-24 10:17:03,816][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35931],
        [34932],
        [35537],
        [33267],
        [32228],
        [33060],
        [33755],
        [33612],
        [33942],
        [33713],
        [33173],
        [33110],
        [33005],
        [32792],
        [33021]], device='cuda:0')
[2024-07-24 10:17:03,818][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22141],
        [22807],
        [24127],
        [24410],
        [24406],
        [24809],
        [26222],
        [25237],
        [24051],
        [23567],
        [23420],
        [22187],
        [22184],
        [22750],
        [22555]], device='cuda:0')
[2024-07-24 10:17:03,820][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[11181],
        [ 4355],
        [ 8483],
        [10930],
        [11170],
        [23265],
        [11926],
        [14791],
        [ 9325],
        [11761],
        [10154],
        [30898],
        [32997],
        [34650],
        [15934]], device='cuda:0')
[2024-07-24 10:17:03,821][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24422],
        [24089],
        [19778],
        [17961],
        [16764],
        [15435],
        [14534],
        [13628],
        [13203],
        [13151],
        [13235],
        [13249],
        [12870],
        [12503],
        [12130]], device='cuda:0')
[2024-07-24 10:17:03,823][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[2258],
        [3836],
        [3237],
        [3513],
        [4680],
        [5507],
        [6805],
        [5873],
        [5007],
        [4833],
        [4740],
        [3939],
        [4001],
        [3644],
        [4005]], device='cuda:0')
[2024-07-24 10:17:03,824][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11390],
        [16147],
        [  861],
        [18291],
        [17610],
        [14922],
        [19764],
        [17636],
        [29896],
        [43041],
        [38145],
        [17912],
        [20469],
        [19265],
        [22476]], device='cuda:0')
[2024-07-24 10:17:03,825][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[4238],
        [4034],
        [3794],
        [3414],
        [3370],
        [3379],
        [3288],
        [3237],
        [3263],
        [3246],
        [3206],
        [3244],
        [3230],
        [3253],
        [3267]], device='cuda:0')
[2024-07-24 10:17:03,826][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15142],
        [ 3255],
        [ 6023],
        [ 4774],
        [12013],
        [13977],
        [15832],
        [13278],
        [13711],
        [11372],
        [10898],
        [ 9653],
        [13183],
        [11779],
        [15318]], device='cuda:0')
[2024-07-24 10:17:03,827][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38345],
        [33381],
        [33971],
        [29121],
        [30556],
        [29943],
        [29319],
        [28992],
        [31630],
        [31645],
        [30507],
        [31215],
        [32214],
        [31753],
        [31869]], device='cuda:0')
[2024-07-24 10:17:03,827][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13106],
        [ 8841],
        [ 9408],
        [ 8328],
        [ 8428],
        [ 8905],
        [ 8416],
        [ 7873],
        [ 8107],
        [ 7817],
        [ 7672],
        [ 7255],
        [ 7373],
        [ 7587],
        [ 7682]], device='cuda:0')
[2024-07-24 10:17:03,828][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8610],
        [ 8771],
        [ 8667],
        [16110],
        [ 9577],
        [ 9389],
        [16835],
        [16379],
        [16307],
        [16155],
        [14966],
        [16326],
        [16468],
        [15440],
        [16061]], device='cuda:0')
[2024-07-24 10:17:03,830][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23460],
        [23494],
        [24082],
        [25087],
        [22100],
        [20688],
        [20045],
        [20264],
        [20654],
        [21131],
        [21354],
        [21332],
        [20552],
        [20066],
        [19849]], device='cuda:0')
[2024-07-24 10:17:03,832][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2173],
        [1146],
        [1076],
        [1178],
        [1091],
        [1238],
        [1285],
        [1188],
        [1163],
        [1174],
        [1159],
        [1106],
        [1088],
        [1073],
        [1149]], device='cuda:0')
[2024-07-24 10:17:03,833][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6382],
        [6300],
        [6136],
        [5933],
        [6140],
        [6094],
        [6026],
        [5809],
        [5536],
        [5565],
        [5539],
        [5601],
        [5656],
        [5712],
        [5641]], device='cuda:0')
[2024-07-24 10:17:03,834][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10514],
        [ 7102],
        [ 6342],
        [ 6534],
        [ 7259],
        [ 7530],
        [ 7330],
        [ 8335],
        [ 8959],
        [ 7219],
        [ 6925],
        [ 7820],
        [ 7930],
        [ 7901],
        [ 7559]], device='cuda:0')
[2024-07-24 10:17:03,836][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 378],
        [ 136],
        [2508],
        [2778],
        [2016],
        [7170],
        [ 304],
        [2551],
        [2116],
        [2251],
        [2021],
        [1173],
        [ 995],
        [1958],
        [3088]], device='cuda:0')
[2024-07-24 10:17:03,837][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[28800],
        [43610],
        [45524],
        [45113],
        [45109],
        [45113],
        [45125],
        [44984],
        [44836],
        [44798],
        [44675],
        [44572],
        [44585],
        [44588],
        [44566]], device='cuda:0')
[2024-07-24 10:17:03,839][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 796],
        [1007],
        [1139],
        [3996],
        [3937],
        [2187],
        [1261],
        [4748],
        [4888],
        [4566],
        [4364],
        [1223],
        [1593],
        [1510],
        [1527]], device='cuda:0')
[2024-07-24 10:17:03,840][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48813],
        [49306],
        [48340],
        [47202],
        [47654],
        [46798],
        [48367],
        [46899],
        [46873],
        [47015],
        [47147],
        [48140],
        [47987],
        [47871],
        [47391]], device='cuda:0')
[2024-07-24 10:17:03,842][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29118],
        [39140],
        [41705],
        [44761],
        [35900],
        [45287],
        [41752],
        [41077],
        [41995],
        [39408],
        [41227],
        [43109],
        [41308],
        [44982],
        [45734]], device='cuda:0')
[2024-07-24 10:17:03,843][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696],
        [19696]], device='cuda:0')
[2024-07-24 10:17:03,851][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:03,851][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,851][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,852][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,852][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,854][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,854][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,854][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,854][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,855][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,855][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,855][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,856][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:03,857][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7228, 0.2772], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,859][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3246, 0.6754], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,860][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3102, 0.6898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,861][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9994e-01, 5.9712e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,863][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1500, 0.8500], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,864][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2494, 0.7506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,866][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9680, 0.0320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,867][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4166, 0.5834], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,869][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1225, 0.8775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,871][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6480, 0.3520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,872][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6658, 0.3342], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,873][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:03,874][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.4444, 0.1680, 0.3876], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,874][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.2040, 0.4483, 0.3476], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,874][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5120, 0.0213, 0.4667], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,874][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.4924, 0.0243, 0.4832], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,875][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0627, 0.4544, 0.4829], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,875][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1440, 0.4134, 0.4426], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,875][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.9091, 0.0140, 0.0769], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,876][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.2954, 0.4129, 0.2917], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,876][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0428, 0.5875, 0.3697], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,876][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.4629, 0.2809, 0.2562], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,876][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.5415, 0.2996, 0.1589], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,877][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([3.8572e-04, 2.8818e-01, 7.1143e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:03,877][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3768, 0.1327, 0.3091, 0.1814], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,878][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1439, 0.3138, 0.2506, 0.2918], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,879][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0218, 0.0070, 0.1813, 0.7899], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,880][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.9894e-01, 6.3847e-04, 2.0013e-01, 2.9626e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,882][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0569, 0.2915, 0.3087, 0.3430], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,883][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1022, 0.2903, 0.3101, 0.2974], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,884][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8434, 0.0083, 0.0856, 0.0627], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,886][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2197, 0.3083, 0.2255, 0.2465], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,888][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0663, 0.3964, 0.2582, 0.2791], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,889][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4279, 0.2141, 0.2018, 0.1563], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,890][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4910, 0.2294, 0.1399, 0.1398], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,892][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.2996e-09, 5.7103e-07, 1.0000e+00, 2.7235e-06], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:03,894][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2662, 0.1104, 0.2419, 0.1465, 0.2349], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,895][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1111, 0.2508, 0.2036, 0.2360, 0.1986], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,897][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.1160, 0.0027, 0.1458, 0.3895, 0.3461], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,897][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.8362, 0.0134, 0.1009, 0.0273, 0.0221], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,897][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0289, 0.2196, 0.2316, 0.2696, 0.2503], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,897][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0781, 0.2240, 0.2394, 0.2292, 0.2294], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,898][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.7658, 0.0091, 0.0652, 0.0762, 0.0837], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,898][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.1835, 0.2484, 0.1789, 0.1939, 0.1952], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,898][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0222, 0.3691, 0.2335, 0.2557, 0.1196], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,899][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.3274, 0.1905, 0.1564, 0.1572, 0.1684], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,899][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.4528, 0.2071, 0.1230, 0.1357, 0.0814], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,899][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([9.7918e-05, 2.5736e-02, 3.6279e-01, 6.1028e-01, 1.0995e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:03,899][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2111, 0.0930, 0.2140, 0.1268, 0.2043, 0.1509], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,900][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1003, 0.2136, 0.1649, 0.1930, 0.1620, 0.1662], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,900][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0120, 0.0024, 0.0638, 0.2750, 0.2069, 0.4399], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,900][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([5.7484e-01, 2.5862e-03, 1.8760e-01, 4.2991e-03, 2.3047e-01, 1.9969e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,901][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0283, 0.1782, 0.1881, 0.2139, 0.2021, 0.1894], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,903][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0601, 0.1822, 0.1977, 0.1891, 0.1896, 0.1813], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,904][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.7668, 0.0108, 0.0505, 0.0423, 0.0581, 0.0716], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,906][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1680, 0.2055, 0.1504, 0.1632, 0.1605, 0.1524], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,907][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0240, 0.2986, 0.1918, 0.2060, 0.1091, 0.1705], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,908][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3004, 0.1667, 0.1215, 0.1254, 0.1236, 0.1624], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,910][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3465, 0.1739, 0.1232, 0.1342, 0.0854, 0.1369], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,911][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([6.8169e-07, 2.7962e-05, 9.1954e-01, 9.5154e-04, 7.7800e-02, 1.6802e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:03,912][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1754, 0.0816, 0.1809, 0.1092, 0.1753, 0.1328, 0.1448],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,914][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0890, 0.1771, 0.1403, 0.1623, 0.1368, 0.1420, 0.1524],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,915][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([7.9212e-03, 1.4825e-04, 1.0695e-02, 3.9830e-02, 2.9952e-02, 1.0437e-01,
        8.0709e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,916][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.8704e-01, 4.8052e-03, 1.3260e-01, 9.4048e-03, 6.4213e-02, 1.2707e-03,
        6.7342e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,918][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0207, 0.1514, 0.1598, 0.1854, 0.1722, 0.1605, 0.1500],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,919][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0559, 0.1531, 0.1652, 0.1569, 0.1573, 0.1524, 0.1592],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,920][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.8241, 0.0068, 0.0278, 0.0212, 0.0319, 0.0429, 0.0453],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,920][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1321, 0.1756, 0.1183, 0.1305, 0.1292, 0.1231, 0.1913],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,920][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0240, 0.2549, 0.1617, 0.1842, 0.0941, 0.1525, 0.1286],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,921][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3040, 0.1448, 0.0985, 0.0963, 0.0981, 0.1466, 0.1117],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,921][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2976, 0.1411, 0.1094, 0.1215, 0.0807, 0.1262, 0.1233],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,921][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.0891e-07, 2.0873e-04, 6.7372e-01, 1.6230e-02, 1.7820e-02, 2.9200e-01,
        2.1311e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:03,922][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1473, 0.0699, 0.1468, 0.0909, 0.1425, 0.1094, 0.1192, 0.1739],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,922][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0689, 0.1505, 0.1226, 0.1418, 0.1223, 0.1270, 0.1366, 0.1303],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,922][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0030, 0.0005, 0.0109, 0.0355, 0.0327, 0.0589, 0.3743, 0.4843],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,922][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.8883, 0.0025, 0.0403, 0.0068, 0.0225, 0.0016, 0.0165, 0.0214],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,923][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0222, 0.1274, 0.1373, 0.1524, 0.1447, 0.1365, 0.1261, 0.1534],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,923][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0459, 0.1326, 0.1433, 0.1359, 0.1368, 0.1313, 0.1356, 0.1386],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,924][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.6021, 0.0078, 0.0511, 0.0424, 0.0622, 0.0818, 0.0996, 0.0530],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,925][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1138, 0.1523, 0.1131, 0.1210, 0.1202, 0.1122, 0.1617, 0.1058],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,927][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0282, 0.2214, 0.1436, 0.1588, 0.0814, 0.1365, 0.1102, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,928][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2309, 0.1175, 0.0876, 0.0834, 0.0931, 0.1338, 0.1113, 0.1424],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,930][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2365, 0.1513, 0.1052, 0.1223, 0.0778, 0.1076, 0.1068, 0.0925],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,931][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([8.4631e-06, 7.1345e-04, 7.3454e-01, 8.3468e-03, 6.9343e-02, 1.1398e-01,
        2.0754e-02, 5.2317e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:03,933][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1219, 0.0605, 0.1274, 0.0787, 0.1243, 0.0948, 0.1032, 0.1516, 0.1377],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,934][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0572, 0.1347, 0.1090, 0.1271, 0.1099, 0.1119, 0.1226, 0.1174, 0.1103],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,936][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0205, 0.0023, 0.0103, 0.0332, 0.0296, 0.0361, 0.1201, 0.2937, 0.4541],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,938][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.5542, 0.0173, 0.0761, 0.0144, 0.1268, 0.0044, 0.0391, 0.1443, 0.0234],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,939][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0166, 0.1120, 0.1218, 0.1350, 0.1282, 0.1197, 0.1098, 0.1344, 0.1225],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,941][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0383, 0.1173, 0.1271, 0.1205, 0.1212, 0.1159, 0.1199, 0.1225, 0.1176],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,942][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.6046, 0.0079, 0.0375, 0.0362, 0.0507, 0.0697, 0.0923, 0.0493, 0.0517],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,943][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1121, 0.1383, 0.1020, 0.1091, 0.1084, 0.1035, 0.1471, 0.0954, 0.0842],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,943][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0193, 0.2144, 0.1365, 0.1515, 0.0730, 0.1292, 0.0988, 0.1085, 0.0689],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,943][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1672, 0.0946, 0.0758, 0.0745, 0.0889, 0.1175, 0.1056, 0.1312, 0.1449],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,944][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2509, 0.1415, 0.0901, 0.1120, 0.0653, 0.0944, 0.0915, 0.0799, 0.0745],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,944][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([5.7117e-07, 2.4130e-05, 4.4729e-03, 3.4845e-04, 2.3665e-03, 1.6542e-03,
        2.2465e-04, 3.0192e-01, 6.8899e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:03,944][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1322, 0.0535, 0.1161, 0.0699, 0.1122, 0.0859, 0.0927, 0.1344, 0.1218,
        0.0813], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,945][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0550, 0.1207, 0.0970, 0.1116, 0.0963, 0.0984, 0.1084, 0.1060, 0.1014,
        0.1052], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,945][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0083, 0.0005, 0.0075, 0.0148, 0.0154, 0.0290, 0.0808, 0.0966, 0.3821,
        0.3651], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,945][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([7.5745e-01, 1.2400e-04, 8.4589e-02, 4.9804e-04, 9.3579e-02, 3.4212e-04,
        4.8643e-03, 1.1761e-02, 4.6728e-02, 6.6562e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,946][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0193, 0.1002, 0.1060, 0.1156, 0.1136, 0.1055, 0.0965, 0.1171, 0.1082,
        0.1180], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,946][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0356, 0.1041, 0.1124, 0.1065, 0.1072, 0.1029, 0.1066, 0.1091, 0.1050,
        0.1107], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,947][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5126, 0.0106, 0.0531, 0.0447, 0.0655, 0.0753, 0.0724, 0.0532, 0.0710,
        0.0417], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,948][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0993, 0.1266, 0.0921, 0.0993, 0.0979, 0.0920, 0.1326, 0.0850, 0.0740,
        0.1012], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,950][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0250, 0.1807, 0.1165, 0.1271, 0.0700, 0.1122, 0.0932, 0.0975, 0.0669,
        0.1109], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,951][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1340, 0.0740, 0.0929, 0.0655, 0.1035, 0.1102, 0.0974, 0.1211, 0.1352,
        0.0662], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,953][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2686, 0.1313, 0.0795, 0.0918, 0.0527, 0.0791, 0.0759, 0.0672, 0.0595,
        0.0944], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,954][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.9335e-13, 9.0696e-12, 3.1700e-05, 2.7223e-10, 3.4115e-06, 2.0068e-06,
        1.6387e-07, 1.1898e-03, 9.9877e-01, 1.0527e-09], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:03,956][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1228, 0.0498, 0.1093, 0.0653, 0.1048, 0.0803, 0.0867, 0.1250, 0.1134,
        0.0754, 0.0674], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,957][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0496, 0.1077, 0.0871, 0.1002, 0.0865, 0.0879, 0.0965, 0.0953, 0.0914,
        0.0951, 0.1028], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,959][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0109, 0.0018, 0.0105, 0.0189, 0.0190, 0.0235, 0.0532, 0.0710, 0.2570,
        0.2608, 0.2734], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,960][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.3228e-01, 5.8471e-04, 8.2957e-02, 3.2873e-04, 7.9033e-02, 4.7219e-04,
        2.3818e-03, 3.5005e-02, 6.6187e-02, 1.9205e-04, 5.7962e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,962][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0170, 0.0898, 0.0959, 0.1043, 0.1029, 0.0947, 0.0874, 0.1059, 0.0972,
        0.1059, 0.0990], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,963][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0316, 0.0937, 0.1010, 0.0962, 0.0967, 0.0927, 0.0961, 0.0980, 0.0944,
        0.0997, 0.0998], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,965][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5035, 0.0049, 0.0313, 0.0228, 0.0450, 0.0598, 0.0710, 0.0532, 0.0617,
        0.0490, 0.0979], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,965][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0917, 0.1160, 0.0833, 0.0900, 0.0885, 0.0840, 0.1202, 0.0773, 0.0677,
        0.0916, 0.0897], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,966][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0234, 0.1528, 0.0991, 0.1089, 0.0632, 0.0967, 0.0843, 0.0870, 0.0619,
        0.1025, 0.1202], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,966][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1562, 0.0737, 0.0772, 0.0517, 0.0827, 0.1068, 0.0849, 0.1052, 0.1369,
        0.0696, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,966][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2321, 0.1140, 0.0782, 0.0919, 0.0514, 0.0716, 0.0663, 0.0627, 0.0549,
        0.0866, 0.0903], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,967][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.3816e-13, 1.0378e-10, 4.2269e-05, 2.4223e-10, 1.3237e-06, 2.1991e-06,
        9.8610e-08, 2.6520e-04, 9.9969e-01, 1.1093e-08, 9.9665e-09],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:03,967][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0989, 0.0465, 0.0961, 0.0597, 0.0948, 0.0725, 0.0775, 0.1143, 0.1040,
        0.0712, 0.0634, 0.1010], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,967][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0489, 0.0987, 0.0796, 0.0925, 0.0802, 0.0817, 0.0893, 0.0877, 0.0825,
        0.0866, 0.0928, 0.0794], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,968][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0041, 0.0019, 0.0044, 0.0176, 0.0093, 0.0306, 0.0626, 0.1443, 0.2400,
        0.1323, 0.1834, 0.1696], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,968][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.3904, 0.0094, 0.0449, 0.0097, 0.0810, 0.0014, 0.0575, 0.2453, 0.0447,
        0.0054, 0.0156, 0.0948], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,968][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0114, 0.0821, 0.0884, 0.0989, 0.0944, 0.0868, 0.0801, 0.0985, 0.0881,
        0.0985, 0.0932, 0.0796], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,969][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0293, 0.0851, 0.0917, 0.0875, 0.0880, 0.0847, 0.0882, 0.0891, 0.0858,
        0.0906, 0.0909, 0.0892], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,969][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.5483, 0.0060, 0.0277, 0.0262, 0.0366, 0.0517, 0.0584, 0.0369, 0.0437,
        0.0354, 0.0906, 0.0383], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,971][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0866, 0.1053, 0.0794, 0.0847, 0.0847, 0.0739, 0.1094, 0.0712, 0.0618,
        0.0829, 0.0804, 0.0797], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,973][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0123, 0.1673, 0.1030, 0.1122, 0.0556, 0.0959, 0.0745, 0.0804, 0.0501,
        0.0848, 0.1082, 0.0556], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,974][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1423, 0.0822, 0.0523, 0.0543, 0.0573, 0.0840, 0.0723, 0.0877, 0.1019,
        0.0745, 0.0625, 0.1289], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,976][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1925, 0.1003, 0.0720, 0.0806, 0.0483, 0.0685, 0.0641, 0.0643, 0.0578,
        0.0892, 0.0880, 0.0744], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,976][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([3.7822e-09, 1.0790e-05, 8.8613e-05, 5.7861e-05, 1.0680e-04, 3.9416e-03,
        9.6539e-04, 1.4579e-02, 9.7696e-01, 4.2417e-04, 2.7547e-03, 1.1285e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:03,979][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0818, 0.0413, 0.0858, 0.0529, 0.0849, 0.0646, 0.0698, 0.1037, 0.0941,
        0.0642, 0.0571, 0.0915, 0.1083], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,980][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0422, 0.0907, 0.0756, 0.0866, 0.0752, 0.0768, 0.0832, 0.0805, 0.0763,
        0.0807, 0.0868, 0.0736, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,981][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0047, 0.0003, 0.0038, 0.0078, 0.0079, 0.0118, 0.0309, 0.0519, 0.1342,
        0.1213, 0.2463, 0.1769, 0.2023], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,983][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.3126, 0.0069, 0.0291, 0.0150, 0.0080, 0.0027, 0.0800, 0.3715, 0.0782,
        0.0038, 0.0169, 0.0650, 0.0104], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,985][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0109, 0.0762, 0.0796, 0.0920, 0.0854, 0.0794, 0.0735, 0.0893, 0.0802,
        0.0916, 0.0869, 0.0728, 0.0821], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,987][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0273, 0.0778, 0.0836, 0.0798, 0.0803, 0.0773, 0.0805, 0.0816, 0.0787,
        0.0828, 0.0830, 0.0814, 0.0859], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,988][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.5041, 0.0063, 0.0220, 0.0217, 0.0224, 0.0419, 0.0571, 0.0377, 0.0485,
        0.0337, 0.0840, 0.0479, 0.0727], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,988][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0730, 0.0963, 0.0698, 0.0767, 0.0762, 0.0690, 0.1006, 0.0635, 0.0555,
        0.0755, 0.0735, 0.0719, 0.0986], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,989][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0090, 0.1598, 0.0976, 0.1131, 0.0504, 0.0948, 0.0720, 0.0836, 0.0488,
        0.0829, 0.1035, 0.0542, 0.0303], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,989][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1144, 0.0714, 0.0499, 0.0540, 0.0537, 0.0725, 0.0648, 0.0818, 0.0964,
        0.0698, 0.0646, 0.1246, 0.0820], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,989][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.2424, 0.1040, 0.0481, 0.0600, 0.0361, 0.0689, 0.0691, 0.0599, 0.0483,
        0.0759, 0.0847, 0.0623, 0.0403], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,990][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([3.5895e-08, 1.8047e-05, 4.4638e-05, 2.1603e-04, 2.8515e-07, 4.5383e-04,
        1.8777e-05, 4.0962e-03, 9.7384e-01, 6.0692e-04, 1.7700e-02, 3.0038e-03,
        3.3209e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:03,990][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0836, 0.0371, 0.0794, 0.0484, 0.0783, 0.0588, 0.0631, 0.0944, 0.0849,
        0.0577, 0.0513, 0.0822, 0.0984, 0.0821], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,990][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0446, 0.0885, 0.0686, 0.0808, 0.0681, 0.0693, 0.0755, 0.0746, 0.0704,
        0.0756, 0.0817, 0.0680, 0.0654, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,991][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0024, 0.0006, 0.0030, 0.0111, 0.0105, 0.0188, 0.0344, 0.0625, 0.1486,
        0.1044, 0.1392, 0.0962, 0.1241, 0.2441], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,991][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1808, 0.0022, 0.1154, 0.0025, 0.1748, 0.0003, 0.0050, 0.0364, 0.0692,
        0.0012, 0.0070, 0.1030, 0.3018, 0.0005], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,992][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0105, 0.0705, 0.0746, 0.0847, 0.0794, 0.0740, 0.0679, 0.0832, 0.0752,
        0.0850, 0.0800, 0.0674, 0.0764, 0.0710], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,992][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0241, 0.0719, 0.0777, 0.0742, 0.0747, 0.0716, 0.0748, 0.0758, 0.0729,
        0.0768, 0.0770, 0.0756, 0.0800, 0.0729], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,994][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.4474, 0.0092, 0.0240, 0.0229, 0.0281, 0.0387, 0.0490, 0.0379, 0.0472,
        0.0363, 0.0711, 0.0495, 0.0774, 0.0612], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,996][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0670, 0.0883, 0.0652, 0.0716, 0.0705, 0.0637, 0.0932, 0.0590, 0.0513,
        0.0695, 0.0674, 0.0665, 0.0909, 0.0759], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,997][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0093, 0.1525, 0.0919, 0.1070, 0.0481, 0.0883, 0.0689, 0.0774, 0.0482,
        0.0825, 0.1055, 0.0525, 0.0306, 0.0372], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:03,998][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1052, 0.0631, 0.0474, 0.0504, 0.0512, 0.0696, 0.0628, 0.0771, 0.0901,
        0.0612, 0.0579, 0.1206, 0.0772, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,000][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1885, 0.1047, 0.0482, 0.0596, 0.0374, 0.0669, 0.0666, 0.0605, 0.0507,
        0.0787, 0.0857, 0.0638, 0.0414, 0.0472], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,001][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([1.1125e-07, 2.6458e-06, 1.0392e-04, 1.8329e-05, 4.8492e-05, 5.4755e-05,
        9.3903e-06, 6.2615e-03, 9.4932e-01, 3.1264e-04, 4.2034e-03, 1.4539e-02,
        7.6174e-04, 2.4359e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,003][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0790, 0.0362, 0.0761, 0.0463, 0.0738, 0.0566, 0.0609, 0.0881, 0.0793,
        0.0538, 0.0481, 0.0771, 0.0913, 0.0776, 0.0558], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,004][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0401, 0.0823, 0.0642, 0.0743, 0.0629, 0.0643, 0.0706, 0.0704, 0.0669,
        0.0702, 0.0762, 0.0647, 0.0619, 0.0647, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,005][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.5992e-03, 5.5761e-05, 1.1595e-03, 2.6124e-03, 3.2677e-03, 7.1790e-03,
        1.6277e-02, 2.9350e-02, 9.2050e-02, 7.1459e-02, 1.4056e-01, 1.4528e-01,
        1.1678e-01, 2.2565e-01, 1.4672e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,008][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.5200, 0.0027, 0.0520, 0.0029, 0.0643, 0.0006, 0.0039, 0.0385, 0.0974,
        0.0012, 0.0045, 0.1066, 0.1023, 0.0006, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,009][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0098, 0.0662, 0.0697, 0.0796, 0.0740, 0.0691, 0.0630, 0.0774, 0.0695,
        0.0790, 0.0754, 0.0639, 0.0712, 0.0663, 0.0660], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,010][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0224, 0.0670, 0.0725, 0.0692, 0.0696, 0.0667, 0.0693, 0.0705, 0.0678,
        0.0715, 0.0716, 0.0704, 0.0746, 0.0681, 0.0687], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,011][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.4190, 0.0048, 0.0195, 0.0140, 0.0245, 0.0389, 0.0394, 0.0291, 0.0371,
        0.0253, 0.0567, 0.0460, 0.0832, 0.0832, 0.0793], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,011][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0673, 0.0816, 0.0609, 0.0660, 0.0651, 0.0613, 0.0872, 0.0574, 0.0502,
        0.0661, 0.0646, 0.0628, 0.0839, 0.0701, 0.0555], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,012][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0082, 0.1448, 0.0848, 0.1049, 0.0449, 0.0832, 0.0675, 0.0765, 0.0462,
        0.0834, 0.1059, 0.0526, 0.0287, 0.0356, 0.0328], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,012][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1108, 0.0571, 0.0417, 0.0406, 0.0434, 0.0652, 0.0531, 0.0678, 0.0939,
        0.0560, 0.0486, 0.1200, 0.0767, 0.0618, 0.0632], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,013][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1705, 0.0825, 0.0573, 0.0672, 0.0438, 0.0649, 0.0619, 0.0551, 0.0454,
        0.0704, 0.0709, 0.0557, 0.0458, 0.0481, 0.0604], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,013][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.7724e-12, 9.9857e-10, 1.1375e-05, 1.9859e-09, 1.6158e-06, 6.6783e-07,
        2.6263e-08, 2.3747e-04, 9.6839e-01, 5.1790e-08, 2.0532e-07, 1.4652e-04,
        3.2783e-05, 3.1172e-02, 2.8785e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,043][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:04,045][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,047][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,048][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,049][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,050][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,052][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,053][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,054][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,056][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,056][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,056][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,056][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,057][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0577, 0.9423], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,057][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1121, 0.8879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,057][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3042, 0.6958], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,058][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4164, 0.5836], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,058][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1035, 0.8965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,058][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7971, 0.2029], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,058][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5991, 0.4009], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,059][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0265, 0.9735], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,059][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0252, 0.9748], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,059][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7693, 0.2307], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,059][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7161, 0.2839], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,060][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0000e+00, 9.7164e-08], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,062][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0516, 0.2008, 0.7476], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,063][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0550, 0.3616, 0.5834], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,065][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.1465, 0.4080, 0.4455], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,066][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2395, 0.3725, 0.3880], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,067][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.1626, 0.2316, 0.6057], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,069][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.2592, 0.0543, 0.6865], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,070][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.4334, 0.2350, 0.3316], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,072][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0073, 0.6477, 0.3449], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,073][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0127, 0.4741, 0.5132], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,075][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.4781, 0.4727, 0.0492], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,077][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.7737, 0.1398, 0.0864], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,078][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([1.0000e+00, 2.8733e-07, 1.1803e-06], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,078][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([4.6207e-04, 1.4495e-01, 8.3652e-01, 1.8066e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,079][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0413, 0.2459, 0.4535, 0.2593], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,079][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1265, 0.2607, 0.3055, 0.3074], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,080][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1905, 0.2719, 0.2847, 0.2529], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,080][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0711, 0.5451, 0.0722, 0.3115], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,080][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1521, 0.0974, 0.6120, 0.1385], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,080][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3105, 0.2018, 0.2956, 0.1921], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,081][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0115, 0.4400, 0.2640, 0.2844], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,081][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0083, 0.3203, 0.3454, 0.3259], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,081][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5954, 0.2535, 0.0314, 0.1198], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,082][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4925, 0.1999, 0.0971, 0.2105], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,082][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.9432e-07, 4.2403e-07, 1.0000e+00, 1.4148e-09], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,082][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0197, 0.1254, 0.6043, 0.0099, 0.2408], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,082][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0278, 0.1797, 0.3355, 0.2000, 0.2571], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,083][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0742, 0.2247, 0.2324, 0.2702, 0.1985], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,085][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1288, 0.2130, 0.2215, 0.2054, 0.2312], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,086][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0102, 0.0406, 0.0434, 0.0150, 0.8907], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,088][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0700, 0.0278, 0.2873, 0.1693, 0.4457], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,089][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.2858, 0.1547, 0.2235, 0.1456, 0.1905], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,090][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0052, 0.3428, 0.2077, 0.2348, 0.2095], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,091][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0063, 0.2348, 0.2563, 0.2430, 0.2597], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,093][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.3585, 0.2032, 0.0384, 0.1290, 0.2709], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,095][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.4894, 0.1720, 0.0963, 0.1710, 0.0713], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,096][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([9.9740e-01, 4.8408e-07, 2.5953e-03, 3.1755e-09, 3.1727e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,097][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0232, 0.0560, 0.2159, 0.0078, 0.1102, 0.5869], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,099][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0210, 0.1377, 0.2622, 0.1576, 0.2179, 0.2037], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,101][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0574, 0.1772, 0.1941, 0.2147, 0.1671, 0.1895], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,102][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1095, 0.1736, 0.1814, 0.1673, 0.1881, 0.1801], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,102][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0034, 0.0127, 0.0065, 0.0022, 0.0602, 0.9151], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,102][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0328, 0.0108, 0.3628, 0.1911, 0.3762, 0.0264], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,103][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2302, 0.1282, 0.1848, 0.1228, 0.1650, 0.1689], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,103][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0065, 0.2850, 0.1571, 0.1851, 0.1590, 0.2074], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,103][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0052, 0.1893, 0.2079, 0.1970, 0.2075, 0.1931], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,104][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2156, 0.1399, 0.0171, 0.0700, 0.2006, 0.3568], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,104][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5601, 0.1240, 0.0495, 0.0954, 0.0538, 0.1171], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,104][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([9.3638e-01, 6.5681e-07, 5.2170e-02, 4.5146e-09, 1.0714e-02, 7.3202e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,104][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.0064e-02, 3.9616e-04, 2.6316e-03, 5.6359e-05, 9.5769e-04, 4.4734e-02,
        9.4116e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,105][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0153, 0.1097, 0.2139, 0.1219, 0.1861, 0.1797, 0.1734],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,105][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0478, 0.1505, 0.1643, 0.1802, 0.1407, 0.1602, 0.1563],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,105][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0922, 0.1481, 0.1543, 0.1404, 0.1595, 0.1532, 0.1522],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,106][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0043, 0.0676, 0.0325, 0.0162, 0.2117, 0.3643, 0.3034],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,108][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0141, 0.0076, 0.6288, 0.0403, 0.2907, 0.0102, 0.0084],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,109][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2060, 0.1090, 0.1569, 0.1034, 0.1401, 0.1423, 0.1423],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,111][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0059, 0.2359, 0.1206, 0.1440, 0.1192, 0.1695, 0.2049],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,112][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0035, 0.1665, 0.1793, 0.1722, 0.1799, 0.1656, 0.1329],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,113][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2660, 0.1038, 0.0183, 0.0520, 0.2112, 0.2627, 0.0860],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,114][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4759, 0.1058, 0.0452, 0.0892, 0.0521, 0.1083, 0.1234],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,116][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.9763e-01, 1.2354e-13, 3.9745e-09, 8.4446e-16, 9.4962e-11, 2.4299e-07,
        2.3673e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,117][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([3.2238e-03, 6.5349e-08, 1.6424e-06, 2.1664e-08, 5.5648e-07, 1.4032e-05,
        6.8732e-04, 9.9607e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,118][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0177, 0.1043, 0.1706, 0.1129, 0.1468, 0.1506, 0.1590, 0.1380],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,120][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0399, 0.1322, 0.1343, 0.1621, 0.1167, 0.1358, 0.1386, 0.1403],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,122][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0789, 0.1286, 0.1334, 0.1223, 0.1384, 0.1326, 0.1319, 0.1339],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,123][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0160, 0.0221, 0.0113, 0.0116, 0.0101, 0.3115, 0.0250, 0.5924],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,124][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0567, 0.0058, 0.1917, 0.1121, 0.3867, 0.0216, 0.1074, 0.1180],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,125][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1595, 0.0956, 0.1364, 0.0914, 0.1235, 0.1262, 0.1278, 0.1396],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,125][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0029, 0.1968, 0.0955, 0.1292, 0.0985, 0.1464, 0.1758, 0.1548],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,126][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0033, 0.1470, 0.1580, 0.1504, 0.1597, 0.1465, 0.1173, 0.1177],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,126][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2439, 0.1031, 0.0095, 0.0488, 0.1474, 0.2133, 0.1024, 0.1316],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,126][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2366, 0.1329, 0.0383, 0.1098, 0.0448, 0.1107, 0.1480, 0.1788],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,126][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.3099e-02, 9.3722e-27, 2.7812e-21, 1.1022e-28, 7.0249e-23, 1.5578e-21,
        6.8019e-15, 9.7690e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,127][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([1.3945e-04, 1.9307e-08, 2.0997e-07, 4.5039e-09, 8.5419e-08, 3.1731e-06,
        2.1435e-04, 8.7058e-01, 1.2906e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,127][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0138, 0.0819, 0.1567, 0.0981, 0.1397, 0.1358, 0.1406, 0.1321, 0.1013],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,127][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0319, 0.1135, 0.1156, 0.1397, 0.1008, 0.1200, 0.1239, 0.1254, 0.1292],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,128][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0696, 0.1126, 0.1184, 0.1074, 0.1221, 0.1166, 0.1160, 0.1178, 0.1194],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,128][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0243, 0.0324, 0.1052, 0.0151, 0.3006, 0.2711, 0.1579, 0.0179, 0.0755],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,128][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0114, 0.0019, 0.0361, 0.0206, 0.0232, 0.0056, 0.0093, 0.8865, 0.0054],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,129][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1373, 0.0832, 0.1198, 0.0787, 0.1066, 0.1112, 0.1116, 0.1230, 0.1287],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,131][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0030, 0.1620, 0.0836, 0.1092, 0.0871, 0.1304, 0.1518, 0.1380, 0.1349],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,132][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0033, 0.1309, 0.1429, 0.1330, 0.1428, 0.1305, 0.1029, 0.1045, 0.1093],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,134][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1685, 0.0775, 0.0096, 0.0457, 0.1211, 0.1952, 0.1247, 0.1878, 0.0698],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,135][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2360, 0.0791, 0.0345, 0.0759, 0.0310, 0.0779, 0.1178, 0.1196, 0.2281],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,136][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([1.4643e-08, 8.9334e-31, 2.6967e-26, 6.8943e-33, 1.6454e-27, 3.7021e-25,
        1.8017e-18, 1.0000e+00, 2.4987e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,137][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([1.1146e-06, 1.3419e-08, 1.7772e-07, 2.0666e-09, 8.9863e-08, 1.0169e-06,
        7.9328e-05, 9.0409e-01, 9.5118e-02, 7.1370e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,139][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0108, 0.0682, 0.1419, 0.0835, 0.1191, 0.1248, 0.1380, 0.1255, 0.1098,
        0.0783], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,140][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0331, 0.0954, 0.1026, 0.1116, 0.0911, 0.1080, 0.1073, 0.1093, 0.1131,
        0.1285], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,142][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0681, 0.1026, 0.1058, 0.0949, 0.1080, 0.1041, 0.1026, 0.1037, 0.1053,
        0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,143][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0206, 0.2110, 0.0368, 0.0859, 0.0724, 0.4175, 0.0185, 0.0707, 0.0076,
        0.0589], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,145][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([5.7437e-03, 4.7117e-04, 2.4660e-02, 4.0622e-02, 5.1042e-02, 4.9073e-03,
        3.1390e-02, 7.8670e-01, 5.0188e-02, 4.2722e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,146][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1227, 0.0735, 0.1052, 0.0697, 0.0951, 0.0976, 0.0986, 0.1083, 0.1142,
        0.1153], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,148][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0040, 0.1372, 0.0812, 0.0895, 0.0809, 0.0996, 0.1210, 0.1132, 0.1074,
        0.1661], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,148][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0031, 0.1185, 0.1299, 0.1207, 0.1287, 0.1170, 0.0934, 0.0955, 0.0982,
        0.0949], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,148][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2775, 0.0600, 0.0074, 0.0274, 0.0987, 0.1811, 0.0652, 0.1560, 0.0846,
        0.0422], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,149][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2691, 0.0720, 0.0305, 0.0630, 0.0312, 0.0694, 0.0803, 0.0902, 0.1853,
        0.1091], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,149][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([8.2929e-19, 5.3731e-32, 1.6083e-24, 9.8499e-35, 3.5486e-26, 7.6194e-26,
        1.0498e-18, 9.9795e-01, 2.0491e-03, 7.6575e-13], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,149][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.1166e-06, 1.0794e-08, 2.0124e-07, 1.2577e-09, 8.6406e-08, 1.0247e-06,
        1.1865e-04, 8.8605e-01, 1.1042e-01, 9.5801e-04, 2.4530e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,150][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0100, 0.0677, 0.1322, 0.0754, 0.1164, 0.1126, 0.1201, 0.1127, 0.0982,
        0.0767, 0.0780], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,150][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0332, 0.0846, 0.0904, 0.0973, 0.0815, 0.0968, 0.0956, 0.0966, 0.1005,
        0.1123, 0.1112], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,150][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0634, 0.0927, 0.0963, 0.0859, 0.0986, 0.0951, 0.0935, 0.0943, 0.0955,
        0.0946, 0.0901], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,151][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0320, 0.2502, 0.0213, 0.1289, 0.0680, 0.1711, 0.0344, 0.0810, 0.0042,
        0.0614, 0.1476], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,151][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0139, 0.0029, 0.0334, 0.0040, 0.0645, 0.0092, 0.0822, 0.6000, 0.1198,
        0.0512, 0.0190], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,151][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1083, 0.0658, 0.0938, 0.0620, 0.0840, 0.0867, 0.0886, 0.0962, 0.1023,
        0.1042, 0.1083], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,152][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0040, 0.1179, 0.0724, 0.0747, 0.0702, 0.0840, 0.1048, 0.1004, 0.0945,
        0.1401, 0.1369], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,154][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0027, 0.1083, 0.1191, 0.1118, 0.1187, 0.1074, 0.0867, 0.0884, 0.0908,
        0.0877, 0.0783], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,155][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1654, 0.0807, 0.0074, 0.0347, 0.1025, 0.2252, 0.0795, 0.1339, 0.0659,
        0.0670, 0.0379], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,157][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2342, 0.0679, 0.0287, 0.0646, 0.0284, 0.0586, 0.0634, 0.0698, 0.1645,
        0.0958, 0.1242], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,158][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.3581e-16, 3.6746e-31, 6.8143e-24, 1.7976e-34, 7.6626e-26, 6.3806e-26,
        1.6637e-18, 9.9858e-01, 1.4216e-03, 1.8988e-11, 9.2690e-11],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,159][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([1.3170e-03, 6.2773e-09, 5.5057e-08, 1.0069e-09, 2.9015e-08, 5.8504e-07,
        3.4155e-05, 4.6699e-02, 6.9509e-03, 1.2955e-04, 2.9986e-04, 9.4457e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,160][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0118, 0.0624, 0.1111, 0.0717, 0.0987, 0.1022, 0.1046, 0.1012, 0.0816,
        0.0712, 0.0757, 0.1078], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,162][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0216, 0.0786, 0.0834, 0.1006, 0.0736, 0.0827, 0.0849, 0.0872, 0.0886,
        0.1102, 0.1099, 0.0787], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,164][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0546, 0.0839, 0.0863, 0.0797, 0.0896, 0.0857, 0.0851, 0.0862, 0.0872,
        0.0877, 0.0841, 0.0899], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,165][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0348, 0.3298, 0.0613, 0.1103, 0.0130, 0.1414, 0.0044, 0.0556, 0.0019,
        0.1086, 0.1085, 0.0304], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,167][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0144, 0.0022, 0.0270, 0.0668, 0.0666, 0.0232, 0.0452, 0.2877, 0.0481,
        0.0356, 0.2490, 0.1344], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,169][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0971, 0.0613, 0.0844, 0.0564, 0.0748, 0.0780, 0.0791, 0.0857, 0.0913,
        0.0934, 0.0961, 0.1025], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,170][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0022, 0.1038, 0.0626, 0.0723, 0.0627, 0.0857, 0.0981, 0.0885, 0.0862,
        0.1221, 0.1227, 0.0931], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,171][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0031, 0.0980, 0.1087, 0.1014, 0.1105, 0.1013, 0.0791, 0.0809, 0.0841,
        0.0795, 0.0707, 0.0826], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,171][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1034, 0.0688, 0.0055, 0.0353, 0.0693, 0.1884, 0.1317, 0.0979, 0.0839,
        0.0688, 0.0387, 0.1085], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,172][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1630, 0.0579, 0.0240, 0.0593, 0.0243, 0.0620, 0.0750, 0.0827, 0.1664,
        0.1069, 0.1268, 0.0518], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,172][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.4078e-04, 5.5024e-32, 1.5024e-26, 2.5784e-33, 1.2454e-27, 3.9309e-25,
        1.4434e-20, 1.2233e-05, 5.1829e-09, 1.4507e-14, 4.2455e-13, 9.9985e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,172][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([2.3259e-03, 8.7427e-09, 8.6573e-08, 6.0325e-10, 1.5041e-08, 7.4710e-07,
        3.8915e-05, 1.5158e-02, 6.7406e-03, 1.2642e-04, 2.1386e-04, 4.3023e-01,
        5.4516e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,173][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0109, 0.0581, 0.1062, 0.0644, 0.0830, 0.0913, 0.0979, 0.0891, 0.0730,
        0.0644, 0.0693, 0.1010, 0.0914], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,173][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0180, 0.0730, 0.0768, 0.0930, 0.0655, 0.0767, 0.0804, 0.0808, 0.0851,
        0.1074, 0.1080, 0.0740, 0.0612], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,173][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0468, 0.0764, 0.0783, 0.0737, 0.0814, 0.0782, 0.0783, 0.0793, 0.0801,
        0.0813, 0.0778, 0.0824, 0.0860], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,174][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0061, 0.0201, 0.0169, 0.0076, 0.3164, 0.0454, 0.0023, 0.0079, 0.0008,
        0.0108, 0.0080, 0.0010, 0.5568], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,174][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0170, 0.0011, 0.0228, 0.0090, 0.0305, 0.0123, 0.0164, 0.1837, 0.0129,
        0.0110, 0.0299, 0.4028, 0.2505], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,174][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0951, 0.0512, 0.0753, 0.0481, 0.0642, 0.0674, 0.0689, 0.0768, 0.0839,
        0.0839, 0.0872, 0.0958, 0.1020], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,175][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0019, 0.0903, 0.0530, 0.0616, 0.0563, 0.0748, 0.0868, 0.0801, 0.0780,
        0.1147, 0.1101, 0.0844, 0.1079], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,177][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0026, 0.0883, 0.0986, 0.0931, 0.1011, 0.0926, 0.0731, 0.0743, 0.0770,
        0.0735, 0.0657, 0.0751, 0.0849], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,179][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.1089, 0.0515, 0.0096, 0.0317, 0.0718, 0.1499, 0.0884, 0.1394, 0.0737,
        0.0466, 0.0330, 0.1250, 0.0705], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,180][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.1868, 0.0577, 0.0275, 0.0488, 0.0202, 0.0732, 0.0785, 0.0828, 0.1308,
        0.0951, 0.1166, 0.0430, 0.0390], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,181][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([4.1686e-05, 3.5555e-32, 5.1360e-27, 4.2888e-35, 3.0045e-31, 2.9395e-27,
        5.8591e-23, 8.4870e-09, 2.4190e-11, 8.2729e-16, 1.4516e-15, 9.9975e-01,
        2.0629e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,182][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([5.2233e-04, 1.0186e-08, 1.8708e-07, 1.1790e-09, 3.1947e-08, 5.7416e-07,
        2.9507e-05, 8.4990e-02, 7.1399e-03, 1.7928e-04, 2.9613e-04, 3.4670e-01,
        4.5828e-01, 1.0186e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,183][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0094, 0.0512, 0.0924, 0.0569, 0.0870, 0.0824, 0.0827, 0.0873, 0.0705,
        0.0596, 0.0606, 0.0911, 0.0939, 0.0751], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,185][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0230, 0.0700, 0.0731, 0.0860, 0.0642, 0.0727, 0.0759, 0.0758, 0.0778,
        0.0937, 0.0939, 0.0690, 0.0592, 0.0655], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,187][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0445, 0.0699, 0.0726, 0.0677, 0.0755, 0.0725, 0.0725, 0.0736, 0.0743,
        0.0747, 0.0716, 0.0763, 0.0798, 0.0744], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,188][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([1.5379e-03, 2.1776e-03, 8.5470e-03, 3.4182e-04, 1.4581e-02, 2.9871e-02,
        2.5469e-03, 8.2638e-04, 3.8222e-03, 1.2543e-03, 4.2196e-04, 1.8688e-04,
        3.1355e-02, 9.0253e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,189][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([3.7188e-03, 8.0505e-04, 5.6379e-03, 2.1706e-02, 1.7992e-02, 1.2261e-03,
        1.5874e-02, 5.6300e-02, 1.6300e-02, 8.9357e-03, 1.0038e-01, 6.2014e-01,
        1.3040e-01, 5.8745e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,191][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0888, 0.0476, 0.0687, 0.0444, 0.0597, 0.0619, 0.0635, 0.0712, 0.0759,
        0.0771, 0.0798, 0.0876, 0.0927, 0.0812], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,192][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0017, 0.0925, 0.0510, 0.0589, 0.0522, 0.0691, 0.0809, 0.0752, 0.0698,
        0.1035, 0.1017, 0.0756, 0.0943, 0.0736], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,194][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0022, 0.0822, 0.0914, 0.0857, 0.0934, 0.0869, 0.0679, 0.0679, 0.0703,
        0.0671, 0.0597, 0.0694, 0.0774, 0.0786], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,194][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1050, 0.0558, 0.0034, 0.0243, 0.0897, 0.1402, 0.0627, 0.0736, 0.0721,
        0.0490, 0.0273, 0.1206, 0.0904, 0.0859], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,195][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.2217, 0.0401, 0.0184, 0.0379, 0.0205, 0.0429, 0.0563, 0.0665, 0.1468,
        0.0773, 0.0872, 0.0387, 0.0439, 0.1017], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,195][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.4851e-09, 4.4457e-33, 2.4803e-27, 1.3386e-35, 2.3504e-29, 1.3367e-27,
        1.8306e-22, 1.4864e-07, 7.0697e-10, 6.1682e-16, 2.4886e-15, 8.3011e-01,
        1.6988e-01, 3.5634e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,195][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.2997e-04, 2.0210e-09, 3.4657e-08, 1.8795e-10, 4.9593e-09, 3.2034e-07,
        1.6862e-05, 1.1092e-02, 4.3782e-03, 4.9489e-05, 8.7086e-05, 2.7797e-01,
        2.3516e-01, 3.7134e-01, 9.9676e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,196][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0066, 0.0449, 0.0874, 0.0507, 0.0805, 0.0738, 0.0803, 0.0790, 0.0748,
        0.0524, 0.0554, 0.0851, 0.0903, 0.0775, 0.0613], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,196][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0210, 0.0655, 0.0691, 0.0792, 0.0604, 0.0700, 0.0711, 0.0689, 0.0713,
        0.0853, 0.0856, 0.0623, 0.0562, 0.0620, 0.0721], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,196][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0392, 0.0658, 0.0679, 0.0634, 0.0703, 0.0675, 0.0674, 0.0680, 0.0688,
        0.0700, 0.0669, 0.0711, 0.0739, 0.0691, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,197][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0246, 0.1835, 0.0344, 0.0807, 0.0716, 0.0955, 0.1058, 0.0587, 0.0131,
        0.0774, 0.0853, 0.0051, 0.1240, 0.0307, 0.0096], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,197][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([9.5827e-04, 1.5117e-04, 8.8525e-03, 4.0620e-03, 4.0951e-02, 3.2157e-04,
        6.5920e-03, 5.0955e-02, 4.6895e-02, 2.4609e-03, 2.3632e-02, 3.0297e-01,
        5.0884e-01, 2.2618e-03, 1.0272e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,197][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0858, 0.0453, 0.0635, 0.0422, 0.0555, 0.0570, 0.0577, 0.0648, 0.0688,
        0.0703, 0.0729, 0.0801, 0.0846, 0.0747, 0.0768], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,198][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0026, 0.0870, 0.0486, 0.0523, 0.0465, 0.0618, 0.0749, 0.0694, 0.0645,
        0.0943, 0.0912, 0.0701, 0.0861, 0.0677, 0.0830], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,200][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0022, 0.0774, 0.0855, 0.0805, 0.0870, 0.0795, 0.0639, 0.0653, 0.0667,
        0.0640, 0.0571, 0.0655, 0.0732, 0.0726, 0.0595], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,201][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1530, 0.0407, 0.0057, 0.0214, 0.0784, 0.0928, 0.0650, 0.0985, 0.0647,
        0.0382, 0.0251, 0.0800, 0.0792, 0.0956, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,203][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1665, 0.0463, 0.0202, 0.0411, 0.0244, 0.0353, 0.0426, 0.0544, 0.1505,
        0.0692, 0.0783, 0.0413, 0.0516, 0.0818, 0.0965], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,204][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.5922e-08, 7.8992e-34, 1.0848e-26, 2.5335e-37, 7.5256e-30, 2.8839e-27,
        2.9113e-22, 5.9181e-08, 3.3147e-09, 8.7855e-17, 1.2432e-16, 6.4523e-01,
        3.5394e-01, 5.6787e-04, 2.6881e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,205][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:04,207][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[18540],
        [ 8803],
        [10490],
        [ 1197],
        [ 6775],
        [ 3762],
        [ 4036],
        [ 6474],
        [ 6803],
        [ 3643],
        [ 3708],
        [ 5061],
        [19290],
        [ 4713],
        [11664]], device='cuda:0')
[2024-07-24 10:17:04,208][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[19738],
        [22975],
        [39436],
        [ 5673],
        [27200],
        [25184],
        [20134],
        [29089],
        [29009],
        [25906],
        [24044],
        [24931],
        [44532],
        [30428],
        [37881]], device='cuda:0')
[2024-07-24 10:17:04,210][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15607],
        [15753],
        [15968],
        [16339],
        [16194],
        [15926],
        [15569],
        [14620],
        [13864],
        [13696],
        [13730],
        [13414],
        [13246],
        [13304],
        [13378]], device='cuda:0')
[2024-07-24 10:17:04,211][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30310],
        [25113],
        [23031],
        [22479],
        [21329],
        [21010],
        [20376],
        [19999],
        [19745],
        [19557],
        [19371],
        [19675],
        [19390],
        [19365],
        [19116]], device='cuda:0')
[2024-07-24 10:17:04,213][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[16573],
        [11754],
        [ 2962],
        [ 6546],
        [ 7171],
        [ 5462],
        [13224],
        [ 7627],
        [ 6239],
        [ 7530],
        [ 7538],
        [ 5905],
        [ 7711],
        [ 7391],
        [ 8164]], device='cuda:0')
[2024-07-24 10:17:04,215][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[19701],
        [19704],
        [ 1369],
        [ 3631],
        [ 8451],
        [ 1397],
        [ 3723],
        [13613],
        [10627],
        [ 5031],
        [ 7152],
        [24410],
        [33864],
        [ 3165],
        [ 7961]], device='cuda:0')
[2024-07-24 10:17:04,216][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[12245],
        [11260],
        [ 9810],
        [10315],
        [10032],
        [10188],
        [10988],
        [11460],
        [11769],
        [12027],
        [11953],
        [12144],
        [12203],
        [12221],
        [12230]], device='cuda:0')
[2024-07-24 10:17:04,217][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24986],
        [20672],
        [18580],
        [17354],
        [16996],
        [16996],
        [17427],
        [16851],
        [16436],
        [15950],
        [15678],
        [15590],
        [15492],
        [15218],
        [15119]], device='cuda:0')
[2024-07-24 10:17:04,219][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23804],
        [23812],
        [18233],
        [14672],
        [11476],
        [10771],
        [12878],
        [10492],
        [10615],
        [10898],
        [12469],
        [12783],
        [12434],
        [11784],
        [11591]], device='cuda:0')
[2024-07-24 10:17:04,220][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[35910],
        [37082],
        [37140],
        [37075],
        [37274],
        [37230],
        [36998],
        [36905],
        [36861],
        [36738],
        [36639],
        [36562],
        [36653],
        [36564],
        [36535]], device='cuda:0')
[2024-07-24 10:17:04,221][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[5255],
        [5257],
        [7722],
        [8142],
        [8601],
        [8754],
        [8623],
        [8768],
        [8763],
        [8478],
        [8525],
        [8857],
        [8910],
        [9101],
        [9163]], device='cuda:0')
[2024-07-24 10:17:04,221][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[21179],
        [16626],
        [17995],
        [16975],
        [16640],
        [17516],
        [18434],
        [19071],
        [20039],
        [20126],
        [20119],
        [18417],
        [18428],
        [18396],
        [18449]], device='cuda:0')
[2024-07-24 10:17:04,222][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[4756],
        [3836],
        [2681],
        [1628],
        [1596],
        [1851],
        [1960],
        [2039],
        [2068],
        [2221],
        [2434],
        [2455],
        [2581],
        [2441],
        [2283]], device='cuda:0')
[2024-07-24 10:17:04,223][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[6949],
        [3673],
        [4339],
        [5857],
        [2848],
        [4861],
        [2515],
        [2996],
        [2730],
        [6147],
        [6164],
        [5843],
        [5904],
        [5873],
        [6101]], device='cuda:0')
[2024-07-24 10:17:04,225][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 6021],
        [14484],
        [  833],
        [ 7190],
        [ 7476],
        [10254],
        [ 7167],
        [ 6814],
        [15435],
        [16724],
        [11326],
        [11338],
        [19847],
        [ 5235],
        [ 9094]], device='cuda:0')
[2024-07-24 10:17:04,226][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[10933],
        [ 1392],
        [ 3358],
        [ 3677],
        [ 5915],
        [  846],
        [  595],
        [ 1257],
        [ 1384],
        [ 1338],
        [ 1350],
        [ 1949],
        [ 6287],
        [ 4955],
        [ 1122]], device='cuda:0')
[2024-07-24 10:17:04,228][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29930],
        [25846],
        [29700],
        [26676],
        [29576],
        [30352],
        [31211],
        [29319],
        [27891],
        [27421],
        [26897],
        [25062],
        [25582],
        [25009],
        [24377]], device='cuda:0')
[2024-07-24 10:17:04,229][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[10571],
        [ 7467],
        [ 7899],
        [ 7939],
        [ 7717],
        [ 7874],
        [ 8565],
        [ 9531],
        [ 9813],
        [10137],
        [10131],
        [10636],
        [10646],
        [10846],
        [11017]], device='cuda:0')
[2024-07-24 10:17:04,231][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[8718],
        [8601],
        [8682],
        [8903],
        [9290],
        [8937],
        [8533],
        [8199],
        [7944],
        [7823],
        [7785],
        [7789],
        [7769],
        [7731],
        [7736]], device='cuda:0')
[2024-07-24 10:17:04,232][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 4306],
        [24027],
        [36712],
        [24636],
        [24826],
        [10978],
        [10831],
        [ 3155],
        [17554],
        [11908],
        [14709],
        [19797],
        [28237],
        [19991],
        [17175]], device='cuda:0')
[2024-07-24 10:17:04,234][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6136],
        [ 7148],
        [11648],
        [13085],
        [17971],
        [16632],
        [13391],
        [11863],
        [  351],
        [  370],
        [  391],
        [ 2517],
        [ 4486],
        [ 2287],
        [11979]], device='cuda:0')
[2024-07-24 10:17:04,235][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[3760],
        [2320],
        [2016],
        [1921],
        [1957],
        [2022],
        [2048],
        [2222],
        [2230],
        [2218],
        [2190],
        [2142],
        [2086],
        [2120],
        [2165]], device='cuda:0')
[2024-07-24 10:17:04,237][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[1838],
        [2576],
        [3137],
        [3078],
        [3361],
        [3001],
        [2670],
        [2716],
        [2946],
        [2921],
        [2822],
        [2904],
        [3045],
        [3015],
        [3021]], device='cuda:0')
[2024-07-24 10:17:04,239][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[21232],
        [21579],
        [19593],
        [19303],
        [19089],
        [19315],
        [19244],
        [19163],
        [18985],
        [19003],
        [19022],
        [18805],
        [18815],
        [18776],
        [18828]], device='cuda:0')
[2024-07-24 10:17:04,240][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[1605],
        [1433],
        [1257],
        [1178],
        [ 888],
        [ 743],
        [ 672],
        [ 838],
        [ 852],
        [ 771],
        [ 857],
        [ 867],
        [ 877],
        [ 722],
        [ 679]], device='cuda:0')
[2024-07-24 10:17:04,241][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2952],
        [ 5533],
        [ 4570],
        [ 7045],
        [ 7105],
        [ 6715],
        [ 8330],
        [ 9882],
        [ 9643],
        [ 9807],
        [10194],
        [10519],
        [10511],
        [10471],
        [10848]], device='cuda:0')
[2024-07-24 10:17:04,243][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[47701],
        [47701],
        [47701],
        [46692],
        [47706],
        [47807],
        [47722],
        [44250],
        [43603],
        [43622],
        [43615],
        [38876],
        [38877],
        [43250],
        [45857]], device='cuda:0')
[2024-07-24 10:17:04,245][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48554],
        [48976],
        [47372],
        [45645],
        [46646],
        [48439],
        [48620],
        [48052],
        [48929],
        [49109],
        [49091],
        [48478],
        [47214],
        [47347],
        [47501]], device='cuda:0')
[2024-07-24 10:17:04,246][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[44667],
        [43279],
        [49585],
        [46954],
        [47618],
        [46694],
        [48641],
        [49176],
        [41517],
        [36223],
        [41251],
        [44146],
        [39614],
        [48597],
        [47408]], device='cuda:0')
[2024-07-24 10:17:04,248][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830],
        [32830]], device='cuda:0')
[2024-07-24 10:17:04,280][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:04,280][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,281][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,281][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,281][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,282][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,282][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,282][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,282][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,283][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,283][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,283][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,284][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,286][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0203, 0.9797], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,287][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9366, 0.0634], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,289][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0447, 0.9553], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,290][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6300, 0.3700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,291][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3098, 0.6902], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,292][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2870, 0.7130], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,294][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3368, 0.6632], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,296][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7810, 0.2190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,297][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0809, 0.9191], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,299][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4792, 0.5208], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,301][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0575, 0.9425], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,302][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0985, 0.9015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,303][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0064, 0.4363, 0.5573], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,303][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.9641, 0.0264, 0.0095], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,303][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0190, 0.4996, 0.4813], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,304][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.3072, 0.2668, 0.4260], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,304][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.1500, 0.3309, 0.5191], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,304][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1287, 0.4425, 0.4289], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,305][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1520, 0.4999, 0.3482], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,305][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.7382, 0.1635, 0.0982], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,305][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.0374, 0.4965, 0.4662], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,305][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.3213, 0.3480, 0.3307], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,306][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0222, 0.5065, 0.4713], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,306][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0491, 0.4266, 0.5243], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,306][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0062, 0.2974, 0.3816, 0.3149], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,306][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6883, 0.0787, 0.0379, 0.1951], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,307][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0162, 0.3295, 0.3219, 0.3324], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,309][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3099, 0.2195, 0.2851, 0.1855], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,310][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0779, 0.2270, 0.3764, 0.3187], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,312][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1099, 0.2758, 0.3268, 0.2874], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,313][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1227, 0.2921, 0.2890, 0.2962], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,314][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6886, 0.1432, 0.0900, 0.0782], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,315][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0285, 0.3307, 0.3128, 0.3280], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,317][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2389, 0.2597, 0.2510, 0.2505], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,319][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0185, 0.3353, 0.3002, 0.3460], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,320][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0301, 0.2874, 0.3472, 0.3353], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,322][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0047, 0.2063, 0.2698, 0.2395, 0.2798], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,324][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.8299, 0.0323, 0.0142, 0.0981, 0.0254], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,325][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0086, 0.2520, 0.2429, 0.2525, 0.2441], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,326][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1926, 0.1664, 0.2139, 0.2102, 0.2169], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,326][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0564, 0.1653, 0.2973, 0.2462, 0.2349], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,326][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0652, 0.2228, 0.2733, 0.2462, 0.1925], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,327][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0904, 0.2463, 0.1975, 0.2785, 0.1874], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,327][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.6430, 0.1264, 0.0828, 0.0823, 0.0655], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,327][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0188, 0.2534, 0.2369, 0.2531, 0.2377], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,328][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1916, 0.2078, 0.2001, 0.1999, 0.2006], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,328][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0145, 0.2382, 0.2287, 0.2454, 0.2733], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,328][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0222, 0.2104, 0.2582, 0.2472, 0.2620], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,328][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0045, 0.1650, 0.2186, 0.1886, 0.2278, 0.1955], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,329][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.8531, 0.0252, 0.0088, 0.0816, 0.0171, 0.0142], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,329][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0075, 0.2066, 0.1959, 0.2051, 0.1970, 0.1880], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,329][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1308, 0.1140, 0.1761, 0.1580, 0.2610, 0.1601], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,330][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0490, 0.1360, 0.2538, 0.1832, 0.1965, 0.1815], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,332][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0718, 0.1821, 0.1973, 0.1938, 0.1858, 0.1691], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,333][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0941, 0.1918, 0.1654, 0.1999, 0.1888, 0.1601], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,335][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.6066, 0.1250, 0.0778, 0.0749, 0.0582, 0.0575], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,336][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0163, 0.2044, 0.1919, 0.2039, 0.1924, 0.1910], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,337][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1589, 0.1722, 0.1672, 0.1670, 0.1676, 0.1671], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,338][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0100, 0.2010, 0.1795, 0.2093, 0.2107, 0.1894], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,340][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0206, 0.1695, 0.2067, 0.1976, 0.2083, 0.1974], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,342][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0033, 0.1413, 0.1804, 0.1612, 0.1875, 0.1706, 0.1556],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,343][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.8869, 0.0171, 0.0050, 0.0639, 0.0104, 0.0088, 0.0079],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,345][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0065, 0.1715, 0.1644, 0.1716, 0.1659, 0.1583, 0.1617],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,347][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1859, 0.0852, 0.1174, 0.1147, 0.2083, 0.1943, 0.0943],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,348][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0413, 0.1198, 0.2329, 0.1522, 0.1662, 0.1564, 0.1311],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,349][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0526, 0.1457, 0.1606, 0.1637, 0.1679, 0.1527, 0.1568],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,349][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0691, 0.1648, 0.1507, 0.1720, 0.1648, 0.1483, 0.1303],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,349][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.5369, 0.1249, 0.0750, 0.0689, 0.0585, 0.0593, 0.0764],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,350][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0137, 0.1702, 0.1601, 0.1701, 0.1608, 0.1596, 0.1655],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,350][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1352, 0.1464, 0.1425, 0.1423, 0.1428, 0.1427, 0.1482],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,350][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0110, 0.1661, 0.1494, 0.1685, 0.1771, 0.1508, 0.1771],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,351][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0180, 0.1417, 0.1709, 0.1637, 0.1718, 0.1644, 0.1695],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,351][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0028, 0.1208, 0.1555, 0.1335, 0.1637, 0.1471, 0.1356, 0.1411],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,351][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.8915, 0.0140, 0.0045, 0.0588, 0.0100, 0.0089, 0.0071, 0.0052],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,351][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0061, 0.1479, 0.1409, 0.1465, 0.1416, 0.1351, 0.1385, 0.1433],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,352][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2256, 0.0876, 0.1059, 0.1109, 0.1691, 0.1052, 0.0878, 0.1079],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,352][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0618, 0.0983, 0.1757, 0.1145, 0.1330, 0.1233, 0.1180, 0.1755],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,352][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0483, 0.1287, 0.1435, 0.1446, 0.1472, 0.1308, 0.1387, 0.1182],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,354][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0716, 0.1480, 0.1183, 0.1576, 0.1233, 0.1405, 0.1284, 0.1123],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,356][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.4803, 0.1155, 0.0717, 0.0686, 0.0605, 0.0598, 0.0755, 0.0680],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,357][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0116, 0.1484, 0.1386, 0.1476, 0.1389, 0.1375, 0.1422, 0.1352],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,358][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1177, 0.1277, 0.1248, 0.1244, 0.1249, 0.1247, 0.1296, 0.1263],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,360][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0076, 0.1423, 0.1288, 0.1463, 0.1511, 0.1271, 0.1459, 0.1508],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,361][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0167, 0.1238, 0.1465, 0.1409, 0.1476, 0.1397, 0.1440, 0.1408],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,363][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0017, 0.1046, 0.1342, 0.1203, 0.1466, 0.1320, 0.1202, 0.1305, 0.1099],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,365][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.9228, 0.0094, 0.0029, 0.0439, 0.0066, 0.0053, 0.0042, 0.0027, 0.0022],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,366][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0049, 0.1300, 0.1243, 0.1297, 0.1250, 0.1190, 0.1213, 0.1259, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,368][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.1892, 0.0504, 0.0749, 0.0942, 0.1661, 0.0971, 0.0888, 0.1655, 0.0739],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,370][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0553, 0.0797, 0.1384, 0.0917, 0.1076, 0.1008, 0.0946, 0.1635, 0.1684],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,371][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0408, 0.1060, 0.1226, 0.1184, 0.1247, 0.1210, 0.1215, 0.1325, 0.1127],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,372][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0426, 0.1339, 0.1113, 0.1426, 0.1236, 0.1135, 0.1222, 0.1134, 0.0968],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,372][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.5137, 0.0983, 0.0617, 0.0587, 0.0508, 0.0496, 0.0639, 0.0564, 0.0469],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,372][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0094, 0.1304, 0.1226, 0.1301, 0.1228, 0.1217, 0.1261, 0.1200, 0.1170],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,373][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1046, 0.1140, 0.1119, 0.1113, 0.1118, 0.1116, 0.1157, 0.1128, 0.1063],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,373][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0065, 0.1234, 0.1141, 0.1261, 0.1345, 0.1121, 0.1263, 0.1277, 0.1294],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,373][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0139, 0.1090, 0.1304, 0.1250, 0.1311, 0.1234, 0.1276, 0.1240, 0.1156],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,374][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0021, 0.0959, 0.1223, 0.1026, 0.1310, 0.1182, 0.1091, 0.1198, 0.1063,
        0.0926], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,374][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7033, 0.0354, 0.0131, 0.1024, 0.0231, 0.0200, 0.0179, 0.0116, 0.0093,
        0.0640], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,374][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0048, 0.1145, 0.1106, 0.1148, 0.1106, 0.1055, 0.1084, 0.1122, 0.1071,
        0.1113], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,375][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1665, 0.0463, 0.0641, 0.0554, 0.1585, 0.1165, 0.0808, 0.1345, 0.1236,
        0.0537], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,375][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0399, 0.0604, 0.1049, 0.0703, 0.0906, 0.0874, 0.0853, 0.1530, 0.1590,
        0.1492], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,375][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0402, 0.0941, 0.1097, 0.1074, 0.1124, 0.1061, 0.1099, 0.1089, 0.1133,
        0.0981], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,376][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0433, 0.1022, 0.1042, 0.1079, 0.1212, 0.1041, 0.1061, 0.1047, 0.1069,
        0.0994], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,378][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4589, 0.0954, 0.0625, 0.0561, 0.0496, 0.0480, 0.0594, 0.0559, 0.0472,
        0.0672], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,379][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0099, 0.1152, 0.1090, 0.1146, 0.1088, 0.1080, 0.1118, 0.1066, 0.1038,
        0.1123], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,381][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0943, 0.1025, 0.1009, 0.1003, 0.1006, 0.1006, 0.1041, 0.1015, 0.0958,
        0.0995], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,382][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0063, 0.1105, 0.0989, 0.1124, 0.1163, 0.0994, 0.1145, 0.1114, 0.1030,
        0.1272], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,384][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0114, 0.0983, 0.1175, 0.1125, 0.1181, 0.1105, 0.1147, 0.1111, 0.1028,
        0.1031], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,385][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0018, 0.0886, 0.1126, 0.0922, 0.1231, 0.1095, 0.1007, 0.1076, 0.0981,
        0.0857, 0.0802], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,387][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5261, 0.0462, 0.0181, 0.1183, 0.0302, 0.0258, 0.0231, 0.0161, 0.0134,
        0.0737, 0.1091], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,388][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0044, 0.1034, 0.0991, 0.1030, 0.0991, 0.0947, 0.0973, 0.1004, 0.0959,
        0.1002, 0.1025], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,390][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1335, 0.0641, 0.0743, 0.0542, 0.1492, 0.0918, 0.0812, 0.1219, 0.0962,
        0.0696, 0.0642], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,392][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0378, 0.0521, 0.0868, 0.0607, 0.0781, 0.0757, 0.0745, 0.1322, 0.1378,
        0.1290, 0.1352], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,394][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0353, 0.0872, 0.1002, 0.0898, 0.1021, 0.0971, 0.1001, 0.1004, 0.1044,
        0.0919, 0.0915], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,395][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0402, 0.0928, 0.0951, 0.0952, 0.1121, 0.0992, 0.0911, 0.0929, 0.0998,
        0.0905, 0.0911], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,395][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4090, 0.0877, 0.0609, 0.0555, 0.0504, 0.0467, 0.0579, 0.0549, 0.0476,
        0.0656, 0.0639], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,395][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0091, 0.1033, 0.0976, 0.1029, 0.0979, 0.0971, 0.1006, 0.0958, 0.0932,
        0.1011, 0.1015], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,396][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0857, 0.0930, 0.0917, 0.0910, 0.0914, 0.0914, 0.0948, 0.0923, 0.0871,
        0.0905, 0.0911], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,396][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0055, 0.0988, 0.0885, 0.1006, 0.1032, 0.0885, 0.1011, 0.0992, 0.0927,
        0.1136, 0.1084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,396][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0096, 0.0894, 0.1059, 0.1021, 0.1066, 0.1005, 0.1044, 0.1006, 0.0928,
        0.0929, 0.0952], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,397][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0012, 0.0804, 0.1020, 0.0891, 0.1154, 0.1012, 0.0930, 0.0973, 0.0876,
        0.0815, 0.0758, 0.0753], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,397][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.8298, 0.0118, 0.0038, 0.0469, 0.0077, 0.0067, 0.0055, 0.0036, 0.0027,
        0.0293, 0.0473, 0.0049], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,397][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0032, 0.0948, 0.0897, 0.0946, 0.0902, 0.0867, 0.0887, 0.0917, 0.0872,
        0.0914, 0.0937, 0.0881], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,398][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0705, 0.0733, 0.0686, 0.0616, 0.1153, 0.0795, 0.0825, 0.1372, 0.0997,
        0.0860, 0.0702, 0.0556], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,398][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0402, 0.0549, 0.1042, 0.0586, 0.0802, 0.0713, 0.0705, 0.1037, 0.1004,
        0.0922, 0.1006, 0.1233], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,398][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0204, 0.0775, 0.0858, 0.0908, 0.0934, 0.0897, 0.0945, 0.0883, 0.0935,
        0.0886, 0.0927, 0.0848], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,400][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0301, 0.0974, 0.0754, 0.1041, 0.0889, 0.0953, 0.0942, 0.0808, 0.0750,
        0.0932, 0.0973, 0.0682], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,402][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.4238, 0.0821, 0.0522, 0.0503, 0.0445, 0.0446, 0.0548, 0.0480, 0.0424,
        0.0586, 0.0577, 0.0408], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,403][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0071, 0.0949, 0.0891, 0.0949, 0.0895, 0.0886, 0.0918, 0.0873, 0.0847,
        0.0924, 0.0926, 0.0871], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,405][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0785, 0.0851, 0.0838, 0.0832, 0.0836, 0.0835, 0.0868, 0.0844, 0.0798,
        0.0829, 0.0834, 0.0850], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,406][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0049, 0.0881, 0.0812, 0.0911, 0.0930, 0.0790, 0.0918, 0.0892, 0.0838,
        0.1025, 0.0981, 0.0972], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,407][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0087, 0.0809, 0.0966, 0.0934, 0.0984, 0.0919, 0.0946, 0.0914, 0.0848,
        0.0843, 0.0867, 0.0885], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,409][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0020, 0.0728, 0.0937, 0.0839, 0.0972, 0.0910, 0.0826, 0.0880, 0.0797,
        0.0727, 0.0702, 0.0706, 0.0958], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,411][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.8180, 0.0133, 0.0043, 0.0498, 0.0091, 0.0076, 0.0060, 0.0038, 0.0030,
        0.0295, 0.0458, 0.0045, 0.0054], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,412][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0029, 0.0869, 0.0829, 0.0866, 0.0829, 0.0799, 0.0817, 0.0854, 0.0810,
        0.0842, 0.0861, 0.0820, 0.0775], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,414][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1085, 0.0617, 0.0607, 0.0724, 0.0667, 0.0663, 0.0889, 0.1087, 0.0676,
        0.0686, 0.0779, 0.0708, 0.0812], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,416][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0359, 0.0544, 0.0976, 0.0634, 0.0681, 0.0622, 0.0576, 0.0849, 0.0861,
        0.0876, 0.0986, 0.1058, 0.0978], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,417][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0224, 0.0761, 0.0916, 0.0841, 0.0667, 0.0838, 0.0846, 0.0842, 0.0880,
        0.0806, 0.0814, 0.0867, 0.0698], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,418][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0367, 0.0900, 0.0691, 0.1003, 0.0668, 0.0828, 0.0852, 0.0770, 0.0738,
        0.0889, 0.0955, 0.0688, 0.0650], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,418][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.3643, 0.0816, 0.0551, 0.0545, 0.0467, 0.0443, 0.0562, 0.0496, 0.0431,
        0.0618, 0.0603, 0.0384, 0.0440], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,419][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0064, 0.0877, 0.0818, 0.0877, 0.0817, 0.0811, 0.0847, 0.0807, 0.0782,
        0.0857, 0.0863, 0.0809, 0.0771], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,419][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0729, 0.0790, 0.0769, 0.0766, 0.0769, 0.0767, 0.0796, 0.0777, 0.0736,
        0.0763, 0.0769, 0.0788, 0.0781], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,419][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0050, 0.0786, 0.0746, 0.0803, 0.0898, 0.0729, 0.0832, 0.0822, 0.0751,
        0.0919, 0.0879, 0.0868, 0.0918], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,420][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0081, 0.0737, 0.0889, 0.0855, 0.0902, 0.0843, 0.0869, 0.0841, 0.0778,
        0.0772, 0.0791, 0.0801, 0.0841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,420][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0011, 0.0673, 0.0869, 0.0770, 0.0938, 0.0819, 0.0765, 0.0811, 0.0711,
        0.0679, 0.0652, 0.0658, 0.0932, 0.0712], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,420][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.7586, 0.0163, 0.0065, 0.0592, 0.0129, 0.0109, 0.0088, 0.0059, 0.0048,
        0.0369, 0.0552, 0.0065, 0.0079, 0.0094], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,421][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0026, 0.0812, 0.0768, 0.0807, 0.0768, 0.0739, 0.0756, 0.0791, 0.0752,
        0.0785, 0.0803, 0.0757, 0.0717, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,421][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0932, 0.0372, 0.0513, 0.0560, 0.0923, 0.0608, 0.0648, 0.0872, 0.0565,
        0.0615, 0.0709, 0.0851, 0.1265, 0.0567], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,421][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0359, 0.0475, 0.0832, 0.0533, 0.0609, 0.0561, 0.0536, 0.0783, 0.0801,
        0.0782, 0.0845, 0.0979, 0.0905, 0.1001], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,422][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0258, 0.0691, 0.0789, 0.0732, 0.0795, 0.0737, 0.0737, 0.0772, 0.0756,
        0.0711, 0.0742, 0.0817, 0.0816, 0.0646], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,424][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0272, 0.0835, 0.0669, 0.0877, 0.0789, 0.0717, 0.0708, 0.0703, 0.0685,
        0.0808, 0.0824, 0.0680, 0.0769, 0.0664], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,425][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.3725, 0.0805, 0.0489, 0.0469, 0.0399, 0.0407, 0.0505, 0.0473, 0.0409,
        0.0537, 0.0536, 0.0383, 0.0402, 0.0462], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,427][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0061, 0.0813, 0.0762, 0.0808, 0.0761, 0.0754, 0.0784, 0.0749, 0.0727,
        0.0792, 0.0793, 0.0747, 0.0715, 0.0735], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,428][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0677, 0.0734, 0.0715, 0.0713, 0.0715, 0.0713, 0.0742, 0.0723, 0.0683,
        0.0709, 0.0715, 0.0733, 0.0726, 0.0702], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,430][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0041, 0.0752, 0.0670, 0.0745, 0.0789, 0.0670, 0.0772, 0.0768, 0.0725,
        0.0864, 0.0812, 0.0813, 0.0805, 0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,432][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0075, 0.0676, 0.0814, 0.0788, 0.0830, 0.0776, 0.0802, 0.0774, 0.0719,
        0.0713, 0.0732, 0.0746, 0.0781, 0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,433][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0013, 0.0637, 0.0802, 0.0694, 0.0877, 0.0771, 0.0729, 0.0777, 0.0696,
        0.0630, 0.0600, 0.0610, 0.0866, 0.0683, 0.0618], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,435][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.7367, 0.0183, 0.0057, 0.0606, 0.0112, 0.0104, 0.0086, 0.0060, 0.0045,
        0.0404, 0.0626, 0.0071, 0.0072, 0.0086, 0.0122], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,437][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0027, 0.0754, 0.0712, 0.0747, 0.0713, 0.0687, 0.0703, 0.0738, 0.0703,
        0.0730, 0.0750, 0.0705, 0.0664, 0.0668, 0.0700], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,439][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0938, 0.0532, 0.0509, 0.0603, 0.1121, 0.0523, 0.0485, 0.0699, 0.0567,
        0.0572, 0.0621, 0.0609, 0.1245, 0.0548, 0.0430], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,440][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0249, 0.0444, 0.0866, 0.0515, 0.0635, 0.0562, 0.0517, 0.0699, 0.0723,
        0.0717, 0.0771, 0.0846, 0.0847, 0.0979, 0.0632], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,441][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0230, 0.0618, 0.0672, 0.0693, 0.0742, 0.0690, 0.0722, 0.0717, 0.0743,
        0.0665, 0.0706, 0.0732, 0.0760, 0.0678, 0.0632], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,441][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0271, 0.0725, 0.0659, 0.0745, 0.0764, 0.0707, 0.0708, 0.0693, 0.0659,
        0.0699, 0.0705, 0.0623, 0.0755, 0.0655, 0.0631], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,442][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3650, 0.0811, 0.0469, 0.0421, 0.0371, 0.0375, 0.0486, 0.0452, 0.0394,
        0.0515, 0.0512, 0.0336, 0.0369, 0.0399, 0.0439], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,442][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0057, 0.0756, 0.0707, 0.0751, 0.0710, 0.0704, 0.0729, 0.0696, 0.0677,
        0.0738, 0.0740, 0.0696, 0.0667, 0.0684, 0.0688], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,442][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0629, 0.0681, 0.0668, 0.0665, 0.0667, 0.0666, 0.0692, 0.0674, 0.0636,
        0.0661, 0.0666, 0.0682, 0.0678, 0.0656, 0.0679], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,443][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0039, 0.0699, 0.0636, 0.0702, 0.0737, 0.0633, 0.0725, 0.0704, 0.0663,
        0.0799, 0.0747, 0.0757, 0.0742, 0.0696, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,443][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0068, 0.0637, 0.0760, 0.0737, 0.0767, 0.0721, 0.0751, 0.0725, 0.0670,
        0.0666, 0.0685, 0.0692, 0.0720, 0.0721, 0.0683], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,476][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:04,478][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,479][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,480][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,482][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,483][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,484][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,485][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,486][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,487][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,487][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,487][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,498][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,499][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1562, 0.8438], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,501][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0190, 0.9810], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,502][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,504][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5832, 0.4168], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,506][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3087, 0.6913], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,507][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1609, 0.8391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,509][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,509][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3120, 0.6880], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,509][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1871, 0.8129], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,510][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1118, 0.8882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,510][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0923, 0.9077], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,510][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9787, 0.0213], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,511][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0852, 0.4412, 0.4736], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,511][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0071, 0.4938, 0.4990], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,511][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([9.9803e-01, 1.3113e-03, 6.6306e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,511][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.2811, 0.2828, 0.4361], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,512][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.1098, 0.2416, 0.6486], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,512][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.0500, 0.4321, 0.5179], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,512][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.2053, 0.7896, 0.0051], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,512][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.1425, 0.3370, 0.5206], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,513][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.0948, 0.5013, 0.4039], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,515][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0526, 0.4953, 0.4521], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,517][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0119, 0.0041, 0.9840], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,518][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.9735, 0.0148, 0.0117], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,519][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0555, 0.3136, 0.3367, 0.2942], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,520][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0053, 0.3192, 0.3181, 0.3573], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,521][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9734e-01, 1.4216e-03, 7.4005e-04, 5.0088e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,523][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2912, 0.2044, 0.2788, 0.2256], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,524][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0411, 0.1675, 0.5449, 0.2465], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,526][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0397, 0.2817, 0.3883, 0.2902], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,527][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([8.9036e-01, 2.8340e-03, 1.0659e-01, 2.1405e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,529][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0755, 0.2456, 0.4140, 0.2649], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,530][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0556, 0.2890, 0.3757, 0.2797], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,532][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0454, 0.3291, 0.3067, 0.3189], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,532][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0204, 0.0676, 0.8948, 0.0171], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,532][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9060, 0.0269, 0.0210, 0.0461], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,533][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0448, 0.2395, 0.2573, 0.2249, 0.2334], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,533][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0029, 0.2449, 0.2425, 0.2734, 0.2362], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,533][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([9.9658e-01, 1.6018e-03, 8.3549e-04, 5.7819e-04, 4.0594e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,534][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1706, 0.1625, 0.2202, 0.2104, 0.2364], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,534][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0501, 0.1172, 0.4192, 0.1800, 0.2336], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,534][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0265, 0.2145, 0.3092, 0.2219, 0.2279], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,535][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.7155, 0.1287, 0.0125, 0.1385, 0.0048], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,535][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0550, 0.1884, 0.2771, 0.1843, 0.2952], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,535][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0412, 0.2486, 0.2463, 0.2702, 0.1936], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,535][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0248, 0.2564, 0.2353, 0.2469, 0.2366], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,536][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0060, 0.0118, 0.1318, 0.0040, 0.8464], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,536][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.8948, 0.0173, 0.0217, 0.0317, 0.0345], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,538][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0371, 0.1960, 0.2089, 0.1824, 0.1887, 0.1869], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,540][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0020, 0.2016, 0.1980, 0.2250, 0.1912, 0.1823], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,541][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([9.9650e-01, 1.4910e-03, 7.7159e-04, 5.6534e-04, 3.8822e-04, 2.8577e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,542][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1530, 0.1222, 0.1600, 0.1437, 0.1836, 0.2375], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,543][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0502, 0.1139, 0.3211, 0.1489, 0.1904, 0.1754], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,545][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0297, 0.1758, 0.2208, 0.1826, 0.2058, 0.1852], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,546][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.7241, 0.0858, 0.0300, 0.0264, 0.1280, 0.0057], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,546][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0754, 0.1616, 0.2029, 0.1533, 0.2119, 0.1949], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,546][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0455, 0.1872, 0.2083, 0.1880, 0.2167, 0.1543], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,547][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0223, 0.2048, 0.1903, 0.1990, 0.1913, 0.1922], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,547][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0108, 0.0435, 0.0582, 0.0176, 0.5384, 0.3314], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,547][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.9265, 0.0110, 0.0076, 0.0215, 0.0120, 0.0215], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,548][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0327, 0.1650, 0.1763, 0.1543, 0.1599, 0.1579, 0.1540],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,548][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0015, 0.1691, 0.1661, 0.1899, 0.1602, 0.1533, 0.1599],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,548][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.9650e-01, 1.4049e-03, 7.0528e-04, 4.8200e-04, 3.4329e-04, 2.5317e-04,
        3.0660e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,550][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1415, 0.0927, 0.1224, 0.1201, 0.1533, 0.2222, 0.1478],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,551][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0415, 0.0946, 0.2781, 0.1243, 0.1564, 0.1630, 0.1422],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,553][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0192, 0.1390, 0.1771, 0.1507, 0.1886, 0.1608, 0.1645],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,555][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8810, 0.0138, 0.0524, 0.0047, 0.0397, 0.0066, 0.0018],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,556][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0475, 0.1141, 0.1576, 0.1271, 0.1591, 0.1603, 0.2344],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,558][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0400, 0.1529, 0.1669, 0.1607, 0.1954, 0.1590, 0.1250],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,558][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0182, 0.1705, 0.1592, 0.1663, 0.1601, 0.1608, 0.1649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,558][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0011, 0.0065, 0.0776, 0.0041, 0.8560, 0.0517, 0.0030],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,559][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.9472, 0.0069, 0.0049, 0.0114, 0.0074, 0.0083, 0.0139],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,559][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0287, 0.1430, 0.1509, 0.1328, 0.1373, 0.1358, 0.1324, 0.1391],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,559][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0015, 0.1473, 0.1437, 0.1653, 0.1397, 0.1328, 0.1384, 0.1314],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,560][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.9700e-01, 1.0952e-03, 5.5181e-04, 3.7009e-04, 2.7140e-04, 2.1658e-04,
        2.5927e-04, 2.3266e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,560][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1292, 0.0801, 0.1057, 0.1018, 0.1327, 0.1740, 0.1331, 0.1433],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,560][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0779, 0.0748, 0.1662, 0.0825, 0.1109, 0.1194, 0.1140, 0.2542],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,561][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0173, 0.1207, 0.1569, 0.1308, 0.1628, 0.1396, 0.1447, 0.1273],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,561][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.7931, 0.0357, 0.0080, 0.0109, 0.0122, 0.0441, 0.0891, 0.0068],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,561][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0513, 0.0861, 0.1183, 0.0816, 0.1282, 0.1114, 0.1748, 0.2483],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,562][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0319, 0.1309, 0.1475, 0.1435, 0.1586, 0.1315, 0.1160, 0.1402],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,562][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0163, 0.1457, 0.1365, 0.1428, 0.1370, 0.1379, 0.1413, 0.1425],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,564][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0082, 0.0838, 0.0488, 0.0503, 0.1424, 0.1125, 0.0061, 0.5478],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,566][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.9765, 0.0038, 0.0016, 0.0048, 0.0021, 0.0024, 0.0032, 0.0057],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,567][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0242, 0.1263, 0.1342, 0.1174, 0.1211, 0.1202, 0.1174, 0.1233, 0.1160],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,568][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0011, 0.1307, 0.1294, 0.1470, 0.1251, 0.1180, 0.1231, 0.1171, 0.1085],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,569][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.9589e-01, 1.2252e-03, 6.4029e-04, 4.5841e-04, 3.2464e-04, 2.4893e-04,
        2.9817e-04, 2.7743e-04, 6.3484e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,571][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1071, 0.0611, 0.0851, 0.0849, 0.1150, 0.1517, 0.1156, 0.1478, 0.1317],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,573][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0451, 0.0544, 0.1283, 0.0542, 0.0867, 0.0897, 0.0839, 0.2438, 0.2139],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,574][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0141, 0.0988, 0.1358, 0.1095, 0.1391, 0.1291, 0.1272, 0.1354, 0.1110],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,575][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2486, 0.1117, 0.0168, 0.0356, 0.1193, 0.0079, 0.2504, 0.2071, 0.0026],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,578][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0438, 0.0758, 0.0905, 0.0676, 0.1014, 0.0970, 0.1537, 0.2203, 0.1499],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,579][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0218, 0.1104, 0.1184, 0.1170, 0.1412, 0.1175, 0.1053, 0.1564, 0.1119],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,581][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0128, 0.1283, 0.1203, 0.1254, 0.1209, 0.1218, 0.1245, 0.1261, 0.1199],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,581][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([9.5264e-04, 6.4251e-03, 5.5681e-03, 2.3935e-03, 7.0010e-03, 1.9354e-02,
        8.3149e-04, 6.4328e-04, 9.5683e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,581][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.9505, 0.0078, 0.0033, 0.0067, 0.0050, 0.0045, 0.0041, 0.0043, 0.0138],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,582][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0202, 0.1138, 0.1212, 0.1063, 0.1095, 0.1080, 0.1052, 0.1105, 0.1038,
        0.1014], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,582][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0016, 0.1153, 0.1133, 0.1290, 0.1099, 0.1050, 0.1091, 0.1030, 0.0956,
        0.1183], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,582][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9332e-01, 1.5547e-03, 8.7741e-04, 6.0790e-04, 4.6950e-04, 3.5228e-04,
        4.3599e-04, 4.2912e-04, 9.4719e-04, 1.0026e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,583][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0934, 0.0567, 0.0784, 0.0724, 0.1043, 0.1514, 0.1056, 0.1311, 0.1348,
        0.0719], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,583][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0178, 0.0404, 0.1340, 0.0528, 0.0765, 0.0742, 0.0720, 0.2304, 0.2077,
        0.0941], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,583][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0147, 0.0922, 0.1219, 0.1029, 0.1277, 0.1128, 0.1149, 0.1133, 0.1104,
        0.0891], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,584][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([6.0865e-01, 3.7580e-04, 3.9709e-02, 1.2823e-04, 1.4826e-01, 5.2789e-03,
        3.6171e-02, 1.0189e-01, 5.9242e-02, 2.8824e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,584][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0301, 0.0658, 0.0908, 0.0640, 0.1034, 0.0838, 0.1382, 0.2024, 0.1298,
        0.0916], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,584][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0217, 0.0847, 0.1083, 0.0960, 0.1344, 0.1033, 0.0976, 0.1404, 0.1211,
        0.0926], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,585][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0147, 0.1135, 0.1071, 0.1108, 0.1077, 0.1082, 0.1101, 0.1114, 0.1068,
        0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,585][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([7.0620e-04, 4.8929e-03, 1.6411e-02, 1.2272e-03, 1.9796e-01, 1.6068e-02,
        3.0746e-04, 6.5771e-03, 7.5464e-01, 1.2085e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,587][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8466, 0.0217, 0.0065, 0.0183, 0.0067, 0.0105, 0.0133, 0.0116, 0.0238,
        0.0409], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,589][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0186, 0.1040, 0.1102, 0.0968, 0.0998, 0.0980, 0.0958, 0.1006, 0.0944,
        0.0924, 0.0894], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,590][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0015, 0.1025, 0.1008, 0.1153, 0.0983, 0.0938, 0.0977, 0.0928, 0.0858,
        0.1063, 0.1052], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,591][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9314e-01, 1.4124e-03, 8.1132e-04, 5.5075e-04, 4.1757e-04, 3.1257e-04,
        3.8791e-04, 3.7513e-04, 8.6170e-04, 9.1744e-04, 8.1517e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,592][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0781, 0.0584, 0.0774, 0.0677, 0.0991, 0.1328, 0.1019, 0.1211, 0.1195,
        0.0743, 0.0695], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,594][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0179, 0.0352, 0.1246, 0.0493, 0.0687, 0.0724, 0.0686, 0.1970, 0.1877,
        0.0867, 0.0919], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,596][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0126, 0.0848, 0.1130, 0.0871, 0.1184, 0.1042, 0.1049, 0.1064, 0.1026,
        0.0827, 0.0831], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,597][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([7.0801e-01, 7.6103e-04, 2.9229e-02, 3.8130e-05, 1.2992e-01, 1.7974e-02,
        6.3916e-03, 5.5017e-02, 5.2155e-02, 4.1103e-04, 9.1725e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,598][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0275, 0.0603, 0.0816, 0.0546, 0.0888, 0.0767, 0.1290, 0.1853, 0.1214,
        0.0860, 0.0888], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,600][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0158, 0.0807, 0.1043, 0.0748, 0.1289, 0.0987, 0.0878, 0.1278, 0.1111,
        0.0931, 0.0769], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,602][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0132, 0.1020, 0.0967, 0.0999, 0.0972, 0.0974, 0.0995, 0.1004, 0.0961,
        0.0988, 0.0989], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,603][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([7.1258e-04, 2.6363e-03, 1.2980e-02, 8.7781e-04, 2.7368e-01, 1.0982e-02,
        1.8991e-04, 5.2585e-03, 6.9118e-01, 7.2263e-04, 7.8154e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,604][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7739, 0.0267, 0.0075, 0.0287, 0.0088, 0.0131, 0.0169, 0.0109, 0.0329,
        0.0423, 0.0384], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,604][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0183, 0.0945, 0.0997, 0.0878, 0.0902, 0.0891, 0.0870, 0.0911, 0.0853,
        0.0838, 0.0811, 0.0922], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,605][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0014, 0.0935, 0.0922, 0.1029, 0.0892, 0.0848, 0.0884, 0.0843, 0.0785,
        0.0948, 0.0938, 0.0961], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,605][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.9591e-01, 7.4683e-04, 4.0984e-04, 2.8622e-04, 2.0906e-04, 1.6136e-04,
        2.0088e-04, 1.9276e-04, 4.6858e-04, 5.2236e-04, 4.4713e-04, 4.4994e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,605][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0609, 0.0540, 0.0685, 0.0629, 0.0849, 0.1237, 0.1003, 0.1187, 0.1164,
        0.0728, 0.0658, 0.0711], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,606][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0383, 0.0360, 0.1002, 0.0388, 0.0640, 0.0698, 0.0660, 0.1852, 0.1477,
        0.0632, 0.0694, 0.1213], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,606][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0087, 0.0761, 0.0949, 0.0840, 0.1086, 0.0969, 0.0990, 0.0938, 0.0935,
        0.0771, 0.0804, 0.0871], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,606][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([4.1801e-02, 5.7158e-02, 7.2078e-04, 3.2382e-02, 3.7663e-02, 5.2506e-02,
        5.5975e-01, 4.0734e-02, 1.1975e-03, 7.9032e-02, 9.6924e-02, 1.2759e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,607][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0339, 0.0555, 0.0693, 0.0495, 0.0756, 0.0696, 0.1101, 0.1437, 0.0985,
        0.0733, 0.0757, 0.1453], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,607][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0118, 0.0729, 0.0729, 0.0835, 0.1144, 0.0917, 0.0815, 0.1066, 0.0993,
        0.0890, 0.0907, 0.0858], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,607][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0097, 0.0931, 0.0880, 0.0912, 0.0885, 0.0890, 0.0911, 0.0919, 0.0874,
        0.0902, 0.0903, 0.0895], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,608][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0259, 0.0568, 0.0616, 0.0644, 0.0408, 0.0866, 0.0169, 0.0298, 0.2649,
        0.0372, 0.0467, 0.2684], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,609][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.9358, 0.0072, 0.0011, 0.0049, 0.0026, 0.0027, 0.0040, 0.0030, 0.0067,
        0.0099, 0.0074, 0.0146], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,611][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0173, 0.0859, 0.0911, 0.0802, 0.0824, 0.0820, 0.0796, 0.0828, 0.0778,
        0.0762, 0.0738, 0.0839, 0.0870], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,612][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0011, 0.0863, 0.0847, 0.0956, 0.0818, 0.0777, 0.0808, 0.0768, 0.0712,
        0.0870, 0.0865, 0.0874, 0.0831], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,613][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([9.9487e-01, 9.6121e-04, 4.8149e-04, 3.5927e-04, 2.4205e-04, 1.9299e-04,
        2.2777e-04, 1.9759e-04, 5.2690e-04, 5.8069e-04, 4.9794e-04, 5.0956e-04,
        3.5589e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,615][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0568, 0.0478, 0.0621, 0.0627, 0.0707, 0.1023, 0.0918, 0.1080, 0.1043,
        0.0704, 0.0669, 0.0744, 0.0819], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,617][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0370, 0.0343, 0.0991, 0.0359, 0.0543, 0.0577, 0.0587, 0.1551, 0.1273,
        0.0510, 0.0614, 0.1023, 0.1259], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,618][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.0092, 0.0724, 0.1030, 0.0754, 0.0771, 0.0899, 0.0857, 0.0931, 0.0884,
        0.0682, 0.0678, 0.0900, 0.0800], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,620][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.3208, 0.0578, 0.0029, 0.0637, 0.0023, 0.0141, 0.1934, 0.0762, 0.0123,
        0.0764, 0.1744, 0.0018, 0.0039], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,621][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0240, 0.0466, 0.0583, 0.0423, 0.0618, 0.0602, 0.0986, 0.1256, 0.0847,
        0.0613, 0.0656, 0.1258, 0.1453], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,624][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0136, 0.0777, 0.0746, 0.0806, 0.0596, 0.0765, 0.0655, 0.1034, 0.0910,
        0.0888, 0.0937, 0.1071, 0.0680], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,625][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0087, 0.0863, 0.0802, 0.0837, 0.0805, 0.0813, 0.0833, 0.0845, 0.0804,
        0.0830, 0.0833, 0.0823, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,626][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0051, 0.0078, 0.0486, 0.0025, 0.3918, 0.0718, 0.0035, 0.0066, 0.0265,
        0.0036, 0.0023, 0.0135, 0.4164], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,627][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.9232, 0.0065, 0.0026, 0.0080, 0.0041, 0.0055, 0.0054, 0.0026, 0.0048,
        0.0111, 0.0088, 0.0067, 0.0107], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,627][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0150, 0.0793, 0.0846, 0.0742, 0.0762, 0.0758, 0.0741, 0.0771, 0.0721,
        0.0705, 0.0681, 0.0776, 0.0809, 0.0747], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,628][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0009, 0.0798, 0.0786, 0.0885, 0.0757, 0.0719, 0.0751, 0.0710, 0.0661,
        0.0809, 0.0801, 0.0812, 0.0768, 0.0734], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,628][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.9311e-01, 1.2495e-03, 6.0333e-04, 4.6620e-04, 3.0638e-04, 2.3454e-04,
        2.8097e-04, 2.4809e-04, 6.7134e-04, 7.4866e-04, 6.5398e-04, 6.3741e-04,
        4.4305e-04, 3.5041e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,628][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0739, 0.0397, 0.0555, 0.0524, 0.0689, 0.1008, 0.0786, 0.0925, 0.0888,
        0.0566, 0.0563, 0.0701, 0.0797, 0.0863], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,629][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0325, 0.0296, 0.0803, 0.0296, 0.0447, 0.0473, 0.0496, 0.1376, 0.1201,
        0.0507, 0.0539, 0.0948, 0.1138, 0.1155], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,629][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0109, 0.0662, 0.0856, 0.0689, 0.0869, 0.0780, 0.0766, 0.0806, 0.0763,
        0.0642, 0.0666, 0.0829, 0.0895, 0.0669], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,630][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1613, 0.1175, 0.0027, 0.0414, 0.0407, 0.0054, 0.0527, 0.1310, 0.0145,
        0.1365, 0.1736, 0.0054, 0.1139, 0.0035], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,630][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0234, 0.0444, 0.0549, 0.0423, 0.0585, 0.0578, 0.0893, 0.1142, 0.0774,
        0.0563, 0.0593, 0.1157, 0.1269, 0.0797], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,630][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0195, 0.0722, 0.0733, 0.0695, 0.0780, 0.0692, 0.0602, 0.0848, 0.0747,
        0.0780, 0.0848, 0.0909, 0.0879, 0.0569], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,631][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0087, 0.0800, 0.0744, 0.0777, 0.0746, 0.0752, 0.0773, 0.0780, 0.0742,
        0.0769, 0.0771, 0.0759, 0.0763, 0.0737], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,631][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.4434e-04, 5.7319e-04, 3.3969e-03, 1.4175e-04, 7.2812e-03, 3.3765e-03,
        2.0847e-04, 5.4501e-04, 8.7236e-01, 5.0204e-04, 1.5695e-04, 1.8090e-02,
        1.4948e-02, 7.8276e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,633][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.9133, 0.0068, 0.0021, 0.0062, 0.0029, 0.0046, 0.0055, 0.0031, 0.0089,
        0.0114, 0.0089, 0.0094, 0.0086, 0.0084], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,635][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0140, 0.0744, 0.0789, 0.0693, 0.0712, 0.0706, 0.0687, 0.0716, 0.0673,
        0.0660, 0.0638, 0.0727, 0.0755, 0.0697, 0.0661], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,636][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0008, 0.0749, 0.0728, 0.0827, 0.0701, 0.0669, 0.0700, 0.0661, 0.0610,
        0.0762, 0.0753, 0.0757, 0.0713, 0.0680, 0.0681], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,637][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.9420e-01, 1.0222e-03, 4.9863e-04, 3.4447e-04, 2.4451e-04, 1.8554e-04,
        2.2051e-04, 1.9881e-04, 5.5247e-04, 6.1232e-04, 5.1810e-04, 5.0110e-04,
        3.5111e-04, 2.9074e-04, 2.6037e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,638][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0637, 0.0415, 0.0518, 0.0490, 0.0656, 0.0949, 0.0707, 0.0827, 0.0836,
        0.0534, 0.0504, 0.0596, 0.0725, 0.0819, 0.0786], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,640][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0241, 0.0293, 0.0908, 0.0334, 0.0478, 0.0472, 0.0466, 0.1109, 0.1034,
        0.0483, 0.0541, 0.0833, 0.1061, 0.1166, 0.0581], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,641][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0091, 0.0600, 0.0745, 0.0644, 0.0842, 0.0738, 0.0762, 0.0732, 0.0729,
        0.0595, 0.0622, 0.0737, 0.0858, 0.0705, 0.0601], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,642][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1466e-01, 2.7012e-03, 1.5867e-02, 3.3390e-04, 1.4778e-01, 5.1541e-03,
        3.2913e-02, 2.0680e-01, 2.2275e-02, 1.5574e-03, 7.7840e-04, 2.1111e-03,
        4.4197e-01, 4.8557e-03, 2.4643e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,644][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0212, 0.0413, 0.0535, 0.0409, 0.0574, 0.0554, 0.0824, 0.0997, 0.0732,
        0.0551, 0.0563, 0.1001, 0.1141, 0.0762, 0.0732], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,646][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0137, 0.0585, 0.0682, 0.0643, 0.0860, 0.0648, 0.0627, 0.0836, 0.0777,
        0.0660, 0.0682, 0.0748, 0.0910, 0.0691, 0.0513], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,648][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0080, 0.0739, 0.0694, 0.0723, 0.0696, 0.0700, 0.0719, 0.0726, 0.0691,
        0.0713, 0.0716, 0.0707, 0.0710, 0.0687, 0.0699], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,649][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.4383e-04, 2.3714e-03, 9.0914e-03, 6.0488e-04, 5.7217e-02, 8.4282e-03,
        2.9766e-04, 3.2794e-03, 6.6285e-01, 8.5842e-04, 4.7422e-04, 9.8927e-02,
        9.7816e-02, 5.5604e-02, 1.6391e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,650][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.8879, 0.0077, 0.0019, 0.0082, 0.0034, 0.0055, 0.0062, 0.0049, 0.0136,
        0.0138, 0.0108, 0.0094, 0.0084, 0.0094, 0.0088], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,651][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:04,652][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16551],
        [ 2344],
        [ 4886],
        [   56],
        [ 1056],
        [  593],
        [  789],
        [ 2200],
        [ 2555],
        [  594],
        [  689],
        [ 1710],
        [ 7412],
        [ 1646],
        [ 3250]], device='cuda:0')
[2024-07-24 10:17:04,653][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17593],
        [ 6854],
        [24473],
        [  928],
        [ 6562],
        [ 2903],
        [ 3265],
        [ 5078],
        [ 4994],
        [ 2159],
        [ 2611],
        [ 3365],
        [17076],
        [ 3201],
        [ 9366]], device='cuda:0')
[2024-07-24 10:17:04,654][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36255],
        [44290],
        [43211],
        [44225],
        [43412],
        [43618],
        [43550],
        [43359],
        [43447],
        [43808],
        [44124],
        [44289],
        [44001],
        [43943],
        [44088]], device='cuda:0')
[2024-07-24 10:17:04,656][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18266],
        [15091],
        [16231],
        [ 8053],
        [11296],
        [12057],
        [13250],
        [13296],
        [14703],
        [ 7092],
        [ 4324],
        [10580],
        [10091],
        [ 8168],
        [ 7568]], device='cuda:0')
[2024-07-24 10:17:04,657][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 808],
        [1628],
        [1422],
        [1292],
        [1391],
        [1422],
        [1341],
        [1269],
        [1248],
        [1218],
        [1226],
        [1277],
        [1314],
        [1322],
        [1323]], device='cuda:0')
[2024-07-24 10:17:04,659][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[20133],
        [23665],
        [ 4742],
        [ 5439],
        [ 3589],
        [ 2166],
        [ 2029],
        [ 4286],
        [ 4956],
        [ 4590],
        [ 5312],
        [ 6541],
        [ 5691],
        [ 4053],
        [ 3903]], device='cuda:0')
[2024-07-24 10:17:04,660][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15596],
        [37420],
        [45309],
        [45167],
        [45912],
        [46215],
        [46128],
        [45839],
        [45747],
        [45537],
        [45349],
        [45326],
        [45678],
        [45666],
        [45816]], device='cuda:0')
[2024-07-24 10:17:04,661][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31806],
        [25436],
        [18346],
        [18621],
        [18992],
        [20820],
        [20181],
        [21013],
        [21959],
        [21958],
        [21641],
        [21680],
        [21491],
        [21874],
        [21885]], device='cuda:0')
[2024-07-24 10:17:04,663][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[13039],
        [ 9963],
        [10821],
        [ 9933],
        [ 6881],
        [ 6144],
        [ 6982],
        [ 6111],
        [ 5863],
        [ 5863],
        [ 5868],
        [ 6432],
        [ 5870],
        [ 5688],
        [ 5659]], device='cuda:0')
[2024-07-24 10:17:04,664][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15574],
        [16416],
        [17419],
        [17795],
        [17969],
        [18496],
        [19251],
        [19471],
        [19103],
        [19534],
        [19833],
        [19653],
        [19857],
        [19918],
        [20085]], device='cuda:0')
[2024-07-24 10:17:04,666][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[22459],
        [23621],
        [23927],
        [24112],
        [23625],
        [23239],
        [24049],
        [23589],
        [23295],
        [22680],
        [22646],
        [23008],
        [23283],
        [23445],
        [23446]], device='cuda:0')
[2024-07-24 10:17:04,667][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[3229],
        [3004],
        [2913],
        [2942],
        [2936],
        [2918],
        [2880],
        [2937],
        [2977],
        [2990],
        [2986],
        [3001],
        [2990],
        [2959],
        [2948]], device='cuda:0')
[2024-07-24 10:17:04,669][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[38105],
        [43346],
        [42452],
        [42763],
        [43210],
        [42774],
        [42412],
        [42283],
        [42341],
        [42117],
        [41826],
        [41969],
        [41760],
        [41760],
        [41736]], device='cuda:0')
[2024-07-24 10:17:04,670][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[36502],
        [29980],
        [20582],
        [16924],
        [13767],
        [13324],
        [14021],
        [14377],
        [14393],
        [14528],
        [14692],
        [15349],
        [15606],
        [15705],
        [15938]], device='cuda:0')
[2024-07-24 10:17:04,672][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11262],
        [31994],
        [ 4658],
        [24796],
        [12856],
        [34197],
        [20143],
        [24946],
        [33284],
        [29498],
        [35298],
        [26188],
        [21696],
        [34898],
        [30488]], device='cuda:0')
[2024-07-24 10:17:04,673][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[2799],
        [1296],
        [1235],
        [1206],
        [1222],
        [1352],
        [1427],
        [1500],
        [1550],
        [1595],
        [1607],
        [1628],
        [1620],
        [1628],
        [1655]], device='cuda:0')
[2024-07-24 10:17:04,675][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[26529],
        [36996],
        [37234],
        [37475],
        [37413],
        [37720],
        [38002],
        [38059],
        [38042],
        [38121],
        [38052],
        [37840],
        [37794],
        [37656],
        [37643]], device='cuda:0')
[2024-07-24 10:17:04,675][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[6607],
        [6607],
        [6601],
        [6601],
        [6595],
        [6591],
        [6585],
        [6591],
        [6588],
        [6579],
        [6574],
        [6581],
        [6580],
        [6577],
        [6576]], device='cuda:0')
[2024-07-24 10:17:04,676][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3087],
        [ 8025],
        [12165],
        [12767],
        [17310],
        [18061],
        [19206],
        [19404],
        [18904],
        [18241],
        [17803],
        [17007],
        [17789],
        [17695],
        [17447]], device='cuda:0')
[2024-07-24 10:17:04,677][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26587],
        [ 8469],
        [ 3762],
        [ 3697],
        [ 3675],
        [ 3959],
        [ 4142],
        [ 4154],
        [ 3669],
        [ 3290],
        [ 3574],
        [ 4511],
        [ 4502],
        [ 4599],
        [ 4550]], device='cuda:0')
[2024-07-24 10:17:04,678][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[33066],
        [44799],
        [44316],
        [44920],
        [45401],
        [45899],
        [46038],
        [46035],
        [46018],
        [46022],
        [46069],
        [46042],
        [46087],
        [46065],
        [46092]], device='cuda:0')
[2024-07-24 10:17:04,679][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38085],
        [38090],
        [24158],
        [37731],
        [38337],
        [47863],
        [43477],
        [36492],
        [26535],
        [41694],
        [46363],
        [21234],
        [25221],
        [34537],
        [34083]], device='cuda:0')
[2024-07-24 10:17:04,681][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35266],
        [ 7810],
        [ 7767],
        [ 9014],
        [ 9719],
        [10517],
        [11597],
        [14115],
        [14703],
        [15044],
        [15411],
        [14830],
        [15092],
        [15642],
        [15383]], device='cuda:0')
[2024-07-24 10:17:04,682][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[29809],
        [ 3008],
        [ 3369],
        [ 4001],
        [ 4559],
        [ 4335],
        [ 4293],
        [ 4090],
        [ 3692],
        [ 3440],
        [ 3464],
        [ 3630],
        [ 3729],
        [ 3814],
        [ 3821]], device='cuda:0')
[2024-07-24 10:17:04,684][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24744],
        [21864],
        [22785],
        [22656],
        [23059],
        [23261],
        [23421],
        [23256],
        [23119],
        [23080],
        [22955],
        [22921],
        [22983],
        [22995],
        [23000]], device='cuda:0')
[2024-07-24 10:17:04,685][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[21177],
        [13811],
        [ 4382],
        [ 3454],
        [12641],
        [ 9741],
        [13040],
        [19312],
        [22922],
        [22326],
        [22416],
        [15922],
        [16858],
        [23751],
        [23021]], device='cuda:0')
[2024-07-24 10:17:04,686][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[40711],
        [39910],
        [40883],
        [40229],
        [42843],
        [41759],
        [41606],
        [41004],
        [41776],
        [40749],
        [41274],
        [40700],
        [41494],
        [41583],
        [41690]], device='cuda:0')
[2024-07-24 10:17:04,688][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[28755],
        [36914],
        [39758],
        [37592],
        [34228],
        [32131],
        [33085],
        [32578],
        [35389],
        [33214],
        [31287],
        [35879],
        [34597],
        [33014],
        [33463]], device='cuda:0')
[2024-07-24 10:17:04,689][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32881],
        [26697],
        [41820],
        [42531],
        [42076],
        [35156],
        [36052],
        [42755],
        [27597],
        [31976],
        [31990],
        [41798],
        [40645],
        [32952],
        [33023]], device='cuda:0')
[2024-07-24 10:17:04,691][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678],
        [45678]], device='cuda:0')
[2024-07-24 10:17:04,726][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:04,728][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,729][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,730][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,730][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,731][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,731][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,731][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,732][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,732][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,732][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,732][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,733][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,733][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2419, 0.7581], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,733][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3079, 0.6921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,734][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3200, 0.6800], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,734][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1268, 0.8732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,735][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9537, 0.0463], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,736][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5205, 0.4795], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,738][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0867, 0.9133], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,739][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.4321, 0.5679], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,741][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9896, 0.0104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,741][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.6064, 0.3936], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,743][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7613, 0.2387], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,745][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0896, 0.9104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,746][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.4199, 0.2865, 0.2937], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,747][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.4089, 0.3479, 0.2431], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,750][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.1812, 0.4184, 0.4004], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,751][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0644, 0.4863, 0.4493], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,753][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.7122, 0.0999, 0.1879], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,753][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.7346, 0.1353, 0.1302], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,754][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.0509, 0.4818, 0.4673], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,754][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.1782, 0.4155, 0.4063], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,754][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([9.9228e-01, 7.5834e-04, 6.9600e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,755][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1881, 0.5304, 0.2815], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,755][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.9488, 0.0471, 0.0041], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,755][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.1428, 0.3908, 0.4664], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,755][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0780, 0.2794, 0.3870, 0.2555], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,756][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1144, 0.2533, 0.2941, 0.3382], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,756][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1382, 0.2985, 0.2851, 0.2783], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,756][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0407, 0.3332, 0.3117, 0.3144], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,756][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9190, 0.0337, 0.0187, 0.0285], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,757][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3868, 0.1898, 0.2684, 0.1550], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,757][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0287, 0.3559, 0.3067, 0.3087], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,758][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1995, 0.2630, 0.3088, 0.2287], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,759][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5919, 0.0116, 0.3859, 0.0107], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,761][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3047, 0.2339, 0.3023, 0.1591], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,762][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8708, 0.0918, 0.0136, 0.0237], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,763][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.6385e-04, 3.8797e-01, 6.1169e-01, 1.8347e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,764][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2227, 0.2150, 0.2344, 0.1886, 0.1392], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,766][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1649, 0.1899, 0.1988, 0.3431, 0.1033], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,768][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0976, 0.2363, 0.2258, 0.2200, 0.2203], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,769][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0339, 0.2562, 0.2392, 0.2411, 0.2296], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,771][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.4671, 0.1721, 0.1220, 0.0943, 0.1446], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,773][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.4077, 0.1213, 0.1659, 0.1301, 0.1750], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,774][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0239, 0.2629, 0.2445, 0.2249, 0.2437], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,776][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.1339, 0.2243, 0.2352, 0.1876, 0.2191], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,776][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.9113, 0.0065, 0.0639, 0.0092, 0.0091], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,777][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0831, 0.2775, 0.3582, 0.1897, 0.0915], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,777][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.9429, 0.0365, 0.0041, 0.0103, 0.0062], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,777][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([6.9763e-03, 2.0794e-01, 7.4248e-01, 1.8345e-04, 4.2419e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,778][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0927, 0.1340, 0.1943, 0.1116, 0.1122, 0.3553], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,778][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1108, 0.1957, 0.1491, 0.2935, 0.0860, 0.1650], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,778][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0825, 0.1929, 0.1845, 0.1796, 0.1800, 0.1806], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,778][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0338, 0.2076, 0.1941, 0.1926, 0.1858, 0.1861], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,779][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.5054, 0.0884, 0.0936, 0.1122, 0.1237, 0.0766], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,779][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2982, 0.1002, 0.1255, 0.1057, 0.2156, 0.1547], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,779][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0187, 0.2222, 0.1921, 0.1840, 0.1809, 0.2020], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,780][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1237, 0.1866, 0.1896, 0.1586, 0.1863, 0.1551], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,780][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.7626, 0.0090, 0.1284, 0.0135, 0.0561, 0.0305], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,781][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3790, 0.1555, 0.1624, 0.1422, 0.0825, 0.0785], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,782][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.6219e-01, 2.6988e-02, 2.6902e-03, 4.5274e-03, 3.0650e-03, 5.4369e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,783][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([1.8575e-03, 3.9882e-01, 5.5599e-01, 1.6018e-04, 4.0931e-02, 2.2402e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,784][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0549, 0.0893, 0.1253, 0.0824, 0.0787, 0.2828, 0.2866],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,786][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1347, 0.1485, 0.1334, 0.2323, 0.0723, 0.1364, 0.1424],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,787][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0713, 0.1628, 0.1562, 0.1520, 0.1530, 0.1530, 0.1517],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,789][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0227, 0.1708, 0.1633, 0.1629, 0.1534, 0.1634, 0.1635],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,791][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2073, 0.1575, 0.0748, 0.1324, 0.1188, 0.1844, 0.1248],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,792][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2618, 0.0814, 0.1114, 0.0685, 0.1497, 0.1384, 0.1888],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,793][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0188, 0.1862, 0.1578, 0.1539, 0.1473, 0.1599, 0.1762],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,796][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1077, 0.1572, 0.1706, 0.1328, 0.1627, 0.1389, 0.1302],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,797][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6556, 0.0065, 0.1875, 0.0119, 0.0792, 0.0487, 0.0107],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,799][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2892, 0.1625, 0.1461, 0.1283, 0.0989, 0.0957, 0.0793],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,799][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.7308e-01, 1.6683e-02, 1.9982e-03, 4.4397e-03, 2.6902e-03, 4.2960e-04,
        6.7635e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,800][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([6.6678e-03, 1.9091e-01, 7.5034e-01, 7.1017e-05, 3.8637e-02, 4.6831e-03,
        8.6887e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,800][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1456, 0.0502, 0.0761, 0.0497, 0.0485, 0.1674, 0.2008, 0.2618],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,800][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0995, 0.1009, 0.1321, 0.1575, 0.0822, 0.1173, 0.1433, 0.1671],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,801][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0693, 0.1401, 0.1331, 0.1301, 0.1304, 0.1308, 0.1305, 0.1357],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,801][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0224, 0.1431, 0.1379, 0.1347, 0.1267, 0.1347, 0.1404, 0.1601],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,801][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2982, 0.0764, 0.0352, 0.1732, 0.0492, 0.0464, 0.2611, 0.0603],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,802][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1856, 0.0606, 0.0851, 0.0618, 0.1101, 0.1241, 0.1844, 0.1882],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,802][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0157, 0.1575, 0.1353, 0.1336, 0.1219, 0.1365, 0.1434, 0.1560],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,802][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0887, 0.1389, 0.1432, 0.1195, 0.1371, 0.1250, 0.1227, 0.1249],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,803][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.8639, 0.0019, 0.0470, 0.0038, 0.0281, 0.0241, 0.0171, 0.0142],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,803][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1045, 0.1522, 0.1537, 0.1163, 0.0998, 0.0956, 0.1651, 0.1129],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,803][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([9.5501e-01, 2.3639e-02, 3.0279e-03, 7.5535e-03, 4.1399e-03, 8.4145e-04,
        1.2191e-03, 4.5698e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,804][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([7.7452e-02, 3.0827e-04, 6.3136e-03, 5.1109e-07, 5.8213e-04, 2.5314e-05,
        1.1789e-04, 9.1520e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,805][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1914, 0.0437, 0.0563, 0.0380, 0.0330, 0.1278, 0.1647, 0.2130, 0.1319],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,807][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1010, 0.0750, 0.1088, 0.1393, 0.0645, 0.0889, 0.1054, 0.1633, 0.1539],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,809][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0573, 0.1240, 0.1183, 0.1152, 0.1157, 0.1159, 0.1156, 0.1203, 0.1178],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,810][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0173, 0.1237, 0.1167, 0.1153, 0.1083, 0.1146, 0.1220, 0.1403, 0.1418],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,812][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.5753, 0.0213, 0.0057, 0.0624, 0.0782, 0.0280, 0.1223, 0.0662, 0.0407],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,813][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.2650, 0.0478, 0.0532, 0.0399, 0.0876, 0.0786, 0.1246, 0.1938, 0.1094],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,815][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0139, 0.1389, 0.1219, 0.1184, 0.1160, 0.1205, 0.1241, 0.1292, 0.1170],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,816][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0673, 0.1239, 0.1300, 0.1080, 0.1200, 0.1097, 0.1061, 0.1152, 0.1198],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,818][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([9.5732e-01, 7.2474e-04, 1.0883e-02, 1.8162e-03, 4.4205e-03, 7.6053e-03,
        6.3011e-03, 6.6123e-03, 4.3178e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,819][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0234, 0.1015, 0.1116, 0.0903, 0.0979, 0.1212, 0.1212, 0.2327, 0.1001],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,820][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([9.8439e-01, 9.8601e-03, 8.2758e-04, 2.1929e-03, 1.1062e-03, 1.7553e-04,
        2.2883e-04, 9.0466e-04, 3.1343e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,821][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([4.4232e-03, 6.7217e-05, 2.9723e-04, 2.4212e-08, 2.0483e-05, 1.0315e-06,
        7.6543e-06, 2.4961e-01, 7.4558e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:04,823][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0254, 0.0339, 0.0506, 0.0313, 0.0330, 0.1031, 0.1326, 0.2539, 0.1791,
        0.1570], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,823][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0308, 0.0564, 0.0709, 0.1024, 0.0434, 0.1022, 0.1119, 0.2194, 0.1775,
        0.0851], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,823][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0532, 0.1108, 0.1054, 0.1030, 0.1035, 0.1037, 0.1029, 0.1075, 0.1052,
        0.1047], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,824][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0171, 0.1082, 0.1024, 0.1020, 0.0956, 0.1039, 0.1068, 0.1220, 0.1226,
        0.1195], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,824][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7975, 0.0137, 0.0044, 0.0183, 0.0312, 0.0139, 0.0585, 0.0197, 0.0099,
        0.0328], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,824][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0733, 0.0322, 0.0674, 0.0361, 0.0974, 0.0859, 0.1356, 0.2284, 0.1794,
        0.0643], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,825][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0113, 0.1295, 0.1108, 0.1086, 0.1044, 0.1075, 0.1140, 0.1130, 0.0963,
        0.1046], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,825][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0696, 0.1044, 0.1149, 0.0939, 0.1123, 0.0957, 0.0981, 0.1027, 0.1087,
        0.0997], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,825][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4790, 0.0036, 0.1227, 0.0087, 0.0693, 0.0444, 0.0344, 0.0653, 0.1625,
        0.0100], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,825][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0622, 0.0639, 0.0777, 0.0622, 0.0925, 0.0947, 0.1103, 0.1436, 0.1938,
        0.0992], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,826][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.4284e-01, 3.2497e-02, 3.4100e-03, 6.7522e-03, 4.1997e-03, 7.5297e-04,
        1.1269e-03, 3.0546e-03, 1.5080e-03, 3.8543e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,826][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([2.1439e-06, 2.2811e-05, 1.1508e-04, 6.8352e-09, 8.1486e-06, 3.2946e-07,
        3.4485e-06, 1.7271e-01, 8.2700e-01, 1.3634e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:04,827][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0171, 0.0282, 0.0439, 0.0256, 0.0282, 0.0872, 0.1133, 0.2320, 0.1620,
        0.1375, 0.1250], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,829][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0322, 0.0491, 0.0655, 0.0681, 0.0501, 0.0959, 0.1070, 0.1644, 0.1499,
        0.0869, 0.1310], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,830][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0479, 0.0999, 0.0953, 0.0932, 0.0936, 0.0938, 0.0929, 0.0973, 0.0954,
        0.0949, 0.0957], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,832][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0127, 0.0967, 0.0912, 0.0922, 0.0854, 0.0927, 0.0958, 0.1097, 0.1092,
        0.1079, 0.1063], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,833][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8879, 0.0066, 0.0044, 0.0088, 0.0172, 0.0060, 0.0261, 0.0171, 0.0035,
        0.0150, 0.0075], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,835][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1136, 0.0325, 0.0486, 0.0246, 0.0914, 0.0733, 0.1176, 0.2019, 0.1659,
        0.0672, 0.0635], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,836][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0095, 0.1152, 0.0981, 0.0998, 0.0946, 0.0976, 0.1026, 0.1038, 0.0871,
        0.0929, 0.0988], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,838][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0620, 0.0938, 0.1053, 0.0843, 0.1045, 0.0879, 0.0905, 0.0927, 0.0993,
        0.0916, 0.0880], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,839][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5142, 0.0038, 0.1176, 0.0037, 0.0605, 0.0320, 0.0289, 0.0607, 0.1511,
        0.0136, 0.0137], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,841][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0621, 0.0718, 0.0754, 0.0474, 0.0989, 0.0930, 0.0921, 0.1280, 0.1630,
        0.1005, 0.0678], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,843][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9134, 0.0400, 0.0051, 0.0115, 0.0077, 0.0013, 0.0020, 0.0049, 0.0025,
        0.0057, 0.0061], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,844][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.5089e-05, 4.3693e-05, 2.5160e-04, 8.2607e-09, 9.8977e-06, 5.0192e-07,
        5.0848e-06, 1.7796e-01, 8.2113e-01, 1.5230e-04, 4.2964e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:04,846][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0865, 0.0321, 0.0399, 0.0283, 0.0258, 0.0848, 0.1120, 0.1453, 0.1075,
        0.1144, 0.1005, 0.1229], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,846][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0823, 0.0470, 0.0546, 0.0836, 0.0376, 0.0633, 0.0830, 0.1041, 0.0995,
        0.0782, 0.1229, 0.1439], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,846][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0441, 0.0908, 0.0866, 0.0848, 0.0850, 0.0856, 0.0849, 0.0886, 0.0868,
        0.0863, 0.0870, 0.0895], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,847][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0127, 0.0863, 0.0842, 0.0832, 0.0795, 0.0825, 0.0871, 0.1001, 0.0997,
        0.0970, 0.0946, 0.0932], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,847][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.4842, 0.0360, 0.0090, 0.0535, 0.0483, 0.0227, 0.1064, 0.0437, 0.0122,
        0.0969, 0.0433, 0.0438], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,847][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.3468, 0.0308, 0.0276, 0.0280, 0.0544, 0.0561, 0.0755, 0.1304, 0.0724,
        0.0570, 0.0571, 0.0639], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,848][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0115, 0.1030, 0.0914, 0.0890, 0.0867, 0.0878, 0.0898, 0.0967, 0.0821,
        0.0828, 0.0873, 0.0919], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,848][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0483, 0.0925, 0.0943, 0.0818, 0.0913, 0.0809, 0.0816, 0.0838, 0.0919,
        0.0902, 0.0847, 0.0787], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,848][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([9.6754e-01, 2.3052e-04, 5.5387e-03, 7.4347e-04, 3.2448e-03, 3.7841e-03,
        2.7018e-03, 2.4400e-03, 4.4144e-03, 1.4660e-03, 2.6227e-03, 5.2717e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,849][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0319, 0.0767, 0.0488, 0.0637, 0.0642, 0.0848, 0.0853, 0.1256, 0.1470,
        0.1029, 0.0893, 0.0798], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,849][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([9.5510e-01, 2.6667e-02, 2.2483e-03, 4.5540e-03, 2.5844e-03, 4.6673e-04,
        6.1841e-04, 2.0291e-03, 8.0090e-04, 1.9250e-03, 2.0469e-03, 9.6375e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,849][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([6.2839e-03, 1.5750e-06, 2.4794e-05, 1.8602e-09, 2.0827e-06, 9.8237e-08,
        5.6060e-07, 5.2685e-03, 1.5825e-02, 4.8102e-06, 1.3795e-05, 9.7257e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:04,851][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0755, 0.0315, 0.0350, 0.0282, 0.0226, 0.0909, 0.1092, 0.1296, 0.0896,
        0.1109, 0.1008, 0.1140, 0.0622], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,853][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0694, 0.0427, 0.0522, 0.0806, 0.0296, 0.0565, 0.0791, 0.1000, 0.0889,
        0.0601, 0.1168, 0.1644, 0.0597], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,854][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0390, 0.0840, 0.0802, 0.0781, 0.0783, 0.0787, 0.0783, 0.0814, 0.0795,
        0.0792, 0.0798, 0.0820, 0.0816], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,856][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0119, 0.0800, 0.0756, 0.0752, 0.0720, 0.0744, 0.0796, 0.0929, 0.0947,
        0.0887, 0.0864, 0.0875, 0.0814], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,857][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.2344, 0.0425, 0.0410, 0.0360, 0.0490, 0.0413, 0.0695, 0.0898, 0.0375,
        0.1088, 0.0336, 0.1647, 0.0522], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,858][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.1839, 0.0281, 0.0394, 0.0260, 0.0438, 0.0741, 0.0672, 0.1260, 0.0850,
        0.0460, 0.0594, 0.1071, 0.1140], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,860][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0093, 0.0933, 0.0864, 0.0797, 0.0858, 0.0820, 0.0850, 0.0875, 0.0708,
        0.0767, 0.0791, 0.0788, 0.0855], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,862][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0462, 0.0852, 0.0872, 0.0732, 0.0809, 0.0771, 0.0719, 0.0807, 0.0852,
        0.0811, 0.0762, 0.0736, 0.0815], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,863][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.9122, 0.0010, 0.0144, 0.0019, 0.0019, 0.0079, 0.0032, 0.0055, 0.0113,
        0.0043, 0.0061, 0.0214, 0.0091], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,865][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0177, 0.0853, 0.0892, 0.0529, 0.0266, 0.0921, 0.0702, 0.1735, 0.1283,
        0.0718, 0.0466, 0.1161, 0.0296], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,866][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([9.3520e-01, 3.1245e-02, 3.3944e-03, 7.2158e-03, 4.2774e-03, 6.3303e-04,
        1.1199e-03, 3.4256e-03, 1.3447e-03, 3.8040e-03, 4.3136e-03, 1.4482e-03,
        2.5773e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,867][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([1.1095e-03, 7.4134e-07, 1.7421e-05, 6.9995e-10, 8.3986e-07, 6.5736e-08,
        3.2585e-07, 2.1618e-03, 1.2562e-02, 1.8885e-06, 5.8034e-06, 4.8497e-01,
        4.9917e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:04,869][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0471, 0.0222, 0.0317, 0.0196, 0.0204, 0.0612, 0.0827, 0.1306, 0.0972,
        0.0902, 0.0789, 0.1152, 0.0679, 0.1353], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,869][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0870, 0.0450, 0.0444, 0.0711, 0.0261, 0.0443, 0.0632, 0.1025, 0.1014,
        0.0635, 0.1110, 0.1308, 0.0546, 0.0549], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,869][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0351, 0.0777, 0.0741, 0.0722, 0.0724, 0.0727, 0.0722, 0.0751, 0.0734,
        0.0732, 0.0738, 0.0758, 0.0756, 0.0765], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,870][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0100, 0.0737, 0.0707, 0.0695, 0.0671, 0.0703, 0.0724, 0.0843, 0.0880,
        0.0820, 0.0800, 0.0812, 0.0766, 0.0743], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,870][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1756, 0.0369, 0.0069, 0.0288, 0.0597, 0.0404, 0.0581, 0.0423, 0.0404,
        0.0738, 0.0286, 0.1552, 0.0607, 0.1927], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,871][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.1392, 0.0286, 0.0381, 0.0266, 0.0582, 0.0475, 0.0796, 0.1042, 0.0697,
        0.0431, 0.0559, 0.0901, 0.1472, 0.0720], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,871][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0088, 0.0861, 0.0776, 0.0732, 0.0757, 0.0769, 0.0790, 0.0779, 0.0685,
        0.0717, 0.0729, 0.0739, 0.0754, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,871][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0454, 0.0793, 0.0825, 0.0682, 0.0761, 0.0683, 0.0667, 0.0734, 0.0801,
        0.0747, 0.0706, 0.0690, 0.0762, 0.0695], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,872][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.8460, 0.0010, 0.0192, 0.0019, 0.0110, 0.0091, 0.0046, 0.0078, 0.0127,
        0.0041, 0.0060, 0.0249, 0.0388, 0.0129], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,872][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0587, 0.0647, 0.0879, 0.0516, 0.0549, 0.0658, 0.0633, 0.1140, 0.0779,
        0.0693, 0.0543, 0.1175, 0.0550, 0.0650], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,872][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([9.6739e-01, 1.9092e-02, 1.9369e-03, 3.3943e-03, 2.0111e-03, 2.9813e-04,
        3.2384e-04, 1.1222e-03, 4.4928e-04, 9.1826e-04, 1.1121e-03, 6.1377e-04,
        9.4262e-04, 3.9835e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,873][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([3.3153e-04, 4.4944e-06, 2.0332e-05, 1.7800e-09, 9.8698e-07, 7.2821e-08,
        3.2391e-07, 3.5352e-03, 2.7260e-02, 7.4291e-06, 1.5136e-05, 6.3920e-01,
        3.2402e-01, 5.6026e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:04,875][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0276, 0.0209, 0.0317, 0.0187, 0.0215, 0.0595, 0.0715, 0.1134, 0.0890,
        0.0712, 0.0608, 0.0988, 0.0620, 0.1243, 0.1293], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,877][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0463, 0.0419, 0.0372, 0.0619, 0.0269, 0.0542, 0.0596, 0.1071, 0.0983,
        0.0647, 0.1032, 0.1042, 0.0568, 0.0569, 0.0809], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,878][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0322, 0.0720, 0.0687, 0.0671, 0.0674, 0.0676, 0.0671, 0.0699, 0.0684,
        0.0682, 0.0688, 0.0708, 0.0705, 0.0713, 0.0699], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,879][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0091, 0.0687, 0.0651, 0.0660, 0.0608, 0.0662, 0.0682, 0.0774, 0.0771,
        0.0770, 0.0752, 0.0742, 0.0697, 0.0690, 0.0761], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,881][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1844, 0.0279, 0.0211, 0.0351, 0.0319, 0.0411, 0.0402, 0.0441, 0.0385,
        0.0811, 0.0445, 0.0754, 0.0417, 0.2633, 0.0297], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,883][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0897, 0.0245, 0.0394, 0.0227, 0.0590, 0.0492, 0.0721, 0.1096, 0.0801,
        0.0404, 0.0486, 0.0773, 0.1352, 0.0788, 0.0733], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,885][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0081, 0.0826, 0.0741, 0.0703, 0.0698, 0.0719, 0.0740, 0.0713, 0.0630,
        0.0670, 0.0692, 0.0691, 0.0699, 0.0693, 0.0704], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,886][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0397, 0.0707, 0.0758, 0.0648, 0.0730, 0.0665, 0.0644, 0.0667, 0.0735,
        0.0675, 0.0668, 0.0643, 0.0730, 0.0672, 0.0662], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,888][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7082, 0.0009, 0.0248, 0.0015, 0.0177, 0.0127, 0.0077, 0.0107, 0.0289,
        0.0037, 0.0053, 0.0429, 0.0841, 0.0462, 0.0043], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,890][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0530, 0.0525, 0.0444, 0.0396, 0.0637, 0.0567, 0.0622, 0.0776, 0.1038,
        0.0665, 0.0558, 0.0862, 0.0694, 0.1095, 0.0592], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,891][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.7907e-01, 1.1479e-02, 1.0161e-03, 2.0065e-03, 1.2128e-03, 1.8660e-04,
        2.3729e-04, 8.8997e-04, 3.5142e-04, 9.3455e-04, 1.0538e-03, 4.4370e-04,
        6.3147e-04, 2.7383e-04, 2.1178e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,892][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([7.9941e-05, 1.1095e-06, 2.4364e-05, 3.6408e-10, 6.7018e-07, 5.8663e-08,
        2.6349e-07, 2.1813e-03, 2.5836e-02, 2.7722e-06, 6.1389e-06, 5.1041e-01,
        4.4190e-01, 1.5784e-02, 3.7748e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:04,916][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:04,916][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,916][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,917][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,917][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,917][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,918][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,918][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,918][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,919][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,919][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,921][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,928][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:04,930][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0069, 0.9931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,931][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9313, 0.0687], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,933][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2358, 0.7642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,935][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6421, 0.3579], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,936][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.9977e-01, 2.2830e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,937][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8368, 0.1632], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,939][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1165, 0.8835], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,941][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4503, 0.5497], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,942][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6976, 0.3024], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,943][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7114, 0.2886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,943][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,943][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0616, 0.9384], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:04,944][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0022, 0.5619, 0.4359], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,944][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.6000, 0.2440, 0.1560], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,944][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0999, 0.6170, 0.2831], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,945][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.3985, 0.3050, 0.2965], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,945][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.9952, 0.0020, 0.0029], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,945][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.7580, 0.0547, 0.1873], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,946][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0739, 0.4642, 0.4620], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,946][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.6817, 0.1917, 0.1266], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,946][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.8628, 0.0412, 0.0960], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,947][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.3282, 0.3305, 0.3414], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,949][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.9858, 0.0056, 0.0085], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,950][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.1124, 0.3378, 0.5498], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:04,952][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0030, 0.3850, 0.3512, 0.2608], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,953][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8435, 0.0461, 0.0918, 0.0187], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,954][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1163, 0.4358, 0.2000, 0.2479], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,956][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2745, 0.2716, 0.2857, 0.1683], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,958][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9885, 0.0022, 0.0034, 0.0059], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,959][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4905, 0.1389, 0.2902, 0.0804], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,961][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0414, 0.3251, 0.3201, 0.3134], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,963][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0721, 0.3346, 0.5485, 0.0448], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,964][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0125, 0.2239, 0.7568, 0.0068], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,966][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3300, 0.3039, 0.2253, 0.1408], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,966][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9759, 0.0070, 0.0091, 0.0080], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,966][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0012, 0.2923, 0.7027, 0.0038], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:04,967][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0012, 0.2584, 0.2162, 0.2312, 0.2929], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,967][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.5265, 0.1298, 0.1420, 0.0819, 0.1199], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,967][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0596, 0.3856, 0.1619, 0.2239, 0.1689], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,968][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.2281, 0.2245, 0.2308, 0.1375, 0.1792], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,968][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.9825, 0.0030, 0.0037, 0.0067, 0.0041], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,968][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.3838, 0.1049, 0.2599, 0.1416, 0.1098], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,969][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0364, 0.2431, 0.2447, 0.2363, 0.2394], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,969][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.2022, 0.1930, 0.2591, 0.0258, 0.3199], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,969][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.3477, 0.1314, 0.4217, 0.0035, 0.0956], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,970][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.3380, 0.2156, 0.2002, 0.1282, 0.1180], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,972][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.9723, 0.0055, 0.0085, 0.0071, 0.0065], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,973][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0372, 0.1457, 0.5421, 0.0031, 0.2719], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:04,975][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0013, 0.2126, 0.1864, 0.1555, 0.2467, 0.1976], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,976][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4769, 0.1054, 0.1472, 0.0518, 0.1236, 0.0952], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,978][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0762, 0.3014, 0.1316, 0.1742, 0.1444, 0.1722], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,980][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.2035, 0.1815, 0.1940, 0.1211, 0.1567, 0.1432], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,981][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([9.9023e-01, 7.7591e-04, 1.7356e-03, 3.0237e-03, 1.8031e-03, 2.4291e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,982][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2842, 0.0912, 0.2534, 0.1209, 0.1775, 0.0728], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,984][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0287, 0.1979, 0.1969, 0.1905, 0.1925, 0.1934], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,986][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0868, 0.1462, 0.2384, 0.0234, 0.4219, 0.0834], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,987][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2097, 0.2156, 0.3169, 0.0069, 0.1783, 0.0726], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,989][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.5167, 0.1180, 0.1137, 0.0812, 0.0633, 0.1070], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,989][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9570, 0.0068, 0.0102, 0.0083, 0.0077, 0.0099], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,989][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0284, 0.2061, 0.4502, 0.0033, 0.2656, 0.0464], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:04,990][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0013, 0.1847, 0.1537, 0.1441, 0.2048, 0.1715, 0.1400],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,990][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5046, 0.0860, 0.1095, 0.0399, 0.0820, 0.0696, 0.1085],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,990][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0592, 0.2309, 0.1053, 0.1219, 0.1248, 0.1402, 0.2176],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,991][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2021, 0.1580, 0.1615, 0.0980, 0.1265, 0.1236, 0.1302],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,991][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.8735e-01, 5.8279e-04, 1.5627e-03, 2.9473e-03, 2.0609e-03, 2.5410e-03,
        2.9536e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,991][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3398, 0.0989, 0.2390, 0.0729, 0.1003, 0.0662, 0.0830],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,992][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0248, 0.1653, 0.1637, 0.1602, 0.1609, 0.1605, 0.1646],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,992][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2064, 0.0817, 0.1439, 0.0103, 0.2554, 0.0629, 0.2395],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,992][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([7.6255e-01, 1.5109e-02, 6.7707e-02, 6.8371e-04, 2.9824e-02, 2.7052e-02,
        9.7077e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,993][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.4078, 0.1380, 0.1264, 0.0872, 0.0691, 0.1072, 0.0642],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,995][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9496, 0.0066, 0.0099, 0.0082, 0.0072, 0.0096, 0.0090],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,997][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1786, 0.0635, 0.2887, 0.0012, 0.1423, 0.0671, 0.2585],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:04,998][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0009, 0.1568, 0.1255, 0.1192, 0.1737, 0.1502, 0.1322, 0.1414],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:04,999][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.4401, 0.0543, 0.0849, 0.0284, 0.0906, 0.0627, 0.1251, 0.1138],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,001][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0510, 0.2372, 0.0852, 0.1273, 0.1017, 0.1369, 0.2021, 0.0586],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,003][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1804, 0.1319, 0.1364, 0.0875, 0.1118, 0.1089, 0.1173, 0.1258],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,004][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([9.9367e-01, 3.5463e-04, 7.1232e-04, 1.4178e-03, 7.7112e-04, 1.0039e-03,
        1.3093e-03, 7.6019e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,005][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3412, 0.0690, 0.1682, 0.0882, 0.0840, 0.0835, 0.0957, 0.0702],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,007][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0221, 0.1414, 0.1410, 0.1367, 0.1382, 0.1382, 0.1407, 0.1418],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,009][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.3007, 0.0128, 0.0177, 0.0018, 0.0369, 0.0110, 0.0542, 0.5649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,010][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([5.2297e-01, 1.8647e-05, 3.5289e-04, 2.0834e-06, 2.0264e-04, 1.5982e-04,
        1.4459e-03, 4.7485e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,011][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.6429, 0.0815, 0.0627, 0.0412, 0.0314, 0.0724, 0.0367, 0.0312],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,012][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.9654, 0.0039, 0.0059, 0.0051, 0.0044, 0.0058, 0.0054, 0.0040],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,013][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([7.5031e-02, 7.7261e-05, 2.1987e-03, 4.8529e-06, 1.5538e-03, 4.0673e-04,
        3.6200e-03, 9.1711e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,013][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0006, 0.1346, 0.1054, 0.1080, 0.1494, 0.1294, 0.1174, 0.1336, 0.1217],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,013][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.4262, 0.0516, 0.0883, 0.0246, 0.0733, 0.0434, 0.0865, 0.1098, 0.0963],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,014][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0417, 0.2204, 0.0911, 0.1267, 0.1014, 0.1472, 0.1821, 0.0509, 0.0384],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,014][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1645, 0.1143, 0.1213, 0.0764, 0.0981, 0.0973, 0.1017, 0.1122, 0.1141],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,014][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([9.9615e-01, 2.0179e-04, 3.8190e-04, 9.2855e-04, 4.1514e-04, 4.4891e-04,
        6.7645e-04, 3.5754e-04, 4.4118e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,015][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.5433, 0.0376, 0.0853, 0.0409, 0.0622, 0.0295, 0.0833, 0.0782, 0.0398],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,015][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0182, 0.1253, 0.1245, 0.1207, 0.1215, 0.1220, 0.1242, 0.1246, 0.1190],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,015][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1759, 0.0095, 0.0116, 0.0009, 0.0176, 0.0060, 0.0296, 0.3932, 0.3558],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,016][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.0074e-01, 8.6826e-06, 9.5978e-05, 5.3421e-07, 2.8056e-05, 3.4141e-05,
        4.6259e-04, 4.8456e-01, 4.1406e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,016][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.4718, 0.0873, 0.0853, 0.0562, 0.0447, 0.0960, 0.0499, 0.0397, 0.0691],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,018][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.9504, 0.0051, 0.0074, 0.0062, 0.0055, 0.0070, 0.0065, 0.0048, 0.0070],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,019][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([4.7171e-03, 2.5235e-05, 1.7659e-04, 6.2056e-07, 1.3020e-04, 4.3454e-05,
        7.1349e-04, 3.9895e-01, 5.9524e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,021][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0006, 0.1178, 0.1019, 0.0861, 0.1423, 0.1204, 0.1004, 0.1162, 0.1287,
        0.0858], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,022][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6247, 0.0243, 0.0428, 0.0106, 0.0427, 0.0366, 0.0561, 0.0829, 0.0631,
        0.0162], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,024][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0495, 0.1975, 0.0793, 0.1101, 0.0918, 0.1220, 0.1758, 0.0524, 0.0420,
        0.0795], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,026][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1374, 0.1116, 0.1173, 0.0713, 0.0916, 0.0896, 0.0957, 0.1068, 0.1095,
        0.0692], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,027][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.7802e-01, 7.8304e-04, 1.6440e-03, 3.1040e-03, 2.3137e-03, 2.4804e-03,
        3.0590e-03, 1.9918e-03, 2.1992e-03, 4.4034e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,028][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3591, 0.0169, 0.1179, 0.0321, 0.0770, 0.0473, 0.0378, 0.1245, 0.1415,
        0.0460], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,029][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0131, 0.1141, 0.1115, 0.1096, 0.1090, 0.1096, 0.1133, 0.1125, 0.1052,
        0.1021], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,031][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.0778e-02, 3.8056e-03, 6.5821e-03, 4.0587e-04, 1.3117e-02, 3.1182e-03,
        2.1217e-02, 5.2383e-01, 3.9315e-01, 2.3997e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,032][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([4.1153e-04, 8.3707e-06, 6.7893e-05, 3.9847e-07, 3.1324e-05, 1.2954e-05,
        3.1312e-04, 3.2213e-01, 6.7432e-01, 2.6959e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,034][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2890, 0.0962, 0.0923, 0.0581, 0.0534, 0.1083, 0.0611, 0.0493, 0.0738,
        0.1185], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,035][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9118, 0.0083, 0.0110, 0.0095, 0.0081, 0.0105, 0.0103, 0.0077, 0.0110,
        0.0118], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,035][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.7128e-05, 1.5512e-05, 1.4511e-04, 4.2554e-07, 1.1444e-04, 2.3369e-05,
        4.5779e-04, 3.7097e-01, 6.2610e-01, 2.1346e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,036][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0005, 0.1105, 0.0952, 0.0774, 0.1361, 0.1113, 0.0915, 0.1083, 0.1173,
        0.0811, 0.0708], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,036][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6051, 0.0237, 0.0450, 0.0078, 0.0654, 0.0366, 0.0667, 0.0632, 0.0594,
        0.0162, 0.0109], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,037][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0448, 0.1823, 0.0767, 0.1020, 0.0869, 0.1190, 0.1723, 0.0507, 0.0376,
        0.0709, 0.0569], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,037][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1253, 0.1057, 0.1124, 0.0667, 0.0884, 0.0824, 0.0899, 0.1008, 0.1024,
        0.0660, 0.0601], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,037][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.7142e-01, 8.4830e-04, 1.8654e-03, 3.3517e-03, 2.5428e-03, 2.9409e-03,
        3.6972e-03, 2.4418e-03, 2.4902e-03, 5.1188e-03, 3.2854e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,038][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5051, 0.0248, 0.0552, 0.0132, 0.0590, 0.0335, 0.0287, 0.0899, 0.0931,
        0.0489, 0.0486], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,038][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0122, 0.1034, 0.1008, 0.0991, 0.0984, 0.0991, 0.1024, 0.1017, 0.0953,
        0.0924, 0.0953], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,038][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.5321e-02, 3.5756e-03, 7.1588e-03, 2.9028e-04, 1.3926e-02, 2.7161e-03,
        2.1154e-02, 4.8872e-01, 3.9920e-01, 2.0282e-02, 2.7651e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,039][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.5234e-04, 6.4840e-06, 7.1050e-05, 2.1742e-07, 2.4445e-05, 1.1691e-05,
        3.6447e-04, 3.1504e-01, 6.7684e-01, 2.4710e-03, 4.6223e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,039][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1924, 0.1047, 0.0933, 0.0545, 0.0543, 0.1226, 0.0641, 0.0537, 0.0723,
        0.1116, 0.0766], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,041][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9026, 0.0079, 0.0106, 0.0090, 0.0080, 0.0101, 0.0098, 0.0072, 0.0106,
        0.0115, 0.0126], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,042][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.3167e-05, 2.0601e-05, 2.1932e-04, 3.1915e-07, 9.6145e-05, 2.4839e-05,
        5.8240e-04, 3.3641e-01, 6.5544e-01, 2.1725e-03, 4.9589e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,044][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0005, 0.1000, 0.0784, 0.0811, 0.1170, 0.0967, 0.0918, 0.1032, 0.1001,
        0.0773, 0.0755, 0.0784], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,045][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.2421, 0.0530, 0.0619, 0.0224, 0.0642, 0.0455, 0.1064, 0.1178, 0.0806,
        0.0399, 0.0321, 0.1341], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,047][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0390, 0.1821, 0.0673, 0.1137, 0.0764, 0.1287, 0.1612, 0.0458, 0.0319,
        0.0661, 0.0592, 0.0284], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,049][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.1670, 0.0861, 0.0935, 0.0547, 0.0731, 0.0719, 0.0743, 0.0853, 0.0875,
        0.0553, 0.0503, 0.1009], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,050][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([9.8124e-01, 5.7942e-04, 1.1433e-03, 2.6685e-03, 1.2460e-03, 1.3134e-03,
        1.8416e-03, 1.0989e-03, 1.3663e-03, 3.3205e-03, 2.0308e-03, 2.1473e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,051][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.6206, 0.0224, 0.0338, 0.0206, 0.0266, 0.0200, 0.0276, 0.0334, 0.0187,
        0.0685, 0.0612, 0.0466], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,052][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0139, 0.0928, 0.0923, 0.0898, 0.0900, 0.0902, 0.0922, 0.0920, 0.0875,
        0.0843, 0.0865, 0.0884], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,054][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([3.4560e-01, 2.6197e-03, 3.9010e-03, 3.1108e-04, 7.9512e-03, 2.4276e-03,
        1.2434e-02, 1.3329e-01, 1.3347e-01, 7.9988e-03, 8.6405e-03, 3.4136e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,055][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.0259e-01, 4.1685e-07, 7.5764e-06, 5.9389e-08, 3.0335e-06, 4.5886e-06,
        4.3984e-05, 1.7779e-02, 1.7912e-02, 1.2416e-04, 2.3488e-04, 8.6130e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,057][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.3009, 0.0855, 0.0682, 0.0431, 0.0377, 0.0773, 0.0439, 0.0321, 0.0487,
        0.0838, 0.0646, 0.1141], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,058][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.9099, 0.0068, 0.0089, 0.0076, 0.0072, 0.0088, 0.0082, 0.0058, 0.0083,
        0.0091, 0.0098, 0.0095], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,059][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([5.7688e-03, 7.2940e-07, 1.4208e-05, 4.5602e-08, 1.1165e-05, 4.9950e-06,
        5.1282e-05, 7.3707e-03, 1.3908e-02, 8.8675e-05, 1.5543e-04, 9.7263e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,059][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0004, 0.0878, 0.0711, 0.0768, 0.0991, 0.0813, 0.0790, 0.0963, 0.0895,
        0.0690, 0.0688, 0.0721, 0.1090], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,059][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.2314, 0.0429, 0.0388, 0.0256, 0.0361, 0.0414, 0.1006, 0.1163, 0.0755,
        0.0333, 0.0416, 0.1558, 0.0606], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,060][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0271, 0.1770, 0.0737, 0.1045, 0.0756, 0.1095, 0.1526, 0.0436, 0.0306,
        0.0651, 0.0543, 0.0366, 0.0497], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,060][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.1267, 0.0846, 0.0826, 0.0492, 0.0642, 0.0684, 0.0704, 0.0782, 0.0834,
        0.0525, 0.0480, 0.0957, 0.0962], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,060][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([9.6814e-01, 7.7100e-04, 1.4357e-03, 3.0026e-03, 1.8804e-03, 2.4636e-03,
        3.5075e-03, 2.1855e-03, 2.3856e-03, 4.8733e-03, 2.7827e-03, 5.0707e-03,
        1.4965e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,061][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.2828, 0.0176, 0.0694, 0.0267, 0.0279, 0.0519, 0.0239, 0.0470, 0.0385,
        0.0547, 0.0919, 0.1939, 0.0738], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,061][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0130, 0.0853, 0.0852, 0.0824, 0.0831, 0.0833, 0.0848, 0.0847, 0.0805,
        0.0770, 0.0790, 0.0817, 0.0798], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,062][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([1.2209e-01, 1.3068e-03, 1.8193e-03, 1.1493e-04, 2.8616e-03, 1.0301e-03,
        4.7855e-03, 5.7779e-02, 6.3604e-02, 3.0887e-03, 3.7995e-03, 2.0853e-01,
        5.2919e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,062][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([9.1784e-02, 6.8091e-07, 8.9047e-06, 3.0816e-08, 1.5143e-06, 2.8792e-06,
        2.3323e-05, 4.8100e-03, 1.5956e-02, 7.3969e-05, 9.7191e-05, 6.7869e-01,
        2.0855e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,064][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.2340, 0.0896, 0.0650, 0.0434, 0.0379, 0.0711, 0.0419, 0.0319, 0.0404,
        0.0674, 0.0547, 0.0978, 0.1249], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,066][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.9222, 0.0045, 0.0069, 0.0059, 0.0054, 0.0071, 0.0065, 0.0046, 0.0067,
        0.0072, 0.0078, 0.0078, 0.0074], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,067][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([1.2239e-03, 3.0403e-07, 6.1295e-06, 1.2729e-08, 3.5417e-06, 2.5680e-06,
        2.3021e-05, 3.1247e-03, 9.9444e-03, 2.8687e-05, 4.8179e-05, 5.7719e-01,
        4.0840e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,068][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0002, 0.0838, 0.0718, 0.0654, 0.1018, 0.0847, 0.0688, 0.0814, 0.0840,
        0.0603, 0.0600, 0.0732, 0.1148, 0.0498], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,069][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.2412, 0.0342, 0.0566, 0.0197, 0.0451, 0.0393, 0.0710, 0.1037, 0.0922,
        0.0271, 0.0299, 0.1275, 0.0748, 0.0378], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,071][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0323, 0.1604, 0.0733, 0.0921, 0.0753, 0.1108, 0.1485, 0.0403, 0.0322,
        0.0611, 0.0504, 0.0314, 0.0516, 0.0403], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,073][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1166, 0.0778, 0.0780, 0.0463, 0.0597, 0.0613, 0.0640, 0.0721, 0.0765,
        0.0492, 0.0441, 0.0874, 0.0890, 0.0780], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,074][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([9.7401e-01, 5.6124e-04, 1.0208e-03, 2.4872e-03, 1.3538e-03, 2.1732e-03,
        2.6765e-03, 1.5639e-03, 1.9045e-03, 3.5855e-03, 2.1205e-03, 2.0998e-03,
        8.2263e-04, 3.6223e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,075][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.3017, 0.0156, 0.0589, 0.0226, 0.0365, 0.0206, 0.0347, 0.0257, 0.0220,
        0.0520, 0.0967, 0.1560, 0.1026, 0.0544], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,077][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0115, 0.0793, 0.0789, 0.0769, 0.0771, 0.0772, 0.0788, 0.0786, 0.0744,
        0.0717, 0.0737, 0.0758, 0.0738, 0.0722], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,078][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([3.5344e-02, 1.3831e-03, 1.6407e-03, 1.3398e-04, 3.4529e-03, 1.2756e-03,
        5.8844e-03, 6.6307e-02, 6.7967e-02, 3.8027e-03, 5.0887e-03, 1.7114e-01,
        5.9880e-01, 3.7783e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,079][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([1.4885e-02, 2.3882e-06, 1.1542e-05, 1.0215e-07, 4.7172e-06, 6.9175e-06,
        2.4642e-05, 7.6529e-03, 2.3687e-02, 2.1702e-04, 2.3078e-04, 6.4971e-01,
        2.7032e-01, 3.3247e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,081][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1952, 0.0771, 0.0536, 0.0369, 0.0340, 0.0607, 0.0371, 0.0285, 0.0374,
        0.0598, 0.0498, 0.0930, 0.1115, 0.1252], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,081][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.9203, 0.0044, 0.0066, 0.0055, 0.0049, 0.0063, 0.0059, 0.0043, 0.0063,
        0.0068, 0.0074, 0.0073, 0.0066, 0.0074], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,082][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([5.6940e-04, 2.7308e-06, 1.3448e-05, 5.5614e-08, 7.0090e-06, 3.7650e-06,
        2.7626e-05, 5.1055e-03, 2.0401e-02, 1.2100e-04, 1.4267e-04, 6.6643e-01,
        2.9371e-01, 1.3461e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,082][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0003, 0.0838, 0.0677, 0.0628, 0.0962, 0.0827, 0.0677, 0.0753, 0.0815,
        0.0606, 0.0562, 0.0663, 0.1061, 0.0502, 0.0426], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,082][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4356, 0.0276, 0.0436, 0.0115, 0.0393, 0.0338, 0.0581, 0.0854, 0.0533,
        0.0187, 0.0144, 0.0723, 0.0594, 0.0252, 0.0218], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,083][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0351, 0.1481, 0.0656, 0.0877, 0.0731, 0.1005, 0.1429, 0.0424, 0.0292,
        0.0583, 0.0495, 0.0309, 0.0504, 0.0406, 0.0456], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,083][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1054, 0.0717, 0.0761, 0.0458, 0.0598, 0.0593, 0.0598, 0.0643, 0.0701,
        0.0463, 0.0418, 0.0796, 0.0818, 0.0744, 0.0639], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,084][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.6436e-01, 6.8792e-04, 1.8721e-03, 3.4100e-03, 1.9614e-03, 2.5887e-03,
        2.8182e-03, 1.9810e-03, 1.9688e-03, 4.6172e-03, 2.8056e-03, 2.6718e-03,
        1.0538e-03, 4.5172e-03, 2.6834e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,084][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2967, 0.0154, 0.0593, 0.0136, 0.0337, 0.0153, 0.0207, 0.0355, 0.0322,
        0.0431, 0.0657, 0.1347, 0.1114, 0.0722, 0.0504], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,084][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0103, 0.0747, 0.0736, 0.0717, 0.0719, 0.0723, 0.0741, 0.0737, 0.0696,
        0.0670, 0.0689, 0.0704, 0.0686, 0.0671, 0.0661], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,085][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.2308e-02, 1.5294e-03, 2.3213e-03, 1.1526e-04, 4.5150e-03, 1.3526e-03,
        4.7290e-03, 4.2885e-02, 6.2985e-02, 3.5251e-03, 3.6703e-03, 1.3383e-01,
        5.6851e-01, 3.3560e-02, 4.4166e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,085][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.5298e-02, 9.0654e-07, 1.1931e-05, 4.3199e-08, 4.2702e-06, 5.6189e-06,
        3.1240e-05, 4.2577e-03, 3.1495e-02, 1.0542e-04, 1.1627e-04, 5.5353e-01,
        3.2347e-01, 4.5602e-02, 1.6071e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,087][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2056, 0.0640, 0.0425, 0.0300, 0.0271, 0.0502, 0.0315, 0.0235, 0.0357,
        0.0617, 0.0494, 0.0820, 0.0936, 0.0994, 0.1038], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,089][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.8832, 0.0058, 0.0086, 0.0075, 0.0065, 0.0084, 0.0082, 0.0060, 0.0086,
        0.0094, 0.0102, 0.0095, 0.0088, 0.0097, 0.0097], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,090][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1552e-03, 1.2591e-06, 1.6856e-05, 2.7563e-08, 7.2928e-06, 4.5296e-06,
        3.5764e-05, 3.9724e-03, 1.9506e-02, 6.4662e-05, 8.1725e-05, 5.4870e-01,
        3.6379e-01, 3.7578e-02, 2.5084e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,091][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:05,093][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15888],
        [ 6945],
        [16407],
        [  709],
        [ 4109],
        [ 1455],
        [  952],
        [ 2869],
        [ 3724],
        [ 1417],
        [  888],
        [ 2677],
        [10984],
        [ 3882],
        [ 2331]], device='cuda:0')
[2024-07-24 10:17:05,095][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[18470],
        [ 4190],
        [24401],
        [  113],
        [ 2572],
        [ 1335],
        [ 1543],
        [ 4011],
        [ 4663],
        [ 1214],
        [ 1134],
        [ 2092],
        [12530],
        [ 3193],
        [ 5551]], device='cuda:0')
[2024-07-24 10:17:05,096][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38956],
        [48761],
        [48247],
        [49038],
        [48846],
        [49050],
        [49126],
        [49151],
        [49142],
        [49193],
        [49252],
        [49237],
        [49183],
        [49238],
        [49262]], device='cuda:0')
[2024-07-24 10:17:05,098][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[35002],
        [41707],
        [43132],
        [42113],
        [41583],
        [41403],
        [41885],
        [41854],
        [41821],
        [41259],
        [40611],
        [40370],
        [40498],
        [40236],
        [39872]], device='cuda:0')
[2024-07-24 10:17:05,100][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19626],
        [23460],
        [22750],
        [22983],
        [23114],
        [22640],
        [22047],
        [21810],
        [21427],
        [21426],
        [21536],
        [21579],
        [21513],
        [21445],
        [21418]], device='cuda:0')
[2024-07-24 10:17:05,101][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12623],
        [11682],
        [13580],
        [12205],
        [12063],
        [12486],
        [12448],
        [12038],
        [12324],
        [12285],
        [12034],
        [12175],
        [12249],
        [12268],
        [11891]], device='cuda:0')
[2024-07-24 10:17:05,103][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14781],
        [12378],
        [47432],
        [18760],
        [41594],
        [40737],
        [33960],
        [25167],
        [22084],
        [19464],
        [17184],
        [23526],
        [31821],
        [27852],
        [22836]], device='cuda:0')
[2024-07-24 10:17:05,104][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4288],
        [17179],
        [ 5836],
        [ 8055],
        [ 8692],
        [ 9472],
        [10960],
        [13427],
        [12750],
        [13818],
        [14095],
        [12559],
        [13483],
        [13790],
        [14006]], device='cuda:0')
[2024-07-24 10:17:05,105][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30024],
        [31435],
        [20274],
        [24821],
        [17818],
        [20213],
        [22293],
        [23392],
        [24972],
        [25592],
        [26060],
        [26903],
        [24176],
        [25263],
        [25924]], device='cuda:0')
[2024-07-24 10:17:05,106][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[30011],
        [35329],
        [33963],
        [36772],
        [38027],
        [39304],
        [39928],
        [40161],
        [40308],
        [40178],
        [39995],
        [39728],
        [39366],
        [39759],
        [39566]], device='cuda:0')
[2024-07-24 10:17:05,107][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14239],
        [15306],
        [15168],
        [42026],
        [24628],
        [33490],
        [36893],
        [26230],
        [18200],
        [39269],
        [39149],
        [17417],
        [23291],
        [27873],
        [34066]], device='cuda:0')
[2024-07-24 10:17:05,108][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[34228],
        [26798],
        [ 9532],
        [ 5777],
        [ 4388],
        [ 9003],
        [ 8567],
        [ 7292],
        [ 8700],
        [ 9918],
        [ 9993],
        [11581],
        [10875],
        [ 9343],
        [ 9432]], device='cuda:0')
[2024-07-24 10:17:05,109][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3713],
        [4464],
        [3653],
        [3666],
        [3575],
        [3611],
        [3584],
        [3506],
        [3647],
        [3512],
        [3401],
        [3532],
        [3437],
        [3566],
        [3601]], device='cuda:0')
[2024-07-24 10:17:05,110][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19498],
        [38469],
        [43915],
        [44311],
        [44140],
        [43700],
        [44019],
        [37294],
        [24936],
        [23516],
        [23611],
        [46331],
        [35044],
        [40531],
        [36308]], device='cuda:0')
[2024-07-24 10:17:05,112][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 4896],
        [27181],
        [ 7700],
        [19090],
        [20571],
        [ 3828],
        [  970],
        [ 4418],
        [ 6617],
        [ 9720],
        [ 5345],
        [ 9849],
        [22591],
        [10041],
        [ 1765]], device='cuda:0')
[2024-07-24 10:17:05,113][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16567],
        [11692],
        [12315],
        [12201],
        [12149],
        [11950],
        [12202],
        [12598],
        [12574],
        [12691],
        [12667],
        [12930],
        [12894],
        [13031],
        [13086]], device='cuda:0')
[2024-07-24 10:17:05,115][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[23306],
        [23860],
        [23779],
        [29921],
        [25443],
        [27807],
        [25682],
        [23112],
        [24355],
        [25460],
        [25768],
        [20569],
        [20424],
        [22907],
        [23752]], device='cuda:0')
[2024-07-24 10:17:05,116][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[30945],
        [30373],
        [35711],
        [34419],
        [35502],
        [34855],
        [34056],
        [33780],
        [34115],
        [33590],
        [33445],
        [33169],
        [33991],
        [33789],
        [33875]], device='cuda:0')
[2024-07-24 10:17:05,117][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11928],
        [12990],
        [12600],
        [13326],
        [12561],
        [12855],
        [12851],
        [13697],
        [13989],
        [14299],
        [14573],
        [14113],
        [13337],
        [13258],
        [13218]], device='cuda:0')
[2024-07-24 10:17:05,119][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[24041],
        [24049],
        [24267],
        [24882],
        [25242],
        [24883],
        [25314],
        [24679],
        [24404],
        [26144],
        [26966],
        [25680],
        [26999],
        [26488],
        [27495]], device='cuda:0')
[2024-07-24 10:17:05,120][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[  754],
        [  799],
        [ 1728],
        [11611],
        [15519],
        [13311],
        [10141],
        [ 8689],
        [ 2176],
        [ 4520],
        [ 2392],
        [ 2157],
        [ 4051],
        [ 3903],
        [ 4263]], device='cuda:0')
[2024-07-24 10:17:05,122][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40461],
        [31144],
        [27146],
        [26361],
        [26032],
        [25753],
        [26000],
        [25772],
        [25552],
        [25341],
        [25177],
        [25316],
        [25431],
        [25344],
        [25323]], device='cuda:0')
[2024-07-24 10:17:05,123][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37964],
        [39999],
        [38497],
        [33879],
        [33831],
        [32767],
        [31264],
        [26543],
        [29734],
        [28658],
        [28889],
        [32564],
        [35444],
        [35010],
        [35053]], device='cuda:0')
[2024-07-24 10:17:05,125][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[45416],
        [22480],
        [46727],
        [35674],
        [41495],
        [38230],
        [46434],
        [41779],
        [34833],
        [34308],
        [34270],
        [29993],
        [34455],
        [34808],
        [36070]], device='cuda:0')
[2024-07-24 10:17:05,126][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26122],
        [30149],
        [27854],
        [27200],
        [25851],
        [25458],
        [25786],
        [26195],
        [25869],
        [25461],
        [25410],
        [25876],
        [25384],
        [25440],
        [25308]], device='cuda:0')
[2024-07-24 10:17:05,128][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15264],
        [15306],
        [15776],
        [16007],
        [16193],
        [16468],
        [16608],
        [16439],
        [16692],
        [17028],
        [17109],
        [17049],
        [16980],
        [16890],
        [16867]], device='cuda:0')
[2024-07-24 10:17:05,129][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6272],
        [14061],
        [15005],
        [17418],
        [20115],
        [18353],
        [12013],
        [14233],
        [20379],
        [20667],
        [20994],
        [18646],
        [19900],
        [19202],
        [18958]], device='cuda:0')
[2024-07-24 10:17:05,131][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35373],
        [35759],
        [29193],
        [27684],
        [26203],
        [27828],
        [29069],
        [31843],
        [32974],
        [31089],
        [32080],
        [34677],
        [31444],
        [31498],
        [30059]], device='cuda:0')
[2024-07-24 10:17:05,131][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40787],
        [17254],
        [29802],
        [16012],
        [12770],
        [23824],
        [33421],
        [23452],
        [26574],
        [19606],
        [22054],
        [20127],
        [ 9176],
        [17970],
        [27795]], device='cuda:0')
[2024-07-24 10:17:05,132][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309],
        [42309]], device='cuda:0')
[2024-07-24 10:17:05,170][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:05,172][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,173][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,174][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,175][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,175][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,176][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,176][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,176][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,177][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,177][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,177][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,178][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,178][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5596, 0.4404], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,178][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0294, 0.9706], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,180][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0987, 0.9013], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,182][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4347, 0.5653], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,184][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7520, 0.2480], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,186][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9939e-01, 6.1223e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,186][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2039, 0.7961], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,186][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9865, 0.0135], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,189][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0900, 0.9100], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,190][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2010, 0.7990], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,192][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0099, 0.9901], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,192][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9639, 0.0361], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,193][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.5352, 0.2933, 0.1714], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,193][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0135, 0.4974, 0.4892], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,193][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.0186, 0.1525, 0.8289], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,194][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.2054, 0.4950, 0.2997], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,194][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.6074, 0.1678, 0.2247], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,194][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([9.9837e-01, 9.5277e-04, 6.7406e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,194][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1027, 0.4295, 0.4679], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,195][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.9277, 0.0251, 0.0472], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,195][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2868, 0.1849, 0.5283], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,195][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1380, 0.4080, 0.4540], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,196][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0173, 0.4446, 0.5381], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,196][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.8110, 0.0438, 0.1452], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,198][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4665, 0.2515, 0.2090, 0.0730], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,200][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0074, 0.3626, 0.3566, 0.2734], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,201][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0133, 0.0760, 0.5457, 0.3650], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,202][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1888, 0.3443, 0.2183, 0.2486], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,203][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4312, 0.1912, 0.2558, 0.1219], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,205][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.9596e-01, 8.4821e-04, 1.7646e-03, 1.4300e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,206][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0743, 0.2946, 0.3202, 0.3108], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,208][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8647, 0.0450, 0.0584, 0.0319], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,209][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([6.2366e-04, 3.4195e-01, 6.5555e-01, 1.8718e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,211][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0459, 0.2990, 0.3982, 0.2570], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,213][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0034, 0.3623, 0.3854, 0.2489], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,214][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6044, 0.1137, 0.1407, 0.1413], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,215][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.5077, 0.1710, 0.1245, 0.0936, 0.1032], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,215][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0037, 0.2402, 0.2415, 0.2376, 0.2770], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,216][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0092, 0.0470, 0.2680, 0.2060, 0.4698], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,216][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.1244, 0.2908, 0.1621, 0.2374, 0.1853], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,216][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.3872, 0.1535, 0.2058, 0.0998, 0.1538], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,217][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([9.9660e-01, 7.0451e-04, 6.9218e-04, 8.7794e-04, 1.1292e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,217][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0518, 0.2240, 0.2431, 0.2362, 0.2450], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,217][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.7338, 0.0457, 0.0923, 0.0711, 0.0571], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,218][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0416, 0.1148, 0.7308, 0.0016, 0.1111], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,218][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0615, 0.2198, 0.2678, 0.1718, 0.2789], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,218][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0064, 0.2792, 0.3128, 0.1954, 0.2063], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,219][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.4304, 0.0729, 0.1283, 0.1618, 0.2066], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,219][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.4608, 0.1609, 0.1142, 0.0743, 0.1176, 0.0721], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,221][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0081, 0.1934, 0.2027, 0.1760, 0.2594, 0.1604], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,223][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0052, 0.0302, 0.1871, 0.1452, 0.3306, 0.3016], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,224][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1471, 0.2290, 0.1382, 0.1807, 0.1481, 0.1569], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,226][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3613, 0.1356, 0.1664, 0.0848, 0.1314, 0.1205], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,226][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9712e-01, 3.6003e-04, 7.1387e-04, 4.4540e-04, 1.1269e-03, 2.3770e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,228][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0452, 0.1795, 0.1949, 0.1880, 0.1976, 0.1948], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,230][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.9369, 0.0141, 0.0197, 0.0110, 0.0123, 0.0060], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,231][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0075, 0.4461, 0.4406, 0.0019, 0.0852, 0.0188], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,233][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0559, 0.1660, 0.2028, 0.1309, 0.2166, 0.2278], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,235][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0043, 0.2204, 0.2348, 0.1516, 0.1544, 0.2344], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,237][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4668, 0.0749, 0.1046, 0.1182, 0.1417, 0.0940], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,238][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4278, 0.1404, 0.0932, 0.0639, 0.0892, 0.0685, 0.1170],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,238][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0107, 0.1406, 0.1866, 0.1508, 0.1975, 0.1362, 0.1777],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,239][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0043, 0.0186, 0.1144, 0.0789, 0.1844, 0.1719, 0.4276],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,239][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1416, 0.2024, 0.1139, 0.1419, 0.1135, 0.1221, 0.1646],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,239][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3300, 0.1131, 0.1451, 0.0714, 0.1140, 0.1104, 0.1159],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,240][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9825e-01, 2.5679e-04, 2.9492e-04, 3.4684e-04, 4.7921e-04, 2.3422e-04,
        1.3380e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,240][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0377, 0.1487, 0.1608, 0.1561, 0.1635, 0.1618, 0.1713],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,240][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.9822, 0.0026, 0.0044, 0.0039, 0.0038, 0.0019, 0.0012],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,241][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0659, 0.1187, 0.4352, 0.0008, 0.0757, 0.0479, 0.2558],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,241][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0378, 0.1277, 0.1631, 0.0975, 0.1667, 0.1908, 0.2165],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,241][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0030, 0.2044, 0.1967, 0.1470, 0.1199, 0.1888, 0.1401],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,242][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.7636, 0.0256, 0.0349, 0.0537, 0.0525, 0.0340, 0.0356],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,242][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.4887, 0.0835, 0.0545, 0.0373, 0.0691, 0.0453, 0.1307, 0.0910],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,244][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0055, 0.1236, 0.1611, 0.1321, 0.1799, 0.1134, 0.1698, 0.1145],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,246][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0036, 0.0154, 0.1250, 0.0665, 0.1798, 0.1420, 0.3022, 0.1654],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,247][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1491, 0.1569, 0.0852, 0.1119, 0.0878, 0.0953, 0.1409, 0.1728],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,248][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.2969, 0.0955, 0.1268, 0.0604, 0.0965, 0.0936, 0.1023, 0.1280],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,249][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.9921e-01, 9.7958e-05, 1.1168e-04, 1.5367e-04, 1.8484e-04, 1.0487e-04,
        7.3657e-05, 6.4711e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,251][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0355, 0.1278, 0.1368, 0.1327, 0.1391, 0.1372, 0.1466, 0.1443],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,253][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.9817, 0.0018, 0.0029, 0.0027, 0.0034, 0.0017, 0.0013, 0.0045],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,254][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([6.6570e-02, 2.6413e-04, 3.7389e-03, 8.2402e-06, 1.0766e-03, 4.7972e-04,
        9.0449e-03, 9.1882e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,255][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0463, 0.0893, 0.1268, 0.0676, 0.1345, 0.1435, 0.1702, 0.2218],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,257][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0037, 0.1478, 0.1525, 0.1182, 0.1063, 0.1717, 0.1269, 0.1731],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,259][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.8310, 0.0107, 0.0278, 0.0293, 0.0333, 0.0252, 0.0289, 0.0138],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,260][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.2397, 0.0997, 0.0647, 0.0530, 0.0838, 0.0526, 0.1528, 0.1743, 0.0793],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,261][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0018, 0.1276, 0.1186, 0.1130, 0.1398, 0.1059, 0.1635, 0.1029, 0.1269],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,261][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0039, 0.0148, 0.1092, 0.0559, 0.1512, 0.1212, 0.2726, 0.1478, 0.1233],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,262][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0815, 0.1404, 0.0759, 0.1055, 0.0777, 0.0820, 0.1356, 0.1790, 0.1223],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,262][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.2271, 0.0861, 0.1107, 0.0534, 0.0833, 0.0820, 0.0885, 0.1154, 0.1535],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,262][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.9927e-01, 7.6427e-05, 7.0946e-05, 1.2348e-04, 1.4016e-04, 7.7108e-05,
        5.1611e-05, 5.4365e-05, 1.3926e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,263][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0268, 0.1105, 0.1202, 0.1179, 0.1233, 0.1216, 0.1302, 0.1291, 0.1204],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,263][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.9617, 0.0014, 0.0027, 0.0038, 0.0050, 0.0019, 0.0021, 0.0082, 0.0132],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,263][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([9.8460e-03, 4.1117e-05, 4.4041e-04, 6.1791e-07, 9.3174e-05, 6.4568e-05,
        9.0504e-04, 2.8839e-01, 7.0022e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,264][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0294, 0.0665, 0.0930, 0.0476, 0.0943, 0.1112, 0.1341, 0.1751, 0.2487],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,264][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0049, 0.1360, 0.1359, 0.0963, 0.0965, 0.1359, 0.1191, 0.1456, 0.1299],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,264][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.6980, 0.0166, 0.0421, 0.0469, 0.0614, 0.0407, 0.0441, 0.0253, 0.0248],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,265][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1198, 0.0852, 0.0892, 0.0357, 0.0905, 0.0635, 0.1387, 0.1757, 0.1404,
        0.0612], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,267][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0027, 0.1112, 0.1164, 0.1001, 0.1321, 0.0925, 0.1391, 0.0985, 0.1059,
        0.1014], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,268][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.0142, 0.1005, 0.0563, 0.1372, 0.1102, 0.2586, 0.1448, 0.1231,
        0.0522], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,270][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0719, 0.1122, 0.0689, 0.0840, 0.0803, 0.0721, 0.1136, 0.1606, 0.1170,
        0.1193], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,271][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1760, 0.0790, 0.1052, 0.0504, 0.0795, 0.0742, 0.0821, 0.1104, 0.1460,
        0.0972], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,272][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9254e-01, 5.3918e-04, 6.6501e-04, 7.8504e-04, 1.1218e-03, 5.2440e-04,
        4.0928e-04, 5.5580e-04, 1.1727e-03, 1.6825e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,274][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0233, 0.0987, 0.1079, 0.1055, 0.1101, 0.1090, 0.1161, 0.1156, 0.1072,
        0.1066], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,276][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7471, 0.0149, 0.0342, 0.0283, 0.0216, 0.0165, 0.0130, 0.0338, 0.0450,
        0.0457], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,277][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([3.3427e-05, 3.2424e-05, 1.6238e-04, 3.0115e-07, 4.1903e-05, 1.3226e-05,
        3.5192e-04, 2.8929e-01, 7.0808e-01, 1.9962e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,278][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0132, 0.0559, 0.0841, 0.0423, 0.0920, 0.0866, 0.1146, 0.1726, 0.2546,
        0.0841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,280][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0017, 0.1114, 0.1343, 0.0805, 0.0832, 0.1252, 0.0950, 0.1303, 0.1104,
        0.1278], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,282][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.5201, 0.0378, 0.0729, 0.0777, 0.0741, 0.0562, 0.0588, 0.0312, 0.0261,
        0.0453], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,283][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1390, 0.0898, 0.0795, 0.0267, 0.0801, 0.0614, 0.1334, 0.1602, 0.1235,
        0.0605, 0.0458], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,284][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0020, 0.1098, 0.1094, 0.0860, 0.1283, 0.0825, 0.1175, 0.0804, 0.0916,
        0.0893, 0.1033], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,284][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0033, 0.0132, 0.0805, 0.0504, 0.1190, 0.0906, 0.2208, 0.1415, 0.1129,
        0.0495, 0.1183], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,285][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0522, 0.0990, 0.0604, 0.0747, 0.0674, 0.0627, 0.1014, 0.1483, 0.1061,
        0.1062, 0.1217], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,285][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1626, 0.0717, 0.0963, 0.0452, 0.0722, 0.0677, 0.0761, 0.1004, 0.1327,
        0.0883, 0.0868], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,285][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.8935e-01, 5.9708e-04, 7.5826e-04, 8.8799e-04, 1.1610e-03, 6.1905e-04,
        5.1385e-04, 6.2810e-04, 1.3415e-03, 1.8475e-03, 2.2976e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,286][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0209, 0.0893, 0.0980, 0.0953, 0.0992, 0.0988, 0.1048, 0.1045, 0.0973,
        0.0963, 0.0955], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,286][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.7249, 0.0222, 0.0243, 0.0230, 0.0145, 0.0093, 0.0105, 0.0297, 0.0373,
        0.0488, 0.0555], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,286][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([3.2068e-05, 3.0938e-05, 1.2083e-04, 1.4904e-07, 2.6636e-05, 1.2139e-05,
        3.7740e-04, 1.8959e-01, 8.0490e-01, 1.7217e-03, 3.1885e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,287][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0116, 0.0507, 0.0789, 0.0378, 0.0862, 0.0772, 0.1019, 0.1631, 0.2396,
        0.0758, 0.0772], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,287][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0010, 0.1028, 0.1152, 0.0721, 0.0701, 0.1075, 0.0861, 0.1202, 0.0978,
        0.1190, 0.1080], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,287][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4610, 0.0452, 0.0752, 0.0708, 0.0812, 0.0558, 0.0639, 0.0333, 0.0254,
        0.0434, 0.0449], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,289][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2051, 0.0731, 0.0528, 0.0353, 0.0677, 0.0512, 0.1353, 0.1139, 0.0659,
        0.0520, 0.0604, 0.0873], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,291][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0024, 0.0934, 0.0906, 0.0814, 0.0927, 0.0734, 0.1028, 0.0749, 0.0846,
        0.0864, 0.0996, 0.1177], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,292][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0018, 0.0105, 0.0929, 0.0442, 0.1306, 0.1070, 0.2333, 0.1221, 0.0999,
        0.0347, 0.0868, 0.0361], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,294][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0465, 0.0936, 0.0547, 0.0747, 0.0579, 0.0549, 0.0962, 0.1034, 0.0814,
        0.1025, 0.1216, 0.1125], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,295][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.1835, 0.0598, 0.0799, 0.0398, 0.0637, 0.0609, 0.0670, 0.0820, 0.1102,
        0.0735, 0.0727, 0.1069], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,296][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.9765e-01, 7.4483e-05, 9.8542e-05, 1.4482e-04, 1.8400e-04, 9.2831e-05,
        6.5984e-05, 5.9065e-05, 1.6832e-04, 3.5236e-04, 3.7106e-04, 7.3740e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,298][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0211, 0.0818, 0.0888, 0.0865, 0.0900, 0.0898, 0.0955, 0.0946, 0.0891,
        0.0879, 0.0872, 0.0878], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,299][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([9.8520e-01, 1.2251e-03, 1.5504e-03, 1.7273e-03, 1.5311e-03, 4.9319e-04,
        5.5764e-04, 1.0867e-03, 8.7983e-04, 2.0514e-03, 2.3210e-03, 1.3766e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,300][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([4.6646e-03, 1.7929e-06, 2.4404e-05, 7.7653e-08, 6.9573e-06, 4.8848e-06,
        9.1479e-05, 1.4996e-02, 4.9582e-02, 2.0478e-04, 3.2807e-04, 9.3009e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,302][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0247, 0.0485, 0.0706, 0.0346, 0.0739, 0.0793, 0.0894, 0.1213, 0.1761,
        0.0595, 0.0593, 0.1629], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,304][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0015, 0.0976, 0.1255, 0.0689, 0.0741, 0.0996, 0.0714, 0.0982, 0.0902,
        0.1001, 0.0942, 0.0788], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,305][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.5161, 0.0203, 0.0824, 0.0573, 0.1059, 0.0571, 0.0356, 0.0164, 0.0175,
        0.0365, 0.0371, 0.0177], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,306][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.2810, 0.0607, 0.0417, 0.0353, 0.0356, 0.0359, 0.0987, 0.0958, 0.0613,
        0.0428, 0.0623, 0.0792, 0.0695], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,307][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0010, 0.0788, 0.0808, 0.0748, 0.0812, 0.0686, 0.0929, 0.0684, 0.0800,
        0.0775, 0.0864, 0.1086, 0.1010], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,307][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0028, 0.0131, 0.0779, 0.0472, 0.1112, 0.0945, 0.1961, 0.1180, 0.0943,
        0.0381, 0.0878, 0.0378, 0.0812], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,308][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0439, 0.0819, 0.0441, 0.0658, 0.0510, 0.0521, 0.0914, 0.1124, 0.0868,
        0.0920, 0.1115, 0.0952, 0.0719], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,308][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1783, 0.0536, 0.0726, 0.0343, 0.0556, 0.0539, 0.0585, 0.0716, 0.0988,
        0.0646, 0.0639, 0.0976, 0.0969], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,308][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([9.9064e-01, 3.2406e-04, 2.2980e-04, 3.2486e-04, 4.2825e-04, 3.0806e-04,
        1.4097e-04, 2.1917e-04, 8.1868e-04, 9.0724e-04, 9.7834e-04, 2.6349e-03,
        2.0472e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,309][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0184, 0.0755, 0.0816, 0.0791, 0.0823, 0.0822, 0.0873, 0.0866, 0.0816,
        0.0805, 0.0800, 0.0807, 0.0841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,309][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.7904, 0.0081, 0.0200, 0.0206, 0.0175, 0.0130, 0.0127, 0.0240, 0.0252,
        0.0194, 0.0197, 0.0138, 0.0156], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,309][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([3.9211e-03, 6.2151e-07, 1.1677e-05, 1.3903e-08, 2.5497e-06, 2.6476e-06,
        1.8251e-05, 4.1122e-03, 2.0832e-02, 2.8685e-05, 5.4951e-05, 5.5308e-01,
        4.1794e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,310][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0198, 0.0402, 0.0600, 0.0276, 0.0593, 0.0703, 0.0802, 0.1022, 0.1606,
        0.0524, 0.0524, 0.1515, 0.1233], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,311][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0012, 0.0878, 0.0996, 0.0632, 0.0645, 0.1032, 0.0691, 0.0943, 0.0783,
        0.0979, 0.0866, 0.0772, 0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,312][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.4439, 0.0253, 0.0701, 0.0669, 0.1120, 0.0845, 0.0546, 0.0210, 0.0147,
        0.0316, 0.0248, 0.0201, 0.0305], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,314][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1343, 0.0685, 0.0482, 0.0318, 0.0591, 0.0376, 0.0816, 0.0984, 0.0569,
        0.0520, 0.0593, 0.0868, 0.1413, 0.0441], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,316][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0018, 0.0733, 0.0750, 0.0648, 0.0825, 0.0642, 0.0934, 0.0577, 0.0731,
        0.0689, 0.0774, 0.0761, 0.0977, 0.0941], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,317][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0024, 0.0109, 0.0618, 0.0389, 0.0954, 0.0764, 0.1727, 0.1090, 0.0840,
        0.0339, 0.0745, 0.0321, 0.0657, 0.1424], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,319][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0468, 0.0767, 0.0408, 0.0576, 0.0461, 0.0469, 0.0730, 0.1058, 0.0790,
        0.0798, 0.0990, 0.0915, 0.0676, 0.0894], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,321][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.1800, 0.0490, 0.0651, 0.0310, 0.0510, 0.0495, 0.0528, 0.0672, 0.0916,
        0.0601, 0.0585, 0.0856, 0.0881, 0.0704], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,322][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.9414e-01, 2.0223e-04, 1.9396e-04, 2.8720e-04, 3.4030e-04, 1.3031e-04,
        9.2697e-05, 1.0574e-04, 2.8068e-04, 6.1284e-04, 7.0081e-04, 1.3523e-03,
        1.2024e-03, 3.5810e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,323][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0172, 0.0692, 0.0759, 0.0732, 0.0769, 0.0758, 0.0805, 0.0802, 0.0751,
        0.0744, 0.0735, 0.0742, 0.0779, 0.0758], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,325][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.9530, 0.0018, 0.0035, 0.0030, 0.0035, 0.0021, 0.0014, 0.0047, 0.0046,
        0.0061, 0.0052, 0.0049, 0.0031, 0.0030], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,326][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([7.3563e-04, 4.6601e-06, 2.0341e-05, 5.3027e-08, 4.1678e-06, 5.2425e-06,
        3.9427e-05, 6.3099e-03, 3.0480e-02, 1.2172e-04, 1.5315e-04, 7.2598e-01,
        2.1748e-01, 1.8670e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,328][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0159, 0.0371, 0.0534, 0.0258, 0.0541, 0.0602, 0.0692, 0.0932, 0.1350,
        0.0461, 0.0457, 0.1319, 0.1086, 0.1238], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,329][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0023, 0.0849, 0.0861, 0.0578, 0.0554, 0.0810, 0.0628, 0.0813, 0.0709,
        0.0956, 0.0853, 0.0741, 0.0682, 0.0944], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,330][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.8242, 0.0106, 0.0218, 0.0204, 0.0251, 0.0184, 0.0153, 0.0072, 0.0046,
        0.0120, 0.0104, 0.0075, 0.0107, 0.0118], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,330][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1631, 0.0586, 0.0507, 0.0253, 0.0536, 0.0395, 0.0816, 0.0958, 0.0626,
        0.0386, 0.0380, 0.0843, 0.1059, 0.0501, 0.0523], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,330][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0021, 0.0683, 0.0715, 0.0592, 0.0800, 0.0551, 0.0815, 0.0503, 0.0678,
        0.0631, 0.0741, 0.0852, 0.0993, 0.0782, 0.0642], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,331][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0017, 0.0089, 0.0547, 0.0357, 0.0850, 0.0721, 0.1568, 0.0923, 0.0697,
        0.0306, 0.0714, 0.0298, 0.0601, 0.1282, 0.1028], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,331][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0504, 0.0749, 0.0427, 0.0581, 0.0477, 0.0443, 0.0731, 0.0831, 0.0666,
        0.0745, 0.0867, 0.0832, 0.0631, 0.0731, 0.0784], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,332][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1398, 0.0485, 0.0636, 0.0319, 0.0503, 0.0487, 0.0522, 0.0635, 0.0882,
        0.0585, 0.0574, 0.0804, 0.0843, 0.0688, 0.0636], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,332][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([9.9669e-01, 1.4556e-04, 1.0160e-04, 1.9197e-04, 1.8415e-04, 9.1924e-05,
        4.2752e-05, 4.7897e-05, 1.6364e-04, 3.3760e-04, 4.0571e-04, 5.8152e-04,
        5.2455e-04, 2.2787e-04, 2.6055e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,332][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0153, 0.0646, 0.0708, 0.0683, 0.0713, 0.0706, 0.0750, 0.0747, 0.0697,
        0.0690, 0.0684, 0.0691, 0.0726, 0.0705, 0.0701], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,333][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.9601, 0.0019, 0.0043, 0.0034, 0.0037, 0.0013, 0.0010, 0.0023, 0.0027,
        0.0052, 0.0046, 0.0024, 0.0027, 0.0022, 0.0022], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,334][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.4153e-04, 3.5224e-06, 3.3227e-05, 4.2956e-08, 9.1667e-06, 6.2493e-06,
        3.9216e-05, 2.5376e-03, 3.0717e-02, 9.8539e-05, 1.0108e-04, 4.8034e-01,
        4.4168e-01, 2.9612e-02, 1.3888e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,335][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0138, 0.0359, 0.0539, 0.0253, 0.0519, 0.0567, 0.0588, 0.0850, 0.1230,
        0.0409, 0.0399, 0.1105, 0.0953, 0.1090, 0.1001], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,337][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0009, 0.0746, 0.0840, 0.0540, 0.0540, 0.0826, 0.0593, 0.0826, 0.0725,
        0.0856, 0.0760, 0.0627, 0.0670, 0.0866, 0.0575], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,339][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.5707, 0.0215, 0.0468, 0.0487, 0.0516, 0.0370, 0.0421, 0.0193, 0.0158,
        0.0257, 0.0261, 0.0166, 0.0177, 0.0258, 0.0345], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,360][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:05,362][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,363][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,364][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,365][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,365][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,366][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,366][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,366][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,367][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,367][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,367][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,368][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,368][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0490, 0.9510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,368][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9973, 0.0027], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,369][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0441, 0.9559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,370][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0991, 0.9009], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,372][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0806, 0.9194], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,373][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6127, 0.3873], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,375][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.4231, 0.5769], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,377][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3813, 0.6187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,378][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7058, 0.2942], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,380][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5488, 0.4512], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,380][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0093, 0.9907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,380][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9944, 0.0056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,381][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0172, 0.5322, 0.4506], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,381][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([9.9886e-01, 7.7599e-04, 3.6294e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,381][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0073, 0.8242, 0.1685], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,381][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0198, 0.7423, 0.2380], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,382][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0363, 0.5685, 0.3952], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,382][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.7653, 0.1329, 0.1018], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,382][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.3004, 0.3621, 0.3374], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,382][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.2525, 0.3913, 0.3562], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,383][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.7768, 0.0616, 0.1616], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,383][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1396, 0.5987, 0.2617], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,383][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0273, 0.2919, 0.6808], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,384][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.9478, 0.0058, 0.0464], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,384][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0222, 0.3737, 0.4291, 0.1751], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,385][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9817e-01, 1.1287e-03, 5.5013e-04, 1.4985e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,387][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0068, 0.4318, 0.1849, 0.3765], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,388][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0236, 0.6359, 0.2360, 0.1045], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,390][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0249, 0.3791, 0.2779, 0.3181], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,391][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4753, 0.1921, 0.1814, 0.1512], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,393][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1997, 0.2767, 0.2645, 0.2591], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,394][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2088, 0.2914, 0.2664, 0.2333], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,396][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0547, 0.2493, 0.6562, 0.0398], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,397][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1279, 0.3830, 0.4218, 0.0673], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,399][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0014, 0.3656, 0.5053, 0.1277], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,401][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8070, 0.0428, 0.0638, 0.0864], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,402][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0149, 0.2590, 0.2557, 0.1693, 0.3011], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,403][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([9.9961e-01, 3.2341e-04, 4.2569e-05, 1.7438e-05, 3.3466e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,403][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0133, 0.3436, 0.0999, 0.3627, 0.1805], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,404][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0213, 0.5550, 0.2078, 0.0842, 0.1317], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,404][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0189, 0.3301, 0.2261, 0.2613, 0.1637], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,404][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.6496, 0.1134, 0.0879, 0.0736, 0.0755], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,405][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.1633, 0.2204, 0.2052, 0.1989, 0.2122], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,405][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.1532, 0.2435, 0.2213, 0.1942, 0.1878], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,405][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.4107, 0.0754, 0.3275, 0.0169, 0.1695], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,405][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0944, 0.3550, 0.1647, 0.2148, 0.1711], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,406][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0027, 0.2548, 0.4488, 0.1039, 0.1899], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,406][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.5785, 0.0260, 0.0816, 0.1279, 0.1860], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,406][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0091, 0.1971, 0.1870, 0.1205, 0.2752, 0.2112], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,407][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([9.9820e-01, 7.0173e-04, 2.0537e-04, 1.6838e-04, 5.1207e-05, 6.7315e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,407][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0018, 0.1454, 0.0572, 0.1519, 0.0710, 0.5728], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,409][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0130, 0.5251, 0.1711, 0.0804, 0.1185, 0.0919], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,410][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0160, 0.2508, 0.1779, 0.2034, 0.1332, 0.2186], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,412][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.5166, 0.1107, 0.1119, 0.0730, 0.0916, 0.0962], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,413][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1306, 0.1855, 0.1655, 0.1719, 0.1765, 0.1700], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,414][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1457, 0.1990, 0.1840, 0.1588, 0.1525, 0.1599], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,416][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2203, 0.2166, 0.3292, 0.0277, 0.1633, 0.0429], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,417][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1481, 0.2301, 0.1586, 0.1115, 0.2290, 0.1226], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,419][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0074, 0.2838, 0.3779, 0.1023, 0.1530, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,420][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.6678, 0.0276, 0.0608, 0.0901, 0.1048, 0.0489], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,423][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0082, 0.1652, 0.1408, 0.1038, 0.2043, 0.1824, 0.1953],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,423][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9760e-01, 1.3888e-03, 1.5317e-04, 1.2290e-04, 2.6688e-05, 6.6788e-04,
        4.1181e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,425][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0008, 0.1277, 0.0688, 0.0673, 0.0744, 0.3620, 0.2990],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,426][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0175, 0.4467, 0.1603, 0.0685, 0.1102, 0.0985, 0.0984],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,426][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0136, 0.2101, 0.1533, 0.1693, 0.1140, 0.1817, 0.1579],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,427][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4074, 0.1240, 0.1109, 0.0825, 0.0875, 0.1134, 0.0743],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,427][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1105, 0.1596, 0.1428, 0.1457, 0.1500, 0.1478, 0.1436],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,427][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1322, 0.1704, 0.1531, 0.1341, 0.1284, 0.1389, 0.1430],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,428][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.5843, 0.0542, 0.1446, 0.0069, 0.0769, 0.0327, 0.1004],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,428][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1304, 0.1587, 0.1140, 0.0655, 0.1482, 0.2054, 0.1777],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,428][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0043, 0.3201, 0.2989, 0.1531, 0.0838, 0.0456, 0.0943],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,428][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.9356, 0.0032, 0.0080, 0.0205, 0.0170, 0.0078, 0.0079],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,429][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0060, 0.1437, 0.1080, 0.0707, 0.1848, 0.1807, 0.2267, 0.0795],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,429][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([9.9783e-01, 1.0061e-03, 1.3458e-04, 1.9874e-04, 2.3655e-05, 4.9823e-04,
        5.6759e-05, 2.5671e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,429][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0045, 0.1761, 0.0878, 0.0396, 0.0378, 0.1958, 0.1592, 0.2991],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,430][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0523, 0.3222, 0.1175, 0.0460, 0.0746, 0.0647, 0.0700, 0.2527],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,430][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0126, 0.1844, 0.1306, 0.1485, 0.0974, 0.1592, 0.1391, 0.1281],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,432][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.5892, 0.0823, 0.0658, 0.0501, 0.0527, 0.0694, 0.0452, 0.0454],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,434][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1009, 0.1363, 0.1256, 0.1234, 0.1341, 0.1252, 0.1255, 0.1289],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,435][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1145, 0.1445, 0.1301, 0.1160, 0.1160, 0.1230, 0.1271, 0.1287],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,436][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.4298, 0.0039, 0.0131, 0.0007, 0.0095, 0.0044, 0.0301, 0.5085],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,438][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1281, 0.0757, 0.0769, 0.0334, 0.1592, 0.0970, 0.1989, 0.2307],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,440][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0129, 0.1133, 0.1895, 0.1285, 0.1372, 0.0932, 0.1526, 0.1728],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,441][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.9653, 0.0011, 0.0058, 0.0074, 0.0090, 0.0044, 0.0047, 0.0022],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,442][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0031, 0.1285, 0.1002, 0.0695, 0.1608, 0.1533, 0.1973, 0.0922, 0.0949],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,443][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([9.9756e-01, 1.1546e-03, 4.7705e-05, 1.9503e-04, 1.8550e-05, 5.6245e-04,
        1.0289e-04, 2.9085e-04, 7.1581e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,446][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0073, 0.3319, 0.0470, 0.0415, 0.0312, 0.1540, 0.1084, 0.2043, 0.0743],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,447][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0352, 0.2187, 0.0873, 0.0358, 0.0496, 0.0438, 0.0508, 0.2101, 0.2686],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,448][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0110, 0.1671, 0.1170, 0.1333, 0.0868, 0.1442, 0.1250, 0.1159, 0.0997],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,449][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.7422, 0.0485, 0.0359, 0.0295, 0.0266, 0.0425, 0.0269, 0.0232, 0.0247],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,449][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0929, 0.1188, 0.1102, 0.1137, 0.1171, 0.1133, 0.1122, 0.1179, 0.1041],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,450][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0937, 0.1264, 0.1171, 0.1049, 0.1055, 0.1085, 0.1128, 0.1153, 0.1159],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,450][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.4420e-01, 1.2041e-03, 4.4910e-03, 2.4743e-04, 3.1211e-03, 2.3061e-03,
        1.1133e-02, 2.9748e-01, 5.3581e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,450][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0400, 0.0939, 0.0479, 0.0387, 0.0908, 0.0829, 0.1554, 0.3008, 0.1496],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,451][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0127, 0.1616, 0.1736, 0.0682, 0.1194, 0.0289, 0.2256, 0.1074, 0.1026],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,451][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.9015, 0.0027, 0.0117, 0.0211, 0.0248, 0.0112, 0.0132, 0.0070, 0.0067],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,451][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0053, 0.0920, 0.1012, 0.0495, 0.1489, 0.1251, 0.1692, 0.0834, 0.1053,
        0.1199], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,452][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9959e-01, 1.2120e-04, 4.4880e-05, 2.3711e-05, 7.6453e-06, 1.1646e-04,
        1.3390e-05, 5.9538e-05, 2.3024e-05, 4.2960e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,452][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0015, 0.2019, 0.1003, 0.0763, 0.0612, 0.2050, 0.1073, 0.1418, 0.0584,
        0.0463], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,452][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0161, 0.1527, 0.0774, 0.0290, 0.0479, 0.0369, 0.0462, 0.2235, 0.2959,
        0.0744], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,453][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0095, 0.1480, 0.1064, 0.1211, 0.0784, 0.1294, 0.1137, 0.1037, 0.0894,
        0.1004], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,453][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2486, 0.0921, 0.0860, 0.0660, 0.0780, 0.0969, 0.0666, 0.0863, 0.0966,
        0.0828], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,455][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0753, 0.1072, 0.1015, 0.1004, 0.1071, 0.1032, 0.1030, 0.1059, 0.0950,
        0.1014], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,457][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0777, 0.1160, 0.1076, 0.0952, 0.0930, 0.0998, 0.1019, 0.1027, 0.1034,
        0.1026], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,458][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([5.1894e-03, 6.0428e-04, 2.0348e-03, 8.7599e-05, 1.5301e-03, 6.4482e-04,
        5.0655e-03, 3.8147e-01, 5.6831e-01, 3.5067e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,459][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0473, 0.0515, 0.0647, 0.0198, 0.1183, 0.0583, 0.1297, 0.1864, 0.2723,
        0.0518], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,460][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0009, 0.0705, 0.2782, 0.0450, 0.0930, 0.0399, 0.1332, 0.1552, 0.1168,
        0.0672], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,462][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7066, 0.0128, 0.0474, 0.0597, 0.0632, 0.0290, 0.0299, 0.0149, 0.0115,
        0.0251], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,463][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0043, 0.0956, 0.0850, 0.0392, 0.1262, 0.1281, 0.1649, 0.0771, 0.0936,
        0.1236, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,464][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9894e-01, 3.0517e-04, 1.1458e-04, 4.2794e-05, 2.1848e-05, 3.1770e-04,
        3.4378e-05, 1.3249e-04, 5.9133e-05, 1.5888e-05, 1.9051e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,466][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0020, 0.2441, 0.1167, 0.0703, 0.0635, 0.1495, 0.0943, 0.1304, 0.0653,
        0.0452, 0.0186], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,468][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0224, 0.1348, 0.0722, 0.0280, 0.0443, 0.0372, 0.0455, 0.2131, 0.2544,
        0.0639, 0.0841], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,470][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0090, 0.1311, 0.0964, 0.1076, 0.0713, 0.1142, 0.1014, 0.0928, 0.0806,
        0.0897, 0.1060], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,471][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1586, 0.0894, 0.0804, 0.0658, 0.0725, 0.0963, 0.0683, 0.0889, 0.0996,
        0.0835, 0.0966], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,472][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0709, 0.0964, 0.0917, 0.0904, 0.0962, 0.0941, 0.0931, 0.0968, 0.0867,
        0.0922, 0.0916], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,472][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0732, 0.1068, 0.0972, 0.0861, 0.0834, 0.0887, 0.0921, 0.0932, 0.0939,
        0.0937, 0.0917], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,473][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.1262e-02, 6.4310e-04, 2.0700e-03, 6.4572e-05, 1.2817e-03, 6.4918e-04,
        5.2543e-03, 2.9452e-01, 5.9493e-01, 3.0229e-02, 5.9094e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,473][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0335, 0.0611, 0.0798, 0.0124, 0.1490, 0.0642, 0.0944, 0.1793, 0.2387,
        0.0530, 0.0347], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,473][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0003, 0.0952, 0.2296, 0.0389, 0.0669, 0.0285, 0.1275, 0.1730, 0.1048,
        0.0688, 0.0666], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,474][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.7062, 0.0179, 0.0394, 0.0529, 0.0539, 0.0229, 0.0302, 0.0127, 0.0089,
        0.0256, 0.0294], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,474][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0018, 0.0855, 0.0715, 0.0414, 0.1188, 0.1224, 0.1576, 0.0621, 0.0755,
        0.1233, 0.0728, 0.0673], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,474][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([9.9830e-01, 7.7753e-04, 5.9354e-05, 6.2018e-05, 1.3673e-05, 3.5226e-04,
        6.0755e-05, 2.0072e-04, 3.3292e-05, 1.5340e-05, 2.3077e-05, 1.0136e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,475][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0012, 0.1240, 0.0172, 0.0596, 0.0248, 0.1458, 0.1053, 0.1607, 0.0603,
        0.0881, 0.0639, 0.1491], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,475][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0676, 0.0660, 0.0571, 0.0194, 0.0351, 0.0283, 0.0311, 0.1313, 0.1331,
        0.0323, 0.0411, 0.3577], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,475][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0077, 0.1269, 0.0875, 0.1031, 0.0646, 0.1100, 0.0950, 0.0863, 0.0735,
        0.0832, 0.0994, 0.0629], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,476][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.3961, 0.0719, 0.0576, 0.0477, 0.0504, 0.0668, 0.0444, 0.0431, 0.0507,
        0.0567, 0.0636, 0.0509], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,477][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0699, 0.0870, 0.0814, 0.0837, 0.0860, 0.0833, 0.0847, 0.0874, 0.0795,
        0.0839, 0.0845, 0.0887], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,479][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0872, 0.0983, 0.0876, 0.0763, 0.0756, 0.0801, 0.0847, 0.0818, 0.0828,
        0.0820, 0.0805, 0.0831], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,480][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([3.3050e-01, 4.4937e-04, 1.6128e-03, 1.2164e-04, 1.3105e-03, 7.5100e-04,
        5.3649e-03, 9.3046e-02, 2.6702e-01, 1.5404e-02, 3.0308e-02, 2.5411e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,481][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0174, 0.0601, 0.0282, 0.0331, 0.0448, 0.0781, 0.1489, 0.1714, 0.1254,
        0.0867, 0.0991, 0.1068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,483][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0082, 0.0657, 0.4521, 0.0408, 0.0968, 0.0185, 0.0381, 0.0586, 0.0615,
        0.0403, 0.0492, 0.0702], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,484][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.9155, 0.0016, 0.0109, 0.0144, 0.0211, 0.0091, 0.0050, 0.0020, 0.0022,
        0.0080, 0.0082, 0.0018], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,486][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0030, 0.0848, 0.0709, 0.0482, 0.0874, 0.1064, 0.1362, 0.0623, 0.0698,
        0.1071, 0.0696, 0.0645, 0.0898], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,487][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([9.9936e-01, 2.3559e-04, 3.4543e-05, 1.6233e-05, 3.2696e-06, 1.5978e-04,
        1.8241e-05, 5.8834e-05, 3.2649e-05, 6.1488e-06, 1.0542e-05, 6.1889e-05,
        4.3934e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,489][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0108, 0.2317, 0.0495, 0.0871, 0.0494, 0.1342, 0.0683, 0.1174, 0.0378,
        0.0604, 0.0436, 0.0865, 0.0232], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,490][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0257, 0.0743, 0.0423, 0.0166, 0.0261, 0.0228, 0.0248, 0.0904, 0.1196,
        0.0299, 0.0424, 0.3030, 0.1821], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,492][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0074, 0.1228, 0.0836, 0.0964, 0.0603, 0.1038, 0.0888, 0.0824, 0.0698,
        0.0781, 0.0933, 0.0601, 0.0531], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,494][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.4467, 0.0687, 0.0463, 0.0381, 0.0388, 0.0602, 0.0322, 0.0340, 0.0473,
        0.0459, 0.0526, 0.0433, 0.0460], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,495][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0627, 0.0830, 0.0765, 0.0754, 0.0796, 0.0777, 0.0749, 0.0806, 0.0719,
        0.0765, 0.0762, 0.0839, 0.0811], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,495][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.0687, 0.0906, 0.0837, 0.0729, 0.0720, 0.0766, 0.0793, 0.0785, 0.0796,
        0.0765, 0.0743, 0.0769, 0.0706], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,496][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([2.2252e-01, 1.2862e-04, 6.0403e-04, 2.1749e-05, 4.7652e-04, 2.2148e-04,
        1.0604e-03, 1.8440e-02, 1.0853e-01, 2.9853e-03, 6.3707e-03, 1.0064e-01,
        5.3800e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,496][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.0269, 0.0500, 0.0246, 0.0341, 0.0265, 0.0419, 0.1536, 0.1698, 0.1232,
        0.0776, 0.1064, 0.0768, 0.0885], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,497][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.0006, 0.0728, 0.2259, 0.0408, 0.0915, 0.0583, 0.0650, 0.0756, 0.0437,
        0.0475, 0.0367, 0.1102, 0.1315], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,497][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.7715, 0.0046, 0.0298, 0.0349, 0.0692, 0.0369, 0.0182, 0.0061, 0.0034,
        0.0087, 0.0071, 0.0027, 0.0068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,497][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0018, 0.0778, 0.0618, 0.0405, 0.1017, 0.0915, 0.1064, 0.0542, 0.0629,
        0.1131, 0.0676, 0.0608, 0.1160, 0.0439], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,498][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.9887e-01, 4.6598e-04, 6.3189e-05, 5.1610e-05, 1.3749e-05, 2.1699e-04,
        4.1930e-05, 8.1603e-05, 5.0255e-05, 1.3978e-05, 2.4820e-05, 2.2895e-05,
        1.4859e-05, 6.4086e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,498][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0031, 0.2629, 0.0370, 0.0528, 0.0347, 0.1631, 0.0790, 0.1616, 0.0450,
        0.0298, 0.0182, 0.0784, 0.0152, 0.0192], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,498][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0088, 0.0873, 0.0312, 0.0136, 0.0191, 0.0175, 0.0202, 0.0783, 0.1171,
        0.0340, 0.0446, 0.3036, 0.1520, 0.0726], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,499][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0069, 0.1131, 0.0777, 0.0893, 0.0574, 0.0962, 0.0831, 0.0764, 0.0655,
        0.0737, 0.0874, 0.0564, 0.0511, 0.0658], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,499][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.5958, 0.0465, 0.0334, 0.0267, 0.0265, 0.0355, 0.0243, 0.0266, 0.0286,
        0.0306, 0.0362, 0.0320, 0.0297, 0.0277], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,501][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0554, 0.0769, 0.0660, 0.0731, 0.0721, 0.0719, 0.0711, 0.0748, 0.0672,
        0.0736, 0.0744, 0.0769, 0.0745, 0.0720], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,503][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0795, 0.0824, 0.0761, 0.0664, 0.0658, 0.0692, 0.0717, 0.0725, 0.0731,
        0.0713, 0.0691, 0.0725, 0.0650, 0.0656], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,504][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([4.9041e-02, 3.8924e-04, 1.0215e-03, 6.3219e-05, 6.0052e-04, 6.4533e-04,
        2.4737e-03, 5.6959e-02, 1.7005e-01, 8.6476e-03, 1.3318e-02, 2.0663e-01,
        4.2119e-01, 6.8970e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,505][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0330, 0.0253, 0.0287, 0.0154, 0.0521, 0.0275, 0.0817, 0.1199, 0.1328,
        0.0425, 0.0513, 0.0783, 0.1724, 0.1392], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,506][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0033, 0.1199, 0.1444, 0.0454, 0.0556, 0.0215, 0.0675, 0.0527, 0.0413,
        0.0797, 0.0652, 0.1625, 0.1004, 0.0406], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,507][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.4539e-01, 1.9025e-03, 6.6747e-03, 9.0947e-03, 1.1011e-02, 4.9143e-03,
        4.0774e-03, 1.5247e-03, 9.3474e-04, 3.9299e-03, 3.3902e-03, 1.3811e-03,
        2.7704e-03, 3.0074e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,509][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0023, 0.0687, 0.0634, 0.0372, 0.0963, 0.0921, 0.1135, 0.0579, 0.0679,
        0.0887, 0.0553, 0.0610, 0.0989, 0.0473, 0.0495], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,510][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9420e-01, 1.8270e-03, 4.2694e-04, 4.5351e-04, 9.7601e-05, 7.4169e-04,
        1.5326e-04, 5.3288e-04, 2.4915e-04, 8.1483e-05, 2.0510e-04, 2.4929e-04,
        8.7279e-05, 1.6435e-04, 5.2989e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,512][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0008, 0.2413, 0.0181, 0.0473, 0.0263, 0.1492, 0.0847, 0.1539, 0.0661,
        0.0426, 0.0235, 0.0859, 0.0140, 0.0201, 0.0262], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,513][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0119, 0.0705, 0.0324, 0.0124, 0.0198, 0.0202, 0.0199, 0.0762, 0.1184,
        0.0321, 0.0402, 0.2549, 0.1403, 0.0804, 0.0704], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,515][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0069, 0.1026, 0.0728, 0.0827, 0.0538, 0.0880, 0.0770, 0.0712, 0.0613,
        0.0684, 0.0807, 0.0531, 0.0482, 0.0615, 0.0717], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,517][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1639, 0.0748, 0.0651, 0.0492, 0.0536, 0.0649, 0.0445, 0.0593, 0.0734,
        0.0575, 0.0621, 0.0617, 0.0606, 0.0644, 0.0449], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,518][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0516, 0.0717, 0.0648, 0.0657, 0.0700, 0.0664, 0.0654, 0.0697, 0.0626,
        0.0677, 0.0667, 0.0735, 0.0719, 0.0651, 0.0672], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,519][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0605, 0.0793, 0.0734, 0.0626, 0.0622, 0.0661, 0.0678, 0.0676, 0.0690,
        0.0672, 0.0652, 0.0685, 0.0624, 0.0634, 0.0650], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,519][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.8252e-02, 3.6259e-04, 1.3598e-03, 6.4444e-05, 1.0833e-03, 7.1428e-04,
        2.2621e-03, 2.6838e-02, 1.3078e-01, 6.6458e-03, 9.1550e-03, 1.0926e-01,
        4.9907e-01, 6.5860e-02, 7.8290e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,519][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0408, 0.0429, 0.0291, 0.0170, 0.0549, 0.0607, 0.0827, 0.0838, 0.0995,
        0.0309, 0.0330, 0.0984, 0.1389, 0.1098, 0.0776], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,520][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0017, 0.0571, 0.1897, 0.0342, 0.0779, 0.0311, 0.0532, 0.0838, 0.0799,
        0.0488, 0.0380, 0.0776, 0.1604, 0.0326, 0.0340], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,520][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.9248, 0.0018, 0.0086, 0.0129, 0.0130, 0.0060, 0.0069, 0.0025, 0.0019,
        0.0047, 0.0047, 0.0017, 0.0018, 0.0039, 0.0047], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,521][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:05,522][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16061],
        [ 4538],
        [25290],
        [ 4805],
        [22078],
        [ 7822],
        [ 2337],
        [ 7272],
        [16226],
        [ 5588],
        [ 3338],
        [ 7784],
        [22843],
        [ 7446],
        [ 7085]], device='cuda:0')
[2024-07-24 10:17:05,524][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17231],
        [12508],
        [32573],
        [ 2511],
        [12611],
        [ 4893],
        [ 2257],
        [ 7720],
        [11820],
        [ 3796],
        [ 2582],
        [ 4116],
        [19649],
        [ 9528],
        [ 6695]], device='cuda:0')
[2024-07-24 10:17:05,525][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19398],
        [19855],
        [18796],
        [19013],
        [20085],
        [21084],
        [22147],
        [24590],
        [27179],
        [27412],
        [27133],
        [26016],
        [25629],
        [26153],
        [26451]], device='cuda:0')
[2024-07-24 10:17:05,527][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[38785],
        [14332],
        [ 3311],
        [ 5352],
        [ 4121],
        [ 5369],
        [ 6372],
        [ 8185],
        [10621],
        [10154],
        [ 9247],
        [ 9788],
        [ 8254],
        [ 9114],
        [ 8706]], device='cuda:0')
[2024-07-24 10:17:05,528][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[30756],
        [21573],
        [32364],
        [30986],
        [28020],
        [25007],
        [20502],
        [21037],
        [20230],
        [19987],
        [19963],
        [20066],
        [19749],
        [18853],
        [18477]], device='cuda:0')
[2024-07-24 10:17:05,529][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[  651],
        [ 4229],
        [11704],
        [10441],
        [15529],
        [11617],
        [10411],
        [ 8850],
        [ 8061],
        [ 8031],
        [ 7810],
        [ 8854],
        [10248],
        [ 9758],
        [ 9411]], device='cuda:0')
[2024-07-24 10:17:05,531][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 5816],
        [12103],
        [13916],
        [16071],
        [15849],
        [16055],
        [15814],
        [15129],
        [14551],
        [14861],
        [14623],
        [14956],
        [14666],
        [14849],
        [15079]], device='cuda:0')
[2024-07-24 10:17:05,532][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[22731],
        [22699],
        [22824],
        [23135],
        [23112],
        [23121],
        [22919],
        [22793],
        [22771],
        [23113],
        [23146],
        [22803],
        [23149],
        [23024],
        [22864]], device='cuda:0')
[2024-07-24 10:17:05,534][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[1359],
        [ 759],
        [ 665],
        [ 700],
        [ 709],
        [ 715],
        [ 702],
        [ 632],
        [ 624],
        [ 651],
        [ 661],
        [ 674],
        [ 677],
        [ 685],
        [ 695]], device='cuda:0')
[2024-07-24 10:17:05,535][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[43505],
        [43235],
        [46666],
        [46967],
        [48901],
        [46690],
        [44653],
        [44677],
        [45844],
        [49042],
        [48499],
        [44340],
        [48993],
        [46247],
        [45915]], device='cuda:0')
[2024-07-24 10:17:05,537][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35675],
        [13116],
        [44858],
        [42856],
        [47065],
        [38992],
        [43232],
        [ 3506],
        [ 8323],
        [ 8306],
        [ 9752],
        [22600],
        [36836],
        [30591],
        [37531]], device='cuda:0')
[2024-07-24 10:17:05,539][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41130],
        [28650],
        [31856],
        [31378],
        [35797],
        [33994],
        [31307],
        [29604],
        [35523],
        [35563],
        [35232],
        [33606],
        [33947],
        [32407],
        [31448]], device='cuda:0')
[2024-07-24 10:17:05,540][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[32124],
        [32751],
        [50023],
        [49366],
        [47775],
        [46150],
        [45796],
        [45477],
        [44702],
        [44619],
        [43708],
        [43623],
        [41313],
        [40233],
        [40161]], device='cuda:0')
[2024-07-24 10:17:05,541][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[38943],
        [42163],
        [50088],
        [49866],
        [50152],
        [50054],
        [49925],
        [49811],
        [49982],
        [49980],
        [49973],
        [50061],
        [50060],
        [49805],
        [49909]], device='cuda:0')
[2024-07-24 10:17:05,543][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22904],
        [ 3093],
        [ 4692],
        [10011],
        [15756],
        [ 7297],
        [ 4758],
        [19621],
        [22286],
        [11307],
        [ 7562],
        [12935],
        [12278],
        [ 6906],
        [ 6101]], device='cuda:0')
[2024-07-24 10:17:05,544][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[30488],
        [28448],
        [24059],
        [24688],
        [25197],
        [25403],
        [26550],
        [26013],
        [25184],
        [24848],
        [24688],
        [24595],
        [24509],
        [24162],
        [24234]], device='cuda:0')
[2024-07-24 10:17:05,544][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38605],
        [38695],
        [38582],
        [38562],
        [38609],
        [38569],
        [38611],
        [38618],
        [38650],
        [38605],
        [38608],
        [38636],
        [38614],
        [38617],
        [38630]], device='cuda:0')
[2024-07-24 10:17:05,545][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[9842],
        [1284],
        [1364],
        [1271],
        [1368],
        [1229],
        [1520],
        [1581],
        [1629],
        [1604],
        [1669],
        [1715],
        [1621],
        [1660],
        [1730]], device='cuda:0')
[2024-07-24 10:17:05,546][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[34724],
        [38473],
        [37784],
        [37719],
        [37178],
        [37198],
        [36660],
        [36014],
        [36284],
        [36142],
        [36199],
        [38496],
        [38759],
        [39193],
        [39050]], device='cuda:0')
[2024-07-24 10:17:05,547][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[32996],
        [39849],
        [39204],
        [38444],
        [38337],
        [38266],
        [38425],
        [38257],
        [38200],
        [38222],
        [38147],
        [38065],
        [38066],
        [38058],
        [38088]], device='cuda:0')
[2024-07-24 10:17:05,549][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[27977],
        [21200],
        [ 5830],
        [ 5266],
        [ 1561],
        [ 2796],
        [ 8836],
        [ 3616],
        [ 5341],
        [27610],
        [32482],
        [17956],
        [12978],
        [ 6148],
        [32568]], device='cuda:0')
[2024-07-24 10:17:05,550][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[25801],
        [ 9224],
        [20197],
        [10002],
        [13793],
        [11727],
        [ 9579],
        [ 8375],
        [ 9668],
        [ 8107],
        [ 7272],
        [ 6839],
        [ 7672],
        [ 7420],
        [ 7829]], device='cuda:0')
[2024-07-24 10:17:05,552][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[12387],
        [ 4945],
        [ 8281],
        [ 8475],
        [ 9806],
        [ 9335],
        [ 8475],
        [ 8397],
        [ 8103],
        [ 8253],
        [ 7975],
        [ 8226],
        [ 8709],
        [ 8695],
        [ 8839]], device='cuda:0')
[2024-07-24 10:17:05,553][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27705],
        [ 6196],
        [ 3298],
        [ 1578],
        [ 1373],
        [ 1862],
        [ 2090],
        [ 5381],
        [ 5024],
        [ 5138],
        [ 4868],
        [ 4211],
        [ 3655],
        [ 4168],
        [ 4118]], device='cuda:0')
[2024-07-24 10:17:05,554][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12760],
        [16032],
        [10498],
        [ 6833],
        [ 7105],
        [ 5167],
        [ 7809],
        [ 8338],
        [15151],
        [16147],
        [13947],
        [17731],
        [14111],
        [ 9606],
        [ 9918]], device='cuda:0')
[2024-07-24 10:17:05,556][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[46342],
        [43722],
        [34995],
        [41187],
        [35191],
        [38343],
        [41914],
        [35591],
        [37402],
        [35243],
        [39280],
        [37826],
        [38182],
        [44217],
        [38750]], device='cuda:0')
[2024-07-24 10:17:05,557][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33561],
        [32385],
        [21276],
        [ 8066],
        [ 2372],
        [ 3502],
        [21509],
        [27063],
        [15676],
        [ 4112],
        [ 4524],
        [17968],
        [ 5461],
        [23330],
        [19730]], device='cuda:0')
[2024-07-24 10:17:05,559][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18926],
        [39261],
        [44982],
        [47543],
        [49035],
        [48753],
        [45538],
        [45950],
        [45077],
        [44758],
        [43920],
        [42997],
        [45779],
        [43346],
        [39482]], device='cuda:0')
[2024-07-24 10:17:05,560][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7670],
        [32996],
        [35429],
        [40417],
        [33137],
        [43935],
        [41153],
        [26652],
        [30475],
        [37700],
        [40014],
        [34808],
        [34735],
        [40491],
        [41917]], device='cuda:0')
[2024-07-24 10:17:05,562][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346],
        [42346]], device='cuda:0')
[2024-07-24 10:17:05,602][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:05,604][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,605][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,605][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,607][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,608][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,609][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,611][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,612][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,614][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,615][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,616][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,617][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,618][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3268, 0.6732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,618][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.1086e-05, 9.9996e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,618][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4745, 0.5255], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,618][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0701, 0.9299], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,619][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6441, 0.3559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,619][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7834, 0.2166], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,619][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9955, 0.0045], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,619][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,620][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2813, 0.7187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,620][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4196, 0.5804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,620][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3732, 0.6268], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,620][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1712, 0.8288], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,621][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.2372, 0.4192, 0.3435], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,621][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([2.4134e-05, 5.7616e-01, 4.2382e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,621][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.3130, 0.3298, 0.3572], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,622][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0542, 0.4045, 0.5413], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,623][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.0973, 0.8797, 0.0231], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,625][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.2870, 0.2334, 0.4795], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,626][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.9962, 0.0018, 0.0020], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,628][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0027, 0.0537, 0.9436], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,630][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2456, 0.3405, 0.4139], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,631][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.2743, 0.4835, 0.2422], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,633][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.2413, 0.3870, 0.3717], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,634][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.1053, 0.4497, 0.4450], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,636][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1312, 0.3106, 0.2765, 0.2818], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,637][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([8.6606e-06, 3.6238e-01, 2.6738e-01, 3.7023e-01], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,639][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2506, 0.2716, 0.2731, 0.2048], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,640][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0336, 0.2890, 0.3993, 0.2782], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,642][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1379, 0.7925, 0.0504, 0.0192], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,644][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0527, 0.0313, 0.9114, 0.0046], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,645][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8927, 0.0508, 0.0283, 0.0282], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,646][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([8.5750e-06, 3.2378e-02, 9.6721e-01, 4.0418e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,646][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0884, 0.2270, 0.3324, 0.3522], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,647][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2146, 0.3973, 0.1967, 0.1914], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,647][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1776, 0.3019, 0.2903, 0.2302], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,647][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0652, 0.3108, 0.3203, 0.3037], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,647][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.1279, 0.2857, 0.2331, 0.2273, 0.1259], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,648][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([9.5766e-06, 2.9622e-01, 2.1155e-01, 3.0675e-01, 1.8548e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,648][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.1899, 0.2156, 0.2309, 0.1604, 0.2032], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,648][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0270, 0.2230, 0.2964, 0.2060, 0.2476], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,649][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.2567, 0.5612, 0.0847, 0.0288, 0.0686], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,649][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.0671, 0.0665, 0.6767, 0.0383, 0.1513], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,649][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.9133, 0.0189, 0.0206, 0.0216, 0.0256], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,650][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([5.1117e-04, 1.4913e-02, 7.9043e-01, 2.5845e-04, 1.9388e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,652][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0599, 0.1807, 0.2374, 0.2665, 0.2555], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,653][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.1880, 0.3638, 0.1690, 0.1688, 0.1104], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,655][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.1419, 0.2401, 0.2305, 0.1803, 0.2072], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,656][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0505, 0.2483, 0.2495, 0.2381, 0.2136], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,658][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0744, 0.1902, 0.1594, 0.1709, 0.0828, 0.3223], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,659][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([5.0448e-06, 2.5519e-01, 1.7855e-01, 2.5898e-01, 1.5382e-01, 1.5345e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,661][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1597, 0.1854, 0.1923, 0.1262, 0.1759, 0.1606], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,662][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0176, 0.1858, 0.2454, 0.1603, 0.2027, 0.1883], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,664][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3437, 0.4933, 0.0187, 0.0601, 0.0641, 0.0200], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,666][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0368, 0.0312, 0.5328, 0.0141, 0.3644, 0.0207], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,667][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.9713, 0.0077, 0.0054, 0.0056, 0.0078, 0.0023], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,669][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0007, 0.0587, 0.5891, 0.0006, 0.3072, 0.0436], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,669][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0517, 0.1292, 0.1861, 0.1837, 0.1951, 0.2541], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,669][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1579, 0.3133, 0.1519, 0.1451, 0.0982, 0.1336], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,670][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1152, 0.1976, 0.1876, 0.1486, 0.1693, 0.1817], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,670][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0369, 0.2013, 0.2061, 0.1974, 0.1802, 0.1781], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,670][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0915, 0.1973, 0.1466, 0.1466, 0.0787, 0.2954, 0.0439],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,671][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([5.2180e-06, 2.1332e-01, 1.4957e-01, 2.1380e-01, 1.2690e-01, 1.2584e-01,
        1.7057e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,671][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1582, 0.1684, 0.1712, 0.1055, 0.1434, 0.1343, 0.1190],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,672][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0114, 0.1503, 0.2031, 0.1321, 0.1640, 0.1567, 0.1823],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,672][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8372, 0.0862, 0.0049, 0.0074, 0.0106, 0.0124, 0.0412],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,672][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0274, 0.0275, 0.4420, 0.0173, 0.4370, 0.0450, 0.0038],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,672][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.9235e-01, 1.5255e-03, 3.4141e-04, 1.8516e-03, 1.4750e-03, 1.1276e-03,
        1.3324e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,673][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([5.1448e-03, 7.0837e-03, 2.9130e-01, 1.4313e-04, 1.0317e-01, 4.2716e-02,
        5.5045e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,675][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0352, 0.1044, 0.1406, 0.1373, 0.1478, 0.2049, 0.2298],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,677][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1274, 0.2556, 0.1324, 0.1225, 0.0850, 0.1184, 0.1588],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,678][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0960, 0.1685, 0.1608, 0.1277, 0.1450, 0.1574, 0.1447],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,679][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0289, 0.1666, 0.1804, 0.1593, 0.1495, 0.1503, 0.1649],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,681][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0682, 0.1566, 0.1565, 0.1307, 0.0810, 0.2987, 0.0462, 0.0622],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,682][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([3.4784e-06, 1.8658e-01, 1.3233e-01, 1.8877e-01, 1.1289e-01, 1.1202e-01,
        1.5055e-01, 1.1685e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,684][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1260, 0.1343, 0.1532, 0.0996, 0.1351, 0.1257, 0.1154, 0.1107],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,685][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0162, 0.1245, 0.1635, 0.1075, 0.1418, 0.1283, 0.1529, 0.1653],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,686][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.5867, 0.0454, 0.0040, 0.0037, 0.0206, 0.0037, 0.1566, 0.1792],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,688][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.1485, 0.0056, 0.3503, 0.0063, 0.1637, 0.0589, 0.0224, 0.2444],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,689][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([9.9423e-01, 6.6148e-04, 3.8675e-04, 1.0921e-03, 1.4499e-03, 5.5133e-04,
        8.3819e-04, 7.8839e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,690][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([8.4960e-04, 2.1637e-07, 1.2344e-04, 4.3557e-08, 7.6560e-05, 1.7005e-05,
        1.0644e-03, 9.9787e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,692][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0396, 0.0737, 0.0988, 0.0995, 0.1068, 0.1557, 0.1924, 0.2335],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,692][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1411, 0.2023, 0.1094, 0.1009, 0.0720, 0.0966, 0.1293, 0.1483],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,692][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0855, 0.1431, 0.1375, 0.1091, 0.1243, 0.1342, 0.1250, 0.1412],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,693][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0300, 0.1457, 0.1546, 0.1373, 0.1333, 0.1281, 0.1430, 0.1281],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,693][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0659, 0.1462, 0.1296, 0.1041, 0.0713, 0.2288, 0.0412, 0.0590, 0.1540],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,694][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([2.8767e-06, 1.7955e-01, 1.1999e-01, 1.7773e-01, 1.0403e-01, 1.0628e-01,
        1.4080e-01, 1.0880e-01, 6.2826e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,694][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0985, 0.1162, 0.1424, 0.0887, 0.1254, 0.1143, 0.0982, 0.0933, 0.1231],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,694][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0100, 0.1084, 0.1440, 0.0997, 0.1212, 0.1101, 0.1251, 0.1367, 0.1449],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,695][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1015, 0.0362, 0.0016, 0.0042, 0.0065, 0.0043, 0.0796, 0.7448, 0.0214],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,695][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0820, 0.0019, 0.0414, 0.0026, 0.0413, 0.0066, 0.0066, 0.4864, 0.3313],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,695][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([9.7664e-01, 1.5583e-03, 1.5204e-03, 2.3564e-03, 3.0515e-03, 9.6725e-04,
        1.6677e-03, 2.4352e-03, 9.8004e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,696][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([4.0025e-05, 5.4990e-08, 1.3692e-05, 5.1757e-09, 7.0700e-06, 2.1425e-06,
        7.6448e-05, 3.2549e-01, 6.7437e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,696][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0371, 0.0619, 0.0884, 0.0850, 0.0942, 0.1254, 0.1492, 0.2021, 0.1568],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,698][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1352, 0.1749, 0.0937, 0.0897, 0.0641, 0.0856, 0.1128, 0.1356, 0.1084],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,700][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0730, 0.1239, 0.1179, 0.0937, 0.1062, 0.1146, 0.1067, 0.1211, 0.1429],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,701][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0269, 0.1288, 0.1316, 0.1249, 0.1161, 0.1120, 0.1307, 0.1173, 0.1117],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,703][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0775, 0.1303, 0.1040, 0.0975, 0.0569, 0.2177, 0.0286, 0.0441, 0.1149,
        0.1286], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,703][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.3379e-06, 1.6725e-01, 1.1271e-01, 1.6977e-01, 9.6232e-02, 9.8053e-02,
        1.3133e-01, 1.0185e-01, 5.7116e-02, 6.5685e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,705][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1032, 0.1109, 0.1215, 0.0817, 0.1079, 0.1011, 0.0836, 0.0862, 0.1139,
        0.0900], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,707][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0078, 0.0930, 0.1266, 0.0856, 0.1037, 0.0971, 0.1151, 0.1262, 0.1353,
        0.1096], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,708][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0839, 0.0275, 0.0067, 0.0020, 0.0116, 0.0020, 0.0439, 0.7144, 0.0359,
        0.0722], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,709][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.8374e-03, 1.2921e-04, 1.7211e-02, 1.5640e-04, 1.1367e-02, 1.2138e-03,
        5.9331e-04, 1.2303e-01, 8.4389e-01, 5.6816e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,712][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7912, 0.0175, 0.0153, 0.0118, 0.0219, 0.0148, 0.0136, 0.0205, 0.0497,
        0.0437], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,713][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([1.8366e-07, 7.3226e-08, 1.6178e-05, 4.6006e-09, 7.6446e-06, 7.8500e-07,
        5.9650e-05, 2.8530e-01, 7.1444e-01, 1.7730e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,714][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0247, 0.0543, 0.0808, 0.0740, 0.0854, 0.1095, 0.1320, 0.1835, 0.1414,
        0.1143], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,715][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1198, 0.1607, 0.0873, 0.0824, 0.0591, 0.0763, 0.1050, 0.1239, 0.0956,
        0.0899], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,715][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0639, 0.1111, 0.1071, 0.0846, 0.0963, 0.1025, 0.0956, 0.1083, 0.1274,
        0.1030], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,716][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0190, 0.1119, 0.1203, 0.1080, 0.1031, 0.1005, 0.1175, 0.1063, 0.1009,
        0.1123], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,716][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0534, 0.1344, 0.0969, 0.0978, 0.0506, 0.1918, 0.0263, 0.0383, 0.0963,
        0.1209, 0.0933], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,717][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.3001e-06, 1.5453e-01, 1.0546e-01, 1.5707e-01, 8.9845e-02, 9.1174e-02,
        1.2215e-01, 9.4480e-02, 5.3257e-02, 6.0839e-02, 7.1202e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,717][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0996, 0.1031, 0.1054, 0.0755, 0.0962, 0.0895, 0.0753, 0.0796, 0.1057,
        0.0855, 0.0847], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,717][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0066, 0.0838, 0.1162, 0.0786, 0.0950, 0.0876, 0.1038, 0.1144, 0.1228,
        0.1000, 0.0913], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,718][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1068, 0.0589, 0.0029, 0.0013, 0.0054, 0.0079, 0.0488, 0.4866, 0.0334,
        0.1457, 0.1022], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,718][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([2.9407e-03, 1.7952e-04, 2.4872e-02, 3.5685e-05, 1.1601e-02, 1.0801e-03,
        5.5910e-04, 8.7410e-02, 8.6767e-01, 1.5638e-03, 2.0910e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,718][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4002, 0.0534, 0.0307, 0.0205, 0.0347, 0.0296, 0.0347, 0.0564, 0.1344,
        0.1052, 0.1003], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,719][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.4199e-07, 5.3753e-08, 1.8011e-05, 2.2528e-09, 5.8979e-06, 9.5239e-07,
        7.5773e-05, 3.0942e-01, 6.8996e-01, 1.1777e-04, 3.9983e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,719][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0228, 0.0494, 0.0735, 0.0631, 0.0739, 0.0990, 0.1207, 0.1619, 0.1298,
        0.1017, 0.1041], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,721][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1077, 0.1499, 0.0811, 0.0752, 0.0542, 0.0701, 0.0972, 0.1146, 0.0883,
        0.0821, 0.0796], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,723][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0581, 0.1003, 0.0967, 0.0762, 0.0870, 0.0932, 0.0870, 0.0984, 0.1160,
        0.0932, 0.0939], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,724][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0183, 0.1008, 0.1072, 0.0963, 0.0938, 0.0919, 0.1046, 0.0950, 0.0914,
        0.1018, 0.0988], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,726][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0442, 0.1158, 0.0968, 0.0944, 0.0508, 0.1845, 0.0266, 0.0386, 0.0911,
        0.1107, 0.0916, 0.0551], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,726][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.8757e-06, 1.4225e-01, 1.0208e-01, 1.4306e-01, 8.8264e-02, 8.6369e-02,
        1.1593e-01, 9.0608e-02, 5.3380e-02, 5.8768e-02, 6.7784e-02, 5.1494e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,728][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0775, 0.0955, 0.1037, 0.0691, 0.0930, 0.0872, 0.0693, 0.0698, 0.0931,
        0.0752, 0.0772, 0.0895], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,730][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0071, 0.0776, 0.1084, 0.0729, 0.0913, 0.0794, 0.0888, 0.0995, 0.1083,
        0.0879, 0.0800, 0.0987], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,731][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0765, 0.0235, 0.0016, 0.0018, 0.0066, 0.0070, 0.1327, 0.4545, 0.0188,
        0.0310, 0.0572, 0.1888], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,732][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([7.3169e-02, 2.2435e-04, 9.9851e-03, 1.9261e-04, 6.8012e-03, 7.1712e-04,
        6.8653e-04, 1.2833e-02, 7.1775e-02, 2.4621e-03, 2.3196e-03, 8.1883e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,734][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.9501, 0.0015, 0.0018, 0.0023, 0.0032, 0.0012, 0.0017, 0.0012, 0.0049,
        0.0072, 0.0100, 0.0150], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,735][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([7.9183e-05, 1.3563e-10, 2.1476e-07, 7.5389e-11, 1.0858e-07, 3.7232e-08,
        9.6819e-07, 1.0956e-03, 2.7177e-03, 1.5440e-06, 3.8208e-06, 9.9610e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,737][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0224, 0.0438, 0.0654, 0.0654, 0.0655, 0.0933, 0.1068, 0.1405, 0.1059,
        0.0850, 0.0891, 0.1169], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,738][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1207, 0.1300, 0.0717, 0.0666, 0.0485, 0.0638, 0.0858, 0.1030, 0.0794,
        0.0709, 0.0682, 0.0914], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,739][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0534, 0.0892, 0.0867, 0.0689, 0.0784, 0.0846, 0.0787, 0.0882, 0.1040,
        0.0839, 0.0842, 0.0999], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,739][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0180, 0.0904, 0.0931, 0.0878, 0.0842, 0.0815, 0.0927, 0.0864, 0.0841,
        0.0930, 0.0906, 0.0981], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,739][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0409, 0.1291, 0.0885, 0.0875, 0.0482, 0.1561, 0.0284, 0.0392, 0.0950,
        0.1036, 0.0831, 0.0520, 0.0485], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,740][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([2.2119e-06, 1.3053e-01, 9.3797e-02, 1.3564e-01, 8.3015e-02, 8.2805e-02,
        1.0886e-01, 8.5478e-02, 5.0044e-02, 5.5908e-02, 6.4886e-02, 4.8621e-02,
        6.0422e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,740][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0702, 0.0893, 0.0986, 0.0588, 0.0854, 0.0799, 0.0669, 0.0641, 0.0859,
        0.0636, 0.0667, 0.0772, 0.0934], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,741][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0066, 0.0697, 0.0943, 0.0643, 0.0802, 0.0754, 0.0867, 0.0895, 0.0995,
        0.0781, 0.0708, 0.0935, 0.0914], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,741][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1410, 0.0397, 0.0047, 0.0025, 0.0046, 0.0042, 0.1052, 0.4385, 0.0095,
        0.0169, 0.0475, 0.0859, 0.0999], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,741][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([1.5163e-02, 2.7561e-04, 2.1298e-02, 3.1965e-04, 3.4924e-03, 8.8129e-04,
        7.9382e-04, 2.7907e-02, 8.2599e-02, 2.4518e-03, 3.5188e-03, 6.7743e-01,
        1.6387e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,742][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.6201, 0.0101, 0.0122, 0.0088, 0.0182, 0.0126, 0.0154, 0.0209, 0.0617,
        0.0344, 0.0396, 0.0705, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,742][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([2.9554e-06, 8.7410e-11, 8.7063e-08, 9.4062e-12, 2.0243e-08, 1.9345e-08,
        3.7836e-07, 4.7529e-04, 3.0171e-03, 3.4053e-07, 6.5040e-07, 7.2129e-01,
        2.7522e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,744][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0191, 0.0373, 0.0524, 0.0472, 0.0536, 0.0822, 0.0913, 0.1267, 0.1035,
        0.0740, 0.0740, 0.1214, 0.1174], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,746][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([0.0980, 0.1304, 0.0674, 0.0630, 0.0442, 0.0602, 0.0819, 0.0950, 0.0753,
        0.0671, 0.0640, 0.0850, 0.0684], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,747][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.0484, 0.0817, 0.0792, 0.0622, 0.0712, 0.0769, 0.0711, 0.0799, 0.0944,
        0.0757, 0.0763, 0.0911, 0.0918], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,749][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0146, 0.0840, 0.0888, 0.0803, 0.0760, 0.0748, 0.0872, 0.0772, 0.0759,
        0.0848, 0.0830, 0.0932, 0.0803], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,750][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0637, 0.1039, 0.0771, 0.0832, 0.0417, 0.1516, 0.0242, 0.0317, 0.0858,
        0.0987, 0.0749, 0.0474, 0.0410, 0.0750], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,751][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.6259e-06, 1.2642e-01, 8.8102e-02, 1.2860e-01, 7.6971e-02, 7.7766e-02,
        1.0290e-01, 8.0252e-02, 4.6775e-02, 5.2555e-02, 6.0850e-02, 4.6557e-02,
        5.6961e-02, 5.5292e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,753][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0747, 0.0805, 0.0825, 0.0564, 0.0774, 0.0704, 0.0581, 0.0630, 0.0777,
        0.0619, 0.0610, 0.0723, 0.0806, 0.0836], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,754][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0073, 0.0642, 0.0889, 0.0568, 0.0748, 0.0687, 0.0782, 0.0802, 0.0875,
        0.0730, 0.0656, 0.0814, 0.0819, 0.0912], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,756][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0540, 0.0191, 0.0007, 0.0035, 0.0038, 0.0013, 0.0319, 0.3135, 0.0099,
        0.0413, 0.2311, 0.0862, 0.1503, 0.0533], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,757][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.1728e-03, 1.1658e-04, 2.8631e-03, 5.8040e-05, 2.7025e-03, 3.3533e-04,
        1.5508e-04, 8.8010e-03, 8.0725e-02, 6.6061e-04, 8.4676e-04, 7.2805e-01,
        1.6516e-01, 8.3585e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,758][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([9.6406e-01, 1.0561e-03, 4.1189e-04, 1.4059e-03, 1.1258e-03, 7.4063e-04,
        9.4396e-04, 1.1644e-03, 3.6367e-03, 3.5330e-03, 5.8258e-03, 8.5186e-03,
        3.5062e-03, 4.0674e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,759][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([1.6104e-06, 3.9916e-09, 2.9631e-07, 1.8489e-10, 1.1879e-07, 1.0533e-07,
        8.5337e-07, 8.0472e-04, 8.6188e-03, 3.6118e-06, 4.2809e-06, 6.8903e-01,
        2.9807e-01, 3.4654e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,761][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0209, 0.0344, 0.0450, 0.0460, 0.0481, 0.0714, 0.0813, 0.1147, 0.0880,
        0.0691, 0.0691, 0.1036, 0.0973, 0.1112], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,761][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0873, 0.1217, 0.0615, 0.0570, 0.0408, 0.0548, 0.0738, 0.0871, 0.0702,
        0.0629, 0.0604, 0.0816, 0.0651, 0.0756], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,762][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0454, 0.0753, 0.0717, 0.0571, 0.0647, 0.0697, 0.0645, 0.0730, 0.0858,
        0.0695, 0.0701, 0.0835, 0.0834, 0.0863], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,762][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0159, 0.0745, 0.0819, 0.0739, 0.0718, 0.0679, 0.0793, 0.0738, 0.0693,
        0.0762, 0.0763, 0.0830, 0.0756, 0.0805], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,762][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0530, 0.1074, 0.0750, 0.0820, 0.0416, 0.1399, 0.0216, 0.0304, 0.0777,
        0.0887, 0.0744, 0.0416, 0.0358, 0.0664, 0.0646], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,763][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3851e-06, 1.2390e-01, 8.5189e-02, 1.2745e-01, 7.2906e-02, 7.3139e-02,
        9.7434e-02, 7.6190e-02, 4.2418e-02, 4.8506e-02, 5.7052e-02, 4.2169e-02,
        5.1836e-02, 5.0130e-02, 5.1679e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,763][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0658, 0.0781, 0.0823, 0.0504, 0.0723, 0.0608, 0.0529, 0.0548, 0.0767,
        0.0577, 0.0574, 0.0716, 0.0779, 0.0790, 0.0625], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,764][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0043, 0.0595, 0.0801, 0.0561, 0.0670, 0.0628, 0.0717, 0.0757, 0.0835,
        0.0693, 0.0618, 0.0742, 0.0734, 0.0873, 0.0733], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,764][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([6.8629e-01, 5.7187e-03, 1.4854e-03, 4.6765e-04, 3.8959e-03, 1.3638e-03,
        1.8771e-02, 7.4286e-02, 1.1678e-02, 3.3013e-03, 9.1564e-03, 6.5398e-02,
        7.4959e-02, 3.3884e-02, 9.3436e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,764][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.2462e-04, 2.0884e-05, 1.7289e-03, 1.2023e-05, 4.2305e-03, 8.8719e-05,
        8.3045e-05, 3.3843e-03, 5.2782e-02, 1.5656e-04, 4.2411e-04, 2.8380e-01,
        6.4007e-01, 1.1595e-02, 1.2057e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,765][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.8907, 0.0037, 0.0015, 0.0031, 0.0043, 0.0018, 0.0021, 0.0018, 0.0100,
        0.0104, 0.0136, 0.0246, 0.0102, 0.0129, 0.0093], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,765][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([8.2508e-06, 3.2751e-09, 5.0062e-07, 2.5713e-10, 1.6430e-07, 1.3131e-07,
        1.5029e-06, 4.6660e-04, 7.0467e-03, 3.2865e-06, 5.1407e-06, 6.7677e-01,
        2.9769e-01, 7.4703e-03, 1.0539e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,767][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0163, 0.0362, 0.0517, 0.0444, 0.0500, 0.0708, 0.0749, 0.0893, 0.0793,
        0.0639, 0.0633, 0.0867, 0.0900, 0.0960, 0.0873], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,769][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0773, 0.1140, 0.0604, 0.0535, 0.0390, 0.0515, 0.0685, 0.0811, 0.0650,
        0.0579, 0.0554, 0.0727, 0.0596, 0.0700, 0.0742], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,771][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0405, 0.0695, 0.0668, 0.0533, 0.0604, 0.0655, 0.0604, 0.0676, 0.0803,
        0.0646, 0.0651, 0.0770, 0.0771, 0.0806, 0.0713], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,772][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0124, 0.0714, 0.0758, 0.0681, 0.0652, 0.0637, 0.0730, 0.0652, 0.0656,
        0.0732, 0.0705, 0.0791, 0.0705, 0.0752, 0.0711], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,811][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:05,812][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,812][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,812][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,813][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,813][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,813][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,814][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,814][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,814][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,815][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,815][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,815][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:05,815][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9923e-01, 7.6899e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,816][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1449, 0.8551], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,818][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,819][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9869, 0.0131], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,821][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0078, 0.9922], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,822][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3870, 0.6130], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,823][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([9.9957e-01, 4.3053e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,824][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0133, 0.9867], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,826][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,828][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9986, 0.0014], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,829][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9089, 0.0911], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,831][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9111, 0.0889], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:05,832][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([9.9797e-01, 1.5687e-03, 4.6001e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,834][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.1913, 0.1952, 0.6134], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,835][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.9961, 0.0020, 0.0019], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,835][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.9523, 0.0082, 0.0395], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,836][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.0271, 0.5518, 0.4212], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,836][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.8439, 0.0843, 0.0718], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,836][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([9.9897e-01, 3.5184e-04, 6.7576e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,837][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0121, 0.2870, 0.7009], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,837][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([9.9770e-01, 6.6639e-04, 1.6337e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,837][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.9822, 0.0069, 0.0109], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,837][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.8855, 0.0522, 0.0623], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,838][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.4431, 0.2437, 0.3132], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:05,838][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9934, 0.0029, 0.0011, 0.0026], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,838][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0425, 0.5277, 0.3953, 0.0345], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,839][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9784, 0.0128, 0.0074, 0.0015], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,839][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.8656, 0.0198, 0.1048, 0.0098], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,839][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.1837e-04, 4.6333e-01, 5.3626e-01, 3.0080e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,841][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0235, 0.4114, 0.5637, 0.0013], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,843][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9934, 0.0035, 0.0016, 0.0016], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,844][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([5.0382e-05, 1.5689e-01, 8.4300e-01, 6.4442e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,845][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9700, 0.0025, 0.0259, 0.0016], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,846][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9539, 0.0116, 0.0313, 0.0032], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,848][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5783, 0.1652, 0.2372, 0.0192], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,850][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3697, 0.1413, 0.4552, 0.0337], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:05,851][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.9841, 0.0033, 0.0011, 0.0015, 0.0100], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,852][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0248, 0.3804, 0.4721, 0.0361, 0.0866], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,855][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.9701, 0.0133, 0.0134, 0.0012, 0.0020], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,856][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.8192, 0.0345, 0.0977, 0.0105, 0.0381], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,857][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([3.3627e-03, 3.2910e-01, 6.2043e-01, 2.4572e-04, 4.6868e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,858][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.2549, 0.1318, 0.4410, 0.0007, 0.1716], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,858][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.9789, 0.0049, 0.0071, 0.0035, 0.0056], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,859][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([9.7112e-04, 9.2259e-02, 8.7617e-01, 4.4947e-05, 3.0558e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,859][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([9.7506e-01, 2.8725e-03, 1.3656e-02, 7.6212e-04, 7.6501e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,859][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.8914, 0.0472, 0.0429, 0.0067, 0.0116], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,860][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.4418, 0.1696, 0.2560, 0.0127, 0.1198], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,860][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1627, 0.2993, 0.4042, 0.0177, 0.1161], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:05,860][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([9.8405e-01, 2.6161e-03, 1.3978e-03, 1.9065e-03, 9.6763e-03, 3.5025e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,860][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1555, 0.4376, 0.2967, 0.0261, 0.0643, 0.0197], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,861][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.9623, 0.0139, 0.0153, 0.0019, 0.0042, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,861][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.8019, 0.0274, 0.1068, 0.0057, 0.0356, 0.0226], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,861][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([8.6343e-04, 7.5234e-01, 2.1518e-01, 2.7188e-04, 2.6412e-02, 4.9377e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,862][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0779, 0.4356, 0.2869, 0.0011, 0.1794, 0.0191], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,862][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([9.9426e-01, 1.9306e-03, 1.4325e-03, 6.7059e-04, 1.3954e-03, 3.0791e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,864][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([1.2145e-03, 4.7823e-01, 4.5882e-01, 1.2678e-04, 5.6908e-02, 4.7030e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,864][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([9.5851e-01, 2.9193e-03, 2.4844e-02, 6.2329e-04, 1.0176e-02, 2.9321e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,866][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.9537, 0.0137, 0.0229, 0.0018, 0.0053, 0.0026], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,868][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.4912, 0.1464, 0.1539, 0.0111, 0.1008, 0.0966], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,869][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1462, 0.2893, 0.2806, 0.0173, 0.1152, 0.1513], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:05,870][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.6989e-01, 1.3919e-03, 4.2994e-04, 7.7240e-04, 4.8708e-03, 1.1939e-04,
        3.2253e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,872][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3400, 0.2989, 0.1744, 0.0293, 0.0529, 0.0284, 0.0760],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,873][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.7755e-01, 8.8296e-03, 7.8103e-03, 8.5313e-04, 1.4949e-03, 1.3823e-03,
        2.0812e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,874][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.7982, 0.0292, 0.0836, 0.0038, 0.0243, 0.0224, 0.0384],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,875][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([2.5164e-02, 2.3833e-01, 5.0496e-01, 1.5391e-04, 4.5891e-02, 2.0218e-02,
        1.6529e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,876][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([5.2213e-01, 1.1869e-01, 1.8054e-01, 2.1132e-04, 1.0383e-01, 1.8226e-02,
        5.6364e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,878][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9928e-01, 2.0221e-04, 4.7393e-05, 1.0041e-04, 1.4222e-04, 9.3956e-05,
        1.2971e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,879][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([3.5008e-02, 7.4462e-02, 6.8330e-01, 2.8344e-05, 3.2986e-02, 9.2931e-03,
        1.6492e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,880][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([9.7301e-01, 1.9811e-03, 1.1422e-02, 3.2166e-04, 5.7250e-03, 2.5451e-03,
        4.9909e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,881][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.9565, 0.0101, 0.0220, 0.0012, 0.0042, 0.0024, 0.0036],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,881][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6795, 0.0777, 0.0619, 0.0047, 0.0373, 0.0663, 0.0727],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,882][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0944, 0.2136, 0.1549, 0.0059, 0.0503, 0.1111, 0.3698],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:05,882][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([8.5515e-01, 4.4027e-04, 3.8479e-04, 3.9662e-04, 3.1716e-03, 8.7269e-05,
        1.3811e-01, 2.2566e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,882][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.5705, 0.1189, 0.0746, 0.0169, 0.0327, 0.0199, 0.0640, 0.1025],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,883][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.9040e-01, 2.2490e-03, 2.8169e-03, 6.6566e-04, 1.0814e-03, 8.4345e-04,
        1.1590e-03, 7.8265e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,883][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([9.0964e-01, 2.6660e-03, 2.2519e-02, 9.0725e-04, 9.7431e-03, 4.5873e-03,
        9.5312e-03, 4.0402e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,883][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([2.5548e-02, 4.3366e-05, 3.3123e-03, 1.8705e-07, 1.5568e-04, 3.1914e-05,
        1.3271e-03, 9.6958e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,884][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.8836e-01, 8.5622e-05, 1.7323e-03, 1.6433e-06, 1.1984e-03, 1.6278e-04,
        2.5673e-03, 4.0589e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,884][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([9.9944e-01, 7.1805e-05, 5.8014e-05, 5.7642e-05, 1.4835e-04, 4.0565e-05,
        7.9693e-05, 1.0148e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,884][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([1.2926e-02, 8.0214e-07, 2.8415e-04, 6.2074e-09, 2.6553e-05, 2.7833e-06,
        3.2500e-04, 9.8643e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,884][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([9.9265e-01, 6.1720e-05, 1.0674e-03, 3.8646e-05, 6.6621e-04, 2.6650e-04,
        7.9341e-04, 4.4538e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,885][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([9.8619e-01, 1.4989e-03, 4.6810e-03, 3.7834e-04, 1.3428e-03, 6.8962e-04,
        8.6741e-04, 4.3519e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,885][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.8231, 0.0065, 0.0128, 0.0011, 0.0087, 0.0124, 0.0167, 0.1187],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,887][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3418, 0.0297, 0.1089, 0.0026, 0.0350, 0.0498, 0.1652, 0.2671],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:05,888][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([9.4674e-01, 1.4284e-04, 1.6365e-04, 1.4974e-04, 1.6650e-03, 3.4352e-05,
        4.9512e-02, 8.8291e-04, 7.1266e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,890][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1774, 0.1623, 0.0886, 0.0205, 0.0348, 0.0121, 0.1018, 0.1703, 0.2321],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,890][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.9495e-01, 8.1556e-04, 1.3750e-03, 2.5427e-04, 5.0753e-04, 3.9945e-04,
        3.4681e-04, 3.1531e-04, 1.0351e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,892][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.6554, 0.0120, 0.0423, 0.0042, 0.0187, 0.0112, 0.0168, 0.0560, 0.1833],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,893][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([6.6845e-04, 5.3478e-06, 5.7216e-05, 8.3320e-09, 4.2055e-06, 1.9225e-06,
        6.2597e-05, 2.0986e-01, 7.8934e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,894][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([8.3938e-02, 2.8235e-05, 2.6441e-04, 1.7150e-07, 1.1562e-04, 2.2469e-05,
        2.4402e-04, 2.0103e-01, 7.1436e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,895][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([9.9602e-01, 2.6301e-04, 2.7441e-04, 1.9676e-04, 3.6772e-04, 9.9416e-05,
        2.3442e-04, 4.9760e-04, 2.0438e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,896][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([2.8789e-04, 9.0298e-08, 1.0731e-05, 1.9467e-10, 6.6177e-07, 1.1883e-07,
        7.2907e-06, 1.7535e-01, 8.2435e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,897][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.8802e-01, 4.8591e-05, 9.6644e-04, 1.7585e-05, 4.4992e-04, 1.4415e-04,
        2.8023e-04, 4.5578e-03, 5.5192e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,898][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([9.8305e-01, 1.1135e-03, 2.9765e-03, 2.6597e-04, 8.5746e-04, 5.4000e-04,
        4.4433e-04, 3.5880e-03, 7.1647e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,900][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.3041, 0.0078, 0.0101, 0.0009, 0.0056, 0.0088, 0.0115, 0.1144, 0.5367],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,902][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2554, 0.0292, 0.0451, 0.0015, 0.0102, 0.0191, 0.0835, 0.2300, 0.3259],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:05,903][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([8.8375e-01, 9.3697e-04, 5.1992e-04, 9.7235e-04, 3.5437e-03, 1.7027e-04,
        1.0266e-01, 3.9560e-03, 2.0742e-03, 1.4098e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,904][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0229, 0.1655, 0.1989, 0.0248, 0.0396, 0.0154, 0.0919, 0.1433, 0.1363,
        0.1615], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,904][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9512, 0.0093, 0.0099, 0.0026, 0.0038, 0.0025, 0.0028, 0.0031, 0.0089,
        0.0060], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,905][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2462, 0.0156, 0.0759, 0.0059, 0.0247, 0.0111, 0.0275, 0.1223, 0.4101,
        0.0606], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,905][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([8.6638e-07, 3.0136e-06, 2.5782e-05, 4.3252e-09, 3.4588e-06, 3.4471e-07,
        2.4253e-05, 1.5199e-01, 8.4780e-01, 1.4996e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,905][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([3.0123e-04, 2.3933e-05, 1.4575e-04, 1.5316e-07, 9.4471e-05, 5.3737e-06,
        1.2898e-04, 1.9017e-01, 8.0789e-01, 1.2449e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,906][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9756, 0.0025, 0.0020, 0.0011, 0.0024, 0.0012, 0.0014, 0.0026, 0.0065,
        0.0048], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,906][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([1.0566e-07, 3.0591e-08, 3.2978e-06, 3.6150e-11, 1.9809e-07, 6.4962e-09,
        1.9454e-06, 1.1845e-01, 8.8153e-01, 1.7966e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,906][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([8.2930e-01, 9.1567e-04, 1.2698e-02, 3.3592e-04, 6.8184e-03, 1.6299e-03,
        4.9143e-03, 5.6410e-02, 7.7965e-02, 9.0134e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,907][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8514, 0.0082, 0.0315, 0.0029, 0.0091, 0.0037, 0.0058, 0.0287, 0.0475,
        0.0112], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,907][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0760, 0.0104, 0.0213, 0.0013, 0.0108, 0.0090, 0.0191, 0.1501, 0.6469,
        0.0550], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,907][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0841, 0.0255, 0.0912, 0.0027, 0.0213, 0.0217, 0.1169, 0.3007, 0.2836,
        0.0524], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:05,908][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([8.3091e-01, 1.4799e-03, 6.8671e-04, 1.1544e-03, 4.1610e-03, 1.8414e-04,
        1.4934e-01, 5.0864e-03, 2.5910e-03, 1.6663e-03, 2.7457e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,908][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0052, 0.1720, 0.1148, 0.0150, 0.0217, 0.0114, 0.0883, 0.1388, 0.1297,
        0.1478, 0.1553], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,910][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.9187, 0.0139, 0.0138, 0.0031, 0.0048, 0.0034, 0.0045, 0.0042, 0.0166,
        0.0087, 0.0082], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,912][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1915, 0.0146, 0.0815, 0.0049, 0.0237, 0.0107, 0.0296, 0.1189, 0.4234,
        0.0542, 0.0471], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,913][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.7653e-06, 2.1710e-06, 2.7838e-05, 1.7466e-09, 2.3931e-06, 3.0313e-07,
        2.3419e-05, 1.1623e-01, 8.8322e-01, 6.5657e-05, 4.3143e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,914][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.6732e-04, 1.5233e-05, 1.5424e-04, 5.2283e-08, 5.6864e-05, 4.4370e-06,
        9.5836e-05, 1.4115e-01, 8.5439e-01, 7.4950e-04, 3.0160e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,915][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9163, 0.0083, 0.0034, 0.0025, 0.0037, 0.0025, 0.0039, 0.0075, 0.0199,
        0.0154, 0.0167], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,916][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.9505e-07, 2.1301e-08, 4.3294e-06, 1.4339e-11, 1.4300e-07, 7.7675e-09,
        2.2151e-06, 1.2619e-01, 8.7373e-01, 9.5622e-06, 5.6765e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,917][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([7.2384e-01, 9.4407e-04, 1.5517e-02, 2.9381e-04, 6.3751e-03, 1.9783e-03,
        7.5211e-03, 8.5432e-02, 1.3543e-01, 1.0685e-02, 1.1977e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,919][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8066, 0.0094, 0.0381, 0.0027, 0.0098, 0.0045, 0.0070, 0.0329, 0.0626,
        0.0117, 0.0147], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,920][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0577, 0.0089, 0.0182, 0.0009, 0.0079, 0.0085, 0.0193, 0.1377, 0.6414,
        0.0443, 0.0551], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,922][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0626, 0.0210, 0.0829, 0.0018, 0.0167, 0.0224, 0.1300, 0.3236, 0.2665,
        0.0412, 0.0313], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:05,923][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.4935e-01, 1.7374e-04, 1.0099e-04, 1.4601e-04, 1.0057e-03, 3.1089e-05,
        4.3463e-02, 7.4072e-04, 4.0481e-04, 2.3304e-04, 3.6986e-04, 3.9823e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,925][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.1382, 0.0963, 0.0856, 0.0131, 0.0256, 0.0100, 0.0413, 0.0559, 0.1084,
        0.1667, 0.1319, 0.1271], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,926][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.8236e-01, 2.5209e-03, 2.9723e-03, 5.6647e-04, 1.0447e-03, 7.1757e-04,
        5.6796e-04, 6.0442e-04, 2.1290e-03, 1.0878e-03, 1.6294e-03, 3.8003e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,927][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.7296, 0.0022, 0.0303, 0.0013, 0.0089, 0.0031, 0.0046, 0.0207, 0.0876,
        0.0130, 0.0086, 0.0900], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,927][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([1.3589e-03, 5.0786e-08, 2.7785e-06, 6.0039e-10, 2.7978e-07, 1.2781e-07,
        3.0568e-06, 3.2616e-03, 1.1356e-02, 2.9777e-06, 1.1502e-05, 9.8400e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,928][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([4.3211e-02, 1.3389e-07, 5.8126e-06, 6.1146e-09, 4.9315e-06, 5.7636e-07,
        6.6002e-06, 1.6596e-03, 5.6933e-03, 1.1866e-05, 3.0191e-05, 9.4938e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,928][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([9.9108e-01, 2.6646e-04, 4.3218e-04, 2.0588e-04, 4.9028e-04, 1.4277e-04,
        2.8648e-04, 2.2670e-04, 9.9504e-04, 8.6062e-04, 1.1202e-03, 3.8928e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,929][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([4.3382e-04, 1.0330e-10, 1.8127e-07, 2.6795e-12, 1.2177e-08, 1.7311e-09,
        7.5341e-08, 4.1870e-04, 1.9606e-03, 7.1016e-08, 2.2898e-07, 9.9719e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,929][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.6071e-01, 1.6477e-05, 6.6030e-04, 1.8271e-05, 2.4940e-04, 9.3533e-05,
        2.1542e-04, 2.5761e-03, 2.5087e-03, 3.0904e-04, 3.2662e-04, 3.2316e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,929][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([9.7887e-01, 3.5124e-04, 2.5564e-03, 1.2134e-04, 6.6942e-04, 2.1062e-04,
        2.4570e-04, 1.7497e-03, 3.9242e-03, 5.0136e-04, 4.9711e-04, 1.0303e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,930][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([2.9751e-01, 1.4852e-03, 4.0484e-03, 3.6519e-04, 2.9045e-03, 4.6132e-03,
        5.4265e-03, 3.5336e-02, 1.5629e-01, 1.2021e-02, 1.0520e-02, 4.6948e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,930][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.4571e-01, 2.7377e-03, 1.5913e-02, 5.2442e-04, 4.7550e-03, 7.4313e-03,
        2.7466e-02, 5.7996e-02, 6.3539e-02, 8.4399e-03, 4.3808e-03, 6.6111e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:05,930][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([8.5722e-01, 5.1715e-04, 2.0391e-04, 1.9568e-04, 1.7317e-03, 4.1307e-05,
        1.0532e-01, 2.3637e-03, 1.2758e-03, 3.9430e-04, 5.1005e-04, 8.6438e-03,
        2.1580e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,931][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0049, 0.0598, 0.0779, 0.0068, 0.0171, 0.0131, 0.0387, 0.0701, 0.0720,
        0.0625, 0.0507, 0.1199, 0.4066], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,931][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([9.6641e-01, 4.2991e-03, 6.8348e-03, 5.3425e-04, 1.3309e-03, 1.4405e-03,
        9.7234e-04, 1.0003e-03, 5.2659e-03, 1.3350e-03, 1.6215e-03, 6.5192e-03,
        2.4360e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,933][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.2988, 0.0076, 0.0313, 0.0021, 0.0111, 0.0103, 0.0142, 0.0364, 0.1967,
        0.0163, 0.0128, 0.2616, 0.1008], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,933][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([1.9326e-04, 4.3701e-08, 3.2292e-06, 1.1295e-10, 1.1379e-07, 5.9257e-08,
        1.0238e-06, 1.6185e-03, 1.3221e-02, 1.1567e-06, 2.8542e-06, 7.0236e-01,
        2.8260e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,935][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([6.4629e-03, 1.2558e-07, 6.4157e-06, 1.4676e-09, 1.3143e-06, 4.0583e-07,
        2.7634e-06, 8.0529e-04, 5.9284e-03, 4.6419e-06, 7.9640e-06, 6.7375e-01,
        3.1303e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,936][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([9.5316e-01, 1.3175e-03, 2.3188e-03, 7.3358e-04, 2.3861e-03, 1.2202e-03,
        1.7367e-03, 2.5208e-03, 9.8414e-03, 3.5935e-03, 3.9363e-03, 9.1401e-03,
        8.0910e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,937][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([1.3870e-05, 1.1632e-10, 9.0853e-08, 2.6128e-13, 1.5825e-09, 7.9500e-10,
        2.6925e-08, 1.8790e-04, 2.8788e-03, 1.4428e-08, 3.7587e-08, 8.4735e-01,
        1.4957e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,937][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([5.3230e-01, 8.1314e-05, 1.2604e-03, 1.7093e-05, 4.7846e-04, 3.2060e-04,
        4.3265e-04, 9.2141e-03, 2.3527e-02, 9.4649e-04, 6.7713e-04, 3.7917e-01,
        5.1574e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,939][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([0.8019, 0.0039, 0.0126, 0.0008, 0.0025, 0.0021, 0.0027, 0.0110, 0.0363,
        0.0046, 0.0041, 0.0972, 0.0204], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,940][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([6.8457e-02, 1.5284e-03, 3.6858e-03, 1.4720e-04, 1.5096e-03, 3.2952e-03,
        2.8588e-03, 1.5253e-02, 1.1665e-01, 4.9813e-03, 4.5422e-03, 4.0759e-01,
        3.6950e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,941][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([1.5538e-02, 4.5582e-03, 9.5983e-03, 1.2678e-04, 1.1105e-03, 3.7874e-03,
        1.0789e-02, 2.3309e-02, 6.5451e-02, 3.3915e-03, 1.4260e-03, 7.7735e-01,
        8.3565e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:05,942][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([8.2411e-01, 4.5334e-04, 2.0149e-04, 3.4734e-04, 1.4365e-03, 6.1650e-05,
        1.3987e-01, 1.8942e-03, 1.3796e-03, 5.1467e-04, 6.9695e-04, 1.0510e-02,
        1.1996e-02, 6.5233e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,944][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1359, 0.1070, 0.0949, 0.0093, 0.0184, 0.0101, 0.0229, 0.0286, 0.0385,
        0.1120, 0.0588, 0.1043, 0.1741, 0.0852], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,945][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.6899e-01, 2.6631e-03, 4.5509e-03, 6.7708e-04, 1.5859e-03, 1.3824e-03,
        1.4682e-03, 1.2343e-03, 2.9321e-03, 2.1532e-03, 1.6914e-03, 6.8451e-03,
        1.5481e-03, 2.2739e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,947][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.4862, 0.0071, 0.0322, 0.0017, 0.0112, 0.0064, 0.0086, 0.0301, 0.1175,
        0.0184, 0.0114, 0.1474, 0.0778, 0.0442], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,948][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([4.8526e-05, 1.2826e-06, 5.4636e-06, 1.6651e-09, 4.4574e-07, 4.0575e-07,
        4.0472e-06, 2.8552e-03, 5.4811e-02, 1.0703e-05, 2.5004e-05, 7.0517e-01,
        2.2638e-01, 1.0690e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,949][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([8.2135e-04, 1.6713e-06, 7.7454e-06, 7.4934e-09, 2.9825e-06, 1.1430e-06,
        5.0232e-06, 1.2090e-03, 1.3038e-02, 1.9768e-05, 3.0471e-05, 6.9758e-01,
        2.8369e-01, 3.5936e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,950][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([9.9666e-01, 1.0071e-04, 4.5026e-05, 6.3027e-05, 8.6340e-05, 4.4032e-05,
        7.3565e-05, 1.2504e-04, 4.4494e-04, 2.0700e-04, 3.1183e-04, 1.2492e-03,
        1.8026e-04, 4.1139e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,950][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([8.4856e-06, 4.5597e-09, 2.1926e-07, 5.2896e-12, 1.0461e-08, 5.0735e-09,
        6.5199e-08, 3.0332e-04, 9.3018e-03, 3.2537e-07, 4.1215e-07, 8.1092e-01,
        1.7762e-01, 1.8478e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,951][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([7.6537e-01, 2.0509e-04, 1.2068e-03, 2.8902e-05, 5.1968e-04, 3.1642e-04,
        5.0319e-04, 6.2232e-03, 1.1623e-02, 1.0295e-03, 8.0720e-04, 1.7867e-01,
        2.6549e-02, 6.9478e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,951][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([9.4585e-01, 2.1150e-03, 4.0134e-03, 2.5443e-04, 9.5464e-04, 4.7715e-04,
        5.2142e-04, 2.5689e-03, 7.7721e-03, 1.1761e-03, 1.2272e-03, 2.4772e-02,
        6.1645e-03, 2.1366e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,951][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([6.7952e-02, 3.2064e-03, 3.3181e-03, 2.4543e-04, 2.0604e-03, 3.3224e-03,
        2.7616e-03, 2.2235e-02, 1.2648e-01, 9.0178e-03, 7.3198e-03, 3.3627e-01,
        3.3163e-01, 8.4183e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,952][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([3.5440e-02, 9.6497e-03, 9.6270e-03, 3.2631e-04, 2.3907e-03, 3.6370e-03,
        1.4695e-02, 3.9429e-02, 7.7352e-02, 9.1787e-03, 4.3668e-03, 5.4316e-01,
        1.5171e-01, 9.9039e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:05,952][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.7298e-01, 9.8281e-04, 3.3787e-04, 6.2419e-04, 3.2861e-03, 9.2813e-05,
        1.6615e-01, 2.4203e-03, 1.9609e-03, 8.0806e-04, 1.2024e-03, 1.2780e-02,
        2.4621e-02, 9.4497e-03, 2.2984e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,953][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0338, 0.0395, 0.0608, 0.0046, 0.0144, 0.0061, 0.0191, 0.0437, 0.0588,
        0.0678, 0.0530, 0.0630, 0.2282, 0.0992, 0.2081], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,953][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([9.6298e-01, 2.9441e-03, 7.0139e-03, 7.3429e-04, 1.9748e-03, 7.5487e-04,
        1.0876e-03, 1.0088e-03, 5.4126e-03, 1.9850e-03, 1.8766e-03, 5.5004e-03,
        1.8848e-03, 1.8179e-03, 3.0225e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,953][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2429, 0.0087, 0.0439, 0.0022, 0.0128, 0.0084, 0.0153, 0.0384, 0.1800,
        0.0275, 0.0167, 0.1825, 0.0995, 0.0701, 0.0510], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,954][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([7.3533e-05, 3.8665e-07, 5.9791e-06, 4.1671e-10, 4.1599e-07, 2.6433e-07,
        2.1996e-06, 1.5348e-03, 3.5457e-02, 3.9113e-06, 9.3083e-06, 6.1370e-01,
        3.2915e-01, 1.7113e-02, 2.9495e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,954][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.4705e-03, 1.1413e-06, 1.1755e-05, 5.3301e-09, 5.2162e-06, 1.2440e-06,
        4.6610e-06, 5.5837e-04, 1.0524e-02, 1.5266e-05, 2.9470e-05, 4.1708e-01,
        5.5736e-01, 8.7760e-03, 4.1607e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,956][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.8375e-01, 7.1501e-04, 2.9944e-04, 2.2514e-04, 5.9044e-04, 1.5444e-04,
        2.4581e-04, 2.2601e-04, 1.8053e-03, 1.1103e-03, 1.2111e-03, 5.2791e-03,
        1.0198e-03, 1.9797e-03, 1.3931e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,956][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.3550e-05, 3.8345e-09, 5.5307e-07, 5.4185e-12, 1.5835e-08, 6.6706e-09,
        1.3238e-07, 1.7735e-04, 8.1437e-03, 2.1434e-07, 4.0582e-07, 7.5154e-01,
        2.3413e-01, 4.1937e-03, 1.8021e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,958][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.5686e-01, 3.1479e-04, 3.7557e-03, 4.8892e-05, 1.4167e-03, 5.7198e-04,
        6.4918e-04, 6.1094e-03, 2.3012e-02, 1.5417e-03, 1.2463e-03, 2.2338e-01,
        5.4928e-02, 1.6919e-02, 9.2511e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,959][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.0584e-01, 2.4323e-03, 1.0525e-02, 4.0213e-04, 1.9432e-03, 7.8456e-04,
        7.1993e-04, 3.9994e-03, 1.4781e-02, 2.0232e-03, 2.0530e-03, 3.6244e-02,
        1.0773e-02, 3.9632e-03, 3.5140e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,960][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([4.7547e-02, 2.1940e-03, 2.9230e-03, 1.9350e-04, 1.7862e-03, 2.9038e-03,
        3.0370e-03, 1.2884e-02, 1.2949e-01, 8.5095e-03, 7.6555e-03, 2.9238e-01,
        3.3532e-01, 9.6826e-02, 5.6340e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,960][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1112e-02, 1.1305e-02, 1.3947e-02, 2.9882e-04, 2.2225e-03, 6.3986e-03,
        2.2506e-02, 4.5927e-02, 9.9654e-02, 9.8430e-03, 4.5033e-03, 3.8927e-01,
        1.4284e-01, 1.7496e-01, 6.5215e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:05,961][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:05,963][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15939],
        [ 4913],
        [32699],
        [ 8908],
        [17415],
        [ 6533],
        [ 1972],
        [ 4250],
        [ 3524],
        [ 2343],
        [ 2069],
        [ 1231],
        [ 7162],
        [ 2862],
        [ 2324]], device='cuda:0')
[2024-07-24 10:17:05,965][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16188],
        [ 6308],
        [42035],
        [ 5759],
        [22851],
        [ 8320],
        [ 2479],
        [ 9676],
        [15738],
        [ 5227],
        [ 2880],
        [ 5823],
        [23573],
        [ 7907],
        [ 6097]], device='cuda:0')
[2024-07-24 10:17:05,966][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6084],
        [ 7952],
        [ 6347],
        [ 6824],
        [ 8362],
        [11216],
        [11347],
        [11701],
        [11552],
        [ 9592],
        [ 8428],
        [ 8739],
        [ 9127],
        [ 8799],
        [ 8638]], device='cuda:0')
[2024-07-24 10:17:05,968][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[20059],
        [16507],
        [20072],
        [18528],
        [18521],
        [17930],
        [17363],
        [17418],
        [17193],
        [16969],
        [16774],
        [16446],
        [16251],
        [16042],
        [15850]], device='cuda:0')
[2024-07-24 10:17:05,969][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1674],
        [1148],
        [2439],
        [2097],
        [2772],
        [3245],
        [2865],
        [2912],
        [2997],
        [2854],
        [2754],
        [2609],
        [2713],
        [2664],
        [2391]], device='cuda:0')
[2024-07-24 10:17:05,971][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[43782],
        [42462],
        [43131],
        [44964],
        [44455],
        [45052],
        [44973],
        [44664],
        [44164],
        [44181],
        [44242],
        [43910],
        [43486],
        [43392],
        [43277]], device='cuda:0')
[2024-07-24 10:17:05,972][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32725],
        [17494],
        [12899],
        [11652],
        [ 8998],
        [11752],
        [21243],
        [ 9163],
        [ 5089],
        [ 4994],
        [ 5829],
        [ 3369],
        [ 4005],
        [ 3687],
        [ 5820]], device='cuda:0')
[2024-07-24 10:17:05,974][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 8895],
        [16851],
        [40336],
        [44279],
        [42464],
        [40821],
        [39733],
        [35294],
        [24725],
        [32068],
        [32608],
        [33045],
        [33330],
        [33358],
        [31864]], device='cuda:0')
[2024-07-24 10:17:05,975][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[25382],
        [25327],
        [25847],
        [32125],
        [36244],
        [28860],
        [26137],
        [26076],
        [27891],
        [41331],
        [43609],
        [30407],
        [47962],
        [29206],
        [36374]], device='cuda:0')
[2024-07-24 10:17:05,976][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13809],
        [32359],
        [41796],
        [41913],
        [41246],
        [40499],
        [35943],
        [38886],
        [33588],
        [33176],
        [33414],
        [25099],
        [26523],
        [26681],
        [26771]], device='cuda:0')
[2024-07-24 10:17:05,977][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[18464],
        [ 6882],
        [30189],
        [27148],
        [25682],
        [21264],
        [13644],
        [ 5521],
        [ 5229],
        [ 4864],
        [ 4644],
        [ 3825],
        [ 2863],
        [ 2235],
        [ 2517]], device='cuda:0')
[2024-07-24 10:17:05,978][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16265],
        [26591],
        [26999],
        [28142],
        [27943],
        [28708],
        [28499],
        [28459],
        [27895],
        [27678],
        [27642],
        [27431],
        [27260],
        [27368],
        [27520]], device='cuda:0')
[2024-07-24 10:17:05,979][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[47957],
        [47693],
        [40943],
        [40888],
        [40369],
        [40209],
        [40330],
        [39966],
        [41348],
        [41604],
        [41941],
        [42141],
        [42233],
        [42045],
        [42228]], device='cuda:0')
[2024-07-24 10:17:05,980][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 5015],
        [  829],
        [50140],
        [48302],
        [41903],
        [30809],
        [22875],
        [17662],
        [10081],
        [ 7606],
        [ 5743],
        [ 3390],
        [ 2824],
        [ 2443],
        [ 2084]], device='cuda:0')
[2024-07-24 10:17:05,981][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18336],
        [25205],
        [19608],
        [25902],
        [24702],
        [26018],
        [29705],
        [27194],
        [22798],
        [30706],
        [31993],
        [24696],
        [18097],
        [25047],
        [26266]], device='cuda:0')
[2024-07-24 10:17:05,983][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13351],
        [13283],
        [13126],
        [12592],
        [ 9625],
        [ 9607],
        [ 1979],
        [ 3742],
        [ 7719],
        [ 4162],
        [ 2806],
        [ 7915],
        [ 2070],
        [ 2130],
        [ 1076]], device='cuda:0')
[2024-07-24 10:17:05,984][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18099],
        [ 8385],
        [  364],
        [ 1222],
        [  608],
        [ 1252],
        [ 2209],
        [ 2575],
        [ 4198],
        [ 1807],
        [ 3002],
        [ 3143],
        [  822],
        [  919],
        [  830]], device='cuda:0')
[2024-07-24 10:17:05,986][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23949],
        [23924],
        [24095],
        [24358],
        [25077],
        [25565],
        [24975],
        [24528],
        [24441],
        [28287],
        [30095],
        [25442],
        [26984],
        [26485],
        [27679]], device='cuda:0')
[2024-07-24 10:17:05,987][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[44358],
        [44733],
        [43316],
        [38608],
        [37084],
        [36245],
        [38391],
        [43831],
        [44531],
        [41558],
        [41528],
        [42614],
        [41986],
        [42748],
        [42432]], device='cuda:0')
[2024-07-24 10:17:05,988][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[13945],
        [39196],
        [38676],
        [39326],
        [39950],
        [38782],
        [40618],
        [34477],
        [35543],
        [36014],
        [36283],
        [19746],
        [22342],
        [23423],
        [23992]], device='cuda:0')
[2024-07-24 10:17:05,990][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[37856],
        [27170],
        [34220],
        [32619],
        [33157],
        [30653],
        [30074],
        [20932],
        [ 2977],
        [ 2627],
        [ 2502],
        [ 1044],
        [ 1503],
        [ 1408],
        [ 2944]], device='cuda:0')
[2024-07-24 10:17:05,991][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30689],
        [30650],
        [30570],
        [30021],
        [27971],
        [30063],
        [30612],
        [30631],
        [30450],
        [28553],
        [23135],
        [29898],
        [26186],
        [30431],
        [29427]], device='cuda:0')
[2024-07-24 10:17:05,993][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 7900],
        [14319],
        [23797],
        [24425],
        [24362],
        [22457],
        [25014],
        [30262],
        [14438],
        [13650],
        [13742],
        [12338],
        [14251],
        [14671],
        [15698]], device='cuda:0')
[2024-07-24 10:17:05,995][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25498],
        [25436],
        [25379],
        [24167],
        [24200],
        [23343],
        [23581],
        [24919],
        [24282],
        [13712],
        [11627],
        [22561],
        [19856],
        [17860],
        [19202]], device='cuda:0')
[2024-07-24 10:17:05,996][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[46559],
        [46629],
        [46744],
        [46819],
        [47308],
        [46571],
        [46525],
        [46305],
        [46013],
        [44746],
        [45323],
        [46150],
        [44601],
        [45259],
        [44392]], device='cuda:0')
[2024-07-24 10:17:05,998][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[16168],
        [ 6158],
        [ 3190],
        [12919],
        [27215],
        [22504],
        [12757],
        [ 9556],
        [13468],
        [16266],
        [16033],
        [18509],
        [25640],
        [25193],
        [25364]], device='cuda:0')
[2024-07-24 10:17:05,999][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[11559],
        [17544],
        [30679],
        [29303],
        [36886],
        [40075],
        [44296],
        [39491],
        [41844],
        [42801],
        [42978],
        [21825],
        [20588],
        [24088],
        [30633]], device='cuda:0')
[2024-07-24 10:17:06,000][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[14593],
        [19277],
        [14369],
        [12007],
        [ 9390],
        [12954],
        [14817],
        [18258],
        [18099],
        [21296],
        [22960],
        [32933],
        [33426],
        [33365],
        [30587]], device='cuda:0')
[2024-07-24 10:17:06,001][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34268],
        [17984],
        [32793],
        [25984],
        [22378],
        [15303],
        [13437],
        [ 8871],
        [27890],
        [30954],
        [32257],
        [20928],
        [27409],
        [22130],
        [21891]], device='cuda:0')
[2024-07-24 10:17:06,002][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491],
        [44491]], device='cuda:0')
[2024-07-24 10:17:06,046][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:06,047][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,047][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,047][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,048][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,048][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,048][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,049][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,049][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,049][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,050][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,050][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,052][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,052][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9982e-01, 1.7771e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,054][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9531, 0.0469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,055][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.9997e-01, 3.1687e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,056][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6813, 0.3187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,057][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9929, 0.0071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,059][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,060][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9114, 0.0886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,062][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9571, 0.0429], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,063][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4208, 0.5792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,065][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,067][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,068][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0276, 0.9724], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,069][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([9.9764e-01, 8.2886e-04, 1.5296e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,069][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.1395, 0.0393, 0.8212], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,070][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([9.9487e-01, 9.4104e-04, 4.1855e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,070][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.9604, 0.0059, 0.0336], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,070][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.9775, 0.0083, 0.0142], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,070][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.9851, 0.0021, 0.0128], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,071][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.3949, 0.4067, 0.1984], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,071][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.7897, 0.1686, 0.0417], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,071][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.1394, 0.4420, 0.4185], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,071][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.0013, 0.5912, 0.4074], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,072][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0404, 0.7215, 0.2381], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,072][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.0100, 0.4744, 0.5156], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,072][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9894, 0.0022, 0.0071, 0.0012], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,073][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3415, 0.0588, 0.5820, 0.0177], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,073][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.9028e-01, 1.6057e-03, 7.2732e-03, 8.3623e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,074][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([7.8815e-03, 1.5309e-01, 8.3893e-01, 1.0473e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,076][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9644, 0.0090, 0.0172, 0.0094], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,077][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9697, 0.0062, 0.0204, 0.0037], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,079][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8016, 0.0665, 0.1269, 0.0051], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,080][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9085, 0.0413, 0.0372, 0.0130], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,082][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0965, 0.3858, 0.3113, 0.2064], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,083][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0020, 0.6188, 0.2931, 0.0861], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,084][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.7001e-05, 5.5743e-01, 4.4251e-01, 3.4158e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,086][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0148, 0.3466, 0.3592, 0.2794], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,088][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.9510, 0.0169, 0.0193, 0.0021, 0.0108], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,089][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0419, 0.0391, 0.8061, 0.0081, 0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,091][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.9033, 0.0113, 0.0490, 0.0046, 0.0318], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,092][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([4.4616e-01, 2.9773e-02, 4.4430e-01, 4.4470e-05, 7.9728e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,092][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.8118, 0.0460, 0.0861, 0.0331, 0.0230], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,093][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([0.9217, 0.0087, 0.0420, 0.0033, 0.0243], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,093][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0925, 0.3962, 0.3562, 0.0177, 0.1374], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,093][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.5661, 0.1886, 0.0554, 0.0500, 0.1399], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,093][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0592, 0.2842, 0.2344, 0.1728, 0.2494], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,094][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([1.4656e-04, 5.9192e-01, 1.1331e-01, 5.2259e-02, 2.4236e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,094][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([9.5465e-03, 3.7946e-01, 5.7061e-01, 5.5979e-05, 4.0333e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,094][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0036, 0.2316, 0.2889, 0.2067, 0.2692], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,095][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.9170, 0.0080, 0.0375, 0.0022, 0.0148, 0.0204], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,095][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1122, 0.0359, 0.6265, 0.0166, 0.1809, 0.0279], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,095][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.9166, 0.0042, 0.0406, 0.0019, 0.0236, 0.0132], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,095][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.3271e-02, 3.0956e-01, 3.2304e-01, 2.2597e-04, 2.6693e-01, 6.9706e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,096][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8333, 0.0237, 0.0910, 0.0259, 0.0110, 0.0151], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,096][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.9352, 0.0107, 0.0237, 0.0038, 0.0145, 0.0121], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,098][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2425, 0.3549, 0.1199, 0.0210, 0.1550, 0.1067], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,100][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.7698, 0.0951, 0.0296, 0.0203, 0.0387, 0.0465], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,101][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0497, 0.2116, 0.1894, 0.1184, 0.2100, 0.2210], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,102][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.7195e-04, 3.4100e-01, 2.2480e-01, 3.2153e-02, 2.3294e-01, 1.6893e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,103][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([3.6111e-04, 8.3627e-01, 1.4789e-01, 5.7938e-05, 1.3209e-02, 2.2168e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,104][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0060, 0.2235, 0.1815, 0.1341, 0.1431, 0.3118], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,106][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.9337, 0.0079, 0.0230, 0.0011, 0.0077, 0.0166, 0.0100],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,108][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.2464, 0.0433, 0.5728, 0.0098, 0.0583, 0.0325, 0.0369],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,109][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.8676, 0.0123, 0.0673, 0.0016, 0.0231, 0.0166, 0.0116],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,110][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.2674e-01, 4.2669e-03, 4.0416e-02, 2.8970e-06, 1.4241e-02, 1.2593e-03,
        1.3074e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,112][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.9706, 0.0064, 0.0096, 0.0045, 0.0028, 0.0034, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,114][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9720, 0.0038, 0.0107, 0.0010, 0.0044, 0.0050, 0.0030],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,115][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.4650, 0.1105, 0.1767, 0.0061, 0.1477, 0.0798, 0.0143],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,115][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.7662, 0.0718, 0.0192, 0.0121, 0.0425, 0.0612, 0.0270],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,116][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0376, 0.1831, 0.1620, 0.1016, 0.1675, 0.1941, 0.1540],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,116][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.2093e-04, 5.1226e-01, 1.2343e-01, 2.0141e-02, 6.6609e-02, 1.1006e-01,
        1.6738e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,116][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([3.5692e-02, 2.0790e-01, 5.5694e-01, 2.1584e-05, 2.1323e-02, 8.9232e-03,
        1.6919e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,117][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0039, 0.1538, 0.1827, 0.0917, 0.1604, 0.2539, 0.1537],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,117][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.4530e-01, 1.7820e-03, 9.1674e-03, 4.3822e-04, 3.7610e-03, 4.2506e-03,
        3.0835e-03, 3.2213e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,117][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.3141, 0.0180, 0.4848, 0.0063, 0.0829, 0.0208, 0.0270, 0.0462],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,118][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([9.8110e-01, 6.1827e-04, 6.3441e-03, 2.4957e-04, 3.7143e-03, 2.2669e-03,
        1.7533e-03, 3.9527e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,118][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.2577e-01, 9.9853e-09, 4.3006e-05, 4.8126e-10, 1.5643e-05, 3.7637e-07,
        4.2808e-05, 3.7412e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,118][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.9741, 0.0034, 0.0076, 0.0055, 0.0022, 0.0024, 0.0022, 0.0026],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,118][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.8270e-01, 7.2021e-04, 3.5873e-03, 2.8706e-04, 1.0991e-03, 1.3781e-03,
        6.0865e-04, 9.6221e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,119][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0900, 0.4816, 0.0914, 0.0496, 0.0443, 0.0285, 0.0396, 0.1750],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,119][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.8253, 0.0298, 0.0115, 0.0086, 0.0201, 0.0256, 0.0400, 0.0392],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,121][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0453, 0.1200, 0.1176, 0.0729, 0.1282, 0.1306, 0.1048, 0.2806],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,122][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([5.1483e-05, 1.1763e-01, 5.6446e-02, 8.9972e-03, 4.5400e-02, 8.3468e-02,
        1.0553e-01, 5.8248e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,123][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([1.0451e-02, 3.0249e-07, 1.1946e-04, 1.2308e-09, 1.0927e-05, 8.0193e-07,
        1.0398e-04, 9.8931e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,125][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0015, 0.1045, 0.0945, 0.0797, 0.0843, 0.1692, 0.1315, 0.3349],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,125][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([9.8695e-01, 1.3422e-04, 1.4270e-03, 5.6380e-05, 8.4592e-04, 5.7726e-04,
        2.4199e-04, 3.7612e-03, 6.0027e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,127][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.3186, 0.0178, 0.3974, 0.0111, 0.0878, 0.0163, 0.0340, 0.0638, 0.0533],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,128][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([9.9751e-01, 4.0599e-05, 6.2831e-04, 2.8232e-05, 6.4008e-04, 1.1903e-04,
        1.2263e-04, 2.7875e-04, 6.3594e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,129][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.3962e-02, 2.3877e-09, 2.9066e-06, 2.7979e-11, 7.4198e-07, 3.4473e-08,
        2.0858e-06, 2.9338e-01, 6.1265e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,131][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.9532, 0.0037, 0.0212, 0.0057, 0.0037, 0.0022, 0.0016, 0.0011, 0.0076],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,132][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.7327e-01, 5.8794e-04, 3.5673e-03, 2.9630e-04, 1.4944e-03, 1.2057e-03,
        5.0737e-04, 5.0922e-03, 1.3979e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,133][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0299, 0.3496, 0.0326, 0.0294, 0.0671, 0.0525, 0.0426, 0.0809, 0.3154],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,135][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.6740, 0.0581, 0.0156, 0.0103, 0.0287, 0.0512, 0.0401, 0.0769, 0.0450],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,137][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0495, 0.0865, 0.0828, 0.0618, 0.1112, 0.1119, 0.0802, 0.2384, 0.1778],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,138][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0007, 0.0857, 0.0795, 0.0167, 0.0802, 0.0553, 0.0890, 0.3872, 0.2058],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,138][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([1.2428e-04, 1.2353e-08, 1.7409e-06, 1.8421e-11, 9.3642e-08, 1.9284e-08,
        1.4064e-06, 1.0684e-01, 8.9303e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,139][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0021, 0.0805, 0.0887, 0.0572, 0.0875, 0.1181, 0.0975, 0.2217, 0.2467],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,139][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.2656e-01, 8.5248e-04, 8.0711e-03, 5.8602e-04, 3.6605e-03, 4.6182e-03,
        3.1128e-03, 1.1883e-02, 3.3130e-02, 7.5253e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,139][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1286, 0.0154, 0.4455, 0.0102, 0.1226, 0.0375, 0.0456, 0.0924, 0.0796,
        0.0226], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,140][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([9.5126e-01, 9.8877e-04, 1.2295e-02, 5.4084e-04, 7.6571e-03, 3.1637e-03,
        2.8249e-03, 3.6605e-03, 1.2849e-02, 4.7547e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,140][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.3050e-06, 2.0206e-09, 7.2971e-07, 7.2934e-12, 3.1079e-07, 1.3772e-09,
        4.2853e-07, 1.8666e-01, 8.1331e-01, 2.0765e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,140][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7556, 0.0305, 0.0717, 0.0296, 0.0124, 0.0113, 0.0091, 0.0046, 0.0256,
        0.0495], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,141][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8750, 0.0021, 0.0105, 0.0013, 0.0080, 0.0040, 0.0025, 0.0187, 0.0711,
        0.0068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,141][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6345, 0.0347, 0.0384, 0.0052, 0.0478, 0.0167, 0.0269, 0.0974, 0.0835,
        0.0148], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,141][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8076, 0.0198, 0.0100, 0.0045, 0.0251, 0.0231, 0.0317, 0.0514, 0.0210,
        0.0059], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,142][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0307, 0.0870, 0.0840, 0.0558, 0.1004, 0.0955, 0.0765, 0.2126, 0.1653,
        0.0922], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,142][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([5.5079e-05, 4.8741e-02, 8.3212e-02, 7.5291e-03, 8.2971e-02, 5.0500e-02,
        8.6103e-02, 3.8979e-01, 2.1184e-01, 3.9265e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,143][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([4.8693e-08, 1.4018e-08, 7.6886e-07, 4.7574e-12, 3.0472e-08, 1.3136e-09,
        3.7623e-07, 8.4520e-02, 9.1547e-01, 6.1055e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,145][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0026, 0.0697, 0.0871, 0.0462, 0.0699, 0.1407, 0.0951, 0.2202, 0.2047,
        0.0637], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,146][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([8.7135e-01, 1.6934e-03, 1.0104e-02, 6.7995e-04, 4.1614e-03, 7.4713e-03,
        4.8297e-03, 2.1254e-02, 6.2162e-02, 9.4129e-03, 6.8857e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,147][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1444, 0.0202, 0.3851, 0.0099, 0.1129, 0.0346, 0.0495, 0.1158, 0.0769,
        0.0222, 0.0283], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,148][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.2257e-01, 1.7739e-03, 1.8922e-02, 6.2024e-04, 9.5806e-03, 4.2455e-03,
        4.4221e-03, 6.2793e-03, 2.1821e-02, 6.4913e-03, 3.2793e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,149][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.3957e-05, 9.5936e-10, 1.0615e-06, 1.6151e-12, 1.9284e-07, 1.6446e-09,
        5.0973e-07, 9.3222e-02, 9.0664e-01, 6.9204e-06, 1.0428e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,151][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.7405, 0.0252, 0.0744, 0.0241, 0.0124, 0.0110, 0.0084, 0.0054, 0.0235,
        0.0460, 0.0292], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,152][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8544, 0.0029, 0.0109, 0.0014, 0.0068, 0.0045, 0.0029, 0.0188, 0.0844,
        0.0070, 0.0058], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,154][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2040, 0.1003, 0.0496, 0.0095, 0.0320, 0.0438, 0.0263, 0.1249, 0.3559,
        0.0362, 0.0173], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,155][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.8424, 0.0135, 0.0086, 0.0021, 0.0258, 0.0194, 0.0316, 0.0313, 0.0178,
        0.0036, 0.0037], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,158][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0290, 0.0844, 0.0777, 0.0473, 0.0884, 0.0859, 0.0680, 0.1914, 0.1543,
        0.0808, 0.0928], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,159][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([4.0639e-05, 6.8633e-02, 5.9798e-02, 6.8952e-03, 6.5892e-02, 5.1112e-02,
        8.0784e-02, 4.0302e-01, 2.0233e-01, 3.5266e-02, 2.6225e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,160][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0662e-07, 6.7330e-09, 7.1085e-07, 1.0764e-12, 2.1212e-08, 1.1675e-09,
        3.2749e-07, 5.2250e-02, 9.4771e-01, 2.2641e-06, 3.3216e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,161][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0033, 0.0877, 0.0811, 0.0596, 0.0580, 0.1142, 0.0878, 0.1822, 0.1769,
        0.0797, 0.0694], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,161][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([9.1712e-01, 2.7751e-04, 1.9734e-03, 2.1730e-04, 1.1446e-03, 1.4323e-03,
        8.4259e-04, 1.3915e-02, 2.3116e-02, 2.3884e-03, 1.5695e-03, 3.6005e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,162][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.4472, 0.0074, 0.2349, 0.0044, 0.0562, 0.0109, 0.0262, 0.0574, 0.0259,
        0.0110, 0.0127, 0.1057], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,162][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([9.8591e-01, 1.2111e-04, 2.5495e-03, 1.0878e-04, 1.9800e-03, 4.4664e-04,
        3.5469e-04, 1.0145e-03, 2.3074e-03, 5.1762e-04, 3.5095e-04, 4.3346e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,162][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.9183e-01, 1.3143e-12, 5.6414e-08, 5.2306e-13, 1.3443e-08, 4.1694e-10,
        2.7449e-08, 4.7888e-04, 6.2635e-04, 2.1325e-08, 1.3502e-07, 8.0706e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,163][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.8655, 0.0104, 0.0148, 0.0100, 0.0057, 0.0043, 0.0044, 0.0060, 0.0234,
        0.0259, 0.0213, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,163][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.4512e-01, 1.9744e-04, 1.9584e-03, 2.2973e-04, 7.2960e-04, 8.7827e-04,
        4.3773e-04, 3.7971e-03, 1.0515e-02, 1.1125e-03, 7.8919e-04, 3.4237e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,163][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0207, 0.2744, 0.0163, 0.0121, 0.0476, 0.0192, 0.0166, 0.0679, 0.1642,
        0.2452, 0.0261, 0.0898], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,164][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.5459, 0.0329, 0.0108, 0.0135, 0.0331, 0.0536, 0.0510, 0.0935, 0.0225,
        0.0161, 0.0277, 0.0995], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,164][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0401, 0.0517, 0.0490, 0.0395, 0.0700, 0.0702, 0.0506, 0.1452, 0.1017,
        0.0597, 0.0731, 0.2491], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,164][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.0833e-04, 5.1146e-02, 4.5465e-02, 6.4770e-03, 3.4589e-02, 3.6475e-02,
        5.1296e-02, 4.2152e-01, 1.4816e-01, 3.7743e-02, 2.5751e-02, 1.4127e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,165][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([4.3163e-04, 2.2530e-11, 6.9271e-08, 6.5788e-13, 4.7975e-09, 6.6751e-10,
        4.4645e-08, 4.6408e-04, 2.9731e-03, 1.6781e-08, 1.6505e-07, 9.9613e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,166][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0008, 0.0730, 0.0722, 0.0450, 0.0707, 0.0966, 0.0709, 0.1710, 0.1749,
        0.0937, 0.0609, 0.0703], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,167][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([7.7455e-01, 1.8009e-03, 7.6114e-03, 3.1245e-04, 3.1792e-03, 2.7412e-03,
        9.1525e-04, 1.2402e-02, 6.7699e-02, 2.9430e-03, 2.0645e-03, 1.0628e-01,
        1.7501e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,169][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0433, 0.0086, 0.3821, 0.0034, 0.0507, 0.0194, 0.0208, 0.0533, 0.0657,
        0.0074, 0.0098, 0.1806, 0.1549], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,170][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([7.3573e-01, 1.2850e-03, 1.9886e-02, 6.0556e-04, 1.0323e-02, 4.0270e-03,
        4.6503e-03, 1.4211e-02, 6.0835e-02, 5.5209e-03, 3.9070e-03, 9.4745e-02,
        4.4278e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,170][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([6.3741e-03, 9.4015e-13, 1.4307e-08, 1.6002e-14, 9.6120e-10, 1.5781e-10,
        6.6987e-09, 1.0110e-04, 6.1293e-04, 2.9536e-09, 1.5053e-08, 7.6756e-01,
        2.2535e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,172][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.5560, 0.0355, 0.0996, 0.0267, 0.0263, 0.0198, 0.0277, 0.0101, 0.0764,
        0.0399, 0.0348, 0.0276, 0.0198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,173][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([8.4642e-01, 7.9012e-04, 7.2692e-03, 4.3262e-04, 3.3014e-03, 2.6320e-03,
        9.1677e-04, 9.9880e-03, 4.0248e-02, 2.5027e-03, 1.3841e-03, 6.6577e-02,
        1.7537e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,175][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0087, 0.1057, 0.0441, 0.0060, 0.0121, 0.0177, 0.0094, 0.1910, 0.4462,
        0.0312, 0.0204, 0.0681, 0.0395], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,176][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.3894, 0.0565, 0.0119, 0.0099, 0.0292, 0.0495, 0.0511, 0.1511, 0.0574,
        0.0275, 0.0232, 0.0749, 0.0684], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,178][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0206, 0.0439, 0.0489, 0.0272, 0.0570, 0.0590, 0.0389, 0.1291, 0.1010,
        0.0466, 0.0537, 0.2171, 0.1571], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,179][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([1.9380e-06, 1.0289e-02, 2.9563e-03, 8.3281e-04, 7.6174e-03, 9.1231e-03,
        1.1563e-02, 5.3038e-02, 3.2727e-02, 8.5794e-03, 6.6932e-03, 5.7382e-02,
        7.9920e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,180][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([3.8466e-05, 1.3841e-11, 1.4328e-08, 1.9859e-14, 4.1320e-10, 1.6143e-10,
        1.0499e-08, 7.5230e-05, 3.4016e-03, 3.7261e-09, 1.9409e-08, 8.2032e-01,
        1.7616e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,182][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0009, 0.0537, 0.0651, 0.0434, 0.0585, 0.1051, 0.0745, 0.1358, 0.1499,
        0.0750, 0.0619, 0.0613, 0.1148], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,183][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([8.5376e-01, 9.8384e-04, 9.7069e-03, 2.6680e-04, 2.4863e-03, 2.3385e-03,
        9.5575e-04, 9.6239e-03, 2.1280e-02, 3.6130e-03, 1.6891e-03, 6.0503e-02,
        9.0098e-03, 2.3783e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,184][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1746, 0.0154, 0.3690, 0.0055, 0.0470, 0.0107, 0.0153, 0.0436, 0.0340,
        0.0118, 0.0098, 0.1822, 0.0584, 0.0227], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,185][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([9.4370e-01, 4.4694e-04, 8.6463e-03, 2.7539e-04, 4.2536e-03, 1.9505e-03,
        1.1984e-03, 2.6639e-03, 9.3291e-03, 1.5612e-03, 9.7290e-04, 1.5198e-02,
        5.2623e-03, 4.5419e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,185][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([7.5278e-04, 2.2136e-10, 2.8388e-08, 7.2490e-13, 1.0620e-08, 1.0021e-09,
        1.1873e-08, 1.3965e-04, 2.5688e-03, 1.1154e-07, 2.9367e-07, 6.7166e-01,
        3.2452e-01, 3.5661e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,185][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.8421, 0.0093, 0.0314, 0.0155, 0.0068, 0.0076, 0.0092, 0.0039, 0.0143,
        0.0206, 0.0168, 0.0072, 0.0023, 0.0130], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,186][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([8.8084e-01, 1.3123e-03, 4.7919e-03, 7.8842e-04, 2.0829e-03, 2.7714e-03,
        1.1051e-03, 9.6458e-03, 2.2232e-02, 2.9858e-03, 1.7604e-03, 4.0972e-02,
        5.5340e-03, 2.3177e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,186][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0171, 0.0924, 0.0157, 0.0086, 0.0284, 0.0213, 0.0240, 0.1657, 0.2953,
        0.0511, 0.0181, 0.0405, 0.0690, 0.1528], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,186][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.4430, 0.0309, 0.0089, 0.0042, 0.0295, 0.0290, 0.0284, 0.0768, 0.0378,
        0.0117, 0.0113, 0.0743, 0.0931, 0.1211], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,187][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0224, 0.0464, 0.0481, 0.0295, 0.0558, 0.0577, 0.0429, 0.1137, 0.0917,
        0.0462, 0.0550, 0.1815, 0.1302, 0.0789], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,187][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([9.7942e-06, 3.1736e-02, 1.8370e-02, 9.8789e-04, 1.0148e-02, 3.8896e-03,
        7.1257e-03, 3.9908e-02, 4.1193e-02, 7.9871e-03, 4.5911e-03, 7.4377e-02,
        7.4624e-01, 1.3439e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,187][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([1.8147e-06, 1.6455e-09, 3.6269e-08, 6.7154e-13, 1.9184e-09, 1.0818e-09,
        1.8299e-08, 1.8176e-04, 1.0092e-02, 9.5827e-08, 2.9867e-07, 8.4534e-01,
        1.4311e-01, 1.2793e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,188][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0007, 0.0507, 0.0496, 0.0322, 0.0382, 0.0995, 0.0621, 0.1814, 0.1264,
        0.0647, 0.0481, 0.0596, 0.0791, 0.1077], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,188][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.6977e-01, 1.4066e-03, 7.9060e-03, 2.1624e-04, 2.6490e-03, 2.7744e-03,
        8.3652e-04, 1.0117e-02, 6.6547e-02, 4.5037e-03, 2.1924e-03, 7.3379e-02,
        1.1564e-02, 3.9778e-02, 6.3645e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,190][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1876, 0.0114, 0.1972, 0.0026, 0.0443, 0.0104, 0.0187, 0.0451, 0.0649,
        0.0094, 0.0102, 0.2153, 0.0983, 0.0400, 0.0447], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,191][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.4478e-01, 1.7625e-03, 1.9901e-02, 3.2772e-04, 8.8596e-03, 2.9925e-03,
        1.9867e-03, 5.7109e-03, 3.8492e-02, 3.6324e-03, 1.8347e-03, 3.6320e-02,
        1.7312e-02, 1.0940e-02, 5.1481e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,192][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.2789e-03, 2.4276e-10, 1.5995e-07, 8.7037e-13, 2.4982e-08, 2.5635e-09,
        3.1346e-08, 7.5560e-05, 3.6329e-03, 7.1218e-08, 2.8513e-07, 4.5887e-01,
        5.3285e-01, 1.6526e-03, 6.3900e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,194][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8990, 0.0048, 0.0163, 0.0082, 0.0044, 0.0040, 0.0034, 0.0032, 0.0104,
        0.0136, 0.0106, 0.0061, 0.0018, 0.0074, 0.0068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,195][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.4922e-01, 1.1573e-03, 5.4557e-03, 3.9024e-04, 3.0035e-03, 2.2017e-03,
        7.5639e-04, 8.7947e-03, 3.4119e-02, 2.3047e-03, 1.4194e-03, 4.9562e-02,
        1.1802e-02, 2.5549e-02, 4.2692e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,196][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0716, 0.0587, 0.0400, 0.0058, 0.0405, 0.0443, 0.0212, 0.0789, 0.2441,
        0.0318, 0.0140, 0.0954, 0.0930, 0.1403, 0.0205], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,198][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6896, 0.0340, 0.0103, 0.0041, 0.0242, 0.0281, 0.0245, 0.0327, 0.0107,
        0.0066, 0.0061, 0.0317, 0.0554, 0.0313, 0.0107], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,199][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0162, 0.0470, 0.0389, 0.0267, 0.0439, 0.0511, 0.0383, 0.1064, 0.0879,
        0.0456, 0.0546, 0.1646, 0.1227, 0.0721, 0.0839], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,200][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.2609e-06, 2.4793e-02, 9.2492e-03, 1.0261e-03, 1.0225e-02, 1.0834e-02,
        1.9417e-02, 1.1319e-01, 9.0297e-02, 1.1111e-02, 7.1704e-03, 5.5752e-02,
        6.0425e-01, 2.0111e-02, 2.2560e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,201][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.1803e-05, 1.8045e-09, 1.8865e-07, 6.1521e-13, 5.0467e-09, 1.9596e-09,
        4.0574e-08, 1.8210e-04, 1.4500e-02, 6.1844e-08, 2.8433e-07, 6.8767e-01,
        2.9273e-01, 4.1021e-03, 7.9503e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,203][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0017, 0.0590, 0.0642, 0.0363, 0.0483, 0.0805, 0.0587, 0.1385, 0.1234,
        0.0557, 0.0449, 0.0521, 0.0814, 0.0936, 0.0617], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,243][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:06,245][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,246][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,247][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,248][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,249][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,249][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,249][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,249][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,250][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,250][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,250][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,252][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,254][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.9982e-01, 1.7771e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,255][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9531, 0.0469], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,256][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.9997e-01, 3.1687e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,257][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6813, 0.3187], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,257][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9929, 0.0071], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,258][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,258][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0933, 0.9067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,258][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9446, 0.0554], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,259][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,259][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,259][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0028, 0.9972], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,260][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9189, 0.0811], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,260][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([9.9764e-01, 8.2886e-04, 1.5296e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,260][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.1395, 0.0393, 0.8212], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,261][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([9.9487e-01, 9.4104e-04, 4.1855e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,261][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.9604, 0.0059, 0.0336], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,263][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.9775, 0.0083, 0.0142], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,265][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.9851, 0.0021, 0.0128], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,266][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.0124, 0.5445, 0.4431], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,267][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.8227, 0.1360, 0.0414], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,269][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.9603, 0.0118, 0.0279], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,271][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.0013, 0.5912, 0.4074], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,272][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0404, 0.7215, 0.2381], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,273][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.2995, 0.3501, 0.3503], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,275][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9894, 0.0022, 0.0071, 0.0012], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,277][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.3415, 0.0588, 0.5820, 0.0177], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,278][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.9028e-01, 1.6057e-03, 7.2732e-03, 8.3623e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,279][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([7.8815e-03, 1.5309e-01, 8.3893e-01, 1.0473e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,280][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9644, 0.0090, 0.0172, 0.0094], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,280][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.9697, 0.0062, 0.0204, 0.0037], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,281][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0172, 0.5747, 0.3627, 0.0455], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,281][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4156, 0.2002, 0.3767, 0.0074], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,281][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9713, 0.0117, 0.0155, 0.0015], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,282][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0020, 0.6188, 0.2931, 0.0861], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,282][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([2.7001e-05, 5.5743e-01, 4.4251e-01, 3.4158e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,282][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3699, 0.1117, 0.4459, 0.0724], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,283][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.9510, 0.0169, 0.0193, 0.0021, 0.0108], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,283][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0419, 0.0391, 0.8061, 0.0081, 0.1048], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,283][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.9033, 0.0113, 0.0490, 0.0046, 0.0318], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,284][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([4.4616e-01, 2.9773e-02, 4.4430e-01, 4.4470e-05, 7.9728e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,285][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.8118, 0.0460, 0.0861, 0.0331, 0.0230], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,286][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([0.9217, 0.0087, 0.0420, 0.0033, 0.0243], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,288][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0010, 0.6230, 0.2670, 0.0427, 0.0663], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,290][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.4780, 0.2570, 0.2346, 0.0032, 0.0272], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,291][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.6554, 0.1291, 0.1654, 0.0138, 0.0363], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,292][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([1.4656e-04, 5.9192e-01, 1.1331e-01, 5.2259e-02, 2.4236e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,293][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([9.5465e-03, 3.7946e-01, 5.7061e-01, 5.5979e-05, 4.0333e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,295][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1199, 0.3800, 0.1946, 0.0973, 0.2082], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,296][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.9170, 0.0080, 0.0375, 0.0022, 0.0148, 0.0204], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,297][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1122, 0.0359, 0.6265, 0.0166, 0.1809, 0.0279], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,300][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.9166, 0.0042, 0.0406, 0.0019, 0.0236, 0.0132], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,301][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([9.3271e-02, 3.0956e-01, 3.2304e-01, 2.2597e-04, 2.6693e-01, 6.9706e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,302][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.8333, 0.0237, 0.0910, 0.0259, 0.0110, 0.0151], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,303][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.9352, 0.0107, 0.0237, 0.0038, 0.0145, 0.0121], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,303][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0035, 0.4222, 0.3259, 0.0282, 0.1235, 0.0968], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,304][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1968, 0.3780, 0.3457, 0.0031, 0.0590, 0.0174], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,304][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8318, 0.0351, 0.0874, 0.0032, 0.0242, 0.0182], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,305][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.7195e-04, 3.4100e-01, 2.2480e-01, 3.2153e-02, 2.3294e-01, 1.6893e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,305][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([3.6111e-04, 8.3627e-01, 1.4789e-01, 5.7938e-05, 1.3209e-02, 2.2168e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,305][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1329, 0.1681, 0.2131, 0.0598, 0.2124, 0.2136], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,306][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.9337, 0.0079, 0.0230, 0.0011, 0.0077, 0.0166, 0.0100],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,306][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2464, 0.0433, 0.5728, 0.0098, 0.0583, 0.0325, 0.0369],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,306][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.8676, 0.0123, 0.0673, 0.0016, 0.0231, 0.0166, 0.0116],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,307][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.2674e-01, 4.2669e-03, 4.0416e-02, 2.8970e-06, 1.4241e-02, 1.2593e-03,
        1.3074e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,307][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9706, 0.0064, 0.0096, 0.0045, 0.0028, 0.0034, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,309][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9720, 0.0038, 0.0107, 0.0010, 0.0044, 0.0050, 0.0030],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,311][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0036, 0.6613, 0.1860, 0.0208, 0.0470, 0.0453, 0.0360],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,312][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.4216, 0.2917, 0.2160, 0.0014, 0.0232, 0.0115, 0.0347],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,314][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8599, 0.0439, 0.0599, 0.0021, 0.0074, 0.0190, 0.0078],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,315][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2093e-04, 5.1226e-01, 1.2343e-01, 2.0141e-02, 6.6609e-02, 1.1006e-01,
        1.6738e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,316][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.5692e-02, 2.0790e-01, 5.5694e-01, 2.1584e-05, 2.1323e-02, 8.9232e-03,
        1.6919e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,318][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3350, 0.1113, 0.1600, 0.0356, 0.0827, 0.0918, 0.1835],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,319][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([9.4530e-01, 1.7820e-03, 9.1674e-03, 4.3822e-04, 3.7610e-03, 4.2506e-03,
        3.0835e-03, 3.2213e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,321][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3141, 0.0180, 0.4848, 0.0063, 0.0829, 0.0208, 0.0270, 0.0462],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,322][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([9.8110e-01, 6.1827e-04, 6.3441e-03, 2.4957e-04, 3.7143e-03, 2.2669e-03,
        1.7533e-03, 3.9527e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,323][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.2577e-01, 9.9853e-09, 4.3006e-05, 4.8126e-10, 1.5643e-05, 3.7637e-07,
        4.2808e-05, 3.7412e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,324][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.9741, 0.0034, 0.0076, 0.0055, 0.0022, 0.0024, 0.0022, 0.0026],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,325][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([9.8270e-01, 7.2021e-04, 3.5873e-03, 2.8706e-04, 1.0991e-03, 1.3781e-03,
        6.0865e-04, 9.6221e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,327][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0037, 0.4070, 0.2642, 0.0219, 0.0774, 0.0476, 0.0506, 0.1276],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,328][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([7.0043e-01, 7.8992e-03, 3.8151e-02, 1.5927e-04, 5.2611e-03, 9.7537e-04,
        5.9511e-03, 2.4117e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,329][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([9.2277e-01, 1.0078e-02, 4.7101e-02, 8.0475e-04, 6.0833e-03, 4.8133e-03,
        2.7981e-03, 5.5529e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,330][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([5.1483e-05, 1.1763e-01, 5.6446e-02, 8.9972e-03, 4.5400e-02, 8.3468e-02,
        1.0553e-01, 5.8248e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,331][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([1.0451e-02, 3.0249e-07, 1.1946e-04, 1.2308e-09, 1.0927e-05, 8.0193e-07,
        1.0398e-04, 9.8931e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,332][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3690, 0.0637, 0.0926, 0.0265, 0.0619, 0.0695, 0.1937, 0.1231],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,332][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([9.8695e-01, 1.3422e-04, 1.4270e-03, 5.6380e-05, 8.4592e-04, 5.7726e-04,
        2.4199e-04, 3.7612e-03, 6.0027e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,332][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.3186, 0.0178, 0.3974, 0.0111, 0.0878, 0.0163, 0.0340, 0.0638, 0.0533],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,333][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([9.9751e-01, 4.0599e-05, 6.2831e-04, 2.8232e-05, 6.4008e-04, 1.1903e-04,
        1.2263e-04, 2.7875e-04, 6.3594e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,333][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([9.3962e-02, 2.3877e-09, 2.9066e-06, 2.7979e-11, 7.4198e-07, 3.4473e-08,
        2.0858e-06, 2.9338e-01, 6.1265e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,333][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.9532, 0.0037, 0.0212, 0.0057, 0.0037, 0.0022, 0.0016, 0.0011, 0.0076],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,334][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([9.7327e-01, 5.8794e-04, 3.5673e-03, 2.9630e-04, 1.4944e-03, 1.2057e-03,
        5.0737e-04, 5.0922e-03, 1.3979e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,334][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0131, 0.2348, 0.2443, 0.0299, 0.0745, 0.0421, 0.0361, 0.0843, 0.2408],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,335][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([4.2125e-01, 3.8285e-03, 6.8908e-03, 3.4748e-05, 1.2784e-03, 4.3606e-04,
        1.0636e-03, 8.6238e-02, 4.7898e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,335][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.5388e-01, 4.2454e-03, 1.1567e-02, 7.8696e-04, 4.5602e-03, 3.7444e-03,
        1.2749e-03, 3.9178e-03, 1.6025e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,337][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0007, 0.0857, 0.0795, 0.0167, 0.0802, 0.0553, 0.0890, 0.3872, 0.2058],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,337][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([1.2428e-04, 1.2353e-08, 1.7409e-06, 1.8421e-11, 9.3642e-08, 1.9284e-08,
        1.4064e-06, 1.0684e-01, 8.9303e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,339][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.2611, 0.0518, 0.0888, 0.0327, 0.0894, 0.0758, 0.1473, 0.1478, 0.1054],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,340][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([9.2656e-01, 8.5248e-04, 8.0711e-03, 5.8602e-04, 3.6605e-03, 4.6182e-03,
        3.1128e-03, 1.1883e-02, 3.3130e-02, 7.5253e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,342][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1286, 0.0154, 0.4455, 0.0102, 0.1226, 0.0375, 0.0456, 0.0924, 0.0796,
        0.0226], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,342][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.5126e-01, 9.8877e-04, 1.2295e-02, 5.4084e-04, 7.6571e-03, 3.1637e-03,
        2.8249e-03, 3.6605e-03, 1.2849e-02, 4.7547e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,344][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.3050e-06, 2.0206e-09, 7.2971e-07, 7.2934e-12, 3.1079e-07, 1.3772e-09,
        4.2853e-07, 1.8666e-01, 8.1331e-01, 2.0765e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,345][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7556, 0.0305, 0.0717, 0.0296, 0.0124, 0.0113, 0.0091, 0.0046, 0.0256,
        0.0495], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,347][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8750, 0.0021, 0.0105, 0.0013, 0.0080, 0.0040, 0.0025, 0.0187, 0.0711,
        0.0068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,349][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0021, 0.1456, 0.2756, 0.0120, 0.0491, 0.0279, 0.0260, 0.0582, 0.3603,
        0.0432], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,350][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([4.2704e-02, 2.9717e-03, 1.5052e-02, 7.4397e-05, 3.5029e-03, 5.0183e-04,
        3.0091e-03, 2.1303e-01, 7.1357e-01, 5.5821e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,352][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8497, 0.0166, 0.0383, 0.0029, 0.0132, 0.0088, 0.0051, 0.0145, 0.0364,
        0.0146], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,353][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.5079e-05, 4.8741e-02, 8.3212e-02, 7.5291e-03, 8.2971e-02, 5.0500e-02,
        8.6103e-02, 3.8979e-01, 2.1184e-01, 3.9265e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,353][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.8693e-08, 1.4018e-08, 7.6886e-07, 4.7574e-12, 3.0472e-08, 1.3136e-09,
        3.7623e-07, 8.4520e-02, 9.1547e-01, 6.1055e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,354][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1699, 0.0342, 0.1706, 0.0303, 0.1353, 0.1086, 0.1069, 0.1484, 0.0440,
        0.0518], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,354][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([8.7135e-01, 1.6934e-03, 1.0104e-02, 6.7995e-04, 4.1614e-03, 7.4713e-03,
        4.8297e-03, 2.1254e-02, 6.2162e-02, 9.4129e-03, 6.8857e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,355][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1444, 0.0202, 0.3851, 0.0099, 0.1129, 0.0346, 0.0495, 0.1158, 0.0769,
        0.0222, 0.0283], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,355][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.2257e-01, 1.7739e-03, 1.8922e-02, 6.2024e-04, 9.5806e-03, 4.2455e-03,
        4.4221e-03, 6.2793e-03, 2.1821e-02, 6.4913e-03, 3.2793e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,356][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.3957e-05, 9.5936e-10, 1.0615e-06, 1.6151e-12, 1.9284e-07, 1.6446e-09,
        5.0973e-07, 9.3222e-02, 9.0664e-01, 6.9204e-06, 1.0428e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,356][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7405, 0.0252, 0.0744, 0.0241, 0.0124, 0.0110, 0.0084, 0.0054, 0.0235,
        0.0460, 0.0292], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,356][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8544, 0.0029, 0.0109, 0.0014, 0.0068, 0.0045, 0.0029, 0.0188, 0.0844,
        0.0070, 0.0058], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,357][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0016, 0.1556, 0.2203, 0.0106, 0.0399, 0.0295, 0.0284, 0.0698, 0.3691,
        0.0418, 0.0334], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,357][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([5.5539e-02, 3.1292e-03, 1.4879e-02, 4.5940e-05, 2.3850e-03, 4.7712e-04,
        2.8928e-03, 1.7242e-01, 7.3796e-01, 4.1507e-03, 6.1191e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,358][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.8536, 0.0184, 0.0344, 0.0019, 0.0105, 0.0077, 0.0042, 0.0118, 0.0360,
        0.0137, 0.0079], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,358][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.0639e-05, 6.8633e-02, 5.9798e-02, 6.8952e-03, 6.5892e-02, 5.1112e-02,
        8.0784e-02, 4.0302e-01, 2.0233e-01, 3.5266e-02, 2.6225e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,360][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.0662e-07, 6.7330e-09, 7.1085e-07, 1.0764e-12, 2.1212e-08, 1.1675e-09,
        3.2749e-07, 5.2250e-02, 9.4771e-01, 2.2641e-06, 3.3216e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,361][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1406, 0.0468, 0.1805, 0.0249, 0.1293, 0.1070, 0.1180, 0.1145, 0.0326,
        0.0523, 0.0535], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,362][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([9.1712e-01, 2.7751e-04, 1.9734e-03, 2.1730e-04, 1.1446e-03, 1.4323e-03,
        8.4259e-04, 1.3915e-02, 2.3116e-02, 2.3884e-03, 1.5695e-03, 3.6005e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,364][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.4472, 0.0074, 0.2349, 0.0044, 0.0562, 0.0109, 0.0262, 0.0574, 0.0259,
        0.0110, 0.0127, 0.1057], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,365][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([9.8591e-01, 1.2111e-04, 2.5495e-03, 1.0878e-04, 1.9800e-03, 4.4664e-04,
        3.5469e-04, 1.0145e-03, 2.3074e-03, 5.1762e-04, 3.5095e-04, 4.3346e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,366][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.9183e-01, 1.3143e-12, 5.6414e-08, 5.2306e-13, 1.3443e-08, 4.1694e-10,
        2.7449e-08, 4.7888e-04, 6.2635e-04, 2.1325e-08, 1.3502e-07, 8.0706e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,368][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.8655, 0.0104, 0.0148, 0.0100, 0.0057, 0.0043, 0.0044, 0.0060, 0.0234,
        0.0259, 0.0213, 0.0083], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,369][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.4512e-01, 1.9744e-04, 1.9584e-03, 2.2973e-04, 7.2960e-04, 8.7827e-04,
        4.3773e-04, 3.7971e-03, 1.0515e-02, 1.1125e-03, 7.8919e-04, 3.4237e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,370][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0018, 0.0942, 0.1480, 0.0158, 0.0394, 0.0269, 0.0409, 0.0780, 0.2677,
        0.0616, 0.0502, 0.1754], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,371][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([4.9103e-01, 2.6016e-04, 3.2827e-03, 1.4362e-05, 5.4879e-04, 1.2963e-04,
        4.8391e-04, 1.6507e-02, 5.1182e-02, 6.1248e-04, 4.6160e-04, 4.3549e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,373][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.8623, 0.0072, 0.0172, 0.0020, 0.0070, 0.0064, 0.0024, 0.0059, 0.0174,
        0.0069, 0.0040, 0.0612], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,374][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.0833e-04, 5.1146e-02, 4.5465e-02, 6.4770e-03, 3.4589e-02, 3.6475e-02,
        5.1296e-02, 4.2152e-01, 1.4816e-01, 3.7743e-02, 2.5751e-02, 1.4127e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,375][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([4.3163e-04, 2.2530e-11, 6.9271e-08, 6.5788e-13, 4.7975e-09, 6.6751e-10,
        4.4645e-08, 4.6408e-04, 2.9731e-03, 1.6781e-08, 1.6505e-07, 9.9613e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,377][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.2648, 0.0514, 0.1121, 0.0207, 0.0695, 0.0641, 0.0793, 0.0792, 0.0355,
        0.0383, 0.0380, 0.1472], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,377][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([7.7455e-01, 1.8009e-03, 7.6114e-03, 3.1245e-04, 3.1792e-03, 2.7412e-03,
        9.1525e-04, 1.2402e-02, 6.7699e-02, 2.9430e-03, 2.0645e-03, 1.0628e-01,
        1.7501e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,378][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0433, 0.0086, 0.3821, 0.0034, 0.0507, 0.0194, 0.0208, 0.0533, 0.0657,
        0.0074, 0.0098, 0.1806, 0.1549], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,378][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([7.3573e-01, 1.2850e-03, 1.9886e-02, 6.0556e-04, 1.0323e-02, 4.0270e-03,
        4.6503e-03, 1.4211e-02, 6.0835e-02, 5.5209e-03, 3.9070e-03, 9.4745e-02,
        4.4278e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,379][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([6.3741e-03, 9.4015e-13, 1.4307e-08, 1.6002e-14, 9.6120e-10, 1.5781e-10,
        6.6987e-09, 1.0110e-04, 6.1293e-04, 2.9536e-09, 1.5053e-08, 7.6756e-01,
        2.2535e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,379][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.5560, 0.0355, 0.0996, 0.0267, 0.0263, 0.0198, 0.0277, 0.0101, 0.0764,
        0.0399, 0.0348, 0.0276, 0.0198], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,379][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([8.4642e-01, 7.9012e-04, 7.2692e-03, 4.3262e-04, 3.3014e-03, 2.6320e-03,
        9.1677e-04, 9.9880e-03, 4.0248e-02, 2.5027e-03, 1.3841e-03, 6.6577e-02,
        1.7537e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,380][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([2.1926e-04, 7.7968e-02, 6.5097e-02, 5.5109e-03, 1.2634e-02, 2.6538e-02,
        1.6207e-02, 3.2492e-02, 1.9136e-01, 2.9963e-02, 2.6213e-02, 2.0010e-01,
        3.1570e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,380][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([8.4124e-02, 3.7087e-04, 1.5848e-03, 2.1060e-06, 9.5216e-05, 7.6514e-05,
        2.8114e-04, 8.1125e-03, 4.6349e-02, 2.4158e-04, 1.7104e-04, 7.9953e-01,
        5.9062e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,381][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.5650, 0.0227, 0.0703, 0.0016, 0.0107, 0.0152, 0.0031, 0.0159, 0.1109,
        0.0109, 0.0048, 0.1318, 0.0372], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,381][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([1.9380e-06, 1.0289e-02, 2.9563e-03, 8.3281e-04, 7.6174e-03, 9.1231e-03,
        1.1563e-02, 5.3038e-02, 3.2727e-02, 8.5794e-03, 6.6932e-03, 5.7382e-02,
        7.9920e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,382][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([3.8466e-05, 1.3841e-11, 1.4328e-08, 1.9859e-14, 4.1320e-10, 1.6143e-10,
        1.0499e-08, 7.5230e-05, 3.4016e-03, 3.7261e-09, 1.9409e-08, 8.2032e-01,
        1.7616e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,384][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.1731, 0.0833, 0.0657, 0.0186, 0.0740, 0.0580, 0.0970, 0.0830, 0.0426,
        0.0346, 0.0272, 0.1121, 0.1307], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,385][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([8.5376e-01, 9.8384e-04, 9.7069e-03, 2.6680e-04, 2.4863e-03, 2.3385e-03,
        9.5575e-04, 9.6239e-03, 2.1280e-02, 3.6130e-03, 1.6891e-03, 6.0503e-02,
        9.0098e-03, 2.3783e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,387][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1746, 0.0154, 0.3690, 0.0055, 0.0470, 0.0107, 0.0153, 0.0436, 0.0340,
        0.0118, 0.0098, 0.1822, 0.0584, 0.0227], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,388][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([9.4370e-01, 4.4694e-04, 8.6463e-03, 2.7539e-04, 4.2536e-03, 1.9505e-03,
        1.1984e-03, 2.6639e-03, 9.3291e-03, 1.5612e-03, 9.7290e-04, 1.5198e-02,
        5.2623e-03, 4.5419e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,389][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([7.5278e-04, 2.2136e-10, 2.8388e-08, 7.2490e-13, 1.0620e-08, 1.0021e-09,
        1.1873e-08, 1.3965e-04, 2.5688e-03, 1.1154e-07, 2.9367e-07, 6.7166e-01,
        3.2452e-01, 3.5661e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,391][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.8421, 0.0093, 0.0314, 0.0155, 0.0068, 0.0076, 0.0092, 0.0039, 0.0143,
        0.0206, 0.0168, 0.0072, 0.0023, 0.0130], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,392][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([8.8084e-01, 1.3123e-03, 4.7919e-03, 7.8842e-04, 2.0829e-03, 2.7714e-03,
        1.1051e-03, 9.6458e-03, 2.2232e-02, 2.9858e-03, 1.7604e-03, 4.0972e-02,
        5.5340e-03, 2.3177e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,393][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0008, 0.0837, 0.0921, 0.0047, 0.0221, 0.0131, 0.0093, 0.0266, 0.1100,
        0.0265, 0.0195, 0.1773, 0.2878, 0.1265], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,394][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.9882e-02, 1.0928e-03, 2.1985e-03, 9.9769e-06, 3.4363e-04, 1.6952e-04,
        3.8491e-04, 1.2501e-02, 9.4304e-02, 8.5089e-04, 6.7755e-04, 6.7127e-01,
        1.5870e-01, 2.7617e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,395][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([8.8582e-01, 7.9867e-03, 2.3792e-02, 7.6593e-04, 4.5482e-03, 4.0275e-03,
        1.4694e-03, 3.8568e-03, 1.9445e-02, 3.3362e-03, 1.7358e-03, 2.3461e-02,
        4.1631e-03, 1.5595e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,397][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([9.7942e-06, 3.1736e-02, 1.8370e-02, 9.8789e-04, 1.0148e-02, 3.8896e-03,
        7.1257e-03, 3.9908e-02, 4.1193e-02, 7.9871e-03, 4.5911e-03, 7.4377e-02,
        7.4624e-01, 1.3439e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,398][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([1.8147e-06, 1.6455e-09, 3.6269e-08, 6.7154e-13, 1.9184e-09, 1.0818e-09,
        1.8299e-08, 1.8176e-04, 1.0092e-02, 9.5827e-08, 2.9867e-07, 8.4534e-01,
        1.4311e-01, 1.2793e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,399][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2694, 0.0440, 0.0802, 0.0174, 0.0696, 0.0497, 0.0746, 0.0715, 0.0233,
        0.0290, 0.0240, 0.1147, 0.0950, 0.0376], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,400][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.6977e-01, 1.4066e-03, 7.9060e-03, 2.1624e-04, 2.6490e-03, 2.7744e-03,
        8.3652e-04, 1.0117e-02, 6.6547e-02, 4.5037e-03, 2.1924e-03, 7.3379e-02,
        1.1564e-02, 3.9778e-02, 6.3645e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,401][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1876, 0.0114, 0.1972, 0.0026, 0.0443, 0.0104, 0.0187, 0.0451, 0.0649,
        0.0094, 0.0102, 0.2153, 0.0983, 0.0400, 0.0447], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,401][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.4478e-01, 1.7625e-03, 1.9901e-02, 3.2772e-04, 8.8596e-03, 2.9925e-03,
        1.9867e-03, 5.7109e-03, 3.8492e-02, 3.6324e-03, 1.8347e-03, 3.6320e-02,
        1.7312e-02, 1.0940e-02, 5.1481e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,402][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.2789e-03, 2.4276e-10, 1.5995e-07, 8.7037e-13, 2.4982e-08, 2.5635e-09,
        3.1346e-08, 7.5560e-05, 3.6329e-03, 7.1218e-08, 2.8513e-07, 4.5887e-01,
        5.3285e-01, 1.6526e-03, 6.3900e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,402][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8990, 0.0048, 0.0163, 0.0082, 0.0044, 0.0040, 0.0034, 0.0032, 0.0104,
        0.0136, 0.0106, 0.0061, 0.0018, 0.0074, 0.0068], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,402][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([8.4922e-01, 1.1573e-03, 5.4557e-03, 3.9024e-04, 3.0035e-03, 2.2017e-03,
        7.5639e-04, 8.7947e-03, 3.4119e-02, 2.3047e-03, 1.4194e-03, 4.9562e-02,
        1.1802e-02, 2.5549e-02, 4.2692e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,403][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0004, 0.0915, 0.0655, 0.0035, 0.0155, 0.0123, 0.0119, 0.0351, 0.2094,
        0.0191, 0.0156, 0.1068, 0.2201, 0.1282, 0.0651], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,403][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([6.4460e-02, 2.5479e-03, 4.5494e-03, 1.2758e-05, 4.4713e-04, 1.7966e-04,
        5.4400e-04, 1.5358e-02, 1.5670e-01, 9.3963e-04, 7.7622e-04, 5.2354e-01,
        1.7611e-01, 4.4425e-02, 9.4185e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,404][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7287, 0.0216, 0.0392, 0.0009, 0.0053, 0.0051, 0.0024, 0.0086, 0.0638,
        0.0089, 0.0037, 0.0456, 0.0124, 0.0466, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,404][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.2609e-06, 2.4793e-02, 9.2492e-03, 1.0261e-03, 1.0225e-02, 1.0834e-02,
        1.9417e-02, 1.1319e-01, 9.0297e-02, 1.1111e-02, 7.1704e-03, 5.5752e-02,
        6.0425e-01, 2.0111e-02, 2.2560e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,406][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.1803e-05, 1.8045e-09, 1.8865e-07, 6.1521e-13, 5.0467e-09, 1.9596e-09,
        4.0574e-08, 1.8210e-04, 1.4500e-02, 6.1844e-08, 2.8433e-07, 6.8767e-01,
        2.9273e-01, 4.1021e-03, 7.9503e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,408][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2156, 0.0329, 0.1352, 0.0127, 0.0854, 0.0435, 0.0575, 0.0659, 0.0184,
        0.0243, 0.0194, 0.0880, 0.0876, 0.0309, 0.0828], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,409][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:06,411][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 7551],
        [10129],
        [    2],
        [ 9006],
        [ 1514],
        [ 1886],
        [14011],
        [ 6965],
        [ 5167],
        [ 8754],
        [11752],
        [21906],
        [ 4470],
        [10086],
        [12256]], device='cuda:0')
[2024-07-24 10:17:06,413][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 4049],
        [14595],
        [    5],
        [ 9352],
        [ 2349],
        [ 3553],
        [17544],
        [ 8634],
        [ 8388],
        [10694],
        [15051],
        [26460],
        [ 5837],
        [15265],
        [17731]], device='cuda:0')
[2024-07-24 10:17:06,414][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40617],
        [40610],
        [40796],
        [41479],
        [41452],
        [42741],
        [42323],
        [40874],
        [41209],
        [42495],
        [41673],
        [39620],
        [32775],
        [35355],
        [33309]], device='cuda:0')
[2024-07-24 10:17:06,416][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27898],
        [25381],
        [12017],
        [12228],
        [12648],
        [13281],
        [12343],
        [11909],
        [12975],
        [12875],
        [12423],
        [11295],
        [13342],
        [11988],
        [14697]], device='cuda:0')
[2024-07-24 10:17:06,417][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13872],
        [13870],
        [14959],
        [15888],
        [39100],
        [34934],
        [39789],
        [16453],
        [14059],
        [15770],
        [15745],
        [14429],
        [17925],
        [15158],
        [14787]], device='cuda:0')
[2024-07-24 10:17:06,419][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29342],
        [30868],
        [31491],
        [46806],
        [46419],
        [44181],
        [33021],
        [38330],
        [39249],
        [38676],
        [38134],
        [41629],
        [42230],
        [42246],
        [42079]], device='cuda:0')
[2024-07-24 10:17:06,420][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[21885],
        [21838],
        [20505],
        [20641],
        [17455],
        [17730],
        [21199],
        [20953],
        [20342],
        [18016],
        [17004],
        [18397],
        [16355],
        [17280],
        [18305]], device='cuda:0')
[2024-07-24 10:17:06,422][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45751],
        [45783],
        [45349],
        [44986],
        [43205],
        [44578],
        [45435],
        [45733],
        [46118],
        [44269],
        [43454],
        [43004],
        [37460],
        [41743],
        [40430]], device='cuda:0')
[2024-07-24 10:17:06,423][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[35462],
        [32946],
        [ 2412],
        [  509],
        [ 1424],
        [18564],
        [ 6673],
        [22577],
        [19399],
        [24490],
        [13563],
        [20670],
        [14474],
        [26801],
        [24501]], device='cuda:0')
[2024-07-24 10:17:06,425][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[1203],
        [ 718],
        [ 891],
        [ 870],
        [1055],
        [ 575],
        [ 483],
        [ 601],
        [ 944],
        [ 645],
        [ 529],
        [1326],
        [1392],
        [1079],
        [ 528]], device='cuda:0')
[2024-07-24 10:17:06,426][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[49702],
        [45287],
        [50160],
        [50111],
        [49979],
        [49828],
        [49784],
        [49734],
        [49518],
        [49522],
        [49604],
        [49645],
        [49563],
        [49514],
        [49474]], device='cuda:0')
[2024-07-24 10:17:06,427][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[47833],
        [45400],
        [50249],
        [50212],
        [46999],
        [48815],
        [47979],
        [35516],
        [34522],
        [34338],
        [31896],
        [30343],
        [10187],
        [12201],
        [11799]], device='cuda:0')
[2024-07-24 10:17:06,428][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[23370],
        [10546],
        [10227],
        [10270],
        [10575],
        [10317],
        [10815],
        [16918],
        [24139],
        [24307],
        [24590],
        [29426],
        [26788],
        [27307],
        [24785]], device='cuda:0')
[2024-07-24 10:17:06,428][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23125],
        [11051],
        [ 2834],
        [ 2989],
        [ 1858],
        [ 5096],
        [ 4356],
        [ 6876],
        [ 7667],
        [ 7980],
        [ 7567],
        [ 7558],
        [ 6376],
        [ 8082],
        [ 7492]], device='cuda:0')
[2024-07-24 10:17:06,430][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[38038],
        [ 9237],
        [ 6577],
        [11501],
        [10527],
        [10174],
        [12908],
        [15621],
        [10341],
        [12520],
        [16520],
        [12491],
        [17669],
        [13934],
        [14152]], device='cuda:0')
[2024-07-24 10:17:06,432][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 2070],
        [ 2071],
        [ 2070],
        [ 2056],
        [ 3894],
        [ 6685],
        [ 4218],
        [ 3656],
        [ 2128],
        [ 7065],
        [22722],
        [ 8899],
        [40459],
        [25490],
        [42646]], device='cuda:0')
[2024-07-24 10:17:06,433][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38149],
        [39038],
        [45757],
        [45818],
        [45172],
        [44102],
        [45865],
        [45119],
        [44424],
        [43866],
        [43382],
        [43968],
        [40835],
        [43925],
        [39971]], device='cuda:0')
[2024-07-24 10:17:06,435][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13228],
        [13228],
        [13194],
        [13095],
        [ 3216],
        [ 4246],
        [ 2569],
        [12718],
        [13200],
        [12099],
        [11353],
        [13128],
        [16940],
        [12607],
        [12716]], device='cuda:0')
[2024-07-24 10:17:06,436][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[4267],
        [3466],
        [3635],
        [2345],
        [1102],
        [2298],
        [3244],
        [3323],
        [4201],
        [4594],
        [4704],
        [1327],
        [1342],
        [1397],
        [1858]], device='cuda:0')
[2024-07-24 10:17:06,438][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 8100],
        [ 7964],
        [ 8720],
        [ 9483],
        [25905],
        [24685],
        [ 9488],
        [ 9470],
        [11381],
        [30155],
        [30445],
        [21521],
        [35557],
        [24172],
        [16976]], device='cuda:0')
[2024-07-24 10:17:06,440][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[18531],
        [18472],
        [18752],
        [18726],
        [16492],
        [15567],
        [16613],
        [17340],
        [15927],
        [10690],
        [10500],
        [14109],
        [13938],
        [13363],
        [13225]], device='cuda:0')
[2024-07-24 10:17:06,441][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18227],
        [20546],
        [22381],
        [23035],
        [22529],
        [23562],
        [23997],
        [28160],
        [22589],
        [20142],
        [20881],
        [23083],
        [15777],
        [15343],
        [16973]], device='cuda:0')
[2024-07-24 10:17:06,443][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[19556],
        [16153],
        [11484],
        [12614],
        [12407],
        [14879],
        [13901],
        [18818],
        [26042],
        [30816],
        [30629],
        [17888],
        [25099],
        [25298],
        [25128]], device='cuda:0')
[2024-07-24 10:17:06,444][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16782],
        [16772],
        [19109],
        [18239],
        [37314],
        [31771],
        [26681],
        [20876],
        [18445],
        [29287],
        [28392],
        [20748],
        [38329],
        [22897],
        [36255]], device='cuda:0')
[2024-07-24 10:17:06,446][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[36583],
        [46625],
        [39141],
        [41948],
        [47885],
        [47194],
        [45121],
        [47434],
        [44274],
        [43751],
        [44222],
        [43543],
        [46924],
        [46992],
        [47214]], device='cuda:0')
[2024-07-24 10:17:06,447][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 6485],
        [13410],
        [12502],
        [11984],
        [12085],
        [12763],
        [12854],
        [17031],
        [31877],
        [32236],
        [32779],
        [ 7503],
        [ 7344],
        [ 7441],
        [ 7276]], device='cuda:0')
[2024-07-24 10:17:06,449][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9273],
        [9768],
        [1667],
        [ 737],
        [1197],
        [1566],
        [1520],
        [1137],
        [ 826],
        [ 639],
        [ 695],
        [1710],
        [1068],
        [1338],
        [ 978]], device='cuda:0')
[2024-07-24 10:17:06,450][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[46527],
        [45978],
        [45453],
        [46745],
        [42031],
        [40278],
        [45657],
        [43060],
        [39814],
        [30141],
        [26615],
        [42384],
        [25753],
        [39151],
        [33325]], device='cuda:0')
[2024-07-24 10:17:06,451][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[14722],
        [30650],
        [45736],
        [40943],
        [38112],
        [37494],
        [36857],
        [34368],
        [41631],
        [38331],
        [34017],
        [39668],
        [28901],
        [33691],
        [33487]], device='cuda:0')
[2024-07-24 10:17:06,451][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744],
        [35744]], device='cuda:0')
[2024-07-24 10:17:06,511][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:06,513][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,514][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,515][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,516][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,517][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,519][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,520][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,521][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,522][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,524][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,525][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,527][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,528][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8644, 0.1356], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,529][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.3268, 0.6732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,529][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,529][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.9987e-01, 1.2830e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,530][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9964, 0.0036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,530][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,530][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.8609, 0.1391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,531][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9948, 0.0052], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,531][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6998, 0.3002], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,531][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0087, 0.9913], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,532][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,532][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.9787, 0.0213], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,534][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.0038, 0.0012, 0.9950], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,536][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.1133, 0.3440, 0.5427], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,537][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.9364, 0.0223, 0.0413], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,538][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([9.9890e-01, 2.9846e-04, 8.0229e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,539][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([0.9404, 0.0479, 0.0117], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,541][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([0.1679, 0.1222, 0.7099], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,543][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.3996, 0.4019, 0.1985], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,544][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.9969, 0.0018, 0.0012], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,545][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.6694, 0.2889, 0.0417], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,548][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([0.1659, 0.1662, 0.6680], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,549][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([5.1870e-04, 9.9709e-01, 2.3864e-03], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,550][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.6856, 0.1165, 0.1979], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,551][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0588, 0.0025, 0.9373, 0.0014], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,551][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3899, 0.3145, 0.2195, 0.0761], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,552][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.8764, 0.0297, 0.0385, 0.0554], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,552][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9883e-01, 3.8117e-04, 7.1426e-04, 7.8114e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,552][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8509, 0.0352, 0.0388, 0.0752], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,553][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([6.1410e-05, 5.1178e-01, 4.8814e-01, 1.9194e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,553][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2912, 0.6160, 0.0765, 0.0164], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,553][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.9906, 0.0052, 0.0030, 0.0012], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,553][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8627, 0.0789, 0.0113, 0.0471], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,554][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([6.7910e-05, 2.4209e-01, 7.5723e-01, 6.1266e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,554][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0009, 0.2774, 0.0020, 0.7197], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,554][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.9825, 0.0043, 0.0104, 0.0028], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,555][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0117, 0.0063, 0.8855, 0.0020, 0.0945], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,555][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0289, 0.1216, 0.3678, 0.0528, 0.4288], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,555][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.4425, 0.1132, 0.1904, 0.1660, 0.0878], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,557][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([9.9271e-01, 1.8452e-03, 3.9576e-03, 2.5101e-04, 1.2400e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,558][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.4988, 0.2132, 0.0794, 0.1537, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,559][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([5.5082e-02, 7.7372e-02, 7.5266e-01, 2.0134e-05, 1.1487e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,560][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0269, 0.6783, 0.1889, 0.0178, 0.0880], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,562][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.9493, 0.0249, 0.0085, 0.0034, 0.0139], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,564][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.3833, 0.3191, 0.0499, 0.2166, 0.0311], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,565][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([1.4337e-02, 1.3924e-01, 6.8715e-01, 6.2945e-04, 1.5864e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,566][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([7.7139e-05, 2.5861e-01, 6.2684e-04, 7.3793e-01, 2.7533e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,567][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.2929, 0.2335, 0.2821, 0.0324, 0.1591], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,568][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0550, 0.0024, 0.7910, 0.0010, 0.1469, 0.0036], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,571][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1064, 0.1535, 0.1036, 0.0529, 0.1947, 0.3890], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,572][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4681, 0.0673, 0.1174, 0.1143, 0.1393, 0.0935], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,573][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.8930e-01, 2.6494e-03, 3.7354e-03, 3.4634e-04, 1.5164e-03, 2.4476e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,574][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3627, 0.1403, 0.0649, 0.1226, 0.0399, 0.2695], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,574][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([8.3887e-04, 7.6555e-01, 1.6588e-01, 2.9697e-05, 6.1747e-02, 5.9504e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,575][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0821, 0.3851, 0.1576, 0.0202, 0.0975, 0.2576], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,575][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.9783, 0.0073, 0.0053, 0.0010, 0.0040, 0.0040], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,575][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.5381, 0.1849, 0.0280, 0.1129, 0.0358, 0.1002], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,576][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([5.9324e-04, 1.7753e-01, 3.8765e-01, 2.6682e-04, 6.3304e-02, 3.7065e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,576][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([6.3966e-05, 1.7849e-01, 1.6541e-04, 7.1107e-01, 9.3856e-04, 1.0926e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,576][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.5819, 0.0512, 0.1171, 0.0152, 0.0365, 0.1981], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,577][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.6620e-02, 6.5312e-04, 9.0904e-01, 3.7993e-04, 6.2010e-02, 1.0654e-03,
        2.3145e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,577][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1139, 0.1169, 0.1172, 0.0218, 0.3235, 0.1818, 0.1248],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,577][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.7031, 0.0602, 0.0359, 0.0439, 0.0337, 0.0234, 0.0997],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,577][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.8685e-01, 5.2567e-03, 2.1288e-03, 2.2930e-04, 8.9933e-04, 2.2548e-03,
        2.3819e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,578][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.5433, 0.2255, 0.0114, 0.0289, 0.0101, 0.1244, 0.0566],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,578][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.5567e-01, 1.2590e-01, 3.1366e-01, 4.8388e-06, 5.4073e-02, 3.7600e-02,
        1.1308e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,580][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0348, 0.7325, 0.0960, 0.0034, 0.0181, 0.0508, 0.0644],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,581][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.8321e-01, 8.6356e-03, 2.2378e-03, 7.9350e-04, 1.7035e-03, 3.0193e-03,
        4.0040e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,583][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.5910, 0.1367, 0.0339, 0.0655, 0.0288, 0.0566, 0.0875],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,584][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.5287e-02, 6.2843e-03, 2.3696e-02, 2.7720e-06, 1.0671e-02, 8.0691e-02,
        8.5337e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,584][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([2.1587e-04, 1.7479e-01, 5.2764e-04, 5.1017e-01, 2.4024e-03, 1.4994e-01,
        1.6196e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,586][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.6265, 0.1016, 0.0859, 0.0044, 0.0238, 0.1258, 0.0321],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,588][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0383, 0.0109, 0.8386, 0.0047, 0.0495, 0.0044, 0.0031, 0.0505],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,589][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0457, 0.0857, 0.0488, 0.0574, 0.0675, 0.1089, 0.1227, 0.4632],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,591][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.6027, 0.0271, 0.0655, 0.0414, 0.0428, 0.0293, 0.0874, 0.1038],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,592][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([9.8019e-01, 9.9538e-04, 2.1764e-03, 2.4148e-04, 1.5700e-03, 1.5831e-03,
        4.2260e-03, 9.0146e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,594][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.8763, 0.0255, 0.0130, 0.0138, 0.0095, 0.0267, 0.0158, 0.0195],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,595][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([6.4923e-02, 8.5405e-08, 4.1770e-04, 5.2346e-10, 8.8939e-05, 3.6939e-06,
        1.3876e-04, 9.3443e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,596][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0583, 0.3934, 0.0948, 0.0136, 0.0567, 0.0966, 0.1925, 0.0940],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,597][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([9.7530e-01, 1.1697e-02, 3.4292e-03, 1.0741e-03, 2.5745e-03, 4.3017e-03,
        5.2921e-04, 1.0959e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,597][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4028, 0.1527, 0.0194, 0.1402, 0.0257, 0.0764, 0.1382, 0.0447],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,598][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([2.3251e-03, 4.4709e-06, 7.2529e-04, 3.0120e-08, 4.2217e-04, 5.0845e-04,
        2.6533e-02, 9.6948e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,598][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([7.2894e-06, 1.2545e-01, 8.4853e-05, 7.0150e-01, 4.5269e-04, 6.9225e-02,
        9.2124e-02, 1.1156e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,598][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3110, 0.0187, 0.0518, 0.0049, 0.0127, 0.0569, 0.0495, 0.4945],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,599][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([7.3591e-03, 2.5550e-03, 8.2614e-01, 8.7419e-04, 6.0495e-02, 1.5752e-03,
        7.1000e-04, 1.7474e-02, 8.2817e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,599][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0261, 0.0459, 0.0312, 0.0286, 0.0458, 0.1284, 0.0744, 0.4922, 0.1273],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,599][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.6278, 0.0138, 0.0247, 0.0549, 0.0208, 0.0134, 0.0813, 0.1172, 0.0463],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,600][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.8454e-01, 5.7460e-04, 1.0717e-03, 1.9833e-04, 4.9109e-04, 9.0376e-04,
        1.4995e-03, 4.1528e-03, 6.5639e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,600][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.9388, 0.0056, 0.0046, 0.0043, 0.0050, 0.0144, 0.0035, 0.0118, 0.0120],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,600][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([7.1806e-04, 5.8269e-09, 5.5029e-06, 8.4059e-12, 1.0130e-06, 1.0716e-07,
        1.9674e-06, 1.0762e-01, 8.9166e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,601][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.4716, 0.0650, 0.0747, 0.0070, 0.0739, 0.0589, 0.0636, 0.0977, 0.0876],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,601][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([9.8879e-01, 4.3654e-03, 1.2615e-03, 5.8919e-04, 1.2806e-03, 2.4273e-03,
        3.1433e-04, 4.3066e-04, 5.4592e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,603][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2759, 0.1693, 0.0191, 0.1648, 0.0186, 0.0976, 0.1455, 0.0281, 0.0811],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,604][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([9.6776e-05, 7.6181e-07, 2.7448e-05, 1.2439e-09, 1.0206e-05, 3.3832e-05,
        1.1104e-03, 1.0474e-01, 8.9398e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,605][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([4.2615e-05, 1.1972e-01, 1.4580e-04, 5.5708e-01, 1.0695e-03, 1.4202e-01,
        1.5856e-01, 2.0007e-02, 1.3525e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,606][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.7011, 0.0029, 0.0170, 0.0011, 0.0045, 0.0110, 0.0069, 0.2227, 0.0327],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,607][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([3.3399e-02, 1.1399e-03, 7.6927e-01, 7.4068e-04, 8.5691e-02, 1.7320e-03,
        1.7989e-03, 2.6691e-02, 7.8958e-02, 5.7650e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,609][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1041, 0.0701, 0.0416, 0.0235, 0.0726, 0.0885, 0.0862, 0.3531, 0.1145,
        0.0457], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,611][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4137, 0.0225, 0.0564, 0.0463, 0.0571, 0.0311, 0.1006, 0.0856, 0.0765,
        0.1102], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,612][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.7186e-01, 8.3799e-04, 1.8984e-03, 2.1117e-04, 1.2098e-03, 1.4675e-03,
        2.3655e-03, 6.3943e-03, 1.1642e-02, 2.1091e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,613][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.6857, 0.0147, 0.0233, 0.0142, 0.0100, 0.0552, 0.0297, 0.0384, 0.0513,
        0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,614][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.7457e-08, 3.4183e-09, 5.4431e-07, 7.3819e-13, 9.1486e-08, 1.1568e-09,
        2.0601e-07, 4.3742e-02, 9.5625e-01, 2.6976e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,616][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0606, 0.1234, 0.0953, 0.0086, 0.0519, 0.0705, 0.1055, 0.0467, 0.3464,
        0.0910], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,617][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.9131e-01, 2.7524e-03, 1.1016e-03, 3.9415e-04, 9.8037e-04, 1.7260e-03,
        2.0806e-04, 2.5179e-04, 5.1677e-04, 7.5471e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,619][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5902, 0.0635, 0.0123, 0.0493, 0.0225, 0.0442, 0.0998, 0.0255, 0.0536,
        0.0391], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,620][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.9426e-09, 8.0559e-08, 2.8639e-06, 1.1665e-10, 4.7676e-07, 8.0014e-07,
        1.8426e-04, 9.9877e-02, 8.9992e-01, 1.6950e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,620][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([2.3621e-04, 1.1597e-01, 4.4922e-04, 2.9042e-01, 2.0680e-03, 8.9854e-02,
        1.4142e-01, 2.5205e-02, 2.4774e-03, 3.3190e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,620][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4581, 0.0136, 0.0526, 0.0048, 0.0158, 0.0382, 0.0288, 0.2099, 0.1138,
        0.0643], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,621][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0672, 0.0043, 0.6839, 0.0028, 0.0972, 0.0067, 0.0059, 0.0444, 0.0829,
        0.0020, 0.0028], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,621][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0336, 0.0720, 0.0279, 0.0216, 0.0590, 0.0912, 0.0763, 0.3637, 0.1520,
        0.0549, 0.0478], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,622][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3128, 0.0272, 0.0556, 0.0445, 0.0440, 0.0368, 0.1034, 0.0954, 0.0955,
        0.1116, 0.0732], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,622][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.6052e-01, 1.7233e-03, 2.2231e-03, 2.8416e-04, 1.1304e-03, 1.9079e-03,
        3.1169e-03, 9.4205e-03, 1.5166e-02, 3.0438e-03, 1.4602e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,622][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.5016, 0.0237, 0.0299, 0.0148, 0.0110, 0.0558, 0.0342, 0.0558, 0.0810,
        0.1098, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,623][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([5.1565e-08, 2.1045e-09, 4.9416e-07, 1.8541e-13, 6.8373e-08, 1.5506e-09,
        2.4485e-07, 2.3907e-02, 9.7607e-01, 9.0015e-07, 1.9840e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,623][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0371, 0.2039, 0.0527, 0.0071, 0.0241, 0.0645, 0.0889, 0.0494, 0.3165,
        0.1053, 0.0505], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,623][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.9027e-01, 3.8752e-03, 9.5796e-04, 3.9581e-04, 6.8597e-04, 1.8499e-03,
        2.1274e-04, 2.6778e-04, 3.6872e-04, 7.5084e-04, 3.6213e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,624][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6525, 0.0570, 0.0099, 0.0291, 0.0129, 0.0328, 0.0737, 0.0155, 0.0476,
        0.0312, 0.0378], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,624][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.4313e-09, 4.1548e-08, 1.6337e-06, 3.0433e-11, 2.2931e-07, 5.9125e-07,
        1.6274e-04, 7.7619e-02, 9.2218e-01, 7.1713e-06, 3.1184e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,625][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0608e-04, 8.8221e-02, 2.8477e-04, 1.9219e-01, 1.4568e-03, 9.1214e-02,
        1.1259e-01, 1.6334e-02, 2.0998e-03, 2.7725e-01, 2.1825e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,627][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3937, 0.0249, 0.0431, 0.0042, 0.0138, 0.0326, 0.0240, 0.2400, 0.1093,
        0.0599, 0.0546], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,628][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0287, 0.0088, 0.5028, 0.0024, 0.0622, 0.0071, 0.0023, 0.0448, 0.2151,
        0.0041, 0.0031, 0.1186], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,630][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0212, 0.0463, 0.0467, 0.0206, 0.0434, 0.0927, 0.0724, 0.2312, 0.1402,
        0.0762, 0.0617, 0.1475], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,631][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.3665, 0.0136, 0.0609, 0.0349, 0.0212, 0.0139, 0.0727, 0.1285, 0.0274,
        0.0773, 0.0526, 0.1304], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,632][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([9.9025e-01, 1.5535e-04, 4.6568e-04, 9.7274e-05, 3.4691e-04, 4.1079e-04,
        5.7649e-04, 2.1877e-03, 2.1406e-03, 7.6430e-04, 3.5818e-04, 2.2475e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,634][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.9072, 0.0028, 0.0029, 0.0063, 0.0028, 0.0143, 0.0042, 0.0071, 0.0083,
        0.0139, 0.0122, 0.0181], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,635][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([4.3662e-04, 1.0319e-12, 6.9789e-08, 1.5641e-13, 2.0059e-08, 8.3651e-10,
        3.7535e-08, 3.4321e-04, 7.3720e-04, 2.6506e-09, 3.0220e-08, 9.9848e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,637][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0820, 0.0502, 0.0882, 0.0110, 0.0516, 0.0531, 0.0970, 0.0720, 0.1113,
        0.0584, 0.0351, 0.2900], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,637][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([9.7068e-01, 6.8555e-03, 3.7585e-03, 1.4932e-03, 3.7384e-03, 5.6045e-03,
        7.8109e-04, 1.0403e-03, 1.1190e-03, 2.6076e-03, 1.4303e-03, 8.9196e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,640][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.1853, 0.1391, 0.0153, 0.0914, 0.0133, 0.0457, 0.1030, 0.0176, 0.0502,
        0.1734, 0.1383, 0.0273], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,640][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([7.1503e-05, 2.6042e-08, 9.1056e-06, 4.2978e-10, 6.9219e-06, 5.9107e-06,
        2.5297e-04, 1.4008e-02, 1.0987e-01, 1.0805e-06, 2.6724e-06, 8.7577e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,641][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([3.0089e-05, 6.1175e-02, 1.1524e-04, 1.8383e-01, 8.0701e-04, 7.4887e-02,
        7.7680e-02, 9.9292e-03, 1.1173e-03, 3.3969e-01, 2.4763e-01, 3.1037e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,643][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.8059, 0.0017, 0.0132, 0.0011, 0.0037, 0.0082, 0.0049, 0.0869, 0.0296,
        0.0138, 0.0110, 0.0200], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,643][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([0.0124, 0.0041, 0.4740, 0.0011, 0.0538, 0.0045, 0.0022, 0.0366, 0.2221,
        0.0017, 0.0018, 0.0367, 0.1488], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,644][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.0027, 0.0200, 0.0409, 0.0116, 0.0338, 0.0733, 0.0527, 0.3432, 0.1583,
        0.0355, 0.0374, 0.0996, 0.0909], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,644][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([0.0594, 0.0150, 0.0608, 0.0348, 0.0241, 0.0275, 0.0984, 0.1893, 0.0517,
        0.0814, 0.0685, 0.2244, 0.0648], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,644][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([8.0995e-01, 1.7341e-03, 2.9394e-03, 2.9657e-04, 1.2609e-03, 4.3948e-03,
        4.5736e-03, 1.6301e-02, 3.7954e-02, 3.9468e-03, 3.1232e-03, 9.9840e-02,
        1.3682e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,645][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.1448, 0.0250, 0.0113, 0.0111, 0.0046, 0.0548, 0.0173, 0.0295, 0.1174,
        0.0692, 0.0445, 0.4259, 0.0445], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,645][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([2.5395e-05, 6.0655e-13, 5.9181e-09, 1.7422e-15, 6.9165e-10, 1.3133e-10,
        4.4820e-09, 4.5780e-05, 7.2190e-04, 3.6107e-10, 2.5116e-09, 8.8076e-01,
        1.1845e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,646][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0025, 0.0790, 0.0396, 0.0032, 0.0146, 0.0209, 0.0425, 0.0320, 0.1668,
        0.0242, 0.0167, 0.4245, 0.1335], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,646][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.9363, 0.0175, 0.0040, 0.0024, 0.0052, 0.0135, 0.0020, 0.0013, 0.0018,
        0.0057, 0.0030, 0.0019, 0.0054], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,646][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.1212, 0.1417, 0.0244, 0.1028, 0.0161, 0.0578, 0.0705, 0.0280, 0.0421,
        0.1839, 0.1566, 0.0319, 0.0230], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,647][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([1.7548e-05, 3.6357e-07, 1.6262e-05, 1.6958e-09, 1.7492e-06, 1.8892e-05,
        1.2385e-03, 1.6227e-02, 1.8947e-01, 2.7068e-06, 4.3048e-06, 7.7775e-01,
        1.5249e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,647][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([1.2309e-05, 7.3137e-02, 1.4668e-04, 2.0119e-01, 5.0384e-04, 6.5386e-02,
        4.5061e-02, 1.8445e-02, 9.3461e-04, 2.8118e-01, 3.1117e-01, 2.5526e-03,
        2.8293e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,648][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([0.0151, 0.0068, 0.0176, 0.0013, 0.0056, 0.0159, 0.0104, 0.2593, 0.2504,
        0.0281, 0.0291, 0.3057, 0.0547], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,649][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([2.4065e-02, 6.3476e-04, 6.0222e-01, 2.2834e-04, 6.8050e-02, 1.3802e-03,
        6.6177e-04, 1.3808e-02, 9.2680e-02, 2.4600e-04, 4.1713e-04, 1.8555e-02,
        1.7361e-01, 3.4456e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,650][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0118, 0.0205, 0.0145, 0.0072, 0.0246, 0.0595, 0.0430, 0.4099, 0.0974,
        0.0337, 0.0296, 0.0745, 0.0545, 0.1193], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,652][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.3379, 0.0165, 0.0341, 0.0248, 0.0256, 0.0103, 0.0595, 0.0830, 0.0394,
        0.0708, 0.0550, 0.1483, 0.0581, 0.0367], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,653][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([9.1579e-01, 2.3399e-03, 2.2760e-03, 2.8668e-04, 9.3872e-04, 2.2643e-03,
        2.2177e-03, 9.6095e-03, 1.1231e-02, 3.2217e-03, 1.2634e-03, 3.3260e-02,
        3.4579e-03, 1.1848e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,654][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.6070, 0.0149, 0.0040, 0.0078, 0.0036, 0.0353, 0.0099, 0.0205, 0.0280,
        0.0512, 0.0356, 0.1411, 0.0123, 0.0287], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,655][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.7618e-06, 4.0558e-10, 2.4317e-08, 8.9151e-14, 3.5940e-09, 2.7852e-09,
        9.2829e-09, 7.7957e-05, 3.2550e-03, 2.0799e-08, 7.0136e-08, 8.6943e-01,
        1.2703e-01, 2.0353e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,657][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0603, 0.1089, 0.0739, 0.0028, 0.0196, 0.0288, 0.0303, 0.0256, 0.1159,
        0.0401, 0.0157, 0.2931, 0.0618, 0.1231], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,658][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([9.9316e-01, 2.7620e-03, 1.1657e-03, 1.6476e-04, 7.8898e-04, 5.8619e-04,
        6.8570e-05, 1.3702e-04, 1.8498e-04, 2.8095e-04, 9.1650e-05, 7.9484e-05,
        4.3102e-04, 9.9281e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,660][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2595, 0.0717, 0.0133, 0.0631, 0.0183, 0.0499, 0.0888, 0.0270, 0.0448,
        0.0811, 0.1023, 0.0304, 0.0272, 0.1225], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,660][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([5.6634e-06, 9.3884e-08, 2.8603e-06, 7.1844e-11, 3.8361e-07, 2.9510e-06,
        8.1125e-05, 5.7189e-03, 9.3253e-02, 7.3371e-07, 1.2269e-06, 5.9786e-01,
        1.4016e-02, 2.8906e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,662][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([7.9705e-06, 5.3994e-02, 3.4288e-05, 2.2976e-01, 1.7648e-04, 4.7100e-02,
        4.3997e-02, 7.5366e-03, 4.5088e-04, 2.7853e-01, 3.3162e-01, 1.4537e-03,
        7.1018e-05, 5.2729e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,664][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.5289, 0.0067, 0.0138, 0.0011, 0.0043, 0.0247, 0.0064, 0.0704, 0.1124,
        0.0294, 0.0215, 0.0544, 0.0283, 0.0978], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,665][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.9514e-02, 9.7751e-04, 6.5438e-01, 8.4664e-04, 6.7212e-02, 3.1496e-03,
        1.3360e-03, 1.8939e-02, 6.6528e-02, 4.1290e-04, 7.5197e-04, 1.9388e-02,
        1.4262e-01, 2.0611e-03, 1.8827e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,666][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0115, 0.0412, 0.0225, 0.0117, 0.0333, 0.0888, 0.0567, 0.2465, 0.1069,
        0.0377, 0.0352, 0.0762, 0.0603, 0.1270, 0.0446], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,667][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2726, 0.0236, 0.0292, 0.0223, 0.0186, 0.0092, 0.0640, 0.0858, 0.0539,
        0.0743, 0.0461, 0.1238, 0.0489, 0.0485, 0.0790], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,667][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.4933e-01, 1.8771e-03, 1.0825e-03, 1.0584e-04, 4.0257e-04, 1.0267e-03,
        1.0769e-03, 5.5711e-03, 1.1788e-02, 1.6304e-03, 7.0073e-04, 1.0959e-02,
        1.8498e-03, 8.3586e-03, 4.2446e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,667][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5219, 0.0368, 0.0130, 0.0056, 0.0068, 0.0335, 0.0095, 0.0137, 0.0599,
        0.0394, 0.0251, 0.1229, 0.0319, 0.0615, 0.0185], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,668][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.1811e-05, 4.6146e-10, 8.3900e-08, 6.7780e-14, 8.2775e-09, 5.2201e-09,
        2.3549e-08, 6.6018e-05, 3.9987e-03, 9.5676e-09, 4.5474e-08, 6.4184e-01,
        3.5325e-01, 7.0210e-04, 1.1969e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,668][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0070, 0.1655, 0.0284, 0.0018, 0.0111, 0.0196, 0.0246, 0.0214, 0.2609,
        0.0396, 0.0158, 0.1830, 0.0672, 0.1099, 0.0444], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,668][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.9071e-01, 3.9260e-03, 1.0934e-03, 1.9852e-04, 6.2958e-04, 1.2011e-03,
        1.1576e-04, 2.0572e-04, 3.3190e-04, 4.5221e-04, 1.7650e-04, 1.6021e-04,
        4.8969e-04, 1.7449e-04, 1.3485e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,669][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3437, 0.0736, 0.0173, 0.0397, 0.0200, 0.0359, 0.0712, 0.0213, 0.0610,
        0.0574, 0.0579, 0.0255, 0.0322, 0.0745, 0.0687], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,669][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.7411e-06, 9.1533e-08, 2.5082e-06, 7.1024e-11, 5.0593e-07, 4.9917e-06,
        1.2216e-04, 3.0148e-03, 8.7374e-02, 1.0265e-06, 2.1505e-06, 4.3476e-01,
        2.1266e-02, 3.9734e-01, 5.6109e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,670][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([1.6037e-05, 7.8029e-02, 1.5098e-04, 1.7052e-01, 7.1523e-04, 5.1223e-02,
        6.5282e-02, 9.3357e-03, 9.9242e-04, 2.8952e-01, 2.1790e-01, 2.6107e-03,
        3.1123e-04, 8.3103e-03, 1.0508e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,670][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1732, 0.0725, 0.0414, 0.0019, 0.0058, 0.0226, 0.0058, 0.0765, 0.1465,
        0.0482, 0.0404, 0.0779, 0.0350, 0.1679, 0.0845], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,719][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:06,720][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,722][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,723][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,724][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,725][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,727][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,728][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,729][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,731][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,732][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,733][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,735][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,735][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5786, 0.4214], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,736][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3812, 0.6188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,736][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,736][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.9987e-01, 1.2830e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,737][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9964, 0.0036], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,737][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0041, 0.9959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,737][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8609, 0.1391], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,738][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9988, 0.0012], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,738][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,738][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.1571e-04, 9.9978e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,739][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9980e-01, 1.9810e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,739][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.9787, 0.0213], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,740][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.0651, 0.5586, 0.3763], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,741][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0222, 0.0956, 0.8822], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,743][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.9364, 0.0223, 0.0413], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,744][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([9.9890e-01, 2.9846e-04, 8.0229e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,745][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([0.9404, 0.0479, 0.0117], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,746][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([0.1679, 0.1222, 0.7099], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,748][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([0.3996, 0.4019, 0.1985], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,749][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([9.9886e-01, 4.2338e-04, 7.1657e-04], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,751][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.9888, 0.0051, 0.0061], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,752][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([0.1197, 0.1265, 0.7538], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,753][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([9.4361e-01, 6.7720e-04, 5.5709e-02], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,755][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.6856, 0.1165, 0.1979], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,757][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1306, 0.7350, 0.1083, 0.0262], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,758][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0345, 0.2626, 0.6816, 0.0212], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,759][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.8764, 0.0297, 0.0385, 0.0554], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,759][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9883e-01, 3.8117e-04, 7.1426e-04, 7.8114e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,759][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8509, 0.0352, 0.0388, 0.0752], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,759][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([6.1410e-05, 5.1178e-01, 4.8814e-01, 1.9194e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,760][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2912, 0.6160, 0.0765, 0.0164], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,760][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.9840, 0.0063, 0.0054, 0.0042], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,760][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9736, 0.0117, 0.0053, 0.0094], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,761][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.1359e-06, 5.8289e-01, 4.1710e-01, 3.3597e-06], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,761][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7636, 0.0020, 0.2331, 0.0013], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,761][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.9825, 0.0043, 0.0104, 0.0028], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:06,762][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([0.0068, 0.8828, 0.0519, 0.0113, 0.0471], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,762][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.0025, 0.2555, 0.5790, 0.0135, 0.1495], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,762][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.4425, 0.1132, 0.1904, 0.1660, 0.0878], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,763][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([9.9271e-01, 1.8452e-03, 3.9576e-03, 2.5101e-04, 1.2400e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,764][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.4988, 0.2132, 0.0794, 0.1537, 0.0550], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,766][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([5.5082e-02, 7.7372e-02, 7.5266e-01, 2.0134e-05, 1.1487e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,767][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0269, 0.6783, 0.1889, 0.0178, 0.0880], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,768][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.9528, 0.0085, 0.0080, 0.0029, 0.0278], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,769][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.8629, 0.0093, 0.0234, 0.0101, 0.0943], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,771][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([8.9707e-03, 1.4905e-01, 8.1308e-01, 4.2078e-06, 2.8886e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,772][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.8114, 0.0018, 0.1826, 0.0009, 0.0033], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,774][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.2929, 0.2335, 0.2821, 0.0324, 0.1591], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:06,775][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0115, 0.3418, 0.1508, 0.0105, 0.1071, 0.3784], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,777][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0036, 0.1126, 0.5762, 0.0087, 0.2305, 0.0685], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,779][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4681, 0.0673, 0.1174, 0.1143, 0.1393, 0.0935], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,780][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([9.8930e-01, 2.6494e-03, 3.7354e-03, 3.4634e-04, 1.5164e-03, 2.4476e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,781][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.3627, 0.1403, 0.0649, 0.1226, 0.0399, 0.2695], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,782][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([8.3887e-04, 7.6555e-01, 1.6588e-01, 2.9697e-05, 6.1747e-02, 5.9504e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,782][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0821, 0.3851, 0.1576, 0.0202, 0.0975, 0.2576], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,782][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.9714, 0.0056, 0.0076, 0.0025, 0.0075, 0.0054], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,783][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7571, 0.0210, 0.0155, 0.0232, 0.0932, 0.0901], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,783][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([5.0743e-05, 7.6986e-01, 1.9540e-01, 5.4447e-06, 3.3333e-02, 1.3490e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,783][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5545, 0.0031, 0.4305, 0.0012, 0.0072, 0.0034], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,784][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.5819, 0.0512, 0.1171, 0.0152, 0.0365, 0.1981], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:06,784][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0045, 0.5026, 0.0719, 0.0041, 0.0342, 0.2493, 0.1334],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,784][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0045, 0.2829, 0.5168, 0.0066, 0.1146, 0.0419, 0.0327],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,785][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.7031, 0.0602, 0.0359, 0.0439, 0.0337, 0.0234, 0.0997],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,785][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.8685e-01, 5.2567e-03, 2.1288e-03, 2.2930e-04, 8.9933e-04, 2.2548e-03,
        2.3819e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,785][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5433, 0.2255, 0.0114, 0.0289, 0.0101, 0.1244, 0.0566],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,785][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.5567e-01, 1.2590e-01, 3.1366e-01, 4.8388e-06, 5.4073e-02, 3.7600e-02,
        1.1308e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,786][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0348, 0.7325, 0.0960, 0.0034, 0.0181, 0.0508, 0.0644],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,787][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.6934e-01, 1.2011e-02, 4.5914e-03, 2.9381e-03, 5.8208e-03, 4.6478e-03,
        6.4910e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,789][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9686, 0.0062, 0.0023, 0.0033, 0.0078, 0.0053, 0.0066],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,790][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([5.2695e-02, 1.3688e-01, 6.4460e-01, 3.5301e-07, 3.8454e-02, 5.2804e-03,
        1.2209e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,791][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4344, 0.0071, 0.5449, 0.0014, 0.0034, 0.0037, 0.0051],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,792][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6265, 0.1016, 0.0859, 0.0044, 0.0238, 0.1258, 0.0321],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:06,794][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0184, 0.2613, 0.1899, 0.0071, 0.0369, 0.1771, 0.0799, 0.2295],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,796][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0077, 0.1178, 0.4506, 0.0100, 0.2259, 0.0505, 0.0682, 0.0692],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,798][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.6027, 0.0271, 0.0655, 0.0414, 0.0428, 0.0293, 0.0874, 0.1038],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,798][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([9.8019e-01, 9.9538e-04, 2.1764e-03, 2.4148e-04, 1.5700e-03, 1.5831e-03,
        4.2260e-03, 9.0146e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,800][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.8763, 0.0255, 0.0130, 0.0138, 0.0095, 0.0267, 0.0158, 0.0195],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,802][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([6.4923e-02, 8.5405e-08, 4.1770e-04, 5.2346e-10, 8.8939e-05, 3.6939e-06,
        1.3876e-04, 9.3443e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,803][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0583, 0.3934, 0.0948, 0.0136, 0.0567, 0.0966, 0.1925, 0.0940],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,804][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([9.9291e-01, 2.0917e-03, 1.3721e-03, 7.4179e-04, 1.0544e-03, 1.2959e-03,
        1.5182e-04, 3.8621e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,805][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.8513, 0.0051, 0.0032, 0.0057, 0.0174, 0.0076, 0.0191, 0.0905],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,805][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([2.1642e-03, 3.4030e-09, 1.3642e-04, 4.0459e-12, 3.8197e-06, 4.7862e-08,
        1.8751e-05, 9.9768e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,805][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.6878, 0.0022, 0.2951, 0.0008, 0.0034, 0.0018, 0.0049, 0.0039],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,806][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3110, 0.0187, 0.0518, 0.0049, 0.0127, 0.0569, 0.0495, 0.4945],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:06,806][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0525, 0.0318, 0.0812, 0.0045, 0.0315, 0.1163, 0.0482, 0.0999, 0.5341],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,806][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0273, 0.0551, 0.3049, 0.0093, 0.0812, 0.0214, 0.0341, 0.0473, 0.4195],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,807][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.6278, 0.0138, 0.0247, 0.0549, 0.0208, 0.0134, 0.0813, 0.1172, 0.0463],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,807][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([9.8454e-01, 5.7460e-04, 1.0717e-03, 1.9833e-04, 4.9109e-04, 9.0376e-04,
        1.4995e-03, 4.1528e-03, 6.5639e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,807][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.9388, 0.0056, 0.0046, 0.0043, 0.0050, 0.0144, 0.0035, 0.0118, 0.0120],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,808][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([7.1806e-04, 5.8269e-09, 5.5029e-06, 8.4059e-12, 1.0130e-06, 1.0716e-07,
        1.9674e-06, 1.0762e-01, 8.9166e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,808][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.4716, 0.0650, 0.0747, 0.0070, 0.0739, 0.0589, 0.0636, 0.0977, 0.0876],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,808][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([9.9650e-01, 5.3783e-04, 5.2879e-04, 3.9302e-04, 8.5857e-04, 6.5496e-04,
        6.9930e-05, 1.9780e-04, 2.5472e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,809][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.4971e-01, 8.7403e-04, 1.6555e-03, 1.9970e-03, 8.7894e-03, 2.9477e-03,
        3.2381e-03, 1.4115e-02, 1.6675e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,810][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([5.8393e-06, 5.4863e-11, 3.0612e-07, 1.1534e-14, 7.3481e-09, 2.9368e-10,
        4.8146e-08, 3.2793e-02, 9.6720e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,811][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([9.0684e-01, 3.6537e-04, 8.7828e-02, 3.5258e-04, 5.8957e-04, 4.4416e-04,
        1.1872e-03, 9.0202e-04, 1.4902e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,813][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.7011, 0.0029, 0.0170, 0.0011, 0.0045, 0.0110, 0.0069, 0.2227, 0.0327],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:06,814][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0068, 0.0583, 0.0931, 0.0033, 0.0274, 0.0822, 0.0506, 0.0845, 0.5344,
        0.0594], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,815][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0052, 0.0435, 0.4781, 0.0065, 0.0720, 0.0196, 0.0227, 0.0291, 0.2707,
        0.0527], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,817][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4137, 0.0225, 0.0564, 0.0463, 0.0571, 0.0311, 0.1006, 0.0856, 0.0765,
        0.1102], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,818][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.7186e-01, 8.3799e-04, 1.8984e-03, 2.1117e-04, 1.2098e-03, 1.4675e-03,
        2.3655e-03, 6.3943e-03, 1.1642e-02, 2.1091e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,820][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6857, 0.0147, 0.0233, 0.0142, 0.0100, 0.0552, 0.0297, 0.0384, 0.0513,
        0.0773], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,821][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.7457e-08, 3.4183e-09, 5.4431e-07, 7.3819e-13, 9.1486e-08, 1.1568e-09,
        2.0601e-07, 4.3742e-02, 9.5625e-01, 2.6976e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,823][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0606, 0.1234, 0.0953, 0.0086, 0.0519, 0.0705, 0.1055, 0.0467, 0.3464,
        0.0910], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,824][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.7572e-01, 3.7721e-03, 2.8835e-03, 2.0842e-03, 4.9675e-03, 3.2358e-03,
        5.0199e-04, 7.1021e-04, 1.7510e-03, 4.3686e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,825][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8348, 0.0036, 0.0047, 0.0057, 0.0189, 0.0073, 0.0129, 0.0444, 0.0420,
        0.0257], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,826][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([8.1093e-11, 2.6373e-11, 1.8231e-08, 1.0518e-15, 9.8463e-10, 1.9530e-12,
        2.9461e-09, 1.1047e-02, 9.8895e-01, 1.3269e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,827][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.2405e-01, 2.0928e-03, 5.5353e-01, 1.3877e-03, 3.3597e-03, 2.4253e-03,
        4.0042e-03, 3.4832e-03, 5.4259e-03, 2.4266e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,828][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4581, 0.0136, 0.0526, 0.0048, 0.0158, 0.0382, 0.0288, 0.2099, 0.1138,
        0.0643], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:06,828][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0042, 0.0860, 0.0415, 0.0024, 0.0160, 0.0679, 0.0420, 0.0752, 0.5934,
        0.0467, 0.0248], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,828][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0041, 0.0709, 0.3781, 0.0062, 0.0577, 0.0228, 0.0241, 0.0363, 0.3109,
        0.0558, 0.0330], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,829][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3128, 0.0272, 0.0556, 0.0445, 0.0440, 0.0368, 0.1034, 0.0954, 0.0955,
        0.1116, 0.0732], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,829][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.6052e-01, 1.7233e-03, 2.2231e-03, 2.8416e-04, 1.1304e-03, 1.9079e-03,
        3.1169e-03, 9.4205e-03, 1.5166e-02, 3.0438e-03, 1.4602e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,829][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.5016, 0.0237, 0.0299, 0.0148, 0.0110, 0.0558, 0.0342, 0.0558, 0.0810,
        0.1098, 0.0824], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,830][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([5.1565e-08, 2.1045e-09, 4.9416e-07, 1.8541e-13, 6.8373e-08, 1.5506e-09,
        2.4485e-07, 2.3907e-02, 9.7607e-01, 9.0015e-07, 1.9840e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,830][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0371, 0.2039, 0.0527, 0.0071, 0.0241, 0.0645, 0.0889, 0.0494, 0.3165,
        0.1053, 0.0505], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,830][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.5834e-01, 9.2424e-03, 3.6896e-03, 3.1627e-03, 5.3175e-03, 5.3940e-03,
        8.0496e-04, 1.3674e-03, 1.9739e-03, 7.1142e-03, 3.5931e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,831][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6782, 0.0090, 0.0064, 0.0079, 0.0198, 0.0158, 0.0237, 0.0670, 0.0823,
        0.0504, 0.0394], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,831][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.0053e-10, 9.3448e-12, 1.8261e-08, 1.3126e-16, 5.8043e-10, 2.3249e-12,
        2.8994e-09, 4.4970e-03, 9.9550e-01, 2.2659e-08, 1.5527e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,831][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([4.5725e-01, 3.2000e-03, 5.1413e-01, 1.5558e-03, 3.5545e-03, 3.2831e-03,
        4.4193e-03, 4.1020e-03, 7.7283e-03, 2.8383e-04, 4.9899e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,832][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3937, 0.0249, 0.0431, 0.0042, 0.0138, 0.0326, 0.0240, 0.2400, 0.1093,
        0.0599, 0.0546], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:06,834][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0093, 0.0264, 0.0320, 0.0017, 0.0126, 0.0420, 0.0256, 0.0436, 0.2965,
        0.0197, 0.0094, 0.4814], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,836][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0053, 0.0135, 0.3577, 0.0041, 0.0885, 0.0115, 0.0198, 0.0222, 0.2959,
        0.0392, 0.0238, 0.1185], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,837][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.3665, 0.0136, 0.0609, 0.0349, 0.0212, 0.0139, 0.0727, 0.1285, 0.0274,
        0.0773, 0.0526, 0.1304], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,838][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([9.9025e-01, 1.5535e-04, 4.6568e-04, 9.7274e-05, 3.4691e-04, 4.1079e-04,
        5.7649e-04, 2.1877e-03, 2.1406e-03, 7.6430e-04, 3.5818e-04, 2.2475e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,840][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.9072, 0.0028, 0.0029, 0.0063, 0.0028, 0.0143, 0.0042, 0.0071, 0.0083,
        0.0139, 0.0122, 0.0181], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,841][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([4.3662e-04, 1.0319e-12, 6.9789e-08, 1.5641e-13, 2.0059e-08, 8.3651e-10,
        3.7535e-08, 3.4321e-04, 7.3720e-04, 2.6506e-09, 3.0220e-08, 9.9848e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,843][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0820, 0.0502, 0.0882, 0.0110, 0.0516, 0.0531, 0.0970, 0.0720, 0.1113,
        0.0584, 0.0351, 0.2900], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,844][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([9.8511e-01, 1.1407e-03, 1.6714e-03, 1.4817e-03, 2.9490e-03, 1.9354e-03,
        2.6162e-04, 6.2057e-04, 4.9289e-04, 2.5187e-03, 1.4113e-03, 4.0861e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,845][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.9170, 0.0012, 0.0018, 0.0022, 0.0074, 0.0024, 0.0033, 0.0099, 0.0110,
        0.0088, 0.0094, 0.0255], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,846][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.3737e-05, 2.0721e-15, 5.9919e-09, 2.0985e-16, 3.2132e-10, 2.5890e-12,
        6.6069e-10, 2.9974e-05, 3.0105e-04, 3.2275e-11, 8.6919e-10, 9.9966e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,847][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([5.0838e-01, 8.8458e-04, 4.4996e-01, 1.2070e-03, 4.9589e-03, 2.4247e-03,
        5.3987e-03, 5.5923e-03, 7.7128e-03, 1.8014e-04, 2.9346e-04, 1.3012e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,849][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.8059, 0.0017, 0.0132, 0.0011, 0.0037, 0.0082, 0.0049, 0.0869, 0.0296,
        0.0138, 0.0110, 0.0200], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:06,850][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([2.5840e-04, 3.9613e-02, 1.0964e-02, 5.4065e-04, 2.5202e-03, 1.3874e-02,
        5.0278e-03, 1.8012e-02, 2.3390e-01, 1.0254e-02, 7.1768e-03, 5.7619e-01,
        8.1670e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,851][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([8.1419e-05, 1.1297e-02, 5.8072e-02, 1.7278e-03, 1.1470e-02, 9.6656e-03,
        1.2966e-02, 1.2688e-02, 1.5938e-01, 3.1535e-02, 2.5065e-02, 3.0812e-01,
        3.5794e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,851][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([0.0594, 0.0150, 0.0608, 0.0348, 0.0241, 0.0275, 0.0984, 0.1893, 0.0517,
        0.0814, 0.0685, 0.2244, 0.0648], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,851][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([8.0995e-01, 1.7341e-03, 2.9394e-03, 2.9657e-04, 1.2609e-03, 4.3948e-03,
        4.5736e-03, 1.6301e-02, 3.7954e-02, 3.9468e-03, 3.1232e-03, 9.9840e-02,
        1.3682e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,852][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.1448, 0.0250, 0.0113, 0.0111, 0.0046, 0.0548, 0.0173, 0.0295, 0.1174,
        0.0692, 0.0445, 0.4259, 0.0445], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,852][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([2.5395e-05, 6.0655e-13, 5.9181e-09, 1.7422e-15, 6.9165e-10, 1.3133e-10,
        4.4820e-09, 4.5780e-05, 7.2190e-04, 3.6107e-10, 2.5116e-09, 8.8076e-01,
        1.1845e-01], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,852][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([0.0025, 0.0790, 0.0396, 0.0032, 0.0146, 0.0209, 0.0425, 0.0320, 0.1668,
        0.0242, 0.0167, 0.4245, 0.1335], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,853][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([0.8962, 0.0073, 0.0072, 0.0035, 0.0219, 0.0098, 0.0014, 0.0019, 0.0051,
        0.0124, 0.0055, 0.0052, 0.0227], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,853][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.6067, 0.0027, 0.0118, 0.0063, 0.0578, 0.0126, 0.0162, 0.0414, 0.0228,
        0.0139, 0.0172, 0.1278, 0.0628], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,854][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([1.0801e-06, 4.3158e-15, 2.7630e-10, 1.6130e-18, 2.7280e-12, 4.3503e-13,
        7.5695e-11, 1.8985e-06, 4.7690e-04, 3.4725e-12, 6.1029e-11, 9.6543e-01,
        3.4086e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,854][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([7.0903e-01, 1.0402e-03, 2.4216e-01, 6.6454e-04, 2.2121e-03, 1.4950e-03,
        3.0179e-03, 2.8040e-03, 1.1157e-02, 8.8305e-05, 2.4808e-04, 2.5997e-02,
        9.1812e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,854][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([0.0151, 0.0068, 0.0176, 0.0013, 0.0056, 0.0159, 0.0104, 0.2593, 0.2504,
        0.0281, 0.0291, 0.3057, 0.0547], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:06,855][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0024, 0.0322, 0.0221, 0.0007, 0.0065, 0.0283, 0.0121, 0.0248, 0.1987,
        0.0191, 0.0082, 0.4352, 0.1003, 0.1094], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,857][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0022, 0.0270, 0.2993, 0.0013, 0.0263, 0.0056, 0.0045, 0.0084, 0.1144,
        0.0174, 0.0105, 0.1795, 0.1588, 0.1448], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,858][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.3379, 0.0165, 0.0341, 0.0248, 0.0256, 0.0103, 0.0595, 0.0830, 0.0394,
        0.0708, 0.0550, 0.1483, 0.0581, 0.0367], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,859][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([9.1579e-01, 2.3399e-03, 2.2760e-03, 2.8668e-04, 9.3872e-04, 2.2643e-03,
        2.2177e-03, 9.6095e-03, 1.1231e-02, 3.2217e-03, 1.2634e-03, 3.3260e-02,
        3.4579e-03, 1.1848e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,861][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.6070, 0.0149, 0.0040, 0.0078, 0.0036, 0.0353, 0.0099, 0.0205, 0.0280,
        0.0512, 0.0356, 0.1411, 0.0123, 0.0287], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,862][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.7618e-06, 4.0558e-10, 2.4317e-08, 8.9151e-14, 3.5940e-09, 2.7852e-09,
        9.2829e-09, 7.7957e-05, 3.2550e-03, 2.0799e-08, 7.0136e-08, 8.6943e-01,
        1.2703e-01, 2.0353e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,863][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0603, 0.1089, 0.0739, 0.0028, 0.0196, 0.0288, 0.0303, 0.0256, 0.1159,
        0.0401, 0.0157, 0.2931, 0.0618, 0.1231], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,865][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([9.8902e-01, 2.0835e-03, 2.3384e-03, 4.7305e-04, 2.1994e-03, 8.2374e-04,
        9.9841e-05, 2.6187e-04, 2.5391e-04, 1.0465e-03, 3.3655e-04, 1.0249e-04,
        8.2683e-04, 1.3747e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,866][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.8339, 0.0025, 0.0039, 0.0030, 0.0125, 0.0038, 0.0078, 0.0210, 0.0132,
        0.0131, 0.0093, 0.0501, 0.0113, 0.0146], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,867][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.1679e-08, 4.2607e-12, 1.4265e-09, 1.8974e-16, 5.1532e-11, 7.1860e-12,
        1.8927e-10, 1.5169e-05, 2.5552e-03, 4.5885e-10, 3.6437e-09, 8.8905e-01,
        1.0823e-01, 1.4878e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,868][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([5.5663e-01, 1.5797e-03, 3.3141e-01, 4.8173e-04, 1.9508e-03, 1.1045e-03,
        1.5329e-03, 2.1599e-03, 4.4803e-03, 1.0309e-04, 1.5876e-04, 8.5221e-03,
        5.4041e-05, 8.9832e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,870][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.5289, 0.0067, 0.0138, 0.0011, 0.0043, 0.0247, 0.0064, 0.0704, 0.1124,
        0.0294, 0.0215, 0.0544, 0.0283, 0.0978], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:06,872][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0006, 0.0482, 0.0130, 0.0005, 0.0028, 0.0181, 0.0090, 0.0192, 0.3142,
        0.0143, 0.0062, 0.3492, 0.0551, 0.1123, 0.0372], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,873][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0017, 0.0199, 0.1646, 0.0009, 0.0248, 0.0080, 0.0080, 0.0121, 0.2453,
        0.0169, 0.0099, 0.1155, 0.1665, 0.1604, 0.0455], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,874][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2726, 0.0236, 0.0292, 0.0223, 0.0186, 0.0092, 0.0640, 0.0858, 0.0539,
        0.0743, 0.0461, 0.1238, 0.0489, 0.0485, 0.0790], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,874][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.4933e-01, 1.8771e-03, 1.0825e-03, 1.0584e-04, 4.0257e-04, 1.0267e-03,
        1.0769e-03, 5.5711e-03, 1.1788e-02, 1.6304e-03, 7.0073e-04, 1.0959e-02,
        1.8498e-03, 8.3586e-03, 4.2446e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,875][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5219, 0.0368, 0.0130, 0.0056, 0.0068, 0.0335, 0.0095, 0.0137, 0.0599,
        0.0394, 0.0251, 0.1229, 0.0319, 0.0615, 0.0185], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,875][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.1811e-05, 4.6146e-10, 8.3900e-08, 6.7780e-14, 8.2775e-09, 5.2201e-09,
        2.3549e-08, 6.6018e-05, 3.9987e-03, 9.5676e-09, 4.5474e-08, 6.4184e-01,
        3.5325e-01, 7.0210e-04, 1.1969e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,875][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0070, 0.1655, 0.0284, 0.0018, 0.0111, 0.0196, 0.0246, 0.0214, 0.2609,
        0.0396, 0.0158, 0.1830, 0.0672, 0.1099, 0.0444], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,876][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([9.7367e-01, 6.2764e-03, 3.0920e-03, 9.9116e-04, 3.4006e-03, 2.6002e-03,
        2.7093e-04, 5.6697e-04, 1.0819e-03, 2.8308e-03, 1.1592e-03, 5.2982e-04,
        2.7476e-03, 3.9926e-04, 3.8280e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,876][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.7139, 0.0033, 0.0033, 0.0018, 0.0072, 0.0043, 0.0067, 0.0289, 0.0345,
        0.0158, 0.0123, 0.1047, 0.0111, 0.0178, 0.0341], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,876][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6454e-07, 4.1830e-12, 5.3525e-09, 1.6870e-16, 1.3828e-10, 1.9440e-11,
        6.5975e-10, 5.5662e-06, 3.1524e-03, 3.2076e-10, 4.0607e-09, 6.3423e-01,
        3.6207e-01, 4.8567e-04, 5.4135e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,877][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.4192e-01, 3.1871e-03, 3.7011e-01, 6.9012e-04, 2.3464e-03, 2.5419e-03,
        4.0828e-03, 4.2338e-03, 1.4296e-02, 2.2412e-04, 3.0897e-04, 1.8334e-02,
        8.0158e-05, 2.2915e-01, 8.5022e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,877][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1732, 0.0725, 0.0414, 0.0019, 0.0058, 0.0226, 0.0058, 0.0765, 0.1465,
        0.0482, 0.0404, 0.0779, 0.0350, 0.1679, 0.0845], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:06,878][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:06,879][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16247],
        [ 5110],
        [    1],
        [ 1343],
        [  437],
        [  327],
        [ 2243],
        [ 1566],
        [  570],
        [  947],
        [  827],
        [ 4328],
        [  904],
        [ 1836],
        [  691]], device='cuda:0')
[2024-07-24 10:17:06,881][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12760],
        [ 4257],
        [    2],
        [ 3379],
        [ 1003],
        [ 1018],
        [ 5836],
        [ 3571],
        [ 1821],
        [ 2479],
        [ 2427],
        [ 7984],
        [ 1722],
        [ 4142],
        [ 2373]], device='cuda:0')
[2024-07-24 10:17:06,883][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18546],
        [ 2072],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1],
        [    1]], device='cuda:0')
[2024-07-24 10:17:06,884][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12603],
        [39263],
        [ 3430],
        [11613],
        [12043],
        [18796],
        [22850],
        [21156],
        [18784],
        [19781],
        [20489],
        [19939],
        [19264],
        [20586],
        [21262]], device='cuda:0')
[2024-07-24 10:17:06,885][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[13076],
        [12835],
        [25381],
        [14664],
        [21767],
        [11551],
        [ 5921],
        [ 5598],
        [ 2162],
        [ 2070],
        [ 1464],
        [ 2549],
        [ 1927],
        [ 1752],
        [ 1482]], device='cuda:0')
[2024-07-24 10:17:06,887][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12426],
        [12433],
        [12711],
        [12685],
        [14157],
        [14723],
        [14896],
        [18357],
        [15135],
        [17365],
        [19808],
        [14729],
        [45426],
        [35796],
        [25302]], device='cuda:0')
[2024-07-24 10:17:06,888][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[38210],
        [38015],
        [34387],
        [29771],
        [18674],
        [14365],
        [14763],
        [30622],
        [35065],
        [17019],
        [11318],
        [32691],
        [19422],
        [21390],
        [19053]], device='cuda:0')
[2024-07-24 10:17:06,890][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[45195],
        [29339],
        [42064],
        [38470],
        [42393],
        [34194],
        [42740],
        [41608],
        [40141],
        [39693],
        [39576],
        [45725],
        [45595],
        [45564],
        [44561]], device='cuda:0')
[2024-07-24 10:17:06,891][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[38538],
        [19065],
        [42532],
        [18816],
        [30323],
        [32105],
        [17037],
        [13713],
        [25350],
        [23050],
        [13149],
        [15151],
        [11050],
        [12369],
        [ 8453]], device='cuda:0')
[2024-07-24 10:17:06,892][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[23231],
        [22650],
        [22041],
        [20261],
        [14916],
        [18202],
        [20530],
        [19116],
        [21747],
        [22070],
        [22067],
        [19689],
        [19005],
        [22061],
        [21973]], device='cuda:0')
[2024-07-24 10:17:06,894][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[31680],
        [31996],
        [33382],
        [34889],
        [34457],
        [35522],
        [36088],
        [34865],
        [34568],
        [35491],
        [35851],
        [35466],
        [35502],
        [34989],
        [35004]], device='cuda:0')
[2024-07-24 10:17:06,896][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31469],
        [ 2894],
        [12155],
        [10815],
        [12683],
        [ 6455],
        [ 2564],
        [ 6175],
        [ 1692],
        [ 1678],
        [ 1629],
        [  906],
        [  964],
        [  808],
        [  862]], device='cuda:0')
[2024-07-24 10:17:06,897][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[34944],
        [ 9167],
        [ 9025],
        [ 9659],
        [ 9767],
        [10541],
        [12212],
        [10942],
        [11954],
        [11371],
        [ 9357],
        [ 8813],
        [ 7987],
        [ 7947],
        [ 7646]], device='cuda:0')
[2024-07-24 10:17:06,899][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[44359],
        [44496],
        [47227],
        [44755],
        [45985],
        [45643],
        [45617],
        [47160],
        [47425],
        [46689],
        [46549],
        [46749],
        [44817],
        [46219],
        [45632]], device='cuda:0')
[2024-07-24 10:17:06,900][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[37415],
        [46343],
        [43919],
        [41919],
        [38369],
        [37248],
        [36914],
        [38091],
        [31989],
        [43448],
        [31833],
        [32683],
        [35530],
        [33681],
        [37743]], device='cuda:0')
[2024-07-24 10:17:06,901][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[27800],
        [48555],
        [48681],
        [48747],
        [48767],
        [49322],
        [48816],
        [48901],
        [45221],
        [45173],
        [43969],
        [47668],
        [48378],
        [48619],
        [47685]], device='cuda:0')
[2024-07-24 10:17:06,902][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[41768],
        [45853],
        [37155],
        [38526],
        [37030],
        [35044],
        [37576],
        [34457],
        [21629],
        [28373],
        [26395],
        [23342],
        [20942],
        [26313],
        [20351]], device='cuda:0')
[2024-07-24 10:17:06,903][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46673],
        [46454],
        [45283],
        [44310],
        [41122],
        [42231],
        [43678],
        [43798],
        [43209],
        [43146],
        [42789],
        [43255],
        [42865],
        [43066],
        [42996]], device='cuda:0')
[2024-07-24 10:17:06,903][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31786],
        [31791],
        [31716],
        [31727],
        [31349],
        [31422],
        [31663],
        [31234],
        [31861],
        [31553],
        [31280],
        [31834],
        [31310],
        [31818],
        [31702]], device='cuda:0')
[2024-07-24 10:17:06,904][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30165],
        [30382],
        [34417],
        [40000],
        [44425],
        [43168],
        [41806],
        [36240],
        [33808],
        [42917],
        [45817],
        [36426],
        [45754],
        [44132],
        [44320]], device='cuda:0')
[2024-07-24 10:17:06,906][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[44802],
        [27906],
        [36253],
        [30593],
        [36241],
        [28386],
        [36085],
        [29123],
        [22605],
        [22605],
        [22626],
        [26218],
        [26627],
        [26652],
        [27342]], device='cuda:0')
[2024-07-24 10:17:06,908][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32399],
        [42707],
        [36196],
        [41338],
        [38619],
        [39186],
        [41553],
        [43276],
        [45329],
        [39371],
        [38822],
        [43471],
        [43543],
        [43279],
        [40805]], device='cuda:0')
[2024-07-24 10:17:06,909][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[45986],
        [45958],
        [45982],
        [45838],
        [45262],
        [45640],
        [45501],
        [45884],
        [45926],
        [45648],
        [45333],
        [45754],
        [44423],
        [45844],
        [45629]], device='cuda:0')
[2024-07-24 10:17:06,910][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28194],
        [28118],
        [27712],
        [27290],
        [20842],
        [20164],
        [26586],
        [25438],
        [25894],
        [24477],
        [25385],
        [25425],
        [25571],
        [25072],
        [26854]], device='cuda:0')
[2024-07-24 10:17:06,912][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[40571],
        [16594],
        [20660],
        [21939],
        [22186],
        [20467],
        [25503],
        [38107],
        [36791],
        [36792],
        [36797],
        [28013],
        [28109],
        [28425],
        [30196]], device='cuda:0')
[2024-07-24 10:17:06,913][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[38130],
        [38127],
        [34650],
        [36908],
        [35892],
        [37978],
        [38633],
        [37182],
        [34470],
        [38631],
        [38378],
        [37777],
        [35366],
        [35654],
        [34257]], device='cuda:0')
[2024-07-24 10:17:06,915][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[18843],
        [17894],
        [15419],
        [18501],
        [13687],
        [14236],
        [14984],
        [18801],
        [16484],
        [16649],
        [16753],
        [16425],
        [16850],
        [14790],
        [13645]], device='cuda:0')
[2024-07-24 10:17:06,916][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[2127],
        [1389],
        [2164],
        [1678],
        [2281],
        [2120],
        [1535],
        [1332],
        [2238],
        [1894],
        [1964],
        [2092],
        [1949],
        [1925],
        [2152]], device='cuda:0')
[2024-07-24 10:17:06,918][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 6999],
        [ 2408],
        [ 3482],
        [ 5032],
        [ 5731],
        [ 9597],
        [ 7261],
        [ 6964],
        [15625],
        [ 7392],
        [19598],
        [13932],
        [ 9947],
        [12697],
        [ 9298]], device='cuda:0')
[2024-07-24 10:17:06,919][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507],
        [42507]], device='cuda:0')
[2024-07-24 10:17:06,978][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:06,979][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,980][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,981][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,983][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,984][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,985][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,986][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,988][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,989][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,991][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,992][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,992][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:06,992][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5355, 0.4645], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,993][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,993][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9983, 0.0017], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,993][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9951, 0.0049], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,994][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2023, 0.7977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,994][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7415, 0.2585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,994][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7053, 0.2947], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,994][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0552, 0.9448], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,995][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.0910e-05, 9.9999e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,995][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,995][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9636, 0.0364], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,995][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7637, 0.2363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:06,996][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Brittany] are: tensor([0.9352, 0.0011, 0.0636], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,996][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Brittany] are: tensor([0.0462, 0.0200, 0.9338], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:06,998][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Brittany] are: tensor([0.5378, 0.0016, 0.4605], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,000][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Brittany] are: tensor([0.0150, 0.7664, 0.2186], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,001][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Brittany] are: tensor([1.7873e-04, 6.2149e-01, 3.7834e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,001][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Brittany] are: tensor([3.0888e-05, 2.3855e-03, 9.9758e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,003][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Brittany] are: tensor([0.1843, 0.0867, 0.7290], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,004][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Brittany] are: tensor([0.0433, 0.5942, 0.3625], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,006][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Brittany] are: tensor([0.2037, 0.2145, 0.5818], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,007][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Brittany] are: tensor([1.6098e-02, 4.1652e-04, 9.8349e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,008][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Brittany] are: tensor([0.0244, 0.7629, 0.2127], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,010][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Brittany] are: tensor([0.9894, 0.0078, 0.0028], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,012][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5186, 0.0735, 0.2775, 0.1304], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,013][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.5506e-01, 5.5214e-04, 8.4432e-01, 7.4113e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,014][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.3454e-02, 8.0306e-06, 9.8651e-01, 2.4589e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,014][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([4.1440e-01, 7.9863e-03, 5.7760e-01, 1.1957e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,017][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0030, 0.4260, 0.0058, 0.5652], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,018][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0739, 0.0593, 0.8650, 0.0018], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,020][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0216, 0.0186, 0.9522, 0.0076], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,020][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0083, 0.5097, 0.2777, 0.2043], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,021][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([3.3914e-05, 7.5942e-01, 1.6923e-01, 7.1318e-02], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,021][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.8889e-02, 3.6668e-04, 9.8073e-01, 1.5185e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,021][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3917, 0.3010, 0.2887, 0.0186], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,022][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3021, 0.5136, 0.1806, 0.0037], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,022][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([7.0795e-01, 9.0064e-04, 1.6596e-01, 5.6423e-04, 1.2463e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,022][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([0.1701, 0.0085, 0.7807, 0.0081, 0.0325], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,022][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([1.1802e-02, 8.3731e-04, 9.8660e-01, 1.1583e-04, 6.4701e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,023][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([0.0708, 0.2116, 0.7002, 0.0081, 0.0093], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,023][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0035, 0.1959, 0.3206, 0.3244, 0.1555], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,023][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([3.4954e-04, 6.8215e-04, 9.9557e-01, 1.3463e-04, 3.2677e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,024][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0970, 0.0935, 0.6813, 0.0176, 0.1105], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,024][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0038, 0.5310, 0.2708, 0.1080, 0.0864], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,025][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0020, 0.1874, 0.5031, 0.1428, 0.1647], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,026][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([5.5808e-04, 2.1379e-05, 9.9073e-01, 7.7464e-07, 8.6894e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,027][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.1063, 0.1181, 0.0172, 0.0087, 0.7497], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,028][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([8.7088e-01, 9.6222e-02, 3.1378e-02, 1.5518e-04, 1.3678e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,030][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8424, 0.0020, 0.0122, 0.0016, 0.1358, 0.0060], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,030][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([8.7408e-04, 1.4548e-03, 9.7627e-01, 8.3462e-04, 2.0474e-02, 9.6582e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,031][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([4.6710e-02, 1.0434e-04, 9.3610e-01, 8.6336e-05, 1.6485e-02, 5.1900e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,032][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([2.2308e-03, 1.6674e-01, 8.1392e-01, 2.8706e-04, 9.9469e-03, 6.8755e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,034][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0016, 0.1037, 0.3027, 0.0746, 0.2298, 0.2876], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,035][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([6.2873e-04, 3.6052e-03, 9.6596e-01, 2.6360e-04, 2.9527e-02, 1.2784e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,037][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.4208, 0.0094, 0.4796, 0.0023, 0.0645, 0.0234], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,038][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0021, 0.4381, 0.2470, 0.1234, 0.0726, 0.1169], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,040][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0020, 0.2060, 0.2817, 0.1140, 0.2376, 0.1588], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,041][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([1.2173e-02, 2.6552e-04, 9.6644e-01, 8.7146e-06, 2.0901e-02, 2.1640e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,042][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([6.6002e-04, 5.8472e-02, 2.8298e-02, 1.3770e-03, 8.3122e-01, 7.9974e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,043][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([9.1153e-01, 6.2962e-02, 2.0612e-02, 6.8342e-05, 3.9402e-04, 4.4328e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,043][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7407, 0.0063, 0.0436, 0.0091, 0.1859, 0.0013, 0.0131],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,044][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.0469e-02, 1.1151e-04, 9.7083e-01, 2.5160e-05, 8.5523e-03, 1.4682e-05,
        1.4638e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,044][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.3851e-02, 6.6566e-06, 9.4367e-01, 2.4700e-05, 3.2355e-02, 9.0646e-05,
        4.0755e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,044][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.1532e-03, 6.8209e-01, 3.0561e-01, 1.3307e-03, 1.3732e-03, 8.4187e-03,
        2.7753e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,045][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0083, 0.0906, 0.1250, 0.2185, 0.2619, 0.1662, 0.1294],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,045][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.0619e-02, 2.9773e-03, 9.3050e-01, 5.9962e-05, 2.5332e-02, 4.9734e-04,
        1.6834e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,045][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2880, 0.0024, 0.5277, 0.0019, 0.1610, 0.0164, 0.0027],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,045][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0025, 0.4377, 0.1743, 0.0869, 0.0521, 0.0930, 0.1537],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,046][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0005, 0.0903, 0.0073, 0.3174, 0.0302, 0.4766, 0.0777],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,046][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([8.2424e-03, 1.3444e-05, 8.9923e-01, 1.2157e-06, 9.2465e-02, 4.8676e-05,
        3.4257e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,046][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([5.8280e-03, 2.5152e-02, 1.0845e-02, 4.8058e-04, 9.3725e-01, 1.8112e-02,
        2.3341e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,047][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([8.0526e-01, 1.4564e-01, 2.5298e-02, 6.0631e-05, 4.3747e-04, 1.9610e-02,
        3.6920e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,047][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([9.3965e-01, 6.4016e-04, 1.3875e-02, 7.4073e-04, 3.2215e-02, 1.1790e-03,
        3.0609e-03, 8.6383e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,048][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([6.2282e-02, 1.3822e-02, 8.1078e-01, 1.2115e-02, 9.8589e-02, 6.8480e-04,
        1.4008e-04, 1.5911e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,049][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([1.0940e-01, 2.0256e-03, 8.5104e-01, 1.3328e-03, 2.0132e-02, 2.5491e-03,
        7.7839e-04, 1.2745e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,051][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0029, 0.1641, 0.4189, 0.0049, 0.0157, 0.3822, 0.0045, 0.0067],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,052][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0011, 0.5382, 0.0501, 0.1720, 0.0260, 0.1143, 0.0145, 0.0839],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,053][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([7.6959e-03, 9.4478e-04, 9.8340e-01, 1.6255e-04, 7.1796e-03, 1.7411e-05,
        2.6892e-06, 5.9821e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,054][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1254, 0.0648, 0.4178, 0.0137, 0.0387, 0.0670, 0.0062, 0.2665],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,056][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0031, 0.2984, 0.1660, 0.0748, 0.0737, 0.0804, 0.1326, 0.1709],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,057][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([8.0888e-05, 8.3721e-02, 4.2697e-02, 2.3292e-01, 3.2769e-02, 7.0694e-02,
        5.2293e-01, 1.4191e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,058][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([5.8839e-02, 2.5405e-04, 8.2024e-01, 1.4241e-05, 8.9498e-02, 8.8937e-05,
        4.7268e-05, 3.1017e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,059][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0010, 0.3374, 0.0207, 0.0379, 0.1082, 0.1788, 0.3109, 0.0051],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,060][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([9.7813e-01, 2.1323e-03, 7.5196e-04, 3.2458e-06, 4.3970e-05, 3.0740e-04,
        1.0920e-04, 1.8519e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,062][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.8129, 0.0034, 0.0224, 0.0023, 0.0957, 0.0015, 0.0060, 0.0153, 0.0404],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,063][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([3.7301e-02, 1.2880e-02, 8.7432e-01, 1.8639e-03, 6.9943e-02, 1.3204e-03,
        2.0298e-04, 2.0608e-03, 1.1063e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,064][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([6.4315e-02, 9.0857e-05, 9.1050e-01, 2.9588e-05, 5.2314e-03, 2.7961e-04,
        3.0389e-05, 3.0213e-03, 1.6498e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,066][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0709, 0.0391, 0.7097, 0.0008, 0.0924, 0.0154, 0.0019, 0.0443, 0.0254],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,066][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([2.2524e-04, 1.2663e-01, 5.9077e-02, 1.1496e-01, 6.9618e-02, 3.9935e-02,
        1.6386e-01, 3.8603e-01, 3.9668e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,067][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([4.6788e-03, 3.4169e-03, 9.7793e-01, 1.6123e-04, 1.2435e-02, 1.1925e-04,
        4.9066e-05, 1.0848e-03, 1.2597e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,067][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1020, 0.0405, 0.4501, 0.0074, 0.0313, 0.0548, 0.0257, 0.2734, 0.0149],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,067][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0072, 0.2646, 0.1056, 0.0777, 0.0611, 0.0970, 0.1040, 0.1665, 0.1163],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,068][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0009, 0.0771, 0.0254, 0.1801, 0.0639, 0.2603, 0.1495, 0.0786, 0.1642],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,068][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([2.7547e-02, 1.0140e-03, 6.9965e-01, 3.9395e-05, 2.2789e-01, 6.4137e-04,
        3.5798e-04, 3.4360e-02, 8.5022e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,068][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0053, 0.2367, 0.0915, 0.0126, 0.4565, 0.1082, 0.0308, 0.0206, 0.0378],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,069][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([9.7458e-01, 7.6415e-04, 6.3569e-04, 5.0891e-07, 1.5237e-05, 7.8066e-05,
        1.3132e-05, 1.0243e-02, 1.3667e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,069][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3643, 0.0392, 0.1207, 0.0331, 0.2346, 0.0030, 0.0194, 0.0246, 0.0139,
        0.1472], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,069][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.6241e-01, 5.3007e-05, 5.3421e-01, 1.5610e-05, 2.9082e-01, 1.2214e-04,
        3.2917e-06, 1.1669e-05, 1.2198e-02, 1.5482e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,069][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.8308e-04, 1.4446e-06, 9.8563e-01, 2.4932e-06, 8.1999e-03, 1.1044e-05,
        1.1060e-06, 3.9554e-04, 4.9779e-03, 4.4137e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,070][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.6796e-01, 1.3487e-03, 4.2588e-01, 3.1110e-06, 1.7931e-02, 7.6476e-03,
        3.3356e-05, 3.0293e-03, 3.7415e-01, 2.0142e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,070][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([6.6134e-04, 1.8006e-03, 5.0163e-03, 3.4140e-03, 4.8349e-02, 3.6110e-03,
        6.7831e-01, 1.7499e-01, 4.7397e-02, 3.6455e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,072][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.9114e-03, 1.1464e-03, 2.3986e-02, 3.6836e-05, 7.2135e-02, 3.7295e-03,
        2.1325e-04, 3.2711e-04, 8.9510e-01, 1.4136e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,073][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0069, 0.0046, 0.7355, 0.0011, 0.1024, 0.0083, 0.0059, 0.1006, 0.0339,
        0.0007], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,075][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0012, 0.2717, 0.1407, 0.0740, 0.0345, 0.0574, 0.0937, 0.1393, 0.1316,
        0.0560], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,075][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([2.8840e-05, 8.6238e-02, 3.8985e-02, 7.7327e-02, 8.4538e-02, 7.0205e-02,
        2.0725e-01, 5.4011e-02, 2.9887e-01, 8.2547e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,076][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([8.4992e-03, 3.1421e-04, 6.0817e-01, 1.1860e-05, 7.3139e-02, 1.0096e-03,
        5.2932e-05, 2.0680e-02, 2.8803e-01, 9.1138e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,077][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([1.2263e-01, 7.3192e-03, 1.0059e-01, 5.1058e-04, 7.3546e-01, 6.9338e-03,
        3.0177e-04, 1.1519e-03, 1.1088e-02, 1.4020e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,078][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([7.1721e-01, 1.0052e-02, 1.4462e-02, 3.4687e-06, 1.3268e-04, 6.8539e-04,
        1.5812e-04, 1.2365e-01, 1.3278e-01, 8.6107e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,080][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3160, 0.0152, 0.2341, 0.0130, 0.1615, 0.0029, 0.0135, 0.0623, 0.0199,
        0.0642, 0.0974], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,081][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.2426e-01, 1.8678e-04, 3.3046e-01, 1.2587e-05, 2.3614e-01, 1.7265e-04,
        7.4048e-06, 6.6330e-06, 8.4739e-03, 2.2606e-04, 5.1045e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,082][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([9.0945e-04, 3.7954e-06, 9.8258e-01, 1.0123e-05, 7.9139e-03, 5.4645e-05,
        7.6089e-06, 4.6178e-04, 8.0488e-03, 1.6260e-06, 7.2599e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,083][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([2.1094e-01, 8.2690e-04, 2.3679e-01, 4.9263e-07, 1.9728e-02, 2.3033e-02,
        2.1088e-04, 6.9596e-03, 4.9981e-01, 1.5614e-03, 1.3910e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,084][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([4.4441e-04, 3.2338e-03, 3.2482e-04, 4.1801e-03, 2.3656e-02, 1.7000e-03,
        7.8104e-01, 4.7840e-02, 2.6073e-02, 7.1213e-02, 4.0295e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,085][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.7177e-03, 1.1536e-03, 9.8082e-03, 1.7365e-05, 2.6393e-02, 1.9379e-03,
        7.1370e-05, 1.0948e-04, 9.5719e-01, 1.3602e-03, 2.3887e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,087][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0044, 0.0211, 0.6152, 0.0053, 0.1141, 0.0196, 0.0212, 0.1273, 0.0658,
        0.0035, 0.0025], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,088][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0007, 0.2791, 0.1407, 0.0696, 0.0278, 0.0536, 0.0898, 0.1359, 0.1104,
        0.0471, 0.0452], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,089][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([3.6293e-05, 5.6318e-02, 4.5393e-02, 1.7358e-02, 9.6606e-02, 9.3017e-02,
        3.1049e-01, 6.7444e-02, 2.7114e-01, 3.7439e-02, 4.7590e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,090][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.1516e-02, 1.2389e-03, 4.5919e-01, 5.1867e-05, 1.0240e-01, 2.5459e-03,
        3.4815e-04, 1.9975e-02, 4.0205e-01, 4.2653e-04, 2.5817e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,090][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([3.5970e-02, 1.0204e-02, 5.2491e-02, 1.5006e-03, 8.3008e-01, 9.3233e-03,
        7.3976e-04, 1.5861e-03, 1.3117e-02, 4.2756e-02, 2.2289e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,090][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([8.1849e-01, 9.4844e-03, 1.1531e-02, 2.1602e-06, 5.0119e-05, 6.4904e-04,
        1.5669e-04, 9.5892e-02, 6.2794e-02, 6.8453e-04, 2.7081e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,091][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.6288, 0.0017, 0.0700, 0.0011, 0.2075, 0.0016, 0.0012, 0.0080, 0.0232,
        0.0033, 0.0058, 0.0479], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,091][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.3961e-01, 1.0088e-02, 5.9834e-01, 1.9524e-03, 1.9628e-01, 1.0574e-03,
        1.3094e-04, 5.6042e-04, 2.9791e-03, 3.2374e-03, 8.8432e-04, 4.4876e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,091][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([6.8129e-02, 4.0079e-04, 7.1724e-01, 3.0623e-04, 2.9532e-02, 3.0736e-03,
        6.8634e-04, 2.6400e-02, 1.3170e-01, 2.6834e-04, 5.6805e-04, 2.1701e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,092][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([2.1169e-02, 1.5993e-03, 3.3921e-01, 1.5242e-04, 1.4825e-02, 6.0890e-03,
        4.1585e-04, 2.2667e-02, 6.5696e-02, 4.0750e-03, 1.8158e-03, 5.2229e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,092][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([5.6715e-05, 3.7900e-02, 1.6136e-02, 7.9709e-02, 1.9145e-01, 4.1095e-03,
        3.7764e-01, 8.7626e-02, 5.1234e-03, 5.0549e-02, 6.9290e-02, 8.0409e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,092][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0986, 0.0615, 0.3156, 0.0046, 0.2188, 0.0051, 0.0026, 0.0094, 0.1664,
        0.0117, 0.0077, 0.0981], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,093][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1121, 0.1060, 0.2081, 0.0141, 0.0587, 0.0429, 0.0317, 0.2191, 0.0261,
        0.0128, 0.0108, 0.1575], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,093][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0027, 0.2411, 0.0559, 0.0533, 0.0254, 0.0719, 0.0705, 0.1097, 0.0841,
        0.0596, 0.0680, 0.1579], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,094][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([4.1439e-05, 3.6876e-02, 6.1349e-02, 1.9699e-01, 2.8848e-02, 1.9556e-01,
        3.3701e-01, 1.7895e-02, 1.0065e-01, 1.3075e-02, 9.8211e-03, 1.8780e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,095][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.9388e-02, 4.0247e-04, 7.9087e-01, 1.1673e-05, 5.8026e-02, 1.3873e-04,
        1.9841e-05, 3.0055e-02, 1.6691e-02, 5.1655e-05, 4.4625e-05, 8.4297e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,096][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0951, 0.0723, 0.1385, 0.0228, 0.2486, 0.0565, 0.0160, 0.0266, 0.0558,
        0.0790, 0.0116, 0.1772], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,097][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([9.2925e-01, 1.6144e-03, 8.3159e-04, 1.6813e-06, 3.3743e-05, 1.4724e-04,
        3.0601e-05, 1.2981e-02, 3.6189e-02, 2.5423e-04, 1.4381e-04, 1.8526e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,098][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Sarah] are: tensor([6.2927e-01, 1.9914e-04, 1.5960e-01, 1.7823e-04, 3.8849e-02, 7.6331e-04,
        5.2901e-04, 9.2985e-04, 1.4613e-02, 6.0845e-04, 1.4536e-03, 7.9519e-02,
        7.3487e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,099][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Sarah] are: tensor([3.6004e-01, 1.1900e-03, 4.2907e-01, 1.0209e-03, 1.5634e-02, 5.3949e-04,
        2.8565e-05, 1.5320e-04, 3.8866e-03, 1.9730e-03, 1.1610e-03, 1.8001e-01,
        5.2995e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,100][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Sarah] are: tensor([1.2275e-03, 2.5691e-04, 9.6496e-01, 3.4233e-05, 2.0695e-04, 8.8728e-04,
        4.6925e-05, 3.2205e-03, 2.2713e-02, 6.4018e-05, 2.0407e-04, 5.0043e-03,
        1.1697e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,101][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Sarah] are: tensor([1.5809e-02, 5.9215e-04, 5.1493e-02, 1.7454e-05, 9.1754e-04, 6.5475e-03,
        7.3579e-05, 7.7755e-03, 1.5280e-01, 3.2146e-03, 7.4750e-04, 7.4381e-01,
        1.6205e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,103][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Sarah] are: tensor([0.0024, 0.0163, 0.0233, 0.0370, 0.0490, 0.0115, 0.0924, 0.0922, 0.0081,
        0.0218, 0.0668, 0.3550, 0.2244], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,104][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Sarah] are: tensor([1.0633e-03, 8.6480e-04, 9.2157e-01, 1.6448e-04, 1.2531e-02, 2.1203e-03,
        6.3053e-05, 9.1110e-04, 4.9952e-03, 1.8165e-04, 1.9209e-04, 4.8657e-02,
        6.6890e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,105][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Sarah] are: tensor([0.0262, 0.0208, 0.5230, 0.0033, 0.0837, 0.0186, 0.0051, 0.2008, 0.0135,
        0.0011, 0.0017, 0.0436, 0.0584], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,107][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Sarah] are: tensor([0.0010, 0.2390, 0.0988, 0.0425, 0.0248, 0.0535, 0.0709, 0.0792, 0.1097,
        0.0404, 0.0423, 0.1307, 0.0672], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,109][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Sarah] are: tensor([0.0012, 0.0540, 0.1564, 0.0960, 0.0789, 0.1667, 0.2615, 0.0220, 0.1366,
        0.0115, 0.0033, 0.0084, 0.0035], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,110][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Sarah] are: tensor([2.3145e-03, 1.6028e-04, 8.8571e-01, 6.9795e-06, 4.0004e-02, 1.7158e-04,
        1.6567e-05, 1.2416e-02, 2.2912e-02, 3.2044e-05, 4.5415e-05, 1.6145e-02,
        2.0060e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,111][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Sarah] are: tensor([0.2440, 0.0094, 0.0117, 0.0022, 0.2335, 0.0121, 0.0019, 0.1212, 0.0208,
        0.0081, 0.0040, 0.2056, 0.1255], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,112][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Sarah] are: tensor([9.8820e-01, 5.8447e-04, 4.7710e-04, 2.5106e-07, 3.5930e-06, 1.0355e-04,
        1.6754e-05, 3.0717e-03, 4.6443e-03, 2.3428e-05, 1.2633e-05, 2.7817e-03,
        8.0629e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,113][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([8.4374e-01, 5.6143e-04, 2.7346e-02, 2.3862e-04, 3.1271e-02, 1.2584e-04,
        1.3826e-04, 1.1630e-03, 5.4383e-03, 2.4687e-03, 2.0442e-03, 2.2309e-02,
        5.8591e-02, 4.5675e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,113][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([8.4800e-03, 1.5889e-04, 9.5617e-01, 5.5347e-05, 2.3708e-02, 6.0247e-05,
        1.1334e-06, 3.1189e-05, 5.9346e-04, 3.9528e-05, 8.4717e-05, 7.5777e-03,
        2.8477e-03, 1.9542e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,113][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([2.2339e-02, 1.8995e-05, 8.8708e-01, 1.7353e-05, 7.1543e-03, 2.1732e-04,
        1.7735e-05, 3.2131e-03, 4.5633e-02, 1.0197e-05, 4.2835e-05, 5.8726e-03,
        2.5680e-02, 2.7053e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,114][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.0502e-02, 3.0055e-02, 9.0037e-02, 9.0876e-05, 2.1140e-02, 1.0891e-03,
        4.2078e-05, 1.2714e-03, 3.7068e-02, 1.4473e-02, 4.4209e-03, 4.6321e-01,
        3.2043e-01, 6.1650e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,114][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([2.5927e-04, 3.2840e-02, 7.5513e-02, 1.8150e-02, 2.9947e-02, 1.3700e-02,
        5.9673e-02, 2.6398e-01, 1.1270e-02, 3.6385e-03, 3.2667e-02, 3.5446e-01,
        3.5712e-02, 6.8194e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,114][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([3.8810e-03, 2.4673e-03, 8.7170e-01, 3.4743e-05, 7.0116e-03, 2.5515e-04,
        9.1740e-06, 1.0443e-03, 2.8174e-03, 6.5235e-05, 3.9084e-05, 1.0780e-01,
        2.8413e-03, 2.4972e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,115][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1488, 0.0122, 0.2804, 0.0034, 0.0575, 0.0164, 0.0082, 0.3716, 0.0122,
        0.0009, 0.0018, 0.0318, 0.0385, 0.0161], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,115][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0021, 0.1974, 0.0814, 0.0415, 0.0219, 0.0609, 0.0572, 0.0986, 0.0827,
        0.0465, 0.0443, 0.1053, 0.0498, 0.1103], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,115][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0019, 0.0282, 0.0518, 0.0508, 0.0436, 0.2220, 0.1332, 0.0627, 0.2913,
        0.0586, 0.0086, 0.0215, 0.0063, 0.0194], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,116][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.3814e-02, 4.4005e-05, 8.4600e-01, 1.3024e-06, 4.3063e-02, 1.1369e-04,
        5.7673e-06, 2.2814e-02, 1.6654e-02, 5.5746e-06, 6.3704e-06, 4.1293e-02,
        1.5673e-02, 5.1162e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,116][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0136, 0.0458, 0.0715, 0.0020, 0.2988, 0.0091, 0.0052, 0.0216, 0.0043,
        0.0825, 0.0049, 0.0613, 0.3722, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,118][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([9.9287e-01, 3.6283e-04, 3.4301e-04, 7.2444e-08, 3.8156e-06, 1.4942e-05,
        1.9626e-06, 9.9426e-04, 1.9515e-03, 7.1801e-06, 1.7020e-06, 2.6513e-03,
        8.1151e-05, 7.1403e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,119][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5361, 0.0051, 0.0613, 0.0021, 0.0375, 0.0010, 0.0027, 0.0063, 0.0663,
        0.0229, 0.0155, 0.0784, 0.1369, 0.0234, 0.0046], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,120][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.9110e-02, 1.8199e-04, 8.1269e-01, 8.1286e-06, 9.7953e-02, 7.2584e-06,
        5.2690e-07, 6.6188e-06, 2.8522e-04, 2.9937e-05, 2.9894e-05, 6.9926e-03,
        5.2641e-02, 5.7724e-05, 4.0862e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,121][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([8.2900e-04, 8.3305e-06, 9.5825e-01, 1.9337e-05, 6.9367e-03, 1.1084e-04,
        1.1447e-05, 4.9649e-04, 8.5237e-03, 2.5381e-06, 1.7869e-05, 2.1423e-03,
        2.1802e-02, 5.3221e-04, 3.1761e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,122][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.1470e-03, 1.1689e-02, 1.7177e-01, 8.5131e-06, 3.0630e-03, 5.2965e-03,
        1.8469e-05, 5.3178e-04, 1.2980e-01, 7.5281e-03, 9.3780e-04, 5.3869e-01,
        1.1943e-01, 6.3672e-03, 7.1067e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,123][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0012, 0.0108, 0.0123, 0.0088, 0.0333, 0.0149, 0.0200, 0.0887, 0.0774,
        0.0087, 0.0359, 0.2612, 0.2364, 0.0407, 0.1497], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,124][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.1709e-02, 3.5094e-03, 6.8660e-01, 1.1104e-04, 8.0949e-02, 2.6658e-04,
        2.2640e-05, 3.8288e-04, 1.0191e-02, 2.4718e-04, 1.9015e-04, 1.1423e-01,
        9.1328e-02, 1.0071e-04, 1.6621e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,125][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([4.2307e-02, 1.9233e-03, 5.0729e-01, 4.6046e-04, 1.2609e-01, 6.3615e-03,
        1.1807e-03, 1.1702e-01, 1.1975e-02, 2.4834e-04, 2.7145e-04, 1.6309e-02,
        1.5830e-01, 4.4425e-03, 5.8100e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,127][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0008, 0.1989, 0.0684, 0.0349, 0.0142, 0.0452, 0.0488, 0.0875, 0.0917,
        0.0431, 0.0416, 0.1000, 0.0323, 0.1001, 0.0927], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,128][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.5009e-05, 5.5611e-02, 1.5999e-02, 1.0268e-01, 3.6572e-02, 1.5935e-01,
        2.8886e-01, 2.8228e-02, 1.9381e-01, 4.1938e-02, 1.0891e-02, 9.8849e-03,
        4.7680e-03, 1.6731e-02, 3.4610e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,129][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([4.4946e-03, 2.5967e-04, 7.3740e-01, 8.8067e-06, 9.6609e-02, 3.6858e-04,
        2.7730e-05, 1.8018e-02, 5.5421e-02, 2.8924e-05, 3.1893e-05, 5.5727e-02,
        3.0650e-02, 8.0302e-04, 1.5389e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,131][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0069, 0.0986, 0.0083, 0.0013, 0.2610, 0.0047, 0.0005, 0.0005, 0.0031,
        0.1325, 0.0046, 0.0299, 0.4451, 0.0006, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,132][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9815e-01, 6.7496e-05, 7.1087e-05, 4.6133e-09, 7.6201e-07, 4.4134e-06,
        2.7485e-07, 1.4887e-04, 7.8021e-04, 1.6236e-06, 3.2129e-07, 5.4284e-04,
        2.4048e-05, 2.0243e-04, 7.2667e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,181][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:17:07,183][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,184][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,186][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,187][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,187][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,188][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,188][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,188][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,188][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,189][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,189][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,189][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:17:07,190][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.5355, 0.4645], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,190][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,190][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9705, 0.0295], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,191][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9951, 0.0049], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,191][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2023, 0.7977], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,193][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7415, 0.2585], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,195][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9979, 0.0021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,196][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.9940e-01, 6.0043e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,197][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([4.7280e-07, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,198][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9604, 0.0396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,200][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9636, 0.0364], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,201][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9995e-01, 4.8512e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:17:07,203][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Brittany] are: tensor([0.9352, 0.0011, 0.0636], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,204][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Brittany] are: tensor([0.0462, 0.0200, 0.9338], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,206][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Brittany] are: tensor([0.0021, 0.3878, 0.6101], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,208][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Brittany] are: tensor([0.0150, 0.7664, 0.2186], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,209][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Brittany] are: tensor([1.7873e-04, 6.2149e-01, 3.7834e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,210][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Brittany] are: tensor([3.0888e-05, 2.3855e-03, 9.9758e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,210][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Brittany] are: tensor([5.5493e-04, 3.8953e-03, 9.9555e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,210][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Brittany] are: tensor([0.0049, 0.0024, 0.9927], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,211][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Brittany] are: tensor([0.9243, 0.0314, 0.0442], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,211][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Brittany] are: tensor([4.3282e-05, 5.0736e-04, 9.9945e-01], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,211][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Brittany] are: tensor([0.0244, 0.7629, 0.2127], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,211][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Brittany] are: tensor([0.0018, 0.0030, 0.9953], device='cuda:0') for source tokens [Then, Brittany]
[2024-07-24 10:17:07,212][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5186, 0.0735, 0.2775, 0.1304], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,212][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.5506e-01, 5.5214e-04, 8.4432e-01, 7.4113e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,212][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([9.2577e-02, 2.3471e-02, 8.8332e-01, 6.3295e-04], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,213][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.1440e-01, 7.9863e-03, 5.7760e-01, 1.1957e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,213][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0030, 0.4260, 0.0058, 0.5652], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,213][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0739, 0.0593, 0.8650, 0.0018], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,213][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([5.8196e-02, 3.8213e-04, 9.4142e-01, 2.5928e-06], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,214][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([7.3987e-01, 9.3322e-05, 2.5999e-01, 4.9906e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,214][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([4.1715e-06, 5.9957e-01, 3.9766e-01, 2.7677e-03], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,215][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([4.3447e-01, 1.8987e-03, 5.6358e-01, 5.8030e-05], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,217][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3917, 0.3010, 0.2887, 0.0186], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,218][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([7.9215e-01, 1.7514e-05, 2.0783e-01, 8.6913e-07], device='cuda:0') for source tokens [Then, Brittany and]
[2024-07-24 10:17:07,219][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([7.0795e-01, 9.0064e-04, 1.6596e-01, 5.6423e-04, 1.2463e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,220][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([0.1701, 0.0085, 0.7807, 0.0081, 0.0325], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,221][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([1.6978e-03, 3.1218e-02, 9.6424e-01, 2.8378e-03, 1.6404e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,223][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([0.0708, 0.2116, 0.7002, 0.0081, 0.0093], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,224][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0035, 0.1959, 0.3206, 0.3244, 0.1555], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,225][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([3.4954e-04, 6.8215e-04, 9.9557e-01, 1.3463e-04, 3.2677e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,226][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([1.7767e-02, 5.6877e-03, 9.7468e-01, 9.7116e-05, 1.7669e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,227][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([1.4891e-02, 1.4189e-04, 9.8258e-01, 8.8316e-05, 2.3004e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,229][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0921, 0.2112, 0.6449, 0.0391, 0.0127], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,230][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([1.7067e-03, 4.4449e-05, 9.9820e-01, 1.9358e-06, 4.3879e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,232][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.1063, 0.1181, 0.0172, 0.0087, 0.7497], device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,233][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([2.1495e-03, 4.9349e-04, 9.9716e-01, 1.3620e-05, 1.8607e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah]
[2024-07-24 10:17:07,233][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8424, 0.0020, 0.0122, 0.0016, 0.1358, 0.0060], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,233][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([8.7408e-04, 1.4548e-03, 9.7627e-01, 8.3462e-04, 2.0474e-02, 9.6582e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,234][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0010, 0.1533, 0.8287, 0.0079, 0.0018, 0.0073], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,234][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([2.2308e-03, 1.6674e-01, 8.1392e-01, 2.8706e-04, 9.9469e-03, 6.8755e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,234][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0016, 0.1037, 0.3027, 0.0746, 0.2298, 0.2876], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,235][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([6.2873e-04, 3.6052e-03, 9.6596e-01, 2.6360e-04, 2.9527e-02, 1.2784e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,235][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([5.3480e-03, 3.7482e-04, 9.9283e-01, 8.7466e-06, 1.3813e-03, 5.7327e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,235][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([4.5664e-03, 5.3657e-04, 9.7939e-01, 5.2877e-04, 1.1847e-02, 3.1293e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,235][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0641, 0.5590, 0.2630, 0.0728, 0.0200, 0.0210], device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,236][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.2974e-02, 1.9116e-04, 9.8675e-01, 2.6354e-06, 6.4345e-05, 2.0065e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,236][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([6.6002e-04, 5.8472e-02, 2.8298e-02, 1.3770e-03, 8.3122e-01, 7.9974e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,236][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.9568e-04, 1.7452e-04, 9.9939e-01, 1.2968e-05, 2.2641e-04, 5.2770e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had]
[2024-07-24 10:17:07,237][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7407, 0.0063, 0.0436, 0.0091, 0.1859, 0.0013, 0.0131],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,237][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.0469e-02, 1.1151e-04, 9.7083e-01, 2.5160e-05, 8.5523e-03, 1.4682e-05,
        1.4638e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,239][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.0663e-03, 1.4235e-02, 9.8131e-01, 1.0341e-03, 3.9433e-04, 9.1991e-04,
        4.1192e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,239][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1532e-03, 6.8209e-01, 3.0561e-01, 1.3307e-03, 1.3732e-03, 8.4187e-03,
        2.7753e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,241][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0083, 0.0906, 0.1250, 0.2185, 0.2619, 0.1662, 0.1294],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,242][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.0619e-02, 2.9773e-03, 9.3050e-01, 5.9962e-05, 2.5332e-02, 4.9734e-04,
        1.6834e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,243][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.3501e-02, 5.3909e-05, 9.8620e-01, 1.2896e-06, 2.3820e-04, 3.9602e-06,
        7.2985e-08], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,244][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([7.0191e-01, 2.3921e-04, 2.8313e-01, 1.7756e-04, 1.4121e-02, 1.3692e-04,
        2.8936e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,245][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0238, 0.4601, 0.0075, 0.2095, 0.0037, 0.2917, 0.0037],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,247][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.9709e-01, 7.3556e-04, 8.0078e-01, 1.7989e-05, 1.0887e-03, 2.7576e-04,
        8.4208e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,248][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([5.8280e-03, 2.5152e-02, 1.0845e-02, 4.8058e-04, 9.3725e-01, 1.8112e-02,
        2.3341e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,249][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.2107e-02, 1.5910e-04, 9.7315e-01, 2.0676e-05, 4.2699e-03, 2.1877e-04,
        7.3658e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a]
[2024-07-24 10:17:07,249][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([9.3965e-01, 6.4016e-04, 1.3875e-02, 7.4073e-04, 3.2215e-02, 1.1790e-03,
        3.0609e-03, 8.6383e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,250][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([6.2282e-02, 1.3822e-02, 8.1078e-01, 1.2115e-02, 9.8589e-02, 6.8480e-04,
        1.4008e-04, 1.5911e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,253][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0049, 0.4243, 0.4962, 0.0217, 0.0030, 0.0059, 0.0041, 0.0398],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,254][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0029, 0.1641, 0.4189, 0.0049, 0.0157, 0.3822, 0.0045, 0.0067],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,255][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0011, 0.5382, 0.0501, 0.1720, 0.0260, 0.1143, 0.0145, 0.0839],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,256][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([7.6959e-03, 9.4478e-04, 9.8340e-01, 1.6255e-04, 7.1796e-03, 1.7411e-05,
        2.6892e-06, 5.9821e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,256][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([1.5063e-02, 3.2438e-03, 9.7842e-01, 3.6420e-05, 7.9675e-04, 1.7215e-04,
        3.4941e-06, 2.2667e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,257][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([6.1635e-02, 5.0468e-03, 8.9823e-01, 1.7284e-03, 3.1400e-02, 1.1827e-03,
        1.9653e-04, 5.8146e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,257][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([3.0773e-02, 3.5358e-01, 3.5642e-02, 5.1925e-01, 4.3554e-03, 4.8635e-02,
        7.4410e-03, 3.2647e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,257][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.8420e-01, 2.1788e-03, 8.1253e-01, 4.1939e-05, 6.4857e-04, 8.1967e-05,
        6.0966e-06, 3.1753e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,258][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0010, 0.3374, 0.0207, 0.0379, 0.1082, 0.1788, 0.3109, 0.0051],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,258][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0072, 0.0082, 0.8775, 0.0020, 0.0460, 0.0029, 0.0148, 0.0414],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long]
[2024-07-24 10:17:07,258][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.8129, 0.0034, 0.0224, 0.0023, 0.0957, 0.0015, 0.0060, 0.0153, 0.0404],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,258][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([3.7301e-02, 1.2880e-02, 8.7432e-01, 1.8639e-03, 6.9943e-02, 1.3204e-03,
        2.0298e-04, 2.0608e-03, 1.1063e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,259][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([4.7359e-03, 8.1757e-02, 7.7163e-01, 5.4066e-03, 5.7479e-04, 3.4112e-03,
        1.2429e-03, 1.0328e-01, 2.7958e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,259][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0709, 0.0391, 0.7097, 0.0008, 0.0924, 0.0154, 0.0019, 0.0443, 0.0254],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,259][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([2.2524e-04, 1.2663e-01, 5.9077e-02, 1.1496e-01, 6.9618e-02, 3.9935e-02,
        1.6386e-01, 3.8603e-01, 3.9668e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,260][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([4.6788e-03, 3.4169e-03, 9.7793e-01, 1.6123e-04, 1.2435e-02, 1.1925e-04,
        4.9066e-05, 1.0848e-03, 1.2597e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,261][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([6.1381e-03, 5.2121e-04, 9.9064e-01, 1.0606e-05, 6.3136e-04, 1.0855e-04,
        1.0985e-05, 1.6319e-03, 3.0914e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,262][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([1.8710e-02, 3.7354e-03, 9.3917e-01, 3.3334e-04, 3.3542e-02, 7.4899e-04,
        1.6435e-04, 2.8877e-03, 7.0769e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,264][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0247, 0.2216, 0.0487, 0.1038, 0.0124, 0.3528, 0.0044, 0.0152, 0.2164],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,265][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.6250e-02, 2.0126e-03, 9.5298e-01, 2.1545e-05, 4.1579e-03, 1.3087e-04,
        1.1475e-04, 1.4937e-03, 2.8358e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,266][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0053, 0.2367, 0.0915, 0.0126, 0.4565, 0.1082, 0.0308, 0.0206, 0.0378],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,267][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([2.6077e-02, 1.0777e-04, 8.9847e-01, 2.8045e-05, 6.1262e-03, 1.5554e-04,
        2.2617e-04, 6.8046e-02, 7.6814e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument]
[2024-07-24 10:17:07,269][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3643, 0.0392, 0.1207, 0.0331, 0.2346, 0.0030, 0.0194, 0.0246, 0.0139,
        0.1472], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,270][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6241e-01, 5.3007e-05, 5.3421e-01, 1.5610e-05, 2.9082e-01, 1.2214e-04,
        3.2917e-06, 1.1669e-05, 1.2198e-02, 1.5482e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,271][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.7196e-02, 1.5749e-04, 9.0280e-01, 1.1187e-05, 2.1156e-04, 8.8931e-05,
        4.0582e-06, 4.2983e-04, 2.8735e-02, 3.6798e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,272][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([1.6796e-01, 1.3487e-03, 4.2588e-01, 3.1110e-06, 1.7931e-02, 7.6476e-03,
        3.3356e-05, 3.0293e-03, 3.7415e-01, 2.0142e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,273][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.6134e-04, 1.8006e-03, 5.0163e-03, 3.4140e-03, 4.8349e-02, 3.6110e-03,
        6.7831e-01, 1.7499e-01, 4.7397e-02, 3.6455e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,274][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([1.9114e-03, 1.1464e-03, 2.3986e-02, 3.6836e-05, 7.2135e-02, 3.7295e-03,
        2.1325e-04, 3.2711e-04, 8.9510e-01, 1.4136e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,275][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.8019e-02, 8.5718e-06, 9.8045e-01, 1.2731e-07, 3.9833e-04, 2.4305e-06,
        7.5042e-08, 3.9442e-05, 1.0761e-03, 4.5127e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,276][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([9.2332e-01, 1.6964e-05, 7.0697e-02, 3.6558e-06, 2.2834e-03, 1.6665e-05,
        1.5935e-05, 1.8558e-04, 3.3879e-03, 6.8913e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,277][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([6.8518e-06, 3.4914e-02, 1.1081e-01, 2.4654e-03, 2.7503e-02, 7.7750e-02,
        1.6948e-02, 1.8620e-01, 5.1449e-01, 2.8915e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,278][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([4.7400e-04, 1.3886e-06, 2.6531e-02, 5.9857e-08, 4.0688e-05, 2.2764e-05,
        2.1926e-07, 9.3369e-07, 9.7292e-01, 4.5557e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,279][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.2263e-01, 7.3192e-03, 1.0059e-01, 5.1058e-04, 7.3546e-01, 6.9338e-03,
        3.0177e-04, 1.1519e-03, 1.1088e-02, 1.4020e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,279][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.6454e-01, 8.6439e-07, 4.2791e-01, 8.0949e-08, 3.0461e-03, 1.2789e-05,
        6.0772e-07, 1.0852e-04, 4.3743e-03, 7.7138e-07], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument,]
[2024-07-24 10:17:07,280][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3160, 0.0152, 0.2341, 0.0130, 0.1615, 0.0029, 0.0135, 0.0623, 0.0199,
        0.0642, 0.0974], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,280][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.2426e-01, 1.8678e-04, 3.3046e-01, 1.2587e-05, 2.3614e-01, 1.7265e-04,
        7.4048e-06, 6.6330e-06, 8.4739e-03, 2.2606e-04, 5.1045e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,280][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.7626e-01, 2.9366e-03, 5.1370e-01, 1.0822e-04, 2.4218e-04, 1.3856e-03,
        7.2061e-05, 2.0038e-03, 9.9374e-02, 3.2542e-03, 6.7177e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,280][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([2.1094e-01, 8.2690e-04, 2.3679e-01, 4.9263e-07, 1.9728e-02, 2.3033e-02,
        2.1088e-04, 6.9596e-03, 4.9981e-01, 1.5614e-03, 1.3910e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,281][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([4.4441e-04, 3.2338e-03, 3.2482e-04, 4.1801e-03, 2.3656e-02, 1.7000e-03,
        7.8104e-01, 4.7840e-02, 2.6073e-02, 7.1213e-02, 4.0295e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,281][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.7177e-03, 1.1536e-03, 9.8082e-03, 1.7365e-05, 2.6393e-02, 1.9379e-03,
        7.1370e-05, 1.0948e-04, 9.5719e-01, 1.3602e-03, 2.3887e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,281][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.0737e-01, 1.8202e-04, 8.8710e-01, 1.8229e-06, 1.2960e-03, 1.4560e-05,
        1.4512e-06, 1.5169e-04, 3.7945e-03, 6.6532e-05, 2.6138e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,282][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([9.7245e-01, 3.1961e-05, 2.1777e-02, 3.4642e-06, 1.9992e-03, 7.8767e-06,
        1.5198e-05, 1.1930e-04, 3.4964e-03, 6.7963e-05, 3.2056e-05],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,282][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.4155e-07, 1.0844e-02, 1.6570e-01, 7.5358e-05, 2.1981e-02, 6.2776e-02,
        1.8082e-02, 3.9945e-01, 3.1835e-01, 2.5683e-03, 1.7521e-04],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,282][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.3912e-03, 2.0659e-05, 1.2597e-02, 6.1727e-07, 6.1848e-05, 1.1115e-04,
        3.3369e-06, 1.9761e-06, 9.8571e-01, 9.1365e-05, 8.5317e-06],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,283][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([3.5970e-02, 1.0204e-02, 5.2491e-02, 1.5006e-03, 8.3008e-01, 9.3233e-03,
        7.3976e-04, 1.5861e-03, 1.3117e-02, 4.2756e-02, 2.2289e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,284][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([9.8722e-01, 4.7189e-07, 1.2176e-02, 8.6371e-09, 2.1942e-04, 1.1222e-05,
        2.8985e-07, 2.7479e-05, 3.4756e-04, 5.3811e-07, 1.8959e-07],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and]
[2024-07-24 10:17:07,286][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.6288, 0.0017, 0.0700, 0.0011, 0.2075, 0.0016, 0.0012, 0.0080, 0.0232,
        0.0033, 0.0058, 0.0479], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,287][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.3961e-01, 1.0088e-02, 5.9834e-01, 1.9524e-03, 1.9628e-01, 1.0574e-03,
        1.3094e-04, 5.6042e-04, 2.9791e-03, 3.2374e-03, 8.8432e-04, 4.4876e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,288][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0329, 0.0834, 0.6272, 0.0107, 0.0020, 0.0130, 0.0036, 0.0515, 0.0998,
        0.0297, 0.0093, 0.0369], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,289][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([2.1169e-02, 1.5993e-03, 3.3921e-01, 1.5242e-04, 1.4825e-02, 6.0890e-03,
        4.1585e-04, 2.2667e-02, 6.5696e-02, 4.0750e-03, 1.8158e-03, 5.2229e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,290][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([5.6715e-05, 3.7900e-02, 1.6136e-02, 7.9709e-02, 1.9145e-01, 4.1095e-03,
        3.7764e-01, 8.7626e-02, 5.1234e-03, 5.0549e-02, 6.9290e-02, 8.0409e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,292][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0986, 0.0615, 0.3156, 0.0046, 0.2188, 0.0051, 0.0026, 0.0094, 0.1664,
        0.0117, 0.0077, 0.0981], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,293][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([1.3531e-01, 2.0855e-02, 5.9020e-01, 8.7624e-04, 3.8256e-02, 6.5261e-04,
        3.7166e-04, 1.0889e-02, 2.0008e-02, 3.5998e-03, 2.6556e-03, 1.7633e-01],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,294][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.3108, 0.0035, 0.3601, 0.0018, 0.0816, 0.0012, 0.0021, 0.0210, 0.0078,
        0.0031, 0.0026, 0.2044], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,295][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.7427e-05, 2.5329e-02, 1.8473e-01, 3.6459e-02, 1.0439e-02, 3.4188e-01,
        4.4679e-02, 1.1161e-02, 2.4960e-01, 5.8560e-02, 3.1633e-02, 5.4348e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,296][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([2.3603e-01, 2.3550e-03, 7.0187e-01, 1.0888e-04, 1.7491e-03, 2.3629e-04,
        3.4890e-05, 1.3371e-03, 5.3506e-02, 3.9496e-04, 7.0597e-05, 2.3093e-03],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,298][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0951, 0.0723, 0.1385, 0.0228, 0.2486, 0.0565, 0.0160, 0.0266, 0.0558,
        0.0790, 0.0116, 0.1772], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,299][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.5197e-01, 3.1483e-04, 6.7541e-01, 1.5848e-04, 8.4264e-03, 5.3667e-04,
        1.5018e-04, 2.0466e-02, 6.0142e-03, 1.8896e-04, 1.8796e-04, 3.6170e-02],
       device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards]
[2024-07-24 10:17:07,300][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Sarah] are: tensor([6.2927e-01, 1.9914e-04, 1.5960e-01, 1.7823e-04, 3.8849e-02, 7.6331e-04,
        5.2901e-04, 9.2985e-04, 1.4613e-02, 6.0845e-04, 1.4536e-03, 7.9519e-02,
        7.3487e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,301][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Sarah] are: tensor([3.6004e-01, 1.1900e-03, 4.2907e-01, 1.0209e-03, 1.5634e-02, 5.3949e-04,
        2.8565e-05, 1.5320e-04, 3.8866e-03, 1.9730e-03, 1.1610e-03, 1.8001e-01,
        5.2995e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,302][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Sarah] are: tensor([4.9147e-03, 2.6343e-03, 9.6785e-01, 7.0571e-04, 1.9359e-06, 1.0073e-03,
        1.0333e-04, 2.3692e-03, 6.4680e-03, 2.7282e-03, 1.3432e-03, 9.8700e-03,
        1.3515e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,302][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Sarah] are: tensor([1.5809e-02, 5.9215e-04, 5.1493e-02, 1.7454e-05, 9.1754e-04, 6.5475e-03,
        7.3579e-05, 7.7755e-03, 1.5280e-01, 3.2146e-03, 7.4750e-04, 7.4381e-01,
        1.6205e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,303][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Sarah] are: tensor([0.0024, 0.0163, 0.0233, 0.0370, 0.0490, 0.0115, 0.0924, 0.0922, 0.0081,
        0.0218, 0.0668, 0.3550, 0.2244], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,303][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Sarah] are: tensor([1.0633e-03, 8.6480e-04, 9.2157e-01, 1.6448e-04, 1.2531e-02, 2.1203e-03,
        6.3053e-05, 9.1110e-04, 4.9952e-03, 1.8165e-04, 1.9209e-04, 4.8657e-02,
        6.6890e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,303][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Sarah] are: tensor([1.8282e-02, 1.3730e-03, 9.5653e-01, 5.9563e-05, 1.5071e-03, 5.1571e-05,
        1.8709e-05, 2.9141e-03, 1.0937e-03, 3.0209e-04, 3.4017e-04, 1.5096e-02,
        2.4288e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,304][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Sarah] are: tensor([1.2687e-01, 1.6781e-04, 8.6123e-01, 7.2597e-05, 5.1982e-03, 2.1320e-05,
        7.2615e-05, 1.4359e-04, 9.3847e-04, 6.4765e-05, 1.2249e-04, 1.9109e-03,
        3.1880e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,304][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Sarah] are: tensor([0.0011, 0.0090, 0.6355, 0.0018, 0.0123, 0.1121, 0.0229, 0.0334, 0.1355,
        0.0057, 0.0016, 0.0267, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,304][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Sarah] are: tensor([6.3802e-04, 7.1477e-05, 9.4535e-01, 4.5961e-06, 1.7264e-04, 4.7423e-05,
        3.8974e-06, 5.8778e-05, 5.0401e-02, 3.0063e-05, 1.0773e-05, 3.1288e-03,
        8.0656e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,305][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Sarah] are: tensor([0.2440, 0.0094, 0.0117, 0.0022, 0.2335, 0.0121, 0.0019, 0.1212, 0.0208,
        0.0081, 0.0040, 0.2056, 0.1255], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,305][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Sarah] are: tensor([7.8114e-02, 1.4915e-05, 8.9754e-01, 2.5148e-07, 5.9614e-05, 6.9076e-06,
        3.5111e-06, 1.8009e-03, 2.7676e-03, 2.3741e-06, 1.5150e-06, 1.9620e-02,
        6.6262e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah]
[2024-07-24 10:17:07,305][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([8.4374e-01, 5.6143e-04, 2.7346e-02, 2.3862e-04, 3.1271e-02, 1.2584e-04,
        1.3826e-04, 1.1630e-03, 5.4383e-03, 2.4687e-03, 2.0442e-03, 2.2309e-02,
        5.8591e-02, 4.5675e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,306][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([8.4800e-03, 1.5889e-04, 9.5617e-01, 5.5347e-05, 2.3708e-02, 6.0247e-05,
        1.1334e-06, 3.1189e-05, 5.9346e-04, 3.9528e-05, 8.4717e-05, 7.5777e-03,
        2.8477e-03, 1.9542e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,307][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.1657e-03, 1.2129e-02, 9.4966e-01, 4.8029e-04, 1.9756e-04, 5.5235e-04,
        5.2583e-05, 5.5992e-03, 1.7361e-02, 2.4663e-03, 1.1252e-03, 5.6779e-03,
        5.8753e-05, 3.4767e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,308][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.0502e-02, 3.0055e-02, 9.0037e-02, 9.0876e-05, 2.1140e-02, 1.0891e-03,
        4.2078e-05, 1.2714e-03, 3.7068e-02, 1.4473e-02, 4.4209e-03, 4.6321e-01,
        3.2043e-01, 6.1650e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,309][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([2.5927e-04, 3.2840e-02, 7.5513e-02, 1.8150e-02, 2.9947e-02, 1.3700e-02,
        5.9673e-02, 2.6398e-01, 1.1270e-02, 3.6385e-03, 3.2667e-02, 3.5446e-01,
        3.5712e-02, 6.8194e-02], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,310][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([3.8810e-03, 2.4673e-03, 8.7170e-01, 3.4743e-05, 7.0116e-03, 2.5515e-04,
        9.1740e-06, 1.0443e-03, 2.8174e-03, 6.5235e-05, 3.9084e-05, 1.0780e-01,
        2.8413e-03, 2.4972e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,311][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([3.5409e-03, 3.6248e-04, 9.9083e-01, 7.2434e-06, 1.5680e-03, 1.8172e-05,
        1.8909e-06, 5.1753e-04, 5.5850e-05, 1.1383e-05, 4.6311e-05, 1.9967e-03,
        8.0792e-04, 2.3351e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,312][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.0862e-02, 1.9557e-03, 9.4557e-01, 2.4760e-04, 1.8087e-02, 5.1080e-04,
        6.3996e-05, 1.6702e-03, 5.7109e-04, 1.6727e-04, 5.5209e-04, 3.2671e-03,
        5.2007e-03, 1.2768e-03], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,314][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0201, 0.0521, 0.1476, 0.0110, 0.0061, 0.1522, 0.0038, 0.0158, 0.1796,
        0.2848, 0.0224, 0.0463, 0.0121, 0.0460], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,315][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.2408e-03, 4.7916e-05, 9.9449e-01, 5.1729e-07, 8.3541e-05, 1.4547e-05,
        2.8787e-07, 5.4938e-05, 3.2668e-03, 2.2313e-06, 5.3490e-07, 7.7636e-04,
        8.1590e-06, 1.7127e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,317][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0136, 0.0458, 0.0715, 0.0020, 0.2988, 0.0091, 0.0052, 0.0216, 0.0043,
        0.0825, 0.0049, 0.0613, 0.3722, 0.0072], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,318][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([1.4621e-02, 3.7356e-05, 9.7898e-01, 1.0792e-06, 4.4598e-04, 3.9968e-06,
        4.5680e-06, 5.2534e-04, 4.2079e-04, 2.1789e-06, 5.6037e-06, 3.7121e-03,
        1.0202e-03, 2.1791e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said]
[2024-07-24 10:17:07,319][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.5361, 0.0051, 0.0613, 0.0021, 0.0375, 0.0010, 0.0027, 0.0063, 0.0663,
        0.0229, 0.0155, 0.0784, 0.1369, 0.0234, 0.0046], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,320][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.9110e-02, 1.8199e-04, 8.1269e-01, 8.1286e-06, 9.7953e-02, 7.2584e-06,
        5.2690e-07, 6.6188e-06, 2.8522e-04, 2.9937e-05, 2.9894e-05, 6.9926e-03,
        5.2641e-02, 5.7724e-05, 4.0862e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,322][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.2027e-03, 7.0031e-03, 9.5496e-01, 2.4191e-04, 9.3952e-04, 2.8896e-04,
        2.1185e-05, 1.5859e-03, 6.6378e-03, 1.2880e-03, 6.3103e-04, 1.6698e-02,
        1.3588e-03, 3.4577e-03, 6.8892e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,323][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.1470e-03, 1.1689e-02, 1.7177e-01, 8.5131e-06, 3.0630e-03, 5.2965e-03,
        1.8469e-05, 5.3178e-04, 1.2980e-01, 7.5281e-03, 9.3780e-04, 5.3869e-01,
        1.1943e-01, 6.3672e-03, 7.1067e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,324][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0012, 0.0108, 0.0123, 0.0088, 0.0333, 0.0149, 0.0200, 0.0887, 0.0774,
        0.0087, 0.0359, 0.2612, 0.2364, 0.0407, 0.1497], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,325][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.1709e-02, 3.5094e-03, 6.8660e-01, 1.1104e-04, 8.0949e-02, 2.6658e-04,
        2.2640e-05, 3.8288e-04, 1.0191e-02, 2.4718e-04, 1.9015e-04, 1.1423e-01,
        9.1328e-02, 1.0071e-04, 1.6621e-04], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,325][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.6528e-02, 5.0658e-05, 9.8091e-01, 4.1844e-07, 1.0603e-03, 1.7089e-06,
        3.3731e-08, 7.7423e-05, 1.0512e-04, 2.0976e-06, 2.3520e-06, 3.2705e-04,
        8.8274e-04, 4.2307e-05, 1.1143e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,326][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([5.8382e-01, 7.6001e-05, 4.0465e-01, 8.5463e-05, 3.4867e-03, 7.6017e-05,
        1.6287e-05, 1.8310e-04, 1.1947e-03, 3.4374e-05, 2.8734e-04, 2.5784e-03,
        2.7969e-03, 6.9008e-04, 2.8404e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,326][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0003, 0.1033, 0.0203, 0.0112, 0.0044, 0.2151, 0.0032, 0.0013, 0.2559,
        0.2679, 0.0245, 0.0236, 0.0083, 0.0462, 0.0145], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,327][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.9859e-02, 3.6014e-04, 7.3596e-01, 9.0873e-06, 6.4328e-04, 6.8336e-05,
        2.9851e-06, 3.7862e-05, 1.9281e-01, 5.1472e-05, 1.7235e-05, 9.7350e-03,
        1.9574e-04, 2.1173e-04, 4.0303e-05], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,327][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0069, 0.0986, 0.0083, 0.0013, 0.2610, 0.0047, 0.0005, 0.0005, 0.0031,
        0.1325, 0.0046, 0.0299, 0.4451, 0.0006, 0.0024], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,327][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.7703e-02, 3.5564e-05, 9.3261e-01, 2.7091e-07, 2.5023e-03, 1.4631e-05,
        1.2699e-06, 4.7854e-04, 3.0848e-03, 4.0453e-06, 6.1727e-06, 1.1532e-02,
        2.1794e-02, 2.3005e-04, 5.3823e-06], device='cuda:0') for source tokens [Then, Brittany and Sarah had a long argument, and afterwards Sarah said to]
[2024-07-24 10:17:07,328][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:17:07,330][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[3402],
        [  22],
        [   1],
        [   1],
        [   1],
        [   7],
        [   1],
        [   3],
        [   5],
        [   2],
        [   3],
        [  10],
        [   2],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:17:07,331][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3857],
        [  27],
        [   4],
        [  15],
        [  32],
        [  98],
        [  26],
        [ 111],
        [  79],
        [  36],
        [  25],
        [ 107],
        [  70],
        [  71],
        [  34]], device='cuda:0')
[2024-07-24 10:17:07,333][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18821],
        [22937],
        [13588],
        [10343],
        [ 9585],
        [15294],
        [13456],
        [15975],
        [15450],
        [13311],
        [10657],
        [12890],
        [10795],
        [15710],
        [15994]], device='cuda:0')
[2024-07-24 10:17:07,334][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6490],
        [ 6363],
        [50112],
        [50113],
        [50134],
        [50117],
        [50114],
        [50140],
        [50134],
        [50176],
        [50186],
        [50168],
        [50164],
        [50118],
        [50148]], device='cuda:0')
[2024-07-24 10:17:07,335][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[8307],
        [8454],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1]], device='cuda:0')
[2024-07-24 10:17:07,337][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[35540],
        [35311],
        [38218],
        [49849],
        [49466],
        [49639],
        [42297],
        [45150],
        [49777],
        [46046],
        [34866],
        [37875],
        [15647],
        [34748],
        [29365]], device='cuda:0')
[2024-07-24 10:17:07,338][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[31150],
        [ 1710],
        [  602],
        [ 1724],
        [ 1015],
        [ 1700],
        [ 3471],
        [ 1061],
        [ 1535],
        [12810],
        [16543],
        [ 7579],
        [ 4683],
        [  977],
        [ 4507]], device='cuda:0')
[2024-07-24 10:17:07,340][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26636],
        [38354],
        [ 2738],
        [ 3125],
        [ 2746],
        [ 2958],
        [ 2955],
        [ 2786],
        [ 2840],
        [32594],
        [32404],
        [21559],
        [ 3238],
        [ 3626],
        [ 6982]], device='cuda:0')
[2024-07-24 10:17:07,341][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[23567],
        [12848],
        [    6],
        [    7],
        [   16],
        [   18],
        [   34],
        [   91],
        [   69],
        [   15],
        [   34],
        [  914],
        [   59],
        [  306],
        [   92]], device='cuda:0')
[2024-07-24 10:17:07,343][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[47781],
        [16894],
        [13961],
        [14345],
        [13968],
        [14884],
        [14965],
        [17442],
        [17764],
        [17070],
        [17206],
        [18067],
        [16659],
        [17596],
        [18442]], device='cuda:0')
[2024-07-24 10:17:07,344][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19738],
        [13252],
        [12399],
        [12742],
        [11058],
        [10891],
        [12540],
        [12900],
        [12354],
        [12319],
        [12261],
        [12684],
        [12138],
        [12490],
        [12700]], device='cuda:0')
[2024-07-24 10:17:07,346][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[2156],
        [2065],
        [  23],
        [  23],
        [  24],
        [  24],
        [  27],
        [  27],
        [  43],
        [ 151],
        [ 538],
        [  33],
        [  30],
        [  30],
        [  43]], device='cuda:0')
[2024-07-24 10:17:07,347][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[48442],
        [47657],
        [  449],
        [    1],
        [17604],
        [17546],
        [18328],
        [38903],
        [ 9881],
        [ 7618],
        [14056],
        [ 4690],
        [26201],
        [13809],
        [24754]], device='cuda:0')
[2024-07-24 10:17:07,349][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37367],
        [33578],
        [38179],
        [37505],
        [39703],
        [39453],
        [36053],
        [36758],
        [36819],
        [30232],
        [31924],
        [36371],
        [37562],
        [37682],
        [37454]], device='cuda:0')
[2024-07-24 10:17:07,350][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26816],
        [25471],
        [29384],
        [20514],
        [22839],
        [14195],
        [12703],
        [10310],
        [15952],
        [25492],
        [26621],
        [ 6456],
        [19378],
        [11149],
        [18651]], device='cuda:0')
[2024-07-24 10:17:07,351][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[34382],
        [36087],
        [35706],
        [37583],
        [35672],
        [33703],
        [34019],
        [34485],
        [36003],
        [36659],
        [37670],
        [34558],
        [34608],
        [33712],
        [35349]], device='cuda:0')
[2024-07-24 10:17:07,352][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[31626],
        [31820],
        [37943],
        [37753],
        [37157],
        [38014],
        [38109],
        [36592],
        [37185],
        [31988],
        [29783],
        [33121],
        [30152],
        [37772],
        [35727]], device='cuda:0')
[2024-07-24 10:17:07,353][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[46665],
        [48174],
        [23680],
        [12865],
        [12857],
        [15171],
        [12616],
        [30422],
        [14816],
        [12596],
        [14733],
        [18723],
        [12706],
        [12833],
        [12921]], device='cuda:0')
[2024-07-24 10:17:07,354][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[28147],
        [29598],
        [26560],
        [22531],
        [22171],
        [22643],
        [24789],
        [18609],
        [23694],
        [19680],
        [25187],
        [17063],
        [23765],
        [21485],
        [19713]], device='cuda:0')
[2024-07-24 10:17:07,355][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[30859],
        [30593],
        [31855],
        [12962],
        [18810],
        [17419],
        [13856],
        [18840],
        [18067],
        [19815],
        [17676],
        [14362],
        [13737],
        [17938],
        [13450]], device='cuda:0')
[2024-07-24 10:17:07,356][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[37029],
        [26047],
        [32349],
        [31855],
        [32368],
        [32347],
        [32335],
        [32361],
        [32329],
        [34056],
        [34377],
        [38882],
        [32616],
        [33171],
        [34510]], device='cuda:0')
[2024-07-24 10:17:07,358][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29005],
        [29109],
        [12491],
        [12472],
        [12605],
        [12422],
        [12402],
        [12571],
        [12455],
        [12441],
        [12688],
        [26292],
        [13016],
        [12493],
        [12454]], device='cuda:0')
[2024-07-24 10:17:07,359][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[37679],
        [37681],
        [17723],
        [21347],
        [17691],
        [17585],
        [20372],
        [17443],
        [17373],
        [33072],
        [37286],
        [22996],
        [17786],
        [17518],
        [19323]], device='cuda:0')
[2024-07-24 10:17:07,361][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[25197],
        [29746],
        [25174],
        [31677],
        [32823],
        [30955],
        [31889],
        [30182],
        [32196],
        [31560],
        [31647],
        [32492],
        [32750],
        [31147],
        [31322]], device='cuda:0')
[2024-07-24 10:17:07,362][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[33583],
        [37420],
        [10000],
        [10738],
        [ 9999],
        [10008],
        [10228],
        [10219],
        [10111],
        [20020],
        [20059],
        [11084],
        [10481],
        [10030],
        [12898]], device='cuda:0')
[2024-07-24 10:17:07,363][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[24479],
        [26208],
        [46507],
        [48341],
        [48261],
        [48056],
        [48183],
        [37453],
        [47651],
        [48595],
        [48273],
        [47088],
        [46911],
        [48246],
        [47353]], device='cuda:0')
[2024-07-24 10:17:07,365][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[22368],
        [22353],
        [15305],
        [16354],
        [15343],
        [15346],
        [15351],
        [14523],
        [14317],
        [15388],
        [20238],
        [14577],
        [15065],
        [15301],
        [15187]], device='cuda:0')
[2024-07-24 10:17:07,366][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 4570],
        [ 3945],
        [14587],
        [18776],
        [20099],
        [19804],
        [19615],
        [20636],
        [19543],
        [14744],
        [11227],
        [16104],
        [21605],
        [19859],
        [20502]], device='cuda:0')
[2024-07-24 10:17:07,368][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23027],
        [22044],
        [21157],
        [26828],
        [23331],
        [27186],
        [27987],
        [32184],
        [26975],
        [22636],
        [21133],
        [32497],
        [24682],
        [27017],
        [26273]], device='cuda:0')
[2024-07-24 10:17:07,369][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808],
        [35808]], device='cuda:0')
